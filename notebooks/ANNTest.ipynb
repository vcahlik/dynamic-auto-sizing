{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from nets.core import train_model, prune_parameters, get_layer_sizes, initialize_parameters\n",
    "from nets.datasets import mnist_3\n",
    "from nets.utils import measure_accuracy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import copy\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = mnist_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784, 33600), (1, 33600))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784, 8400), (1, 8400))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pixels = X_train[:, 1].reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dims = [784, 20, 20, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.430815\n",
      "Cost after epoch 1: 0.407259\n",
      "Cost after epoch 2: 0.406516\n",
      "Cost after epoch 3: 0.408454\n",
      "Cost after epoch 4: 0.410047\n",
      "Cost after epoch 5: 0.410788\n",
      "Cost after epoch 6: 0.410328\n",
      "Cost after epoch 7: 0.406868\n",
      "Cost after epoch 8: 0.393573\n",
      "Cost after epoch 9: 0.362331\n",
      "Cost after epoch 10: 0.317457\n",
      "Cost after epoch 11: 0.279190\n",
      "Cost after epoch 12: 0.236498\n",
      "Cost after epoch 13: 0.149960\n",
      "Cost after epoch 14: 0.104616\n",
      "Cost after epoch 15: 0.093431\n",
      "Cost after epoch 16: 0.087492\n",
      "Cost after epoch 17: 0.083259\n",
      "Cost after epoch 18: 0.080126\n",
      "Cost after epoch 19: 0.077734\n",
      "Cost after epoch 20: 0.075829\n",
      "Cost after epoch 21: 0.074281\n",
      "Cost after epoch 22: 0.072976\n",
      "Cost after epoch 23: 0.071847\n",
      "Cost after epoch 24: 0.070862\n",
      "Cost after epoch 25: 0.069997\n",
      "Cost after epoch 26: 0.069224\n",
      "Cost after epoch 27: 0.068522\n",
      "Cost after epoch 28: 0.067895\n",
      "Cost after epoch 29: 0.067314\n"
     ]
    }
   ],
   "source": [
    "parameters_unreg = L_layer_model(X_train, y_train, layers_dims, learning_rate=0.01, l1_term=0, num_epochs=30, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9755357142857143"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "p, _ = L_model_forward(X_train, parameters_unreg)\n",
    "y_train_pred = (p > 0.5).astype(int)\n",
    "accuracy_score(y_train.reshape((-1),), y_train_pred.reshape((-1),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.448906\n",
      "Cost after epoch 1: 0.423507\n",
      "Cost after epoch 2: 0.421041\n",
      "Cost after epoch 3: 0.421441\n",
      "Cost after epoch 4: 0.421764\n",
      "Cost after epoch 5: 0.421659\n",
      "Cost after epoch 6: 0.421221\n",
      "Cost after epoch 7: 0.420585\n",
      "Cost after epoch 8: 0.419848\n",
      "Cost after epoch 9: 0.419061\n",
      "Cost after epoch 10: 0.418218\n",
      "Cost after epoch 11: 0.417216\n",
      "Cost after epoch 12: 0.415717\n",
      "Cost after epoch 13: 0.412344\n",
      "Cost after epoch 14: 0.402713\n",
      "Cost after epoch 15: 0.380030\n",
      "Cost after epoch 16: 0.339927\n",
      "Cost after epoch 17: 0.303582\n",
      "Cost after epoch 18: 0.273109\n",
      "Cost after epoch 19: 0.246411\n",
      "Cost after epoch 20: 0.223080\n",
      "Cost after epoch 21: 0.203517\n",
      "Cost after epoch 22: 0.185436\n",
      "Cost after epoch 23: 0.167289\n",
      "Cost after epoch 24: 0.142887\n",
      "Cost after epoch 25: 0.113212\n",
      "Cost after epoch 26: 0.098133\n",
      "Cost after epoch 27: 0.092885\n",
      "Cost after epoch 28: 0.090363\n",
      "Cost after epoch 29: 0.088437\n"
     ]
    }
   ],
   "source": [
    "parameters_reg = L_layer_model(X_train, y_train, layers_dims, learning_rate=0.01, l1_term=0.01, num_epochs=30, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736607142857143"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "p, _ = L_model_forward(X_train, parameters_reg)\n",
    "y_train_pred = (p > 0.5).astype(int)\n",
    "accuracy_score(y_train.reshape((-1),), y_train_pred.reshape((-1),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.448215\n",
      "Cost after epoch 1: 0.422285\n",
      "Cost after epoch 2: 0.419419\n",
      "Cost after epoch 3: 0.419546\n",
      "Cost after epoch 4: 0.419713\n",
      "Cost after epoch 5: 0.419547\n",
      "Cost after epoch 6: 0.419121\n",
      "Cost after epoch 7: 0.418531\n",
      "Cost after epoch 8: 0.417825\n",
      "Cost after epoch 9: 0.416959\n",
      "Cost after epoch 10: 0.415629\n",
      "Cost after epoch 11: 0.413236\n",
      "Cost after epoch 12: 0.410141\n",
      "Cost after epoch 13: 0.403526\n",
      "Cost after epoch 14: 0.386231\n",
      "Cost after epoch 15: 0.349768\n",
      "Cost after epoch 16: 0.299857\n",
      "Cost after epoch 17: 0.187668\n",
      "Cost after epoch 18: 0.121146\n",
      "Cost after epoch 19: 0.106763\n",
      "Cost after epoch 20: 0.099291\n",
      "Cost after epoch 21: 0.094234\n",
      "Cost after epoch 22: 0.090470\n",
      "Cost after epoch 23: 0.087580\n",
      "Cost after epoch 24: 0.085306\n",
      "Cost after epoch 25: 0.083472\n",
      "Cost after epoch 26: 0.081934\n",
      "Cost after epoch 27: 0.080627\n",
      "Cost after epoch 28: 0.079499\n",
      "Cost after epoch 29: 0.078535\n",
      "Cost after epoch 30: 0.077693\n",
      "Cost after epoch 31: 0.076980\n",
      "Cost after epoch 32: 0.076358\n",
      "Cost after epoch 33: 0.075795\n",
      "Cost after epoch 34: 0.075295\n",
      "Cost after epoch 35: 0.074814\n",
      "Cost after epoch 36: 0.074359\n",
      "Cost after epoch 37: 0.073934\n",
      "Cost after epoch 38: 0.073625\n",
      "Cost after epoch 39: 0.073329\n",
      "Cost after epoch 40: 0.073035\n",
      "Cost after epoch 41: 0.072740\n",
      "Cost after epoch 42: 0.072441\n",
      "Cost after epoch 43: 0.072187\n",
      "Cost after epoch 44: 0.072094\n",
      "Cost after epoch 45: 0.072208\n",
      "Cost after epoch 46: 0.072237\n",
      "Cost after epoch 47: 0.072370\n",
      "Cost after epoch 48: 0.072796\n",
      "Cost after epoch 49: 0.072981\n",
      "Cost after epoch 50: 0.073376\n",
      "Cost after epoch 51: 0.073511\n",
      "Cost after epoch 52: 0.073340\n",
      "Cost after epoch 53: 0.072962\n",
      "Cost after epoch 54: 0.072694\n",
      "Cost after epoch 55: 0.072377\n",
      "Cost after epoch 56: 0.071958\n",
      "Cost after epoch 57: 0.071738\n",
      "Cost after epoch 58: 0.071435\n",
      "Cost after epoch 59: 0.070789\n",
      "Cost after epoch 60: 0.070075\n",
      "Cost after epoch 61: 0.069983\n",
      "Cost after epoch 62: 0.069670\n",
      "Cost after epoch 63: 0.069076\n",
      "Cost after epoch 64: 0.068713\n",
      "Cost after epoch 65: 0.068357\n",
      "Cost after epoch 66: 0.068383\n",
      "Cost after epoch 67: 0.066190\n",
      "Cost after epoch 68: 0.061159\n",
      "Cost after epoch 69: 0.056961\n",
      "Cost after epoch 70: 0.054162\n",
      "Cost after epoch 71: 0.051812\n",
      "Cost after epoch 72: 0.049973\n",
      "Cost after epoch 73: 0.047876\n",
      "Cost after epoch 74: 0.045532\n",
      "Cost after epoch 75: 0.043354\n",
      "Cost after epoch 76: 0.041123\n",
      "Cost after epoch 77: 0.039341\n",
      "Cost after epoch 78: 0.037737\n",
      "Cost after epoch 79: 0.036302\n",
      "Cost after epoch 80: 0.035040\n",
      "Cost after epoch 81: 0.034068\n",
      "Cost after epoch 82: 0.033023\n",
      "Cost after epoch 83: 0.032225\n",
      "Cost after epoch 84: 0.031641\n",
      "Cost after epoch 85: 0.031024\n",
      "Cost after epoch 86: 0.030130\n",
      "Cost after epoch 87: 0.029528\n",
      "Cost after epoch 88: 0.028878\n",
      "Cost after epoch 89: 0.028356\n",
      "Cost after epoch 90: 0.027550\n",
      "Cost after epoch 91: 0.027020\n",
      "Cost after epoch 92: 0.026544\n",
      "Cost after epoch 93: 0.026058\n",
      "Cost after epoch 94: 0.025477\n",
      "Cost after epoch 95: 0.025001\n",
      "Cost after epoch 96: 0.024826\n",
      "Cost after epoch 97: 0.024601\n",
      "Cost after epoch 98: 0.023946\n",
      "Cost after epoch 99: 0.023431\n"
     ]
    }
   ],
   "source": [
    "parameters_scaled = L_layer_model(X_train, y_train, layers_dims, learning_rate=0.01, l1_term=0.02, self_scale=True, num_epochs=100, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9853273809523809"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "p, _ = L_model_forward(X_train, parameters_scaled)\n",
    "y_train_pred = (p > 0.5).astype(int)\n",
    "accuracy_score(y_train.reshape((-1),), y_train_pred.reshape((-1),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[784, 8, 12, 1]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_pruned = copy.deepcopy(parameters_scaled)\n",
    "prune_parameters(parameters_pruned)\n",
    "get_layer_sizes(parameters_pruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9853273809523809"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "p, _ = L_model_forward(X_train, parameters_pruned)\n",
    "y_train_pred = (p > 0.5).astype(int)\n",
    "accuracy_score(y_train.reshape((-1),), y_train_pred.reshape((-1),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.431117\n",
      "Cost after epoch 1: 0.407389\n",
      "Cost after epoch 2: 0.406448\n",
      "Cost after epoch 3: 0.408345\n",
      "Cost after epoch 4: 0.410126\n",
      "Cost after epoch 5: 0.411401\n",
      "Cost after epoch 6: 0.412244\n",
      "Cost after epoch 7: 0.412780\n",
      "Cost after epoch 8: 0.413115\n",
      "Cost after epoch 9: 0.413321\n",
      "Cost after epoch 10: 0.413444\n",
      "Cost after epoch 11: 0.413513\n",
      "Cost after epoch 12: 0.413546\n",
      "Cost after epoch 13: 0.413552\n",
      "Cost after epoch 14: 0.413534\n",
      "Cost after epoch 15: 0.413488\n",
      "Cost after epoch 16: 0.413402\n",
      "Cost after epoch 17: 0.413240\n",
      "Cost after epoch 18: 0.412923\n",
      "Cost after epoch 19: 0.412322\n",
      "Cost after epoch 20: 0.411303\n",
      "Cost after epoch 21: 0.409002\n",
      "Cost after epoch 22: 0.402787\n",
      "Cost after epoch 23: 0.383750\n",
      "Cost after epoch 24: 0.334164\n",
      "Cost after epoch 25: 0.208864\n",
      "Cost after epoch 26: 0.124095\n",
      "Cost after epoch 27: 0.105026\n",
      "Cost after epoch 28: 0.095823\n",
      "Cost after epoch 29: 0.089813\n",
      "Cost after epoch 30: 0.085375\n",
      "Cost after epoch 31: 0.081924\n",
      "Cost after epoch 32: 0.079218\n",
      "Cost after epoch 33: 0.077065\n",
      "Cost after epoch 34: 0.075308\n",
      "Cost after epoch 35: 0.073841\n",
      "Cost after epoch 36: 0.072621\n",
      "Cost after epoch 37: 0.071629\n",
      "Cost after epoch 38: 0.070747\n",
      "Cost after epoch 39: 0.070038\n",
      "Cost after epoch 40: 0.069406\n",
      "Cost after epoch 41: 0.068876\n",
      "Cost after epoch 42: 0.068422\n",
      "Cost after epoch 43: 0.068009\n",
      "Cost after epoch 44: 0.067676\n",
      "Cost after epoch 45: 0.067313\n",
      "Cost after epoch 46: 0.067072\n",
      "Cost after epoch 47: 0.066974\n",
      "Cost after epoch 48: 0.066827\n",
      "Cost after epoch 49: 0.066702\n",
      "Cost after epoch 50: 0.066575\n",
      "Cost after epoch 51: 0.066520\n",
      "Cost after epoch 52: 0.066595\n",
      "Cost after epoch 53: 0.066594\n",
      "Cost after epoch 54: 0.066500\n",
      "Cost after epoch 55: 0.066440\n",
      "Cost after epoch 56: 0.066450\n",
      "Cost after epoch 57: 0.066451\n",
      "Cost after epoch 58: 0.066702\n",
      "Cost after epoch 59: 0.066892\n",
      "Cost after epoch 60: 0.067260\n",
      "Cost after epoch 61: 0.067365\n",
      "Cost after epoch 62: 0.067596\n",
      "Cost after epoch 63: 0.067632\n",
      "Cost after epoch 64: 0.067940\n",
      "Cost after epoch 65: 0.068240\n",
      "Cost after epoch 66: 0.068544\n",
      "Cost after epoch 67: 0.068331\n",
      "Cost after epoch 68: 0.068467\n",
      "Cost after epoch 69: 0.068550\n",
      "Cost after epoch 70: 0.068661\n",
      "Cost after epoch 71: 0.068617\n",
      "Cost after epoch 72: 0.068709\n",
      "Cost after epoch 73: 0.068709\n",
      "Cost after epoch 74: 0.068559\n",
      "Cost after epoch 75: 0.068438\n",
      "Cost after epoch 76: 0.068012\n",
      "Cost after epoch 77: 0.067799\n",
      "Cost after epoch 78: 0.067727\n",
      "Cost after epoch 79: 0.067546\n",
      "Cost after epoch 80: 0.067262\n",
      "Cost after epoch 81: 0.066814\n",
      "Cost after epoch 82: 0.066371\n",
      "Cost after epoch 83: 0.066045\n",
      "Cost after epoch 84: 0.065600\n",
      "Cost after epoch 85: 0.065497\n",
      "Cost after epoch 86: 0.065064\n",
      "Cost after epoch 87: 0.064390\n",
      "Cost after epoch 88: 0.063588\n",
      "Cost after epoch 89: 0.062821\n",
      "Cost after epoch 90: 0.062379\n",
      "Cost after epoch 91: 0.062169\n",
      "Cost after epoch 92: 0.061784\n",
      "Cost after epoch 93: 0.060961\n",
      "Cost after epoch 94: 0.060144\n",
      "Cost after epoch 95: 0.058691\n",
      "Cost after epoch 96: 0.058100\n",
      "Cost after epoch 97: 0.057479\n",
      "Cost after epoch 98: 0.056489\n",
      "Cost after epoch 99: 0.054484\n"
     ]
    }
   ],
   "source": [
    "parameters = L_layer_model(X_train, y_train, get_layer_sizes(parameters_pruned), learning_rate=0.01, num_epochs=100, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9823809523809524"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "p, _ = L_model_forward(X_train, parameters)\n",
    "y_train_pred = (p > 0.5).astype(int)\n",
    "accuracy_score(y_train.reshape((-1),), y_train_pred.reshape((-1),))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keeping parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dims = [784, 20, 20, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.430815\n",
      "Cost after epoch 1: 0.407259\n",
      "Cost after epoch 2: 0.406516\n",
      "Cost after epoch 3: 0.408454\n",
      "Cost after epoch 4: 0.410047\n",
      "Cost after epoch 5: 0.410788\n",
      "Cost after epoch 6: 0.410328\n",
      "Cost after epoch 7: 0.406868\n",
      "Cost after epoch 8: 0.393573\n",
      "Cost after epoch 9: 0.362331\n",
      "Cost after epoch 10: 0.317457\n",
      "Cost after epoch 11: 0.279190\n",
      "Cost after epoch 12: 0.236498\n",
      "Cost after epoch 13: 0.149960\n",
      "Cost after epoch 14: 0.104616\n",
      "Cost after epoch 15: 0.093431\n",
      "Cost after epoch 16: 0.087492\n",
      "Cost after epoch 17: 0.083259\n",
      "Cost after epoch 18: 0.080126\n",
      "Cost after epoch 19: 0.077734\n",
      "Cost after epoch 20: 0.075829\n",
      "Cost after epoch 21: 0.074281\n",
      "Cost after epoch 22: 0.072976\n",
      "Cost after epoch 23: 0.071847\n",
      "Cost after epoch 24: 0.070862\n",
      "Cost after epoch 25: 0.069997\n",
      "Cost after epoch 26: 0.069224\n",
      "Cost after epoch 27: 0.068522\n",
      "Cost after epoch 28: 0.067895\n",
      "Cost after epoch 29: 0.067314\n",
      "Cost after epoch 30: 0.066769\n",
      "Cost after epoch 31: 0.066249\n",
      "Cost after epoch 32: 0.065738\n",
      "Cost after epoch 33: 0.065234\n",
      "Cost after epoch 34: 0.064723\n",
      "Cost after epoch 35: 0.064188\n",
      "Cost after epoch 36: 0.063613\n",
      "Cost after epoch 37: 0.062983\n",
      "Cost after epoch 38: 0.062318\n",
      "Cost after epoch 39: 0.061564\n",
      "Cost after epoch 40: 0.060717\n",
      "Cost after epoch 41: 0.059782\n",
      "Cost after epoch 42: 0.058759\n",
      "Cost after epoch 43: 0.057612\n",
      "Cost after epoch 44: 0.056375\n",
      "Cost after epoch 45: 0.055024\n",
      "Cost after epoch 46: 0.053552\n",
      "Cost after epoch 47: 0.051957\n",
      "Cost after epoch 48: 0.050289\n",
      "Cost after epoch 49: 0.048507\n",
      "Cost after epoch 50: 0.046679\n",
      "Cost after epoch 51: 0.044811\n",
      "Cost after epoch 52: 0.042911\n",
      "Cost after epoch 53: 0.040999\n",
      "Cost after epoch 54: 0.039117\n",
      "Cost after epoch 55: 0.037220\n",
      "Cost after epoch 56: 0.035417\n",
      "Cost after epoch 57: 0.033674\n",
      "Cost after epoch 58: 0.032049\n",
      "Cost after epoch 59: 0.030560\n",
      "Cost after epoch 60: 0.029026\n",
      "Cost after epoch 61: 0.027769\n",
      "Cost after epoch 62: 0.026482\n",
      "Cost after epoch 63: 0.025328\n",
      "Cost after epoch 64: 0.024238\n",
      "Cost after epoch 65: 0.023118\n",
      "Cost after epoch 66: 0.022022\n",
      "Cost after epoch 67: 0.020988\n",
      "Cost after epoch 68: 0.020226\n",
      "Cost after epoch 69: 0.019533\n",
      "Cost after epoch 70: 0.019016\n",
      "Cost after epoch 71: 0.018467\n",
      "Cost after epoch 72: 0.018029\n",
      "Cost after epoch 73: 0.017573\n",
      "Cost after epoch 74: 0.017088\n",
      "Cost after epoch 75: 0.016592\n",
      "Cost after epoch 76: 0.016105\n",
      "Cost after epoch 77: 0.015767\n",
      "Cost after epoch 78: 0.015228\n",
      "Cost after epoch 79: 0.014759\n",
      "Cost after epoch 80: 0.014488\n",
      "Cost after epoch 81: 0.013853\n",
      "Cost after epoch 82: 0.013319\n",
      "Cost after epoch 83: 0.013079\n",
      "Cost after epoch 84: 0.012902\n",
      "Cost after epoch 85: 0.012548\n",
      "Cost after epoch 86: 0.012250\n",
      "Cost after epoch 87: 0.012016\n",
      "Cost after epoch 88: 0.011870\n",
      "Cost after epoch 89: 0.011578\n",
      "Cost after epoch 90: 0.011348\n",
      "Cost after epoch 91: 0.011341\n",
      "Cost after epoch 92: 0.010855\n",
      "Cost after epoch 93: 0.010778\n",
      "Cost after epoch 94: 0.010555\n",
      "Cost after epoch 95: 0.010455\n",
      "Cost after epoch 96: 0.010418\n",
      "Cost after epoch 97: 0.010222\n",
      "Cost after epoch 98: 0.009982\n",
      "Cost after epoch 99: 0.009865\n"
     ]
    }
   ],
   "source": [
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters = train_model(X_train, y_train, parameters, learning_rate=0.01, num_epochs=100, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9906845238095238"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_accuracy(parameters, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9864285714285714"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_accuracy(parameters, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dims_small = [784, 11, 14, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.431119\n",
      "Cost after epoch 1: 0.407392\n",
      "Cost after epoch 2: 0.406453\n",
      "Cost after epoch 3: 0.408351\n",
      "Cost after epoch 4: 0.410132\n",
      "Cost after epoch 5: 0.411408\n",
      "Cost after epoch 6: 0.412251\n",
      "Cost after epoch 7: 0.412789\n",
      "Cost after epoch 8: 0.413124\n",
      "Cost after epoch 9: 0.413329\n",
      "Cost after epoch 10: 0.413451\n",
      "Cost after epoch 11: 0.413520\n",
      "Cost after epoch 12: 0.413550\n",
      "Cost after epoch 13: 0.413549\n",
      "Cost after epoch 14: 0.413519\n",
      "Cost after epoch 15: 0.413448\n",
      "Cost after epoch 16: 0.413308\n",
      "Cost after epoch 17: 0.413034\n",
      "Cost after epoch 18: 0.412481\n",
      "Cost after epoch 19: 0.411448\n",
      "Cost after epoch 20: 0.409207\n",
      "Cost after epoch 21: 0.403088\n",
      "Cost after epoch 22: 0.383622\n",
      "Cost after epoch 23: 0.322974\n",
      "Cost after epoch 24: 0.168219\n",
      "Cost after epoch 25: 0.118703\n",
      "Cost after epoch 26: 0.103595\n",
      "Cost after epoch 27: 0.095517\n",
      "Cost after epoch 28: 0.090004\n",
      "Cost after epoch 29: 0.085756\n",
      "Cost after epoch 30: 0.082504\n",
      "Cost after epoch 31: 0.079982\n",
      "Cost after epoch 32: 0.078035\n",
      "Cost after epoch 33: 0.076483\n",
      "Cost after epoch 34: 0.075296\n",
      "Cost after epoch 35: 0.074187\n",
      "Cost after epoch 36: 0.073324\n",
      "Cost after epoch 37: 0.072459\n",
      "Cost after epoch 38: 0.071860\n",
      "Cost after epoch 39: 0.071252\n",
      "Cost after epoch 40: 0.070688\n",
      "Cost after epoch 41: 0.070261\n",
      "Cost after epoch 42: 0.069987\n",
      "Cost after epoch 43: 0.069726\n",
      "Cost after epoch 44: 0.069212\n",
      "Cost after epoch 45: 0.068893\n",
      "Cost after epoch 46: 0.068676\n",
      "Cost after epoch 47: 0.068560\n",
      "Cost after epoch 48: 0.068544\n",
      "Cost after epoch 49: 0.068528\n",
      "Cost after epoch 50: 0.068499\n",
      "Cost after epoch 51: 0.068478\n",
      "Cost after epoch 52: 0.068484\n",
      "Cost after epoch 53: 0.068433\n",
      "Cost after epoch 54: 0.068511\n",
      "Cost after epoch 55: 0.068750\n",
      "Cost after epoch 56: 0.068740\n",
      "Cost after epoch 57: 0.068966\n",
      "Cost after epoch 58: 0.069086\n",
      "Cost after epoch 59: 0.069147\n",
      "Cost after epoch 60: 0.069477\n",
      "Cost after epoch 61: 0.069603\n",
      "Cost after epoch 62: 0.069732\n",
      "Cost after epoch 63: 0.069866\n",
      "Cost after epoch 64: 0.070251\n",
      "Cost after epoch 65: 0.070466\n",
      "Cost after epoch 66: 0.070514\n",
      "Cost after epoch 67: 0.070498\n",
      "Cost after epoch 68: 0.070302\n",
      "Cost after epoch 69: 0.070259\n",
      "Cost after epoch 70: 0.070325\n",
      "Cost after epoch 71: 0.070407\n",
      "Cost after epoch 72: 0.070087\n",
      "Cost after epoch 73: 0.068971\n",
      "Cost after epoch 74: 0.065581\n",
      "Cost after epoch 75: 0.062404\n",
      "Cost after epoch 76: 0.059023\n",
      "Cost after epoch 77: 0.055576\n",
      "Cost after epoch 78: 0.051873\n",
      "Cost after epoch 79: 0.048111\n",
      "Cost after epoch 80: 0.044169\n",
      "Cost after epoch 81: 0.041931\n",
      "Cost after epoch 82: 0.039913\n",
      "Cost after epoch 83: 0.038020\n",
      "Cost after epoch 84: 0.036523\n",
      "Cost after epoch 85: 0.035089\n",
      "Cost after epoch 86: 0.033874\n",
      "Cost after epoch 87: 0.031480\n",
      "Cost after epoch 88: 0.029776\n",
      "Cost after epoch 89: 0.027987\n",
      "Cost after epoch 90: 0.026479\n",
      "Cost after epoch 91: 0.024758\n",
      "Cost after epoch 92: 0.023224\n",
      "Cost after epoch 93: 0.021863\n",
      "Cost after epoch 94: 0.020510\n",
      "Cost after epoch 95: 0.019516\n",
      "Cost after epoch 96: 0.018425\n",
      "Cost after epoch 97: 0.017308\n",
      "Cost after epoch 98: 0.016164\n",
      "Cost after epoch 99: 0.015265\n"
     ]
    }
   ],
   "source": [
    "parameters = initialize_parameters(layers_dims_small)\n",
    "parameters_small = train_model(X_train, y_train, parameters, learning_rate=0.01, num_epochs=100, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9866964285714286"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_accuracy(parameters_small, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9826190476190476"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_accuracy(parameters_small, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.448215\n",
      "Cost after epoch 1: 0.422285\n",
      "Cost after epoch 2: 0.419419\n",
      "Cost after epoch 3: 0.419546\n",
      "Cost after epoch 4: 0.419713\n",
      "Cost after epoch 5: 0.419547\n",
      "Cost after epoch 6: 0.419121\n",
      "Cost after epoch 7: 0.418531\n",
      "Cost after epoch 8: 0.417825\n",
      "Cost after epoch 9: 0.416959\n",
      "Cost after epoch 10: 0.415629\n",
      "Cost after epoch 11: 0.413236\n",
      "Cost after epoch 12: 0.410141\n",
      "Cost after epoch 13: 0.403526\n",
      "Cost after epoch 14: 0.386231\n",
      "Cost after epoch 15: 0.349768\n",
      "Cost after epoch 16: 0.299857\n",
      "Cost after epoch 17: 0.187668\n",
      "Cost after epoch 18: 0.121146\n",
      "Cost after epoch 19: 0.106763\n",
      "Cost after epoch 20: 0.099291\n",
      "Cost after epoch 21: 0.094234\n",
      "Cost after epoch 22: 0.090470\n",
      "Cost after epoch 23: 0.087580\n",
      "Cost after epoch 24: 0.085306\n",
      "Cost after epoch 25: 0.083472\n",
      "Cost after epoch 26: 0.081934\n",
      "Cost after epoch 27: 0.080627\n",
      "Cost after epoch 28: 0.079499\n",
      "Cost after epoch 29: 0.078535\n",
      "Cost after epoch 30: 0.077693\n",
      "Cost after epoch 31: 0.076980\n",
      "Cost after epoch 32: 0.076358\n",
      "Cost after epoch 33: 0.075795\n",
      "Cost after epoch 34: 0.075295\n",
      "Cost after epoch 35: 0.074814\n",
      "Cost after epoch 36: 0.074359\n",
      "Cost after epoch 37: 0.073934\n",
      "Cost after epoch 38: 0.073625\n",
      "Cost after epoch 39: 0.073329\n",
      "Cost after epoch 40: 0.073035\n",
      "Cost after epoch 41: 0.072740\n",
      "Cost after epoch 42: 0.072441\n",
      "Cost after epoch 43: 0.072187\n",
      "Cost after epoch 44: 0.072094\n",
      "Cost after epoch 45: 0.072208\n",
      "Cost after epoch 46: 0.072237\n",
      "Cost after epoch 47: 0.072370\n",
      "Cost after epoch 48: 0.072796\n",
      "Cost after epoch 49: 0.072981\n"
     ]
    }
   ],
   "source": [
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters_scaled = train_model(X_train, y_train, parameters, learning_rate=0.01, l1_term=0.02, self_scale=True, num_epochs=50, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.976547619047619"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_accuracy(parameters_scaled, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[784, 11, 14, 1]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_pruned = copy.deepcopy(parameters_scaled)\n",
    "prune_parameters(parameters_pruned)\n",
    "get_layer_sizes(parameters_pruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.976547619047619"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_accuracy(parameters_pruned, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.068162\n",
      "Cost after epoch 1: 0.068107\n",
      "Cost after epoch 2: 0.067846\n",
      "Cost after epoch 3: 0.067470\n",
      "Cost after epoch 4: 0.067049\n",
      "Cost after epoch 5: 0.066743\n",
      "Cost after epoch 6: 0.066580\n",
      "Cost after epoch 7: 0.065768\n",
      "Cost after epoch 8: 0.065288\n",
      "Cost after epoch 9: 0.064633\n",
      "Cost after epoch 10: 0.063909\n",
      "Cost after epoch 11: 0.063855\n",
      "Cost after epoch 12: 0.063281\n",
      "Cost after epoch 13: 0.063048\n",
      "Cost after epoch 14: 0.063028\n",
      "Cost after epoch 15: 0.063694\n",
      "Cost after epoch 16: 0.062957\n",
      "Cost after epoch 17: 0.057640\n",
      "Cost after epoch 18: 0.053005\n",
      "Cost after epoch 19: 0.049765\n",
      "Cost after epoch 20: 0.047411\n",
      "Cost after epoch 21: 0.043448\n",
      "Cost after epoch 22: 0.039785\n",
      "Cost after epoch 23: 0.036768\n",
      "Cost after epoch 24: 0.034182\n",
      "Cost after epoch 25: 0.032045\n",
      "Cost after epoch 26: 0.029961\n",
      "Cost after epoch 27: 0.028210\n",
      "Cost after epoch 28: 0.026672\n",
      "Cost after epoch 29: 0.024867\n",
      "Cost after epoch 30: 0.023336\n",
      "Cost after epoch 31: 0.022010\n",
      "Cost after epoch 32: 0.020892\n",
      "Cost after epoch 33: 0.019923\n",
      "Cost after epoch 34: 0.018760\n",
      "Cost after epoch 35: 0.017389\n",
      "Cost after epoch 36: 0.015794\n",
      "Cost after epoch 37: 0.014446\n",
      "Cost after epoch 38: 0.013093\n",
      "Cost after epoch 39: 0.011893\n",
      "Cost after epoch 40: 0.010868\n",
      "Cost after epoch 41: 0.009833\n",
      "Cost after epoch 42: 0.009270\n",
      "Cost after epoch 43: 0.008523\n",
      "Cost after epoch 44: 0.008040\n",
      "Cost after epoch 45: 0.007535\n",
      "Cost after epoch 46: 0.007081\n",
      "Cost after epoch 47: 0.006552\n",
      "Cost after epoch 48: 0.006187\n",
      "Cost after epoch 49: 0.005854\n"
     ]
    }
   ],
   "source": [
    "parameters_final = train_model(X_train, y_train, parameters_pruned, learning_rate=0.01, num_epochs=50, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9891666666666666"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_accuracy(parameters_final, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9841666666666666"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_accuracy(parameters_final, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[784, 20, 20, 1]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agnosticity about initial number of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dims = [784, 20, 20, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.447466\n",
      "Cost after epoch 1: 0.421750\n",
      "Cost after epoch 2: 0.419062\n",
      "Cost after epoch 3: 0.419331\n",
      "Cost after epoch 4: 0.419606\n",
      "Cost after epoch 5: 0.419520\n",
      "Cost after epoch 6: 0.419143\n",
      "Cost after epoch 7: 0.418580\n",
      "Cost after epoch 8: 0.417862\n",
      "Cost after epoch 9: 0.416916\n",
      "Cost after epoch 10: 0.415325\n",
      "Cost after epoch 11: 0.412548\n",
      "Cost after epoch 12: 0.408499\n",
      "Cost after epoch 13: 0.398863\n",
      "Cost after epoch 14: 0.374069\n",
      "Cost after epoch 15: 0.331510\n",
      "Cost after epoch 16: 0.272481\n",
      "Cost after epoch 17: 0.147786\n",
      "Cost after epoch 18: 0.114804\n",
      "Cost after epoch 19: 0.103948\n",
      "Cost after epoch 20: 0.097586\n",
      "Cost after epoch 21: 0.093109\n",
      "Cost after epoch 22: 0.089724\n",
      "Cost after epoch 23: 0.087075\n",
      "Cost after epoch 24: 0.084956\n",
      "Cost after epoch 25: 0.083225\n",
      "Cost after epoch 26: 0.081775\n",
      "Cost after epoch 27: 0.080528\n",
      "Cost after epoch 28: 0.079445\n",
      "Cost after epoch 29: 0.078504\n",
      "Cost after epoch 30: 0.077669\n",
      "Cost after epoch 31: 0.076941\n",
      "Cost after epoch 32: 0.076331\n",
      "Cost after epoch 33: 0.075784\n",
      "Cost after epoch 34: 0.075296\n",
      "Cost after epoch 35: 0.074838\n",
      "Cost after epoch 36: 0.074403\n",
      "Cost after epoch 37: 0.073989\n",
      "Cost after epoch 38: 0.073656\n",
      "Cost after epoch 39: 0.073376\n",
      "Cost after epoch 40: 0.073112\n",
      "Cost after epoch 41: 0.072811\n",
      "Cost after epoch 42: 0.072506\n",
      "Cost after epoch 43: 0.072226\n",
      "Cost after epoch 44: 0.072093\n",
      "Cost after epoch 45: 0.072240\n",
      "Cost after epoch 46: 0.072201\n",
      "Cost after epoch 47: 0.072276\n",
      "Cost after epoch 48: 0.072686\n",
      "Cost after epoch 49: 0.072857\n",
      "Cost after epoch 50: 0.073215\n",
      "Cost after epoch 51: 0.073369\n",
      "Cost after epoch 52: 0.073238\n",
      "Cost after epoch 53: 0.072948\n",
      "Cost after epoch 54: 0.072623\n",
      "Cost after epoch 55: 0.072416\n",
      "Cost after epoch 56: 0.072065\n",
      "Cost after epoch 57: 0.071760\n",
      "Cost after epoch 58: 0.071548\n",
      "Cost after epoch 59: 0.070692\n",
      "Cost after epoch 60: 0.070208\n",
      "Cost after epoch 61: 0.069306\n",
      "Cost after epoch 62: 0.069452\n",
      "Cost after epoch 63: 0.068820\n",
      "Cost after epoch 64: 0.068541\n",
      "Cost after epoch 65: 0.067989\n",
      "Cost after epoch 66: 0.067836\n",
      "Cost after epoch 67: 0.068210\n",
      "Cost after epoch 68: 0.064293\n",
      "Cost after epoch 69: 0.059402\n",
      "Cost after epoch 70: 0.055849\n",
      "Cost after epoch 71: 0.053648\n",
      "Cost after epoch 72: 0.051822\n",
      "Cost after epoch 73: 0.049793\n",
      "Cost after epoch 74: 0.047127\n",
      "Cost after epoch 75: 0.044701\n",
      "Cost after epoch 76: 0.041960\n",
      "Cost after epoch 77: 0.040069\n",
      "Cost after epoch 78: 0.038334\n",
      "Cost after epoch 79: 0.036743\n",
      "Cost after epoch 80: 0.035445\n",
      "Cost after epoch 81: 0.034262\n",
      "Cost after epoch 82: 0.033424\n",
      "Cost after epoch 83: 0.032420\n",
      "Cost after epoch 84: 0.031603\n",
      "Cost after epoch 85: 0.030739\n",
      "Cost after epoch 86: 0.029903\n",
      "Cost after epoch 87: 0.029218\n",
      "Cost after epoch 88: 0.028771\n",
      "Cost after epoch 89: 0.028092\n",
      "Cost after epoch 90: 0.027370\n",
      "Cost after epoch 91: 0.026812\n",
      "Cost after epoch 92: 0.026359\n",
      "Cost after epoch 93: 0.025883\n",
      "Cost after epoch 94: 0.025291\n",
      "Cost after epoch 95: 0.024940\n",
      "Cost after epoch 96: 0.024493\n",
      "Cost after epoch 97: 0.023835\n",
      "Cost after epoch 98: 0.023878\n",
      "Cost after epoch 99: 0.023418\n"
     ]
    }
   ],
   "source": [
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters_scaled = train_model(X_train, y_train, parameters, learning_rate=0.01, l1_term=0.001, self_scale=True, num_epochs=100, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[784, 8, 12, 1]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_pruned = copy.deepcopy(parameters_scaled)\n",
    "prune_parameters(parameters_pruned)\n",
    "get_layer_sizes(parameters_pruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dims = [784, 100, 100, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.690337\n",
      "Cost after epoch 1: 0.528154\n",
      "Cost after epoch 2: 0.467875\n",
      "Cost after epoch 3: 0.443347\n",
      "Cost after epoch 4: 0.430120\n",
      "Cost after epoch 5: 0.416833\n",
      "Cost after epoch 6: 0.389002\n",
      "Cost after epoch 7: 0.338527\n",
      "Cost after epoch 8: 0.300451\n",
      "Cost after epoch 9: 0.271006\n",
      "Cost after epoch 10: 0.245603\n",
      "Cost after epoch 11: 0.224083\n",
      "Cost after epoch 12: 0.205855\n",
      "Cost after epoch 13: 0.190307\n",
      "Cost after epoch 14: 0.176630\n",
      "Cost after epoch 15: 0.163583\n",
      "Cost after epoch 16: 0.150328\n",
      "Cost after epoch 17: 0.134241\n",
      "Cost after epoch 18: 0.114823\n",
      "Cost after epoch 19: 0.100922\n",
      "Cost after epoch 20: 0.094499\n",
      "Cost after epoch 21: 0.091466\n",
      "Cost after epoch 22: 0.089254\n",
      "Cost after epoch 23: 0.087176\n",
      "Cost after epoch 24: 0.085483\n",
      "Cost after epoch 25: 0.083792\n",
      "Cost after epoch 26: 0.082154\n",
      "Cost after epoch 27: 0.080512\n",
      "Cost after epoch 28: 0.079083\n",
      "Cost after epoch 29: 0.077673\n",
      "Cost after epoch 30: 0.076255\n",
      "Cost after epoch 31: 0.074938\n",
      "Cost after epoch 32: 0.073707\n",
      "Cost after epoch 33: 0.072505\n",
      "Cost after epoch 34: 0.071316\n",
      "Cost after epoch 35: 0.070200\n",
      "Cost after epoch 36: 0.069153\n",
      "Cost after epoch 37: 0.068121\n",
      "Cost after epoch 38: 0.067043\n",
      "Cost after epoch 39: 0.065982\n",
      "Cost after epoch 40: 0.064823\n",
      "Cost after epoch 41: 0.063725\n",
      "Cost after epoch 42: 0.062710\n",
      "Cost after epoch 43: 0.061651\n",
      "Cost after epoch 44: 0.060502\n",
      "Cost after epoch 45: 0.059353\n",
      "Cost after epoch 46: 0.058093\n",
      "Cost after epoch 47: 0.056766\n",
      "Cost after epoch 48: 0.055432\n",
      "Cost after epoch 49: 0.053842\n",
      "Cost after epoch 50: 0.052151\n",
      "Cost after epoch 51: 0.050563\n",
      "Cost after epoch 52: 0.049006\n",
      "Cost after epoch 53: 0.047860\n",
      "Cost after epoch 54: 0.046749\n",
      "Cost after epoch 55: 0.045581\n",
      "Cost after epoch 56: 0.044444\n",
      "Cost after epoch 57: 0.043400\n",
      "Cost after epoch 58: 0.042639\n",
      "Cost after epoch 59: 0.042144\n",
      "Cost after epoch 60: 0.041616\n",
      "Cost after epoch 61: 0.041324\n",
      "Cost after epoch 62: 0.041135\n",
      "Cost after epoch 63: 0.040944\n",
      "Cost after epoch 64: 0.040915\n",
      "Cost after epoch 65: 0.040817\n",
      "Cost after epoch 66: 0.040942\n",
      "Cost after epoch 67: 0.041122\n",
      "Cost after epoch 68: 0.041232\n",
      "Cost after epoch 69: 0.041557\n",
      "Cost after epoch 70: 0.041898\n",
      "Cost after epoch 71: 0.042242\n",
      "Cost after epoch 72: 0.042259\n",
      "Cost after epoch 73: 0.042211\n",
      "Cost after epoch 74: 0.042476\n",
      "Cost after epoch 75: 0.042971\n",
      "Cost after epoch 76: 0.043196\n",
      "Cost after epoch 77: 0.043279\n",
      "Cost after epoch 78: 0.044306\n",
      "Cost after epoch 79: 0.042592\n",
      "Cost after epoch 80: 0.040370\n",
      "Cost after epoch 81: 0.038559\n",
      "Cost after epoch 82: 0.035591\n",
      "Cost after epoch 83: 0.033401\n",
      "Cost after epoch 84: 0.032306\n",
      "Cost after epoch 85: 0.031261\n",
      "Cost after epoch 86: 0.030267\n",
      "Cost after epoch 87: 0.030392\n",
      "Cost after epoch 88: 0.029374\n",
      "Cost after epoch 89: 0.029089\n",
      "Cost after epoch 90: 0.028397\n",
      "Cost after epoch 91: 0.028298\n",
      "Cost after epoch 92: 0.027503\n",
      "Cost after epoch 93: 0.026671\n",
      "Cost after epoch 94: 0.026102\n",
      "Cost after epoch 95: 0.025223\n",
      "Cost after epoch 96: 0.025237\n",
      "Cost after epoch 97: 0.024913\n",
      "Cost after epoch 98: 0.024609\n",
      "Cost after epoch 99: 0.024378\n"
     ]
    }
   ],
   "source": [
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters_scaled = train_model(X_train, y_train, parameters, learning_rate=0.01, l1_term=0.001, self_scale=True, num_epochs=100, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[784, 10, 16, 1]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_pruned = copy.deepcopy(parameters_scaled)\n",
    "prune_parameters(parameters_pruned)\n",
    "get_layer_sizes(parameters_pruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dims = [784, 300, 300, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.098841\n",
      "Cost after epoch 1: 0.587784\n",
      "Cost after epoch 2: 0.494406\n",
      "Cost after epoch 3: 0.463500\n",
      "Cost after epoch 4: 0.449631\n",
      "Cost after epoch 5: 0.442349\n",
      "Cost after epoch 6: 0.437789\n",
      "Cost after epoch 7: 0.434503\n",
      "Cost after epoch 8: 0.430655\n",
      "Cost after epoch 9: 0.423373\n",
      "Cost after epoch 10: 0.402940\n",
      "Cost after epoch 11: 0.359627\n",
      "Cost after epoch 12: 0.318269\n",
      "Cost after epoch 13: 0.287682\n",
      "Cost after epoch 14: 0.261287\n",
      "Cost after epoch 15: 0.238261\n",
      "Cost after epoch 16: 0.217529\n",
      "Cost after epoch 17: 0.198610\n",
      "Cost after epoch 18: 0.177072\n",
      "Cost after epoch 19: 0.146617\n",
      "Cost after epoch 20: 0.118679\n",
      "Cost after epoch 21: 0.108829\n",
      "Cost after epoch 22: 0.105467\n",
      "Cost after epoch 23: 0.103294\n",
      "Cost after epoch 24: 0.101530\n",
      "Cost after epoch 25: 0.100046\n",
      "Cost after epoch 26: 0.098677\n",
      "Cost after epoch 27: 0.097494\n",
      "Cost after epoch 28: 0.096385\n",
      "Cost after epoch 29: 0.095460\n",
      "Cost after epoch 30: 0.094646\n",
      "Cost after epoch 31: 0.093996\n",
      "Cost after epoch 32: 0.093388\n",
      "Cost after epoch 33: 0.092866\n",
      "Cost after epoch 34: 0.092296\n",
      "Cost after epoch 35: 0.091871\n",
      "Cost after epoch 36: 0.091457\n",
      "Cost after epoch 37: 0.091173\n",
      "Cost after epoch 38: 0.090883\n",
      "Cost after epoch 39: 0.090687\n",
      "Cost after epoch 40: 0.090448\n",
      "Cost after epoch 41: 0.090263\n",
      "Cost after epoch 42: 0.090035\n",
      "Cost after epoch 43: 0.089872\n",
      "Cost after epoch 44: 0.089635\n",
      "Cost after epoch 45: 0.089455\n",
      "Cost after epoch 46: 0.089237\n",
      "Cost after epoch 47: 0.089061\n",
      "Cost after epoch 48: 0.088838\n",
      "Cost after epoch 49: 0.088642\n",
      "Cost after epoch 50: 0.088386\n",
      "Cost after epoch 51: 0.088221\n",
      "Cost after epoch 52: 0.088014\n",
      "Cost after epoch 53: 0.087850\n",
      "Cost after epoch 54: 0.087614\n",
      "Cost after epoch 55: 0.087369\n",
      "Cost after epoch 56: 0.087013\n",
      "Cost after epoch 57: 0.086655\n",
      "Cost after epoch 58: 0.086213\n",
      "Cost after epoch 59: 0.085781\n",
      "Cost after epoch 60: 0.085247\n",
      "Cost after epoch 61: 0.084751\n",
      "Cost after epoch 62: 0.084184\n",
      "Cost after epoch 63: 0.083522\n",
      "Cost after epoch 64: 0.082707\n",
      "Cost after epoch 65: 0.081954\n",
      "Cost after epoch 66: 0.081052\n",
      "Cost after epoch 67: 0.080034\n",
      "Cost after epoch 68: 0.079021\n",
      "Cost after epoch 69: 0.077943\n",
      "Cost after epoch 70: 0.076554\n",
      "Cost after epoch 71: 0.075320\n",
      "Cost after epoch 72: 0.073990\n",
      "Cost after epoch 73: 0.072224\n",
      "Cost after epoch 74: 0.070156\n",
      "Cost after epoch 75: 0.067673\n",
      "Cost after epoch 76: 0.064756\n",
      "Cost after epoch 77: 0.061709\n",
      "Cost after epoch 78: 0.058772\n",
      "Cost after epoch 79: 0.055922\n",
      "Cost after epoch 80: 0.053336\n",
      "Cost after epoch 81: 0.051092\n",
      "Cost after epoch 82: 0.049547\n",
      "Cost after epoch 83: 0.048106\n",
      "Cost after epoch 84: 0.046847\n",
      "Cost after epoch 85: 0.045742\n",
      "Cost after epoch 86: 0.044505\n",
      "Cost after epoch 87: 0.043666\n",
      "Cost after epoch 88: 0.042979\n",
      "Cost after epoch 89: 0.042214\n",
      "Cost after epoch 90: 0.041504\n",
      "Cost after epoch 91: 0.041062\n",
      "Cost after epoch 92: 0.040721\n",
      "Cost after epoch 93: 0.040550\n",
      "Cost after epoch 94: 0.040173\n",
      "Cost after epoch 95: 0.039974\n",
      "Cost after epoch 96: 0.039519\n",
      "Cost after epoch 97: 0.039577\n",
      "Cost after epoch 98: 0.039354\n",
      "Cost after epoch 99: 0.039234\n"
     ]
    }
   ],
   "source": [
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters_scaled = train_model(X_train, y_train, parameters, learning_rate=0.01, l1_term=0.001, self_scale=True, num_epochs=100, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[784, 6, 17, 1]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_pruned = copy.deepcopy(parameters_scaled)\n",
    "prune_parameters(parameters_pruned)\n",
    "get_layer_sizes(parameters_pruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dims = [784, 30, 30, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.430593\n",
      "Cost after epoch 1: 0.407121\n",
      "Cost after epoch 2: 0.406458\n",
      "Cost after epoch 3: 0.408239\n",
      "Cost after epoch 4: 0.409137\n",
      "Cost after epoch 5: 0.407660\n",
      "Cost after epoch 6: 0.398960\n",
      "Cost after epoch 7: 0.366922\n",
      "Cost after epoch 8: 0.320643\n",
      "Cost after epoch 9: 0.282019\n",
      "Cost after epoch 10: 0.241086\n",
      "Cost after epoch 11: 0.159988\n",
      "Cost after epoch 12: 0.105483\n",
      "Cost after epoch 13: 0.093902\n",
      "Cost after epoch 14: 0.088086\n",
      "Cost after epoch 15: 0.084117\n",
      "Cost after epoch 16: 0.081074\n",
      "Cost after epoch 17: 0.078711\n",
      "Cost after epoch 18: 0.076856\n",
      "Cost after epoch 19: 0.075308\n",
      "Cost after epoch 20: 0.074013\n",
      "Cost after epoch 21: 0.072899\n",
      "Cost after epoch 22: 0.071910\n",
      "Cost after epoch 23: 0.071028\n",
      "Cost after epoch 24: 0.070227\n",
      "Cost after epoch 25: 0.069489\n",
      "Cost after epoch 26: 0.068802\n",
      "Cost after epoch 27: 0.068155\n",
      "Cost after epoch 28: 0.067550\n",
      "Cost after epoch 29: 0.066953\n",
      "Cost after epoch 30: 0.066364\n",
      "Cost after epoch 31: 0.065767\n",
      "Cost after epoch 32: 0.065144\n",
      "Cost after epoch 33: 0.064478\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-2b3631f46e23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparameters_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_cost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/self-scaling-nets/nets/core.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(X, Y, parameters, learning_rate, l1_term, self_scale, self_scale_coef, num_epochs, print_cost)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0;31m# Backward propagation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_term\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_scale_coef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0;31m# Update parameters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/self-scaling-nets/nets/core.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(AL, Y, caches, l1_term, self_scale, self_scale_coef)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;31m# Inputs: \"grads[\"dA\" + str(l + 1)], current_cache\". Outputs: \"grads[\"dA\" + str(l)] , grads[\"dW\" + str(l + 1)] , grads[\"db\" + str(l + 1)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mcurrent_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcaches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         dA_prev_temp, dW_temp, db_temp = linear_activation_backward(\n\u001b[0m\u001b[1;32m    382\u001b[0m             \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dA\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_cache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_term\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_scale_coef\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         )\n",
      "\u001b[0;32m~/code/self-scaling-nets/nets/core.py\u001b[0m in \u001b[0;36mlinear_activation_backward\u001b[0;34m(dA, cache, activation, l1_term, self_scale, self_scale_coef)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0mdZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mdA_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_cache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_term\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_scale_coef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/self-scaling-nets/nets/core.py\u001b[0m in \u001b[0;36mlinear_backward\u001b[0;34m(dZ, cache, l1_term, self_scale, self_scale_coef)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mscaling_matrix\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mdW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_prev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml1_term\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml1_term\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0mdA_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters_scaled = train_model(X_train, y_train, parameters, learning_rate=0.01, num_epochs=50, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
