{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from nets.core import train_model, prune_neurons, grow_neurons, get_layer_sizes, initialize_parameters, get_param_string, train_dynamic_model, measure_accuracy\n",
    "from nets.datasets import mnist_3, fashion_mnist_tshirt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import copy\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784, 48000), (1, 48000), (784, 12000), (1, 12000))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_m, X_test_m, y_train_m, y_test_m = mnist_3()\n",
    "X_train_m.shape, y_train_m.shape, X_test_m.shape, y_test_m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pixels = X_train_m[:, 1].reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784, 48000), (1, 48000), (784, 12000), (1, 12000))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_fm, X_test_fm, y_train_fm, y_test_fm = fashion_mnist_tshirt()\n",
    "X_train_fm.shape, y_train_fm.shape, X_test_fm.shape, y_test_fm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAO0ElEQVR4nO3df4xV5Z3H8c8XBJEfCoiMCChsJbpGjVX8kdRs2GzaqDGBRlvLX24WM/0Dm5o0aUn7R02qiXFl+2cTmhJY07VpokZDNtsqabSJCXEwVrGEqoSFKSMjReWHIg58+8ccmhHnPM94zzn3XPi+X8nkzpzvPec8XOYz59z7nOc85u4CcO6b1HYDAHQHYQeCIOxAEIQdCIKwA0Gc182dmRkf/QMNc3cbb3mlI7uZ3WFmu8zsHTNbV2VbAJplnfazm9lkSX+R9HVJg5JelbTa3f+cWIcjO9CwJo7st0h6x913u/sJSb+RtLLC9gA0qErYF0raN+bnwWLZ55hZv5kNmNlAhX0BqKjKB3TjnSp84TTd3TdI2iBxGg+0qcqRfVDS4jE/L5K0v1pzADSlSthflbTMzJaa2VRJ35H0fD3NAlC3jk/j3X3EzB6U9DtJkyVtdPe3amsZgFp13PXW0c54zw40rpGLagCcPQg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQXQ8P7skmdkeSUcknZQ04u7L62gUgPpVCnvhX939YA3bAdAgTuOBIKqG3SX93sy2m1n/eE8ws34zGzCzgYr7AlCBuXvnK5td5u77zWy+pBckfc/dX048v/OdAZgQd7fxllc6srv7/uJxWNKzkm6psj0Azek47GY2w8xmnf5e0jck7airYQDqVeXT+D5Jz5rZ6e38j7v/Xy2tAlC7Su/Zv/TOeM8ONK6R9+wAzh6EHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EUccNJ9GwYhhxqYp3G2ps2+hMU/8nHNmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAj62c8CTfZ1N92Pfs8995TWlixZklx3/fr1Nbemey644IJkfdKk8uPsxx9/XHdzRvfZyFYB9BzCDgRB2IEgCDsQBGEHgiDsQBCEHQiCWVyRtHHjxmS9r68vWU/1N8+aNSu57s0335ys56T6slM1SRoZGam07zZ1PIurmW00s2Ez2zFm2Vwze8HM3i4e59TZWAD1m8hp/CZJd5yxbJ2kre6+TNLW4mcAPSwbdnd/WdKhMxavlLS5+H6zpFX1NgtA3Tq9Nr7P3Yckyd2HzGx+2RPNrF9Sf4f7AVCTxgfCuPsGSRskPqAD2tRp19sBM1sgScXjcH1NAtCETsP+vKT7i+/vl/RcPc0B0JTsabyZPSVphaR5ZjYo6aeSHpP0WzNbI2mvpG812Uh0bsWKFcn6c8+l/05v27YtWT927FiyPnXq1NJarp89ta4knThxIlk/depUR7U63Hbbbcn6qlWrSmvr1jXTuZUNu7uvLin9W81tAdAgLpcFgiDsQBCEHQiCsANBEHYgiJ66lXRuqtopU6aU1nJdKSdPnqy075Smu3FynnjiidLa3XffnVz3lVdeSdZzQz0vu+yyZH14uPx6q1RNkvbu3ZusP/nkk8n6iy++WFpbunRpct377rsvWb/00kuT9fnzS68glyR99tlnpbVDh84civJ5jz/+eLJehiM7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgTR9VtJn3deedf+2Xz73pSZM2cm62vWrEnW+/vTd/U6ePBgae348ePJdSdPnpysX3zxxcn60aNHk/W5c+eW1nJDVFO/K5J0ySWXdLx+6poNKT9t8kcffZSsf/LJJ8n6hRdeWFrLTfecu7ah41tJAzg3EHYgCMIOBEHYgSAIOxAEYQeCIOxAEF0fz16lL/2aa64prR04cCC57pEjR5L13Hj3VL/oo48+mlz31ltvTdZz/c1DQ0PJ+owZM0prhw8fTq6bm7o41w+f+//cvXt3ae3aa69Nrjt79uxkPTfuO3UNSWo8uZTvh58+fXqynusrf//990trufsjXHHFFaW11O8KR3YgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCKKn7hu/du3aZP3ee+/teNu5ftXcuOxUX3Zu6uHc2OfcvnPXAOzatau0lrs/em5M+L59+5L1XF946vqE7du3J9e9/PLLk/XFixcn66lrBHL/7tQ9AqT871OqH11Kz1OQ68O/7rrrSmsffvhhaS17ZDezjWY2bGY7xix72Mz+amavF1935bYDoF0TOY3fJOmOcZb/3N1vKL7+t95mAahbNuzu/rKk9HWJAHpelQ/oHjSzN4rT/DllTzKzfjMbMLOBCvsCUFGnYf+FpK9IukHSkKT1ZU909w3uvtzdl3e4LwA16Cjs7n7A3U+6+ylJv5R0S73NAlC3jsJuZgvG/PhNSTvKngugN2T72c3sKUkrJM0zs0FJP5W0wsxukOSS9kj67kR2Nm3aNF155ZWl9Vzf55YtW0prCxcuTK6b23ZfX1+y/sEHH5TWcvcIz/V158Y+5/p0U/dmz42NztWvvvrqZH3evHnJempceO76gtxY/Fzbc69rSu6e9dOmTUvWc79Pg4ODpbXc3O+pewikxvBnw+7uq8dZ/KvcegB6C5fLAkEQdiAIwg4EQdiBIAg7EERXh7iOjIxoeHi4tH799dcn13/33XdLa6ntSvnbMaeGBuakhnFK6dspS9KiRYuS9fPPPz9Zv+iii0prqaG5E9l2qstRkt57771kPdVNlJsWOdflmOseS6k6PXiuu/XYsWPJeqpbMXcb69TQ3qlTp5bWOLIDQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCWGhJX+87Mkju78cYbk+s/8MADpbVly5Yl1839O3PDKVO3Fs6tW/U21rm+8JTULYul6kNgc33dqXpu27n+5ty/LfV/nrs9d27bqf5sKT/VdWr93LZTHnnkEe3Zs2fcxnNkB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgeqqfvYrUmG5JuvPOO5P1q666Klm/6aabOt53rk83N+Y815ed2v6nn36aXLdKn65UrT8697s3aVK1Y1Fq+7l25+TGw+f62VPj3XPXbbz00kultU2bNmloaIh+diAywg4EQdiBIAg7EARhB4Ig7EAQhB0I4pzpZ29Trq96/vz5yXpqymVJmj59erI+e/bs0lpuLHyuvznXT3/ixIlkPdUfnbv+IHdv9ir3fq8yFl6Sjh8/nqzn7omfmucg95rnuHtn/exmttjM/mBmO83sLTP7frF8rpm9YGZvF49zKrUQQKMmcho/IukH7v7Pkm6TtNbMrpG0TtJWd18maWvxM4AelQ27uw+5+2vF90ck7ZS0UNJKSZuLp22WtKqhNgKowZeaLMvMlkj6qqRtkvrcfUga/YNgZuO+MTWzfkn9FdsJoKIJh93MZkp6WtJD7n54ogMJ3H2DpA3FNs7JD+iAs8GEut7MbIpGg/5rd3+mWHzAzBYU9QWS0tOoAmhVtuvNRg/hmyUdcveHxiz/T0l/c/fHzGydpLnu/sPMtjiyAw0r63qbSNhvl/RHSW9KOn2j7x9r9H37byVdLmmvpG+5+6HMtgg70LCOw14nwg40r+OLagCcGwg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IIht2M1tsZn8ws51m9paZfb9Y/rCZ/dXMXi++7mq+uQA6NZH52RdIWuDur5nZLEnbJa2S9G1JR939iQnvjCmbgcaVTdl83gRWHJI0VHx/xMx2SlpYb/MANO1LvWc3syWSvippW7HoQTN7w8w2mtmcknX6zWzAzAaqNRVAFdnT+H880WympJckPeruz5hZn6SDklzSzzR6qv8fmW1wGg80rOw0fkJhN7MpkrZI+p27/9c49SWStrj7tZntEHagYWVhn8in8SbpV5J2jg168cHdad+UtKNqIwE0ZyKfxt8u6Y+S3pR0qlj8Y0mrJd2g0dP4PZK+W3yYl9oWR3agYZVO4+tC2IHmdXwaD+DcQNiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQgie8PJmh2U9P9jfp5XLOtFvdq2Xm2XRNs6VWfbrigrdHU8+xd2bjbg7stba0BCr7atV9sl0bZOdattnMYDQRB2IIi2w76h5f2n9GrberVdEm3rVFfa1up7dgDd0/aRHUCXEHYgiFbCbmZ3mNkuM3vHzNa10YYyZrbHzN4spqFudX66Yg69YTPbMWbZXDN7wczeLh7HnWOvpbb1xDTeiWnGW33t2p7+vOvv2c1ssqS/SPq6pEFJr0pa7e5/7mpDSpjZHknL3b31CzDM7F8kHZX036en1jKzxyUdcvfHij+Uc9z9Rz3Stof1JafxbqhtZdOM/7tafO3qnP68E20c2W+R9I6773b3E5J+I2llC+3oee7+sqRDZyxeKWlz8f1mjf6ydF1J23qCuw+5+2vF90cknZ5mvNXXLtGurmgj7Asl7Rvz86B6a753l/R7M9tuZv1tN2Ycfaen2Soe57fcnjNlp/HupjOmGe+Z166T6c+raiPs401N00v9f19z9xsl3SlpbXG6ion5haSvaHQOwCFJ69tsTDHN+NOSHnL3w222Zaxx2tWV162NsA9KWjzm50WS9rfQjnG5+/7icVjSsxp929FLDpyeQbd4HG65Pf/g7gfc/aS7n5L0S7X42hXTjD8t6dfu/kyxuPXXbrx2det1ayPsr0paZmZLzWyqpO9Ier6FdnyBmc0oPjiRmc2Q9A313lTUz0u6v/j+fknPtdiWz+mVabzLphlXy69d69Ofu3vXvyTdpdFP5N+V9JM22lDSrn+S9Kfi66222ybpKY2e1n2m0TOiNZIulrRV0tvF49weatuTGp3a+w2NBmtBS227XaNvDd+Q9HrxdVfbr12iXV153bhcFgiCK+iAIAg7EARhB4Ig7EAQhB0IgrADQRB2IIi/A2FW9Vlq43KEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pixels = X_train_fm[:, 1].reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test pruning neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dims = [784, 20, 20, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.359812\n",
      "Cost after epoch 1: 0.214252\n",
      "Cost after epoch 2: 0.156755\n",
      "Cost after epoch 3: 0.126837\n",
      "Cost after epoch 4: 0.119046\n",
      "Cost after epoch 5: 0.112092\n",
      "Cost after epoch 6: 0.110529\n",
      "Cost after epoch 7: 0.105766\n",
      "Cost after epoch 8: 0.101518\n",
      "Cost after epoch 9: 0.096901\n",
      "Cost after epoch 10: 0.092610\n",
      "Cost after epoch 11: 0.088425\n",
      "Cost after epoch 12: 0.087657\n",
      "Cost after epoch 13: 0.084147\n",
      "Cost after epoch 14: 0.080914\n",
      "Cost after epoch 15: 0.081007\n",
      "Cost after epoch 16: 0.076784\n",
      "Cost after epoch 17: 0.075424\n",
      "Cost after epoch 18: 0.081668\n",
      "Cost after epoch 19: 0.077549\n"
     ]
    }
   ],
   "source": [
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters = train_model(X_train_m, y_train_m, parameters, learning_rate=0.05, l1_term=0.05, num_epochs=20, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9865416666666667"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_accuracy(parameters, X_train_m, y_train_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.297169\n",
      "Cost after epoch 1: 0.154100\n",
      "Cost after epoch 2: 0.120355\n",
      "Cost after epoch 3: 0.104911\n",
      "Cost after epoch 4: 0.101299\n",
      "Cost after epoch 5: 0.087843\n",
      "Cost after epoch 6: 0.090634\n",
      "Cost after epoch 7: 0.092526\n",
      "Cost after epoch 8: 0.079348\n",
      "Cost after epoch 9: 0.080150\n",
      "Cost after epoch 10: 0.080602\n",
      "Cost after epoch 11: 0.077172\n",
      "Cost after epoch 12: 0.076063\n",
      "Cost after epoch 13: 0.072677\n",
      "Cost after epoch 14: 0.063783\n",
      "Cost after epoch 15: 0.061885\n",
      "Cost after epoch 16: 0.061831\n",
      "Cost after epoch 17: 0.062763\n",
      "Cost after epoch 18: 0.061132\n",
      "Cost after epoch 19: 0.060422\n"
     ]
    }
   ],
   "source": [
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters_scaled = train_model(X_train_m, y_train_m, parameters, learning_rate=0.05, l1_term=0.05, self_scale=True, num_epochs=20, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9818333333333333"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_accuracy(parameters_scaled, X_train_m, y_train_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[784, 2, 5, 1]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_pruned = copy.deepcopy(parameters_scaled)\n",
    "prune_neurons(parameters_pruned)\n",
    "get_layer_sizes(parameters_pruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9818333333333333"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_accuracy(parameters_pruned, X_train_m, y_train_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.317890\n",
      "Cost after epoch 1: 0.180584\n",
      "Cost after epoch 2: 0.122194\n",
      "Cost after epoch 3: 0.093648\n",
      "Cost after epoch 4: 0.075114\n",
      "Cost after epoch 5: 0.064961\n",
      "Cost after epoch 6: 0.059103\n",
      "Cost after epoch 7: 0.052779\n",
      "Cost after epoch 8: 0.049598\n",
      "Cost after epoch 9: 0.047101\n",
      "Cost after epoch 10: 0.043771\n",
      "Cost after epoch 11: 0.042957\n",
      "Cost after epoch 12: 0.041046\n",
      "Cost after epoch 13: 0.040205\n",
      "Cost after epoch 14: 0.040432\n",
      "Cost after epoch 15: 0.040886\n",
      "Cost after epoch 16: 0.040099\n",
      "Cost after epoch 17: 0.036542\n",
      "Cost after epoch 18: 0.036072\n",
      "Cost after epoch 19: 0.034638\n"
     ]
    }
   ],
   "source": [
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters_scaled = train_model(X_train_m, y_train_m, parameters, learning_rate=0.05, l1_term=0.01, self_scale=True, num_epochs=20, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.988625"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_accuracy(parameters_scaled, X_train_m, y_train_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[784, 7, 8, 1]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_pruned = copy.deepcopy(parameters_scaled)\n",
    "prune_neurons(parameters_pruned)\n",
    "get_layer_sizes(parameters_pruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.988625"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_accuracy(parameters_pruned, X_train_m, y_train_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dims = [784, 100, 100, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.782117\n",
      "Cost after epoch 1: 0.396082\n",
      "Cost after epoch 2: 0.310997\n",
      "Cost after epoch 3: 0.277403\n",
      "Cost after epoch 4: 0.261473\n",
      "Cost after epoch 5: 0.247344\n",
      "Cost after epoch 6: 0.234010\n",
      "Cost after epoch 7: 0.230796\n",
      "Cost after epoch 8: 0.231137\n",
      "Cost after epoch 9: 0.232779\n",
      "Cost after epoch 10: 0.229599\n",
      "Cost after epoch 11: 0.228239\n",
      "Cost after epoch 12: 0.221841\n",
      "Cost after epoch 13: 0.218048\n",
      "Cost after epoch 14: 0.215499\n",
      "Cost after epoch 15: 0.216250\n",
      "Cost after epoch 16: 0.218483\n",
      "Cost after epoch 17: 0.217932\n",
      "Cost after epoch 18: 0.213969\n",
      "Cost after epoch 19: 0.214877\n"
     ]
    }
   ],
   "source": [
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters_scaled = train_model(X_train_m, y_train_m, parameters, learning_rate=0.05, l1_term=0.01, self_scale=True, num_epochs=20, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9879375"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_accuracy(parameters_scaled, X_train_m, y_train_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[784, 5, 7, 1]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_pruned = copy.deepcopy(parameters_scaled)\n",
    "prune_neurons(parameters_pruned)\n",
    "get_layer_sizes(parameters_pruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11111\n",
      "0121011\n"
     ]
    }
   ],
   "source": [
    "print(get_param_string(parameters_pruned['W1']))\n",
    "print(get_param_string(parameters_pruned['W2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9878958333333333"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_accuracy(parameters_pruned, X_train_m, y_train_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test growing neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[784, 10, 12, 1]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_grown = copy.deepcopy(parameters_pruned)\n",
    "grow_neurons(parameters_grown)\n",
    "get_layer_sizes(parameters_grown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111122222\n",
      "011101112212\n"
     ]
    }
   ],
   "source": [
    "print(get_param_string(parameters_grown['W1']))\n",
    "print(get_param_string(parameters_grown['W2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 784)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_grown['W1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 10)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_grown['W2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After growing: [784, 15, 15, 1]\n",
      "111111111133333\n",
      "110110110033333\n",
      "Cost after epoch 0: 0.152068\n",
      "Cost after epoch 1: 0.101780\n",
      "Cost after epoch 2: 0.086675\n",
      "Cost after epoch 3: 0.078669\n",
      "Cost after epoch 4: 0.073484\n",
      "Iteration 1: accuracy 0.9774791666666667\n",
      "After pruning: [784, 15, 15, 1]\n",
      "Accuracy 0.9774791666666667\n",
      "111111111122222\n",
      "110110110022222\n",
      "-------------------\n",
      "After growing: [784, 20, 20, 1]\n",
      "11111111112222233333\n",
      "11011011001111133333\n",
      "Cost after epoch 0: 0.074828\n",
      "Cost after epoch 1: 0.071787\n",
      "Cost after epoch 2: 0.069272\n",
      "Cost after epoch 3: 0.067022\n",
      "Cost after epoch 4: 0.064941\n",
      "Iteration 2: accuracy 0.9826875\n",
      "After pruning: [784, 15, 16, 1]\n",
      "Accuracy 0.9826875\n",
      "111111111122222\n",
      "1101101100222233\n",
      "-------------------\n",
      "After growing: [784, 20, 21, 1]\n",
      "11111111112222233333\n",
      "110110110011111133333\n",
      "Cost after epoch 0: 0.063942\n",
      "Cost after epoch 1: 0.062330\n",
      "Cost after epoch 2: 0.060768\n",
      "Cost after epoch 3: 0.059234\n",
      "Cost after epoch 4: 0.057587\n",
      "Iteration 3: accuracy 0.9858125\n",
      "After pruning: [784, 15, 16, 1]\n",
      "Accuracy 0.9857916666666666\n",
      "111111111121232\n",
      "1101101100212233\n",
      "-------------------\n",
      "After growing: [784, 20, 21, 1]\n",
      "11111111112123233333\n",
      "110110110011111133333\n",
      "Cost after epoch 0: 0.056394\n",
      "Cost after epoch 1: 0.055065\n",
      "Cost after epoch 2: 0.053773\n",
      "Cost after epoch 3: 0.052634\n",
      "Cost after epoch 4: 0.051687\n",
      "Iteration 4: accuracy 0.9882083333333334\n",
      "After pruning: [784, 15, 15, 1]\n",
      "Accuracy 0.9882083333333334\n",
      "111111111121232\n",
      "110110110021223\n",
      "-------------------\n",
      "After growing: [784, 20, 20, 1]\n",
      "11111111112123233333\n",
      "11011011001111133333\n",
      "Cost after epoch 0: 0.050262\n",
      "Cost after epoch 1: 0.049332\n",
      "Cost after epoch 2: 0.048403\n",
      "Cost after epoch 3: 0.047560\n",
      "Cost after epoch 4: 0.046665\n",
      "Iteration 5: accuracy 0.989125\n",
      "After pruning: [784, 14, 14, 1]\n",
      "Accuracy 0.989125\n",
      "11111111113122\n",
      "11011011002132\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [784, 10, 10, 1]\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters = train_dynamic_model(X_train_m, y_train_m, parameters, learning_rate=0.01, l1_term=0.002, n_iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.989125"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_accuracy(parameters, X_train_m, y_train_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After growing: [784, 8, 8, 1]\n",
      "11133333\n",
      "01033233\n",
      "Cost after epoch 0: 0.114036\n",
      "Cost after epoch 1: 0.087633\n",
      "Cost after epoch 2: 0.070972\n",
      "Cost after epoch 3: 0.055175\n",
      "Cost after epoch 4: 0.042520\n",
      "Iteration 1: accuracy 0.9767916666666666\n",
      "After pruning: [784, 8, 8, 1]\n",
      "Accuracy 0.9767916666666666\n",
      "11112222\n",
      "01011212\n",
      "-------------------\n",
      "After growing: [784, 13, 13, 1]\n",
      "1111222233333\n",
      "0101111133233\n",
      "Cost after epoch 0: 0.036444\n",
      "Cost after epoch 1: 0.033487\n",
      "Cost after epoch 2: 0.031706\n",
      "Cost after epoch 3: 0.030753\n",
      "Cost after epoch 4: 0.030708\n",
      "Iteration 2: accuracy 0.9800625\n",
      "After pruning: [784, 12, 11, 1]\n",
      "Accuracy 0.9800625\n",
      "111122222432\n",
      "01011111232\n",
      "-------------------\n",
      "After growing: [784, 17, 16, 1]\n",
      "11112222243233333\n",
      "0101111111123333\n",
      "Cost after epoch 0: 0.033145\n",
      "Cost after epoch 1: 0.033334\n",
      "Cost after epoch 2: 0.031064\n",
      "Cost after epoch 3: 0.029907\n",
      "Cost after epoch 4: 0.028567\n",
      "Iteration 3: accuracy 0.9826666666666667\n",
      "After pruning: [784, 12, 12, 1]\n",
      "Accuracy 0.9826666666666667\n",
      "111122222322\n",
      "010111111112\n",
      "-------------------\n",
      "After growing: [784, 17, 17, 1]\n",
      "11112222232233333\n",
      "01011111111123333\n",
      "Cost after epoch 0: 0.028299\n",
      "Cost after epoch 1: 0.027439\n",
      "Cost after epoch 2: 0.026860\n",
      "Cost after epoch 3: 0.025866\n",
      "Cost after epoch 4: 0.025490\n",
      "Iteration 4: accuracy 0.9857916666666666\n",
      "After pruning: [784, 13, 14, 1]\n",
      "Accuracy 0.9857916666666666\n",
      "1111222223222\n",
      "01011111111122\n",
      "-------------------\n",
      "After growing: [784, 18, 19, 1]\n",
      "111122222322233333\n",
      "0101111111111133333\n",
      "Cost after epoch 0: 0.026942\n",
      "Cost after epoch 1: 0.026569\n",
      "Cost after epoch 2: 0.026351\n",
      "Cost after epoch 3: 0.026151\n",
      "Cost after epoch 4: 0.026052\n",
      "Iteration 5: accuracy 0.9884166666666667\n",
      "After pruning: [784, 14, 14, 1]\n",
      "Accuracy 0.9883958333333334\n",
      "11112221222122\n",
      "01011111111111\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [784, 3, 3, 1]\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters = train_dynamic_model(X_train_m, y_train_m, parameters, learning_rate=0.01, l1_term=0.002, n_iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9883958333333334"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_accuracy(parameters, X_train_m, y_train_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dims = [784, 100, 100, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 3.471439\n",
      "Cost after epoch 1: 1.922243\n",
      "Cost after epoch 2: 1.201067\n",
      "Cost after epoch 3: 0.824852\n",
      "Cost after epoch 4: 0.598112\n",
      "Cost after epoch 5: 0.455540\n",
      "Cost after epoch 6: 0.358875\n",
      "Cost after epoch 7: 0.291958\n",
      "Cost after epoch 8: 0.246167\n",
      "Cost after epoch 9: 0.212625\n",
      "Cost after epoch 10: 0.186393\n",
      "Cost after epoch 11: 0.164651\n",
      "Cost after epoch 12: 0.150406\n",
      "Cost after epoch 13: 0.137818\n",
      "Cost after epoch 14: 0.127331\n",
      "Cost after epoch 15: 0.119736\n",
      "Cost after epoch 16: 0.111852\n",
      "Cost after epoch 17: 0.106494\n",
      "Cost after epoch 18: 0.100673\n",
      "Cost after epoch 19: 0.096830\n"
     ]
    }
   ],
   "source": [
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters_scaled = train_model(X_train_fm, y_train_fm, parameters, learning_rate=0.02, l1_term=0.002, self_scale=True, num_epochs=20, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9618125"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_accuracy(parameters_scaled, X_train_fm, y_train_fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[784, 22, 43, 1]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_pruned = copy.deepcopy(parameters_scaled)\n",
    "prune_neurons(parameters_pruned)\n",
    "get_layer_sizes(parameters_pruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After growing: [784, 8, 8, 1]\n",
      "11133333\n",
      "01033233\n",
      "Cost after epoch 0: 0.064613\n",
      "Cost after epoch 1: 0.058200\n",
      "Cost after epoch 2: 0.064434\n",
      "Cost after epoch 3: 0.064971\n",
      "Cost after epoch 4: 0.063740\n",
      "Iteration 1: accuracy 0.9601041666666666\n",
      "After pruning: [784, 7, 8, 1]\n",
      "Accuracy 0.9601041666666666\n",
      "1111222\n",
      "01022215\n",
      "-------------------\n",
      "After growing: [784, 12, 13, 1]\n",
      "111122233333\n",
      "0101111133233\n",
      "Cost after epoch 0: 0.061949\n",
      "Cost after epoch 1: 0.058552\n",
      "Cost after epoch 2: 0.059104\n",
      "Cost after epoch 3: 0.060814\n",
      "Cost after epoch 4: 0.058835\n",
      "Iteration 2: accuracy 0.9611666666666666\n",
      "After pruning: [784, 9, 9, 1]\n",
      "Accuracy 0.9611875\n",
      "111121232\n",
      "010111112\n",
      "-------------------\n",
      "After growing: [784, 14, 14, 1]\n",
      "11112123233333\n",
      "01011111132333\n",
      "Cost after epoch 0: 0.061744\n",
      "Cost after epoch 1: 0.059893\n",
      "Cost after epoch 2: 0.047801\n",
      "Cost after epoch 3: 0.058577\n",
      "Cost after epoch 4: 0.057644\n",
      "Iteration 3: accuracy 0.963\n",
      "After pruning: [784, 8, 9, 1]\n",
      "Accuracy 0.963\n",
      "11112122\n",
      "010111112\n",
      "-------------------\n",
      "After growing: [784, 13, 14, 1]\n",
      "1111212233333\n",
      "01011111132333\n",
      "Cost after epoch 0: 0.057525\n",
      "Cost after epoch 1: 0.057686\n",
      "Cost after epoch 2: 0.058102\n",
      "Cost after epoch 3: 0.059770\n",
      "Cost after epoch 4: 0.059299\n",
      "Iteration 4: accuracy 0.964125\n",
      "After pruning: [784, 9, 9, 1]\n",
      "Accuracy 0.9641041666666667\n",
      "111121123\n",
      "000111111\n",
      "-------------------\n",
      "After growing: [784, 14, 14, 1]\n",
      "11112112333333\n",
      "00011111132333\n",
      "Cost after epoch 0: 0.056722\n",
      "Cost after epoch 1: 0.058180\n",
      "Cost after epoch 2: 0.058959\n",
      "Cost after epoch 3: 0.058232\n",
      "Cost after epoch 4: 0.058919\n",
      "Iteration 5: accuracy 0.9646875\n",
      "After pruning: [784, 8, 10, 1]\n",
      "Accuracy 0.9646875\n",
      "11112111\n",
      "0001111123\n",
      "-------------------\n",
      "After growing: [784, 13, 15, 1]\n",
      "1111211133333\n",
      "000111111132333\n",
      "Cost after epoch 0: 0.060194\n",
      "Cost after epoch 1: 0.055773\n",
      "Cost after epoch 2: 0.058388\n",
      "Cost after epoch 3: 0.059399\n",
      "Cost after epoch 4: 0.059028\n",
      "Iteration 6: accuracy 0.965875\n",
      "After pruning: [784, 8, 9, 1]\n",
      "Accuracy 0.965875\n",
      "11112111\n",
      "000111122\n",
      "-------------------\n",
      "After growing: [784, 13, 14, 1]\n",
      "1111211133333\n",
      "00011111132333\n",
      "Cost after epoch 0: 0.059584\n",
      "Cost after epoch 1: 0.062690\n",
      "Cost after epoch 2: 0.062543\n",
      "Cost after epoch 3: 0.061491\n",
      "Cost after epoch 4: 0.061364\n",
      "Iteration 7: accuracy 0.9671458333333334\n",
      "After pruning: [784, 8, 9, 1]\n",
      "Accuracy 0.9671458333333334\n",
      "11112111\n",
      "000111123\n",
      "-------------------\n",
      "After growing: [784, 13, 14, 1]\n",
      "1111211133333\n",
      "00011111132333\n",
      "Cost after epoch 0: 0.063076\n",
      "Cost after epoch 1: 0.062687\n",
      "Cost after epoch 2: 0.065317\n",
      "Cost after epoch 3: 0.066018\n",
      "Cost after epoch 4: 0.067313\n",
      "Iteration 8: accuracy 0.9679166666666666\n",
      "After pruning: [784, 9, 9, 1]\n",
      "Accuracy 0.9679166666666666\n",
      "111121113\n",
      "000111111\n",
      "-------------------\n",
      "After growing: [784, 14, 14, 1]\n",
      "11112111333333\n",
      "00011111132333\n",
      "Cost after epoch 0: 0.067597\n",
      "Cost after epoch 1: 0.070186\n",
      "Cost after epoch 2: 0.068539\n",
      "Cost after epoch 3: 0.071335\n",
      "Cost after epoch 4: 0.072138\n",
      "Iteration 9: accuracy 0.9685625\n",
      "After pruning: [784, 9, 10, 1]\n",
      "Accuracy 0.9685833333333334\n",
      "111121113\n",
      "0001111113\n",
      "-------------------\n",
      "After growing: [784, 14, 15, 1]\n",
      "11112111333333\n",
      "000111111132333\n",
      "Cost after epoch 0: 0.073132\n",
      "Cost after epoch 1: 0.068266\n",
      "Cost after epoch 2: 0.067009\n",
      "Cost after epoch 3: 0.073857\n",
      "Cost after epoch 4: 0.069979\n",
      "Iteration 10: accuracy 0.9696875\n",
      "After pruning: [784, 10, 10, 1]\n",
      "Accuracy 0.9696875\n",
      "1111211133\n",
      "0001111111\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [784, 3, 3, 1]\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters = train_dynamic_model(X_train_fm, y_train_fm, parameters, learning_rate=0.02, l1_term=0.002, n_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After growing: [784, 110, 110, 1]\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113333333333\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113333333333\n",
      "Cost after epoch 0: 3.601171\n",
      "Cost after epoch 1: 2.016749\n",
      "Cost after epoch 2: 1.269526\n",
      "Cost after epoch 3: 0.874773\n",
      "Cost after epoch 4: 0.635476\n",
      "Iteration 1: accuracy 0.9545833333333333\n",
      "After pruning: [784, 76, 100, 1]\n",
      "Accuracy 0.9546875\n",
      "1111111111111111111111111211112222211222222222122222222222222222223233333232\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111121221111121\n",
      "-------------------\n",
      "After growing: [784, 83, 110, 1]\n",
      "11111111111111111111111112111122222112222222221222222222222222222232333332323333333\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113333333333\n",
      "Cost after epoch 0: 0.497077\n",
      "Cost after epoch 1: 0.393175\n",
      "Cost after epoch 2: 0.316682\n",
      "Cost after epoch 3: 0.262178\n",
      "Cost after epoch 4: 0.223167\n",
      "Iteration 2: accuracy 0.958\n",
      "After pruning: [784, 39, 76, 1]\n",
      "Accuracy 0.9580833333333333\n",
      "111111111111111211122212122222223222334\n",
      "1111111111111111111111111111111111121111112112112111222223222211212221112222\n",
      "-------------------\n",
      "After growing: [784, 44, 83, 1]\n",
      "11111111111111121112221212222222322233433333\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111113333333\n",
      "Cost after epoch 0: 0.199157\n",
      "Cost after epoch 1: 0.178923\n",
      "Cost after epoch 2: 0.159569\n",
      "Cost after epoch 3: 0.147127\n",
      "Cost after epoch 4: 0.135376\n",
      "Iteration 3: accuracy 0.9600833333333333\n",
      "After pruning: [784, 27, 53, 1]\n",
      "Accuracy 0.9601041666666666\n",
      "111111111112212222222222132\n",
      "11111111111111112111111111111122111321121211222231212\n",
      "-------------------\n",
      "After growing: [784, 32, 58, 1]\n",
      "11111111111221222222222213233333\n",
      "1111111111111111111111111111111111111111111111111111133333\n",
      "Cost after epoch 0: 0.127423\n",
      "Cost after epoch 1: 0.123391\n",
      "Cost after epoch 2: 0.114601\n",
      "Cost after epoch 3: 0.109617\n",
      "Cost after epoch 4: 0.106116\n",
      "Iteration 4: accuracy 0.9616666666666667\n",
      "After pruning: [784, 22, 42, 1]\n",
      "Accuracy 0.9622916666666667\n",
      "1111111121122122222321\n",
      "111111111111111221211111211212221122131111\n",
      "-------------------\n",
      "After growing: [784, 27, 47, 1]\n",
      "111111112112212222232133333\n",
      "11111111111111111111111111111111111111111133333\n",
      "Cost after epoch 0: 0.101841\n",
      "Cost after epoch 1: 0.096393\n",
      "Cost after epoch 2: 0.094243\n",
      "Cost after epoch 3: 0.091406\n",
      "Cost after epoch 4: 0.088344\n",
      "Iteration 5: accuracy 0.9634583333333333\n",
      "After pruning: [784, 18, 36, 1]\n",
      "Accuracy 0.9634583333333333\n",
      "111111112112222322\n",
      "111111111111112221222112211131212121\n",
      "-------------------\n",
      "After growing: [784, 23, 41, 1]\n",
      "11111111211222232233333\n",
      "11111111111111111111111111111111111133333\n",
      "Cost after epoch 0: 0.085450\n",
      "Cost after epoch 1: 0.083032\n",
      "Cost after epoch 2: 0.082910\n",
      "Cost after epoch 3: 0.081440\n",
      "Cost after epoch 4: 0.078939\n",
      "Iteration 6: accuracy 0.96425\n",
      "After pruning: [784, 14, 30, 1]\n",
      "Accuracy 0.9645\n",
      "11111121212222\n",
      "111111111111112212222222112132\n",
      "-------------------\n",
      "After growing: [784, 19, 35, 1]\n",
      "1111112121222233333\n",
      "11111111111111111111111111111133333\n",
      "Cost after epoch 0: 0.078378\n",
      "Cost after epoch 1: 0.077379\n",
      "Cost after epoch 2: 0.075706\n",
      "Cost after epoch 3: 0.074897\n",
      "Cost after epoch 4: 0.074003\n",
      "Iteration 7: accuracy 0.9651875\n",
      "After pruning: [784, 12, 24, 1]\n",
      "Accuracy 0.9651875\n",
      "111112212122\n",
      "111111111112111322221131\n",
      "-------------------\n",
      "After growing: [784, 17, 29, 1]\n",
      "11111221212233333\n",
      "11111111111111011111111133333\n",
      "Cost after epoch 0: 0.069386\n",
      "Cost after epoch 1: 0.068019\n",
      "Cost after epoch 2: 0.067772\n",
      "Cost after epoch 3: 0.067090\n",
      "Cost after epoch 4: 0.066672\n",
      "Iteration 8: accuracy 0.9657083333333333\n",
      "After pruning: [784, 11, 19, 1]\n",
      "Accuracy 0.9657083333333333\n",
      "11111221212\n",
      "1111111111121112111\n",
      "-------------------\n",
      "After growing: [784, 16, 24, 1]\n",
      "1111122121233333\n",
      "111111111111110111133233\n",
      "Cost after epoch 0: 0.063378\n",
      "Cost after epoch 1: 0.062308\n",
      "Cost after epoch 2: 0.060107\n",
      "Cost after epoch 3: 0.062336\n",
      "Cost after epoch 4: 0.059946\n",
      "Iteration 9: accuracy 0.9664583333333333\n",
      "After pruning: [784, 10, 18, 1]\n",
      "Accuracy 0.9664583333333333\n",
      "1111122112\n",
      "111111211121111113\n",
      "-------------------\n",
      "After growing: [784, 15, 23, 1]\n",
      "111112211233333\n",
      "11111111111111011133233\n",
      "Cost after epoch 0: 0.062193\n",
      "Cost after epoch 1: 0.061918\n",
      "Cost after epoch 2: 0.061636\n",
      "Cost after epoch 3: 0.060797\n",
      "Cost after epoch 4: 0.060605\n",
      "Iteration 10: accuracy 0.9668541666666667\n",
      "After pruning: [784, 11, 19, 1]\n",
      "Accuracy 0.9668541666666667\n",
      "11111221134\n",
      "1111111111111101113\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [784, 100, 100, 1]\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters = train_dynamic_model(X_train_fm, y_train_fm, parameters, learning_rate=0.02, l1_term=0.002, n_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After growing: [784, 8, 8, 1]\n",
      "11155555\n",
      "01055455\n",
      "Cost after epoch 0: 0.066023\n",
      "Cost after epoch 1: 0.060020\n",
      "Cost after epoch 2: 0.050706\n",
      "Cost after epoch 3: 0.056405\n",
      "Cost after epoch 4: 0.057278\n",
      "Iteration 1: accuracy 0.9592291666666667\n",
      "After pruning: [784, 8, 8, 1]\n",
      "Accuracy 0.9592291666666667\n",
      "11112222\n",
      "01011212\n",
      "-------------------\n",
      "After growing: [784, 13, 13, 1]\n",
      "1111222255555\n",
      "0101111155455\n",
      "Cost after epoch 0: 0.053881\n",
      "Cost after epoch 1: 0.056833\n",
      "Cost after epoch 2: 0.060530\n",
      "Cost after epoch 3: 0.062232\n",
      "Cost after epoch 4: 0.061549\n",
      "Iteration 2: accuracy 0.9612083333333333\n",
      "After pruning: [784, 9, 10, 1]\n",
      "Accuracy 0.9612083333333333\n",
      "111122221\n",
      "0101121122\n",
      "-------------------\n",
      "After growing: [784, 14, 15, 1]\n",
      "11112222155555\n",
      "010111111154555\n",
      "Cost after epoch 0: 0.061748\n",
      "Cost after epoch 1: 0.064419\n",
      "Cost after epoch 2: 0.061927\n",
      "Cost after epoch 3: 0.063600\n",
      "Cost after epoch 4: 0.062343\n",
      "Iteration 3: accuracy 0.9642916666666667\n",
      "After pruning: [784, 9, 12, 1]\n",
      "Accuracy 0.9642708333333333\n",
      "111122221\n",
      "010112122233\n",
      "-------------------\n",
      "After growing: [784, 14, 17, 1]\n",
      "11112222155555\n",
      "01011111111145554\n",
      "Cost after epoch 0: 0.063329\n",
      "Cost after epoch 1: 0.062693\n",
      "Cost after epoch 2: 0.061771\n",
      "Cost after epoch 3: 0.061415\n",
      "Cost after epoch 4: 0.062585\n",
      "Iteration 4: accuracy 0.9659375\n",
      "After pruning: [784, 9, 12, 1]\n",
      "Accuracy 0.9659375\n",
      "111122121\n",
      "010112122223\n",
      "-------------------\n",
      "After growing: [784, 14, 17, 1]\n",
      "11112212155555\n",
      "01011111111145554\n",
      "Cost after epoch 0: 0.058767\n",
      "Cost after epoch 1: 0.060054\n",
      "Cost after epoch 2: 0.060269\n",
      "Cost after epoch 3: 0.065091\n",
      "Cost after epoch 4: 0.064175\n",
      "Iteration 5: accuracy 0.9656458333333333\n",
      "After pruning: [784, 9, 12, 1]\n",
      "Accuracy 0.9656458333333333\n",
      "111121121\n",
      "010102122233\n",
      "-------------------\n",
      "After growing: [784, 14, 17, 1]\n",
      "11112112155555\n",
      "01010111111145554\n",
      "Cost after epoch 0: 0.060984\n",
      "Cost after epoch 1: 0.063354\n",
      "Cost after epoch 2: 0.063804\n",
      "Cost after epoch 3: 0.060514\n",
      "Cost after epoch 4: 0.061830\n",
      "Iteration 6: accuracy 0.9668541666666667\n",
      "After pruning: [784, 10, 12, 1]\n",
      "Accuracy 0.9668541666666667\n",
      "1111211213\n",
      "010102111111\n",
      "-------------------\n",
      "After growing: [784, 15, 17, 1]\n",
      "111121121355555\n",
      "01010111111145554\n",
      "Cost after epoch 0: 0.060422\n",
      "Cost after epoch 1: 0.055190\n",
      "Cost after epoch 2: 0.060679\n",
      "Cost after epoch 3: 0.060517\n",
      "Cost after epoch 4: 0.058225\n",
      "Iteration 7: accuracy 0.9668958333333333\n",
      "After pruning: [784, 11, 12, 1]\n",
      "Accuracy 0.966875\n",
      "11112112133\n",
      "010101111111\n",
      "-------------------\n",
      "After growing: [784, 16, 17, 1]\n",
      "1111211213355555\n",
      "01010111111145554\n",
      "Cost after epoch 0: 0.059751\n",
      "Cost after epoch 1: 0.060224\n",
      "Cost after epoch 2: 0.059609\n",
      "Cost after epoch 3: 0.057402\n",
      "Cost after epoch 4: 0.058740\n",
      "Iteration 8: accuracy 0.9686875\n",
      "After pruning: [784, 10, 12, 1]\n",
      "Accuracy 0.9687083333333333\n",
      "1111211313\n",
      "010102122111\n",
      "-------------------\n",
      "After growing: [784, 15, 17, 1]\n",
      "111121131355555\n",
      "01010111111145554\n",
      "Cost after epoch 0: 0.056004\n",
      "Cost after epoch 1: 0.057857\n",
      "Cost after epoch 2: 0.057903\n",
      "Cost after epoch 3: 0.057885\n",
      "Cost after epoch 4: 0.058240\n",
      "Iteration 9: accuracy 0.9694166666666667\n",
      "After pruning: [784, 10, 13, 1]\n",
      "Accuracy 0.9694166666666667\n",
      "1111211133\n",
      "0101021111113\n",
      "-------------------\n",
      "After growing: [784, 15, 18, 1]\n",
      "111121113355555\n",
      "010101111111145554\n",
      "Cost after epoch 0: 0.061705\n",
      "Cost after epoch 1: 0.061546\n",
      "Cost after epoch 2: 0.058195\n",
      "Cost after epoch 3: 0.059722\n",
      "Cost after epoch 4: 0.061314\n",
      "Iteration 10: accuracy 0.9703958333333333\n",
      "After pruning: [784, 10, 13, 1]\n",
      "Accuracy 0.9703958333333333\n",
      "1111211133\n",
      "0101021111111\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [784, 3, 3, 1]\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters = train_dynamic_model(X_train_fm, y_train_fm, parameters, learning_rate=0.02, l1_term=0.002, n_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After growing: [784, 8, 8, 1]\n",
      "11155555\n",
      "01055455\n",
      "Cost after epoch 0: 0.066023\n",
      "Cost after epoch 1: 0.060020\n",
      "Iteration 1: accuracy 0.9557083333333334\n",
      "After pruning: [784, 8, 8, 1]\n",
      "Accuracy 0.9557083333333334\n",
      "11122222\n",
      "01022213\n",
      "-------------------\n",
      "After growing: [784, 13, 13, 1]\n",
      "1112222255555\n",
      "0101111155455\n",
      "Cost after epoch 0: 0.053017\n",
      "Cost after epoch 1: 0.056349\n",
      "Iteration 2: accuracy 0.9573125\n",
      "After pruning: [784, 10, 10, 1]\n",
      "Accuracy 0.9573541666666666\n",
      "1111222222\n",
      "0101111122\n",
      "-------------------\n",
      "After growing: [784, 15, 15, 1]\n",
      "111122222255555\n",
      "010111111154555\n",
      "Cost after epoch 0: 0.058499\n",
      "Cost after epoch 1: 0.059999\n",
      "Iteration 3: accuracy 0.95875\n",
      "After pruning: [784, 11, 10, 1]\n",
      "Accuracy 0.95875\n",
      "11112222223\n",
      "0101111111\n",
      "-------------------\n",
      "After growing: [784, 16, 15, 1]\n",
      "1111222222355555\n",
      "010111111154554\n",
      "Cost after epoch 0: 0.062419\n",
      "Cost after epoch 1: 0.062080\n",
      "Iteration 4: accuracy 0.9600625\n",
      "After pruning: [784, 11, 10, 1]\n",
      "Accuracy 0.9600625\n",
      "11112222223\n",
      "0101111111\n",
      "-------------------\n",
      "After growing: [784, 16, 15, 1]\n",
      "1111222222355555\n",
      "010111111154554\n",
      "Cost after epoch 0: 0.061326\n",
      "Cost after epoch 1: 0.061901\n",
      "Iteration 5: accuracy 0.9609375\n",
      "After pruning: [784, 11, 10, 1]\n",
      "Accuracy 0.9609375\n",
      "11112122223\n",
      "0101111111\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [784, 3, 3, 1]\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters = train_dynamic_model(X_train_fm, y_train_fm, parameters, learning_rate=0.02, l1_term=0.002, n_iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After growing: [784, 8, 8, 1]\n",
      "11155555\n",
      "01055455\n",
      "Cost after epoch 0: 0.059515\n",
      "Cost after epoch 1: 0.055179\n",
      "Iteration 1: accuracy 0.9545416666666666\n",
      "After pruning: [784, 7, 6, 1]\n",
      "Accuracy 0.9545416666666666\n",
      "1112322\n",
      "010213\n",
      "-------------------\n",
      "After growing: [784, 12, 11, 1]\n",
      "111232255555\n",
      "01011155545\n",
      "Cost after epoch 0: 0.058415\n",
      "Cost after epoch 1: 0.059838\n",
      "Iteration 2: accuracy 0.9590833333333333\n",
      "After pruning: [784, 9, 8, 1]\n",
      "Accuracy 0.9590833333333333\n",
      "111122223\n",
      "01011152\n",
      "-------------------\n",
      "After growing: [784, 14, 13, 1]\n",
      "11112222355555\n",
      "0101111155455\n",
      "Cost after epoch 0: 0.060264\n",
      "Cost after epoch 1: 0.056483\n",
      "Iteration 3: accuracy 0.961875\n",
      "After pruning: [784, 11, 9, 1]\n",
      "Accuracy 0.961875\n",
      "11112222323\n",
      "010111111\n",
      "-------------------\n",
      "After growing: [784, 16, 14, 1]\n",
      "1111222232355555\n",
      "01011111154555\n",
      "Cost after epoch 0: 0.057089\n",
      "Cost after epoch 1: 0.058138\n",
      "Iteration 4: accuracy 0.9628541666666667\n",
      "After pruning: [784, 11, 10, 1]\n",
      "Accuracy 0.9628541666666667\n",
      "11112222323\n",
      "0101111112\n",
      "-------------------\n",
      "After growing: [784, 16, 15, 1]\n",
      "1111222232355555\n",
      "010111111154554\n",
      "Cost after epoch 0: 0.059883\n",
      "Cost after epoch 1: 0.060503\n",
      "Iteration 5: accuracy 0.9634375\n",
      "After pruning: [784, 11, 10, 1]\n",
      "Accuracy 0.9634375\n",
      "11112112223\n",
      "0101111112\n",
      "-------------------\n",
      "After growing: [784, 16, 15, 1]\n",
      "1111211222355555\n",
      "010111111154554\n",
      "Cost after epoch 0: 0.060156\n",
      "Cost after epoch 1: 0.060962\n",
      "Iteration 6: accuracy 0.964375\n",
      "After pruning: [784, 11, 12, 1]\n",
      "Accuracy 0.964375\n",
      "11112112223\n",
      "010111111233\n",
      "-------------------\n",
      "After growing: [784, 16, 17, 1]\n",
      "1111211222355555\n",
      "01011111111145554\n",
      "Cost after epoch 0: 0.060681\n",
      "Cost after epoch 1: 0.060925\n",
      "Iteration 7: accuracy 0.9648333333333333\n",
      "After pruning: [784, 11, 12, 1]\n",
      "Accuracy 0.9648958333333333\n",
      "11112112222\n",
      "000111111233\n",
      "-------------------\n",
      "After growing: [784, 16, 17, 1]\n",
      "1111211222255555\n",
      "00011111111145554\n",
      "Cost after epoch 0: 0.060238\n",
      "Cost after epoch 1: 0.058979\n",
      "Iteration 8: accuracy 0.9651875\n",
      "After pruning: [784, 11, 12, 1]\n",
      "Accuracy 0.9651875\n",
      "11112112222\n",
      "000111111232\n",
      "-------------------\n",
      "After growing: [784, 16, 17, 1]\n",
      "1111211222255555\n",
      "00011111111145554\n",
      "Cost after epoch 0: 0.055446\n",
      "Cost after epoch 1: 0.055388\n",
      "Iteration 9: accuracy 0.9658958333333333\n",
      "After pruning: [784, 11, 12, 1]\n",
      "Accuracy 0.9658958333333333\n",
      "11112112222\n",
      "000111111232\n",
      "-------------------\n",
      "After growing: [784, 16, 17, 1]\n",
      "1111211222255555\n",
      "00011111111145554\n",
      "Cost after epoch 0: 0.050487\n",
      "Cost after epoch 1: 0.054162\n",
      "Iteration 10: accuracy 0.9665625\n",
      "After pruning: [784, 11, 12, 1]\n",
      "Accuracy 0.9665625\n",
      "11112111222\n",
      "000111111232\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [784, 3, 3, 1]\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters = train_dynamic_model(X_train_fm, y_train_fm, parameters, learning_rate=0.02, l1_term=0.0005, n_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After growing: [784, 8, 8, 1]\n",
      "11144444\n",
      "01044344\n",
      "Cost after epoch 0: 0.056939\n",
      "Cost after epoch 1: 0.053669\n",
      "Iteration 1: accuracy 0.9548958333333334\n",
      "After pruning: [784, 7, 6, 1]\n",
      "Accuracy 0.9548958333333334\n",
      "1112222\n",
      "010213\n",
      "-------------------\n",
      "After growing: [784, 12, 11, 1]\n",
      "111222244444\n",
      "01011144434\n",
      "Cost after epoch 0: 0.057099\n",
      "Cost after epoch 1: 0.060770\n",
      "Iteration 2: accuracy 0.960375\n",
      "After pruning: [784, 8, 11, 1]\n",
      "Accuracy 0.960375\n",
      "11112223\n",
      "01011133332\n",
      "-------------------\n",
      "After growing: [784, 13, 16, 1]\n",
      "1111222344444\n",
      "0101111111143444\n",
      "Cost after epoch 0: 0.059942\n",
      "Cost after epoch 1: 0.058777\n",
      "Iteration 3: accuracy 0.9618958333333333\n",
      "After pruning: [784, 10, 14, 1]\n",
      "Accuracy 0.9618958333333333\n",
      "1111212332\n",
      "01011111111232\n",
      "-------------------\n",
      "After growing: [784, 15, 19, 1]\n",
      "111121233244444\n",
      "0101111111111134434\n",
      "Cost after epoch 0: 0.058107\n",
      "Cost after epoch 1: 0.056124\n",
      "Iteration 4: accuracy 0.9625208333333334\n",
      "After pruning: [784, 11, 16, 1]\n",
      "Accuracy 0.9625208333333334\n",
      "11112123223\n",
      "0101111111011233\n",
      "-------------------\n",
      "After growing: [784, 16, 21, 1]\n",
      "1111212322344444\n",
      "010111111101110144434\n",
      "Cost after epoch 0: 0.056560\n",
      "Cost after epoch 1: 0.059729\n",
      "Iteration 5: accuracy 0.9637708333333334\n",
      "After pruning: [784, 12, 17, 1]\n",
      "Accuracy 0.9637708333333334\n",
      "111121232223\n",
      "01011111110112123\n",
      "-------------------\n",
      "After growing: [784, 17, 22, 1]\n",
      "11112123222344444\n",
      "0101111111011101144444\n",
      "Cost after epoch 0: 0.060810\n",
      "Cost after epoch 1: 0.062041\n",
      "Iteration 6: accuracy 0.965625\n",
      "After pruning: [784, 13, 18, 1]\n",
      "Accuracy 0.965625\n",
      "1111112322233\n",
      "010111111101121213\n",
      "-------------------\n",
      "After growing: [784, 18, 23, 1]\n",
      "111111232223344444\n",
      "01011111110111111144444\n",
      "Cost after epoch 0: 0.061401\n",
      "Cost after epoch 1: 0.058885\n",
      "Iteration 7: accuracy 0.9662083333333333\n",
      "After pruning: [784, 14, 20, 1]\n",
      "Accuracy 0.9662083333333333\n",
      "11111123222233\n",
      "01011111110112121133\n",
      "-------------------\n",
      "After growing: [784, 19, 25, 1]\n",
      "1111112322223344444\n",
      "0101111111011111111144444\n",
      "Cost after epoch 0: 0.058049\n",
      "Cost after epoch 1: 0.060105\n",
      "Iteration 8: accuracy 0.9673125\n",
      "After pruning: [784, 14, 21, 1]\n",
      "Accuracy 0.9673125\n",
      "11111113222233\n",
      "010111111101121211333\n",
      "-------------------\n",
      "After growing: [784, 19, 26, 1]\n",
      "1111111322223344444\n",
      "01011111110111111111144444\n",
      "Cost after epoch 0: 0.059844\n",
      "Cost after epoch 1: 0.057895\n",
      "Iteration 9: accuracy 0.9682083333333333\n",
      "After pruning: [784, 15, 22, 1]\n",
      "Accuracy 0.9682083333333333\n",
      "111111131222233\n",
      "0001111111011111112213\n",
      "-------------------\n",
      "After growing: [784, 20, 27, 1]\n",
      "11111113122223344444\n",
      "000111111101111111111144444\n",
      "Cost after epoch 0: 0.062466\n",
      "Cost after epoch 1: 0.055497\n",
      "Iteration 10: accuracy 0.9689583333333334\n",
      "After pruning: [784, 15, 23, 1]\n",
      "Accuracy 0.9689583333333334\n",
      "111111131222233\n",
      "00011111110111111122133\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [784, 3, 3, 1]\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters = train_dynamic_model(X_train_fm, y_train_fm, parameters, learning_rate=0.02, l1_term=0.000005, n_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After growing: [784, 8, 8, 1]\n",
      "11144444\n",
      "01044344\n",
      "Cost after epoch 0: 0.132515\n",
      "Cost after epoch 1: 0.102758\n",
      "Iteration 1: accuracy 0.9465208333333334\n",
      "After pruning: [784, 5, 6, 1]\n",
      "Accuracy 0.947125\n",
      "11124\n",
      "010212\n",
      "-------------------\n",
      "After growing: [784, 10, 11, 1]\n",
      "1112444444\n",
      "01011144343\n",
      "Cost after epoch 0: 0.101188\n",
      "Cost after epoch 1: 0.088477\n",
      "Iteration 2: accuracy 0.9468333333333333\n",
      "After pruning: [784, 5, 8, 1]\n",
      "Accuracy 0.9473333333333334\n",
      "11124\n",
      "00011222\n",
      "-------------------\n",
      "After growing: [784, 10, 13, 1]\n",
      "1112444444\n",
      "0001111143434\n",
      "Cost after epoch 0: 0.101360\n",
      "Cost after epoch 1: 0.092261\n",
      "Iteration 3: accuracy 0.9494583333333333\n",
      "After pruning: [784, 5, 8, 1]\n",
      "Accuracy 0.9494583333333333\n",
      "11114\n",
      "00011112\n",
      "-------------------\n",
      "After growing: [784, 10, 13, 1]\n",
      "1111444444\n",
      "0001111143434\n",
      "Cost after epoch 0: 0.092617\n",
      "Cost after epoch 1: 0.087501\n",
      "Iteration 4: accuracy 0.9516041666666667\n",
      "After pruning: [784, 4, 6, 1]\n",
      "Accuracy 0.9519583333333334\n",
      "1122\n",
      "010113\n",
      "-------------------\n",
      "After growing: [784, 9, 11, 1]\n",
      "112244444\n",
      "01000144343\n",
      "Cost after epoch 0: 0.078055\n",
      "Cost after epoch 1: 0.073680\n",
      "Iteration 5: accuracy 0.9533125\n",
      "After pruning: [784, 4, 7, 1]\n",
      "Accuracy 0.9534583333333333\n",
      "1122\n",
      "0101133\n",
      "-------------------\n",
      "After growing: [784, 9, 12, 1]\n",
      "112244444\n",
      "010001143433\n",
      "Cost after epoch 0: 0.080522\n",
      "Cost after epoch 1: 0.076840\n",
      "Iteration 6: accuracy 0.9546458333333333\n",
      "After pruning: [784, 4, 6, 1]\n",
      "Accuracy 0.9546458333333333\n",
      "1122\n",
      "010112\n",
      "-------------------\n",
      "After growing: [784, 9, 11, 1]\n",
      "112244444\n",
      "01000144343\n",
      "Cost after epoch 0: 0.075951\n",
      "Cost after epoch 1: 0.073314\n",
      "Iteration 7: accuracy 0.9558125\n",
      "After pruning: [784, 4, 8, 1]\n",
      "Accuracy 0.9557916666666667\n",
      "1121\n",
      "01011333\n",
      "-------------------\n",
      "After growing: [784, 9, 13, 1]\n",
      "112144444\n",
      "0100011143433\n",
      "Cost after epoch 0: 0.088271\n",
      "Cost after epoch 1: 0.078216\n",
      "Iteration 8: accuracy 0.9563958333333333\n",
      "After pruning: [784, 4, 8, 1]\n",
      "Accuracy 0.9564375\n",
      "1121\n",
      "01021233\n",
      "-------------------\n",
      "After growing: [784, 9, 13, 1]\n",
      "112144444\n",
      "0100011143433\n",
      "Cost after epoch 0: 0.084449\n",
      "Cost after epoch 1: 0.086945\n",
      "Iteration 9: accuracy 0.9572291666666667\n",
      "After pruning: [784, 5, 7, 1]\n",
      "Accuracy 0.95725\n",
      "11313\n",
      "0101123\n",
      "-------------------\n",
      "After growing: [784, 10, 12, 1]\n",
      "1131344444\n",
      "010111143433\n",
      "Cost after epoch 0: 0.085940\n",
      "Cost after epoch 1: 0.081156\n",
      "Iteration 10: accuracy 0.9576041666666667\n",
      "After pruning: [784, 3, 7, 1]\n",
      "Accuracy 0.957625\n",
      "111\n",
      "0102123\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [784, 3, 3, 1]\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters = train_dynamic_model(X_train_fm, y_train_fm, parameters, learning_rate=0.02, l1_term=0.05, n_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.957625"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_accuracy(parameters, X_train_fm, y_train_fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After growing: [784, 110, 110, 1]\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111114444444444\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111114444444444\n",
      "Cost after epoch 0: 0.066194\n",
      "Cost after epoch 1: 0.066859\n",
      "Iteration 1: accuracy 0.9577916666666667\n",
      "After pruning: [784, 106, 107, 1]\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111323322\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113322233\n",
      "-------------------\n",
      "After growing: [784, 116, 117, 1]\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113233224444444444\n",
      "111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111114444444444\n",
      "Cost after epoch 0: 0.066956\n",
      "Cost after epoch 1: 0.066768\n",
      "Iteration 2: accuracy 0.9606458333333333\n",
      "After pruning: [784, 107, 108, 1]\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113223222\n",
      "111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111212213\n",
      "-------------------\n",
      "After growing: [784, 117, 118, 1]\n",
      "111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111132232224444444444\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111114444444444\n",
      "Cost after epoch 0: 0.067019\n",
      "Cost after epoch 1: 0.067521\n",
      "Iteration 3: accuracy 0.9623541666666666\n",
      "After pruning: [784, 109, 108, 1]\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111322322233\n",
      "111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111212111\n",
      "-------------------\n",
      "After growing: [784, 119, 118, 1]\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113223222334444444444\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111114444444444\n",
      "Cost after epoch 0: 0.066960\n",
      "Cost after epoch 1: 0.067215\n",
      "Iteration 4: accuracy 0.96375\n",
      "After pruning: [784, 109, 109, 1]\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111322322233\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111112121113\n",
      "-------------------\n",
      "After growing: [784, 119, 119, 1]\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113223222334444444444\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111114444444444\n",
      "Cost after epoch 0: 0.067236\n",
      "Cost after epoch 1: 0.066675\n",
      "Iteration 5: accuracy 0.9649791666666667\n",
      "After pruning: [784, 110, 110, 1]\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113223222223\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111211221123\n",
      "-------------------\n",
      "After growing: [784, 121, 121, 1]\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111322322222344444444444\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111144444444444\n",
      "Cost after epoch 0: 0.066231\n",
      "Cost after epoch 1: 0.065426\n",
      "Iteration 6: accuracy 0.96675\n",
      "After pruning: [784, 110, 110, 1]\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113223222222\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111211221123\n",
      "-------------------\n",
      "After growing: [784, 121, 121, 1]\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111322322222244444444444\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111144444444444\n",
      "Cost after epoch 0: 0.065127\n",
      "Cost after epoch 1: 0.064564\n",
      "Iteration 7: accuracy 0.968\n",
      "After pruning: [784, 110, 109, 1]\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113222221222\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111121122112\n",
      "-------------------\n",
      "After growing: [784, 121, 119, 1]\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111322222122244444444444\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111114444444444\n",
      "Cost after epoch 0: 0.064478\n",
      "Cost after epoch 1: 0.063667\n",
      "Iteration 8: accuracy 0.96925\n",
      "After pruning: [784, 110, 109, 1]\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113222221222\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111121122112\n",
      "-------------------\n",
      "After growing: [784, 121, 119, 1]\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111322222122244444444444\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111114444444444\n",
      "Cost after epoch 0: 0.062969\n",
      "Cost after epoch 1: 0.063294\n",
      "Iteration 9: accuracy 0.97025\n",
      "After pruning: [784, 110, 109, 1]\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113222221222\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111121122112\n",
      "-------------------\n",
      "After growing: [784, 121, 119, 1]\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111322222122244444444444\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111114444444444\n",
      "Cost after epoch 0: 0.063058\n",
      "Cost after epoch 1: 0.062581\n",
      "Iteration 10: accuracy 0.9709375\n",
      "After pruning: [784, 110, 109, 1]\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113222221222\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111121122112\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [784, 100, 100, 1]\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters = train_dynamic_model(X_train_fm, y_train_fm, parameters, learning_rate=0.02, l1_term=0.000005, n_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After growing: [784, 110, 110, 1]\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111114444444444\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111114444444444\n",
      "Cost after epoch 0: 0.066194\n",
      "Cost after epoch 1: 0.066859\n",
      "Iteration 1: accuracy 0.9577916666666667\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111115443234322\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113443222334\n",
      "After pruning: [784, 106, 107, 1]\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111323322\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113322233\n",
      "-------------------\n",
      "After growing: [784, 116, 117, 1]\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113233224444444444\n",
      "111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111114444444444\n",
      "Cost after epoch 0: 0.066956\n",
      "Cost after epoch 1: 0.066768\n",
      "Iteration 2: accuracy 0.9606458333333333\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113223224552544554\n",
      "111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111115344444444\n",
      "After pruning: [784, 107, 108, 1]\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113223222\n",
      "111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111212213\n",
      "-------------------\n",
      "After growing: [784, 117, 118, 1]\n",
      "111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111132232224444444444\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111114444444444\n",
      "Cost after epoch 0: 0.067019\n",
      "Cost after epoch 1: 0.067521\n",
      "Iteration 3: accuracy 0.9623541666666666\n",
      "111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111132232225563555345\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111114454444444\n",
      "After pruning: [784, 109, 108, 1]\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111322322233\n",
      "111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111212111\n",
      "-------------------\n",
      "After growing: [784, 119, 118, 1]\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113223222334444444444\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111114444444444\n",
      "Cost after epoch 0: 0.066960\n",
      "Cost after epoch 1: 0.067215\n",
      "Iteration 4: accuracy 0.96375\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113223222335454554544\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113444544444\n",
      "After pruning: [784, 109, 109, 1]\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111322322233\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111112121113\n",
      "-------------------\n",
      "After growing: [784, 119, 119, 1]\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113223222334444444444\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111114444444444\n",
      "Cost after epoch 0: 0.067236\n",
      "Cost after epoch 1: 0.066675\n",
      "Iteration 5: accuracy 0.9649791666666667\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113223222225564456435\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111114434444544\n",
      "After pruning: [784, 110, 110, 1]\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113223222223\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111211221123\n",
      "-------------------\n",
      "After growing: [784, 121, 121, 1]\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111322322222344444444444\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111144444444444\n",
      "Cost after epoch 0: 0.066231\n",
      "Cost after epoch 1: 0.065426\n",
      "Iteration 6: accuracy 0.96675\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111322322222244544554544\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111144455446545\n",
      "After pruning: [784, 110, 110, 1]\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113223222222\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111211221123\n",
      "-------------------\n",
      "After growing: [784, 121, 121, 1]\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111322322222244444444444\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111144444444444\n",
      "Cost after epoch 0: 0.065127\n",
      "Cost after epoch 1: 0.064564\n",
      "Iteration 7: accuracy 0.968\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111322222122255745545645\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111144455445545\n",
      "After pruning: [784, 110, 109, 1]\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113222221222\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111121122112\n",
      "-------------------\n",
      "After growing: [784, 121, 119, 1]\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111322222122244444444444\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111114444444444\n",
      "Cost after epoch 0: 0.064478\n",
      "Cost after epoch 1: 0.063667\n",
      "Iteration 8: accuracy 0.96925\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111322222122254645545454\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111114445445554\n",
      "After pruning: [784, 110, 109, 1]\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113222221222\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111121122112\n",
      "-------------------\n",
      "After growing: [784, 121, 119, 1]\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111322222122244444444444\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111114444444444\n",
      "Cost after epoch 0: 0.062969\n",
      "Cost after epoch 1: 0.063294\n",
      "Iteration 9: accuracy 0.97025\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111322222122254554645454\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111114445445454\n",
      "After pruning: [784, 110, 109, 1]\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113222221222\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111121122112\n",
      "-------------------\n",
      "After growing: [784, 121, 119, 1]\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111322222122244444444444\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111114444444444\n",
      "Cost after epoch 0: 0.063058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 1: 0.062581\n",
      "Iteration 10: accuracy 0.9709375\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111322222122255554444554\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111114445454454\n",
      "After pruning: [784, 110, 109, 1]\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113222221222\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111121122112\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [784, 100, 100, 1]\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters = train_dynamic_model(X_train_fm, y_train_fm, parameters, learning_rate=0.02, l1_term=0.000005, n_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After growing: [784, 25, 25, 1]\n",
      "1111111111111111111144444\n",
      "1011111111111111111144444\n",
      "Cost after epoch 0: 0.464558\n",
      "Cost after epoch 1: 0.348559\n",
      "Iteration 1: accuracy 0.9564375\n",
      "1111111111111111111155454\n",
      "1011111111111111111155524\n",
      "After pruning: [784, 20, 21, 1]\n",
      "11111111111111111111\n",
      "101111111111111111112\n",
      "-------------------\n",
      "After growing: [784, 25, 26, 1]\n",
      "1111111111111111111144444\n",
      "10111111111111111111144444\n",
      "Cost after epoch 0: 0.272006\n",
      "Cost after epoch 1: 0.218069\n",
      "Iteration 2: accuracy 0.9562083333333333\n",
      "1111111111111112211245444\n",
      "10111111111111111111145544\n",
      "After pruning: [784, 20, 21, 1]\n",
      "11111111111111122112\n",
      "101111111111111111113\n",
      "-------------------\n",
      "After growing: [784, 25, 26, 1]\n",
      "1111111111111112211244444\n",
      "10111111111111111111144444\n",
      "Cost after epoch 0: 0.184533\n",
      "Cost after epoch 1: 0.160731\n",
      "Iteration 3: accuracy 0.9566666666666667\n",
      "1111111111221122222244554\n",
      "10111111111111111111145554\n",
      "After pruning: [784, 20, 20, 1]\n",
      "11111111112211222222\n",
      "10111111111111111111\n",
      "-------------------\n",
      "After growing: [784, 25, 25, 1]\n",
      "1111111111221122222244444\n",
      "1011111111111111111144444\n",
      "Cost after epoch 0: 0.144671\n",
      "Cost after epoch 1: 0.133718\n",
      "Iteration 4: accuracy 0.9574375\n",
      "1111112111221222222345544\n",
      "1011101111111111111155434\n",
      "After pruning: [784, 20, 21, 1]\n",
      "11111121112212222223\n",
      "101110111111111111113\n",
      "-------------------\n",
      "After growing: [784, 25, 26, 1]\n",
      "1111112111221222222344444\n",
      "10111011111111111111144444\n",
      "Cost after epoch 0: 0.129521\n",
      "Cost after epoch 1: 0.122071\n",
      "Iteration 5: accuracy 0.9580625\n",
      "1111112122222244232445554\n",
      "10111011111111111111154444\n",
      "After pruning: [784, 17, 21, 1]\n",
      "11111121222222232\n",
      "101110111111111111113\n",
      "-------------------\n",
      "After growing: [784, 22, 26, 1]\n",
      "1111112122222223244444\n",
      "10111011111111111111144444\n",
      "Cost after epoch 0: 0.117258\n",
      "Cost after epoch 1: 0.111188\n",
      "Iteration 6: accuracy 0.9592291666666667\n",
      "1112112122232224244454\n",
      "10111011111111111111155444\n",
      "After pruning: [784, 16, 21, 1]\n",
      "1112112122232222\n",
      "101110111111111111113\n",
      "-------------------\n",
      "After growing: [784, 21, 26, 1]\n",
      "111211212223222244444\n",
      "10111011111111111111144444\n",
      "Cost after epoch 0: 0.107660\n",
      "Cost after epoch 1: 0.104919\n",
      "Iteration 7: accuracy 0.9608125\n",
      "111212212235244344544\n",
      "10111011111111111111134445\n",
      "After pruning: [784, 13, 21, 1]\n",
      "1112122122323\n",
      "101110111111111111113\n",
      "-------------------\n",
      "After growing: [784, 18, 26, 1]\n",
      "111212212232344444\n",
      "10111011111111111111144444\n",
      "Cost after epoch 0: 0.099295\n",
      "Cost after epoch 1: 0.095767\n",
      "Iteration 8: accuracy 0.9610833333333333\n",
      "111212212242345554\n",
      "10111011111111111111144453\n",
      "After pruning: [784, 12, 21, 1]\n",
      "111212212223\n",
      "101110111111111111113\n",
      "-------------------\n",
      "After growing: [784, 17, 26, 1]\n",
      "11121221222344444\n",
      "10111011111111011111144444\n",
      "Cost after epoch 0: 0.093719\n",
      "Cost after epoch 1: 0.090293\n",
      "Iteration 9: accuracy 0.9608333333333333\n",
      "11121221332344444\n",
      "10111011111111111111155553\n",
      "After pruning: [784, 12, 21, 1]\n",
      "111212213323\n",
      "101110111111111111123\n",
      "-------------------\n",
      "After growing: [784, 17, 26, 1]\n",
      "11121221332344444\n",
      "10111011111111011111144444\n",
      "Cost after epoch 0: 0.090146\n",
      "Cost after epoch 1: 0.086557\n",
      "Iteration 10: accuracy 0.9606875\n",
      "11121231444354544\n",
      "10111011111111111111135553\n",
      "After pruning: [784, 9, 22, 1]\n",
      "111212313\n",
      "1011101111111111111233\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [784, 20, 20, 1]\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters = train_dynamic_model(X_train_fm, y_train_fm, parameters, learning_rate=0.02, l1_term=0.005, n_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After growing: [784, 55, 55, 1]\n",
      "1111111111111111111111111111111111111111111111111144444\n",
      "1111111111111111111111111111111111111111111111111144444\n",
      "Cost after epoch 0: 1.784532\n",
      "Cost after epoch 1: 0.944362\n",
      "Iteration 1: accuracy 0.9513125\n",
      "1111111111111111111111211221112222211222222222122255554\n",
      "1111111111111111111111111111111111111111111111111155452\n",
      "After pruning: [784, 50, 51, 1]\n",
      "11111111111111111111112112211122222112222222221222\n",
      "111111111111111111111111111111111111111111111111112\n",
      "-------------------\n",
      "After growing: [784, 55, 56, 1]\n",
      "1111111111111111111111211221112222211222222222122244444\n",
      "11111111111111111111111111111111111111111111111111144444\n",
      "Cost after epoch 0: 0.653125\n",
      "Cost after epoch 1: 0.479562\n",
      "Iteration 2: accuracy 0.9511458333333334\n",
      "1111111111111112221222222222212254222245554454344444444\n",
      "11111111111111111111111111111111111111111111111111155554\n",
      "After pruning: [784, 37, 50, 1]\n",
      "1111111111111112221222222222212222223\n",
      "11111111111111111111111111111111111111111111111121\n",
      "-------------------\n",
      "After growing: [784, 42, 55, 1]\n",
      "111111111111111222122222222221222222344444\n",
      "1111111111111111111111111111111111111111111111111144444\n",
      "Cost after epoch 0: 0.343945\n",
      "Cost after epoch 1: 0.278050\n",
      "Iteration 3: accuracy 0.9520208333333333\n",
      "111111111121212222222253354552555555554554\n",
      "1111111111111111111111111111111111111111111111111155455\n",
      "After pruning: [784, 25, 49, 1]\n",
      "1111111111212122222222332\n",
      "1111111111111111111111111111111111111112112111231\n",
      "-------------------\n",
      "After growing: [784, 30, 54, 1]\n",
      "111111111121212222222233244444\n",
      "111111111111111111111111111111111111111111111111144444\n",
      "Cost after epoch 0: 0.238242\n",
      "Cost after epoch 1: 0.204273\n",
      "Iteration 4: accuracy 0.952375\n",
      "111111212121212223235555345555\n",
      "111111111111111111111111111111111121011111111111154444\n",
      "After pruning: [784, 21, 44, 1]\n",
      "111111212121212223233\n",
      "11111111111111111111111112111112122102131112\n",
      "-------------------\n",
      "After growing: [784, 26, 49, 1]\n",
      "11111121212121222323344444\n",
      "1111111111111111111111111111111111110111111144444\n",
      "Cost after epoch 0: 0.186146\n",
      "Cost after epoch 1: 0.166468\n",
      "Iteration 5: accuracy 0.9525833333333333\n",
      "11111121222121325554445544\n",
      "1111111111111111111111111111111111210111111145545\n",
      "After pruning: [784, 16, 40, 1]\n",
      "1111112122212132\n",
      "1111111111111111112112112211111222202112\n",
      "-------------------\n",
      "After growing: [784, 21, 45, 1]\n",
      "111111212221213244444\n",
      "111111111111111111111111111111111110111144444\n",
      "Cost after epoch 0: 0.153569\n",
      "Cost after epoch 1: 0.140494\n",
      "Iteration 6: accuracy 0.9528125\n",
      "111111212221415454544\n",
      "111111111111111111111111111111111120111155545\n",
      "After pruning: [784, 13, 35, 1]\n",
      "1111112122211\n",
      "11111111111111121121121121211233022\n",
      "-------------------\n",
      "After growing: [784, 18, 40, 1]\n",
      "111111212221144444\n",
      "1111111111111111111111111111111101144444\n",
      "Cost after epoch 0: 0.132165\n",
      "Cost after epoch 1: 0.124836\n",
      "Iteration 7: accuracy 0.9541458333333334\n",
      "111111222222155544\n",
      "1111111111111111111111111111111101255555\n",
      "After pruning: [784, 13, 30, 1]\n",
      "1111112222221\n",
      "111111111111111211112223213303\n",
      "-------------------\n",
      "After growing: [784, 18, 35, 1]\n",
      "111111222222144444\n",
      "11111111111111111111111111110144444\n",
      "Cost after epoch 0: 0.117138\n",
      "Cost after epoch 1: 0.113093\n",
      "Iteration 8: accuracy 0.9546041666666667\n",
      "111111222242154445\n",
      "11111111111111111111111111110154454\n",
      "After pruning: [784, 12, 26, 1]\n",
      "111111222221\n",
      "11111111111111121211222310\n",
      "-------------------\n",
      "After growing: [784, 17, 31, 1]\n",
      "11111122222144444\n",
      "1111111111111101111111111044444\n",
      "Cost after epoch 0: 0.104143\n",
      "Cost after epoch 1: 0.101079\n",
      "Iteration 9: accuracy 0.9559791666666667\n",
      "11111122352145545\n",
      "1111111111111111111111111054544\n",
      "After pruning: [784, 11, 23, 1]\n",
      "11111122321\n",
      "11111111111111121211320\n",
      "-------------------\n",
      "After growing: [784, 16, 28, 1]\n",
      "1111112232144444\n",
      "1111111111111101111111034444\n",
      "Cost after epoch 0: 0.095199\n",
      "Cost after epoch 1: 0.091413\n",
      "Iteration 10: accuracy 0.9558541666666667\n",
      "1111112252154445\n",
      "1111111111111101111111045454\n",
      "After pruning: [784, 10, 21, 1]\n",
      "1111112221\n",
      "111111111211121122220\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [784, 50, 50, 1]\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters = train_dynamic_model(X_train_fm, y_train_fm, parameters, learning_rate=0.02, l1_term=0.005, n_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After growing: [784, 10, 10, 1]\n",
      "1111144444\n",
      "0011034334\n",
      "Cost after epoch 0: 0.082807\n",
      "Cost after epoch 1: 0.067625\n",
      "Iteration 1: accuracy 0.9539583333333334\n",
      "1111122242\n",
      "0011022111\n",
      "After pruning: [784, 10, 10, 1]\n",
      "1111122242\n",
      "0011022111\n",
      "-------------------\n",
      "After growing: [784, 15, 15, 1]\n",
      "111112224244444\n",
      "001101111143444\n",
      "Cost after epoch 0: 0.069392\n",
      "Cost after epoch 1: 0.066885\n",
      "Iteration 2: accuracy 0.9558333333333333\n",
      "111112224245445\n",
      "001101111144325\n",
      "After pruning: [784, 10, 12, 1]\n",
      "1111122242\n",
      "001102211132\n",
      "-------------------\n",
      "After growing: [784, 15, 17, 1]\n",
      "111112224244444\n",
      "00110111111134443\n",
      "Cost after epoch 0: 0.069398\n",
      "Cost after epoch 1: 0.068238\n",
      "Iteration 3: accuracy 0.9565833333333333\n",
      "111112324235444\n",
      "00110111111153454\n",
      "After pruning: [784, 10, 13, 1]\n",
      "1111123223\n",
      "0011022111113\n",
      "-------------------\n",
      "After growing: [784, 15, 18, 1]\n",
      "111112322344444\n",
      "001101111111134443\n",
      "Cost after epoch 0: 0.070334\n",
      "Cost after epoch 1: 0.069424\n",
      "Iteration 4: accuracy 0.9580625\n",
      "111112313355454\n",
      "001101111111154544\n",
      "After pruning: [784, 10, 12, 1]\n",
      "1111123133\n",
      "001102211111\n",
      "-------------------\n",
      "After growing: [784, 15, 17, 1]\n",
      "111112313344444\n",
      "00110111111134443\n",
      "Cost after epoch 0: 0.067122\n",
      "Cost after epoch 1: 0.067025\n",
      "Iteration 5: accuracy 0.9584375\n",
      "111112313445444\n",
      "00110111111154354\n",
      "After pruning: [784, 9, 12, 1]\n",
      "111112313\n",
      "001103212113\n",
      "-------------------\n",
      "After growing: [784, 14, 17, 1]\n",
      "11111231344444\n",
      "00110111111134443\n",
      "Cost after epoch 0: 0.065137\n",
      "Cost after epoch 1: 0.068738\n",
      "Iteration 6: accuracy 0.9584583333333333\n",
      "11111231345545\n",
      "00110111111155444\n",
      "After pruning: [784, 9, 11, 1]\n",
      "111112313\n",
      "00110312113\n",
      "-------------------\n",
      "After growing: [784, 14, 16, 1]\n",
      "11111231344444\n",
      "0011011111143444\n",
      "Cost after epoch 0: 0.067070\n",
      "Cost after epoch 1: 0.066813\n",
      "Iteration 7: accuracy 0.9582291666666667\n",
      "11111241444455\n",
      "0011011111135455\n",
      "After pruning: [784, 8, 10, 1]\n",
      "11111214\n",
      "0011012113\n",
      "-------------------\n",
      "After growing: [784, 13, 15, 1]\n",
      "1111121444444\n",
      "001101111143444\n",
      "Cost after epoch 0: 0.064193\n",
      "Cost after epoch 1: 0.065068\n",
      "Iteration 8: accuracy 0.9597708333333334\n",
      "1111121545445\n",
      "001101111155445\n",
      "After pruning: [784, 7, 10, 1]\n",
      "1111121\n",
      "0011012113\n",
      "-------------------\n",
      "After growing: [784, 12, 15, 1]\n",
      "111112144444\n",
      "001101111143444\n",
      "Cost after epoch 0: 0.062834\n",
      "Cost after epoch 1: 0.062460\n",
      "Iteration 9: accuracy 0.9605208333333334\n",
      "111113155454\n",
      "001101111154555\n",
      "After pruning: [784, 7, 9, 1]\n",
      "1111131\n",
      "001101211\n",
      "-------------------\n",
      "After growing: [784, 12, 14, 1]\n",
      "111113144444\n",
      "00110111144344\n",
      "Cost after epoch 0: 0.061103\n",
      "Cost after epoch 1: 0.059540\n",
      "Iteration 10: accuracy 0.9611875\n",
      "111114144454\n",
      "00110111155545\n",
      "After pruning: [784, 6, 9, 1]\n",
      "111111\n",
      "001101311\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [784, 5, 5, 1]\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters = train_dynamic_model(X_train_fm, y_train_fm, parameters, learning_rate=0.02, l1_term=0.005, n_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.047827\n",
      "Cost after epoch 1: 0.042520\n",
      "Iteration 1: accuracy 0.956\n",
      "After pruning: [784, 5, 7, 1]\n",
      "11223\n",
      "0032121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.040865\n",
      "Cost after epoch 1: 0.038965\n",
      "Iteration 2: accuracy 0.9573125\n",
      "After pruning: [784, 7, 12, 1]\n",
      "1122233\n",
      "001111123222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.040428\n",
      "Cost after epoch 1: 0.044966\n",
      "Iteration 3: accuracy 0.959125\n",
      "After pruning: [784, 9, 15, 1]\n",
      "112123233\n",
      "001111111111223\n",
      "-------------------\n",
      "Cost after epoch 0: 0.055996\n",
      "Cost after epoch 1: 0.058450\n",
      "Iteration 4: accuracy 0.9607916666666667\n",
      "After pruning: [784, 9, 17, 1]\n",
      "112123233\n",
      "00111111111122323\n",
      "-------------------\n",
      "Cost after epoch 0: 0.060388\n",
      "Cost after epoch 1: 0.060863\n",
      "Iteration 5: accuracy 0.9617083333333334\n",
      "After pruning: [784, 9, 17, 1]\n",
      "112122232\n",
      "00111111111122323\n",
      "-------------------\n",
      "Cost after epoch 0: 0.058235\n",
      "Cost after epoch 1: 0.057322\n",
      "Iteration 6: accuracy 0.96225\n",
      "After pruning: [784, 10, 17, 1]\n",
      "1121222323\n",
      "00111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.057032\n",
      "Cost after epoch 1: 0.057796\n",
      "Iteration 7: accuracy 0.9631666666666666\n",
      "After pruning: [784, 10, 17, 1]\n",
      "1121222322\n",
      "00111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.057095\n",
      "Cost after epoch 1: 0.055171\n",
      "Iteration 8: accuracy 0.9633333333333334\n",
      "After pruning: [784, 9, 17, 1]\n",
      "112122222\n",
      "00111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.050791\n",
      "Cost after epoch 1: 0.055900\n",
      "Iteration 9: accuracy 0.9631875\n",
      "After pruning: [784, 9, 18, 1]\n",
      "112122222\n",
      "001111111111111113\n",
      "-------------------\n",
      "Cost after epoch 0: 0.052416\n",
      "Cost after epoch 1: 0.052427\n",
      "Iteration 10: accuracy 0.9638333333333333\n",
      "After pruning: [784, 10, 18, 1]\n",
      "1121222223\n",
      "001111111111111111\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [784, 2, 2, 1]\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters = train_dynamic_model(X_train_fm, y_train_fm, parameters, learning_rate=0.02, l1_term=0.001, n_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 3.889504\n",
      "Cost after epoch 1: 1.531979\n",
      "Iteration 1: accuracy 0.9519375\n",
      "After pruning: [784, 76, 100, 1]\n",
      "1111111111111111111111111211112222211222222222122222222222222222223233333233\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111121221111121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.802132\n",
      "Cost after epoch 1: 0.475432\n",
      "Iteration 2: accuracy 0.9529791666666667\n",
      "After pruning: [784, 37, 75, 1]\n",
      "1111111111111112211222121222212222223\n",
      "111111111111111111111111111111111112111111211211211122222322211212221112222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.324618\n",
      "Cost after epoch 1: 0.246431\n",
      "Iteration 3: accuracy 0.955125\n",
      "After pruning: [784, 26, 50, 1]\n",
      "11111111111221222222222212\n",
      "11111111111111112111111111111122111221121111222121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.198155\n",
      "Cost after epoch 1: 0.171620\n",
      "Iteration 4: accuracy 0.9568541666666667\n",
      "After pruning: [784, 22, 42, 1]\n",
      "1111112121122122222322\n",
      "111111111111111221211122211212221222121112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.153899\n",
      "Cost after epoch 1: 0.140344\n",
      "Iteration 5: accuracy 0.957875\n",
      "After pruning: [784, 17, 34, 1]\n",
      "11111121212222242\n",
      "1111111111111122212221221113131212\n",
      "-------------------\n",
      "Cost after epoch 0: 0.125387\n",
      "Cost after epoch 1: 0.117170\n",
      "Iteration 6: accuracy 0.9583958333333333\n",
      "After pruning: [784, 14, 28, 1]\n",
      "11111121222324\n",
      "1111111111111122122222132213\n",
      "-------------------\n",
      "Cost after epoch 0: 0.107173\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-549a5c340f87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlayers_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dynamic_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_fm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_fm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_term\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/self-scaling-nets/nets/core.py\u001b[0m in \u001b[0;36mtrain_dynamic_model\u001b[0;34m(X, y, parameters, learning_rate, l1_term, n_iterations)\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;31m# print(get_param_string(parameters['W2']))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         parameters = train_model(X, y, parameters, learning_rate=learning_rate, l1_term=l1_term, self_scale=True,\n\u001b[0;32m--> 527\u001b[0;31m                                  self_scale_coef=None, num_epochs=2, print_cost=True)\n\u001b[0m\u001b[1;32m    528\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Iteration {iteration}: accuracy {measure_accuracy(parameters, X, y)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;31m# print(get_param_string(parameters['W1']))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/self-scaling-nets/nets/core.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(X, Y, parameters, learning_rate, l1_term, self_scale, self_scale_coef, num_epochs, print_cost)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0;31m# Compute cost.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m             \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_term\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_scale_coef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0;31m# Backward propagation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/self-scaling-nets/nets/core.py\u001b[0m in \u001b[0;36mcompute_cost\u001b[0;34m(AL, Y, parameters, l1_term, self_scale, self_scale_coef)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself_scale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0mscaling_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_scaling_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1_term\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_scale_coef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m             \u001b[0mreg_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaling_matrix\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mreg_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaling_matrix\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/self-scaling-nets/nets/core.py\u001b[0m in \u001b[0;36mget_scaling_matrix\u001b[0;34m(l1_term, n_output_neurons, self_scale_coef)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mscaling_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaling_matrix\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mscaling_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ml1_term\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0mscaling_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_term\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_output_neurons\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_output_neurons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscaling_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mlinspace\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/ml/lib/python3.7/site-packages/numpy/core/function_base.py\u001b[0m in \u001b[0;36mlinspace\u001b[0;34m(start, stop, num, endpoint, retstep, dtype, axis)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdiv\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;31m# Special handling for denormal numbers, gh-5437\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36many\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/ml/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36many\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   2315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m     \"\"\"\n\u001b[0;32m-> 2317\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'any'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/ml/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "layers_dims = [784, 100, 100, 1]\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters = train_dynamic_model(X_train_fm, y_train_fm, parameters, learning_rate=0.02, l1_term=0.005, n_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.092306\n",
      "Cost after epoch 1: 0.085953\n",
      "Iteration 1: accuracy 0.9555208333333334\n",
      "After pruning: [784, 9, 10, 1]\n",
      "111112222\n",
      "0011022211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.079161\n",
      "Cost after epoch 1: 0.074457\n",
      "Iteration 2: accuracy 0.9570208333333333\n",
      "After pruning: [784, 11, 15, 1]\n",
      "11111333222\n",
      "001101211122222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.084775\n",
      "Cost after epoch 1: 0.084161\n",
      "Iteration 3: accuracy 0.9583958333333333\n",
      "After pruning: [784, 11, 19, 1]\n",
      "11111343222\n",
      "0011012111222222222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.089904\n",
      "Cost after epoch 1: 0.090685\n",
      "Iteration 4: accuracy 0.9591666666666666\n",
      "After pruning: [784, 11, 23, 1]\n",
      "11111342223\n",
      "00110121111111011122222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.103428\n",
      "Cost after epoch 1: 0.093115\n",
      "Iteration 5: accuracy 0.9593541666666666\n",
      "After pruning: [784, 10, 16, 1]\n",
      "1111134212\n",
      "0011012111333222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.082899\n",
      "Cost after epoch 1: 0.080845\n",
      "Iteration 6: accuracy 0.960625\n",
      "After pruning: [784, 11, 21, 1]\n",
      "11111342123\n",
      "001101211111110132222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.093041\n",
      "Cost after epoch 1: 0.087644\n",
      "Iteration 7: accuracy 0.9610833333333333\n",
      "After pruning: [784, 9, 16, 1]\n",
      "111114212\n",
      "0010012211323222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.080268\n",
      "Cost after epoch 1: 0.074423\n",
      "Iteration 8: accuracy 0.9610208333333333\n",
      "After pruning: [784, 9, 18, 1]\n",
      "111114212\n",
      "001001221123332222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.086440\n",
      "Cost after epoch 1: 0.074588\n",
      "Iteration 9: accuracy 0.9611666666666666\n",
      "After pruning: [784, 10, 23, 1]\n",
      "1111143123\n",
      "00100121111111011122222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.098054\n",
      "Cost after epoch 1: 0.094286\n",
      "Iteration 10: accuracy 0.9625208333333334\n",
      "After pruning: [784, 9, 13, 1]\n",
      "111114312\n",
      "0010012112222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.076635\n",
      "Cost after epoch 1: 0.070534\n",
      "Iteration 11: accuracy 0.9628541666666667\n",
      "After pruning: [784, 9, 16, 1]\n",
      "111114312\n",
      "0010022112323222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.064894\n",
      "Cost after epoch 1: 0.080751\n",
      "Iteration 12: accuracy 0.9638333333333333\n",
      "After pruning: [784, 8, 18, 1]\n",
      "11211412\n",
      "001002211232232222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.085994\n",
      "Cost after epoch 1: 0.071473\n",
      "Iteration 13: accuracy 0.9647083333333333\n",
      "After pruning: [784, 8, 18, 1]\n",
      "11211412\n",
      "001102311232222322\n",
      "-------------------\n",
      "Cost after epoch 0: 0.073475\n",
      "Cost after epoch 1: 0.071884\n",
      "Iteration 14: accuracy 0.965375\n",
      "After pruning: [784, 8, 14, 1]\n",
      "11211412\n",
      "00110211222322\n",
      "-------------------\n",
      "Cost after epoch 0: 0.074853\n",
      "Cost after epoch 1: 0.072542\n",
      "Iteration 15: accuracy 0.9665625\n",
      "After pruning: [784, 8, 14, 1]\n",
      "11211412\n",
      "00110211323222\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [784, 5, 5, 1]\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters = train_dynamic_model(X_train_fm, y_train_fm, parameters, learning_rate=0.02, l1_term=0.005, n_iterations=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.092306\n",
      "Cost after epoch 1: 0.085953\n",
      "Cost after epoch 2: 0.080205\n",
      "Iteration 1: accuracy 0.9573541666666666\n",
      "After pruning: [784, 9, 10, 1]\n",
      "111112232\n",
      "0011022211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.071381\n",
      "Cost after epoch 1: 0.060681\n",
      "Cost after epoch 2: 0.060275\n",
      "Iteration 2: accuracy 0.9575833333333333\n",
      "After pruning: [784, 11, 15, 1]\n",
      "11111233222\n",
      "001101211122222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.068230\n",
      "Cost after epoch 1: 0.085632\n",
      "Cost after epoch 2: 0.075234\n",
      "Iteration 3: accuracy 0.9591875\n",
      "After pruning: [784, 10, 18, 1]\n",
      "1111124222\n",
      "001101211122322322\n",
      "-------------------\n",
      "Cost after epoch 0: 0.090078\n",
      "Cost after epoch 1: 0.086322\n",
      "Cost after epoch 2: 0.082395\n",
      "Iteration 4: accuracy 0.9606666666666667\n",
      "After pruning: [784, 10, 15, 1]\n",
      "1111124222\n",
      "001101211133322\n",
      "-------------------\n",
      "Cost after epoch 0: 0.080377\n",
      "Cost after epoch 1: 0.077387\n",
      "Cost after epoch 2: 0.075291\n",
      "Iteration 5: accuracy 0.9613958333333333\n",
      "After pruning: [784, 10, 13, 1]\n",
      "1111134211\n",
      "0011012211222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.071615\n",
      "Cost after epoch 1: 0.070443\n",
      "Cost after epoch 2: 0.072730\n",
      "Iteration 6: accuracy 0.9625416666666666\n",
      "After pruning: [784, 9, 15, 1]\n",
      "111114211\n",
      "001101321132232\n",
      "-------------------\n",
      "Cost after epoch 0: 0.078413\n",
      "Cost after epoch 1: 0.074528\n",
      "Cost after epoch 2: 0.067437\n",
      "Iteration 7: accuracy 0.9628333333333333\n",
      "After pruning: [784, 9, 14, 1]\n",
      "111114311\n",
      "00110121132332\n",
      "-------------------\n",
      "Cost after epoch 0: 0.075424\n",
      "Cost after epoch 1: 0.075154\n",
      "Cost after epoch 2: 0.057663\n",
      "Iteration 8: accuracy 0.9625416666666666\n",
      "After pruning: [784, 9, 13, 1]\n",
      "112114411\n",
      "0011022113222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.062254\n",
      "Cost after epoch 1: 0.062002\n",
      "Cost after epoch 2: 0.077776\n",
      "Iteration 9: accuracy 0.9648333333333333\n",
      "After pruning: [784, 9, 17, 1]\n",
      "112114113\n",
      "00110221111112232\n",
      "-------------------\n",
      "Cost after epoch 0: 0.071446\n",
      "Cost after epoch 1: 0.070088\n",
      "Cost after epoch 2: 0.083259\n",
      "Iteration 10: accuracy 0.9653125\n",
      "After pruning: [784, 9, 17, 1]\n",
      "112114113\n",
      "00110211111223222\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [784, 5, 5, 1]\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters = train_dynamic_model(X_train_fm, y_train_fm, parameters, learning_rate=0.02, l1_term=0.005, n_iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.092306\n",
      "Cost after epoch 1: 0.085953\n",
      "Cost after epoch 2: 0.080205\n",
      "Cost after epoch 3: 0.072603\n",
      "Cost after epoch 4: 0.060748\n",
      "Iteration 1: accuracy 0.9575208333333334\n",
      "After pruning: [784, 9, 10, 1]\n",
      "111112332\n",
      "0011022221\n",
      "-------------------\n",
      "Cost after epoch 0: 0.057817\n",
      "Cost after epoch 1: 0.057874\n",
      "Cost after epoch 2: 0.055294\n",
      "Cost after epoch 3: 0.066852\n",
      "Cost after epoch 4: 0.063286\n",
      "Iteration 2: accuracy 0.9591458333333334\n",
      "After pruning: [784, 10, 14, 1]\n",
      "1111123222\n",
      "00110121112222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.071442\n",
      "Cost after epoch 1: 0.073760\n",
      "Cost after epoch 2: 0.073518\n",
      "Cost after epoch 3: 0.072838\n",
      "Cost after epoch 4: 0.068825\n",
      "Iteration 3: accuracy 0.9605208333333334\n",
      "After pruning: [784, 10, 11, 1]\n",
      "1111123212\n",
      "00110122112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.078398\n",
      "Cost after epoch 1: 0.072410\n",
      "Cost after epoch 2: 0.072927\n",
      "Cost after epoch 3: 0.061262\n",
      "Cost after epoch 4: 0.070523\n",
      "Iteration 4: accuracy 0.9617708333333334\n",
      "After pruning: [784, 10, 13, 1]\n",
      "1111133212\n",
      "0011012112323\n",
      "-------------------\n",
      "Cost after epoch 0: 0.079475\n",
      "Cost after epoch 1: 0.076422\n",
      "Cost after epoch 2: 0.071076\n",
      "Cost after epoch 3: 0.077560\n",
      "Cost after epoch 4: 0.065088\n",
      "Iteration 5: accuracy 0.9649583333333334\n",
      "After pruning: [784, 9, 10, 1]\n",
      "112114312\n",
      "0011021133\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [784, 5, 5, 1]\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters = train_dynamic_model(X_train_fm, y_train_fm, parameters, learning_rate=0.02, l1_term=0.005, n_iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.092306\n",
      "Cost after epoch 1: 0.085953\n",
      "Cost after epoch 2: 0.080205\n",
      "Cost after epoch 3: 0.072603\n",
      "Cost after epoch 4: 0.060748\n",
      "Iteration 1: accuracy 0.9575208333333334\n",
      "After pruning: [784, 9, 10, 1]\n",
      "111112332\n",
      "0011022221\n",
      "-------------------\n",
      "Cost after epoch 0: 0.057817\n",
      "Cost after epoch 1: 0.057874\n",
      "Cost after epoch 2: 0.055294\n",
      "Cost after epoch 3: 0.066852\n",
      "Cost after epoch 4: 0.063286\n",
      "Iteration 2: accuracy 0.9591458333333334\n",
      "After pruning: [784, 10, 14, 1]\n",
      "1111123222\n",
      "00110121112222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.071442\n",
      "Cost after epoch 1: 0.073760\n",
      "Cost after epoch 2: 0.073518\n",
      "Cost after epoch 3: 0.072838\n",
      "Cost after epoch 4: 0.068825\n",
      "Iteration 3: accuracy 0.9605208333333334\n",
      "After pruning: [784, 10, 11, 1]\n",
      "1111123212\n",
      "00110122112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.078398\n",
      "Cost after epoch 1: 0.072410\n",
      "Cost after epoch 2: 0.072927\n",
      "Cost after epoch 3: 0.061262\n",
      "Cost after epoch 4: 0.070523\n",
      "Iteration 4: accuracy 0.9617708333333334\n",
      "After pruning: [784, 10, 13, 1]\n",
      "1111133212\n",
      "0011012112323\n",
      "-------------------\n",
      "Cost after epoch 0: 0.079475\n",
      "Cost after epoch 1: 0.076422\n",
      "Cost after epoch 2: 0.071076\n",
      "Cost after epoch 3: 0.077560\n",
      "Cost after epoch 4: 0.065088\n",
      "Iteration 5: accuracy 0.9649583333333334\n",
      "After pruning: [784, 9, 10, 1]\n",
      "112114312\n",
      "0011021133\n",
      "-------------------\n",
      "Cost after epoch 0: 0.065663\n",
      "Cost after epoch 1: 0.066018\n",
      "Cost after epoch 2: 0.065280\n",
      "Cost after epoch 3: 0.062907\n",
      "Cost after epoch 4: 0.058330\n",
      "Iteration 6: accuracy 0.9649583333333334\n",
      "After pruning: [784, 9, 11, 1]\n",
      "112114412\n",
      "00110211222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.065097\n",
      "Cost after epoch 1: 0.078307\n",
      "Cost after epoch 2: 0.064936\n",
      "Cost after epoch 3: 0.065842\n",
      "Cost after epoch 4: 0.064130\n",
      "Iteration 7: accuracy 0.9662291666666667\n",
      "After pruning: [784, 9, 14, 1]\n",
      "112114123\n",
      "00110111111323\n",
      "-------------------\n",
      "Cost after epoch 0: 0.074784\n",
      "Cost after epoch 1: 0.075040\n",
      "Cost after epoch 2: 0.073377\n",
      "Cost after epoch 3: 0.075024\n",
      "Cost after epoch 4: 0.077345\n",
      "Iteration 8: accuracy 0.9662291666666667\n",
      "After pruning: [784, 7, 9, 1]\n",
      "1121141\n",
      "001101323\n",
      "-------------------\n",
      "Cost after epoch 0: 0.071307\n",
      "Cost after epoch 1: 0.069996\n",
      "Cost after epoch 2: 0.068166\n",
      "Cost after epoch 3: 0.070294\n",
      "Cost after epoch 4: 0.068099\n",
      "Iteration 9: accuracy 0.9675\n",
      "After pruning: [784, 7, 10, 1]\n",
      "1121141\n",
      "0011013322\n",
      "-------------------\n",
      "Cost after epoch 0: 0.073442\n",
      "Cost after epoch 1: 0.073254\n",
      "Cost after epoch 2: 0.070027\n",
      "Cost after epoch 3: 0.071756\n",
      "Cost after epoch 4: 0.071436\n",
      "Iteration 10: accuracy 0.9677916666666667\n",
      "After pruning: [784, 8, 14, 1]\n",
      "11211413\n",
      "00110132212322\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [784, 5, 5, 1]\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters = train_dynamic_model(X_train_fm, y_train_fm, parameters, learning_rate=0.02, l1_term=0.005, n_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.082807\n",
      "Iteration 1: accuracy 0.953375\n",
      "After pruning: [784, 10, 10, 1]\n",
      "1111122232\n",
      "0011022211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.071879\n",
      "Iteration 2: accuracy 0.9539375\n",
      "After pruning: [784, 11, 14, 1]\n",
      "11111222422\n",
      "00110221112321\n",
      "-------------------\n",
      "Cost after epoch 0: 0.076350\n",
      "Iteration 3: accuracy 0.9550625\n",
      "After pruning: [784, 12, 15, 1]\n",
      "111112224233\n",
      "001102211111112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.078469\n",
      "Iteration 4: accuracy 0.956\n",
      "After pruning: [784, 11, 15, 1]\n",
      "11111232423\n",
      "001102211111112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.075879\n",
      "Iteration 5: accuracy 0.9565208333333334\n",
      "After pruning: [784, 11, 15, 1]\n",
      "11111232423\n",
      "001102111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.076327\n",
      "Iteration 6: accuracy 0.956625\n",
      "After pruning: [784, 9, 13, 1]\n",
      "111112323\n",
      "0011022111213\n",
      "-------------------\n",
      "Cost after epoch 0: 0.069081\n",
      "Iteration 7: accuracy 0.9576041666666667\n",
      "After pruning: [784, 9, 12, 1]\n",
      "111112313\n",
      "001103212121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.066809\n",
      "Iteration 8: accuracy 0.957875\n",
      "After pruning: [784, 9, 11, 1]\n",
      "111112313\n",
      "00110222121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.065422\n",
      "Iteration 9: accuracy 0.95825\n",
      "After pruning: [784, 9, 12, 1]\n",
      "111112313\n",
      "001102221313\n",
      "-------------------\n",
      "Cost after epoch 0: 0.064139\n",
      "Iteration 10: accuracy 0.9583125\n",
      "After pruning: [784, 10, 13, 1]\n",
      "1111123133\n",
      "0011012112113\n",
      "-------------------\n",
      "Cost after epoch 0: 0.071134\n",
      "Iteration 11: accuracy 0.9584583333333333\n",
      "After pruning: [784, 10, 13, 1]\n",
      "1111123133\n",
      "0011012112111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.071811\n",
      "Iteration 12: accuracy 0.9584375\n",
      "After pruning: [784, 9, 12, 1]\n",
      "111112313\n",
      "001102221133\n",
      "-------------------\n",
      "Cost after epoch 0: 0.068317\n",
      "Iteration 13: accuracy 0.9585416666666666\n",
      "After pruning: [784, 10, 13, 1]\n",
      "1111123133\n",
      "0011011111123\n",
      "-------------------\n",
      "Cost after epoch 0: 0.070744\n",
      "Iteration 14: accuracy 0.9588333333333333\n",
      "After pruning: [784, 7, 12, 1]\n",
      "1111121\n",
      "001103221133\n",
      "-------------------\n",
      "Cost after epoch 0: 0.064826\n",
      "Iteration 15: accuracy 0.9594583333333333\n",
      "After pruning: [784, 7, 10, 1]\n",
      "1111121\n",
      "0011022113\n",
      "-------------------\n",
      "Cost after epoch 0: 0.060607\n",
      "Iteration 16: accuracy 0.9594791666666667\n",
      "After pruning: [784, 8, 10, 1]\n",
      "11111213\n",
      "0011021111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.056761\n",
      "Iteration 17: accuracy 0.9585833333333333\n",
      "After pruning: [784, 9, 10, 1]\n",
      "111112133\n",
      "0011021111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.059498\n",
      "Iteration 18: accuracy 0.9594375\n",
      "After pruning: [784, 7, 10, 1]\n",
      "1111131\n",
      "0011023113\n",
      "-------------------\n",
      "Cost after epoch 0: 0.059507\n",
      "Iteration 19: accuracy 0.9608541666666667\n",
      "After pruning: [784, 7, 8, 1]\n",
      "1111131\n",
      "00110211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.054894\n",
      "Iteration 20: accuracy 0.9610208333333333\n",
      "After pruning: [784, 7, 8, 1]\n",
      "1111131\n",
      "00110211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.053383\n",
      "Iteration 21: accuracy 0.9615833333333333\n",
      "After pruning: [784, 6, 8, 1]\n",
      "111111\n",
      "00110211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.049368\n",
      "Iteration 22: accuracy 0.9620208333333333\n",
      "After pruning: [784, 6, 9, 1]\n",
      "111111\n",
      "001102113\n",
      "-------------------\n",
      "Cost after epoch 0: 0.048899\n",
      "Iteration 23: accuracy 0.962375\n",
      "After pruning: [784, 7, 9, 1]\n",
      "1121113\n",
      "001101111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.048710\n",
      "Iteration 24: accuracy 0.9618958333333333\n",
      "After pruning: [784, 6, 8, 1]\n",
      "112111\n",
      "00110211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.045906\n",
      "Iteration 25: accuracy 0.9625416666666666\n",
      "After pruning: [784, 6, 8, 1]\n",
      "112111\n",
      "00110211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.046732\n",
      "Iteration 26: accuracy 0.96275\n",
      "After pruning: [784, 6, 8, 1]\n",
      "112111\n",
      "00110211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.047251\n",
      "Iteration 27: accuracy 0.9633958333333333\n",
      "After pruning: [784, 6, 8, 1]\n",
      "112111\n",
      "00110211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.045722\n",
      "Iteration 28: accuracy 0.9639583333333334\n",
      "After pruning: [784, 7, 8, 1]\n",
      "1121113\n",
      "00110111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.045711\n",
      "Iteration 29: accuracy 0.9641041666666667\n",
      "After pruning: [784, 6, 8, 1]\n",
      "112111\n",
      "00110211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.044274\n",
      "Iteration 30: accuracy 0.9644375\n",
      "After pruning: [784, 6, 8, 1]\n",
      "112111\n",
      "00110211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.043749\n",
      "Iteration 31: accuracy 0.9646666666666667\n",
      "After pruning: [784, 6, 8, 1]\n",
      "112111\n",
      "00110211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.042231\n",
      "Iteration 32: accuracy 0.9643958333333333\n",
      "After pruning: [784, 6, 8, 1]\n",
      "112111\n",
      "00110211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.042158\n",
      "Iteration 33: accuracy 0.9650833333333333\n",
      "After pruning: [784, 6, 8, 1]\n",
      "112111\n",
      "00110211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.042543\n",
      "Iteration 34: accuracy 0.9649375\n",
      "After pruning: [784, 6, 8, 1]\n",
      "112111\n",
      "00110211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.041541\n",
      "Iteration 35: accuracy 0.9651666666666666\n",
      "After pruning: [784, 7, 8, 1]\n",
      "1121113\n",
      "00110111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.042543\n",
      "Iteration 36: accuracy 0.9653958333333333\n",
      "After pruning: [784, 7, 8, 1]\n",
      "1121113\n",
      "00110111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.043284\n",
      "Iteration 37: accuracy 0.9653125\n",
      "After pruning: [784, 6, 8, 1]\n",
      "112111\n",
      "00110211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.041803\n",
      "Iteration 38: accuracy 0.9656458333333333\n",
      "After pruning: [784, 6, 8, 1]\n",
      "112111\n",
      "00110211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.040704\n",
      "Iteration 39: accuracy 0.9657083333333333\n",
      "After pruning: [784, 6, 8, 1]\n",
      "112111\n",
      "00110211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.044154\n",
      "Iteration 40: accuracy 0.9656041666666667\n",
      "After pruning: [784, 6, 8, 1]\n",
      "112111\n",
      "00110211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.044514\n",
      "Iteration 41: accuracy 0.966\n",
      "After pruning: [784, 6, 8, 1]\n",
      "112111\n",
      "00110211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.043687\n",
      "Iteration 42: accuracy 0.9663958333333333\n",
      "After pruning: [784, 6, 8, 1]\n",
      "112111\n",
      "00110311\n",
      "-------------------\n",
      "Cost after epoch 0: 0.046520\n",
      "Iteration 43: accuracy 0.9663125\n",
      "After pruning: [784, 6, 8, 1]\n",
      "112111\n",
      "00110311\n",
      "-------------------\n",
      "Cost after epoch 0: 0.045153\n",
      "Iteration 44: accuracy 0.9669166666666666\n",
      "After pruning: [784, 6, 8, 1]\n",
      "112111\n",
      "00110311\n",
      "-------------------\n",
      "Cost after epoch 0: 0.043324\n",
      "Iteration 45: accuracy 0.9669583333333334\n",
      "After pruning: [784, 6, 7, 1]\n",
      "112111\n",
      "0011011\n",
      "-------------------\n",
      "Cost after epoch 0: 0.044109\n",
      "Iteration 46: accuracy 0.9671875\n",
      "After pruning: [784, 6, 7, 1]\n",
      "112111\n",
      "0011011\n",
      "-------------------\n",
      "Cost after epoch 0: 0.044598\n",
      "Iteration 47: accuracy 0.9673125\n",
      "After pruning: [784, 6, 7, 1]\n",
      "112111\n",
      "0011011\n",
      "-------------------\n",
      "Cost after epoch 0: 0.043655\n",
      "Iteration 48: accuracy 0.9674375\n",
      "After pruning: [784, 6, 7, 1]\n",
      "112111\n",
      "0011011\n",
      "-------------------\n",
      "Cost after epoch 0: 0.045841\n",
      "Iteration 49: accuracy 0.9677708333333334\n",
      "After pruning: [784, 6, 7, 1]\n",
      "112111\n",
      "0011011\n",
      "-------------------\n",
      "Cost after epoch 0: 0.043890\n",
      "Iteration 50: accuracy 0.9675416666666666\n",
      "After pruning: [784, 6, 7, 1]\n",
      "112111\n",
      "0011011\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [784, 5, 5, 1]\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters = train_dynamic_model(X_train_fm, y_train_fm, parameters, learning_rate=0.02, l1_term=0.005, n_iterations=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 3.889684\n",
      "Iteration 1: accuracy 0.9512291666666667\n",
      "After pruning: [784, 100, 100, 1]\n",
      "1111111111111111111111111111111111111111111111111121122111112122112122222222122222212212222222222222\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 1.627600\n",
      "Iteration 2: accuracy 0.9519166666666666\n",
      "After pruning: [784, 76, 100, 1]\n",
      "1111111111111111111111111211112222211222222222122222222222222222223233333233\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111121221111121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.802006\n",
      "Iteration 3: accuracy 0.9526666666666667\n",
      "After pruning: [784, 54, 93, 1]\n",
      "111111111111111111111212122221222222222222222222233243\n",
      "111111111111111111111111111111111111111111111111211111111111111122211211112111222222222222222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.474940\n",
      "Iteration 4: accuracy 0.953125\n",
      "After pruning: [784, 37, 75, 1]\n",
      "1111111111111112211222121222212222223\n",
      "111111111111111111111111111111111112111111211211211122222322211212221112222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.326965\n",
      "Iteration 5: accuracy 0.9539583333333334\n",
      "After pruning: [784, 30, 63, 1]\n",
      "111111111112212222222212132232\n",
      "111111111111111111111111111111211112111111212121122322222122122\n",
      "-------------------\n",
      "Cost after epoch 0: 0.252439\n",
      "Iteration 6: accuracy 0.95525\n",
      "After pruning: [784, 26, 52, 1]\n",
      "11111111111221222222222212\n",
      "1111111111111111211111111111112211122112111122213213\n",
      "-------------------\n",
      "Cost after epoch 0: 0.206059\n",
      "Iteration 7: accuracy 0.9562291666666667\n",
      "After pruning: [784, 24, 45, 1]\n",
      "111111112112212222222213\n",
      "111111111111111121111111111212221222121211211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.169230\n",
      "Iteration 8: accuracy 0.9568958333333333\n",
      "After pruning: [784, 22, 42, 1]\n",
      "1111112121122122222322\n",
      "111111111111111221211122211212221222121112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.155130\n",
      "Iteration 9: accuracy 0.9577291666666666\n",
      "After pruning: [784, 20, 37, 1]\n",
      "11111121211222232322\n",
      "1111111111111112212211221121212211112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.134617\n",
      "Iteration 10: accuracy 0.9581041666666666\n",
      "After pruning: [784, 17, 33, 1]\n",
      "11111121212222232\n",
      "111111111111112221222122111112123\n",
      "-------------------\n",
      "Cost after epoch 0: 0.122964\n",
      "Iteration 11: accuracy 0.95825\n",
      "After pruning: [784, 16, 31, 1]\n",
      "1111112121222242\n",
      "1111111111111122132222311111212\n",
      "-------------------\n",
      "Cost after epoch 0: 0.116394\n",
      "Iteration 12: accuracy 0.9584375\n",
      "After pruning: [784, 14, 27, 1]\n",
      "11111121222324\n",
      "111111111111112212221212212\n",
      "-------------------\n",
      "Cost after epoch 0: 0.104057\n",
      "Iteration 13: accuracy 0.9587291666666666\n",
      "After pruning: [784, 13, 25, 1]\n",
      "1111112122224\n",
      "1111111111121121222221221\n",
      "-------------------\n",
      "Cost after epoch 0: 0.097429\n",
      "Iteration 14: accuracy 0.9585416666666666\n",
      "After pruning: [784, 13, 25, 1]\n",
      "1111122122224\n",
      "1111111111121122222212213\n",
      "-------------------\n",
      "Cost after epoch 0: 0.095734\n",
      "Iteration 15: accuracy 0.9591875\n",
      "After pruning: [784, 12, 22, 1]\n",
      "111112212223\n",
      "1111111111121122221221\n",
      "-------------------\n",
      "Cost after epoch 0: 0.089550\n",
      "Iteration 16: accuracy 0.9593541666666666\n",
      "After pruning: [784, 11, 22, 1]\n",
      "11111221222\n",
      "1111112111121123212313\n",
      "-------------------\n",
      "Cost after epoch 0: 0.089423\n",
      "Iteration 17: accuracy 0.9592916666666667\n",
      "After pruning: [784, 11, 22, 1]\n",
      "11121221322\n",
      "1111112111121122123133\n",
      "-------------------\n",
      "Cost after epoch 0: 0.088346\n",
      "Iteration 18: accuracy 0.9590833333333333\n",
      "After pruning: [784, 11, 23, 1]\n",
      "11121221223\n",
      "11111111111111121131133\n",
      "-------------------\n",
      "Cost after epoch 0: 0.091527\n",
      "Iteration 19: accuracy 0.9581041666666666\n",
      "After pruning: [784, 11, 23, 1]\n",
      "11121221234\n",
      "11111121111111011121111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.095832\n",
      "Iteration 20: accuracy 0.9597083333333334\n",
      "After pruning: [784, 10, 24, 1]\n",
      "1112122123\n",
      "111111111111111311311223\n",
      "-------------------\n",
      "Cost after epoch 0: 0.096875\n",
      "Iteration 21: accuracy 0.9597916666666667\n",
      "After pruning: [784, 10, 24, 1]\n",
      "1112122133\n",
      "111111111111111312113233\n",
      "-------------------\n",
      "Cost after epoch 0: 0.095601\n",
      "Iteration 22: accuracy 0.959875\n",
      "After pruning: [784, 8, 20, 1]\n",
      "11121221\n",
      "11111121131123121333\n",
      "-------------------\n",
      "Cost after epoch 0: 0.083218\n",
      "Iteration 23: accuracy 0.9599791666666667\n",
      "After pruning: [784, 8, 16, 1]\n",
      "11121221\n",
      "1111112111121213\n",
      "-------------------\n",
      "Cost after epoch 0: 0.077523\n",
      "Iteration 24: accuracy 0.9601041666666666\n",
      "After pruning: [784, 8, 16, 1]\n",
      "11122222\n",
      "1111112111121213\n",
      "-------------------\n",
      "Cost after epoch 0: 0.077586\n",
      "Iteration 25: accuracy 0.9603541666666666\n",
      "After pruning: [784, 9, 17, 1]\n",
      "111222223\n",
      "11111111111112133\n",
      "-------------------\n",
      "Cost after epoch 0: 0.080079\n",
      "Iteration 26: accuracy 0.9594166666666667\n",
      "After pruning: [784, 9, 17, 1]\n",
      "111222323\n",
      "11111111111112133\n",
      "-------------------\n",
      "Cost after epoch 0: 0.080504\n",
      "Iteration 27: accuracy 0.9596666666666667\n",
      "After pruning: [784, 9, 17, 1]\n",
      "111222323\n",
      "11111111111112133\n",
      "-------------------\n",
      "Cost after epoch 0: 0.081464\n",
      "Iteration 28: accuracy 0.9598125\n",
      "After pruning: [784, 7, 16, 1]\n",
      "1112222\n",
      "1111112111121213\n",
      "-------------------\n",
      "Cost after epoch 0: 0.077146\n",
      "Iteration 29: accuracy 0.9599583333333334\n",
      "After pruning: [784, 7, 17, 1]\n",
      "1112232\n",
      "11111121111212133\n",
      "-------------------\n",
      "Cost after epoch 0: 0.082096\n",
      "Iteration 30: accuracy 0.9607083333333334\n",
      "After pruning: [784, 7, 18, 1]\n",
      "1112232\n",
      "111111211112121333\n",
      "-------------------\n",
      "Cost after epoch 0: 0.084197\n",
      "Iteration 31: accuracy 0.9606875\n",
      "After pruning: [784, 6, 17, 1]\n",
      "111222\n",
      "11112121111212133\n",
      "-------------------\n",
      "Cost after epoch 0: 0.082931\n",
      "Iteration 32: accuracy 0.9605\n",
      "After pruning: [784, 6, 17, 1]\n",
      "111222\n",
      "11112121111312133\n",
      "-------------------\n",
      "Cost after epoch 0: 0.085055\n",
      "Iteration 33: accuracy 0.9610416666666667\n",
      "After pruning: [784, 6, 16, 1]\n",
      "111222\n",
      "1111212111131213\n",
      "-------------------\n",
      "Cost after epoch 0: 0.083128\n",
      "Iteration 34: accuracy 0.961\n",
      "After pruning: [784, 6, 18, 1]\n",
      "111222\n",
      "111121211123121333\n",
      "-------------------\n",
      "Cost after epoch 0: 0.084608\n",
      "Iteration 35: accuracy 0.960875\n",
      "After pruning: [784, 6, 19, 1]\n",
      "111222\n",
      "1111212111231213323\n",
      "-------------------\n",
      "Cost after epoch 0: 0.088152\n",
      "Iteration 36: accuracy 0.9604166666666667\n",
      "After pruning: [784, 6, 18, 1]\n",
      "111222\n",
      "111121211123121333\n",
      "-------------------\n",
      "Cost after epoch 0: 0.089633\n",
      "Iteration 37: accuracy 0.9613958333333333\n",
      "After pruning: [784, 6, 18, 1]\n",
      "111223\n",
      "111121211223121333\n",
      "-------------------\n",
      "Cost after epoch 0: 0.087504\n",
      "Iteration 38: accuracy 0.9610416666666667\n",
      "After pruning: [784, 5, 19, 1]\n",
      "11122\n",
      "1111212112231213333\n",
      "-------------------\n",
      "Cost after epoch 0: 0.093239\n",
      "Iteration 39: accuracy 0.9615208333333334\n",
      "After pruning: [784, 5, 19, 1]\n",
      "11122\n",
      "1111213112231213333\n",
      "-------------------\n",
      "Cost after epoch 0: 0.093071\n",
      "Iteration 40: accuracy 0.9615416666666666\n",
      "After pruning: [784, 7, 20, 1]\n",
      "1112233\n",
      "11111111110111011113\n",
      "-------------------\n",
      "Cost after epoch 0: 0.103190\n",
      "Iteration 41: accuracy 0.9612708333333333\n",
      "After pruning: [784, 6, 20, 1]\n",
      "111223\n",
      "11111111110113131133\n",
      "-------------------\n",
      "Cost after epoch 0: 0.099128\n",
      "Iteration 42: accuracy 0.9612708333333333\n",
      "After pruning: [784, 5, 17, 1]\n",
      "11122\n",
      "11112111223131333\n",
      "-------------------\n",
      "Cost after epoch 0: 0.091790\n",
      "Iteration 43: accuracy 0.9614375\n",
      "After pruning: [784, 6, 18, 1]\n",
      "111223\n",
      "111111111211111123\n",
      "-------------------\n",
      "Cost after epoch 0: 0.093476\n",
      "Iteration 44: accuracy 0.9611041666666666\n",
      "After pruning: [784, 8, 18, 1]\n",
      "11123343\n",
      "111111111111111011\n",
      "-------------------\n",
      "Cost after epoch 0: 0.090802\n",
      "Iteration 45: accuracy 0.9587083333333334\n",
      "After pruning: [784, 7, 18, 1]\n",
      "1112343\n",
      "111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.097377\n",
      "Iteration 46: accuracy 0.961\n",
      "After pruning: [784, 5, 19, 1]\n",
      "11123\n",
      "1111111111211111113\n",
      "-------------------\n",
      "Cost after epoch 0: 0.098868\n",
      "Iteration 47: accuracy 0.9610208333333333\n",
      "After pruning: [784, 5, 19, 1]\n",
      "11123\n",
      "1111111111211111113\n",
      "-------------------\n",
      "Cost after epoch 0: 0.097848\n",
      "Iteration 48: accuracy 0.96125\n",
      "After pruning: [784, 5, 18, 1]\n",
      "11133\n",
      "111111111131111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.098293\n",
      "Iteration 49: accuracy 0.9611041666666666\n",
      "After pruning: [784, 7, 18, 1]\n",
      "1113333\n",
      "111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.102561\n",
      "Iteration 50: accuracy 0.9612708333333333\n",
      "After pruning: [784, 9, 18, 1]\n",
      "111333333\n",
      "111111111111111111\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [784, 100, 100, 1]\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters = train_dynamic_model(X_train_fm, y_train_fm, parameters, learning_rate=0.02, l1_term=0.005, n_iterations=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 3.179080\n",
      "Iteration 1: accuracy 0.955375\n",
      "After pruning: [784, 100, 100, 1]\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 2.020085\n",
      "Iteration 2: accuracy 0.955\n",
      "After pruning: [784, 100, 100, 1]\n",
      "1111111111111111111111111111111111111111111111111111111111111111111112111111121111112111111122111221\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 1.376806\n",
      "Iteration 3: accuracy 0.9546041666666667\n",
      "After pruning: [784, 100, 100, 1]\n",
      "1111111111111111111111111111111111111111111111111111122111111111112122222211122222212112222222212222\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 1.011372\n",
      "Iteration 4: accuracy 0.9550416666666667\n",
      "After pruning: [784, 100, 100, 1]\n",
      "1111111111111111111111111111111111111121121111111121122112122122222222222222122222222222222222222222\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.784692\n",
      "Iteration 5: accuracy 0.9551875\n",
      "After pruning: [784, 96, 100, 1]\n",
      "111111111111111111111111111111122211112212221112122222211222212222222222222212222222322222222332\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.612668\n",
      "Iteration 6: accuracy 0.9555\n",
      "After pruning: [784, 85, 100, 1]\n",
      "1111111111111111111111111111112222111122222221122222222122222222222223232322232322223\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111121111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.480935\n",
      "Iteration 7: accuracy 0.957\n",
      "After pruning: [784, 69, 100, 1]\n",
      "111111111111111111111111121111222221122222222212222222222222222222223\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111122221121221\n",
      "-------------------\n",
      "Cost after epoch 0: 0.360484\n",
      "Iteration 8: accuracy 0.9573958333333333\n",
      "After pruning: [784, 64, 100, 1]\n",
      "1111111111111111111111111211212222211222222222222222232222322332\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111132221221221\n",
      "-------------------\n",
      "Cost after epoch 0: 0.313144\n",
      "Iteration 9: accuracy 0.9583125\n",
      "After pruning: [784, 58, 98, 1]\n",
      "1111111111111111111111111221212222222222222222222222223323\n",
      "11111111111111111111111111111111111111111111111111111111111111111221111111111111122112221232222132\n",
      "-------------------\n",
      "Cost after epoch 0: 0.269091\n",
      "Iteration 10: accuracy 0.9586041666666667\n",
      "After pruning: [784, 54, 94, 1]\n",
      "111111111111111111111212122121222222222222222222233233\n",
      "1111111111111111111111111111111111111111111111112111111111111111222112111121112222222222222212\n",
      "-------------------\n",
      "Cost after epoch 0: 0.237233\n",
      "Iteration 11: accuracy 0.9589166666666666\n",
      "After pruning: [784, 50, 92, 1]\n",
      "11111111111111111111121212222122222222222323322324\n",
      "11111111111111111111111111111111111111111121111121111111121111112221221111222122223222222212\n",
      "-------------------\n",
      "Cost after epoch 0: 0.218859\n",
      "Iteration 12: accuracy 0.9593541666666666\n",
      "After pruning: [784, 43, 81, 1]\n",
      "1111111111111111111222121222212222222232224\n",
      "111111111111111111111111111111111111111111211111211112111222211123122111132223221\n",
      "-------------------\n",
      "Cost after epoch 0: 0.189171\n",
      "Iteration 13: accuracy 0.9599166666666666\n",
      "After pruning: [784, 40, 78, 1]\n",
      "1111111111111111111222121222222233222224\n",
      "111111111111111111111111111111111112111111211211211112122222221121222111222321\n",
      "-------------------\n",
      "Cost after epoch 0: 0.175293\n",
      "Iteration 14: accuracy 0.9605625\n",
      "After pruning: [784, 36, 73, 1]\n",
      "111111111111111211122212122222322224\n",
      "1111111111111111111111111111112111121111112112112111222222222111221112222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.160591\n",
      "Iteration 15: accuracy 0.9607291666666666\n",
      "After pruning: [784, 34, 69, 1]\n",
      "1111111111111112111222121222223224\n",
      "111111111111111111111111111111211112111111211212111222222222111211232\n",
      "-------------------\n",
      "Cost after epoch 0: 0.147460\n",
      "Iteration 16: accuracy 0.9611458333333334\n",
      "After pruning: [784, 33, 67, 1]\n",
      "111111111111211212222212122222334\n",
      "1111111111111111111111111111112111121111113112121122222232212121122\n",
      "-------------------\n",
      "Cost after epoch 0: 0.139011\n",
      "Iteration 17: accuracy 0.9612708333333333\n",
      "After pruning: [784, 31, 63, 1]\n",
      "1111111111122112122222121322324\n",
      "111111111111111111111111111111211112111111212121122232231211122\n",
      "-------------------\n",
      "Cost after epoch 0: 0.130270\n",
      "Iteration 18: accuracy 0.9617291666666666\n",
      "After pruning: [784, 28, 60, 1]\n",
      "1111111111122122122222121222\n",
      "111111111111111111111111111111211112111111213121222321211222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.123546\n",
      "Iteration 19: accuracy 0.96175\n",
      "After pruning: [784, 29, 59, 1]\n",
      "11111111111221221222222213223\n",
      "11111111111111112111111111111111111121111111121112111211231\n",
      "-------------------\n",
      "Cost after epoch 0: 0.122570\n",
      "Iteration 20: accuracy 0.9605416666666666\n",
      "After pruning: [784, 27, 55, 1]\n",
      "111111111112212212222222132\n",
      "1111111111111111211111111111112211132112121122222131122\n",
      "-------------------\n",
      "Cost after epoch 0: 0.114040\n",
      "Iteration 21: accuracy 0.9625416666666666\n",
      "After pruning: [784, 27, 51, 1]\n",
      "111111111112212222222222132\n",
      "111111111111111121111111111111211121121211223311123\n",
      "-------------------\n",
      "Cost after epoch 0: 0.107152\n",
      "Iteration 22: accuracy 0.9629791666666667\n",
      "After pruning: [784, 26, 49, 1]\n",
      "11111111111221222222232212\n",
      "1111111111111111211111111112112111211212112212123\n",
      "-------------------\n",
      "Cost after epoch 0: 0.103159\n",
      "Iteration 23: accuracy 0.9630208333333333\n",
      "After pruning: [784, 26, 48, 1]\n",
      "11111111111221222222232213\n",
      "111111111111111121111111111212211121121211212123\n",
      "-------------------\n",
      "Cost after epoch 0: 0.098658\n",
      "Iteration 24: accuracy 0.9627916666666667\n",
      "After pruning: [784, 24, 48, 1]\n",
      "111111111112212222222221\n",
      "111111111111111121111111111212211121221211312133\n",
      "-------------------\n",
      "Cost after epoch 0: 0.098191\n",
      "Iteration 25: accuracy 0.9635416666666666\n",
      "After pruning: [784, 24, 46, 1]\n",
      "111111112112212222223221\n",
      "1111111111111111212111111112122111212212111212\n",
      "-------------------\n",
      "Cost after epoch 0: 0.093372\n",
      "Iteration 26: accuracy 0.9630833333333333\n",
      "After pruning: [784, 23, 46, 1]\n",
      "11111111211221222223221\n",
      "1111111111111111212111112112122111322312111212\n",
      "-------------------\n",
      "Cost after epoch 0: 0.092001\n",
      "Iteration 27: accuracy 0.9636458333333333\n",
      "After pruning: [784, 22, 44, 1]\n",
      "1111111121122122222231\n",
      "11111111111111112121111121121221122213111212\n",
      "-------------------\n",
      "Cost after epoch 0: 0.089490\n",
      "Iteration 28: accuracy 0.9640625\n",
      "After pruning: [784, 21, 43, 1]\n",
      "111111112112212222221\n",
      "1111111111111112212111112112122212221111212\n",
      "-------------------\n",
      "Cost after epoch 0: 0.086738\n",
      "Iteration 29: accuracy 0.9636666666666667\n",
      "After pruning: [784, 21, 43, 1]\n",
      "111111112112222322221\n",
      "1111111111111112212211112112123212221111312\n",
      "-------------------\n",
      "Cost after epoch 0: 0.086221\n",
      "Iteration 30: accuracy 0.9645208333333334\n",
      "After pruning: [784, 21, 41, 1]\n",
      "111111112112222322321\n",
      "11111111111111122122111221121221222111112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.082044\n",
      "Iteration 31: accuracy 0.9645625\n",
      "After pruning: [784, 20, 41, 1]\n",
      "11111111211222222322\n",
      "11111111111111222122111221131321223111112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.082326\n",
      "Iteration 32: accuracy 0.9648333333333333\n",
      "After pruning: [784, 20, 41, 1]\n",
      "11111111211222223223\n",
      "11111111111111112112111211111111212121111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.086672\n",
      "Iteration 33: accuracy 0.9653541666666666\n",
      "After pruning: [784, 19, 38, 1]\n",
      "1111111121122222322\n",
      "11111111111111222122211221112122121112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.079524\n",
      "Iteration 34: accuracy 0.9656666666666667\n",
      "After pruning: [784, 18, 38, 1]\n",
      "111111112112222222\n",
      "11111111111111222122212221112123121112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.078467\n",
      "Iteration 35: accuracy 0.9649791666666667\n",
      "After pruning: [784, 18, 38, 1]\n",
      "111111112112222222\n",
      "11111111111111222122222221112133121112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.079348\n",
      "Iteration 36: accuracy 0.9658333333333333\n",
      "After pruning: [784, 18, 36, 1]\n",
      "111111112112222222\n",
      "111111111111112221222222311121121112\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.078206\n",
      "Iteration 37: accuracy 0.9662291666666667\n",
      "After pruning: [784, 18, 35, 1]\n",
      "111111112122323222\n",
      "11111111111111222132222211121121112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.073699\n",
      "Iteration 38: accuracy 0.9664583333333333\n",
      "After pruning: [784, 18, 34, 1]\n",
      "111111112122323332\n",
      "1111111111111122312222221121121112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.074469\n",
      "Iteration 39: accuracy 0.9666458333333333\n",
      "After pruning: [784, 16, 34, 1]\n",
      "1111111121223232\n",
      "1111111111111122312222221121121212\n",
      "-------------------\n",
      "Cost after epoch 0: 0.073870\n",
      "Iteration 40: accuracy 0.9667291666666666\n",
      "After pruning: [784, 15, 34, 1]\n",
      "111111112122223\n",
      "1111111111111111211211121111111121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.078065\n",
      "Iteration 41: accuracy 0.9667708333333334\n",
      "After pruning: [784, 14, 32, 1]\n",
      "11111111212222\n",
      "11111111111111231222322131121222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.072188\n",
      "Iteration 42: accuracy 0.967\n",
      "After pruning: [784, 14, 31, 1]\n",
      "11111111212222\n",
      "1111111111111123122222131121222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.071613\n",
      "Iteration 43: accuracy 0.9669375\n",
      "After pruning: [784, 14, 29, 1]\n",
      "11111111212322\n",
      "11111111111111212222221131222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.069137\n",
      "Iteration 44: accuracy 0.967\n",
      "After pruning: [784, 15, 29, 1]\n",
      "111112112123223\n",
      "11111111111111112111121121111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.070614\n",
      "Iteration 45: accuracy 0.9673125\n",
      "After pruning: [784, 14, 29, 1]\n",
      "11111211212223\n",
      "11111111111111112111121121111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.070063\n",
      "Iteration 46: accuracy 0.9673541666666666\n",
      "After pruning: [784, 14, 29, 1]\n",
      "11111211212223\n",
      "11111111111111112112111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.070057\n",
      "Iteration 47: accuracy 0.9675833333333334\n",
      "After pruning: [784, 13, 27, 1]\n",
      "1111121121222\n",
      "111111111111111323222111222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.066347\n",
      "Iteration 48: accuracy 0.9678333333333333\n",
      "After pruning: [784, 14, 27, 1]\n",
      "11111211212223\n",
      "111111111111111111221111112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.065875\n",
      "Iteration 49: accuracy 0.9663125\n",
      "After pruning: [784, 14, 27, 1]\n",
      "11111211212323\n",
      "111111111111111111221111112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.068931\n",
      "Iteration 50: accuracy 0.9674791666666667\n",
      "After pruning: [784, 13, 23, 1]\n",
      "1111121121232\n",
      "11111111111211122211132\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [784, 100, 100, 1]\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters = train_dynamic_model(X_train_fm, y_train_fm, parameters, learning_rate=0.02, l1_term=0.0015, n_iterations=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 3.268812\n",
      "Iteration 1: accuracy 0.9553333333333334\n",
      "After pruning: [784, 100, 101, 1]\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113\n",
      "-------------------\n",
      "Cost after epoch 0: 2.106771\n",
      "Iteration 2: accuracy 0.9566041666666667\n",
      "After pruning: [784, 100, 100, 1]\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111112122112121212121212\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 1.513231\n",
      "Iteration 3: accuracy 0.955125\n",
      "After pruning: [784, 100, 100, 1]\n",
      "1111111111111111111111111111111111111111111111112111211211111112111221212111212112222122222222222222\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 1.074942\n",
      "Iteration 4: accuracy 0.9571458333333334\n",
      "After pruning: [784, 100, 100, 1]\n",
      "1111111111111111111111111111111111111111121112212122211211122212112222222222212222222222222222222222\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.835954\n",
      "Iteration 5: accuracy 0.9588541666666667\n",
      "After pruning: [784, 94, 100, 1]\n",
      "1111111111111111111111111111111111221211122212212222212222122222212222222222222222233222322323\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.692308\n",
      "Iteration 6: accuracy 0.9595416666666666\n",
      "After pruning: [784, 83, 100, 1]\n",
      "11111111111111111111111111111111222222122222122222222122222222222222222222222222232\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.523679\n",
      "Iteration 7: accuracy 0.9588125\n",
      "After pruning: [784, 73, 100, 1]\n",
      "1111111111111111111111112111112222222212222222222222222222222222222233322\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111212111111112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.398552\n",
      "Iteration 8: accuracy 0.9598125\n",
      "After pruning: [784, 62, 100, 1]\n",
      "11111111111111111111112221111122222222222222222222222222223222\n",
      "1111111111111111111111111111111111111111111111111111111111111111111221121112112121112111212111111213\n",
      "-------------------\n",
      "Cost after epoch 0: 0.365416\n",
      "Iteration 9: accuracy 0.9603958333333333\n",
      "After pruning: [784, 57, 97, 1]\n",
      "111111111111111111111122221222222222222222222332233223322\n",
      "1111111111111111111111111111111111111111111111111111111111111111111221122222212111121113112111222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.297983\n",
      "Iteration 10: accuracy 0.9615416666666666\n",
      "After pruning: [784, 50, 95, 1]\n",
      "11111111111111121122112222222222222222222323223222\n",
      "11111111111111111111111111111111111111111111111111111111111111211212212232222222111221221211232\n",
      "-------------------\n",
      "Cost after epoch 0: 0.248819\n",
      "Iteration 11: accuracy 0.9617708333333334\n",
      "After pruning: [784, 46, 87, 1]\n",
      "1111111111111112122211222222222222222222222222\n",
      "111111111111111111111111111111111111111111111111111111111111212112123122222221222213212\n",
      "-------------------\n",
      "Cost after epoch 0: 0.185069\n",
      "Iteration 12: accuracy 0.9624791666666667\n",
      "After pruning: [784, 43, 82, 1]\n",
      "1111111111111112122221222222222222222222332\n",
      "1111111111111111111111111111111111111111111111111111111112212122121123232122222212\n",
      "-------------------\n",
      "Cost after epoch 0: 0.231589\n",
      "Iteration 13: accuracy 0.9618125\n",
      "After pruning: [784, 39, 76, 1]\n",
      "111111111111122222222222222222222232232\n",
      "1111111111111111111111111111111111111111121121222121111122222221221221222222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.221241\n",
      "Iteration 14: accuracy 0.9620625\n",
      "After pruning: [784, 38, 76, 1]\n",
      "11111111111112222222222222222222333223\n",
      "1111111111111111111111111111111111211111111112121111111121111111211122121211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.197854\n",
      "Iteration 15: accuracy 0.9624583333333333\n",
      "After pruning: [784, 33, 68, 1]\n",
      "111111111111122222222222222222222\n",
      "11111111111111111111111111111111122111111212222221221122222121233222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.166857\n",
      "Iteration 16: accuracy 0.9635833333333333\n",
      "After pruning: [784, 32, 66, 1]\n",
      "11111111111112222222222222222233\n",
      "111111111111111111111111111111111221112112122222222221322221312323\n",
      "-------------------\n",
      "Cost after epoch 0: 0.199584\n",
      "Iteration 17: accuracy 0.9589375\n",
      "After pruning: [784, 29, 61, 1]\n",
      "11111111111112222222222222222\n",
      "1111111111111111111111112111111112221122122322222222122211223\n",
      "-------------------\n",
      "Cost after epoch 0: 0.169829\n",
      "Iteration 18: accuracy 0.960625\n",
      "After pruning: [784, 29, 57, 1]\n",
      "11111111111122222222222222323\n",
      "111111111111111111111111211111111232122212222223221223213\n",
      "-------------------\n",
      "Cost after epoch 0: 0.100055\n",
      "Iteration 19: accuracy 0.9636666666666667\n",
      "After pruning: [784, 26, 50, 1]\n",
      "11111111111122222222222332\n",
      "11111111111111111111111121112111222122213222212221\n",
      "-------------------\n",
      "Cost after epoch 0: 0.165010\n",
      "Iteration 20: accuracy 0.9649791666666667\n",
      "After pruning: [784, 25, 50, 1]\n",
      "1111111111112222222222233\n",
      "11111111111111111111111111111111221122212111111311\n",
      "-------------------\n",
      "Cost after epoch 0: 0.100156\n",
      "Iteration 21: accuracy 0.9649583333333334\n",
      "After pruning: [784, 24, 50, 1]\n",
      "111111121111222222222233\n",
      "11111111111111111111111121112111211112211211211111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.157268\n",
      "Iteration 22: accuracy 0.965125\n",
      "After pruning: [784, 22, 43, 1]\n",
      "1111111211112222222222\n",
      "1111111111111111111111112121221222122132222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.163722\n",
      "Iteration 23: accuracy 0.96425\n",
      "After pruning: [784, 22, 42, 1]\n",
      "1111111211112222222322\n",
      "111111111111111111111111212122122312313222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.128692\n",
      "Iteration 24: accuracy 0.9637916666666667\n",
      "After pruning: [784, 22, 39, 1]\n",
      "1111111211112222223322\n",
      "111111111111111111111111212122123121222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.090578\n",
      "Iteration 25: accuracy 0.9659375\n",
      "After pruning: [784, 20, 36, 1]\n",
      "11111112111122222323\n",
      "111111111111111111111111212132211222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.094035\n",
      "Iteration 26: accuracy 0.9651666666666666\n",
      "After pruning: [784, 19, 36, 1]\n",
      "1111111211112222233\n",
      "111111111111111111111111212122112223\n",
      "-------------------\n",
      "Cost after epoch 0: 0.118801\n",
      "Iteration 27: accuracy 0.9642916666666667\n",
      "After pruning: [784, 17, 36, 1]\n",
      "11111112111122232\n",
      "111111111111111111111112312121133233\n",
      "-------------------\n",
      "Cost after epoch 0: 0.086873\n",
      "Iteration 28: accuracy 0.9648125\n",
      "After pruning: [784, 17, 34, 1]\n",
      "11111112111122232\n",
      "1111111111111111111211121212113323\n",
      "-------------------\n",
      "Cost after epoch 0: 0.137771\n",
      "Iteration 29: accuracy 0.9657291666666666\n",
      "After pruning: [784, 16, 32, 1]\n",
      "1111111211112223\n",
      "11111111111111111112111212121132\n",
      "-------------------\n",
      "Cost after epoch 0: 0.079041\n",
      "Iteration 30: accuracy 0.9667708333333334\n",
      "After pruning: [784, 16, 31, 1]\n",
      "1111111211112223\n",
      "1111111111111121112211121312112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.135890\n",
      "Iteration 31: accuracy 0.9664166666666667\n",
      "After pruning: [784, 15, 29, 1]\n",
      "111111121111222\n",
      "11111111111111211123111221112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.081995\n",
      "Iteration 32: accuracy 0.9665\n",
      "After pruning: [784, 16, 29, 1]\n",
      "1111111211112223\n",
      "11111111111111111123111121112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.090942\n",
      "Iteration 33: accuracy 0.9679791666666666\n",
      "After pruning: [784, 16, 29, 1]\n",
      "1111111211112333\n",
      "11111111111111111111111121111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.105991\n",
      "Iteration 34: accuracy 0.9678333333333333\n",
      "After pruning: [784, 16, 29, 1]\n",
      "1111111221112333\n",
      "11111111111111211121111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.081745\n",
      "Iteration 35: accuracy 0.9670416666666667\n",
      "After pruning: [784, 15, 29, 1]\n",
      "111111122111233\n",
      "11111111111111111111111111112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.112311\n",
      "Iteration 36: accuracy 0.9645833333333333\n",
      "After pruning: [784, 14, 27, 1]\n",
      "11111112211123\n",
      "111111111111112111211122111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.073907\n",
      "Iteration 37: accuracy 0.96725\n",
      "After pruning: [784, 13, 27, 1]\n",
      "1111111221112\n",
      "111111111111112111211222111\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.138713\n",
      "Iteration 38: accuracy 0.9671458333333334\n",
      "After pruning: [784, 13, 27, 1]\n",
      "1111111221112\n",
      "111111111111112111211232111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.084949\n",
      "Iteration 39: accuracy 0.9668958333333333\n",
      "After pruning: [784, 13, 26, 1]\n",
      "1111111221112\n",
      "11111111111111211121122111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.057834\n",
      "Iteration 40: accuracy 0.9668125\n",
      "After pruning: [784, 14, 26, 1]\n",
      "11111112211123\n",
      "11111111111111111121111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.083832\n",
      "Iteration 41: accuracy 0.9679166666666666\n",
      "After pruning: [784, 14, 26, 1]\n",
      "11111112211123\n",
      "11111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.093256\n",
      "Iteration 42: accuracy 0.969\n",
      "After pruning: [784, 14, 26, 1]\n",
      "11111112211133\n",
      "11111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.114440\n",
      "Iteration 43: accuracy 0.9676458333333333\n",
      "After pruning: [784, 13, 25, 1]\n",
      "1111111221113\n",
      "1111111111111121112112111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.098946\n",
      "Iteration 44: accuracy 0.9684375\n",
      "After pruning: [784, 15, 26, 1]\n",
      "111111122111333\n",
      "11111111111111111111111113\n",
      "-------------------\n",
      "Cost after epoch 0: 0.066577\n",
      "Iteration 45: accuracy 0.9687083333333333\n",
      "After pruning: [784, 12, 25, 1]\n",
      "111111122111\n",
      "1111111111111122113112111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.157640\n",
      "Iteration 46: accuracy 0.9661875\n",
      "After pruning: [784, 12, 24, 1]\n",
      "111112222111\n",
      "111121111111112211112111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.028113\n",
      "Iteration 47: accuracy 0.9680416666666667\n",
      "After pruning: [784, 14, 24, 1]\n",
      "11111222211133\n",
      "111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.165491\n",
      "Iteration 48: accuracy 0.9680625\n",
      "After pruning: [784, 13, 24, 1]\n",
      "1111122221113\n",
      "111111111111112111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.193294\n",
      "Iteration 49: accuracy 0.9674791666666667\n",
      "After pruning: [784, 14, 24, 1]\n",
      "11111222211133\n",
      "111111111111112111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.059514\n",
      "Iteration 50: accuracy 0.9695833333333334\n",
      "After pruning: [784, 12, 25, 1]\n",
      "111112222111\n",
      "1111211111111132111131213\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [784, 100, 100, 1]\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters = train_dynamic_model(X_train_fm, y_train_fm, parameters, learning_rate=0.02, l1_term=0.0015, n_iterations=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 3.889684\n",
      "Iteration 1: accuracy 0.9512291666666667\n",
      "After pruning: [784, 100, 100, 1]\n",
      "1111111111111111111111111111111111111111111111111121122111112122112122222222122222212212222222222222\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 1.627600\n",
      "Iteration 2: accuracy 0.9519166666666666\n",
      "After pruning: [784, 76, 100, 1]\n",
      "1111111111111111111111111211112222211222222222122222222222222222223233333233\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111121221111121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.802006\n",
      "Iteration 3: accuracy 0.9526666666666667\n",
      "After pruning: [784, 54, 93, 1]\n",
      "111111111111111111111212122221222222222222222222233243\n",
      "111111111111111111111111111111111111111111111111211111111111111122211211112111222222222222222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.474940\n",
      "Iteration 4: accuracy 0.953125\n",
      "After pruning: [784, 37, 75, 1]\n",
      "1111111111111112211222121222212222223\n",
      "111111111111111111111111111111111112111111211211211122222322211212221112222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.326965\n",
      "Iteration 5: accuracy 0.9539583333333334\n",
      "After pruning: [784, 30, 63, 1]\n",
      "111111111112212222222212132232\n",
      "111111111111111111111111111111211112111111212121122322222122122\n",
      "-------------------\n",
      "Cost after epoch 0: 0.252439\n",
      "Iteration 6: accuracy 0.95525\n",
      "After pruning: [784, 26, 52, 1]\n",
      "11111111111221222222222212\n",
      "1111111111111111211111111111112211122112111122213213\n",
      "-------------------\n",
      "Cost after epoch 0: 0.206059\n",
      "Iteration 7: accuracy 0.9562291666666667\n",
      "After pruning: [784, 24, 45, 1]\n",
      "111111112112212222222213\n",
      "111111111111111121111111111212221222121211211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.169230\n",
      "Iteration 8: accuracy 0.9568958333333333\n",
      "After pruning: [784, 22, 42, 1]\n",
      "1111112121122122222322\n",
      "111111111111111221211122211212221222121112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.155130\n",
      "Iteration 9: accuracy 0.9577291666666666\n",
      "After pruning: [784, 20, 37, 1]\n",
      "11111121211222232322\n",
      "1111111111111112212211221121212211112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.134617\n",
      "Iteration 10: accuracy 0.9581041666666666\n",
      "After pruning: [784, 17, 33, 1]\n",
      "11111121212222232\n",
      "111111111111112221222122111112123\n",
      "-------------------\n",
      "Cost after epoch 0: 0.122964\n",
      "Iteration 11: accuracy 0.95825\n",
      "After pruning: [784, 16, 31, 1]\n",
      "1111112121222242\n",
      "1111111111111122132222311111212\n",
      "-------------------\n",
      "Cost after epoch 0: 0.116394\n",
      "Iteration 12: accuracy 0.9584375\n",
      "After pruning: [784, 14, 27, 1]\n",
      "11111121222324\n",
      "111111111111112212221212212\n",
      "-------------------\n",
      "Cost after epoch 0: 0.104057\n",
      "Iteration 13: accuracy 0.9587291666666666\n",
      "After pruning: [784, 13, 25, 1]\n",
      "1111112122224\n",
      "1111111111121121222221221\n",
      "-------------------\n",
      "Cost after epoch 0: 0.097429\n",
      "Iteration 14: accuracy 0.9585416666666666\n",
      "After pruning: [784, 13, 25, 1]\n",
      "1111122122224\n",
      "1111111111121122222212213\n",
      "-------------------\n",
      "Cost after epoch 0: 0.095734\n",
      "Iteration 15: accuracy 0.9591875\n",
      "After pruning: [784, 12, 22, 1]\n",
      "111112212223\n",
      "1111111111121122221221\n",
      "-------------------\n",
      "Cost after epoch 0: 0.089550\n",
      "Iteration 16: accuracy 0.9593541666666666\n",
      "After pruning: [784, 11, 22, 1]\n",
      "11111221222\n",
      "1111112111121123212313\n",
      "-------------------\n",
      "Cost after epoch 0: 0.089423\n",
      "Iteration 17: accuracy 0.9592916666666667\n",
      "After pruning: [784, 11, 22, 1]\n",
      "11121221322\n",
      "1111112111121122123133\n",
      "-------------------\n",
      "Cost after epoch 0: 0.088346\n",
      "Iteration 18: accuracy 0.9590833333333333\n",
      "After pruning: [784, 11, 23, 1]\n",
      "11121221223\n",
      "11111111111111121131133\n",
      "-------------------\n",
      "Cost after epoch 0: 0.091527\n",
      "Iteration 19: accuracy 0.9581041666666666\n",
      "After pruning: [784, 11, 23, 1]\n",
      "11121221234\n",
      "11111121111111011121111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.095832\n",
      "Iteration 20: accuracy 0.9597083333333334\n",
      "After pruning: [784, 10, 24, 1]\n",
      "1112122123\n",
      "111111111111111311311223\n",
      "-------------------\n",
      "Cost after epoch 0: 0.096875\n",
      "Iteration 21: accuracy 0.9597916666666667\n",
      "After pruning: [784, 10, 24, 1]\n",
      "1112122133\n",
      "111111111111111312113233\n",
      "-------------------\n",
      "Cost after epoch 0: 0.095601\n",
      "Iteration 22: accuracy 0.959875\n",
      "After pruning: [784, 8, 20, 1]\n",
      "11121221\n",
      "11111121131123121333\n",
      "-------------------\n",
      "Cost after epoch 0: 0.083218\n",
      "Iteration 23: accuracy 0.9599791666666667\n",
      "After pruning: [784, 8, 16, 1]\n",
      "11121221\n",
      "1111112111121213\n",
      "-------------------\n",
      "Cost after epoch 0: 0.077523\n",
      "Iteration 24: accuracy 0.9601041666666666\n",
      "After pruning: [784, 8, 16, 1]\n",
      "11122222\n",
      "1111112111121213\n",
      "-------------------\n",
      "Cost after epoch 0: 0.077586\n",
      "Iteration 25: accuracy 0.9603541666666666\n",
      "After pruning: [784, 9, 17, 1]\n",
      "111222223\n",
      "11111111111112133\n",
      "-------------------\n",
      "Cost after epoch 0: 0.080079\n",
      "Iteration 26: accuracy 0.9594166666666667\n",
      "After pruning: [784, 9, 17, 1]\n",
      "111222323\n",
      "11111111111112133\n",
      "-------------------\n",
      "Cost after epoch 0: 0.080504\n",
      "Iteration 27: accuracy 0.9596666666666667\n",
      "After pruning: [784, 9, 17, 1]\n",
      "111222323\n",
      "11111111111112133\n",
      "-------------------\n",
      "Cost after epoch 0: 0.081464\n",
      "Iteration 28: accuracy 0.9598125\n",
      "After pruning: [784, 7, 16, 1]\n",
      "1112222\n",
      "1111112111121213\n",
      "-------------------\n",
      "Cost after epoch 0: 0.077146\n",
      "Iteration 29: accuracy 0.9599583333333334\n",
      "After pruning: [784, 7, 17, 1]\n",
      "1112232\n",
      "11111121111212133\n",
      "-------------------\n",
      "Cost after epoch 0: 0.082096\n",
      "Iteration 30: accuracy 0.9607083333333334\n",
      "After pruning: [784, 7, 18, 1]\n",
      "1112232\n",
      "111111211112121333\n",
      "-------------------\n",
      "Cost after epoch 0: 0.084197\n",
      "Iteration 31: accuracy 0.9606875\n",
      "After pruning: [784, 6, 17, 1]\n",
      "111222\n",
      "11112121111212133\n",
      "-------------------\n",
      "Cost after epoch 0: 0.082931\n",
      "Iteration 32: accuracy 0.9605\n",
      "After pruning: [784, 6, 17, 1]\n",
      "111222\n",
      "11112121111312133\n",
      "-------------------\n",
      "Cost after epoch 0: 0.085055\n",
      "Iteration 33: accuracy 0.9610416666666667\n",
      "After pruning: [784, 6, 16, 1]\n",
      "111222\n",
      "1111212111131213\n",
      "-------------------\n",
      "Cost after epoch 0: 0.083128\n",
      "Iteration 34: accuracy 0.961\n",
      "After pruning: [784, 6, 18, 1]\n",
      "111222\n",
      "111121211123121333\n",
      "-------------------\n",
      "Cost after epoch 0: 0.084608\n",
      "Iteration 35: accuracy 0.960875\n",
      "After pruning: [784, 6, 19, 1]\n",
      "111222\n",
      "1111212111231213323\n",
      "-------------------\n",
      "Cost after epoch 0: 0.088152\n",
      "Iteration 36: accuracy 0.9604166666666667\n",
      "After pruning: [784, 6, 18, 1]\n",
      "111222\n",
      "111121211123121333\n",
      "-------------------\n",
      "Cost after epoch 0: 0.089633\n",
      "Iteration 37: accuracy 0.9613958333333333\n",
      "After pruning: [784, 6, 18, 1]\n",
      "111223\n",
      "111121211223121333\n",
      "-------------------\n",
      "Cost after epoch 0: 0.087504\n",
      "Iteration 38: accuracy 0.9610416666666667\n",
      "After pruning: [784, 5, 19, 1]\n",
      "11122\n",
      "1111212112231213333\n",
      "-------------------\n",
      "Cost after epoch 0: 0.093239\n",
      "Iteration 39: accuracy 0.9615208333333334\n",
      "After pruning: [784, 5, 19, 1]\n",
      "11122\n",
      "1111213112231213333\n",
      "-------------------\n",
      "Cost after epoch 0: 0.093071\n",
      "Iteration 40: accuracy 0.9615416666666666\n",
      "After pruning: [784, 7, 20, 1]\n",
      "1112233\n",
      "11111111110111011113\n",
      "-------------------\n",
      "Cost after epoch 0: 0.103190\n",
      "Iteration 41: accuracy 0.9612708333333333\n",
      "After pruning: [784, 6, 20, 1]\n",
      "111223\n",
      "11111111110113131133\n",
      "-------------------\n",
      "Cost after epoch 0: 0.099128\n",
      "Iteration 42: accuracy 0.9612708333333333\n",
      "After pruning: [784, 5, 17, 1]\n",
      "11122\n",
      "11112111223131333\n",
      "-------------------\n",
      "Cost after epoch 0: 0.091790\n",
      "Iteration 43: accuracy 0.9614375\n",
      "After pruning: [784, 6, 18, 1]\n",
      "111223\n",
      "111111111211111123\n",
      "-------------------\n",
      "Cost after epoch 0: 0.093476\n",
      "Iteration 44: accuracy 0.9611041666666666\n",
      "After pruning: [784, 8, 18, 1]\n",
      "11123343\n",
      "111111111111111011\n",
      "-------------------\n",
      "Cost after epoch 0: 0.090802\n",
      "Iteration 45: accuracy 0.9587083333333334\n",
      "After pruning: [784, 7, 18, 1]\n",
      "1112343\n",
      "111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.097377\n",
      "Iteration 46: accuracy 0.961\n",
      "After pruning: [784, 5, 19, 1]\n",
      "11123\n",
      "1111111111211111113\n",
      "-------------------\n",
      "Cost after epoch 0: 0.098868\n",
      "Iteration 47: accuracy 0.9610208333333333\n",
      "After pruning: [784, 5, 19, 1]\n",
      "11123\n",
      "1111111111211111113\n",
      "-------------------\n",
      "Cost after epoch 0: 0.097848\n",
      "Iteration 48: accuracy 0.96125\n",
      "After pruning: [784, 5, 18, 1]\n",
      "11133\n",
      "111111111131111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.098293\n",
      "Iteration 49: accuracy 0.9611041666666666\n",
      "After pruning: [784, 7, 18, 1]\n",
      "1113333\n",
      "111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.102561\n",
      "Iteration 50: accuracy 0.9612708333333333\n",
      "After pruning: [784, 9, 18, 1]\n",
      "111333333\n",
      "111111111111111111\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [784, 100, 100, 1]\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters = train_dynamic_model(X_train_fm, y_train_fm, parameters, learning_rate=0.02, l1_term=0.005, n_iterations=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 3.997040\n",
      "Iteration 1: accuracy 0.9535208333333334\n",
      "After pruning: [784, 100, 100, 1]\n",
      "1111111111111111111111111111111111111111111111211121211122222221212122212222111211222222222222222122\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 1.741875\n",
      "Iteration 2: accuracy 0.9538541666666667\n",
      "After pruning: [784, 77, 100, 1]\n",
      "11111111111111111111111111121221122212222222222222222222222333222222332222222\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111112111111111111111111111211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.920258\n",
      "Iteration 3: accuracy 0.9539583333333334\n",
      "After pruning: [784, 49, 95, 1]\n",
      "1111111111111111111121222212222222222222222222223\n",
      "11111111111111111111111111111111111111111111111111211111111221212211212122232321122222222222222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.491789\n",
      "Iteration 4: accuracy 0.9560208333333333\n",
      "After pruning: [784, 38, 72, 1]\n",
      "11111111111121112122222222222222223323\n",
      "111111111111111111111111111111111111111111111121112222122122222222222222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.367203\n",
      "Iteration 5: accuracy 0.9572083333333333\n",
      "After pruning: [784, 32, 56, 1]\n",
      "11111111111221212222222222232232\n",
      "11111111111111111111111111111111111221211112113121212123\n",
      "-------------------\n",
      "Cost after epoch 0: 0.363140\n",
      "Iteration 6: accuracy 0.9578333333333333\n",
      "After pruning: [784, 28, 50, 1]\n",
      "1111111111122221222222223244\n",
      "11111111111111111111111211112121111221222221113221\n",
      "-------------------\n",
      "Cost after epoch 0: 0.299671\n",
      "Iteration 7: accuracy 0.9553958333333333\n",
      "After pruning: [784, 24, 44, 1]\n",
      "111111111122222122222344\n",
      "11111111111111111212111221222221111212211122\n",
      "-------------------\n",
      "Cost after epoch 0: 0.349826\n",
      "Iteration 8: accuracy 0.95575\n",
      "After pruning: [784, 21, 38, 1]\n",
      "111111121122222222444\n",
      "11111111111111111211112212222111211112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.216933\n",
      "Iteration 9: accuracy 0.9584791666666667\n",
      "After pruning: [784, 20, 38, 1]\n",
      "11111122212222223244\n",
      "11111111111111111211212213232111211112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.245899\n",
      "Iteration 10: accuracy 0.9548958333333334\n",
      "After pruning: [784, 18, 31, 1]\n",
      "111111222122222244\n",
      "1111111111112111122121311121121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.205749\n",
      "Iteration 11: accuracy 0.9587916666666667\n",
      "After pruning: [784, 17, 29, 1]\n",
      "11111122212223254\n",
      "11111111111121111222111121121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.246565\n",
      "Iteration 12: accuracy 0.9599166666666666\n",
      "After pruning: [784, 14, 29, 1]\n",
      "11111122212324\n",
      "11111111111131113222121121221\n",
      "-------------------\n",
      "Cost after epoch 0: 0.131066\n",
      "Iteration 13: accuracy 0.9566875\n",
      "After pruning: [784, 13, 29, 1]\n",
      "1111112221243\n",
      "11111111111111111112111121211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.137873\n",
      "Iteration 14: accuracy 0.9591458333333334\n",
      "After pruning: [784, 14, 29, 1]\n",
      "11111122212423\n",
      "11111111111111111112111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.105285\n",
      "Iteration 15: accuracy 0.9602291666666667\n",
      "After pruning: [784, 13, 29, 1]\n",
      "1111112221242\n",
      "11111111111111111122111121211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.184331\n",
      "Iteration 16: accuracy 0.9602291666666667\n",
      "After pruning: [784, 13, 30, 1]\n",
      "1111112221342\n",
      "111111111111111111221111312113\n",
      "-------------------\n",
      "Cost after epoch 0: 0.123175\n",
      "Iteration 17: accuracy 0.958875\n",
      "After pruning: [784, 13, 30, 1]\n",
      "1111112221423\n",
      "111111111112111111211111112111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.141312\n",
      "Iteration 18: accuracy 0.961125\n",
      "After pruning: [784, 13, 30, 1]\n",
      "1111112321233\n",
      "111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.130704\n",
      "Iteration 19: accuracy 0.9616875\n",
      "After pruning: [784, 11, 30, 1]\n",
      "11111123123\n",
      "111111111111111111211121111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.163707\n",
      "Iteration 20: accuracy 0.9606041666666667\n",
      "After pruning: [784, 10, 29, 1]\n",
      "1111112123\n",
      "11111111111211111211111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.112384\n",
      "Iteration 21: accuracy 0.9608125\n",
      "After pruning: [784, 9, 27, 1]\n",
      "111111213\n",
      "111111211112111112132113113\n",
      "-------------------\n",
      "Cost after epoch 0: 0.206010\n",
      "Iteration 22: accuracy 0.9594375\n",
      "After pruning: [784, 10, 27, 1]\n",
      "1112113133\n",
      "111111111111111112112111112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.134454\n",
      "Iteration 23: accuracy 0.9614375\n",
      "After pruning: [784, 9, 27, 1]\n",
      "111211133\n",
      "111111111111111111112111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.153552\n",
      "Iteration 24: accuracy 0.9618541666666667\n",
      "After pruning: [784, 8, 24, 1]\n",
      "11121113\n",
      "111111211112111111113113\n",
      "-------------------\n",
      "Cost after epoch 0: 0.126563\n",
      "Iteration 25: accuracy 0.9618333333333333\n",
      "After pruning: [784, 9, 24, 1]\n",
      "111211133\n",
      "111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.172094\n",
      "Iteration 26: accuracy 0.9573333333333334\n",
      "After pruning: [784, 9, 25, 1]\n",
      "111211133\n",
      "1111111111111121111111113\n",
      "-------------------\n",
      "Cost after epoch 0: 0.114442\n",
      "Iteration 27: accuracy 0.9595\n",
      "After pruning: [784, 10, 25, 1]\n",
      "1112111444\n",
      "1111111111111102111111211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.121555\n",
      "Iteration 28: accuracy 0.9616041666666667\n",
      "After pruning: [784, 10, 25, 1]\n",
      "1112111334\n",
      "1111111111111102111111211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.138256\n",
      "Iteration 29: accuracy 0.9564375\n",
      "After pruning: [784, 9, 25, 1]\n",
      "111211133\n",
      "1111111111111121111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.106283\n",
      "Iteration 30: accuracy 0.9608125\n",
      "After pruning: [784, 9, 25, 1]\n",
      "111211143\n",
      "1111111101111111221111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.187333\n",
      "Iteration 31: accuracy 0.9617291666666666\n",
      "After pruning: [784, 9, 25, 1]\n",
      "111211133\n",
      "1111111101111111211111121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.173735\n",
      "Iteration 32: accuracy 0.9605416666666666\n",
      "After pruning: [784, 8, 25, 1]\n",
      "11121113\n",
      "1111111111111121211111121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.233853\n",
      "Iteration 33: accuracy 0.961625\n",
      "After pruning: [784, 7, 18, 1]\n",
      "1112111\n",
      "111111113313211333\n",
      "-------------------\n",
      "Cost after epoch 0: 0.093739\n",
      "Iteration 34: accuracy 0.9620625\n",
      "After pruning: [784, 7, 16, 1]\n",
      "1112111\n",
      "1111111133121133\n",
      "-------------------\n",
      "Cost after epoch 0: 0.199175\n",
      "Iteration 35: accuracy 0.9610833333333333\n",
      "After pruning: [784, 7, 15, 1]\n",
      "1112111\n",
      "111111113121133\n",
      "-------------------\n",
      "Cost after epoch 0: 0.044429\n",
      "Iteration 36: accuracy 0.9615625\n",
      "After pruning: [784, 7, 15, 1]\n",
      "1112111\n",
      "111111113121133\n",
      "-------------------\n",
      "Cost after epoch 0: 0.070933\n",
      "Iteration 37: accuracy 0.9625208333333334\n",
      "After pruning: [784, 7, 14, 1]\n",
      "1112111\n",
      "11111111121133\n",
      "-------------------\n",
      "Cost after epoch 0: 0.124756\n",
      "Iteration 38: accuracy 0.9614583333333333\n",
      "After pruning: [784, 8, 14, 1]\n",
      "11121114\n",
      "11111111121111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.161522\n",
      "Iteration 39: accuracy 0.9621041666666666\n",
      "After pruning: [784, 8, 14, 1]\n",
      "11121113\n",
      "11111111121111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.173238\n",
      "Iteration 40: accuracy 0.9577083333333334\n",
      "After pruning: [784, 8, 15, 1]\n",
      "11121113\n",
      "111111111211113\n",
      "-------------------\n",
      "Cost after epoch 0: 0.143798\n",
      "Iteration 41: accuracy 0.9623125\n",
      "After pruning: [784, 7, 13, 1]\n",
      "1122111\n",
      "1111111112113\n",
      "-------------------\n",
      "Cost after epoch 0: 0.095426\n",
      "Iteration 42: accuracy 0.9630833333333333\n",
      "After pruning: [784, 9, 13, 1]\n",
      "112211133\n",
      "1111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.057426\n",
      "Iteration 43: accuracy 0.9615\n",
      "After pruning: [784, 7, 13, 1]\n",
      "1122111\n",
      "1111111112113\n",
      "-------------------\n",
      "Cost after epoch 0: 0.179099\n",
      "Iteration 44: accuracy 0.9613333333333334\n",
      "After pruning: [784, 8, 13, 1]\n",
      "11221113\n",
      "1111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.085387\n",
      "Iteration 45: accuracy 0.9627291666666666\n",
      "After pruning: [784, 8, 14, 1]\n",
      "11221113\n",
      "11111111111113\n",
      "-------------------\n",
      "Cost after epoch 0: 0.144870\n",
      "Iteration 46: accuracy 0.9598125\n",
      "After pruning: [784, 7, 14, 1]\n",
      "1122111\n",
      "11211111131133\n",
      "-------------------\n",
      "Cost after epoch 0: 0.096959\n",
      "Iteration 47: accuracy 0.9629791666666667\n",
      "After pruning: [784, 7, 13, 1]\n",
      "1123111\n",
      "1121111113113\n",
      "-------------------\n",
      "Cost after epoch 0: 0.140689\n",
      "Iteration 48: accuracy 0.96225\n",
      "After pruning: [784, 8, 13, 1]\n",
      "11231113\n",
      "1111111111011\n",
      "-------------------\n",
      "Cost after epoch 0: 0.134937\n",
      "Iteration 49: accuracy 0.961125\n",
      "After pruning: [784, 8, 13, 1]\n",
      "11231113\n",
      "1120111113111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.042659\n",
      "Iteration 50: accuracy 0.9626875\n",
      "After pruning: [784, 6, 13, 1]\n",
      "112111\n",
      "1120111113113\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [784, 100, 100, 1]\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters = train_dynamic_model(X_train_fm, y_train_fm, parameters, learning_rate=0.02, l1_term=0.005, n_iterations=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.548506\n",
      "Iteration 1: accuracy 0.9555\n",
      "After pruning: [784, 102, 101, 1]\n",
      "111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111153\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111113\n",
      "-------------------\n",
      "Cost after epoch 0: 1.444902\n",
      "Iteration 2: accuracy 0.9568333333333333\n",
      "After pruning: [784, 102, 100, 1]\n",
      "111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111144\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 1.209555\n",
      "Iteration 3: accuracy 0.9586875\n",
      "After pruning: [784, 102, 100, 1]\n",
      "111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111144\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.998654\n",
      "Iteration 4: accuracy 0.9606875\n",
      "After pruning: [784, 102, 100, 1]\n",
      "111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111154\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.845197\n",
      "Iteration 5: accuracy 0.9614791666666667\n",
      "After pruning: [784, 102, 100, 1]\n",
      "111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111121255\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.773021\n",
      "Iteration 6: accuracy 0.9613125\n",
      "After pruning: [784, 101, 100, 1]\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111121111111111111221111111112124\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.759693\n",
      "Iteration 7: accuracy 0.9611875\n",
      "After pruning: [784, 101, 100, 1]\n",
      "11111111111111111111111111111111111111111111111111111111111112112111112221211112221112221111211212224\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.772567\n",
      "Iteration 8: accuracy 0.9616458333333333\n",
      "After pruning: [784, 100, 100, 1]\n",
      "1111111111111111111111111111111111111111111111111111111111111211212122222121112222111222112121222222\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.575477\n",
      "Iteration 9: accuracy 0.9610833333333333\n",
      "After pruning: [784, 100, 100, 1]\n",
      "1111111111111111111111111111111111111111111121111111111111111211212122222222122222122222212122222222\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.566539\n",
      "Iteration 10: accuracy 0.9580208333333333\n",
      "After pruning: [784, 100, 100, 1]\n",
      "1111111111111111111111111111111111111111111121111111112211121211212122222222222222222222212122222222\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.469618\n",
      "Iteration 11: accuracy 0.9604583333333333\n",
      "After pruning: [784, 100, 100, 1]\n",
      "1111111111111111111111111111111111111111111121111111112211122211222222222222222222222222222122222222\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.462082\n",
      "Iteration 12: accuracy 0.9604375\n",
      "After pruning: [784, 100, 100, 1]\n",
      "1111111111111111111111111111111111111111111222221111122211122222222222222222222222222222222222222222\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.437213\n",
      "Iteration 13: accuracy 0.9629166666666666\n",
      "After pruning: [784, 100, 100, 1]\n",
      "1111111111111111111111111111111111112111111222222121122211122222222222222222222222222222222222222223\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.385738\n",
      "Iteration 14: accuracy 0.9629583333333334\n",
      "After pruning: [784, 98, 100, 1]\n",
      "11111111111111111111111111111111111121111112222221212222121222222222222222222222222222222222322222\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.327105\n",
      "Iteration 15: accuracy 0.957625\n",
      "After pruning: [784, 97, 100, 1]\n",
      "1111111111111111111111111111111111112121111222222122222212122222222222222222222222222223222222323\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.339652\n",
      "Iteration 16: accuracy 0.9642708333333333\n",
      "After pruning: [784, 94, 100, 1]\n",
      "1111111111111111111111111111111122122221211222222222222212222222222222222222222222222332222222\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.292346\n",
      "Iteration 17: accuracy 0.9635\n",
      "After pruning: [784, 90, 100, 1]\n",
      "111111111111111111111111111111112212222121122222222222221222222222222222223222333222432232\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.296394\n",
      "Iteration 18: accuracy 0.9650833333333333\n",
      "After pruning: [784, 85, 100, 1]\n",
      "1111111111111111111111111111111122122221221222222222222212222222222222223232222225222\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.288087\n",
      "Iteration 19: accuracy 0.9612708333333333\n",
      "After pruning: [784, 83, 100, 1]\n",
      "11111111111111111111111111111111221222212212222222222222222222223232232223222334223\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.264328\n",
      "Iteration 20: accuracy 0.9617083333333334\n",
      "After pruning: [784, 77, 100, 1]\n",
      "11111111111111111111111111111112221222212212222222222222222222222233333333532\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.299252\n",
      "Iteration 21: accuracy 0.9652916666666667\n",
      "After pruning: [784, 68, 100, 1]\n",
      "11111111111111111111112111111112221222212212222222222222222222222243\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.165900\n",
      "Iteration 22: accuracy 0.9657708333333334\n",
      "After pruning: [784, 67, 100, 1]\n",
      "1111111111111111111112211121221222122221221222222222222222222222225\n",
      "1111111111111111111111111111111111111111111111111111111111111111111121111111111111111111111111112212\n",
      "-------------------\n",
      "Cost after epoch 0: 0.229313\n",
      "Iteration 23: accuracy 0.9645833333333333\n",
      "After pruning: [784, 67, 100, 1]\n",
      "1111111111111111111112211121221222122221221222222222222322232322225\n",
      "1111111111111111111111111111111111111111111111111111111111111111111121111111111111111111111111122212\n",
      "-------------------\n",
      "Cost after epoch 0: 0.134820\n",
      "Iteration 24: accuracy 0.9639583333333334\n",
      "After pruning: [784, 66, 100, 1]\n",
      "111111111111111111112221112122122212222122122222222222232222323325\n",
      "1111111111111111111111111111111111111111111111111111111111111111111121111111111111111111111111122212\n",
      "-------------------\n",
      "Cost after epoch 0: 0.204725\n",
      "Iteration 25: accuracy 0.9654375\n",
      "After pruning: [784, 63, 100, 1]\n",
      "111111111111111111112221112122122212222122122222222222222222325\n",
      "1111111111111111111111111111111111111111111111111111111111111111111121111111121111211111211111122212\n",
      "-------------------\n",
      "Cost after epoch 0: 0.285653\n",
      "Iteration 26: accuracy 0.9664166666666667\n",
      "After pruning: [784, 61, 100, 1]\n",
      "1111111111111111111122211121221222122221221222222222222222233\n",
      "1111111111111111111111111111111111111111111111111111121111111111111121111121121112212111211111122212\n",
      "-------------------\n",
      "Cost after epoch 0: 0.167455\n",
      "Iteration 27: accuracy 0.9663958333333333\n",
      "After pruning: [784, 60, 100, 1]\n",
      "111111111111111111112221112122122212222122122222222223322223\n",
      "1111111111111111111111111111111111111111111111111111121111111111111121111121121112212211212111122212\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.184426\n",
      "Iteration 28: accuracy 0.9668541666666667\n",
      "After pruning: [784, 59, 100, 1]\n",
      "11111111111111111111222111212222221222212212222322223323234\n",
      "1111111111111111111111111111111111111111111111111111121111111111111121121121121212212211212211122213\n",
      "-------------------\n",
      "Cost after epoch 0: 0.129934\n",
      "Iteration 29: accuracy 0.9666666666666667\n",
      "After pruning: [784, 56, 99, 1]\n",
      "11111111111111121111222111212222221222212212223332322234\n",
      "111111111111111111111111111111111111111111111111111112111111111111112112122113121221221121221112222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.146950\n",
      "Iteration 30: accuracy 0.9669375\n",
      "After pruning: [784, 53, 95, 1]\n",
      "11111111111111121111222111212222221222212223223232234\n",
      "11111111111111111111111111111111111111111111111111111211111111111121221212211121221221121221112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.126319\n",
      "Iteration 31: accuracy 0.9672916666666667\n",
      "After pruning: [784, 50, 95, 1]\n",
      "11111111111111121111222111212222221222212223322224\n",
      "11111111111111111111111111111111111111111111111111111211111111111121222212211122221222121221112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.124566\n",
      "Iteration 32: accuracy 0.9663958333333333\n",
      "After pruning: [784, 49, 95, 1]\n",
      "1111111111111112111122221121222222122222222323224\n",
      "11111111111111111111111111111111111211111111111111111211112111111121222212211222221222121221112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.083380\n",
      "Iteration 33: accuracy 0.9673125\n",
      "After pruning: [784, 48, 95, 1]\n",
      "111111111111111211112222112122222212222222233325\n",
      "11111111111111111111111111111111111211111111111121111211112111211121222223311222221222121221112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.078564\n",
      "Iteration 34: accuracy 0.966\n",
      "After pruning: [784, 47, 93, 1]\n",
      "11111111111111121111222211212222221232222223334\n",
      "111111111111111111111111111111111112111111111111211112111122112111213222211222222322131231112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.160721\n",
      "Iteration 35: accuracy 0.9667291666666666\n",
      "After pruning: [784, 45, 89, 1]\n",
      "111111111111111211112222112122222222322232234\n",
      "11111111111111111111111111111111111211111112111121111221112211211121222212222232222121112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.108280\n",
      "Iteration 36: accuracy 0.9675416666666666\n",
      "After pruning: [784, 43, 88, 1]\n",
      "1111111111111112111122221121222222222323224\n",
      "1111111111111111111111111111111111121111111211122111122211221121112122221222232322131112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.274169\n",
      "Iteration 37: accuracy 0.9644375\n",
      "After pruning: [784, 43, 87, 1]\n",
      "1111111111111112111122221121222222223322243\n",
      "111111111111111111111111111111111111111111211111111111121112111111212111221222121111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.128272\n",
      "Iteration 38: accuracy 0.9672083333333333\n",
      "After pruning: [784, 41, 85, 1]\n",
      "11111111111111121111222211212222222232324\n",
      "1111111111111111111111111111111111121111112221122111122221221121122222222223222211112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.184697\n",
      "Iteration 39: accuracy 0.965625\n",
      "After pruning: [784, 41, 85, 1]\n",
      "11111111111111121111222211212222222323243\n",
      "1111111111111111111111111111111111111111112211111111112221121121111211112121212211111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.113036\n",
      "Iteration 40: accuracy 0.9693125\n",
      "After pruning: [784, 39, 84, 1]\n",
      "111111111111111211112222112122223223224\n",
      "111111111111111111111111111111111112111111222112221113222122112113222222222223221113\n",
      "-------------------\n",
      "Cost after epoch 0: 0.162481\n",
      "Iteration 41: accuracy 0.968875\n",
      "After pruning: [784, 38, 82, 1]\n",
      "11111111111111121111222211212222322224\n",
      "1111111111111111111111111111111111121111112221122211132221222121132322222232221113\n",
      "-------------------\n",
      "Cost after epoch 0: 0.159111\n",
      "Iteration 42: accuracy 0.9691458333333334\n",
      "After pruning: [784, 38, 78, 1]\n",
      "11111111111111121111222211212222322225\n",
      "111111111111111111111111111111111112111111222112221112321222121132322223222111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.149173\n",
      "Iteration 43: accuracy 0.9688333333333333\n",
      "After pruning: [784, 37, 74, 1]\n",
      "1111111111111112112122221121222222225\n",
      "11111111111111111111111111111111111211111122211222111221222122122222222112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.089059\n",
      "Iteration 44: accuracy 0.9695833333333334\n",
      "After pruning: [784, 37, 74, 1]\n",
      "1111111111111112112122221122222222225\n",
      "11111111111111111111111111111111111211111122211222111221332122122222322112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.151702\n",
      "Iteration 45: accuracy 0.9686875\n",
      "After pruning: [784, 36, 73, 1]\n",
      "111111111111111211212222122222222222\n",
      "1111111111111111111111111111111111121111112221122211222133313212222222112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.103298\n",
      "Iteration 46: accuracy 0.9665416666666666\n",
      "After pruning: [784, 36, 70, 1]\n",
      "111111111111111211212222122222222222\n",
      "1111111111111111111111111111111111121111112221122211222113212222322112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.109619\n",
      "Iteration 47: accuracy 0.9687916666666667\n",
      "After pruning: [784, 36, 68, 1]\n",
      "111111111111111212212222122222222222\n",
      "11111111111111111111111111112111111211111122211222112221221223222112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.193683\n",
      "Iteration 48: accuracy 0.9700833333333333\n",
      "After pruning: [784, 36, 67, 1]\n",
      "111111111111111212212222122223222222\n",
      "1111111111111111111111111111211111121111112221122221222122132222112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.100646\n",
      "Iteration 49: accuracy 0.9707708333333334\n",
      "After pruning: [784, 36, 66, 1]\n",
      "111111111111111212212222122223222222\n",
      "111111111111111111111111111121111112111111222112322123212213322112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.142791\n",
      "Iteration 50: accuracy 0.9692708333333333\n",
      "After pruning: [784, 37, 66, 1]\n",
      "1111111111111112122122221222332222223\n",
      "111111111111111111111111111111111221111111212112111111112211311111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.122754\n",
      "Iteration 51: accuracy 0.9696458333333333\n",
      "After pruning: [784, 35, 61, 1]\n",
      "11111111111111121221222212223222222\n",
      "1111111111111111111111111111211112221111112222122212212122112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.067607\n",
      "Iteration 52: accuracy 0.9696458333333333\n",
      "After pruning: [784, 35, 61, 1]\n",
      "11111111111111122221222212223222222\n",
      "1111111111111111111111111111211112221111112222132212312122112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.101067\n",
      "Iteration 53: accuracy 0.9694583333333333\n",
      "After pruning: [784, 34, 61, 1]\n",
      "1111111111111112222122221222223232\n",
      "1111111111111111111112111111211112221111113322132212322133112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.150368\n",
      "Iteration 54: accuracy 0.9687916666666667\n",
      "After pruning: [784, 34, 57, 1]\n",
      "1111111111111112222122221222323232\n",
      "111111111111111111111211111121111223111111322122122213112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.094696\n",
      "Iteration 55: accuracy 0.9701458333333334\n",
      "After pruning: [784, 33, 56, 1]\n",
      "111111111111111222212222122232322\n",
      "11111111111111111111121111112111122311111132122122211123\n",
      "-------------------\n",
      "Cost after epoch 0: 0.086825\n",
      "Iteration 56: accuracy 0.9710625\n",
      "After pruning: [784, 33, 56, 1]\n",
      "111111111111111222212232123223223\n",
      "11111111111111111111121111111111112111111111121121111121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.176218\n",
      "Iteration 57: accuracy 0.9696458333333333\n",
      "After pruning: [784, 31, 52, 1]\n",
      "1111111111111112222122321232222\n",
      "1111111111111111111112111111211112211111121321221112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.090030\n",
      "Iteration 58: accuracy 0.9710416666666667\n",
      "After pruning: [784, 31, 51, 1]\n",
      "1111111111111112222122321232222\n",
      "111111111111111111111211111121111221111122121221112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.093509\n",
      "Iteration 59: accuracy 0.9683958333333333\n",
      "After pruning: [784, 31, 51, 1]\n",
      "1111111111111112222122212322223\n",
      "111111111111111111111211111111111111111111111111112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.120831\n",
      "Iteration 60: accuracy 0.9711458333333334\n",
      "After pruning: [784, 30, 51, 1]\n",
      "111111111111111222212321222223\n",
      "111111111111111111111111111111111111111121111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.059602\n",
      "Iteration 61: accuracy 0.9716041666666667\n",
      "After pruning: [784, 30, 51, 1]\n",
      "111111111111111222212321222223\n",
      "111111111111111111111111111121111111111111111211111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.059791\n",
      "Iteration 62: accuracy 0.9708958333333333\n",
      "After pruning: [784, 29, 50, 1]\n",
      "11111111111111122221232122223\n",
      "11111111111111111111121111112111122111112212122111\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.127532\n",
      "Iteration 63: accuracy 0.969875\n",
      "After pruning: [784, 29, 50, 1]\n",
      "11111111111111122221332122223\n",
      "11111111111111111111121211122111122111112212122111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.075054\n",
      "Iteration 64: accuracy 0.9717083333333333\n",
      "After pruning: [784, 28, 50, 1]\n",
      "1111111111111122222132122223\n",
      "11111111111111111111121211122111122111112212132111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.068479\n",
      "Iteration 65: accuracy 0.9721041666666667\n",
      "After pruning: [784, 29, 50, 1]\n",
      "11111111111111222221321222233\n",
      "11111111111111111111121111111111111111112111121111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.092675\n",
      "Iteration 66: accuracy 0.9682708333333333\n",
      "After pruning: [784, 29, 50, 1]\n",
      "11111111111111222221331222233\n",
      "11111111111111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.068077\n",
      "Iteration 67: accuracy 0.9689583333333334\n",
      "After pruning: [784, 26, 48, 1]\n",
      "11111111111111222221312222\n",
      "111111111111111111112212111221111221111222113111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.106054\n",
      "Iteration 68: accuracy 0.9723958333333333\n",
      "After pruning: [784, 26, 48, 1]\n",
      "11111111111111222221312222\n",
      "111111111111111111112212111221111221111223113111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.085424\n",
      "Iteration 69: accuracy 0.9669583333333334\n",
      "After pruning: [784, 26, 48, 1]\n",
      "11111111111111222221312222\n",
      "111111111111111111112212111221111221111223113111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.036758\n",
      "Iteration 70: accuracy 0.9690416666666667\n",
      "After pruning: [784, 25, 46, 1]\n",
      "1111111111111122222112233\n",
      "1111111111111111111122121112211112211112211111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.151628\n",
      "Iteration 71: accuracy 0.9695833333333334\n",
      "After pruning: [784, 25, 46, 1]\n",
      "1111111111111122222112233\n",
      "1111111111111111211122121112211112211112211111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.063126\n",
      "Iteration 72: accuracy 0.9702291666666667\n",
      "After pruning: [784, 24, 46, 1]\n",
      "111111111111112222211223\n",
      "1111111111111111211122121112212112211112212111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.079960\n",
      "Iteration 73: accuracy 0.9717708333333334\n",
      "After pruning: [784, 25, 46, 1]\n",
      "1111111111111122222112233\n",
      "1111111111111111111111121111111111111111112111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.150038\n",
      "Iteration 74: accuracy 0.9700833333333333\n",
      "After pruning: [784, 24, 46, 1]\n",
      "111111111111112222211223\n",
      "1111111111111111211122121112212213311112212111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.055655\n",
      "Iteration 75: accuracy 0.9721458333333334\n",
      "After pruning: [784, 25, 46, 1]\n",
      "1111111111111112222112233\n",
      "1111111111111111111111111112111111211111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.069083\n",
      "Iteration 76: accuracy 0.972625\n",
      "After pruning: [784, 24, 46, 1]\n",
      "111111111111111222211223\n",
      "1111111111111111111112121112111111121111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.055803\n",
      "Iteration 77: accuracy 0.9725208333333333\n",
      "After pruning: [784, 23, 43, 1]\n",
      "11111111111111122221122\n",
      "1111111111111121211122221112212212111231121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.110924\n",
      "Iteration 78: accuracy 0.9721666666666666\n",
      "After pruning: [784, 23, 43, 1]\n",
      "11111111111112122221123\n",
      "1111111111111121211122221112312212112231121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.073548\n",
      "Iteration 79: accuracy 0.9720416666666667\n",
      "After pruning: [784, 24, 43, 1]\n",
      "111111111111121222211233\n",
      "1111111111111111211111121112112111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.124421\n",
      "Iteration 80: accuracy 0.9710416666666667\n",
      "After pruning: [784, 23, 42, 1]\n",
      "11111111111112132221123\n",
      "111111111111112121112222111231321211221121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.103530\n",
      "Iteration 81: accuracy 0.9720208333333333\n",
      "After pruning: [784, 24, 42, 1]\n",
      "111111121111121322211233\n",
      "111111111111111111112122111111111111121111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.145442\n",
      "Iteration 82: accuracy 0.9711875\n",
      "After pruning: [784, 23, 42, 1]\n",
      "11111112111112132221123\n",
      "111111111111112121112222112213212112211213\n",
      "-------------------\n",
      "Cost after epoch 0: 0.125370\n",
      "Iteration 83: accuracy 0.9715625\n",
      "After pruning: [784, 22, 41, 1]\n",
      "1111111211111213222112\n",
      "11111111111111212111222211221421211221121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.111119\n",
      "Iteration 84: accuracy 0.9733333333333334\n",
      "After pruning: [784, 22, 40, 1]\n",
      "1111111211111213222112\n",
      "1111111111111121211122221122121211221121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.116647\n",
      "Iteration 85: accuracy 0.9711458333333334\n",
      "After pruning: [784, 22, 40, 1]\n",
      "1111111211111212221123\n",
      "1111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.070967\n",
      "Iteration 86: accuracy 0.9715625\n",
      "After pruning: [784, 22, 40, 1]\n",
      "1111111211111212221123\n",
      "1111111111111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.059906\n",
      "Iteration 87: accuracy 0.9726041666666667\n",
      "After pruning: [784, 21, 40, 1]\n",
      "111111121111121222112\n",
      "1111111111111121211122221122121211231121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.125127\n",
      "Iteration 88: accuracy 0.9716041666666667\n",
      "After pruning: [784, 23, 40, 1]\n",
      "11111112111112122211233\n",
      "1111111111111111111111111111111111121111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.045146\n",
      "Iteration 89: accuracy 0.970625\n",
      "After pruning: [784, 22, 40, 1]\n",
      "1111111211111212221124\n",
      "1111111111111111111111111111112111111121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.062639\n",
      "Iteration 90: accuracy 0.9709375\n",
      "After pruning: [784, 21, 39, 1]\n",
      "111111121111121222112\n",
      "111111111111112121112222112222221122121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.113653\n",
      "Iteration 91: accuracy 0.9705\n",
      "After pruning: [784, 22, 39, 1]\n",
      "1111111211111212221123\n",
      "111111111111111121111122112221011111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.060191\n",
      "Iteration 92: accuracy 0.9737916666666667\n",
      "After pruning: [784, 22, 39, 1]\n",
      "1111111211111212221123\n",
      "111111111111112111111111112212121111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.090748\n",
      "Iteration 93: accuracy 0.9737708333333334\n",
      "After pruning: [784, 21, 39, 1]\n",
      "111111121111121223112\n",
      "111111111111112121112322112322221122121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.117582\n",
      "Iteration 94: accuracy 0.9725625\n",
      "After pruning: [784, 21, 37, 1]\n",
      "111111121111121223112\n",
      "1111111111111121211222211222221122121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.103426\n",
      "Iteration 95: accuracy 0.9708541666666667\n",
      "After pruning: [784, 21, 37, 1]\n",
      "111111121111121223112\n",
      "1111111111111121221222211222221222121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.042387\n",
      "Iteration 96: accuracy 0.9725833333333334\n",
      "After pruning: [784, 21, 37, 1]\n",
      "111111121111121233112\n",
      "1111111111111121221222311222221222121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.115490\n",
      "Iteration 97: accuracy 0.9728333333333333\n",
      "After pruning: [784, 20, 37, 1]\n",
      "11111112111112123112\n",
      "1111111111111121221222311222221222121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.064024\n",
      "Iteration 98: accuracy 0.9742291666666667\n",
      "After pruning: [784, 20, 37, 1]\n",
      "11111112111112123112\n",
      "1111111111111121221222321222221222121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.098426\n",
      "Iteration 99: accuracy 0.9730833333333333\n",
      "After pruning: [784, 22, 37, 1]\n",
      "1111111211111212311333\n",
      "1111111111111111111111111111111121111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.094343\n",
      "Iteration 100: accuracy 0.9737708333333334\n",
      "After pruning: [784, 19, 36, 1]\n",
      "1111112211111212113\n",
      "111111111111112122122221223221222121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.087068\n",
      "Iteration 101: accuracy 0.9732083333333333\n",
      "After pruning: [784, 19, 35, 1]\n",
      "1111112211111213113\n",
      "11111111111111212212222122221222121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.047923\n",
      "Iteration 102: accuracy 0.9717708333333334\n",
      "After pruning: [784, 19, 35, 1]\n",
      "1111112211111213113\n",
      "11111111111111212212222122221222122\n",
      "-------------------\n",
      "Cost after epoch 0: 0.035715\n",
      "Iteration 103: accuracy 0.9746666666666667\n",
      "After pruning: [784, 20, 35, 1]\n",
      "11111122111112131133\n",
      "11111111111111211111111111111121122\n",
      "-------------------\n",
      "Cost after epoch 0: 0.117012\n",
      "Iteration 104: accuracy 0.9751875\n",
      "After pruning: [784, 19, 35, 1]\n",
      "1111112211111213113\n",
      "11111111111111212212322122221222122\n",
      "-------------------\n",
      "Cost after epoch 0: 0.077368\n",
      "Iteration 105: accuracy 0.9748125\n",
      "After pruning: [784, 19, 35, 1]\n",
      "1111112211111213113\n",
      "11111111111111212212322122221222122\n",
      "-------------------\n",
      "Cost after epoch 0: 0.145639\n",
      "Iteration 106: accuracy 0.9752916666666667\n",
      "After pruning: [784, 18, 35, 1]\n",
      "111111221111121113\n",
      "11111111111111111112221111111111121\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.078747\n",
      "Iteration 107: accuracy 0.9730833333333333\n",
      "After pruning: [784, 17, 34, 1]\n",
      "11111122111112111\n",
      "1111111111111121221222122221222122\n",
      "-------------------\n",
      "Cost after epoch 0: 0.085097\n",
      "Iteration 108: accuracy 0.972625\n",
      "After pruning: [784, 17, 34, 1]\n",
      "11111122111112111\n",
      "1111111111111121221222122221222122\n",
      "-------------------\n",
      "Cost after epoch 0: 0.049690\n",
      "Iteration 109: accuracy 0.9743958333333333\n",
      "After pruning: [784, 17, 34, 1]\n",
      "11111122111112111\n",
      "1111111111111121221222122221222122\n",
      "-------------------\n",
      "Cost after epoch 0: 0.077461\n",
      "Iteration 110: accuracy 0.9733541666666666\n",
      "After pruning: [784, 17, 34, 1]\n",
      "11111112111112111\n",
      "1111111111111121221222122221232122\n",
      "-------------------\n",
      "Cost after epoch 0: 0.078281\n",
      "Iteration 111: accuracy 0.9755208333333333\n",
      "After pruning: [784, 18, 34, 1]\n",
      "111111121111121113\n",
      "1111111111111111121211111111121111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.105142\n",
      "Iteration 112: accuracy 0.9749166666666667\n",
      "After pruning: [784, 17, 34, 1]\n",
      "11111112111112111\n",
      "1111111111111121221232122231232132\n",
      "-------------------\n",
      "Cost after epoch 0: 0.043260\n",
      "Iteration 113: accuracy 0.9756041666666667\n",
      "After pruning: [784, 18, 34, 1]\n",
      "111111121111121113\n",
      "1111111111111111111221111111122112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.124224\n",
      "Iteration 114: accuracy 0.9702708333333333\n",
      "After pruning: [784, 19, 34, 1]\n",
      "1111111211111211133\n",
      "1111111111111111111111111121111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.131614\n",
      "Iteration 115: accuracy 0.9698333333333333\n",
      "After pruning: [784, 17, 31, 1]\n",
      "11111112111112111\n",
      "1111111111111121221221322322212\n",
      "-------------------\n",
      "Cost after epoch 0: 0.103423\n",
      "Iteration 116: accuracy 0.9744791666666667\n",
      "After pruning: [784, 18, 31, 1]\n",
      "111111121111121113\n",
      "1111111111111121111111212111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.103241\n",
      "Iteration 117: accuracy 0.9715416666666666\n",
      "After pruning: [784, 18, 31, 1]\n",
      "111111121111121113\n",
      "1111111111111111111121121211111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.058033\n",
      "Iteration 118: accuracy 0.9761458333333334\n",
      "After pruning: [784, 18, 31, 1]\n",
      "111111121111121113\n",
      "1111111111111111111121121211111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.046408\n",
      "Iteration 119: accuracy 0.9719375\n",
      "After pruning: [784, 20, 31, 1]\n",
      "11111112111112111333\n",
      "1111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.072122\n",
      "Iteration 120: accuracy 0.9759791666666666\n",
      "After pruning: [784, 19, 31, 1]\n",
      "1111111211111211133\n",
      "1111111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.077165\n",
      "Iteration 121: accuracy 0.9659375\n",
      "After pruning: [784, 17, 28, 1]\n",
      "11111112111112111\n",
      "1111111111111121321221222222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.038475\n",
      "Iteration 122: accuracy 0.9718125\n",
      "After pruning: [784, 17, 28, 1]\n",
      "11111112111112111\n",
      "1111111111111121321221222322\n",
      "-------------------\n",
      "Cost after epoch 0: 0.101916\n",
      "Iteration 123: accuracy 0.9753333333333334\n",
      "After pruning: [784, 17, 27, 1]\n",
      "11111112111112111\n",
      "111111111111112121221222322\n",
      "-------------------\n",
      "Cost after epoch 0: 0.152906\n",
      "Iteration 124: accuracy 0.9657708333333334\n",
      "After pruning: [784, 18, 27, 1]\n",
      "111111121111121113\n",
      "111111111111111111111121121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.089998\n",
      "Iteration 125: accuracy 0.9704375\n",
      "After pruning: [784, 18, 27, 1]\n",
      "111111121111121113\n",
      "111111111111121111121211111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.108246\n",
      "Iteration 126: accuracy 0.9760416666666667\n",
      "After pruning: [784, 17, 27, 1]\n",
      "11111112111112111\n",
      "111111111111122121221222322\n",
      "-------------------\n",
      "Cost after epoch 0: 0.082532\n",
      "Iteration 127: accuracy 0.9758541666666667\n",
      "After pruning: [784, 18, 27, 1]\n",
      "111111121111121113\n",
      "111111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.088285\n",
      "Iteration 128: accuracy 0.9750208333333333\n",
      "After pruning: [784, 17, 26, 1]\n",
      "11111112111112111\n",
      "11111111111112212122122222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.065928\n",
      "Iteration 129: accuracy 0.9710833333333333\n",
      "After pruning: [784, 17, 26, 1]\n",
      "11111112111112111\n",
      "11111111111112212122122222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.142467\n",
      "Iteration 130: accuracy 0.9765833333333334\n",
      "After pruning: [784, 17, 26, 1]\n",
      "11111112111112111\n",
      "11111111111112212122122222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.067425\n",
      "Iteration 131: accuracy 0.9696041666666667\n",
      "After pruning: [784, 17, 26, 1]\n",
      "11111112111112111\n",
      "11111111111112212122122222\n",
      "-------------------\n",
      "Cost after epoch 0: 0.072084\n",
      "Iteration 132: accuracy 0.9768125\n",
      "After pruning: [784, 18, 26, 1]\n",
      "111111121111121113\n",
      "11111111111111211121131211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.079006\n",
      "Iteration 133: accuracy 0.9760833333333333\n",
      "After pruning: [784, 19, 26, 1]\n",
      "1111111211111211133\n",
      "11111111111111211111121111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.181568\n",
      "Iteration 134: accuracy 0.9728333333333333\n",
      "After pruning: [784, 18, 26, 1]\n",
      "111111121111121113\n",
      "11111111111111211111121112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.111656\n",
      "Iteration 135: accuracy 0.9729791666666666\n",
      "After pruning: [784, 18, 26, 1]\n",
      "111111121111121113\n",
      "11111111111111211111121112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.063817\n",
      "Iteration 136: accuracy 0.9752083333333333\n",
      "After pruning: [784, 19, 26, 1]\n",
      "1111111211111211133\n",
      "11111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.106413\n",
      "Iteration 137: accuracy 0.9732083333333333\n",
      "After pruning: [784, 19, 26, 1]\n",
      "1111111211111211133\n",
      "11111111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.104852\n",
      "Iteration 138: accuracy 0.9767291666666666\n",
      "After pruning: [784, 17, 24, 1]\n",
      "11111112111112111\n",
      "111111111111121313212223\n",
      "-------------------\n",
      "Cost after epoch 0: 0.029152\n",
      "Iteration 139: accuracy 0.9750208333333333\n",
      "After pruning: [784, 18, 24, 1]\n",
      "111111121111121113\n",
      "111111111111111111112211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.084645\n",
      "Iteration 140: accuracy 0.9780416666666667\n",
      "After pruning: [784, 18, 24, 1]\n",
      "111111121111121113\n",
      "111111111111121111112111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.066204\n",
      "Iteration 141: accuracy 0.9773333333333334\n",
      "After pruning: [784, 17, 22, 1]\n",
      "11111112111112111\n",
      "1111111111111221212323\n",
      "-------------------\n",
      "Cost after epoch 0: 0.033867\n",
      "Iteration 142: accuracy 0.9780625\n",
      "After pruning: [784, 17, 22, 1]\n",
      "11111112111112111\n",
      "1111111111111221212323\n",
      "-------------------\n",
      "Cost after epoch 0: 0.131358\n",
      "Iteration 143: accuracy 0.9716875\n",
      "After pruning: [784, 17, 21, 1]\n",
      "11111112111113111\n",
      "111111111111122131232\n",
      "-------------------\n",
      "Cost after epoch 0: 0.059717\n",
      "Iteration 144: accuracy 0.9729583333333334\n",
      "After pruning: [784, 17, 21, 1]\n",
      "11111112111113111\n",
      "111111111111122131232\n",
      "-------------------\n",
      "Cost after epoch 0: 0.102878\n",
      "Iteration 145: accuracy 0.9759791666666666\n",
      "After pruning: [784, 18, 21, 1]\n",
      "111111121111131113\n",
      "111111111111112111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.079061\n",
      "Iteration 146: accuracy 0.9776041666666667\n",
      "After pruning: [784, 20, 21, 1]\n",
      "11111112111113111333\n",
      "111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.049368\n",
      "Iteration 147: accuracy 0.976375\n",
      "After pruning: [784, 17, 21, 1]\n",
      "11111112111111113\n",
      "111111111111111121112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.307284\n",
      "Iteration 148: accuracy 0.9785\n",
      "After pruning: [784, 18, 21, 1]\n",
      "111111121111111133\n",
      "111111111111111111112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.117147\n",
      "Iteration 149: accuracy 0.9761666666666666\n",
      "After pruning: [784, 18, 21, 1]\n",
      "111111121111111133\n",
      "111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.035627\n",
      "Iteration 150: accuracy 0.9768333333333333\n",
      "After pruning: [784, 18, 21, 1]\n",
      "111111121111111133\n",
      "111111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.119003\n",
      "Iteration 151: accuracy 0.9766458333333333\n",
      "After pruning: [784, 16, 20, 1]\n",
      "1111111211111111\n",
      "11111111111122211232\n",
      "-------------------\n",
      "Cost after epoch 0: 0.126949\n",
      "Iteration 152: accuracy 0.9755\n",
      "After pruning: [784, 18, 20, 1]\n",
      "111111121111111133\n",
      "10111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.036265\n",
      "Iteration 153: accuracy 0.9784166666666667\n",
      "After pruning: [784, 17, 20, 1]\n",
      "11111112111111113\n",
      "11111111111121111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.055277\n",
      "Iteration 154: accuracy 0.9697083333333333\n",
      "After pruning: [784, 19, 20, 1]\n",
      "1111111211111111333\n",
      "11111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.031185\n",
      "Iteration 155: accuracy 0.9777291666666666\n",
      "After pruning: [784, 18, 20, 1]\n",
      "111111121111111133\n",
      "11111111111111111111\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.089029\n",
      "Iteration 156: accuracy 0.9781875\n",
      "After pruning: [784, 17, 20, 1]\n",
      "11111112111111113\n",
      "11111111111121111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.071238\n",
      "Iteration 157: accuracy 0.9755\n",
      "After pruning: [784, 16, 19, 1]\n",
      "1111111211111111\n",
      "1111111111112221122\n",
      "-------------------\n",
      "Cost after epoch 0: 0.058940\n",
      "Iteration 158: accuracy 0.9780208333333333\n",
      "After pruning: [784, 17, 19, 1]\n",
      "11111112111111113\n",
      "1111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.075128\n",
      "Iteration 159: accuracy 0.9744791666666667\n",
      "After pruning: [784, 18, 19, 1]\n",
      "111111121111111133\n",
      "1111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.107596\n",
      "Iteration 160: accuracy 0.9783125\n",
      "After pruning: [784, 16, 19, 1]\n",
      "1111111211111111\n",
      "1111111111112221122\n",
      "-------------------\n",
      "Cost after epoch 0: 0.038627\n",
      "Iteration 161: accuracy 0.9793541666666666\n",
      "After pruning: [784, 17, 19, 1]\n",
      "11111112111111113\n",
      "1111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.029712\n",
      "Iteration 162: accuracy 0.9783541666666666\n",
      "After pruning: [784, 17, 19, 1]\n",
      "11111112111111113\n",
      "1111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.091198\n",
      "Iteration 163: accuracy 0.974625\n",
      "After pruning: [784, 17, 19, 1]\n",
      "11111112111111113\n",
      "1111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.021569\n",
      "Iteration 164: accuracy 0.9740208333333333\n",
      "After pruning: [784, 16, 19, 1]\n",
      "1111111211111111\n",
      "1111111111112221122\n",
      "-------------------\n",
      "Cost after epoch 0: 0.093966\n",
      "Iteration 165: accuracy 0.9781041666666667\n",
      "After pruning: [784, 17, 19, 1]\n",
      "11111112111111113\n",
      "1111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.080366\n",
      "Iteration 166: accuracy 0.9792708333333333\n",
      "After pruning: [784, 16, 19, 1]\n",
      "1111111211111111\n",
      "1111111111112221122\n",
      "-------------------\n",
      "Cost after epoch 0: 0.047604\n",
      "Iteration 167: accuracy 0.9774583333333333\n",
      "After pruning: [784, 16, 19, 1]\n",
      "1111111211111111\n",
      "1111111111112221122\n",
      "-------------------\n",
      "Cost after epoch 0: 0.058171\n",
      "Iteration 168: accuracy 0.9788541666666667\n",
      "After pruning: [784, 16, 19, 1]\n",
      "1111111211111111\n",
      "1111111111112221122\n",
      "-------------------\n",
      "Cost after epoch 0: 0.039867\n",
      "Iteration 169: accuracy 0.979625\n",
      "After pruning: [784, 16, 19, 1]\n",
      "1111111211111111\n",
      "1111111111112221122\n",
      "-------------------\n",
      "Cost after epoch 0: 0.114263\n",
      "Iteration 170: accuracy 0.9773333333333334\n",
      "After pruning: [784, 16, 19, 1]\n",
      "1111111211111111\n",
      "1111111111112221132\n",
      "-------------------\n",
      "Cost after epoch 0: 0.101324\n",
      "Iteration 171: accuracy 0.9800833333333333\n",
      "After pruning: [784, 17, 19, 1]\n",
      "11111112111111113\n",
      "1111111111111221111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.099081\n",
      "Iteration 172: accuracy 0.9799583333333334\n",
      "After pruning: [784, 18, 19, 1]\n",
      "111111121111111133\n",
      "1111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.029563\n",
      "Iteration 173: accuracy 0.9807708333333334\n",
      "After pruning: [784, 16, 19, 1]\n",
      "1111111211111111\n",
      "1111111111112221132\n",
      "-------------------\n",
      "Cost after epoch 0: 0.155657\n",
      "Iteration 174: accuracy 0.9724166666666667\n",
      "After pruning: [784, 16, 19, 1]\n",
      "1111111211111111\n",
      "1111111111112221132\n",
      "-------------------\n",
      "Cost after epoch 0: 0.042810\n",
      "Iteration 175: accuracy 0.972125\n",
      "After pruning: [784, 16, 19, 1]\n",
      "1111111211111111\n",
      "1111111111112221133\n",
      "-------------------\n",
      "Cost after epoch 0: 0.058147\n",
      "Iteration 176: accuracy 0.9725625\n",
      "After pruning: [784, 18, 19, 1]\n",
      "111111121111111133\n",
      "1111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.154406\n",
      "Iteration 177: accuracy 0.9785\n",
      "After pruning: [784, 17, 19, 1]\n",
      "11111112111111113\n",
      "1111111111112111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.119053\n",
      "Iteration 178: accuracy 0.9773333333333334\n",
      "After pruning: [784, 17, 19, 1]\n",
      "11111112111111113\n",
      "1111111111112111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.047737\n",
      "Iteration 179: accuracy 0.9775208333333333\n",
      "After pruning: [784, 19, 19, 1]\n",
      "1111111211111111334\n",
      "1111111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.036876\n",
      "Iteration 180: accuracy 0.9760208333333333\n",
      "After pruning: [784, 17, 19, 1]\n",
      "11111112111111113\n",
      "1111111111112221131\n",
      "-------------------\n",
      "Cost after epoch 0: 0.098801\n",
      "Iteration 181: accuracy 0.9805416666666666\n",
      "After pruning: [784, 16, 17, 1]\n",
      "1111111211111211\n",
      "11111111111122211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.063255\n",
      "Iteration 182: accuracy 0.9787291666666667\n",
      "After pruning: [784, 17, 17, 1]\n",
      "11111112111111113\n",
      "11111111111121111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.148502\n",
      "Iteration 183: accuracy 0.9799583333333334\n",
      "After pruning: [784, 17, 17, 1]\n",
      "11111112111111113\n",
      "11111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.038460\n",
      "Iteration 184: accuracy 0.9786041666666667\n",
      "After pruning: [784, 18, 17, 1]\n",
      "111111121111121133\n",
      "11111111111111011\n",
      "-------------------\n",
      "Cost after epoch 0: 0.156103\n",
      "Iteration 185: accuracy 0.9777083333333333\n",
      "After pruning: [784, 16, 17, 1]\n",
      "1111111211111211\n",
      "11111111111123211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.027630\n",
      "Iteration 186: accuracy 0.9783541666666666\n",
      "After pruning: [784, 16, 17, 1]\n",
      "1111111211111211\n",
      "11111111111133211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.037688\n",
      "Iteration 187: accuracy 0.9785416666666666\n",
      "After pruning: [784, 16, 17, 1]\n",
      "1111111211111211\n",
      "11111111111133211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.047996\n",
      "Iteration 188: accuracy 0.9794583333333333\n",
      "After pruning: [784, 17, 17, 1]\n",
      "11111112111111113\n",
      "11111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.204981\n",
      "Iteration 189: accuracy 0.962625\n",
      "After pruning: [784, 16, 16, 1]\n",
      "1111111211111111\n",
      "1111111111113211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.055591\n",
      "Iteration 190: accuracy 0.9790833333333333\n",
      "After pruning: [784, 18, 16, 1]\n",
      "111121131111121133\n",
      "1111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.065731\n",
      "Iteration 191: accuracy 0.9809583333333334\n",
      "After pruning: [784, 18, 16, 1]\n",
      "111121131111121133\n",
      "1111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.080630\n",
      "Iteration 192: accuracy 0.9797291666666667\n",
      "After pruning: [784, 16, 15, 1]\n",
      "1111211311111211\n",
      "111111111121211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.022626\n",
      "Iteration 193: accuracy 0.9809375\n",
      "After pruning: [784, 16, 15, 1]\n",
      "1111211311111211\n",
      "111111111121211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.054846\n",
      "Iteration 194: accuracy 0.9815208333333333\n",
      "After pruning: [784, 16, 15, 1]\n",
      "1111211311111211\n",
      "111111111121211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.071551\n",
      "Iteration 195: accuracy 0.979875\n",
      "After pruning: [784, 16, 15, 1]\n",
      "1111211311111211\n",
      "111111111121211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.073618\n",
      "Iteration 196: accuracy 0.9793541666666666\n",
      "After pruning: [784, 17, 15, 1]\n",
      "11122113111112113\n",
      "111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.043857\n",
      "Iteration 197: accuracy 0.9813333333333333\n",
      "After pruning: [784, 16, 15, 1]\n",
      "1112211311111211\n",
      "111111111121311\n",
      "-------------------\n",
      "Cost after epoch 0: 0.020974\n",
      "Iteration 198: accuracy 0.9762291666666667\n",
      "After pruning: [784, 18, 15, 1]\n",
      "111221131111121134\n",
      "111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.055475\n",
      "Iteration 199: accuracy 0.981125\n",
      "After pruning: [784, 16, 15, 1]\n",
      "1112211311111211\n",
      "111111111121311\n",
      "-------------------\n",
      "Cost after epoch 0: 0.112707\n",
      "Iteration 200: accuracy 0.9773958333333334\n",
      "After pruning: [784, 16, 15, 1]\n",
      "1112211311111211\n",
      "111111111121311\n",
      "-------------------\n",
      "Cost after epoch 0: 0.071305\n",
      "Iteration 201: accuracy 0.9811458333333334\n",
      "After pruning: [784, 16, 15, 1]\n",
      "1112211311111211\n",
      "111111111121311\n",
      "-------------------\n",
      "Cost after epoch 0: 0.044172\n",
      "Iteration 202: accuracy 0.9790416666666667\n",
      "After pruning: [784, 17, 15, 1]\n",
      "11122111111121133\n",
      "111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.156915\n",
      "Iteration 203: accuracy 0.9797291666666667\n",
      "After pruning: [784, 16, 15, 1]\n",
      "1112211111112113\n",
      "111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.059246\n",
      "Iteration 204: accuracy 0.9776041666666667\n",
      "After pruning: [784, 16, 15, 1]\n",
      "1112211111112113\n",
      "111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.049340\n",
      "Iteration 205: accuracy 0.9813541666666666\n",
      "After pruning: [784, 16, 15, 1]\n",
      "1112211111112113\n",
      "111111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.137971\n",
      "Iteration 206: accuracy 0.9782916666666667\n",
      "After pruning: [784, 15, 14, 1]\n",
      "111221111111211\n",
      "11111112112111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.184217\n",
      "Iteration 207: accuracy 0.9805208333333333\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111112111111\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.085906\n",
      "Iteration 208: accuracy 0.9818125\n",
      "After pruning: [784, 15, 14, 1]\n",
      "111221111111211\n",
      "11111112112111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.038527\n",
      "Iteration 209: accuracy 0.9762916666666667\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11110111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.047192\n",
      "Iteration 210: accuracy 0.9824375\n",
      "After pruning: [784, 17, 14, 1]\n",
      "11122111111121133\n",
      "11110111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.039177\n",
      "Iteration 211: accuracy 0.97875\n",
      "After pruning: [784, 17, 14, 1]\n",
      "11122111111121133\n",
      "11110111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.058566\n",
      "Iteration 212: accuracy 0.9741666666666666\n",
      "After pruning: [784, 17, 14, 1]\n",
      "11122111111121133\n",
      "11111112111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.073487\n",
      "Iteration 213: accuracy 0.974375\n",
      "After pruning: [784, 18, 14, 1]\n",
      "111221111111211333\n",
      "11111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.023685\n",
      "Iteration 214: accuracy 0.9781666666666666\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111111112111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.068861\n",
      "Iteration 215: accuracy 0.981\n",
      "After pruning: [784, 17, 14, 1]\n",
      "11122111111121133\n",
      "11111111112111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.058317\n",
      "Iteration 216: accuracy 0.9823333333333333\n",
      "After pruning: [784, 17, 14, 1]\n",
      "11122111111121133\n",
      "11111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.056228\n",
      "Iteration 217: accuracy 0.9799791666666666\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111111111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.031194\n",
      "Iteration 218: accuracy 0.9798333333333333\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111112111111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.041010\n",
      "Iteration 219: accuracy 0.9798958333333333\n",
      "After pruning: [784, 15, 14, 1]\n",
      "111221111111211\n",
      "11111112112111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.051409\n",
      "Iteration 220: accuracy 0.981625\n",
      "After pruning: [784, 18, 14, 1]\n",
      "111221111111211333\n",
      "10111111101111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.148320\n",
      "Iteration 221: accuracy 0.9797291666666667\n",
      "After pruning: [784, 17, 14, 1]\n",
      "11122111111121133\n",
      "11111112101101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.082558\n",
      "Iteration 222: accuracy 0.97875\n",
      "After pruning: [784, 17, 14, 1]\n",
      "11122111111121133\n",
      "11111111101101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.025347\n",
      "Iteration 223: accuracy 0.9789166666666667\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.038514\n",
      "Iteration 224: accuracy 0.9817291666666667\n",
      "After pruning: [784, 17, 14, 1]\n",
      "11122111111121133\n",
      "11111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.036828\n",
      "Iteration 225: accuracy 0.9813125\n",
      "After pruning: [784, 15, 14, 1]\n",
      "111221111111211\n",
      "11111112112101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.034064\n",
      "Iteration 226: accuracy 0.9811666666666666\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.034315\n",
      "Iteration 227: accuracy 0.9815625\n",
      "After pruning: [784, 17, 14, 1]\n",
      "11122111111121133\n",
      "11111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.026636\n",
      "Iteration 228: accuracy 0.9819166666666667\n",
      "After pruning: [784, 18, 14, 1]\n",
      "111221111111211333\n",
      "11111112111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.090935\n",
      "Iteration 229: accuracy 0.9816875\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111111112101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.041667\n",
      "Iteration 230: accuracy 0.9838958333333333\n",
      "After pruning: [784, 17, 14, 1]\n",
      "11122111111121133\n",
      "11111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.023192\n",
      "Iteration 231: accuracy 0.9806875\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.039222\n",
      "Iteration 232: accuracy 0.9822916666666667\n",
      "After pruning: [784, 18, 14, 1]\n",
      "111221111111211333\n",
      "11111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.084430\n",
      "Iteration 233: accuracy 0.9783333333333334\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.047208\n",
      "Iteration 234: accuracy 0.982375\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.076113\n",
      "Iteration 235: accuracy 0.9814166666666667\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111112111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.061900\n",
      "Iteration 236: accuracy 0.9833958333333334\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.049327\n",
      "Iteration 237: accuracy 0.9816666666666667\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111112112101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.018129\n",
      "Iteration 238: accuracy 0.9815\n",
      "After pruning: [784, 18, 14, 1]\n",
      "111221111111211333\n",
      "11111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.030054\n",
      "Iteration 239: accuracy 0.9797708333333334\n",
      "After pruning: [784, 17, 14, 1]\n",
      "11122111111121133\n",
      "11111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.076356\n",
      "Iteration 240: accuracy 0.9802916666666667\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111112111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.100096\n",
      "Iteration 241: accuracy 0.9825\n",
      "After pruning: [784, 17, 14, 1]\n",
      "11122111111121133\n",
      "11111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.212387\n",
      "Iteration 242: accuracy 0.9763125\n",
      "After pruning: [784, 17, 14, 1]\n",
      "11122111111121133\n",
      "11111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.059224\n",
      "Iteration 243: accuracy 0.983625\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.074817\n",
      "Iteration 244: accuracy 0.9826875\n",
      "After pruning: [784, 17, 14, 1]\n",
      "11122111111121133\n",
      "11111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.047417\n",
      "Iteration 245: accuracy 0.982625\n",
      "After pruning: [784, 17, 14, 1]\n",
      "11122111111121133\n",
      "11111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.074135\n",
      "Iteration 246: accuracy 0.9830208333333333\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111111112101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.137554\n",
      "Iteration 247: accuracy 0.9808333333333333\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.029695\n",
      "Iteration 248: accuracy 0.982\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111111112101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.034682\n",
      "Iteration 249: accuracy 0.9821875\n",
      "After pruning: [784, 17, 14, 1]\n",
      "11122111111121133\n",
      "11111111110101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.068781\n",
      "Iteration 250: accuracy 0.9814791666666667\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111111112101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.042623\n",
      "Iteration 251: accuracy 0.9820416666666667\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111112112101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.048463\n",
      "Iteration 252: accuracy 0.9805416666666666\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111112112101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.079031\n",
      "Iteration 253: accuracy 0.9821041666666667\n",
      "After pruning: [784, 17, 14, 1]\n",
      "11122111111121133\n",
      "11111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.047668\n",
      "Iteration 254: accuracy 0.9836458333333333\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111112111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.056382\n",
      "Iteration 255: accuracy 0.9835625\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111112111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.048181\n",
      "Iteration 256: accuracy 0.9799583333333334\n",
      "After pruning: [784, 15, 14, 1]\n",
      "111221111111211\n",
      "11121112112101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.091854\n",
      "Iteration 257: accuracy 0.9807708333333334\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.070862\n",
      "Iteration 258: accuracy 0.9817916666666666\n",
      "After pruning: [784, 17, 14, 1]\n",
      "11122111111121133\n",
      "11111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.041256\n",
      "Iteration 259: accuracy 0.9840416666666667\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.099791\n",
      "Iteration 260: accuracy 0.9799375\n",
      "After pruning: [784, 17, 14, 1]\n",
      "11122111111121133\n",
      "01111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.125267\n",
      "Iteration 261: accuracy 0.9797083333333333\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11121111112101\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.033447\n",
      "Iteration 262: accuracy 0.9829791666666666\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11121111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.108659\n",
      "Iteration 263: accuracy 0.9784166666666667\n",
      "After pruning: [784, 15, 14, 1]\n",
      "111221111111211\n",
      "11121112112101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.075848\n",
      "Iteration 264: accuracy 0.9819583333333334\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111112111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.031857\n",
      "Iteration 265: accuracy 0.9818333333333333\n",
      "After pruning: [784, 15, 14, 1]\n",
      "111221111111211\n",
      "11121112112101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.032999\n",
      "Iteration 266: accuracy 0.9835208333333333\n",
      "After pruning: [784, 15, 14, 1]\n",
      "111221111111211\n",
      "11121112112101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.069070\n",
      "Iteration 267: accuracy 0.9823125\n",
      "After pruning: [784, 17, 14, 1]\n",
      "11122111111121133\n",
      "11111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.056546\n",
      "Iteration 268: accuracy 0.9821041666666667\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.038907\n",
      "Iteration 269: accuracy 0.9849791666666666\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.068792\n",
      "Iteration 270: accuracy 0.9835833333333334\n",
      "After pruning: [784, 18, 14, 1]\n",
      "111221111111211333\n",
      "11111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.039668\n",
      "Iteration 271: accuracy 0.98175\n",
      "After pruning: [784, 17, 14, 1]\n",
      "11122111111121133\n",
      "11111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.024860\n",
      "Iteration 272: accuracy 0.9801458333333334\n",
      "After pruning: [784, 17, 14, 1]\n",
      "11122111111121133\n",
      "11111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.087523\n",
      "Iteration 273: accuracy 0.9840208333333333\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111112111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.040937\n",
      "Iteration 274: accuracy 0.9847291666666667\n",
      "After pruning: [784, 18, 14, 1]\n",
      "111221111111211333\n",
      "11111112101101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.073503\n",
      "Iteration 275: accuracy 0.9841041666666667\n",
      "After pruning: [784, 18, 15, 1]\n",
      "111221111111211333\n",
      "111111111011013\n",
      "-------------------\n",
      "Cost after epoch 0: 0.034612\n",
      "Iteration 276: accuracy 0.9818125\n",
      "After pruning: [784, 19, 15, 1]\n",
      "1112211111112113333\n",
      "111111111011011\n",
      "-------------------\n",
      "Cost after epoch 0: 0.051404\n",
      "Iteration 277: accuracy 0.9828125\n",
      "After pruning: [784, 19, 15, 1]\n",
      "1112211111112113333\n",
      "111111111111011\n",
      "-------------------\n",
      "Cost after epoch 0: 0.039034\n",
      "Iteration 278: accuracy 0.9808541666666667\n",
      "After pruning: [784, 16, 15, 1]\n",
      "1112211111112113\n",
      "111211111121011\n",
      "-------------------\n",
      "Cost after epoch 0: 0.136389\n",
      "Iteration 279: accuracy 0.9837708333333334\n",
      "After pruning: [784, 17, 15, 1]\n",
      "11122111111121133\n",
      "111211111111011\n",
      "-------------------\n",
      "Cost after epoch 0: 0.044941\n",
      "Iteration 280: accuracy 0.984125\n",
      "After pruning: [784, 17, 15, 1]\n",
      "11122111111121133\n",
      "111211111111011\n",
      "-------------------\n",
      "Cost after epoch 0: 0.048358\n",
      "Iteration 281: accuracy 0.9801041666666667\n",
      "After pruning: [784, 16, 15, 1]\n",
      "1112211111112113\n",
      "111111111111011\n",
      "-------------------\n",
      "Cost after epoch 0: 0.050518\n",
      "Iteration 282: accuracy 0.9812083333333333\n",
      "After pruning: [784, 16, 15, 1]\n",
      "1112211111112113\n",
      "111111111111011\n",
      "-------------------\n",
      "Cost after epoch 0: 0.024577\n",
      "Iteration 283: accuracy 0.9785208333333333\n",
      "After pruning: [784, 16, 15, 1]\n",
      "1112211111112113\n",
      "111111111111011\n",
      "-------------------\n",
      "Cost after epoch 0: 0.070978\n",
      "Iteration 284: accuracy 0.9807083333333333\n",
      "After pruning: [784, 16, 15, 1]\n",
      "1112211111112113\n",
      "111111111111011\n",
      "-------------------\n",
      "Cost after epoch 0: 0.023865\n",
      "Iteration 285: accuracy 0.9806041666666667\n",
      "After pruning: [784, 15, 13, 1]\n",
      "111221111111211\n",
      "1112111311101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.063983\n",
      "Iteration 286: accuracy 0.9838125\n",
      "After pruning: [784, 15, 13, 1]\n",
      "111221111111211\n",
      "1112111311101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.070065\n",
      "Iteration 287: accuracy 0.9837708333333334\n",
      "After pruning: [784, 16, 13, 1]\n",
      "1112211111112113\n",
      "1111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.089444\n",
      "Iteration 288: accuracy 0.9834583333333333\n",
      "After pruning: [784, 16, 13, 1]\n",
      "1112211111112113\n",
      "1111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.027433\n",
      "Iteration 289: accuracy 0.9832708333333333\n",
      "After pruning: [784, 18, 13, 1]\n",
      "111221111111211333\n",
      "1111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.031219\n",
      "Iteration 290: accuracy 0.9841041666666667\n",
      "After pruning: [784, 16, 13, 1]\n",
      "1112211111112113\n",
      "1111111311101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.093985\n",
      "Iteration 291: accuracy 0.9801458333333334\n",
      "After pruning: [784, 18, 13, 1]\n",
      "111221111111211333\n",
      "1111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.041041\n",
      "Iteration 292: accuracy 0.9824791666666667\n",
      "After pruning: [784, 18, 13, 1]\n",
      "111221111111211333\n",
      "1111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.033439\n",
      "Iteration 293: accuracy 0.9794583333333333\n",
      "After pruning: [784, 17, 13, 1]\n",
      "11122111111121143\n",
      "1111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.075436\n",
      "Iteration 294: accuracy 0.9809166666666667\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111221111111211\n",
      "111211111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.081788\n",
      "Iteration 295: accuracy 0.9834166666666667\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111221111111211\n",
      "111211111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.093670\n",
      "Iteration 296: accuracy 0.9786875\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112211111112113\n",
      "111111110101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.207139\n",
      "Iteration 297: accuracy 0.9807083333333333\n",
      "After pruning: [784, 18, 14, 1]\n",
      "111221111111211333\n",
      "11111111010133\n",
      "-------------------\n",
      "Cost after epoch 0: 0.079118\n",
      "Iteration 298: accuracy 0.9852083333333334\n",
      "After pruning: [784, 20, 15, 1]\n",
      "11122111111121123333\n",
      "111111110101113\n",
      "-------------------\n",
      "Cost after epoch 0: 0.078070\n",
      "Iteration 299: accuracy 0.9839791666666666\n",
      "After pruning: [784, 18, 15, 1]\n",
      "111221111111211333\n",
      "111111110101111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.090255\n",
      "Iteration 300: accuracy 0.9842291666666667\n",
      "After pruning: [784, 17, 15, 1]\n",
      "11122111111121123\n",
      "111111110101113\n",
      "-------------------\n",
      "Cost after epoch 0: 0.111786\n",
      "Iteration 301: accuracy 0.9839375\n",
      "After pruning: [784, 17, 15, 1]\n",
      "11122111111121133\n",
      "111111110101112\n",
      "-------------------\n",
      "Cost after epoch 0: 0.060070\n",
      "Iteration 302: accuracy 0.9844583333333333\n",
      "After pruning: [784, 17, 15, 1]\n",
      "11122111111121133\n",
      "111111110101111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.068274\n",
      "Iteration 303: accuracy 0.9833125\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111111010132\n",
      "-------------------\n",
      "Cost after epoch 0: 0.028993\n",
      "Iteration 304: accuracy 0.9799375\n",
      "After pruning: [784, 19, 14, 1]\n",
      "1112211111112113343\n",
      "11111111010111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.047880\n",
      "Iteration 305: accuracy 0.9782083333333333\n",
      "After pruning: [784, 18, 14, 1]\n",
      "111221111111211333\n",
      "11111111010111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.025834\n",
      "Iteration 306: accuracy 0.9825\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11111111110111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.063348\n",
      "Iteration 307: accuracy 0.9813958333333334\n",
      "After pruning: [784, 17, 14, 1]\n",
      "11122111111121133\n",
      "11111111110111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.082483\n",
      "Iteration 308: accuracy 0.98275\n",
      "After pruning: [784, 17, 14, 1]\n",
      "11122111111121133\n",
      "11111111110111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.023316\n",
      "Iteration 309: accuracy 0.9820208333333333\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11121111110111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.071460\n",
      "Iteration 310: accuracy 0.9794166666666667\n",
      "After pruning: [784, 18, 14, 1]\n",
      "111221111111211333\n",
      "11111111110111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.030359\n",
      "Iteration 311: accuracy 0.9810833333333333\n",
      "After pruning: [784, 18, 14, 1]\n",
      "111221111111211333\n",
      "11111111110111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.024775\n",
      "Iteration 312: accuracy 0.9838541666666667\n",
      "After pruning: [784, 19, 14, 1]\n",
      "1112211111112113333\n",
      "11111111110111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.045318\n",
      "Iteration 313: accuracy 0.9834791666666667\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11121111110111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.041339\n",
      "Iteration 314: accuracy 0.9851875\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11121111110111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.049757\n",
      "Iteration 315: accuracy 0.9835\n",
      "After pruning: [784, 16, 15, 1]\n",
      "1112211111112113\n",
      "111211111101113\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.040612\n",
      "Iteration 316: accuracy 0.98425\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11121111110111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.051832\n",
      "Iteration 317: accuracy 0.9819791666666666\n",
      "After pruning: [784, 18, 14, 1]\n",
      "111221111111211333\n",
      "11111111110111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.047515\n",
      "Iteration 318: accuracy 0.9847291666666667\n",
      "After pruning: [784, 16, 14, 1]\n",
      "1112211111112113\n",
      "11121111110111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.093113\n",
      "Iteration 319: accuracy 0.9845833333333334\n",
      "After pruning: [784, 18, 14, 1]\n",
      "111221111111211333\n",
      "11111111110111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.133231\n",
      "Iteration 320: accuracy 0.985625\n",
      "After pruning: [784, 18, 14, 1]\n",
      "111221111111211333\n",
      "11111111110111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.044352\n",
      "Iteration 321: accuracy 0.9802083333333333\n",
      "After pruning: [784, 15, 13, 1]\n",
      "111221111111211\n",
      "1112111111013\n",
      "-------------------\n",
      "Cost after epoch 0: 0.059587\n",
      "Iteration 322: accuracy 0.9795\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111221111111211\n",
      "111211111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.069848\n",
      "Iteration 323: accuracy 0.9842916666666667\n",
      "After pruning: [784, 17, 12, 1]\n",
      "11122111111121134\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.054784\n",
      "Iteration 324: accuracy 0.9772291666666667\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111221111111211\n",
      "111211111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.061855\n",
      "Iteration 325: accuracy 0.9834375\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112211111112113\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.064520\n",
      "Iteration 326: accuracy 0.98425\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111221111111211\n",
      "111211111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.034560\n",
      "Iteration 327: accuracy 0.9858541666666667\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111221111111211\n",
      "111211111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.034904\n",
      "Iteration 328: accuracy 0.9856041666666666\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111221111111211\n",
      "111211111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.110538\n",
      "Iteration 329: accuracy 0.985875\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112211111112113\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.070965\n",
      "Iteration 330: accuracy 0.9853958333333334\n",
      "After pruning: [784, 17, 12, 1]\n",
      "11122111111121133\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.058928\n",
      "Iteration 331: accuracy 0.9856041666666666\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111221111111211\n",
      "111211111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.077040\n",
      "Iteration 332: accuracy 0.9859166666666667\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112211111112113\n",
      "111211111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.125641\n",
      "Iteration 333: accuracy 0.9851666666666666\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111221111111211\n",
      "111211111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.057578\n",
      "Iteration 334: accuracy 0.9843125\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111221111111211\n",
      "111211111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.020096\n",
      "Iteration 335: accuracy 0.9845\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111221111111211\n",
      "111211111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.048731\n",
      "Iteration 336: accuracy 0.9866875\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112211111112113\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.048340\n",
      "Iteration 337: accuracy 0.9844583333333333\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112211111112113\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.073612\n",
      "Iteration 338: accuracy 0.9839583333333334\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112211111112113\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.067218\n",
      "Iteration 339: accuracy 0.9852916666666667\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111221111111211\n",
      "111211111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.023454\n",
      "Iteration 340: accuracy 0.9835833333333334\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111221111111311\n",
      "111211111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.019297\n",
      "Iteration 341: accuracy 0.9850833333333333\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112211111113113\n",
      "111211111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.043926\n",
      "Iteration 342: accuracy 0.986375\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112211111113113\n",
      "111211111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.026981\n",
      "Iteration 343: accuracy 0.9851666666666666\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112211111113113\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.084079\n",
      "Iteration 344: accuracy 0.9828541666666667\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112211111113113\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.035206\n",
      "Iteration 345: accuracy 0.9805\n",
      "After pruning: [784, 17, 12, 1]\n",
      "11122111111131133\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.060997\n",
      "Iteration 346: accuracy 0.9856666666666667\n",
      "After pruning: [784, 17, 12, 1]\n",
      "11122111111131133\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.049311\n",
      "Iteration 347: accuracy 0.9857916666666666\n",
      "After pruning: [784, 17, 12, 1]\n",
      "11122111111131133\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.063285\n",
      "Iteration 348: accuracy 0.9844583333333333\n",
      "After pruning: [784, 18, 12, 1]\n",
      "111221111111113333\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.153443\n",
      "Iteration 349: accuracy 0.9849583333333334\n",
      "After pruning: [784, 17, 12, 1]\n",
      "11122111111111333\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.047878\n",
      "Iteration 350: accuracy 0.9834166666666667\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112211111111133\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.062552\n",
      "Iteration 351: accuracy 0.98475\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112211111111133\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.056014\n",
      "Iteration 352: accuracy 0.986\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112211111111133\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.033435\n",
      "Iteration 353: accuracy 0.9851666666666666\n",
      "After pruning: [784, 17, 13, 1]\n",
      "11122111111111333\n",
      "1111111011013\n",
      "-------------------\n",
      "Cost after epoch 0: 0.075009\n",
      "Iteration 354: accuracy 0.9858125\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111221111111113\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.077159\n",
      "Iteration 355: accuracy 0.9825208333333333\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111221111111113\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.053580\n",
      "Iteration 356: accuracy 0.984125\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111221111111113\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.064991\n",
      "Iteration 357: accuracy 0.9844375\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111221111111113\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.032366\n",
      "Iteration 358: accuracy 0.9854791666666667\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111221111111113\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.086889\n",
      "Iteration 359: accuracy 0.980375\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112211111111133\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.039796\n",
      "Iteration 360: accuracy 0.9856666666666667\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111221111111113\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.054945\n",
      "Iteration 361: accuracy 0.9824791666666667\n",
      "After pruning: [784, 17, 12, 1]\n",
      "11122111111111333\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.039326\n",
      "Iteration 362: accuracy 0.9870833333333333\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112211111111133\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.089815\n",
      "Iteration 363: accuracy 0.9849375\n",
      "After pruning: [784, 17, 12, 1]\n",
      "11122111111111333\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.121397\n",
      "Iteration 364: accuracy 0.9843125\n",
      "After pruning: [784, 18, 12, 1]\n",
      "111221111111113333\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.086450\n",
      "Iteration 365: accuracy 0.9831458333333334\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112211111111133\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.040327\n",
      "Iteration 366: accuracy 0.9823125\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112211111111133\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.020193\n",
      "Iteration 367: accuracy 0.9850833333333333\n",
      "After pruning: [784, 17, 12, 1]\n",
      "11122111111111333\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.041857\n",
      "Iteration 368: accuracy 0.982875\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112211111111133\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.044946\n",
      "Iteration 369: accuracy 0.9846875\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111221111111113\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.062238\n",
      "Iteration 370: accuracy 0.985875\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111221111111113\n",
      "111111111101\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.035647\n",
      "Iteration 371: accuracy 0.9866041666666666\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112211111111133\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.046687\n",
      "Iteration 372: accuracy 0.9824791666666667\n",
      "After pruning: [784, 14, 12, 1]\n",
      "11122111111111\n",
      "111211111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.043593\n",
      "Iteration 373: accuracy 0.9841666666666666\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111221111111113\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.048976\n",
      "Iteration 374: accuracy 0.9839166666666667\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111221111111113\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.058953\n",
      "Iteration 375: accuracy 0.9822708333333333\n",
      "After pruning: [784, 17, 12, 1]\n",
      "11122111111111343\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.071950\n",
      "Iteration 376: accuracy 0.9840625\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112211111111133\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.078507\n",
      "Iteration 377: accuracy 0.9847083333333333\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111221111111113\n",
      "111211111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.035011\n",
      "Iteration 378: accuracy 0.9857708333333334\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111221111111113\n",
      "111211111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.082774\n",
      "Iteration 379: accuracy 0.9842708333333333\n",
      "After pruning: [784, 14, 12, 1]\n",
      "11122111111111\n",
      "111211111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.032407\n",
      "Iteration 380: accuracy 0.9839166666666667\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111221111111113\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.050853\n",
      "Iteration 381: accuracy 0.9763958333333334\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112211111111133\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.046526\n",
      "Iteration 382: accuracy 0.986\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111221111111113\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.075694\n",
      "Iteration 383: accuracy 0.9849166666666667\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111221111111113\n",
      "111111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.044353\n",
      "Iteration 384: accuracy 0.9819166666666667\n",
      "After pruning: [784, 17, 12, 1]\n",
      "11122111111111333\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.074712\n",
      "Iteration 385: accuracy 0.981125\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112211111111133\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.028300\n",
      "Iteration 386: accuracy 0.9849166666666667\n",
      "After pruning: [784, 18, 12, 1]\n",
      "111221111111113333\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.048394\n",
      "Iteration 387: accuracy 0.9855833333333334\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112211111111133\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.079341\n",
      "Iteration 388: accuracy 0.9834583333333333\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112311111111133\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.053004\n",
      "Iteration 389: accuracy 0.9828541666666667\n",
      "After pruning: [784, 14, 12, 1]\n",
      "11123111111111\n",
      "011211111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.041681\n",
      "Iteration 390: accuracy 0.9834375\n",
      "After pruning: [784, 14, 12, 1]\n",
      "11123111111111\n",
      "011211111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.046657\n",
      "Iteration 391: accuracy 0.9829791666666666\n",
      "After pruning: [784, 17, 12, 1]\n",
      "11123111111111333\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.038095\n",
      "Iteration 392: accuracy 0.9820833333333333\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111231111111113\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.039459\n",
      "Iteration 393: accuracy 0.9840625\n",
      "After pruning: [784, 14, 12, 1]\n",
      "11123111111111\n",
      "011211111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.028655\n",
      "Iteration 394: accuracy 0.9862708333333333\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112311111111133\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.032357\n",
      "Iteration 395: accuracy 0.978375\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112311111111133\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.043710\n",
      "Iteration 396: accuracy 0.9843958333333334\n",
      "After pruning: [784, 17, 12, 1]\n",
      "11123111111111333\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.118327\n",
      "Iteration 397: accuracy 0.9870625\n",
      "After pruning: [784, 18, 12, 1]\n",
      "111231111111113333\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.041732\n",
      "Iteration 398: accuracy 0.9839583333333334\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111231111111113\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.058885\n",
      "Iteration 399: accuracy 0.9785\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111231111111113\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.074425\n",
      "Iteration 400: accuracy 0.9860416666666667\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111231111111113\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.041019\n",
      "Iteration 401: accuracy 0.9862291666666667\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111231111111113\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.109730\n",
      "Iteration 402: accuracy 0.9760833333333333\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111231111111113\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.048122\n",
      "Iteration 403: accuracy 0.9869375\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111231111111113\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.055222\n",
      "Iteration 404: accuracy 0.987125\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111231111111113\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.224195\n",
      "Iteration 405: accuracy 0.9861666666666666\n",
      "After pruning: [784, 17, 12, 1]\n",
      "11123111111111333\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.140713\n",
      "Iteration 406: accuracy 0.985\n",
      "After pruning: [784, 17, 12, 1]\n",
      "11123111111111333\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.032961\n",
      "Iteration 407: accuracy 0.9867708333333334\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111231111111113\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.044566\n",
      "Iteration 408: accuracy 0.9800208333333333\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112311111111133\n",
      "011111011101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.022963\n",
      "Iteration 409: accuracy 0.9768541666666667\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112311111111133\n",
      "011111011101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.045665\n",
      "Iteration 410: accuracy 0.9799583333333334\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112311111111133\n",
      "011111011101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.096569\n",
      "Iteration 411: accuracy 0.9875\n",
      "After pruning: [784, 14, 12, 1]\n",
      "11123111111111\n",
      "011211111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.077156\n",
      "Iteration 412: accuracy 0.9853541666666666\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111231111111113\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.047914\n",
      "Iteration 413: accuracy 0.9856875\n",
      "After pruning: [784, 13, 12, 1]\n",
      "1112111111111\n",
      "011212111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.029884\n",
      "Iteration 414: accuracy 0.9879791666666666\n",
      "After pruning: [784, 14, 12, 1]\n",
      "11121111111113\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.029337\n",
      "Iteration 415: accuracy 0.9848541666666667\n",
      "After pruning: [784, 13, 12, 1]\n",
      "1112111111111\n",
      "011212111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.059918\n",
      "Iteration 416: accuracy 0.9856458333333333\n",
      "After pruning: [784, 13, 12, 1]\n",
      "1112111111111\n",
      "011212111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.043712\n",
      "Iteration 417: accuracy 0.9844791666666667\n",
      "After pruning: [784, 13, 12, 1]\n",
      "1112111111111\n",
      "011212111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.072634\n",
      "Iteration 418: accuracy 0.984625\n",
      "After pruning: [784, 14, 12, 1]\n",
      "11121111111113\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.060840\n",
      "Iteration 419: accuracy 0.9817291666666667\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111211111111133\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.046822\n",
      "Iteration 420: accuracy 0.986375\n",
      "After pruning: [784, 14, 12, 1]\n",
      "11121111111113\n",
      "011212111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.029723\n",
      "Iteration 421: accuracy 0.9859583333333334\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111211111111133\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.047966\n",
      "Iteration 422: accuracy 0.98725\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112111111111333\n",
      "011211111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.130223\n",
      "Iteration 423: accuracy 0.983625\n",
      "After pruning: [784, 14, 12, 1]\n",
      "11121111111113\n",
      "011211111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.021155\n",
      "Iteration 424: accuracy 0.9873333333333333\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112111111111333\n",
      "011211111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.158383\n",
      "Iteration 425: accuracy 0.9634791666666667\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111211111111133\n",
      "011211111101\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.042839\n",
      "Iteration 426: accuracy 0.9829166666666667\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112111111111333\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.062803\n",
      "Iteration 427: accuracy 0.9850833333333333\n",
      "After pruning: [784, 17, 12, 1]\n",
      "11121111111113333\n",
      "011111111001\n",
      "-------------------\n",
      "Cost after epoch 0: 0.065832\n",
      "Iteration 428: accuracy 0.9857083333333333\n",
      "After pruning: [784, 17, 12, 1]\n",
      "11121111111113333\n",
      "011111111001\n",
      "-------------------\n",
      "Cost after epoch 0: 0.139345\n",
      "Iteration 429: accuracy 0.9857708333333334\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111211111111133\n",
      "011111111001\n",
      "-------------------\n",
      "Cost after epoch 0: 0.019256\n",
      "Iteration 430: accuracy 0.9873333333333333\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112111111111333\n",
      "011111111001\n",
      "-------------------\n",
      "Cost after epoch 0: 0.050240\n",
      "Iteration 431: accuracy 0.9846666666666667\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111211111111133\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.021269\n",
      "Iteration 432: accuracy 0.9843125\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111211111111133\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.037044\n",
      "Iteration 433: accuracy 0.9854166666666667\n",
      "After pruning: [784, 14, 12, 1]\n",
      "11121111111113\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.049611\n",
      "Iteration 434: accuracy 0.9865625\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111211111111133\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.029120\n",
      "Iteration 435: accuracy 0.9813125\n",
      "After pruning: [784, 14, 12, 1]\n",
      "11121111111113\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.116077\n",
      "Iteration 436: accuracy 0.9860833333333333\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112111111111333\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.248844\n",
      "Iteration 437: accuracy 0.9851875\n",
      "After pruning: [784, 14, 12, 1]\n",
      "11121111111113\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.039314\n",
      "Iteration 438: accuracy 0.9882291666666667\n",
      "After pruning: [784, 14, 12, 1]\n",
      "11121111111113\n",
      "011112111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.021206\n",
      "Iteration 439: accuracy 0.9835208333333333\n",
      "After pruning: [784, 13, 12, 1]\n",
      "1112111111111\n",
      "011212111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.024249\n",
      "Iteration 440: accuracy 0.9844166666666667\n",
      "After pruning: [784, 14, 12, 1]\n",
      "11121111111113\n",
      "011211111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.077433\n",
      "Iteration 441: accuracy 0.98525\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112111111111333\n",
      "011111111100\n",
      "-------------------\n",
      "Cost after epoch 0: 0.027348\n",
      "Iteration 442: accuracy 0.9865208333333333\n",
      "After pruning: [784, 14, 12, 1]\n",
      "11121111111113\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.030722\n",
      "Iteration 443: accuracy 0.9839791666666666\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111211111111133\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.064144\n",
      "Iteration 444: accuracy 0.9864166666666667\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111211111111133\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.040573\n",
      "Iteration 445: accuracy 0.9890625\n",
      "After pruning: [784, 14, 12, 1]\n",
      "11121111111113\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.050984\n",
      "Iteration 446: accuracy 0.9878958333333333\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111211111111133\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.040983\n",
      "Iteration 447: accuracy 0.9840208333333333\n",
      "After pruning: [784, 14, 12, 1]\n",
      "11121111111113\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.044735\n",
      "Iteration 448: accuracy 0.9874791666666667\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111211111111133\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.145967\n",
      "Iteration 449: accuracy 0.982875\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112111111111333\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.121112\n",
      "Iteration 450: accuracy 0.9704791666666667\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111211111111133\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.023762\n",
      "Iteration 451: accuracy 0.9855\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1112111111111333\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.023829\n",
      "Iteration 452: accuracy 0.9882916666666667\n",
      "After pruning: [784, 14, 12, 1]\n",
      "11131111111113\n",
      "011112111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.022950\n",
      "Iteration 453: accuracy 0.9869583333333334\n",
      "After pruning: [784, 14, 12, 1]\n",
      "11131111111113\n",
      "011112111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.030934\n",
      "Iteration 454: accuracy 0.9874375\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111311111111133\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.029889\n",
      "Iteration 455: accuracy 0.9874791666666667\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111311111111133\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.026920\n",
      "Iteration 456: accuracy 0.9858333333333333\n",
      "After pruning: [784, 14, 12, 1]\n",
      "11131111111113\n",
      "011112111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.034464\n",
      "Iteration 457: accuracy 0.975625\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111311111111133\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.061744\n",
      "Iteration 458: accuracy 0.9872916666666667\n",
      "After pruning: [784, 13, 12, 1]\n",
      "1113111111121\n",
      "011213111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.053654\n",
      "Iteration 459: accuracy 0.988375\n",
      "After pruning: [784, 14, 12, 1]\n",
      "11131111111213\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.028804\n",
      "Iteration 460: accuracy 0.9795833333333334\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111311111112133\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.026199\n",
      "Iteration 461: accuracy 0.9875833333333334\n",
      "After pruning: [784, 14, 12, 1]\n",
      "11131111111213\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.051094\n",
      "Iteration 462: accuracy 0.9875416666666667\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1113111111121333\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.048623\n",
      "Iteration 463: accuracy 0.9875833333333334\n",
      "After pruning: [784, 14, 12, 1]\n",
      "11131111111213\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.062045\n",
      "Iteration 464: accuracy 0.9841875\n",
      "After pruning: [784, 14, 12, 1]\n",
      "11131111111213\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.171077\n",
      "Iteration 465: accuracy 0.9824791666666667\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111311111112133\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.055992\n",
      "Iteration 466: accuracy 0.9886458333333333\n",
      "After pruning: [784, 14, 12, 1]\n",
      "11131111111213\n",
      "011212111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.069600\n",
      "Iteration 467: accuracy 0.9854583333333333\n",
      "After pruning: [784, 14, 12, 1]\n",
      "11131111111213\n",
      "011212111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.066589\n",
      "Iteration 468: accuracy 0.9852916666666667\n",
      "After pruning: [784, 14, 12, 1]\n",
      "11131111111213\n",
      "011212111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.078257\n",
      "Iteration 469: accuracy 0.986875\n",
      "After pruning: [784, 17, 12, 1]\n",
      "11131111111213333\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.035091\n",
      "Iteration 470: accuracy 0.9779166666666667\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111311111112133\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.053201\n",
      "Iteration 471: accuracy 0.9868958333333333\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1113111111121333\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.035193\n",
      "Iteration 472: accuracy 0.988125\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1113111111121333\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.034145\n",
      "Iteration 473: accuracy 0.9870208333333333\n",
      "After pruning: [784, 16, 12, 1]\n",
      "1113111111121333\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.046858\n",
      "Iteration 474: accuracy 0.9837083333333333\n",
      "After pruning: [784, 15, 12, 1]\n",
      "111311111112133\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.045529\n",
      "Iteration 475: accuracy 0.9894166666666667\n",
      "After pruning: [784, 14, 12, 1]\n",
      "11131111111213\n",
      "011111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.030735\n",
      "Iteration 476: accuracy 0.9885625\n",
      "After pruning: [784, 13, 11, 1]\n",
      "1113111111121\n",
      "01121111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.073387\n",
      "Iteration 477: accuracy 0.9851458333333334\n",
      "After pruning: [784, 13, 11, 1]\n",
      "1113111111121\n",
      "01121111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.068515\n",
      "Iteration 478: accuracy 0.9862291666666667\n",
      "After pruning: [784, 13, 11, 1]\n",
      "1111111111213\n",
      "01121111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.033411\n",
      "Iteration 479: accuracy 0.9885833333333334\n",
      "After pruning: [784, 13, 11, 1]\n",
      "1111111111213\n",
      "01121111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.029941\n",
      "Iteration 480: accuracy 0.9874166666666667\n",
      "After pruning: [784, 12, 11, 1]\n",
      "111111111121\n",
      "01121111101\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.027450\n",
      "Iteration 481: accuracy 0.9888541666666667\n",
      "After pruning: [784, 12, 11, 1]\n",
      "111111111121\n",
      "01121111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.063742\n",
      "Iteration 482: accuracy 0.9860416666666667\n",
      "After pruning: [784, 13, 11, 1]\n",
      "1111111111213\n",
      "01111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.093844\n",
      "Iteration 483: accuracy 0.9809791666666666\n",
      "After pruning: [784, 14, 11, 1]\n",
      "11111111112133\n",
      "01111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.134358\n",
      "Iteration 484: accuracy 0.988875\n",
      "After pruning: [784, 13, 11, 1]\n",
      "1111111111213\n",
      "01121111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.020837\n",
      "Iteration 485: accuracy 0.9871875\n",
      "After pruning: [784, 12, 11, 1]\n",
      "111111111121\n",
      "01121111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.023003\n",
      "Iteration 486: accuracy 0.9883958333333334\n",
      "After pruning: [784, 12, 11, 1]\n",
      "111111111121\n",
      "01121111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.036803\n",
      "Iteration 487: accuracy 0.9845625\n",
      "After pruning: [784, 14, 11, 1]\n",
      "11111111112143\n",
      "01111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.066648\n",
      "Iteration 488: accuracy 0.9860208333333333\n",
      "After pruning: [784, 14, 11, 1]\n",
      "11111111112133\n",
      "01111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.065046\n",
      "Iteration 489: accuracy 0.9880416666666667\n",
      "After pruning: [784, 13, 11, 1]\n",
      "1111111111213\n",
      "01111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.053558\n",
      "Iteration 490: accuracy 0.9890625\n",
      "After pruning: [784, 13, 11, 1]\n",
      "1111111111213\n",
      "01111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.083644\n",
      "Iteration 491: accuracy 0.9866875\n",
      "After pruning: [784, 12, 11, 1]\n",
      "111111111121\n",
      "01121111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.033369\n",
      "Iteration 492: accuracy 0.9840416666666667\n",
      "After pruning: [784, 13, 11, 1]\n",
      "1111111111213\n",
      "01121111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.037023\n",
      "Iteration 493: accuracy 0.98775\n",
      "After pruning: [784, 14, 11, 1]\n",
      "11111111112133\n",
      "01111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.029472\n",
      "Iteration 494: accuracy 0.9844791666666667\n",
      "After pruning: [784, 15, 11, 1]\n",
      "111111111121333\n",
      "01111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.030909\n",
      "Iteration 495: accuracy 0.9867916666666666\n",
      "After pruning: [784, 15, 11, 1]\n",
      "111111111121333\n",
      "01111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.019865\n",
      "Iteration 496: accuracy 0.9872291666666667\n",
      "After pruning: [784, 14, 11, 1]\n",
      "11111111112133\n",
      "01111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.021566\n",
      "Iteration 497: accuracy 0.989375\n",
      "After pruning: [784, 14, 11, 1]\n",
      "11111111112133\n",
      "01111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.035202\n",
      "Iteration 498: accuracy 0.9845833333333334\n",
      "After pruning: [784, 14, 11, 1]\n",
      "11111111112133\n",
      "01111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.061929\n",
      "Iteration 499: accuracy 0.9860833333333333\n",
      "After pruning: [784, 16, 11, 1]\n",
      "1111111111213333\n",
      "01111111101\n",
      "-------------------\n",
      "Cost after epoch 0: 0.058149\n",
      "Iteration 500: accuracy 0.9895416666666667\n",
      "After pruning: [784, 14, 11, 1]\n",
      "11111111112133\n",
      "01111111101\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [784, 100, 100, 1]\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters = train_dynamic_model(X_train_fm, y_train_fm, parameters, learning_rate=0.02, l1_term=0.0005, n_iterations=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_bak = copy.deepcopy(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.513137\n",
      "Iteration 1: accuracy 0.9650208333333333\n",
      "After pruning: [784, 12, 8, 1]\n",
      "111111111113\n",
      "01112111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.300194\n",
      "Iteration 2: accuracy 0.9660625\n",
      "After pruning: [784, 11, 6, 1]\n",
      "11111111111\n",
      "011111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.203887\n",
      "Iteration 3: accuracy 0.9606666666666667\n",
      "After pruning: [784, 12, 6, 1]\n",
      "111111112213\n",
      "011111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.214973\n",
      "Iteration 4: accuracy 0.9633125\n",
      "After pruning: [784, 11, 6, 1]\n",
      "11111111313\n",
      "011111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.154301\n",
      "Iteration 5: accuracy 0.9625208333333334\n",
      "After pruning: [784, 10, 6, 1]\n",
      "1111111123\n",
      "011111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.117887\n",
      "Iteration 6: accuracy 0.963125\n",
      "After pruning: [784, 9, 6, 1]\n",
      "111121213\n",
      "011111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.184627\n",
      "Iteration 7: accuracy 0.963\n",
      "After pruning: [784, 11, 6, 1]\n",
      "11112122333\n",
      "011111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.246694\n",
      "Iteration 8: accuracy 0.9632083333333333\n",
      "After pruning: [784, 7, 5, 1]\n",
      "1111213\n",
      "01211\n",
      "-------------------\n",
      "Cost after epoch 0: 0.175664\n",
      "Iteration 9: accuracy 0.9534166666666667\n",
      "After pruning: [784, 8, 5, 1]\n",
      "11111333\n",
      "01111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.111515\n",
      "Iteration 10: accuracy 0.9599583333333334\n",
      "After pruning: [784, 6, 5, 1]\n",
      "111123\n",
      "02221\n",
      "-------------------\n",
      "Cost after epoch 0: 0.161501\n",
      "Iteration 11: accuracy 0.96225\n",
      "After pruning: [784, 6, 5, 1]\n",
      "111123\n",
      "01131\n",
      "-------------------\n",
      "Cost after epoch 0: 0.138504\n",
      "Iteration 12: accuracy 0.9622083333333333\n",
      "After pruning: [784, 7, 5, 1]\n",
      "1111234\n",
      "01111\n",
      "-------------------\n",
      "Cost after epoch 0: 0.122647\n",
      "Iteration 13: accuracy 0.9624375\n",
      "After pruning: [784, 5, 4, 1]\n",
      "11113\n",
      "0241\n",
      "-------------------\n",
      "Cost after epoch 0: 0.104146\n",
      "Iteration 14: accuracy 0.9597291666666666\n",
      "After pruning: [784, 5, 4, 1]\n",
      "11123\n",
      "0121\n",
      "-------------------\n",
      "Cost after epoch 0: 0.118340\n",
      "Iteration 15: accuracy 0.96275\n",
      "After pruning: [784, 5, 5, 1]\n",
      "11123\n",
      "01114\n",
      "-------------------\n",
      "Cost after epoch 0: 0.091457\n",
      "Iteration 16: accuracy 0.9628333333333333\n",
      "After pruning: [784, 4, 3, 1]\n",
      "1113\n",
      "031\n",
      "-------------------\n",
      "Cost after epoch 0: 0.130683\n",
      "Iteration 17: accuracy 0.9632291666666667\n",
      "After pruning: [784, 5, 3, 1]\n",
      "11133\n",
      "010\n",
      "-------------------\n",
      "Cost after epoch 0: 0.113550\n",
      "Iteration 18: accuracy 0.9607083333333334\n",
      "After pruning: [784, 6, 3, 1]\n",
      "111333\n",
      "010\n",
      "-------------------\n",
      "Cost after epoch 0: 0.154880\n",
      "Iteration 19: accuracy 0.9625\n",
      "After pruning: [784, 6, 3, 1]\n",
      "111333\n",
      "011\n",
      "-------------------\n",
      "Cost after epoch 0: 0.146894\n",
      "Iteration 20: accuracy 0.946875\n",
      "After pruning: [784, 4, 3, 1]\n",
      "1113\n",
      "021\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "parameters = train_dynamic_model(X_train_fm, y_train_fm, parameters, learning_rate=0.02, l1_term=0.05, n_iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
