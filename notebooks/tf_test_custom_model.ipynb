{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "y_train = y_train.astype('float32')\n",
    "X_test = X_test.astype('float32')  / 255.0\n",
    "y_test = y_test.astype('float32')\n",
    "\n",
    "X_train = np.reshape(X_train, (-1, 784))\n",
    "X_test = np.reshape(X_test, (-1, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSRegularizer(tf.keras.regularizers.Regularizer):\n",
    "    def __init__(self, l1):\n",
    "        self.l1 = l1\n",
    "\n",
    "    def __call__(self, x):\n",
    "        scaling_vector = tf.cumsum(tf.constant(self.l1, shape=x.shape[-1]), axis=0) - 0.1\n",
    "        return tf.reduce_sum(scaling_vector * tf.abs(x))\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'l1': float(self.l1)}\n",
    "\n",
    "\n",
    "class SSModel(tf.keras.Model):\n",
    "    def __init__(self, units, activation=None, kernel_initializer='glorot_uniform', bias_initializer='zeros'):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.activation1 = tf.keras.activations.get(activation)\n",
    "        self.activation2 = tf.keras.activations.get('softmax')\n",
    "        self.kernel_initializer = tf.keras.initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = tf.keras.initializers.get(bias_initializer)\n",
    "        self.regularizer = SSRegularizer(0.01)\n",
    "        \n",
    "        self.W1 = tf.Variable(\n",
    "            name='W1',\n",
    "            initial_value=self.kernel_initializer(shape=(784, self.units), dtype='float32'),\n",
    "            trainable=True)\n",
    "        \n",
    "        self.b1 = tf.Variable(\n",
    "            name='b1',\n",
    "            initial_value=self.bias_initializer(shape=(self.units,), dtype='float32'),\n",
    "            trainable=True)\n",
    "        \n",
    "        self.W2 = tf.Variable(\n",
    "            name='W2',\n",
    "            initial_value=self.kernel_initializer(shape=(self.units, 10), dtype='float32'),\n",
    "            trainable=True)\n",
    "        \n",
    "        self.b2 = tf.Variable(\n",
    "            name='b2',\n",
    "            initial_value=self.bias_initializer(shape=(10,), dtype='float32'),\n",
    "            trainable=True)\n",
    "        \n",
    "        self.add_loss(lambda: self.regularizer(self.W1))\n",
    "        self.add_loss(lambda: self.regularizer(self.b1))\n",
    "        self.add_loss(lambda: self.regularizer(self.W2))\n",
    "        self.add_loss(lambda: self.regularizer(self.b2))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        A1 = self.activation1(tf.matmul(inputs, self.W1) + self.b1)\n",
    "        A2 = self.activation2(tf.matmul(A1, self.W2) + self.b2)\n",
    "\n",
    "        return A2\n",
    "    \n",
    "    def prune(self, threshold=0.001):\n",
    "        W1 = self.W1.value()\n",
    "        b1 = self.b1.value()\n",
    "        W2 = self.W2.value()\n",
    "        \n",
    "        weights_with_biases = tf.concat([W1, tf.reshape(b1, (1, -1))], axis=0)\n",
    "        neurons_are_active = tf.math.reduce_max(weights_with_biases, axis=0) >= threshold\n",
    "        active_neurons_indices = tf.reshape(tf.where(neurons_are_active), (-1,))\n",
    "        \n",
    "        new_W1 = tf.gather(W1, active_neurons_indices, axis=1)\n",
    "        new_b1 = tf.gather(b1, active_neurons_indices, axis=0)\n",
    "        new_W2 = tf.gather(W2, active_neurons_indices, axis=0)\n",
    "        \n",
    "        self.W1 = tf.Variable(name='W1', initial_value=new_W1, trainable=True)\n",
    "        self.b1 = tf.Variable(name='b1', initial_value=new_b1, trainable=True)\n",
    "        self.W2 = tf.Variable(name='W2', initial_value=new_W2, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, epochs, batch_size, train_dataset):\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "        for step, (x_batch, y_batch) in enumerate(train_dataset):\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_pred = model(x_batch, training=True)\n",
    "                loss_value = tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(y_batch, y_pred))\n",
    "                loss_value += sum(model.losses)\n",
    "\n",
    "            grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        \n",
    "        # Show epoch statistics\n",
    "        y_pred = model(X_train)\n",
    "        loss_value = tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(y_train, y_pred))\n",
    "        accuracy = tf.reduce_mean(tf.keras.metrics.sparse_categorical_accuracy(y_train, y_pred))\n",
    "        print(f\"loss: {loss_value} - accuracy: {accuracy} - units: {model.W1.shape[1]}\")\n",
    "        \n",
    "        model.prune()\n",
    "        \n",
    "        # Show epoch statistics\n",
    "        y_pred = model(X_train)\n",
    "        loss_value = tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(y_train, y_pred))\n",
    "        accuracy = tf.reduce_mean(tf.keras.metrics.sparse_categorical_accuracy(y_train, y_pred))\n",
    "        print(f\"loss: {loss_value} - accuracy: {accuracy} - units: {model.W1.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "loss: 1.7096461057662964 - accuracy: 0.5578166842460632 - units: 100\n",
      "loss: 1.7096459865570068 - accuracy: 0.5578166842460632 - units: 97\n",
      "Epoch 2/10\n",
      "loss: 1.900716781616211 - accuracy: 0.6493833065032959 - units: 97\n",
      "loss: 1.90078604221344 - accuracy: 0.6493833065032959 - units: 93\n",
      "Epoch 3/10\n",
      "loss: 2.4009337425231934 - accuracy: 0.6944166421890259 - units: 93\n",
      "loss: 2.4010181427001953 - accuracy: 0.6943833231925964 - units: 89\n",
      "Epoch 4/10\n",
      "loss: 3.115446090698242 - accuracy: 0.7389833331108093 - units: 89\n",
      "loss: 3.115446090698242 - accuracy: 0.7389833331108093 - units: 87\n",
      "Epoch 5/10\n",
      "loss: 4.33226203918457 - accuracy: 0.6991166472434998 - units: 87\n",
      "loss: 4.33226203918457 - accuracy: 0.6991166472434998 - units: 84\n",
      "Epoch 6/10\n",
      "loss: 5.3541178703308105 - accuracy: 0.6970666646957397 - units: 84\n",
      "loss: 5.3541178703308105 - accuracy: 0.6970666646957397 - units: 83\n",
      "Epoch 7/10\n",
      "loss: 6.86423397064209 - accuracy: 0.7108333110809326 - units: 83\n",
      "loss: 6.86423397064209 - accuracy: 0.7108333110809326 - units: 82\n",
      "Epoch 8/10\n",
      "loss: 7.375539779663086 - accuracy: 0.709766685962677 - units: 82\n",
      "loss: 7.375529766082764 - accuracy: 0.709766685962677 - units: 79\n",
      "Epoch 9/10\n",
      "loss: 15.684357643127441 - accuracy: 0.6050999760627747 - units: 79\n",
      "loss: 15.68372917175293 - accuracy: 0.6050999760627747 - units: 76\n",
      "Epoch 10/10\n",
      "loss: 12.136178970336914 - accuracy: 0.6704666614532471 - units: 76\n",
      "loss: 12.136178970336914 - accuracy: 0.6704666614532471 - units: 75\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "model = SSModel(units=100, activation='relu')\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "train_model(model, optimizer, 10, batch_size, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "loss: 2.3635358810424805 - accuracy: 0.7073333263397217\n"
     ]
    }
   ],
   "source": [
    "model.prune()\n",
    "train_model(model, optimizer, 1, batch_size, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(784, 10), dtype=float32, numpy=\n",
       "array([[-8.45908   ,  7.518516  ,  6.5726666 , ...,  1.9297397 ,\n",
       "        -0.9787072 , -0.01317163],\n",
       "       [ 8.437461  , -7.5142074 ,  6.5818934 , ...,  1.8981346 ,\n",
       "        -0.9950207 ,  0.0211658 ],\n",
       "       [-8.453113  , -7.516163  ,  6.6172676 , ..., -1.9027253 ,\n",
       "         0.9439355 ,  0.02779727],\n",
       "       ...,\n",
       "       [ 8.446647  , -7.5786667 , -6.5709434 , ..., -1.9094808 ,\n",
       "        -0.9905917 ,  0.07739742],\n",
       "       [ 8.504931  ,  7.5016556 , -6.6205573 , ...,  1.9115169 ,\n",
       "        -0.9903703 , -0.05508175],\n",
       "       [-8.475748  ,  7.5195327 , -6.6430144 , ...,  1.9527134 ,\n",
       "        -0.9456445 , -0.01849682]], dtype=float32)>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.W1[:, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'test:0' shape=(10,) dtype=float32, numpy=\n",
       "array([ 0.10325973,  0.28163418, -0.02973413, -0.09620668, -0.07770138,\n",
       "        0.19860472,  0.07667638,  0.07115997,  0.28643882,  0.11287516],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.Variable(name='test',\n",
    "            initial_value=model.b1[:10],\n",
    "            trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'b1:0' shape=(100,) dtype=float32, numpy=\n",
       "array([ 7.7180185e+00, -9.5333204e+00, -8.4282074e+00,  3.6814294e+00,\n",
       "        3.0408814e+00, -5.1143255e+00,  1.5648246e+00, -2.9887168e+00,\n",
       "        3.1807947e-01,  1.5764303e+00,  6.2338686e-01,  1.9603917e-01,\n",
       "        2.1873888e-02,  9.9807698e-03,  3.5673131e-03, -5.0638691e-03,\n",
       "       -3.7083528e-03, -2.0554103e-03,  8.4837107e-04,  4.6422998e-03,\n",
       "        1.2599836e-03,  4.3248530e-03, -1.4403258e-03, -5.2472483e-03,\n",
       "       -2.3949654e-03, -1.5769964e-03, -3.8820663e-03, -6.2360056e-04,\n",
       "        9.2419318e-04,  2.4113364e-03, -1.5476472e-03, -4.8201147e-04,\n",
       "       -4.8491023e-03, -2.9747889e-03, -5.5699162e-03, -4.4958424e-03,\n",
       "        2.9769551e-04, -3.5081524e-05, -2.5447488e-03, -7.2792927e-03,\n",
       "       -5.0031999e-04,  3.0598373e-03, -5.1800897e-03, -1.1878333e-02,\n",
       "       -4.1770102e-03, -3.9493092e-03,  4.6534883e-04, -3.4572212e-03,\n",
       "        1.1882372e-03, -1.0890003e-02,  7.1908114e-03,  7.8994385e-04,\n",
       "       -9.4388379e-04,  3.2572090e-03,  4.3430696e-03, -2.1371553e-03,\n",
       "        3.8904375e-03, -4.2605698e-03, -2.3687859e-03,  3.2661716e-04,\n",
       "        6.3246116e-06,  5.1708175e-03,  4.6027452e-03, -1.3340637e-03,\n",
       "       -4.9536070e-03,  1.1986713e-03,  1.8921271e-03, -1.6536471e-03,\n",
       "        2.3115980e-03, -4.5506805e-03, -5.0199805e-03,  1.9038140e-03,\n",
       "        2.7641957e-03, -4.3931510e-03, -5.8521293e-03, -9.1179516e-03,\n",
       "       -2.9695900e-03, -1.3094298e-03,  2.5569345e-03, -3.8383934e-03,\n",
       "       -4.5411838e-03, -1.8368978e-02,  8.2532577e-03,  3.5418193e-03,\n",
       "        3.4862510e-03, -5.6864833e-04, -3.7183005e-03, -8.8313557e-03,\n",
       "        4.3041809e-03,  6.2568113e-04, -2.2947667e-03, -2.7353796e-03,\n",
       "        2.8992062e-03, -3.4144660e-03,  3.8295602e-03,  7.7841049e-03,\n",
       "       -8.8896789e-03, -1.1749081e-03,  2.2339690e-03, -5.0792228e-03],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.54801464e+00, 7.58154488e+00, 6.67377949e+00, 5.71237659e+00,\n",
       "       4.76999712e+00, 3.84227133e+00, 3.40639615e+00, 2.08757424e+00,\n",
       "       1.39305019e+00, 5.54792762e-01, 5.46755552e-01, 3.44100893e-01,\n",
       "       4.29232270e-01, 3.53028566e-01, 6.19301246e-03, 1.32577680e-03,\n",
       "       6.67357957e-03, 2.54884213e-01, 4.66621574e-03, 5.53519232e-03,\n",
       "       2.84283306e-03, 8.22989084e-03, 5.04944241e-03, 1.39534415e-03,\n",
       "       6.41245907e-03, 5.24821132e-03, 2.78953370e-03, 7.86001887e-03,\n",
       "       2.67719897e-03, 6.63585402e-03, 2.09694263e-03, 2.71954667e-03,\n",
       "       2.29622913e-03, 2.39135046e-03, 2.49643694e-03, 2.58640596e-03,\n",
       "       7.78836431e-03, 2.79369904e-03, 7.04646949e-03, 2.99354363e-03,\n",
       "       3.09780124e-03, 6.52314164e-03, 5.12211584e-03, 3.87223973e-03,\n",
       "       3.49415187e-03, 3.58668645e-03, 3.69629939e-03, 4.31363657e-03,\n",
       "       4.35943343e-03, 4.78814356e-03, 7.92876817e-03, 5.71044441e-03,\n",
       "       4.28779563e-03, 4.39967215e-03, 4.49936511e-03, 4.59608994e-03,\n",
       "       1.08794738e-02, 4.79784934e-03, 4.89585334e-03, 1.07256435e-02,\n",
       "       5.08050621e-03, 5.53701445e-03, 1.00821480e-02, 5.39197586e-03,\n",
       "       5.49688237e-03, 5.59407240e-03, 5.69140865e-03, 8.29566270e-03,\n",
       "       5.89431450e-03, 5.98344672e-03, 9.44554806e-03, 9.02320631e-03,\n",
       "       1.19242426e-02, 8.62168614e-03, 6.49409136e-03, 6.45190291e-03,\n",
       "       6.78271055e-03, 9.51754209e-03, 6.87232846e-03, 1.23866173e-02,\n",
       "       1.11233052e-02, 7.30995601e-03, 9.52013955e-03, 1.16748959e-02,\n",
       "       7.47868419e-03, 7.59479962e-03, 7.67493434e-03, 9.54385940e-03,\n",
       "       7.85340555e-03, 7.99479429e-03, 1.05522973e-02, 9.10875201e-03,\n",
       "       8.29962455e-03, 1.41389566e-02, 1.10084303e-02, 8.59923847e-03,\n",
       "       8.66937079e-03, 9.04388446e-03, 8.88729189e-03, 8.99673533e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amax(model.W1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.0424 - accuracy: 0.7244 - val_loss: 0.3615 - val_accuracy: 0.9038\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3588 - accuracy: 0.8997 - val_loss: 0.2952 - val_accuracy: 0.9192\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2979 - accuracy: 0.9152 - val_loss: 0.2641 - val_accuracy: 0.9264\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2667 - accuracy: 0.9234 - val_loss: 0.2392 - val_accuracy: 0.9338\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2428 - accuracy: 0.9319 - val_loss: 0.2224 - val_accuracy: 0.9371\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2237 - accuracy: 0.9374 - val_loss: 0.2080 - val_accuracy: 0.9408\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2061 - accuracy: 0.9421 - val_loss: 0.1947 - val_accuracy: 0.9443\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1940 - accuracy: 0.9443 - val_loss: 0.1843 - val_accuracy: 0.9467\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1822 - accuracy: 0.9488 - val_loss: 0.1763 - val_accuracy: 0.9476\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 926us/step - loss: 0.1736 - accuracy: 0.9510 - val_loss: 0.1671 - val_accuracy: 0.9519\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa3c2899880>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
