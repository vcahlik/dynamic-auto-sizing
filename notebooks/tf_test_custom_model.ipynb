{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = 'float32'\n",
    "tf.keras.backend.set_floatx(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "X_train = X_train.astype(dtype) / 255.0\n",
    "y_train = y_train.astype(dtype)\n",
    "X_test = X_test.astype(dtype)  / 255.0\n",
    "y_test = y_test.astype(dtype)\n",
    "\n",
    "X_train = np.reshape(X_train, (-1, 784))\n",
    "X_test = np.reshape(X_test, (-1, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSRegularizer(tf.keras.regularizers.Regularizer):\n",
    "    def __init__(self, l1):\n",
    "        self.l1 = l1\n",
    "\n",
    "    def __call__(self, x):\n",
    "        scaling_vector = tf.cumsum(tf.constant(self.l1, shape=(x.shape[-1],), dtype=dtype), axis=0) - self.l1\n",
    "        return tf.reduce_sum(scaling_vector * tf.abs(x))\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'l1': float(self.l1)}\n",
    "\n",
    "\n",
    "class SSModel(tf.keras.Model):\n",
    "    def __init__(self, units, activation=None, l1=0.01, kernel_initializer='glorot_uniform', bias_initializer='zeros'):\n",
    "        super().__init__()\n",
    "        self.activation1 = tf.keras.activations.get(activation)\n",
    "        self.activation2 = tf.keras.activations.get('softmax')\n",
    "        self.l1 = l1\n",
    "        self.kernel_initializer = tf.keras.initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = tf.keras.initializers.get(bias_initializer)\n",
    "        self.regularizer = SSRegularizer(self.l1)\n",
    "        \n",
    "        self.W1 = tf.Variable(\n",
    "            name='W1',\n",
    "            initial_value=self.kernel_initializer(shape=(784, units), dtype=dtype),\n",
    "            trainable=True)\n",
    "        \n",
    "        self.b1 = tf.Variable(\n",
    "            name='b1',\n",
    "            initial_value=self.bias_initializer(shape=(units,), dtype=dtype),\n",
    "            trainable=True)\n",
    "        \n",
    "        self.W2 = tf.Variable(\n",
    "            name='W2',\n",
    "            initial_value=self.kernel_initializer(shape=(units, 10), dtype=dtype),\n",
    "            trainable=True)\n",
    "        \n",
    "        self.b2 = tf.Variable(\n",
    "            name='b2',\n",
    "            initial_value=self.bias_initializer(shape=(10,), dtype=dtype),\n",
    "            trainable=True)\n",
    "        \n",
    "        self.add_loss(lambda: self.regularizer(self.W1))\n",
    "        self.add_loss(lambda: self.regularizer(self.b1))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        S1 = tf.matmul(inputs, self.W1)\n",
    "        A1 = self.activation1(S1 + self.b1)\n",
    "        A2 = self.activation2(tf.matmul(A1, self.W2) + self.b2)\n",
    "\n",
    "        return A2\n",
    "    \n",
    "    def prune(self, threshold=0.001):\n",
    "        W1 = self.W1.value()\n",
    "        b1 = self.b1.value()\n",
    "        W2 = self.W2.value()\n",
    "        \n",
    "        weights_with_biases = tf.concat([W1, tf.reshape(b1, (1, -1))], axis=0)\n",
    "        neurons_are_active = tf.math.reduce_max(weights_with_biases, axis=0) >= threshold\n",
    "        active_neurons_indices = tf.reshape(tf.where(neurons_are_active), (-1,))\n",
    "        \n",
    "        new_W1 = tf.gather(W1, active_neurons_indices, axis=1)\n",
    "        new_b1 = tf.gather(b1, active_neurons_indices, axis=0)\n",
    "        new_W2 = tf.gather(W2, active_neurons_indices, axis=0)\n",
    "        \n",
    "        self.W1 = tf.Variable(name='W1', initial_value=new_W1, trainable=True)\n",
    "        self.b1 = tf.Variable(name='b1', initial_value=new_b1, trainable=True)\n",
    "        self.W2 = tf.Variable(name='W2', initial_value=new_W2, trainable=True)\n",
    "    \n",
    "    def grow(self, min_new_neurons=5, scaling_factor=0.001):      \n",
    "        W1 = self.W1.value()\n",
    "        b1 = self.b1.value()\n",
    "        W2 = self.W2.value()\n",
    "        \n",
    "        n_new_neurons = max(min_new_neurons, int(W1.shape[1] * 0.2))\n",
    "        \n",
    "        W1_growth = self.kernel_initializer(shape=(W1.shape[0], W1.shape[1] + n_new_neurons), dtype=dtype)[:, -n_new_neurons:] * scaling_factor\n",
    "        b1_growth = self.kernel_initializer(shape=(n_new_neurons,), dtype=dtype)\n",
    "        W2_growth = self.kernel_initializer(shape=(W2.shape[0] + n_new_neurons, W2.shape[1]), dtype=dtype)[-n_new_neurons:, :]\n",
    "        \n",
    "        new_W1 = tf.concat([W1, W1_growth], axis=1)\n",
    "        new_b1 = tf.concat([b1, b1_growth], axis=0)\n",
    "        new_W2 = tf.concat([W2, W2_growth], axis=0)\n",
    "        \n",
    "        self.W1 = tf.Variable(name='W1', initial_value=new_W1, trainable=True)\n",
    "        self.b1 = tf.Variable(name='b1', initial_value=new_b1, trainable=True)\n",
    "        self.W2 = tf.Variable(name='W2', initial_value=new_W2, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param_string(weights):\n",
    "    param_string = \"\"\n",
    "    max_parameters = tf.math.reduce_max(weights, axis=0).numpy()\n",
    "    magnitudes = np.floor(np.log10(max_parameters))\n",
    "    for m in magnitudes:\n",
    "        if m > 0:\n",
    "            m = 0\n",
    "        param_string += str(int(-m))\n",
    "    return param_string\n",
    "\n",
    "\n",
    "def print_epoch_statistics(model):\n",
    "    y_pred = model(X_train)\n",
    "    loss = tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(y_train, y_pred))\n",
    "    accuracy = tf.reduce_mean(tf.keras.metrics.sparse_categorical_accuracy(y_train, y_pred))\n",
    "    \n",
    "    y_pred_val = model(X_test)\n",
    "    val_loss = tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(y_test, y_pred_val))\n",
    "    val_accuracy = tf.reduce_mean(tf.keras.metrics.sparse_categorical_accuracy(y_test, y_pred_val))\n",
    "    print(f\"loss: {loss} - accuracy: {accuracy} - val_loss: {val_loss} - val_accuracy: {val_accuracy}\")\n",
    "    print(f\"units: {model.W1.shape[1]} - {get_param_string(model.W1)}\")\n",
    "    \n",
    "\n",
    "def train_model(model, optimizer, epochs, batch_size, train_dataset):\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        \n",
    "        print(\"Before growing:\")\n",
    "        print_epoch_statistics(model)\n",
    "        model.grow(min_new_neurons=5, scaling_factor=0.001)\n",
    "        print(\"After growing:\")\n",
    "        print_epoch_statistics(model)\n",
    "\n",
    "        for step, (x_batch, y_batch) in enumerate(train_dataset):\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_pred = model(x_batch, training=True)\n",
    "                loss_value = tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(y_batch, y_pred))\n",
    "                loss_value += sum(model.losses)\n",
    "\n",
    "            grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        \n",
    "        print(\"Before pruning:\")\n",
    "        print_epoch_statistics(model)\n",
    "        model.prune(threshold=0.001)\n",
    "        print(\"After pruning:\")\n",
    "        print_epoch_statistics(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Before growing:\n",
      "loss: 2.3557889461517334 - accuracy: 0.16066665947437286 - val_loss: 2.3568131923675537 - val_accuracy: 0.16110000014305115\n",
      "units: 200 - 11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "After growing:\n",
      "loss: 2.366809368133545 - accuracy: 0.1540333330631256 - val_loss: 2.3678812980651855 - val_accuracy: 0.15639999508857727\n",
      "units: 240 - 111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111114444444444444444444444444444444444444444\n",
      "Before pruning:\n",
      "loss: 0.46726271510124207 - accuracy: 0.8273666501045227 - val_loss: 0.5071299076080322 - val_accuracy: 0.8126999735832214\n",
      "units: 240 - 111111111111111111111211111111211111111111111111111111311131121413111121414111113111131111111141121311123312412114132211211112211131211313221131111113431224221132241232122134123242211421111123333113234143443343434323334344334333444333333433\n",
      "After pruning:\n",
      "loss: 0.467258095741272 - accuracy: 0.8273500204086304 - val_loss: 0.5071225762367249 - val_accuracy: 0.8127999901771545\n",
      "units: 215 - 11111111111111111111121111111121111111111111111111111131113112113111121111111311113111111111121311123312121113221121111221113121131322113111111331222211322123212213123222112111112333311323133343332333333333433333333\n",
      "Epoch 2/20\n",
      "Before growing:\n",
      "loss: 0.467258095741272 - accuracy: 0.8273500204086304 - val_loss: 0.5071225762367249 - val_accuracy: 0.8127999901771545\n",
      "units: 215 - 11111111111111111111121111111121111111111111111111111131113112113111121111111311113111111111121311123312121113221121111221113121131322113111111331222211322123212213123222112111112333311323133343332333333333433333333\n",
      "After growing:\n",
      "loss: 0.46374571323394775 - accuracy: 0.8288666605949402 - val_loss: 0.5032075047492981 - val_accuracy: 0.8137999773025513\n",
      "units: 258 - 111111111111111111111211111111211111111111111111111111311131121131111211111113111131111111111213111233121211132211211112211131211313221131111113312222113221232122131232221121111123333113231333433323333333334333333334444444444444444444444444444444444444444444\n",
      "Before pruning:\n",
      "loss: 0.34655818343162537 - accuracy: 0.8738666772842407 - val_loss: 0.3880971670150757 - val_accuracy: 0.86080002784729\n",
      "units: 258 - 111121111111111111112211111111411112111121121311111141211121141124111414142113214231113313111422324333131411134212323243312332342443433333422124343332323434343323231443333244444423333414332334443334334444334333323343323343333433343344434333323234333343344433\n",
      "After pruning:\n",
      "loss: 0.3465610146522522 - accuracy: 0.8739166855812073 - val_loss: 0.38810214400291443 - val_accuracy: 0.86080002784729\n",
      "units: 204 - 111121111111111111112211111111111121111211213111111121112111121111121132123111331311122323331311113212323233123323233333322123333232333332323133332233331332333333333333323333233333333333433333232333333333\n",
      "Epoch 3/20\n",
      "Before growing:\n",
      "loss: 0.3465610146522522 - accuracy: 0.8739166855812073 - val_loss: 0.38810214400291443 - val_accuracy: 0.86080002784729\n",
      "units: 204 - 111121111111111111112211111111111121111211213111111121112111121111121132123111331311122323331311113212323233123323233333322123333232333332323133332233331332333333333333323333233333333333433333232333333333\n",
      "After growing:\n",
      "loss: 0.34344619512557983 - accuracy: 0.8754500150680542 - val_loss: 0.3848877251148224 - val_accuracy: 0.8605999946594238\n",
      "units: 244 - 1111211111111111111122111111111111211112112131111111211121111211111211321231113313111223233313111132123232331233232333333221233332323333323231333322333313323333333333333233332333333333334333332323333333334444444444444444444444444444444444444444\n",
      "Before pruning:\n",
      "loss: 0.3255660831928253 - accuracy: 0.8817499876022339 - val_loss: 0.3767383396625519 - val_accuracy: 0.8658000230789185\n",
      "units: 244 - 1111211111111111111123111111111111211113112241211111411231112311112214422431114413142333424313214142244433343433344333343432433344343334333431443343343423334333343333334333333333333333434333432333343433433333343333334343333333433333333333433333\n",
      "After pruning:\n",
      "loss: 0.3255757689476013 - accuracy: 0.8817499876022339 - val_loss: 0.37675121426582336 - val_accuracy: 0.8658000230789185\n",
      "units: 198 - 111121111111111111112311111111111121111311221211111112311123111122122311113123332313211223333333333333233333333333133333233333333333333333333333333333333323333333333333333333333333333333333333333333\n",
      "Epoch 4/20\n",
      "Before growing:\n",
      "loss: 0.3255757689476013 - accuracy: 0.8817499876022339 - val_loss: 0.37675121426582336 - val_accuracy: 0.8658000230789185\n",
      "units: 198 - 111121111111111111112311111111111121111311221211111112311123111122122311113123332313211223333333333333233333333333133333233333333333333333333333333333333323333333333333333333333333333333333333333333\n",
      "After growing:\n",
      "loss: 0.3264349699020386 - accuracy: 0.8815666437149048 - val_loss: 0.37779897451400757 - val_accuracy: 0.8648999929428101\n",
      "units: 237 - 111121111111111111112311111111111121111311221211111112311123111122122311113123332313211223333333333333233333333333133333233333333333333333333333333333333323333333333333333333333333333333333333333333444444444444444444444444444444444444444\n",
      "Before pruning:\n",
      "loss: 0.32295915484428406 - accuracy: 0.8802000284194946 - val_loss: 0.3803161382675171 - val_accuracy: 0.8629000186920166\n",
      "units: 237 - 101121111111111111112411111111111141111211441411111124412124111142143413114424243322441343332233343434243343333344433333433333433333333343333434343333443323334333433324333343343343334323333434333433443343433333334343444444433343334333444\n",
      "After pruning:\n",
      "loss: 0.32297056913375854 - accuracy: 0.8802333474159241 - val_loss: 0.3803290128707886 - val_accuracy: 0.8628000020980835\n",
      "units: 176 - 10112111111111111111211111111111111112111111111212121111213131122332213333223333323333333333333333333333333333334333333332333333333233333333333323333333333333333333333333333333\n",
      "Epoch 5/20\n",
      "Before growing:\n",
      "loss: 0.32297056913375854 - accuracy: 0.8802333474159241 - val_loss: 0.3803290128707886 - val_accuracy: 0.8628000020980835\n",
      "units: 176 - 10112111111111111111211111111111111112111111111212121111213131122332213333223333323333333333333333333333333333334333333332333333333233333333333323333333333333333333333333333333\n",
      "After growing:\n",
      "loss: 0.32437533140182495 - accuracy: 0.8801166415214539 - val_loss: 0.38153690099716187 - val_accuracy: 0.8626000285148621\n",
      "units: 211 - 1011211111111111111121111111111111111211111111121212111121313112233221333322333332333333333333333333333333333333433333333233333333323333333333332333333333333333333333333333333344444444444444444444444444444444444\n",
      "Before pruning:\n",
      "loss: 0.3011392652988434 - accuracy: 0.8898500204086304 - val_loss: 0.3603646755218506 - val_accuracy: 0.8743000030517578\n",
      "units: 211 - 1011411111111111111141111111111111112414111211142212111141222144333221243432322333333433344333433434343343334244343433343333334333344334443433332334443333333333423433343333343443434243444333334433443443333243334\n",
      "After pruning:\n",
      "loss: 0.3011492192745209 - accuracy: 0.8898166418075562 - val_loss: 0.3603726923465729 - val_accuracy: 0.8741999864578247\n",
      "units: 158 - 10111111111111111111111111111111112111121112212111112221433322123323223333333333333333333332333333333333333333333323333333333332333333333333233333333333332333\n",
      "Epoch 6/20\n",
      "Before growing:\n",
      "loss: 0.3011492192745209 - accuracy: 0.8898166418075562 - val_loss: 0.3603726923465729 - val_accuracy: 0.8741999864578247\n",
      "units: 158 - 10111111111111111111111111111111112111121112212111112221433322123323223333333333333333333332333333333333333333333323333333333332333333333333233333333333332333\n",
      "After growing:\n",
      "loss: 0.30215054750442505 - accuracy: 0.8893166780471802 - val_loss: 0.3613685667514801 - val_accuracy: 0.8730000257492065\n",
      "units: 189 - 101111111111111111111111111111111121111211122121111122214333221233232233333333333333333333323333333333333333333333233333333333323333333333332333333333333323334444444444444444444444444444444\n",
      "Before pruning:\n",
      "loss: 0.2978155016899109 - accuracy: 0.8907333612442017 - val_loss: 0.3593088388442993 - val_accuracy: 0.8690999746322632\n",
      "units: 189 - 101111111111111111111111111111111142121211142141112223214433231444433433332344333343333333422433434333333424223343343323334343444422334233323343443442333343334343333333344433443444433433433\n",
      "After pruning:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.29783010482788086 - accuracy: 0.8907833099365234 - val_loss: 0.3593212366104126 - val_accuracy: 0.8690999746322632\n",
      "units: 142 - 1011111111111111111111111111111111212121112111122232133231333333233333333333322333333333222333333233333223323332333323333333333333333333333333\n",
      "Epoch 7/20\n",
      "Before growing:\n",
      "loss: 0.29783010482788086 - accuracy: 0.8907833099365234 - val_loss: 0.3593212366104126 - val_accuracy: 0.8690999746322632\n",
      "units: 142 - 1011111111111111111111111111111111212121112111122232133231333333233333333333322333333333222333333233333223323332333323333333333333333333333333\n",
      "After growing:\n",
      "loss: 0.29767563939094543 - accuracy: 0.8903833627700806 - val_loss: 0.3596833348274231 - val_accuracy: 0.8672000169754028\n",
      "units: 170 - 10111111111111111111111111111111112121211121111222321332313333332333333333333223333333332223333332333332233233323333233333333333333333333333334444444444444444444444444444\n",
      "Before pruning:\n",
      "loss: 0.2979072332382202 - accuracy: 0.8901833295822144 - val_loss: 0.36739298701286316 - val_accuracy: 0.871399998664856\n",
      "units: 170 - 10111111111111111111111101111111112141211142144422321332412443434332232323444344233334432344334334333342333344423343433433333343433344333344334334343343333333224443334233\n",
      "After pruning:\n",
      "loss: 0.2979086637496948 - accuracy: 0.8902000188827515 - val_loss: 0.3673951029777527 - val_accuracy: 0.871399998664856\n",
      "units: 128 - 10111111111111111111111101111111112112111212232133212333322323233233333233333333323333233333333333333333333333333333333322333233\n",
      "Epoch 8/20\n",
      "Before growing:\n",
      "loss: 0.2979086637496948 - accuracy: 0.8902000188827515 - val_loss: 0.3673951029777527 - val_accuracy: 0.871399998664856\n",
      "units: 128 - 10111111111111111111111101111111112112111212232133212333322323233233333233333333323333233333333333333333333333333333333322333233\n",
      "After growing:\n",
      "loss: 0.29439711570739746 - accuracy: 0.8918499946594238 - val_loss: 0.36391228437423706 - val_accuracy: 0.8695999979972839\n",
      "units: 153 - 101111111111111111111111011111111121121112122321332123333223232332333332333333333233332333333333333333333333333333333333223332334444444444444444444444444\n",
      "Before pruning:\n",
      "loss: 0.29261353611946106 - accuracy: 0.8930666446685791 - val_loss: 0.36495161056518555 - val_accuracy: 0.8694999814033508\n",
      "units: 153 - 001111111111111111111111112111111121121112122231344144334334232333333424333423333343333433422333433334333433342233344443443433232344333343334334344234334\n",
      "After pruning:\n",
      "loss: 0.2926127314567566 - accuracy: 0.8930500149726868 - val_loss: 0.3649502694606781 - val_accuracy: 0.8694999814033508\n",
      "units: 122 - 00111111111111111111111111211111112112111212223131333323233333323332333333333332233333333333332233333332323333333333432333\n",
      "Epoch 9/20\n",
      "Before growing:\n",
      "loss: 0.2926127314567566 - accuracy: 0.8930500149726868 - val_loss: 0.3649502694606781 - val_accuracy: 0.8694999814033508\n",
      "units: 122 - 00111111111111111111111111211111112112111212223131333323233333323332333333333332233333333333332233333332323333333333432333\n",
      "After growing:\n",
      "loss: 0.29226863384246826 - accuracy: 0.8932666778564453 - val_loss: 0.36479100584983826 - val_accuracy: 0.8708000183105469\n",
      "units: 146 - 00111111111111111111111111211111112112111212223131333323233333323332333333333332233333333333332233333332323333333333432333444444444444444444444444\n",
      "Before pruning:\n",
      "loss: 0.28879863023757935 - accuracy: 0.8946999907493591 - val_loss: 0.36492177844047546 - val_accuracy: 0.8719000220298767\n",
      "units: 146 - 00111111111411111111111101111111114114111313444141443444332243434343333343332334443343333344343434333334433334443343344434423333333442443333333443\n",
      "After pruning:\n",
      "loss: 0.2887960374355316 - accuracy: 0.8947333097457886 - val_loss: 0.3649196922779083 - val_accuracy: 0.8719000220298767\n",
      "units: 104 - 00111111111111111111111011111111141111131311333223333333333323333333333333333333333333323333333233333333\n",
      "Epoch 10/20\n",
      "Before growing:\n",
      "loss: 0.2887960374355316 - accuracy: 0.8947333097457886 - val_loss: 0.3649196922779083 - val_accuracy: 0.8719000220298767\n",
      "units: 104 - 00111111111111111111111011111111141111131311333223333333333323333333333333333333333333323333333233333333\n",
      "After growing:\n",
      "loss: 0.29105129837989807 - accuracy: 0.8937000036239624 - val_loss: 0.36694276332855225 - val_accuracy: 0.8705999851226807\n",
      "units: 124 - 0011111111111111111111101111111114111113131133322333333333332333333333333333333333333332333333323333333344444444444444444444\n",
      "Before pruning:\n",
      "loss: 0.28775936365127563 - accuracy: 0.8960166573524475 - val_loss: 0.36645087599754333 - val_accuracy: 0.8705000281333923\n",
      "units: 124 - 0011011111111111111111101212111114111112141144223344324334432342344332443243343443333444233334233433434442234342444334343333\n",
      "After pruning:\n",
      "loss: 0.28775912523269653 - accuracy: 0.8960166573524475 - val_loss: 0.3664524555206299 - val_accuracy: 0.8705000281333923\n",
      "units: 92 - 00110111111111111111111012121111111111211122333233323233323233333332333323333322343233343333\n",
      "Epoch 11/20\n",
      "Before growing:\n",
      "loss: 0.28775912523269653 - accuracy: 0.8960166573524475 - val_loss: 0.3664524555206299 - val_accuracy: 0.8705000281333923\n",
      "units: 92 - 00110111111111111111111012121111111111211122333233323233323233333332333323333322343233343333\n",
      "After growing:\n",
      "loss: 0.29503360390663147 - accuracy: 0.8930666446685791 - val_loss: 0.3745065927505493 - val_accuracy: 0.8677999973297119\n",
      "units: 110 - 00110111111111111111111012121111111111211122333233323233323233333332333323333322343233343333444444444444444444\n",
      "Before pruning:\n",
      "loss: 0.27892738580703735 - accuracy: 0.8970166444778442 - val_loss: 0.357136070728302 - val_accuracy: 0.8725000023841858\n",
      "units: 110 - 00100111101111111111111114121411111111211134323433434443343333443334443342334434433433433243433424243443244444\n",
      "After pruning:\n",
      "loss: 0.27892857789993286 - accuracy: 0.8970166444778442 - val_loss: 0.35713690519332886 - val_accuracy: 0.8725000023841858\n",
      "units: 78 - 001001111011111111111111112111111111211133233333333333333323333333433233322332\n",
      "Epoch 12/20\n",
      "Before growing:\n",
      "loss: 0.27892857789993286 - accuracy: 0.8970166444778442 - val_loss: 0.35713690519332886 - val_accuracy: 0.8725000023841858\n",
      "units: 78 - 001001111011111111111111112111111111211133233333333333333323333333433233322332\n",
      "After growing:\n",
      "loss: 0.2791285812854767 - accuracy: 0.8968833088874817 - val_loss: 0.3576692044734955 - val_accuracy: 0.871999979019165\n",
      "units: 93 - 001001111011111111111111112111111111211133233333333333333323333333433233322332444444444444444\n",
      "Before pruning:\n",
      "loss: 0.27172455191612244 - accuracy: 0.8984166383743286 - val_loss: 0.35504859685897827 - val_accuracy: 0.8733000159263611\n",
      "units: 93 - 001001111011111111111111112111114111411144224333342424432333333323433333444233432424243242423\n",
      "After pruning:\n",
      "loss: 0.27172476053237915 - accuracy: 0.8984166383743286 - val_loss: 0.3550490140914917 - val_accuracy: 0.8733000159263611\n",
      "units: 75 - 001001111011111111111111112111111111112233332232333333323333334233322232223\n",
      "Epoch 13/20\n",
      "Before growing:\n",
      "loss: 0.27172476053237915 - accuracy: 0.8984166383743286 - val_loss: 0.3550490140914917 - val_accuracy: 0.8733000159263611\n",
      "units: 75 - 001001111011111111111111112111111111112233332232333333323333334233322232223\n",
      "After growing:\n",
      "loss: 0.27473074197769165 - accuracy: 0.8974833488464355 - val_loss: 0.3574348986148834 - val_accuracy: 0.8733000159263611\n",
      "units: 90 - 001001111011111111111111112111111111112233332232333333323333334233322232223444444444444444\n",
      "Before pruning:\n",
      "loss: 0.30025652050971985 - accuracy: 0.8899333477020264 - val_loss: 0.3873913884162903 - val_accuracy: 0.8637999892234802\n",
      "units: 90 - 001001111011011111111111112111111111114332432422444444433233334342423343244242322444444343\n",
      "After pruning:\n",
      "loss: 0.30025675892829895 - accuracy: 0.8899333477020264 - val_loss: 0.3873916268348694 - val_accuracy: 0.8637999892234802\n",
      "units: 67 - 0010011110110111111111111121111111111133232223323333322333222322433\n",
      "Epoch 14/20\n",
      "Before growing:\n",
      "loss: 0.30025675892829895 - accuracy: 0.8899333477020264 - val_loss: 0.3873916268348694 - val_accuracy: 0.8637999892234802\n",
      "units: 67 - 0010011110110111111111111121111111111133232223323333322333222322433\n",
      "After growing:\n",
      "loss: 0.3114149272441864 - accuracy: 0.8850833177566528 - val_loss: 0.3980800211429596 - val_accuracy: 0.8597999811172485\n",
      "units: 80 - 00100111101101111111111111211111111111332322233233333223332223224334444444444444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before pruning:\n",
      "loss: 0.27381640672683716 - accuracy: 0.8989666700363159 - val_loss: 0.3640250563621521 - val_accuracy: 0.8736000061035156\n",
      "units: 80 - 00000111101101111111112111411111111111324423342422443244233224242442323334232423\n",
      "After pruning:\n",
      "loss: 0.27381640672683716 - accuracy: 0.8989666700363159 - val_loss: 0.3640250563621521 - val_accuracy: 0.8736000061035156\n",
      "units: 67 - 0000011110110111111111211111111111111322332223223322224423233323223\n",
      "Epoch 15/20\n",
      "Before growing:\n",
      "loss: 0.27381640672683716 - accuracy: 0.8989666700363159 - val_loss: 0.3640250563621521 - val_accuracy: 0.8736000061035156\n",
      "units: 67 - 0000011110110111111111211111111111111322332223223322224423233323223\n",
      "After growing:\n",
      "loss: 0.27821439504623413 - accuracy: 0.8970666527748108 - val_loss: 0.36789897084236145 - val_accuracy: 0.870199978351593\n",
      "units: 80 - 00000111101101111111112111111111111113223322232233222244232333232234444444444444\n",
      "Before pruning:\n",
      "loss: 0.2658196985721588 - accuracy: 0.9023000001907349 - val_loss: 0.3594515025615692 - val_accuracy: 0.8762000203132629\n",
      "units: 80 - 00000111101401111111113111111111111114232232443242234433343422324234332222332333\n",
      "After pruning:\n",
      "loss: 0.2658196985721588 - accuracy: 0.9023000001907349 - val_loss: 0.35945144295692444 - val_accuracy: 0.8762000203132629\n",
      "units: 70 - 0000011110101111111113111111111111112322323222333334223223332222332333\n",
      "Epoch 16/20\n",
      "Before growing:\n",
      "loss: 0.2658196985721588 - accuracy: 0.9023000001907349 - val_loss: 0.35945144295692444 - val_accuracy: 0.8762000203132629\n",
      "units: 70 - 0000011110101111111113111111111111112322323222333334223223332222332333\n",
      "After growing:\n",
      "loss: 0.2704366147518158 - accuracy: 0.8995500206947327 - val_loss: 0.3634836971759796 - val_accuracy: 0.8737000226974487\n",
      "units: 84 - 000001111010111111111311111111111111232232322233333422322333222233233344444444444444\n",
      "Before pruning:\n",
      "loss: 0.2664521038532257 - accuracy: 0.8999500274658203 - val_loss: 0.3631449341773987 - val_accuracy: 0.8738999962806702\n",
      "units: 84 - 000001111010110111111211112111111111322444422343443434422332433434424322423433424332\n",
      "After pruning:\n",
      "loss: 0.2664497494697571 - accuracy: 0.8999500274658203 - val_loss: 0.3631426692008972 - val_accuracy: 0.8738999962806702\n",
      "units: 66 - 000001111010110111111211112111111111322223333223323332322423332332\n",
      "Epoch 17/20\n",
      "Before growing:\n",
      "loss: 0.2664497494697571 - accuracy: 0.8999500274658203 - val_loss: 0.3631426692008972 - val_accuracy: 0.8738999962806702\n",
      "units: 66 - 000001111010110111111211112111111111322223333223323332322423332332\n",
      "After growing:\n",
      "loss: 0.26477935910224915 - accuracy: 0.900433361530304 - val_loss: 0.36212214827537537 - val_accuracy: 0.8745999932289124\n",
      "units: 79 - 0000011110101101111112111121111111113222233332233233323224233323324444444444444\n",
      "Before pruning:\n",
      "loss: 0.27522334456443787 - accuracy: 0.8991666436195374 - val_loss: 0.3694075644016266 - val_accuracy: 0.8723000288009644\n",
      "units: 79 - 0000011110100101111014111121111111122333423243342234443423323244422443343232324\n",
      "After pruning:\n",
      "loss: 0.2752367854118347 - accuracy: 0.899150013923645 - val_loss: 0.36942294239997864 - val_accuracy: 0.8723000288009644\n",
      "units: 65 - 00000111101001011110111112111111112233323233223323323242233323232\n",
      "Epoch 18/20\n",
      "Before growing:\n",
      "loss: 0.2752367854118347 - accuracy: 0.899150013923645 - val_loss: 0.36942294239997864 - val_accuracy: 0.8723000288009644\n",
      "units: 65 - 00000111101001011110111112111111112233323233223323323242233323232\n",
      "After growing:\n",
      "loss: 0.2748434841632843 - accuracy: 0.8985000252723694 - val_loss: 0.36991292238235474 - val_accuracy: 0.8733999729156494\n",
      "units: 78 - 000001111010010111101111121111111122333232332233233232422333232324444444444444\n",
      "Before pruning:\n",
      "loss: 0.2691507935523987 - accuracy: 0.8993333578109741 - val_loss: 0.37085428833961487 - val_accuracy: 0.8727999925613403\n",
      "units: 78 - 000001111011010111100111121011111144443442433324233343432242423334243424222242\n",
      "After pruning:\n",
      "loss: 0.2691511809825897 - accuracy: 0.8993333578109741 - val_loss: 0.37085390090942383 - val_accuracy: 0.8727999925613403\n",
      "units: 61 - 0000011110110101111001111210111111323332233333222233323222222\n",
      "Epoch 19/20\n",
      "Before growing:\n",
      "loss: 0.2691511809825897 - accuracy: 0.8993333578109741 - val_loss: 0.37085390090942383 - val_accuracy: 0.8727999925613403\n",
      "units: 61 - 0000011110110101111001111210111111323332233333222233323222222\n",
      "After growing:\n",
      "loss: 0.26949048042297363 - accuracy: 0.8987666964530945 - val_loss: 0.37074393033981323 - val_accuracy: 0.8715000152587891\n",
      "units: 73 - 0000011110110101111001111210111111323332233333222233323222222444444444444\n",
      "Before pruning:\n",
      "loss: 0.26421791315078735 - accuracy: 0.9017500281333923 - val_loss: 0.37053754925727844 - val_accuracy: 0.8715999722480774\n",
      "units: 73 - 0000001110100101111001111210113111422324443432344334422344242222334324242\n",
      "After pruning:\n",
      "loss: 0.26421788334846497 - accuracy: 0.9017500281333923 - val_loss: 0.37053754925727844 - val_accuracy: 0.8715999722480774\n",
      "units: 58 - 0000001110100101111001111210113111223233233322322222333222\n",
      "Epoch 20/20\n",
      "Before growing:\n",
      "loss: 0.26421788334846497 - accuracy: 0.9017500281333923 - val_loss: 0.37053754925727844 - val_accuracy: 0.8715999722480774\n",
      "units: 58 - 0000001110100101111001111210113111223233233322322222333222\n",
      "After growing:\n",
      "loss: 0.26399797201156616 - accuracy: 0.9015499949455261 - val_loss: 0.37023261189460754 - val_accuracy: 0.8712000250816345\n",
      "units: 69 - 000000111010010111100111121011311122323323332232222233322244444444444\n",
      "Before pruning:\n",
      "loss: 0.27027931809425354 - accuracy: 0.8989499807357788 - val_loss: 0.37591537833213806 - val_accuracy: 0.8701000213623047\n",
      "units: 69 - 000000111010011110100111141111211124344344234423324344443444444224324\n",
      "After pruning:\n",
      "loss: 0.27027955651283264 - accuracy: 0.8989499807357788 - val_loss: 0.37591543793678284 - val_accuracy: 0.8701000213623047\n",
      "units: 49 - 0000001110100111101001111411112111233232332332232\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "model = SSModel(units=200, activation='relu', l1=0.000001, kernel_initializer='he_normal')\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "train_model(model, optimizer, epochs, batch_size, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation='relu', kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax', kernel_initializer='he_normal')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.6934 - accuracy: 0.7661 - val_loss: 0.4622 - val_accuracy: 0.8381\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4254 - accuracy: 0.8513 - val_loss: 0.4326 - val_accuracy: 0.8507\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3777 - accuracy: 0.8659 - val_loss: 0.4079 - val_accuracy: 0.8546\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3489 - accuracy: 0.8762 - val_loss: 0.3977 - val_accuracy: 0.8587\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3324 - accuracy: 0.8804 - val_loss: 0.3927 - val_accuracy: 0.8616\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3169 - accuracy: 0.8833 - val_loss: 0.3703 - val_accuracy: 0.8692\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3031 - accuracy: 0.8895 - val_loss: 0.3712 - val_accuracy: 0.8697\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2948 - accuracy: 0.8910 - val_loss: 0.3685 - val_accuracy: 0.8683\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2869 - accuracy: 0.8947 - val_loss: 0.3655 - val_accuracy: 0.8691\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2743 - accuracy: 0.8981 - val_loss: 0.3550 - val_accuracy: 0.8739\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2689 - accuracy: 0.9012 - val_loss: 0.3561 - val_accuracy: 0.8776\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2638 - accuracy: 0.9038 - val_loss: 0.3510 - val_accuracy: 0.8756\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2609 - accuracy: 0.9044 - val_loss: 0.3506 - val_accuracy: 0.8737\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2503 - accuracy: 0.9083 - val_loss: 0.3503 - val_accuracy: 0.8785\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2482 - accuracy: 0.9083 - val_loss: 0.3517 - val_accuracy: 0.8758\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2432 - accuracy: 0.9084 - val_loss: 0.3579 - val_accuracy: 0.8799\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2368 - accuracy: 0.9138 - val_loss: 0.3648 - val_accuracy: 0.8756\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2343 - accuracy: 0.9137 - val_loss: 0.3619 - val_accuracy: 0.8755\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2295 - accuracy: 0.9163 - val_loss: 0.3527 - val_accuracy: 0.8784\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2257 - accuracy: 0.9152 - val_loss: 0.3613 - val_accuracy: 0.8748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5317706a60>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
