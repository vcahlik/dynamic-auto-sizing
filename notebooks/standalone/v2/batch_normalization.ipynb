{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23284cdb-b6aa-41da-a0d5-c140938079c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 28 14:15:54 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  On   | 00000000:01:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    53W / 275W |      3MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM...  On   | 00000000:47:00.0 Off |                    0 |\n",
      "| N/A   36C    P0    55W / 275W |  16426MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    52W / 275W |      3MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA DGX Display  On   | 00000000:C1:00.0 Off |                  N/A |\n",
      "| 33%   35C    P8    N/A /  50W |     13MiB /  3911MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA A100-SXM...  On   | 00000000:C2:00.0 Off |                    0 |\n",
      "| N/A   36C    P0    55W / 275W |      3MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    1   N/A  N/A    356922      C   Unknown Error                   16397MiB |\n",
      "|    3   N/A  N/A      4983      G   Unknown Error                       9MiB |\n",
      "|    3   N/A  N/A      5295      G   Unknown Error                       2MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f992d9a1-faa6-45b6-acf8-facb1a4a606e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-28 14:15:58.945624: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-28 14:15:59.301037: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-28 14:16:00.192978: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-28 14:16:00.193095: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-28 14:16:00.193102: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from enum import Enum\n",
    "import imageio\n",
    "import os\n",
    "import hashlib\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "dtype = 'float32'\n",
    "tf.keras.backend.set_floatx(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d775242d-75c7-4266-9de3-0d351ca3ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### datasets.py\n",
    "\n",
    "def get_dataset_sample(X, y, fraction, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)  # Set random seed\n",
    "    selection = np.random.choice([True, False], len(X), p=[fraction, 1 - fraction])\n",
    "    if seed is not None:\n",
    "        np.random.seed()  # Unset random seed\n",
    "    X_sampled = X[selection]\n",
    "    y_sampled = y[selection]\n",
    "    return X_sampled, y_sampled\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, X_train, y_train, X_test, y_test, shape, shape_flattened, fraction, vision=True,\n",
    "                 standardize=True):\n",
    "        if fraction is not None:\n",
    "            X_train, y_train = get_dataset_sample(X_train, y_train, fraction, seed=42)\n",
    "            X_test, y_test = get_dataset_sample(X_test, y_test, fraction, seed=42)\n",
    "\n",
    "        X_train = X_train.astype(dtype)\n",
    "        y_train = y_train.astype(dtype)\n",
    "        X_test = X_test.astype(dtype)\n",
    "        y_test = y_test.astype(dtype)\n",
    "\n",
    "        if vision:\n",
    "            X_train = X_train / 255.0\n",
    "            X_test = X_test / 255.0\n",
    "\n",
    "        X_train = np.reshape(X_train, shape_flattened)\n",
    "        X_test = np.reshape(X_test, shape_flattened)\n",
    "\n",
    "        X = np.concatenate((X_train, X_test), axis=0)\n",
    "        y = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "        if standardize:\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(X_train)  # Scaling each feature independently\n",
    "\n",
    "            X_norm = scaler.transform(X)\n",
    "            del X\n",
    "            X_train_norm = scaler.transform(X_train)\n",
    "            del X_train\n",
    "            X_test_norm = scaler.transform(X_test)\n",
    "            del X_test\n",
    "        else:\n",
    "            X_norm = X\n",
    "            X_train_norm = X_train\n",
    "            X_test_norm = X_test\n",
    "\n",
    "        X_norm = np.reshape(X_norm, shape)\n",
    "        X_train_norm = np.reshape(X_train_norm, shape)\n",
    "        X_test_norm = np.reshape(X_test_norm, shape)\n",
    "\n",
    "        # Shuffle X_norm and y\n",
    "        assert len(X_norm) == len(y)\n",
    "        p = np.random.permutation(len(X_norm))\n",
    "        X_norm, y = X_norm[p], y[p]\n",
    "\n",
    "        self.X_norm = X_norm\n",
    "        self.y = y\n",
    "        self.X_train_norm = X_train_norm\n",
    "        self.y_train = y_train\n",
    "        self.X_test_norm = X_test_norm\n",
    "        self.y_test = y_test\n",
    "\n",
    "\n",
    "def get_cifar_10_dataset(fraction=None):\n",
    "    cifar10 = tf.keras.datasets.cifar10\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "    shape = (-1, 32, 32, 3)\n",
    "    shape_flattened = (-1, 3072)  # Scaling each feature independently\n",
    "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened, fraction=fraction)\n",
    "\n",
    "\n",
    "def get_cifar_100_dataset(fraction=None):\n",
    "    cifar100 = tf.keras.datasets.cifar100\n",
    "    (X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
    "    shape = (-1, 32, 32, 3)\n",
    "    shape_flattened = (-1, 3072)  # Scaling each feature independently\n",
    "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened, fraction=fraction)\n",
    "\n",
    "\n",
    "def get_svhn_dataset(fraction=None):\n",
    "    from urllib.request import urlretrieve\n",
    "    from scipy import io\n",
    "\n",
    "    train_filename, _ = urlretrieve('http://ufldl.stanford.edu/housenumbers/train_32x32.mat')\n",
    "    test_filename, _ = urlretrieve('http://ufldl.stanford.edu/housenumbers/test_32x32.mat')\n",
    "\n",
    "    X_train = io.loadmat(train_filename, variable_names='X').get('X')\n",
    "    y_train = io.loadmat(train_filename, variable_names='y').get('y')\n",
    "    X_test = io.loadmat(test_filename, variable_names='X').get('X')\n",
    "    y_test = io.loadmat(test_filename, variable_names='y').get('y')\n",
    "\n",
    "    X_train = np.moveaxis(X_train, -1, 0)\n",
    "    y_train -= 1\n",
    "    X_test = np.moveaxis(X_test, -1, 0)\n",
    "    y_test -= 1\n",
    "\n",
    "    shape = (-1, 32, 32, 3)\n",
    "    shape_flattened = (-1, 3072)  # Scaling each feature independently\n",
    "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened, fraction=fraction)\n",
    "\n",
    "\n",
    "def get_tiny_imagenet_dataset(fraction=None):\n",
    "    \"\"\"\n",
    "    Original source: https://github.com/sonugiri1043/Train_ResNet_On_Tiny_ImageNet/blob/master/Train_ResNet_On_Tiny_ImageNet.ipynb\n",
    "    Original author: sonugiri1043@gmail.com\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.isdir('IMagenet'):\n",
    "        os.system('git clone https://github.com/seshuad/IMagenet')\n",
    "\n",
    "    print(\"Processing the downloaded dataset...\")\n",
    "\n",
    "    path = 'IMagenet/tiny-imagenet-200/'\n",
    "\n",
    "    id_dict = {}\n",
    "    for i, line in enumerate(open(path + 'wnids.txt', 'r')):\n",
    "        id_dict[line.replace('\\n', '')] = i\n",
    "\n",
    "    train_data = list()\n",
    "    test_data = list()\n",
    "    train_labels = list()\n",
    "    test_labels = list()\n",
    "\n",
    "    for key, value in id_dict.items():\n",
    "        train_data += [imageio.imread(path + 'train/{}/images/{}_{}.JPEG'.format(key, key, str(i)), pilmode='RGB') for i\n",
    "                       in range(500)]\n",
    "        train_labels_ = np.array([[0] * 200] * 500)\n",
    "        train_labels_[:, value] = 1\n",
    "        train_labels += train_labels_.tolist()\n",
    "\n",
    "    X_train = np.array(train_data)\n",
    "    X_test = np.array(test_data)\n",
    "    del train_data, train_labels_\n",
    "\n",
    "    for line in open(path + 'val/val_annotations.txt'):\n",
    "        img_name, class_id = line.split('\\t')[:2]\n",
    "        test_data.append(imageio.imread(path + 'val/images/{}'.format(img_name), pilmode='RGB'))\n",
    "        test_labels_ = np.array([[0] * 200])\n",
    "        test_labels_[0, id_dict[class_id]] = 1\n",
    "        test_labels += test_labels_.tolist()\n",
    "\n",
    "    y_train = np.argmax(np.array(train_labels), axis=1)\n",
    "    y_test = np.argmax(np.array(test_labels), axis=1)\n",
    "    del train_labels\n",
    "    del test_data, test_labels_, test_labels\n",
    "\n",
    "    shape = (-1, 64, 64, 3)\n",
    "    shape_flattened = (-1, 12288)  # Scaling each feature independently\n",
    "    print(\"Calling Dataset()\")\n",
    "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened, fraction=fraction)\n",
    "\n",
    "\n",
    "def get_mnist_dataset(fraction=None):\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    shape = (-1, 28, 28, 1)\n",
    "    shape_flattened = (-1, 1)  # Scaling all features together\n",
    "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened, fraction=fraction)\n",
    "\n",
    "\n",
    "def get_fashion_mnist_dataset(fraction=None):\n",
    "    fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "    (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "    shape = (-1, 28, 28, 1)\n",
    "    shape_flattened = (-1, 1)  # Scaling all features together\n",
    "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened, fraction=fraction)\n",
    "\n",
    "\n",
    "def get_fifteen_puzzle_dataset(path=None, fraction=None):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    if path is None:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/gdrive')\n",
    "        path = 'gdrive/MyDrive/15-costs-v3.csv'\n",
    "    costs = pd.read_csv(path)\n",
    "    costs = costs.sample(frac=fraction, random_state=42)\n",
    "\n",
    "    X_raw = costs.iloc[:, :-1].values\n",
    "    y = costs['cost'].values\n",
    "    X = np.apply_along_axis(lambda x: np.eye(16)[x].ravel(), 1, X_raw)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    del X, X_raw, y\n",
    "\n",
    "    shape = (-1, 256)\n",
    "    shape_flattened = (-1, 256)  # Scaling all features together\n",
    "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened, vision=False,\n",
    "                   fraction=None)\n",
    "\n",
    "##### models.py\n",
    "\n",
    "dtype = 'float32'\n",
    "tf.keras.backend.set_floatx(dtype)\n",
    "\n",
    "\n",
    "class Regularizer(tf.keras.regularizers.Regularizer):\n",
    "    def __init__(self):\n",
    "        self.n_new_neurons = 0\n",
    "        self.scaling_tensor = None\n",
    "        self.set_regularization_penalty(0.)\n",
    "        self.set_regularization_method(None)\n",
    "\n",
    "    def copy(self):\n",
    "        regularizer_copy = Regularizer.__new__(Regularizer)\n",
    "        regularizer_copy.n_new_neurons = self.n_new_neurons\n",
    "        regularizer_copy.scaling_tensor = self.scaling_tensor\n",
    "        regularizer_copy.set_regularization_penalty(self.regularization_penalty)\n",
    "        regularizer_copy.set_regularization_method(self.regularization_method)\n",
    "        return regularizer_copy\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if self.regularization_method is None or self.regularization_penalty == 0:\n",
    "            return 0\n",
    "        elif self.regularization_method == 'weighted_l1':\n",
    "            return self.weighted_l1(x)\n",
    "        elif self.regularization_method == 'weighted_l1_reordered':\n",
    "            return self.weighted_l1_reordered(x)\n",
    "        elif self.regularization_method == 'group_sparsity':\n",
    "            return self.group_sparsity(x)\n",
    "        elif self.regularization_method == 'l1':\n",
    "            return self.l1(x)\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Unknown regularization method {self.regularization_method}\")\n",
    "\n",
    "    def weighted_l1(self, x):\n",
    "        # I.e. for a parameter matrix of 4 input and 10 output neurons:\n",
    "        #\n",
    "        # [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]\n",
    "        #\n",
    "        # the scaling tensor, as well as the resulting weighted values, could be:\n",
    "        #\n",
    "        # [[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
    "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
    "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
    "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]\n",
    "        #\n",
    "        # Therefore every additional output neuron is regularized more.\n",
    "\n",
    "        scaling_tensor = tf.cumsum(tf.constant(self.regularization_penalty, shape=x.shape, dtype=dtype), axis=-1)\n",
    "        weighted_values = scaling_tensor * tf.abs(x)\n",
    "        return tf.reduce_sum(weighted_values)\n",
    "\n",
    "    def weighted_l1_reordered(self, x):\n",
    "        if self.update_scaling_tensor:\n",
    "            scaling_tensor_raw = tf.cumsum(tf.constant(self.regularization_penalty, shape=x.shape, dtype=dtype),\n",
    "                                           axis=-1)\n",
    "\n",
    "            scaling_tensor_old_neurons = scaling_tensor_raw[:, :-self.n_new_neurons]\n",
    "            scaling_tensor_new_neurons = scaling_tensor_raw[:, -self.n_new_neurons:]\n",
    "            scaling_tensor_old_neurons_shuffled = tf.transpose(\n",
    "                tf.random.shuffle(tf.transpose(scaling_tensor_old_neurons)))\n",
    "            self.scaling_tensor = tf.concat([scaling_tensor_old_neurons_shuffled, scaling_tensor_new_neurons], axis=-1)\n",
    "            self.update_scaling_tensor = False\n",
    "\n",
    "        weighted_values = self.scaling_tensor * tf.abs(x)\n",
    "        return tf.reduce_sum(weighted_values)\n",
    "\n",
    "    def group_sparsity(self, x):\n",
    "        # I.e. for a parameter matrix of 3 input and 5 output neurons:\n",
    "        #\n",
    "        # [[1., 1., 1., 1., 1.],\n",
    "        #  [1., 2., 2., 1., 2.],\n",
    "        #  [2., 2., 3., 1., 3.]]\n",
    "        #\n",
    "        # The resulting vector of group norms is [2., 2., 3., 1., 3.], therefore for\n",
    "        # every output neuron, its incoming connections form a group.\n",
    "\n",
    "        group_norms = tf.norm(x, ord=2, axis=0)\n",
    "        # assert group_norms.shape[0] == x.shape[1]\n",
    "        return self.regularization_penalty * tf.reduce_sum(group_norms)\n",
    "\n",
    "    def l1(self, x):\n",
    "        weighted_values = self.regularization_penalty * tf.abs(x)\n",
    "        return tf.reduce_sum(weighted_values)\n",
    "\n",
    "    def prune(self):\n",
    "        self.n_new_neurons = 0\n",
    "        if self.regularization_method == 'weighted_l1_reordered':\n",
    "            self.update_scaling_tensor = True\n",
    "\n",
    "    def grow(self, n_new_neurons):\n",
    "        self.n_new_neurons = n_new_neurons\n",
    "        if self.regularization_method == 'weighted_l1_reordered':\n",
    "            self.update_scaling_tensor = True\n",
    "\n",
    "    def set_regularization_penalty(self, regularization_penalty):\n",
    "        self.regularization_penalty = regularization_penalty\n",
    "\n",
    "    def set_regularization_method(self, regularization_method):\n",
    "        self.regularization_method = regularization_method\n",
    "        if self.regularization_method == 'weighted_l1_reordered':\n",
    "            self.update_scaling_tensor = True\n",
    "        else:\n",
    "            self.update_scaling_tensor = None\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'regularization_penalty': float(self.regularization_penalty)}\n",
    "\n",
    "\n",
    "class DASLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_shape, fixed_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self._input_shape = input_shape\n",
    "        self.fixed_size = fixed_size\n",
    "        self._built = False\n",
    "\n",
    "\n",
    "class Dense(DASLayer):\n",
    "    def __init__(self, units, activation, kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros', input_shape=None, fixed_size=False,\n",
    "                 regularizer=None):\n",
    "        super().__init__(input_shape, fixed_size)\n",
    "\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.bias_initializer = bias_initializer\n",
    "\n",
    "        self.A = tf.keras.activations.get(activation)\n",
    "        self.W_init = tf.keras.initializers.get(kernel_initializer)\n",
    "        self.b_init = tf.keras.initializers.get(bias_initializer)\n",
    "        if regularizer is not None:\n",
    "            self.regularizer = regularizer\n",
    "        else:\n",
    "            self.regularizer = Regularizer()\n",
    "\n",
    "    def copy(self):\n",
    "        layer_copy = Dense.__new__(Dense)\n",
    "        super(Dense, layer_copy).__init__(self._input_shape)\n",
    "\n",
    "        layer_copy.units = self.units\n",
    "        layer_copy.activation = self.activation\n",
    "        layer_copy.kernel_initializer = self.kernel_initializer\n",
    "        layer_copy.bias_initializer = self.bias_initializer\n",
    "        layer_copy.fixed_size = self.fixed_size\n",
    "\n",
    "        layer_copy.A = self.A\n",
    "        layer_copy.W_init = self.W_init\n",
    "        layer_copy.b_init = self.b_init\n",
    "        layer_copy.regularizer = self.regularizer.copy()\n",
    "\n",
    "        layer_copy.W = tf.Variable(\n",
    "            name='W',\n",
    "            initial_value=self.W,\n",
    "            trainable=True)\n",
    "\n",
    "        layer_copy.b = tf.Variable(\n",
    "            name='b',\n",
    "            initial_value=self.b,\n",
    "            trainable=True)\n",
    "\n",
    "        layer_copy.add_regularizer_loss()\n",
    "\n",
    "        layer_copy._built = True\n",
    "        return layer_copy\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self._built:\n",
    "            return\n",
    "\n",
    "        input_units = input_shape[-1]\n",
    "\n",
    "        self.W = tf.Variable(\n",
    "            name='W',\n",
    "            initial_value=self.W_init(shape=(input_units, self.units), dtype=dtype),\n",
    "            trainable=True)\n",
    "\n",
    "        self.b = tf.Variable(\n",
    "            name='b',\n",
    "            initial_value=self.b_init(shape=(self.units,), dtype=dtype),\n",
    "            trainable=True)\n",
    "\n",
    "        self.add_regularizer_loss()\n",
    "\n",
    "        self._built = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        return self.A(tf.matmul(inputs, self.W) + self.b)\n",
    "\n",
    "    def add_regularizer_loss(self):\n",
    "        self.add_loss(lambda: self.regularizer(tf.concat([self.W, tf.reshape(self.b, (1, -1))], axis=0)))\n",
    "\n",
    "    def get_size(self):\n",
    "        return self.W.shape[0], self.W.shape[1]\n",
    "\n",
    "    def prune(self, threshold, active_input_units_indices):\n",
    "        # Remove connections from pruned units in previous layer\n",
    "        new_W = tf.gather(self.W.value(), active_input_units_indices, axis=0)\n",
    "\n",
    "        if self.fixed_size:\n",
    "            active_output_neurons_indices = list(range(new_W.shape[1]))\n",
    "        else:\n",
    "            # Prune units in this layer\n",
    "            weights_with_biases = tf.concat([new_W, tf.reshape(self.b.value(), (1, -1))], axis=0)\n",
    "            neurons_are_active = tf.math.reduce_max(tf.abs(weights_with_biases), axis=0) >= threshold\n",
    "            active_output_neurons_indices = tf.reshape(tf.where(neurons_are_active), (-1,))\n",
    "\n",
    "            new_W = tf.gather(new_W, active_output_neurons_indices, axis=1)\n",
    "            new_b = tf.gather(self.b.value(), active_output_neurons_indices, axis=0)\n",
    "\n",
    "            self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
    "\n",
    "        self.W = tf.Variable(name='W', initial_value=new_W, trainable=True)\n",
    "\n",
    "        self.regularizer.prune()\n",
    "        return active_output_neurons_indices\n",
    "\n",
    "    def grow(self, n_new_input_units, percentage, min_new_units, scaling_factor):\n",
    "        if n_new_input_units > 0:\n",
    "            # Add connections to grown units in previous layer\n",
    "            W_growth = self.W_init(shape=(self.W.shape[0] + n_new_input_units, self.W.shape[1]), dtype=dtype)[\n",
    "                       -n_new_input_units:,\n",
    "                       :] * scaling_factor  # TODO is it better to be multiplying here by scaling_factor? It does help with not increasing the max weights of existing neurons when new neurons are added.\n",
    "            new_W = tf.concat([self.W.value(), W_growth], axis=0)\n",
    "        else:\n",
    "            new_W = self.W.value()\n",
    "\n",
    "        if self.fixed_size:\n",
    "            n_new_output_units = 0\n",
    "        else:\n",
    "            # Grow new units in this layer\n",
    "            n_new_output_units = max(min_new_units, int(new_W.shape[1] * percentage))\n",
    "            if n_new_output_units > 0:\n",
    "                W_growth = self.W_init(shape=(new_W.shape[0], new_W.shape[1] + n_new_output_units), dtype=dtype)[:,\n",
    "                           -n_new_output_units:] * scaling_factor\n",
    "                b_growth = self.b_init(shape=(n_new_output_units,),\n",
    "                                       dtype=dtype)  # TODO for all possible bias initializers to work properly, the whole bias vector should be initialized at once\n",
    "                new_W = tf.concat([new_W, W_growth], axis=1)\n",
    "                new_b = tf.concat([self.b.value(), b_growth], axis=0)\n",
    "\n",
    "                self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
    "\n",
    "        self.W = tf.Variable(name='W', initial_value=new_W, trainable=True)\n",
    "\n",
    "        self.regularizer.grow(n_new_output_units)\n",
    "        return n_new_output_units\n",
    "\n",
    "    def mutate(self, mutation_strength):\n",
    "        self.W.assign_add(tf.random.normal(self.W.shape, mean=0.0, stddev=mutation_strength))\n",
    "        self.b.assign_add(tf.random.normal(self.b.shape, mean=0.0, stddev=mutation_strength))\n",
    "\n",
    "    def set_regularization_penalty(self, regularization_penalty):\n",
    "        if not self.fixed_size:\n",
    "            self.regularizer.set_regularization_penalty(regularization_penalty)\n",
    "\n",
    "    def set_regularization_method(self, regularization_method):\n",
    "        if not self.fixed_size:\n",
    "            self.regularizer.set_regularization_method(regularization_method)\n",
    "\n",
    "    def get_param_string(self):\n",
    "        param_string = \"\"\n",
    "        weights_with_bias = tf.concat([self.W, tf.reshape(self.b, (1, -1))], axis=0)\n",
    "        max_parameters = tf.math.reduce_max(tf.abs(weights_with_bias), axis=0).numpy()\n",
    "        magnitudes = np.floor(np.log10(max_parameters))\n",
    "        for m in magnitudes:\n",
    "            if m > 0:\n",
    "                m = 0\n",
    "            param_string += str(int(-m))\n",
    "        return param_string\n",
    "\n",
    "\n",
    "class Conv2D(DASLayer):\n",
    "    def __init__(self, filters, filter_size, activation, strides=(1, 1),\n",
    "                 padding='SAME', kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros', input_shape=None, fixed_size=False,\n",
    "                 regularizer=None):\n",
    "        super().__init__(input_shape, fixed_size)\n",
    "\n",
    "        self.filters = filters\n",
    "        self.filter_size = filter_size\n",
    "        self.activation = activation\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.bias_initializer = bias_initializer\n",
    "\n",
    "        self.A = tf.keras.activations.get(activation)\n",
    "        self.F_init = tf.keras.initializers.get(kernel_initializer)\n",
    "        self.b_init = tf.keras.initializers.get(bias_initializer)\n",
    "        if regularizer is not None:\n",
    "            self.regularizer = regularizer\n",
    "        else:\n",
    "            self.regularizer = Regularizer()\n",
    "\n",
    "    def copy(self):\n",
    "        layer_copy = Conv2D.__new__(Conv2D)\n",
    "        super(Conv2D, layer_copy).__init__(self._input_shape)\n",
    "\n",
    "        layer_copy.filters = self.filters\n",
    "        layer_copy.filter_size = self.filter_size\n",
    "        layer_copy.activation = self.activation\n",
    "        layer_copy.strides = self.strides\n",
    "        layer_copy.padding = self.padding\n",
    "        layer_copy.kernel_initializer = self.kernel_initializer\n",
    "        layer_copy.bias_initializer = self.bias_initializer\n",
    "        layer_copy.fixed_size = self.fixed_size\n",
    "\n",
    "        layer_copy.A = self.A\n",
    "        layer_copy.F_init = self.F_init\n",
    "        layer_copy.b_init = self.b_init\n",
    "        layer_copy.regularizer = self.regularizer.copy()\n",
    "\n",
    "        layer_copy.F = tf.Variable(\n",
    "            name='F',\n",
    "            initial_value=self.F,\n",
    "            trainable=True)\n",
    "\n",
    "        layer_copy.b = tf.Variable(\n",
    "            name='b',\n",
    "            initial_value=self.b,\n",
    "            trainable=True)\n",
    "\n",
    "        layer_copy.add_regularizer_loss()\n",
    "\n",
    "        layer_copy._built = True\n",
    "        return layer_copy\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self._built:\n",
    "            return\n",
    "\n",
    "        input_filters = input_shape[-1]\n",
    "\n",
    "        self.F = tf.Variable(\n",
    "            name='F',\n",
    "            initial_value=self.F_init(\n",
    "                shape=(self.filter_size[0], self.filter_size[1], input_filters, self.filters), dtype=dtype\n",
    "            ),\n",
    "            trainable=True)\n",
    "\n",
    "        self.b = tf.Variable(\n",
    "            name='b',\n",
    "            initial_value=self.b_init(shape=(self.filters,), dtype=dtype),\n",
    "            trainable=True)\n",
    "\n",
    "        self.add_regularizer_loss()\n",
    "\n",
    "        self._built = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        y = tf.nn.conv2d(inputs, self.F, strides=self.strides, padding=self.padding)\n",
    "        y = tf.nn.bias_add(y, self.b)\n",
    "        y = self.A(y)\n",
    "        return y\n",
    "\n",
    "    def add_regularizer_loss(self):\n",
    "        self.add_loss(lambda: self.regularizer(\n",
    "            tf.concat([tf.reshape(self.F, (-1, self.F.shape[-1])), tf.reshape(self.b, (1, -1))], axis=0)))\n",
    "\n",
    "    def get_size(self):\n",
    "        return self.F.shape[-2], self.F.shape[-1]\n",
    "\n",
    "    def prune(self, threshold, active_input_units_indices):\n",
    "        # Remove connections from pruned units in previous layer\n",
    "        new_F = tf.gather(self.F.value(), active_input_units_indices, axis=-2)\n",
    "\n",
    "        if self.fixed_size:\n",
    "            active_output_filters_indices = list(range(new_F.shape[-1]))\n",
    "        else:\n",
    "            # Prune units in this layer\n",
    "            F_reduced_max = tf.reshape(tf.math.reduce_max(tf.abs(new_F), axis=(0, 1, 2)), (1, -1))\n",
    "            F_reduced_max_with_biases = tf.concat([F_reduced_max, tf.reshape(self.b.value(), (1, -1))], axis=0)\n",
    "            filters_are_active = tf.math.reduce_max(tf.abs(F_reduced_max_with_biases), axis=0) >= threshold\n",
    "            active_output_filters_indices = tf.reshape(tf.where(filters_are_active), (-1,))\n",
    "\n",
    "            new_F = tf.gather(new_F, active_output_filters_indices, axis=-1)\n",
    "            new_b = tf.gather(self.b.value(), active_output_filters_indices, axis=0)\n",
    "\n",
    "            self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
    "\n",
    "        self.F = tf.Variable(name='F', initial_value=new_F, trainable=True)\n",
    "\n",
    "        self.regularizer.prune()\n",
    "        return active_output_filters_indices\n",
    "\n",
    "    def grow(self, n_new_input_units, percentage, min_new_units, scaling_factor):\n",
    "        if n_new_input_units > 0:\n",
    "            # Add connections to grown units in previous layer\n",
    "            F_growth = self.F_init(\n",
    "                shape=(self.F.shape[0], self.F.shape[1], self.F.shape[2] + n_new_input_units, self.F.shape[3]),\n",
    "                dtype=dtype)[:, :, -n_new_input_units:,\n",
    "                       :] * scaling_factor  # TODO is it better to be multiplying here by scaling_factor? It does help with not increasing the max weights of existing neurons when new neurons are added.\n",
    "            new_F = tf.concat([self.F.value(), F_growth], axis=-2)\n",
    "        else:\n",
    "            new_F = self.F.value()\n",
    "\n",
    "        if self.fixed_size:\n",
    "            n_new_output_units = 0\n",
    "        else:\n",
    "            # Grow new units in this layer\n",
    "            n_new_output_units = max(min_new_units, int(new_F.shape[-1] * percentage))\n",
    "            if n_new_output_units > 0:\n",
    "                F_growth = self.F_init(\n",
    "                    shape=(new_F.shape[0], new_F.shape[1], new_F.shape[2], new_F.shape[3] + n_new_output_units),\n",
    "                    dtype=dtype)[:, :, :, -n_new_output_units:] * scaling_factor\n",
    "                b_growth = self.b_init(shape=(n_new_output_units,),\n",
    "                                       dtype=dtype)  # TODO for all possible bias initializers to work properly, the whole bias vector should be initialized at once\n",
    "                new_F = tf.concat([new_F, F_growth], axis=-1)\n",
    "                new_b = tf.concat([self.b.value(), b_growth], axis=0)\n",
    "\n",
    "                self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
    "\n",
    "        self.F = tf.Variable(name='F', initial_value=new_F, trainable=True)\n",
    "\n",
    "        self.regularizer.grow(n_new_output_units)\n",
    "        return n_new_output_units\n",
    "\n",
    "    def mutate(self, mutation_strength):\n",
    "        self.F.assign_add(tf.random.normal(self.F.shape, mean=0.0, stddev=mutation_strength))\n",
    "        self.b.assign_add(tf.random.normal(self.b.shape, mean=0.0, stddev=mutation_strength))\n",
    "\n",
    "    def set_regularization_penalty(self, regularization_penalty):\n",
    "        if not self.fixed_size:\n",
    "            self.regularizer.set_regularization_penalty(regularization_penalty)\n",
    "\n",
    "    def set_regularization_method(self, regularization_method):\n",
    "        if not self.fixed_size:\n",
    "            self.regularizer.set_regularization_method(regularization_method)\n",
    "\n",
    "    def get_param_string(self):\n",
    "        param_string = \"\"\n",
    "        # TODO\n",
    "        return param_string\n",
    "\n",
    "\n",
    "class Flatten(tf.keras.layers.Layer):\n",
    "    def call(self, inputs, training=None):\n",
    "        return tf.reshape(tf.transpose(inputs, perm=[0, 3, 1, 2]), (inputs.shape[0], -1))\n",
    "\n",
    "\n",
    "class Sequential(tf.keras.Model):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lrs = layers\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = inputs\n",
    "        for layer in self.lrs:\n",
    "            x = layer(x, training=training)\n",
    "        return x\n",
    "\n",
    "    def copy(self):\n",
    "        copied_layers = list()\n",
    "        for layer in self.lrs:\n",
    "            if isinstance(layer, DASLayer):\n",
    "                layer_copy = layer.copy()\n",
    "            else:\n",
    "                layer_copy = copy.deepcopy(layer)\n",
    "            copied_layers.append(layer_copy)\n",
    "\n",
    "        model_copy = Sequential(copied_layers)\n",
    "        return model_copy\n",
    "\n",
    "    def get_layer_input_shape(self, target_layer):\n",
    "        if target_layer._input_shape is not None:\n",
    "            return target_layer._input_shape\n",
    "\n",
    "        input = np.random.normal(size=(1,) + self.lrs[0]._input_shape)\n",
    "        for layer in self.lrs:\n",
    "            if layer is target_layer:\n",
    "                return tuple(input.shape[1:])\n",
    "            input = layer(input)\n",
    "        raise Exception(\"Layer not found in the model.\")\n",
    "\n",
    "    def get_layer_output_shape(self, target_layer):\n",
    "        input = np.random.normal(size=(1,) + self.lrs[0]._input_shape)\n",
    "        for layer in self.lrs:\n",
    "            output = layer(input)\n",
    "            if layer is target_layer:\n",
    "                return tuple(output.shape[1:])\n",
    "            input = output\n",
    "        raise Exception(\"Layer not found in the model.\")\n",
    "\n",
    "    def get_layer_sizes(self):\n",
    "        \"\"\"\n",
    "        Returns the sizes of all layers in the model, including the input and output layer.\n",
    "        \"\"\"\n",
    "        layer_sizes = list()\n",
    "        first_layer = True\n",
    "        for l in range(len(self.lrs)):\n",
    "            layer = self.lrs[l]\n",
    "            if isinstance(layer, DASLayer) and not layer.fixed_size:\n",
    "                layer_size = layer.get_size()\n",
    "                if first_layer:\n",
    "                    layer_sizes.append(layer_size[0])\n",
    "                    first_layer = False\n",
    "                layer_sizes.append(layer_size[1])\n",
    "        return layer_sizes\n",
    "\n",
    "    def get_hidden_layer_sizes(self):\n",
    "        return self.get_layer_sizes()\n",
    "\n",
    "    def get_regularization_penalty(self):\n",
    "        # TODO improve\n",
    "        dense_layers = [l for l in self.lrs if isinstance(l, Dense)]\n",
    "        return dense_layers[-2].regularizer.regularization_penalty\n",
    "\n",
    "    def set_regularization_penalty(self, regularization_penalty):\n",
    "        for layer in self.lrs:\n",
    "            if isinstance(layer, DASLayer) and not layer.fixed_size:\n",
    "                layer.set_regularization_penalty(regularization_penalty)\n",
    "\n",
    "    def set_regularization_method(self, regularization_method):\n",
    "        for layer in self.lrs:\n",
    "            if isinstance(layer, DASLayer) and not layer.fixed_size:\n",
    "                layer.set_regularization_method(regularization_method)\n",
    "\n",
    "    def prune(self, params):\n",
    "        input_shape = self.get_layer_input_shape(self.lrs[0])\n",
    "        n_input_units = input_shape[-1]\n",
    "        active_units_indices = list(range(n_input_units))\n",
    "\n",
    "        last_custom_layer = None\n",
    "        for layer in self.lrs:\n",
    "            if isinstance(layer, Flatten):\n",
    "                convolutional_shape = self.get_layer_output_shape(last_custom_layer)\n",
    "                active_units_indices = self.convert_channel_indices_to_flattened_indices(active_units_indices,\n",
    "                                                                                         convolutional_shape)\n",
    "            elif isinstance(layer, DASLayer):\n",
    "                active_units_indices = layer.prune(params.pruning_threshold, active_units_indices)\n",
    "                last_custom_layer = layer\n",
    "\n",
    "    def grow(self, params):\n",
    "        n_new_units = 0\n",
    "\n",
    "        last_custom_layer = None\n",
    "        for layer in self.lrs:\n",
    "            if isinstance(layer, Flatten):\n",
    "                convolutional_shape = self.get_layer_output_shape(last_custom_layer)\n",
    "                n_new_units = n_new_units * convolutional_shape[0] * convolutional_shape[1]\n",
    "            elif isinstance(layer, DASLayer):\n",
    "                n_new_units = layer.grow(n_new_units, params.growth_percentage, min_new_units=params.min_new_neurons,\n",
    "                                         scaling_factor=params.pruning_threshold)\n",
    "                last_custom_layer = layer\n",
    "\n",
    "    def mutate(self, mutation_strength):\n",
    "        for layer in self.lrs:\n",
    "            if isinstance(layer, DASLayer):\n",
    "                layer.mutate(mutation_strength)\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_channel_indices_to_flattened_indices(channel_indices, convolutional_shape):\n",
    "        dense_indices = list()\n",
    "        units_per_channel = convolutional_shape[0] * convolutional_shape[1]\n",
    "        for channel_index in channel_indices:\n",
    "            for iter in range(units_per_channel):\n",
    "                dense_indices.append(channel_index * units_per_channel + iter)\n",
    "        return dense_indices\n",
    "\n",
    "    def print_neurons(self):\n",
    "        for layer in self.lrs[:-1]:\n",
    "            print(layer.get_param_string())\n",
    "\n",
    "    def evaluate(self, params, summed_training_loss, summed_training_metric):\n",
    "        # Calculate training loss and metric\n",
    "        if summed_training_loss is not None:\n",
    "            loss = summed_training_loss / params.x.shape[0]\n",
    "        else:\n",
    "            loss = None\n",
    "\n",
    "        if summed_training_metric is not None:\n",
    "            metric = summed_training_metric / params.x.shape[0]\n",
    "        else:\n",
    "            metric = None\n",
    "\n",
    "        # Calculate val loss and metric\n",
    "        summed_val_loss = 0\n",
    "        summed_val_metric = 0\n",
    "        n_val_instances = 0\n",
    "\n",
    "        for step, (x_batch, y_batch) in enumerate(params.val_dataset):\n",
    "            # y_pred = tf.reshape(self(x_batch, training=False), y_batch.shape)\n",
    "            y_pred = self(x_batch, training=False)\n",
    "            summed_val_loss += tf.reduce_sum(params.loss_fn(y_batch, y_pred))\n",
    "            summed_val_metric += float(tf.reduce_sum(params.metric_fn(y_batch, y_pred)))\n",
    "            n_val_instances += x_batch.shape[0]\n",
    "\n",
    "        val_loss = summed_val_loss / n_val_instances\n",
    "        val_metric = summed_val_metric / n_val_instances\n",
    "\n",
    "        return loss, metric, val_loss, val_metric\n",
    "\n",
    "    def list_params(self):\n",
    "        trainable_count = np.sum([K.count_params(w) for w in self.trainable_weights])\n",
    "        non_trainable_count = np.sum([K.count_params(w) for w in self.non_trainable_weights])\n",
    "        total_count = trainable_count + non_trainable_count\n",
    "\n",
    "        print('Total params: {:,}'.format(total_count))\n",
    "        print('Trainable params: {:,}'.format(trainable_count))\n",
    "        print('Non-trainable params: {:,}'.format(non_trainable_count))\n",
    "\n",
    "        return total_count, trainable_count, non_trainable_count\n",
    "\n",
    "    def print_epoch_statistics(self, params, summed_training_loss, summed_training_metric, message=None,\n",
    "                               require_result=False):\n",
    "        if not params.verbose:\n",
    "            if require_result:\n",
    "                return self.evaluate(params, summed_training_loss, summed_training_metric)\n",
    "            else:\n",
    "                return\n",
    "\n",
    "        loss, metric, val_loss, val_metric = self.evaluate(params, summed_training_loss, summed_training_metric)\n",
    "\n",
    "        if message is not None:\n",
    "            print(message)\n",
    "\n",
    "        print(\n",
    "            f\"loss: {loss} - metric: {metric} - val_loss: {val_loss} - val_metric: {val_metric} - penalty: {self.get_regularization_penalty()}\")\n",
    "        hidden_layer_sizes = self.get_hidden_layer_sizes()\n",
    "        print(f\"hidden layer sizes: {hidden_layer_sizes}, total units: {sum(hidden_layer_sizes)}\")\n",
    "        if params.print_neurons:\n",
    "            self.print_neurons()\n",
    "\n",
    "        if require_result:\n",
    "            return loss, metric, val_loss, val_metric\n",
    "\n",
    "    def update_history(self, params, loss, metric, val_loss, val_metric):\n",
    "        params.history['loss'].append(float(loss))\n",
    "        params.history['metric'].append(float(metric))\n",
    "        params.history['val_loss'].append(float(val_loss))\n",
    "        params.history['val_metric'].append(float(val_metric))\n",
    "        params.history['hidden_layer_sizes'].append(self.get_hidden_layer_sizes())\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_datasets(x, y, batch_size, validation_data):\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "        train_dataset = train_dataset.shuffle(buffer_size=20000).batch(batch_size)\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices(validation_data).batch(batch_size)\n",
    "        return train_dataset.prefetch(tf.data.AUTOTUNE), val_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    def manage_dynamic_regularization(self, params, val_loss):\n",
    "        if val_loss >= params.best_conditional_val_loss * params.stall_coefficient:\n",
    "            # Training is currently in stall\n",
    "            if not params.training_stalled:\n",
    "                penalty = self.get_regularization_penalty() * params.regularization_penalty_multiplier\n",
    "                print(\"Changing penalty...\")\n",
    "                # TODO this must be modified, penalty can differ for each layer\n",
    "                self.set_regularization_penalty(penalty)\n",
    "                params.training_stalled = True\n",
    "        else:\n",
    "            params.best_conditional_val_loss = val_loss\n",
    "            params.training_stalled = False\n",
    "\n",
    "    def grow_wrapper(self, params):\n",
    "        dynamic_reqularization_active = params.regularization_penalty_multiplier != 1.\n",
    "        if dynamic_reqularization_active:\n",
    "            loss, metric, val_loss, val_metric = self.print_epoch_statistics(params, None, None, \"Before growing:\",\n",
    "                                                                             require_result=True)\n",
    "            self.manage_dynamic_regularization(params, val_loss)\n",
    "        else:\n",
    "            self.print_epoch_statistics(params, None, None, \"Before growing:\")\n",
    "\n",
    "        self.grow(params)\n",
    "        print(\"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\")\n",
    "        self.print_epoch_statistics(params, None, None, \"After growing:\")\n",
    "\n",
    "    def prune_wrapper(self, params, summed_loss, summed_metric):\n",
    "        loss, metric, _, _ = self.print_epoch_statistics(params, summed_loss, summed_metric, \"Before pruning:\",\n",
    "                                                         require_result=True)\n",
    "        self.prune(params)\n",
    "        _, _, val_loss, val_metric = self.print_epoch_statistics(params, None, None, \"After pruning:\",\n",
    "                                                                 require_result=True)\n",
    "        self.update_history(params, loss, metric, val_loss, val_metric)\n",
    "\n",
    "    class ParameterContainer:\n",
    "        def __init__(self, x, y, optimizer, batch_size, min_new_neurons, validation_data, pruning_threshold,\n",
    "                     regularization_penalty_multiplier,\n",
    "                     stall_coefficient, growth_percentage, mini_epochs_per_epoch, verbose, print_neurons,\n",
    "                     use_static_graph, loss_fn, metric_fn):\n",
    "            self.x = x\n",
    "            self.y = y\n",
    "            self.optimizer = optimizer\n",
    "            self.batch_size = batch_size\n",
    "            self.min_new_neurons = min_new_neurons\n",
    "            self.validation_data = validation_data\n",
    "            self.pruning_threshold = pruning_threshold\n",
    "            self.regularization_penalty_multiplier = regularization_penalty_multiplier\n",
    "            self.stall_coefficient = stall_coefficient\n",
    "            self.growth_percentage = growth_percentage\n",
    "            self.mini_epochs_per_epoch = mini_epochs_per_epoch\n",
    "            self.verbose = verbose\n",
    "            self.print_neurons = print_neurons\n",
    "            self.use_static_graph = use_static_graph\n",
    "            self.loss_fn = loss_fn\n",
    "            self.metric_fn = metric_fn\n",
    "\n",
    "            self.train_dataset, self.val_dataset = Sequential.prepare_datasets(x, y, batch_size, validation_data)\n",
    "            self.history = self.prepare_history()\n",
    "\n",
    "            self.best_conditional_val_loss = np.inf\n",
    "            self.training_stalled = False\n",
    "\n",
    "        @staticmethod\n",
    "        def prepare_history():\n",
    "            history = {\n",
    "                'loss': list(),\n",
    "                'metric': list(),\n",
    "                'val_loss': list(),\n",
    "                'val_metric': list(),\n",
    "                'hidden_layer_sizes': list(),\n",
    "            }\n",
    "            return history\n",
    "\n",
    "    def fit_single_step(self, x_batch, y_batch, optimizer, loss_fn, metric_fn):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # y_pred = tf.reshape(self(x_batch, training=True), y_batch.shape)\n",
    "            y_pred = self(x_batch, training=True)\n",
    "            raw_loss = loss_fn(y_batch, y_pred)\n",
    "            loss_value = tf.reduce_mean(raw_loss)\n",
    "            loss_value += sum(self.losses)  # Add losses registered by model.add_loss\n",
    "\n",
    "            loss = tf.reduce_sum(raw_loss)\n",
    "            metric = float(tf.reduce_sum(metric_fn(y_batch, y_pred)))\n",
    "\n",
    "        grads = tape.gradient(loss_value, self.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "\n",
    "        return loss, metric\n",
    "\n",
    "    def fit_single_epoch(self, params):\n",
    "        summed_loss = 0\n",
    "        summed_metric = 0\n",
    "\n",
    "        for mini_epoch in range(params.mini_epochs_per_epoch):\n",
    "            summed_loss = 0\n",
    "            summed_metric = 0\n",
    "\n",
    "            if params.use_static_graph:\n",
    "                fit_single_step_function = tf.function(self.fit_single_step)\n",
    "            else:\n",
    "                fit_single_step_function = self.fit_single_step\n",
    "            for step, (x_batch, y_batch) in enumerate(params.train_dataset):\n",
    "                loss, metric = fit_single_step_function(x_batch, y_batch, params.optimizer, params.loss_fn,\n",
    "                                                        params.metric_fn)\n",
    "                summed_loss += loss\n",
    "                summed_metric += metric\n",
    "\n",
    "        return summed_loss, summed_metric\n",
    "\n",
    "    def fit(self, x, y, optimizer, schedule, batch_size, min_new_neurons, validation_data, pruning_threshold=0.001,\n",
    "            regularization_penalty_multiplier=1.,\n",
    "            stall_coefficient=1, growth_percentage=0.2, mini_epochs_per_epoch=1, verbose=True, print_neurons=False,\n",
    "            use_static_graph=True,\n",
    "            loss_fn=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "            metric_fn=tf.keras.metrics.sparse_categorical_accuracy):\n",
    "        params = self.ParameterContainer(x=x, y=y, optimizer=optimizer, batch_size=batch_size,\n",
    "                                         min_new_neurons=min_new_neurons, validation_data=validation_data,\n",
    "                                         pruning_threshold=pruning_threshold,\n",
    "                                         regularization_penalty_multiplier=regularization_penalty_multiplier,\n",
    "                                         stall_coefficient=stall_coefficient,\n",
    "                                         growth_percentage=growth_percentage,\n",
    "                                         mini_epochs_per_epoch=mini_epochs_per_epoch, verbose=verbose,\n",
    "                                         print_neurons=print_neurons,\n",
    "                                         use_static_graph=use_static_graph, loss_fn=loss_fn, metric_fn=metric_fn)\n",
    "        self.build(x.shape)  # Necessary when verbose == False\n",
    "\n",
    "        for epoch_no, epoch in enumerate(schedule):\n",
    "            if verbose:\n",
    "                print(\"##########################################################\")\n",
    "                print(f\"Epoch {epoch_no + 1}/{len(schedule)}\")\n",
    "\n",
    "            self.set_regularization_penalty(epoch.regularization_penalty)\n",
    "            self.set_regularization_method(epoch.regularization_method)\n",
    "\n",
    "            if epoch.grow:\n",
    "                self.grow_wrapper(params)\n",
    "\n",
    "            summed_loss, summed_metric = self.fit_single_epoch(params)\n",
    "\n",
    "            if epoch.prune:\n",
    "                self.prune_wrapper(params, summed_loss, summed_metric)\n",
    "            else:\n",
    "                loss, metric, val_loss, val_metric = self.print_epoch_statistics(params, summed_loss, summed_metric,\n",
    "                                                                                 require_result=True)\n",
    "                self.update_history(params, loss, metric, val_loss, val_metric)\n",
    "\n",
    "        return params.history\n",
    "\n",
    "##### schedule.py\n",
    "\n",
    "class Epoch:\n",
    "    def __init__(self, grow, prune, regularization_penalty, regularization_method):\n",
    "        self.grow = grow\n",
    "        self.prune = prune\n",
    "        self.regularization_penalty = regularization_penalty\n",
    "        self.regularization_method = regularization_method\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{int(self.grow)}{int(self.prune)}{self.regularization_penalty}{self.regularization_method}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "\n",
    "class DynamicEpoch(Epoch):\n",
    "    def __init__(self, regularization_penalty, regularization_method):\n",
    "        super().__init__(True, True, regularization_penalty, regularization_method)\n",
    "\n",
    "\n",
    "class StaticEpoch(Epoch):\n",
    "    def __init__(self, regularization_penalty, regularization_method):\n",
    "        super().__init__(False, False, regularization_penalty, regularization_method)\n",
    "\n",
    "\n",
    "class StaticEpochNoRegularization(StaticEpoch):\n",
    "    def __init__(self):\n",
    "        super().__init__(0., None)\n",
    "\n",
    "\n",
    "class Schedule:\n",
    "    def __init__(self, epochs):\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.epochs.__iter__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.epochs)\n",
    "\n",
    "    def __str__(self):\n",
    "        text = ''.join([str(epoch) for epoch in self.epochs])\n",
    "        _hash = hashlib.sha1(text.encode('utf-8')).hexdigest()[:10]\n",
    "        return f'{_hash}({self.epochs[0].regularization_penalty})'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "##### helpers.py\n",
    "\n",
    "def get_statistics_from_history(history):\n",
    "    best_epoch_number = np.argmax(history['val_metric'])\n",
    "    best_loss = history['loss'][best_epoch_number]\n",
    "    best_metric = history['metric'][best_epoch_number]\n",
    "    best_val_loss = history['val_loss'][best_epoch_number]\n",
    "    best_val_metric = history['val_metric'][best_epoch_number]\n",
    "    best_hidden_layer_sizes = history['hidden_layer_sizes'][best_epoch_number]\n",
    "    return best_loss, best_metric, best_val_loss, best_val_metric, best_hidden_layer_sizes\n",
    "\n",
    "\n",
    "def get_statistics_from_histories(histories):\n",
    "    best_val_losses = list()\n",
    "    best_val_metrics = list()\n",
    "    all_best_hidden_layer_sizes = list()\n",
    "\n",
    "    for history in histories:\n",
    "        _, _, best_val_loss, best_val_metric, best_hidden_layer_sizes = get_statistics_from_history(history)\n",
    "        best_val_losses.append(best_val_loss)\n",
    "        best_val_metrics.append(best_val_metric)\n",
    "        all_best_hidden_layer_sizes.append(best_hidden_layer_sizes)\n",
    "\n",
    "    mean_best_val_loss = np.mean(best_val_losses)\n",
    "    mean_best_val_metric = np.mean(best_val_metrics)\n",
    "    mean_best_hidden_layer_sizes = [np.mean(layer) for layer in list(zip(*all_best_hidden_layer_sizes))]\n",
    "\n",
    "    return mean_best_val_loss, mean_best_val_metric, mean_best_hidden_layer_sizes\n",
    "\n",
    "\n",
    "def cross_validate(train_fn, x, y, n_splits, random_state=42, *args, **kwargs):\n",
    "    from sklearn.model_selection import KFold\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    histories = list()\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "        xtrain, xtest = x[train_index], x[test_index]\n",
    "        ytrain, ytest = y[train_index], y[test_index]\n",
    "\n",
    "        history = train_fn(xtrain, ytrain, validation_data=(xtest, ytest), *args, **kwargs)\n",
    "        histories.append(history)\n",
    "\n",
    "        _, _, best_val_loss, best_val_metric, best_hidden_layer_sizes = get_statistics_from_history(history)\n",
    "        print(\n",
    "            f\"Run {i} completed, best_val_loss: {best_val_loss}, best_val_metric: {best_val_metric}, best_hidden_layer_sizes: {best_hidden_layer_sizes}\")\n",
    "\n",
    "    mean_best_val_loss, mean_best_val_metric, mean_best_hidden_layer_sizes = get_statistics_from_histories(histories)\n",
    "    print(f'mean_best_val_loss: {mean_best_val_loss}')\n",
    "    print(f'mean_best_val_metric: {mean_best_val_metric}')\n",
    "    print(f'mean_best_hidden_layer_sizes: {mean_best_hidden_layer_sizes}')\n",
    "\n",
    "    return histories, mean_best_hidden_layer_sizes\n",
    "\n",
    "\n",
    "def hyperparameter_search(train_fn, x, y, validation_data, *args, **kwargs):\n",
    "    from itertools import product\n",
    "\n",
    "    all_params = [*args] + list(kwargs.values())\n",
    "    histories = list()\n",
    "\n",
    "    best_overall_val_loss = np.inf\n",
    "    best_overall_val_metric = None\n",
    "    best_overall_combination = None\n",
    "\n",
    "    for combination in product(*all_params):\n",
    "        combination_args = combination[:len(args)]\n",
    "\n",
    "        combination_kwargs_values = combination[len(args):]\n",
    "        combination_kwargs = dict(zip(kwargs.keys(), combination_kwargs_values))\n",
    "\n",
    "        history = train_fn(x, y, validation_data, *combination_args, **combination_kwargs)\n",
    "        history['parameters'] = combination\n",
    "        histories.append(history)\n",
    "\n",
    "        _, _, best_val_loss, best_val_metric, best_hidden_layer_sizes = get_statistics_from_history(history)\n",
    "        print(\n",
    "            f\"Run with parameters {combination} completed, best_val_loss: {best_val_loss}, best_val_metric: {best_val_metric}, best_hidden_layer_sizes: {best_hidden_layer_sizes}\")\n",
    "\n",
    "        if best_val_loss < best_overall_val_loss:\n",
    "            best_overall_val_loss = best_val_loss\n",
    "            best_overall_val_metric = best_val_metric\n",
    "            best_overall_combination = combination\n",
    "\n",
    "    print(f'Best overall combination: {best_overall_combination}, val_metric: {best_overall_val_metric}')\n",
    "\n",
    "    return histories, best_overall_combination\n",
    "\n",
    "\n",
    "\n",
    "def merge_histories(history1, history2):\n",
    "    merged_history = dict()\n",
    "    for key in history1.keys():\n",
    "        merged_history[key] = history1[key] + history2[key]\n",
    "    return merged_history\n",
    "\n",
    "\n",
    "def get_convolutional_model(x, layer_sizes, output_neurons=10):\n",
    "    dropout_rate = 0.3\n",
    "    model = Sequential([\n",
    "        Conv2D(layer_sizes[0], filter_size=(3, 3), activation='selu', padding='SAME', kernel_initializer='lecun_normal', input_shape=x[0, :, :, :].shape),\n",
    "        BatchNormalization(),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        Conv2D(layer_sizes[1], filter_size=(3, 3), activation='selu', padding='SAME', kernel_initializer='lecun_normal'),\n",
    "        BatchNormalization(),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        Conv2D(layer_sizes[2], filter_size=(3, 3), activation='selu', padding='SAME', kernel_initializer='lecun_normal'),\n",
    "        BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        Conv2D(layer_sizes[3], filter_size=(3, 3), activation='selu', padding='SAME', kernel_initializer='lecun_normal'),\n",
    "        BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        Conv2D(layer_sizes[4], filter_size=(3, 3), strides=(2, 2), activation='selu', padding='SAME', kernel_initializer='lecun_normal'),\n",
    "        BatchNormalization(),\n",
    "        # tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        Flatten(),\n",
    "        Dense(layer_sizes[5], activation='selu', kernel_initializer='lecun_normal', fixed_size=True),\n",
    "        BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        Dense(layer_sizes[6], activation='selu', kernel_initializer='lecun_normal', fixed_size=True),\n",
    "        BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        Dense(output_neurons, activation='softmax', fixed_size=True),\n",
    "        \n",
    "        # Conv2D(layer_sizes[1], filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME',\n",
    "        #        kernel_initializer='lecun_normal'),\n",
    "        # tf.keras.layers.Dropout(0.2),\n",
    "        # Conv2D(layer_sizes[2], filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME',\n",
    "        #        kernel_initializer='lecun_normal'),\n",
    "        # Conv2D(layer_sizes[3], filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME',\n",
    "        #        kernel_initializer='lecun_normal'),\n",
    "        # tf.keras.layers.Dropout(0.5),\n",
    "        # Flatten(),\n",
    "        # Dense(layer_sizes[4], activation='selu', kernel_initializer='lecun_normal'),\n",
    "        # Dense(output_neurons, activation='softmax', fixed_size=True),\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_dense_model(x, layer_sizes):\n",
    "    layers = list()\n",
    "\n",
    "    layers.append(\n",
    "        Dense(layer_sizes[0], activation='selu', kernel_initializer='lecun_normal', input_shape=x[0, :].shape))\n",
    "    for layer_size in layer_sizes[1:]:\n",
    "        layers.append(Dense(layer_size, activation='selu', kernel_initializer='lecun_normal'))\n",
    "    layers.append(Dense(1, activation=None, kernel_initializer='lecun_normal', fixed_size=True))\n",
    "\n",
    "    model = Sequential(layers)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_fn_conv(x, y, validation_data, learning_rate, schedule, layer_sizes, output_neurons=10, min_new_neurons=20,\n",
    "                  growth_percentage=0.2, verbose=False, use_static_graph=True, batch_size=128):\n",
    "    model = get_convolutional_model(x, layer_sizes, output_neurons)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    history = model.fit(x=x, y=y, optimizer=optimizer, schedule=schedule, batch_size=batch_size,\n",
    "                        min_new_neurons=min_new_neurons,\n",
    "                        validation_data=validation_data, growth_percentage=growth_percentage, verbose=verbose,\n",
    "                        use_static_graph=use_static_graph)\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "def squared_error(y_true, y_pred):\n",
    "    return (y_true - y_pred) ** 2\n",
    "\n",
    "\n",
    "def negative_squared_error(y_true, y_pred):\n",
    "    return - ((y_true - y_pred) ** 2)\n",
    "\n",
    "\n",
    "def train_fn_dense(x, y, validation_data, learning_rate, schedule, layer_sizes, min_new_neurons=20,\n",
    "                   growth_percentage=0.2, verbose=False, use_static_graph=True, batch_size=128):\n",
    "    model = get_dense_model(x, layer_sizes)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    history = model.fit(x=x, y=y, optimizer=optimizer, schedule=schedule, batch_size=batch_size,\n",
    "                        min_new_neurons=min_new_neurons,\n",
    "                        validation_data=validation_data, growth_percentage=growth_percentage, verbose=verbose,\n",
    "                        use_static_graph=use_static_graph,\n",
    "                        loss_fn=squared_error, metric_fn=negative_squared_error)\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "def early_stopping_conv(x, y, validation_data, learning_rate, schedule, layer_sizes, output_neurons=10,\n",
    "                        min_new_neurons=20,\n",
    "                        growth_percentage=0.2, verbose=False, use_static_graph=True, batch_size=128, max_setbacks=2):\n",
    "    assert len(schedule) == 1\n",
    "\n",
    "    model = get_convolutional_model(x, layer_sizes, output_neurons)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    history = Sequential.ParameterContainer.prepare_history()\n",
    "\n",
    "    best_val_loss = np.inf\n",
    "    n_setbacks = 0\n",
    "    while True:\n",
    "        epoch_history = model.fit(x=x, y=y, optimizer=optimizer, schedule=schedule, batch_size=batch_size,\n",
    "                                  min_new_neurons=min_new_neurons,\n",
    "                                  validation_data=validation_data, growth_percentage=growth_percentage, verbose=verbose,\n",
    "                                  use_static_graph=use_static_graph)\n",
    "        history = merge_histories(history, epoch_history)\n",
    "        val_loss = epoch_history['val_loss'][-1]\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            n_setbacks = 0\n",
    "        else:\n",
    "            n_setbacks += 1\n",
    "            if n_setbacks > max_setbacks:\n",
    "                break\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "def early_stopping_dense(x, y, validation_data, learning_rate, schedule, layer_sizes, output_neurons=1,\n",
    "                         min_new_neurons=20,\n",
    "                         growth_percentage=0.2, verbose=False, use_static_graph=True, batch_size=128, max_setbacks=2):\n",
    "    assert len(schedule) == 1\n",
    "    assert output_neurons == 1\n",
    "\n",
    "    model = get_dense_model(x, layer_sizes)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    history = Sequential.ParameterContainer.prepare_history()\n",
    "\n",
    "    best_val_loss = np.inf\n",
    "    n_setbacks = 0\n",
    "    while True:\n",
    "        epoch_history = model.fit(x=x, y=y, optimizer=optimizer, schedule=schedule, batch_size=batch_size,\n",
    "                                  min_new_neurons=min_new_neurons,\n",
    "                                  validation_data=validation_data, growth_percentage=growth_percentage, verbose=verbose,\n",
    "                                  use_static_graph=use_static_graph,\n",
    "                                  loss_fn=squared_error, metric_fn=negative_squared_error)\n",
    "        history = merge_histories(history, epoch_history)\n",
    "        val_loss = epoch_history['val_loss'][-1]\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            n_setbacks = 0\n",
    "        else:\n",
    "            n_setbacks += 1\n",
    "            if n_setbacks > max_setbacks:\n",
    "                break\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "def layer_sizes_join_postprocess(args, kwargs):\n",
    "    kwargs['layer_sizes'] = kwargs['layer_1_size'], kwargs['layer_2_size'], kwargs['layer_3_size'], kwargs[\n",
    "        'layer_4_size'], kwargs['layer_5_size']\n",
    "    del kwargs['layer_1_size'], kwargs['layer_2_size'], kwargs['layer_3_size'], kwargs['layer_4_size'], kwargs[\n",
    "        'layer_5_size']\n",
    "    return args, kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc6ce8e5-8fe3-4e17-9ab4-7daabca0903b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded.\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Converted type.\n",
      "Divided by 255.\n",
      "Reshaped.\n",
      "Concatenated.\n",
      "Fit scaler.\n",
      "Transformed using scaler.\n",
      "Reshaped.\n",
      "Shuffled.\n"
     ]
    }
   ],
   "source": [
    "cifar100 = get_cifar_100_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b3916e-9885-4e33-9f48-5d834d6cb795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alexnet_layer_sizes = [96, 256, 384, 384, 256, 4096, 4096]\n",
    "alexnet_layer_sizes = [96, 256, 384, 384, 256, 1024, 1024]\n",
    "layer_sizes = [size // 3 for size in alexnet_layer_sizes]\n",
    "layer_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9574a342-41be-47c6-b129-7a48d1c30bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormalization(DASLayer):\n",
    "    def __init__(self, momentum=0.99, epsilon=0.001, input_shape=None):\n",
    "        super().__init__(input_shape, fixed_size=True)\n",
    "\n",
    "        self.momentum = momentum\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def copy(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        if self._built:\n",
    "            return\n",
    "        \n",
    "        self.offset = tf.Variable(\n",
    "            name='offset',\n",
    "            initial_value=tf.zeros(input_shape[1:]),\n",
    "            trainable=True)\n",
    "        self.scale = tf.Variable(\n",
    "            name='scale',\n",
    "            initial_value=tf.ones(input_shape[1:]),\n",
    "            trainable=True)\n",
    "        self.moving_mean = tf.Variable(\n",
    "            name='moving_mean',\n",
    "            initial_value=tf.zeros(input_shape[1:]),\n",
    "            trainable=False)\n",
    "        self.moving_variance = tf.Variable(\n",
    "            name='moving_variance',\n",
    "            initial_value=tf.ones(input_shape[1:]),\n",
    "            trainable=False)\n",
    "\n",
    "        self._built = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # print(inputs.shape)\n",
    "        # print(self.offset.shape)\n",
    "        # print(self.scale.shape)\n",
    "        # print(self.moving_mean.shape)\n",
    "        # print(self.moving_variance.shape)\n",
    "        if training:\n",
    "            mean, variance = tf.nn.moments(inputs, axes=[0])\n",
    "            self.moving_mean.assign(self.moving_mean * self.momentum + mean * (1 - self.momentum))\n",
    "            self.moving_variance.assign(self.moving_variance * self.momentum + variance * (1 - self.momentum))\n",
    "        else:\n",
    "            mean = self.moving_mean\n",
    "            variance = self.moving_variance\n",
    "        return tf.nn.batch_normalization(inputs, mean, variance, self.offset, self.scale, self.epsilon)\n",
    "\n",
    "    # def get_size(self):\n",
    "    #     return self.F.shape[-2], self.F.shape[-1]\n",
    "\n",
    "    def prune(self, threshold, active_input_units_indices):\n",
    "        new_offset = tf.gather(self.offset.value(), active_input_units_indices, axis=-1)\n",
    "        new_scale = tf.gather(self.scale.value(), active_input_units_indices, axis=-1)\n",
    "        new_moving_mean = tf.gather(self.moving_mean.value(), active_input_units_indices, axis=-1)\n",
    "        new_moving_variance = tf.gather(self.moving_variance.value(), active_input_units_indices, axis=-1)\n",
    "        self.offset = tf.Variable(name='offset', initial_value=new_offset, trainable=True)\n",
    "        self.scale = tf.Variable(name='scale', initial_value=new_scale, trainable=True)\n",
    "        self.moving_mean = tf.Variable(name='moving_mean', initial_value=new_moving_mean, trainable=False)\n",
    "        self.moving_variance = tf.Variable(name='moving_variance', initial_value=new_moving_variance, trainable=False)\n",
    "        return active_input_units_indices\n",
    "\n",
    "    def grow(self, n_new_input_units, percentage, min_new_units, scaling_factor):\n",
    "        if n_new_input_units > 0:\n",
    "            growth_shape = list(self.offset.shape)\n",
    "            growth_shape[-1] = n_new_input_units\n",
    "            new_offset = tf.concat([self.offset, tf.zeros(growth_shape)], axis=-1)\n",
    "            new_scale = tf.concat([self.scale, tf.ones(growth_shape)], axis=-1)\n",
    "            new_moving_mean = tf.concat([self.moving_mean, tf.zeros(growth_shape)], axis=-1)\n",
    "            new_moving_variance = tf.concat([self.moving_variance, tf.ones(growth_shape)], axis=-1)\n",
    "            self.offset = tf.Variable(name='offset', initial_value=new_offset, trainable=True)\n",
    "            self.scale = tf.Variable(name='scale', initial_value=new_scale, trainable=True)\n",
    "            self.moving_mean = tf.Variable(name='moving_mean', initial_value=new_moving_mean, trainable=False)\n",
    "            self.moving_variance = tf.Variable(name='moving_variance', initial_value=new_moving_variance, trainable=False)\n",
    "        return n_new_input_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdd7c11-c9cb-41da-a62e-71145fa1d582",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "schedule = [DynamicEpoch(0.00035, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 30\n",
    "train_fn_conv(x=cifar100.X_train_norm, y=cifar100.y_train, \n",
    "              validation_data=(cifar100.X_test_norm, cifar100.y_test), learning_rate=0.0006, \n",
    "              schedule=schedule, layer_sizes=layer_sizes, output_neurons=100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23b4e706-a40a-45d9-bd4b-e5df2e3077fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1249937"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_convolutional_model(cifar100.X_norm, layer_sizes=[32, 85, 128, 128, 85, 341, 341], output_neurons=100)\n",
    "model.build(cifar100.X_norm.shape)\n",
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "804e01ed-34e6-4f1d-a4f4-f314e8c9fbe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1662165"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_convolutional_model(cifar100.X_norm, layer_sizes=[45, 113, 115, 115, 172, 257, 414], output_neurons=100)\n",
    "model.build(cifar100.X_norm.shape)\n",
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24907582-3dd9-4389-b7a5-9e514872f5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1283618"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_convolutional_model(cifar100.X_norm, layer_sizes=[40, 92, 85, 91, 148, 243, 346], output_neurons=100)\n",
    "model.build(cifar100.X_norm.shape)\n",
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65fe4b3d-fa01-4c0c-8b1a-4d8270753727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4880848"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_convolutional_model(cifar100.X_norm, layer_sizes=[89, 158, 144, 204, 321, 519, 687], output_neurons=100)\n",
    "model.build(cifar100.X_norm.shape)\n",
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7ae6291-83e4-4986-ad25-7c0e0138653f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2737636"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_convolutional_model(cifar100.X_norm, layer_sizes=[54, 98, 82, 113, 249, 407, 570], output_neurons=100)\n",
    "model.build(cifar100.X_norm.shape)\n",
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5da52b65-4ecc-4f7c-b71f-7ce67a79266f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1401959"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_convolutional_model(cifar100.X_norm, layer_sizes=[54, 75, 68, 74, 151, 285, 399], output_neurons=100)\n",
    "model.build(cifar100.X_norm.shape)\n",
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "703adbe5-18c5-4249-8491-036be2fd1324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################################\n",
      "Epoch 1/50\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 5.291324138641357 - val_metric: 0.0107 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 5.291316032409668 - val_metric: 0.0107 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 52, 105, 153, 153, 105, 409, 409], total units: 1389\n",
      "Before pruning:\n",
      "loss: 4.703121662139893 - metric: 0.03691999986767769 - val_loss: 4.544463634490967 - val_metric: 0.0189 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 52, 105, 153, 153, 105, 409, 409], total units: 1389\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.549563407897949 - val_metric: 0.0185 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 44, 93, 117, 118, 105, 270, 341], total units: 1091\n",
      "##########################################################\n",
      "Epoch 2/50\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.549563407897949 - val_metric: 0.0185 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 44, 93, 117, 118, 105, 270, 341], total units: 1091\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.549561023712158 - val_metric: 0.0185 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 64, 113, 140, 141, 126, 324, 409], total units: 1320\n",
      "Before pruning:\n",
      "loss: 4.459319591522217 - metric: 0.0379600003361702 - val_loss: 4.3380231857299805 - val_metric: 0.0453 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 64, 113, 140, 141, 126, 324, 409], total units: 1320\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.343166828155518 - val_metric: 0.0477 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 49, 83, 80, 86, 124, 239, 348], total units: 1012\n",
      "##########################################################\n",
      "Epoch 3/50\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.343166828155518 - val_metric: 0.0477 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 49, 83, 80, 86, 124, 239, 348], total units: 1012\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.343168258666992 - val_metric: 0.0477 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 69, 103, 100, 106, 148, 286, 417], total units: 1232\n",
      "Before pruning:\n",
      "loss: 4.247586727142334 - metric: 0.04879999905824661 - val_loss: 4.117953300476074 - val_metric: 0.0669 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 69, 103, 100, 106, 148, 286, 417], total units: 1232\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.14404821395874 - val_metric: 0.0631 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 45, 84, 86, 97, 130, 213, 363], total units: 1021\n",
      "##########################################################\n",
      "Epoch 4/50\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.14404821395874 - val_metric: 0.0631 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 45, 84, 86, 97, 130, 213, 363], total units: 1021\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.144049644470215 - val_metric: 0.0631 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 65, 104, 106, 117, 156, 255, 435], total units: 1241\n",
      "Before pruning:\n",
      "loss: 4.144129276275635 - metric: 0.06004000082612038 - val_loss: 4.26912784576416 - val_metric: 0.0472 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 65, 104, 106, 117, 156, 255, 435], total units: 1241\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.265250205993652 - val_metric: 0.0486 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 43, 69, 60, 88, 128, 190, 379], total units: 960\n",
      "##########################################################\n",
      "Epoch 5/50\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.265250205993652 - val_metric: 0.0486 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 43, 69, 60, 88, 128, 190, 379], total units: 960\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.265250205993652 - val_metric: 0.0487 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 63, 89, 80, 108, 153, 228, 454], total units: 1178\n",
      "Before pruning:\n",
      "loss: 4.080292224884033 - metric: 0.06521999835968018 - val_loss: 4.090951442718506 - val_metric: 0.0633 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 63, 89, 80, 108, 153, 228, 454], total units: 1178\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.0883917808532715 - val_metric: 0.0662 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 38, 71, 72, 86, 133, 192, 375], total units: 970\n",
      "##########################################################\n",
      "Epoch 6/50\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.0883917808532715 - val_metric: 0.0662 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 38, 71, 72, 86, 133, 192, 375], total units: 970\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.08839225769043 - val_metric: 0.0662 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 58, 91, 92, 106, 159, 230, 450], total units: 1189\n",
      "Before pruning:\n",
      "loss: 4.051141738891602 - metric: 0.0674000009894371 - val_loss: 4.087037563323975 - val_metric: 0.0615 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 58, 91, 92, 106, 159, 230, 450], total units: 1189\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.085074424743652 - val_metric: 0.0593 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 37, 54, 62, 79, 132, 210, 377], total units: 954\n",
      "##########################################################\n",
      "Epoch 7/50\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.085074424743652 - val_metric: 0.0593 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 37, 54, 62, 79, 132, 210, 377], total units: 954\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.085076808929443 - val_metric: 0.0593 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 57, 74, 82, 99, 158, 252, 452], total units: 1177\n",
      "Before pruning:\n",
      "loss: 3.9985287189483643 - metric: 0.07171999663114548 - val_loss: 4.01100492477417 - val_metric: 0.0764 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 57, 74, 82, 99, 158, 252, 452], total units: 1177\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.019465446472168 - val_metric: 0.0779 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 38, 58, 62, 80, 122, 206, 361], total units: 930\n",
      "##########################################################\n",
      "Epoch 8/50\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.019465446472168 - val_metric: 0.0779 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 38, 58, 62, 80, 122, 206, 361], total units: 930\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.019466400146484 - val_metric: 0.0779 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 58, 78, 82, 100, 146, 247, 433], total units: 1147\n",
      "Before pruning:\n",
      "loss: 3.9788947105407715 - metric: 0.07129999995231628 - val_loss: 3.8534116744995117 - val_metric: 0.1014 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 58, 78, 82, 100, 146, 247, 433], total units: 1147\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.8513848781585693 - val_metric: 0.1018 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 47, 61, 54, 68, 134, 215, 365], total units: 947\n",
      "##########################################################\n",
      "Epoch 9/50\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.8513848781585693 - val_metric: 0.1018 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 47, 61, 54, 68, 134, 215, 365], total units: 947\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.8513848781585693 - val_metric: 0.1018 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 67, 81, 74, 88, 160, 258, 438], total units: 1169\n",
      "Before pruning:\n",
      "loss: 3.955388069152832 - metric: 0.07732000201940536 - val_loss: 4.090855121612549 - val_metric: 0.0693 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 67, 81, 74, 88, 160, 258, 438], total units: 1169\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.07581901550293 - val_metric: 0.0707 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 43, 63, 67, 85, 147, 224, 361], total units: 993\n",
      "##########################################################\n",
      "Epoch 10/50\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.07581901550293 - val_metric: 0.0707 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 43, 63, 67, 85, 147, 224, 361], total units: 993\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.075819492340088 - val_metric: 0.0707 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 63, 83, 87, 105, 176, 268, 433], total units: 1218\n",
      "Before pruning:\n",
      "loss: 3.949291944503784 - metric: 0.07688000053167343 - val_loss: 3.9698081016540527 - val_metric: 0.0913 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 63, 83, 87, 105, 176, 268, 433], total units: 1218\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.9625980854034424 - val_metric: 0.0909 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 43, 55, 35, 55, 134, 236, 374], total units: 935\n",
      "##########################################################\n",
      "Epoch 11/50\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.9625980854034424 - val_metric: 0.0909 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 43, 55, 35, 55, 134, 236, 374], total units: 935\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.9626145362854004 - val_metric: 0.0909 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 63, 75, 55, 75, 160, 283, 448], total units: 1162\n",
      "Before pruning:\n",
      "loss: 3.9144363403320312 - metric: 0.08141999691724777 - val_loss: 3.8389344215393066 - val_metric: 0.1067 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 63, 75, 55, 75, 160, 283, 448], total units: 1162\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.839813232421875 - val_metric: 0.1061 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 46, 60, 54, 68, 145, 248, 385], total units: 1009\n",
      "##########################################################\n",
      "Epoch 12/50\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.839813232421875 - val_metric: 0.1061 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 46, 60, 54, 68, 145, 248, 385], total units: 1009\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.8397881984710693 - val_metric: 0.1061 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 66, 80, 74, 88, 174, 297, 462], total units: 1244\n",
      "Before pruning:\n",
      "loss: 3.9200363159179688 - metric: 0.08094000071287155 - val_loss: 3.802687168121338 - val_metric: 0.1167 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 66, 80, 74, 88, 174, 297, 462], total units: 1244\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.801640510559082 - val_metric: 0.1164 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 50, 61, 57, 73, 137, 232, 389], total units: 1002\n",
      "##########################################################\n",
      "Epoch 13/50\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.801640510559082 - val_metric: 0.1164 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 50, 61, 57, 73, 137, 232, 389], total units: 1002\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.8016562461853027 - val_metric: 0.1165 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 70, 81, 77, 93, 164, 278, 466], total units: 1232\n",
      "Before pruning:\n",
      "loss: 3.9068493843078613 - metric: 0.08472000062465668 - val_loss: 3.874154806137085 - val_metric: 0.0952 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 70, 81, 77, 93, 164, 278, 466], total units: 1232\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.8802831172943115 - val_metric: 0.0945 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 45, 64, 69, 89, 144, 243, 388], total units: 1045\n",
      "##########################################################\n",
      "Epoch 14/50\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.8802831172943115 - val_metric: 0.0945 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 45, 64, 69, 89, 144, 243, 388], total units: 1045\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.8802905082702637 - val_metric: 0.0945 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 65, 84, 89, 109, 172, 291, 465], total units: 1278\n",
      "Before pruning:\n",
      "loss: 3.900813341140747 - metric: 0.08613999933004379 - val_loss: 3.882939338684082 - val_metric: 0.1014 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 65, 84, 89, 109, 172, 291, 465], total units: 1278\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.881084442138672 - val_metric: 0.1005 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 43, 63, 44, 66, 137, 241, 387], total units: 984\n",
      "##########################################################\n",
      "Epoch 15/50\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.881084442138672 - val_metric: 0.1005 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 43, 63, 44, 66, 137, 241, 387], total units: 984\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.88106632232666 - val_metric: 0.1005 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 63, 83, 64, 86, 164, 289, 464], total units: 1216\n",
      "Before pruning:\n",
      "loss: 3.8712222576141357 - metric: 0.08839999884366989 - val_loss: 3.8210926055908203 - val_metric: 0.112 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 63, 83, 64, 86, 164, 289, 464], total units: 1216\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.8205690383911133 - val_metric: 0.1101 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 42, 50, 53, 80, 148, 258, 406], total units: 1040\n",
      "##########################################################\n",
      "Epoch 16/50\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.8205690383911133 - val_metric: 0.1101 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 42, 50, 53, 80, 148, 258, 406], total units: 1040\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.820571184158325 - val_metric: 0.1101 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 62, 70, 73, 100, 177, 309, 487], total units: 1281\n",
      "Before pruning:\n",
      "loss: 3.8658688068389893 - metric: 0.08879999816417694 - val_loss: 3.868396759033203 - val_metric: 0.1056 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 62, 70, 73, 100, 177, 309, 487], total units: 1281\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.872136354446411 - val_metric: 0.1052 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 40, 61, 63, 90, 148, 272, 411], total units: 1088\n",
      "##########################################################\n",
      "Epoch 17/50\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.872136354446411 - val_metric: 0.1052 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 40, 61, 63, 90, 148, 272, 411], total units: 1088\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.8721346855163574 - val_metric: 0.1052 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 60, 81, 83, 110, 177, 326, 493], total units: 1333\n",
      "Before pruning:\n",
      "loss: 3.860919952392578 - metric: 0.08829999715089798 - val_loss: 3.8557698726654053 - val_metric: 0.1023 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 60, 81, 83, 110, 177, 326, 493], total units: 1333\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.8577167987823486 - val_metric: 0.1014 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 40, 69, 47, 52, 147, 259, 392], total units: 1009\n",
      "##########################################################\n",
      "Epoch 18/50\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.8577167987823486 - val_metric: 0.1014 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 40, 69, 47, 52, 147, 259, 392], total units: 1009\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.857802629470825 - val_metric: 0.1013 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 60, 89, 67, 72, 176, 310, 470], total units: 1247\n",
      "Before pruning:\n",
      "loss: 3.8587567806243896 - metric: 0.09102000296115875 - val_loss: 3.80008864402771 - val_metric: 0.113 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 60, 89, 67, 72, 176, 310, 470], total units: 1247\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.796480417251587 - val_metric: 0.1142 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 34, 49, 55, 69, 160, 274, 400], total units: 1044\n",
      "##########################################################\n",
      "Epoch 19/50\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.796480417251587 - val_metric: 0.1142 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 34, 49, 55, 69, 160, 274, 400], total units: 1044\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.7964816093444824 - val_metric: 0.1142 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 54, 69, 75, 89, 192, 328, 480], total units: 1290\n",
      "Before pruning:\n",
      "loss: 3.827441453933716 - metric: 0.09567999839782715 - val_loss: 3.7762703895568848 - val_metric: 0.1152 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 54, 69, 75, 89, 192, 328, 480], total units: 1290\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.768497943878174 - val_metric: 0.1176 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 44, 64, 67, 81, 163, 265, 403], total units: 1090\n",
      "##########################################################\n",
      "Epoch 20/50\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.768497943878174 - val_metric: 0.1176 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 44, 64, 67, 81, 163, 265, 403], total units: 1090\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.7684848308563232 - val_metric: 0.1175 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 64, 84, 87, 101, 195, 318, 483], total units: 1335\n",
      "Before pruning:\n",
      "loss: 3.8293046951293945 - metric: 0.09589999914169312 - val_loss: 3.792809009552002 - val_metric: 0.118 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 64, 84, 87, 101, 195, 318, 483], total units: 1335\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.792659282684326 - val_metric: 0.1181 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "##########################################################\n",
      "Epoch 21/50\n",
      "loss: 3.5286405086517334 - metric: 0.14951999485492706 - val_loss: 3.1718599796295166 - val_metric: 0.2135 - penalty: 0.0\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "##########################################################\n",
      "Epoch 22/50\n",
      "loss: 3.119860887527466 - metric: 0.22288000583648682 - val_loss: 2.9359147548675537 - val_metric: 0.2625 - penalty: 0.0\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "##########################################################\n",
      "Epoch 23/50\n",
      "loss: 2.9153389930725098 - metric: 0.2635599970817566 - val_loss: 2.7034053802490234 - val_metric: 0.3044 - penalty: 0.0\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "##########################################################\n",
      "Epoch 24/50\n",
      "loss: 2.746250867843628 - metric: 0.3009600043296814 - val_loss: 2.5882341861724854 - val_metric: 0.3329 - penalty: 0.0\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "##########################################################\n",
      "Epoch 25/50\n",
      "loss: 2.611711025238037 - metric: 0.3251599967479706 - val_loss: 2.5351758003234863 - val_metric: 0.3463 - penalty: 0.0\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "##########################################################\n",
      "Epoch 26/50\n",
      "loss: 2.5217537879943848 - metric: 0.3447999954223633 - val_loss: 2.451542854309082 - val_metric: 0.3657 - penalty: 0.0\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "##########################################################\n",
      "Epoch 27/50\n",
      "loss: 2.4377903938293457 - metric: 0.36149999499320984 - val_loss: 2.313870668411255 - val_metric: 0.397 - penalty: 0.0\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "##########################################################\n",
      "Epoch 28/50\n",
      "loss: 2.3668408393859863 - metric: 0.3783999979496002 - val_loss: 2.35158109664917 - val_metric: 0.3915 - penalty: 0.0\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "##########################################################\n",
      "Epoch 29/50\n",
      "loss: 2.3098018169403076 - metric: 0.38995999097824097 - val_loss: 2.2105631828308105 - val_metric: 0.422 - penalty: 0.0\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "##########################################################\n",
      "Epoch 30/50\n",
      "loss: 2.2732138633728027 - metric: 0.3980199992656708 - val_loss: 2.24554181098938 - val_metric: 0.417 - penalty: 0.0\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "##########################################################\n",
      "Epoch 31/50\n",
      "loss: 2.215714454650879 - metric: 0.4081200063228607 - val_loss: 2.1674766540527344 - val_metric: 0.4319 - penalty: 0.0\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "##########################################################\n",
      "Epoch 32/50\n",
      "loss: 2.1793954372406006 - metric: 0.4174000024795532 - val_loss: 2.124666213989258 - val_metric: 0.4333 - penalty: 0.0\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "##########################################################\n",
      "Epoch 33/50\n",
      "loss: 2.1461281776428223 - metric: 0.4248200058937073 - val_loss: 2.0969479084014893 - val_metric: 0.4465 - penalty: 0.0\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "##########################################################\n",
      "Epoch 34/50\n",
      "loss: 2.1089487075805664 - metric: 0.43285998702049255 - val_loss: 2.06304931640625 - val_metric: 0.454 - penalty: 0.0\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "##########################################################\n",
      "Epoch 35/50\n",
      "loss: 2.073307991027832 - metric: 0.43950000405311584 - val_loss: 1.984543800354004 - val_metric: 0.4701 - penalty: 0.0\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "##########################################################\n",
      "Epoch 36/50\n",
      "loss: 2.0417354106903076 - metric: 0.4462200105190277 - val_loss: 2.078261375427246 - val_metric: 0.4527 - penalty: 0.0\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "##########################################################\n",
      "Epoch 37/50\n",
      "loss: 2.014540672302246 - metric: 0.4536600112915039 - val_loss: 2.0576388835906982 - val_metric: 0.4598 - penalty: 0.0\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "##########################################################\n",
      "Epoch 38/50\n",
      "loss: 1.984652042388916 - metric: 0.46132001280784607 - val_loss: 2.0135254859924316 - val_metric: 0.4675 - penalty: 0.0\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "##########################################################\n",
      "Epoch 39/50\n",
      "loss: 1.9486398696899414 - metric: 0.4673599898815155 - val_loss: 1.993196725845337 - val_metric: 0.4722 - penalty: 0.0\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "##########################################################\n",
      "Epoch 40/50\n",
      "loss: 1.9270168542861938 - metric: 0.4743399918079376 - val_loss: 1.9119939804077148 - val_metric: 0.4934 - penalty: 0.0\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "##########################################################\n",
      "Epoch 41/50\n",
      "loss: 1.9049450159072876 - metric: 0.47760000824928284 - val_loss: 1.996229648590088 - val_metric: 0.4779 - penalty: 0.0\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "##########################################################\n",
      "Epoch 42/50\n",
      "loss: 1.8731952905654907 - metric: 0.4853599965572357 - val_loss: 1.9687610864639282 - val_metric: 0.48 - penalty: 0.0\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "##########################################################\n",
      "Epoch 43/50\n",
      "loss: 1.8610385656356812 - metric: 0.4884999990463257 - val_loss: 1.9010334014892578 - val_metric: 0.494 - penalty: 0.0\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "##########################################################\n",
      "Epoch 44/50\n",
      "loss: 1.8306832313537598 - metric: 0.4961400032043457 - val_loss: 1.998901605606079 - val_metric: 0.4774 - penalty: 0.0\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "##########################################################\n",
      "Epoch 45/50\n",
      "loss: 1.8127906322479248 - metric: 0.4968999922275543 - val_loss: 1.9831421375274658 - val_metric: 0.4826 - penalty: 0.0\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "##########################################################\n",
      "Epoch 46/50\n",
      "loss: 1.7956626415252686 - metric: 0.5052800178527832 - val_loss: 1.8675891160964966 - val_metric: 0.5027 - penalty: 0.0\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "##########################################################\n",
      "Epoch 47/50\n",
      "loss: 1.7691645622253418 - metric: 0.5090799927711487 - val_loss: 1.8768175840377808 - val_metric: 0.506 - penalty: 0.0\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "##########################################################\n",
      "Epoch 48/50\n",
      "loss: 1.7608144283294678 - metric: 0.5120599865913391 - val_loss: 1.8316501379013062 - val_metric: 0.5115 - penalty: 0.0\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "##########################################################\n",
      "Epoch 49/50\n",
      "loss: 1.7316988706588745 - metric: 0.5172200202941895 - val_loss: 1.8196125030517578 - val_metric: 0.5113 - penalty: 0.0\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "##########################################################\n",
      "Epoch 50/50\n",
      "loss: 1.7259821891784668 - metric: 0.516979992389679 - val_loss: 1.8995798826217651 - val_metric: 0.5005 - penalty: 0.0\n",
      "hidden layer sizes: [3, 48, 72, 59, 86, 159, 273, 402], total units: 1102\n",
      "CPU times: user 6min 1s, sys: 10.2 s, total: 6min 11s\n",
      "Wall time: 5min 57s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [4.703121662139893,\n",
       "  4.459319591522217,\n",
       "  4.247586727142334,\n",
       "  4.144129276275635,\n",
       "  4.080292224884033,\n",
       "  4.051141738891602,\n",
       "  3.9985287189483643,\n",
       "  3.9788947105407715,\n",
       "  3.955388069152832,\n",
       "  3.949291944503784,\n",
       "  3.9144363403320312,\n",
       "  3.9200363159179688,\n",
       "  3.9068493843078613,\n",
       "  3.900813341140747,\n",
       "  3.8712222576141357,\n",
       "  3.8658688068389893,\n",
       "  3.860919952392578,\n",
       "  3.8587567806243896,\n",
       "  3.827441453933716,\n",
       "  3.8293046951293945,\n",
       "  3.5286405086517334,\n",
       "  3.119860887527466,\n",
       "  2.9153389930725098,\n",
       "  2.746250867843628,\n",
       "  2.611711025238037,\n",
       "  2.5217537879943848,\n",
       "  2.4377903938293457,\n",
       "  2.3668408393859863,\n",
       "  2.3098018169403076,\n",
       "  2.2732138633728027,\n",
       "  2.215714454650879,\n",
       "  2.1793954372406006,\n",
       "  2.1461281776428223,\n",
       "  2.1089487075805664,\n",
       "  2.073307991027832,\n",
       "  2.0417354106903076,\n",
       "  2.014540672302246,\n",
       "  1.984652042388916,\n",
       "  1.9486398696899414,\n",
       "  1.9270168542861938,\n",
       "  1.9049450159072876,\n",
       "  1.8731952905654907,\n",
       "  1.8610385656356812,\n",
       "  1.8306832313537598,\n",
       "  1.8127906322479248,\n",
       "  1.7956626415252686,\n",
       "  1.7691645622253418,\n",
       "  1.7608144283294678,\n",
       "  1.7316988706588745,\n",
       "  1.7259821891784668],\n",
       " 'metric': [0.03691999986767769,\n",
       "  0.0379600003361702,\n",
       "  0.04879999905824661,\n",
       "  0.06004000082612038,\n",
       "  0.06521999835968018,\n",
       "  0.0674000009894371,\n",
       "  0.07171999663114548,\n",
       "  0.07129999995231628,\n",
       "  0.07732000201940536,\n",
       "  0.07688000053167343,\n",
       "  0.08141999691724777,\n",
       "  0.08094000071287155,\n",
       "  0.08472000062465668,\n",
       "  0.08613999933004379,\n",
       "  0.08839999884366989,\n",
       "  0.08879999816417694,\n",
       "  0.08829999715089798,\n",
       "  0.09102000296115875,\n",
       "  0.09567999839782715,\n",
       "  0.09589999914169312,\n",
       "  0.14951999485492706,\n",
       "  0.22288000583648682,\n",
       "  0.2635599970817566,\n",
       "  0.3009600043296814,\n",
       "  0.3251599967479706,\n",
       "  0.3447999954223633,\n",
       "  0.36149999499320984,\n",
       "  0.3783999979496002,\n",
       "  0.38995999097824097,\n",
       "  0.3980199992656708,\n",
       "  0.4081200063228607,\n",
       "  0.4174000024795532,\n",
       "  0.4248200058937073,\n",
       "  0.43285998702049255,\n",
       "  0.43950000405311584,\n",
       "  0.4462200105190277,\n",
       "  0.4536600112915039,\n",
       "  0.46132001280784607,\n",
       "  0.4673599898815155,\n",
       "  0.4743399918079376,\n",
       "  0.47760000824928284,\n",
       "  0.4853599965572357,\n",
       "  0.4884999990463257,\n",
       "  0.4961400032043457,\n",
       "  0.4968999922275543,\n",
       "  0.5052800178527832,\n",
       "  0.5090799927711487,\n",
       "  0.5120599865913391,\n",
       "  0.5172200202941895,\n",
       "  0.516979992389679],\n",
       " 'val_loss': [4.549563407897949,\n",
       "  4.343166828155518,\n",
       "  4.14404821395874,\n",
       "  4.265250205993652,\n",
       "  4.0883917808532715,\n",
       "  4.085074424743652,\n",
       "  4.019465446472168,\n",
       "  3.8513848781585693,\n",
       "  4.07581901550293,\n",
       "  3.9625980854034424,\n",
       "  3.839813232421875,\n",
       "  3.801640510559082,\n",
       "  3.8802831172943115,\n",
       "  3.881084442138672,\n",
       "  3.8205690383911133,\n",
       "  3.872136354446411,\n",
       "  3.8577167987823486,\n",
       "  3.796480417251587,\n",
       "  3.768497943878174,\n",
       "  3.792659282684326,\n",
       "  3.1718599796295166,\n",
       "  2.9359147548675537,\n",
       "  2.7034053802490234,\n",
       "  2.5882341861724854,\n",
       "  2.5351758003234863,\n",
       "  2.451542854309082,\n",
       "  2.313870668411255,\n",
       "  2.35158109664917,\n",
       "  2.2105631828308105,\n",
       "  2.24554181098938,\n",
       "  2.1674766540527344,\n",
       "  2.124666213989258,\n",
       "  2.0969479084014893,\n",
       "  2.06304931640625,\n",
       "  1.984543800354004,\n",
       "  2.078261375427246,\n",
       "  2.0576388835906982,\n",
       "  2.0135254859924316,\n",
       "  1.993196725845337,\n",
       "  1.9119939804077148,\n",
       "  1.996229648590088,\n",
       "  1.9687610864639282,\n",
       "  1.9010334014892578,\n",
       "  1.998901605606079,\n",
       "  1.9831421375274658,\n",
       "  1.8675891160964966,\n",
       "  1.8768175840377808,\n",
       "  1.8316501379013062,\n",
       "  1.8196125030517578,\n",
       "  1.8995798826217651],\n",
       " 'val_metric': [0.0185,\n",
       "  0.0477,\n",
       "  0.0631,\n",
       "  0.0486,\n",
       "  0.0662,\n",
       "  0.0593,\n",
       "  0.0779,\n",
       "  0.1018,\n",
       "  0.0707,\n",
       "  0.0909,\n",
       "  0.1061,\n",
       "  0.1164,\n",
       "  0.0945,\n",
       "  0.1005,\n",
       "  0.1101,\n",
       "  0.1052,\n",
       "  0.1014,\n",
       "  0.1142,\n",
       "  0.1176,\n",
       "  0.1181,\n",
       "  0.2135,\n",
       "  0.2625,\n",
       "  0.3044,\n",
       "  0.3329,\n",
       "  0.3463,\n",
       "  0.3657,\n",
       "  0.397,\n",
       "  0.3915,\n",
       "  0.422,\n",
       "  0.417,\n",
       "  0.4319,\n",
       "  0.4333,\n",
       "  0.4465,\n",
       "  0.454,\n",
       "  0.4701,\n",
       "  0.4527,\n",
       "  0.4598,\n",
       "  0.4675,\n",
       "  0.4722,\n",
       "  0.4934,\n",
       "  0.4779,\n",
       "  0.48,\n",
       "  0.494,\n",
       "  0.4774,\n",
       "  0.4826,\n",
       "  0.5027,\n",
       "  0.506,\n",
       "  0.5115,\n",
       "  0.5113,\n",
       "  0.5005],\n",
       " 'hidden_layer_sizes': [[3, 44, 93, 117, 118, 105, 270, 341],\n",
       "  [3, 49, 83, 80, 86, 124, 239, 348],\n",
       "  [3, 45, 84, 86, 97, 130, 213, 363],\n",
       "  [3, 43, 69, 60, 88, 128, 190, 379],\n",
       "  [3, 38, 71, 72, 86, 133, 192, 375],\n",
       "  [3, 37, 54, 62, 79, 132, 210, 377],\n",
       "  [3, 38, 58, 62, 80, 122, 206, 361],\n",
       "  [3, 47, 61, 54, 68, 134, 215, 365],\n",
       "  [3, 43, 63, 67, 85, 147, 224, 361],\n",
       "  [3, 43, 55, 35, 55, 134, 236, 374],\n",
       "  [3, 46, 60, 54, 68, 145, 248, 385],\n",
       "  [3, 50, 61, 57, 73, 137, 232, 389],\n",
       "  [3, 45, 64, 69, 89, 144, 243, 388],\n",
       "  [3, 43, 63, 44, 66, 137, 241, 387],\n",
       "  [3, 42, 50, 53, 80, 148, 258, 406],\n",
       "  [3, 40, 61, 63, 90, 148, 272, 411],\n",
       "  [3, 40, 69, 47, 52, 147, 259, 392],\n",
       "  [3, 34, 49, 55, 69, 160, 274, 400],\n",
       "  [3, 44, 64, 67, 81, 163, 265, 403],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402],\n",
       "  [3, 48, 72, 59, 86, 159, 273, 402]]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "schedule = [DynamicEpoch(0.00035, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 30\n",
    "train_fn_conv(x=cifar100.X_train_norm, y=cifar100.y_train, \n",
    "              validation_data=(cifar100.X_test_norm, cifar100.y_test), learning_rate=0.0006, \n",
    "              schedule=schedule, layer_sizes=layer_sizes, output_neurons=100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a2493a9-3a0b-4997-9ddc-0c5de954253e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################################\n",
      "Epoch 1/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 5.229409694671631 - val_metric: 0.0124 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 5.229409217834473 - val_metric: 0.0124 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 52, 105, 153, 153, 105, 409, 409], total units: 1389\n",
      "Before pruning:\n",
      "loss: 4.733028888702393 - metric: 0.038120001554489136 - val_loss: 4.581501483917236 - val_metric: 0.0108 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 52, 105, 153, 153, 105, 409, 409], total units: 1389\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.57942008972168 - val_metric: 0.0099 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 51, 95, 91, 86, 105, 244, 341], total units: 1016\n",
      "##########################################################\n",
      "Epoch 2/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.57942008972168 - val_metric: 0.0099 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 51, 95, 91, 86, 105, 244, 341], total units: 1016\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.57942008972168 - val_metric: 0.0099 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 71, 115, 111, 106, 126, 292, 409], total units: 1233\n",
      "Before pruning:\n",
      "loss: 4.432036876678467 - metric: 0.04312000051140785 - val_loss: 4.32390022277832 - val_metric: 0.0482 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 71, 115, 111, 106, 126, 292, 409], total units: 1233\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.328681468963623 - val_metric: 0.0493 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 57, 76, 83, 87, 124, 258, 352], total units: 1040\n",
      "##########################################################\n",
      "Epoch 3/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.328681468963623 - val_metric: 0.0493 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 57, 76, 83, 87, 124, 258, 352], total units: 1040\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.328683853149414 - val_metric: 0.0493 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 77, 96, 103, 107, 148, 309, 422], total units: 1265\n",
      "Before pruning:\n",
      "loss: 4.257425308227539 - metric: 0.049240000545978546 - val_loss: 4.2506794929504395 - val_metric: 0.0526 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 77, 96, 103, 107, 148, 309, 422], total units: 1265\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.254485607147217 - val_metric: 0.0531 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 35, 74, 66, 94, 137, 216, 364], total units: 989\n",
      "##########################################################\n",
      "Epoch 4/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.254485607147217 - val_metric: 0.0531 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 35, 74, 66, 94, 137, 216, 364], total units: 989\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.25448751449585 - val_metric: 0.0531 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 55, 94, 86, 114, 164, 259, 436], total units: 1211\n",
      "Before pruning:\n",
      "loss: 4.147165298461914 - metric: 0.05640000104904175 - val_loss: 4.183206081390381 - val_metric: 0.0522 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 55, 94, 86, 114, 164, 259, 436], total units: 1211\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.195013046264648 - val_metric: 0.0516 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 43, 71, 59, 73, 115, 176, 382], total units: 922\n",
      "##########################################################\n",
      "Epoch 5/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.195013046264648 - val_metric: 0.0516 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 43, 71, 59, 73, 115, 176, 382], total units: 922\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.195021152496338 - val_metric: 0.0516 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 63, 91, 79, 93, 138, 211, 458], total units: 1136\n",
      "Before pruning:\n",
      "loss: 4.070200443267822 - metric: 0.06430000066757202 - val_loss: 4.066438674926758 - val_metric: 0.0742 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 63, 91, 79, 93, 138, 211, 458], total units: 1136\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.062140941619873 - val_metric: 0.0749 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 41, 67, 75, 89, 128, 190, 369], total units: 962\n",
      "##########################################################\n",
      "Epoch 6/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.062140941619873 - val_metric: 0.0749 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 41, 67, 75, 89, 128, 190, 369], total units: 962\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.062140464782715 - val_metric: 0.0749 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 61, 87, 95, 109, 153, 228, 442], total units: 1178\n",
      "Before pruning:\n",
      "loss: 4.038814544677734 - metric: 0.06718000024557114 - val_loss: 3.965985059738159 - val_metric: 0.0865 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 61, 87, 95, 109, 153, 228, 442], total units: 1178\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.9747512340545654 - val_metric: 0.0856 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 38, 75, 66, 78, 131, 204, 379], total units: 974\n",
      "##########################################################\n",
      "Epoch 7/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.9747512340545654 - val_metric: 0.0856 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 38, 75, 66, 78, 131, 204, 379], total units: 974\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.97475266456604 - val_metric: 0.0856 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 58, 95, 86, 98, 157, 244, 454], total units: 1195\n",
      "Before pruning:\n",
      "loss: 4.002682685852051 - metric: 0.06830000132322311 - val_loss: 3.9552500247955322 - val_metric: 0.0856 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 58, 95, 86, 98, 157, 244, 454], total units: 1195\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.9536120891571045 - val_metric: 0.0882 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 43, 68, 63, 78, 133, 208, 356], total units: 952\n",
      "##########################################################\n",
      "Epoch 8/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.9536120891571045 - val_metric: 0.0882 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 43, 68, 63, 78, 133, 208, 356], total units: 952\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.953611373901367 - val_metric: 0.0882 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 63, 88, 83, 98, 159, 249, 427], total units: 1170\n",
      "Before pruning:\n",
      "loss: 3.984564781188965 - metric: 0.0729999989271164 - val_loss: 3.987247943878174 - val_metric: 0.0781 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 63, 88, 83, 98, 159, 249, 427], total units: 1170\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.981092691421509 - val_metric: 0.0789 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 47, 61, 47, 75, 126, 216, 353], total units: 928\n",
      "##########################################################\n",
      "Epoch 9/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.981092691421509 - val_metric: 0.0789 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 47, 61, 47, 75, 126, 216, 353], total units: 928\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.98110032081604 - val_metric: 0.0789 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 67, 81, 67, 95, 151, 259, 423], total units: 1146\n",
      "Before pruning:\n",
      "loss: 3.9531188011169434 - metric: 0.07320000231266022 - val_loss: 4.00871467590332 - val_metric: 0.0744 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 67, 81, 67, 95, 151, 259, 423], total units: 1146\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.994173049926758 - val_metric: 0.0775 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 46, 65, 63, 85, 143, 225, 357], total units: 987\n",
      "##########################################################\n",
      "Epoch 10/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.994173049926758 - val_metric: 0.0775 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 46, 65, 63, 85, 143, 225, 357], total units: 987\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.994180917739868 - val_metric: 0.0774 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 66, 85, 83, 105, 171, 270, 428], total units: 1211\n",
      "Before pruning:\n",
      "loss: 3.9488308429718018 - metric: 0.07354000210762024 - val_loss: 3.9263694286346436 - val_metric: 0.0851 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 66, 85, 83, 105, 171, 270, 428], total units: 1211\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.9183218479156494 - val_metric: 0.0829 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 49, 77, 70, 87, 141, 234, 353], total units: 1014\n",
      "##########################################################\n",
      "Epoch 11/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.9183218479156494 - val_metric: 0.0829 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 49, 77, 70, 87, 141, 234, 353], total units: 1014\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.918288230895996 - val_metric: 0.0829 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 69, 97, 90, 107, 169, 280, 423], total units: 1238\n",
      "Before pruning:\n",
      "loss: 3.9352946281433105 - metric: 0.07819999754428864 - val_loss: 3.9837710857391357 - val_metric: 0.0788 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 69, 97, 90, 107, 169, 280, 423], total units: 1238\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.98376727104187 - val_metric: 0.0775 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 48, 75, 54, 78, 126, 233, 382], total units: 999\n",
      "##########################################################\n",
      "Epoch 12/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.98376727104187 - val_metric: 0.0775 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 48, 75, 54, 78, 126, 233, 382], total units: 999\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.98380184173584 - val_metric: 0.0775 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 68, 95, 74, 98, 151, 279, 458], total units: 1226\n",
      "Before pruning:\n",
      "loss: 3.912813663482666 - metric: 0.07801999896764755 - val_loss: 4.041949272155762 - val_metric: 0.0664 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 68, 95, 74, 98, 151, 279, 458], total units: 1226\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.038660526275635 - val_metric: 0.069 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 46, 56, 43, 52, 138, 249, 377], total units: 964\n",
      "##########################################################\n",
      "Epoch 13/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.038660526275635 - val_metric: 0.069 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 46, 56, 43, 52, 138, 249, 377], total units: 964\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.03866720199585 - val_metric: 0.0691 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 66, 76, 63, 72, 165, 298, 452], total units: 1195\n",
      "Before pruning:\n",
      "loss: 3.8895275592803955 - metric: 0.08596000075340271 - val_loss: 3.936035633087158 - val_metric: 0.0762 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 66, 76, 63, 72, 165, 298, 452], total units: 1195\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.9314136505126953 - val_metric: 0.0772 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 47, 76, 62, 71, 160, 251, 382], total units: 1052\n",
      "##########################################################\n",
      "Epoch 14/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.9314136505126953 - val_metric: 0.0772 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 47, 76, 62, 71, 160, 251, 382], total units: 1052\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.9314253330230713 - val_metric: 0.0772 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 67, 96, 82, 91, 192, 301, 458], total units: 1290\n",
      "Before pruning:\n",
      "loss: 3.887681245803833 - metric: 0.08414000272750854 - val_loss: 3.894151449203491 - val_metric: 0.0893 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 67, 96, 82, 91, 192, 301, 458], total units: 1290\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.891528606414795 - val_metric: 0.0898 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 37, 55, 64, 88, 169, 260, 387], total units: 1063\n",
      "##########################################################\n",
      "Epoch 15/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.891528606414795 - val_metric: 0.0898 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 37, 55, 64, 88, 169, 260, 387], total units: 1063\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.8915441036224365 - val_metric: 0.0898 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 57, 75, 84, 108, 202, 312, 464], total units: 1305\n",
      "Before pruning:\n",
      "loss: 3.876310348510742 - metric: 0.08618000149726868 - val_loss: 3.919872999191284 - val_metric: 0.088 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 57, 75, 84, 108, 202, 312, 464], total units: 1305\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.9099936485290527 - val_metric: 0.0899 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 34, 58, 54, 80, 149, 263, 381], total units: 1022\n",
      "##########################################################\n",
      "Epoch 16/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.9099936485290527 - val_metric: 0.0899 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 34, 58, 54, 80, 149, 263, 381], total units: 1022\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.9099953174591064 - val_metric: 0.0899 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 54, 78, 74, 100, 178, 315, 457], total units: 1259\n",
      "Before pruning:\n",
      "loss: 3.850679636001587 - metric: 0.08748000115156174 - val_loss: 3.852321147918701 - val_metric: 0.1084 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 54, 78, 74, 100, 178, 315, 457], total units: 1259\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.861614942550659 - val_metric: 0.1069 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 46, 73, 53, 80, 154, 261, 387], total units: 1057\n",
      "##########################################################\n",
      "Epoch 17/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.861614942550659 - val_metric: 0.1069 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 46, 73, 53, 80, 154, 261, 387], total units: 1057\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.861626625061035 - val_metric: 0.107 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 66, 93, 73, 100, 184, 313, 464], total units: 1296\n",
      "Before pruning:\n",
      "loss: 3.8487446308135986 - metric: 0.08801999688148499 - val_loss: 3.7662527561187744 - val_metric: 0.1108 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 66, 93, 73, 100, 184, 313, 464], total units: 1296\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.7560176849365234 - val_metric: 0.1123 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 56, 88, 73, 93, 156, 271, 391], total units: 1131\n",
      "##########################################################\n",
      "Epoch 18/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.7560176849365234 - val_metric: 0.1123 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 56, 88, 73, 93, 156, 271, 391], total units: 1131\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.755966901779175 - val_metric: 0.1123 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 76, 108, 93, 113, 187, 325, 469], total units: 1374\n",
      "Before pruning:\n",
      "loss: 3.831327199935913 - metric: 0.0908999964594841 - val_loss: 3.8455328941345215 - val_metric: 0.1078 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 76, 108, 93, 113, 187, 325, 469], total units: 1374\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.8437862396240234 - val_metric: 0.1104 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 51, 75, 63, 84, 154, 249, 412], total units: 1091\n",
      "##########################################################\n",
      "Epoch 19/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.8437862396240234 - val_metric: 0.1104 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 51, 75, 63, 84, 154, 249, 412], total units: 1091\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.8438031673431396 - val_metric: 0.1104 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 71, 95, 83, 104, 184, 298, 494], total units: 1332\n",
      "Before pruning:\n",
      "loss: 3.81691312789917 - metric: 0.09285999834537506 - val_loss: 3.705505132675171 - val_metric: 0.1226 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 71, 95, 83, 104, 184, 298, 494], total units: 1332\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.702119827270508 - val_metric: 0.1226 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 51, 84, 73, 97, 153, 277, 375], total units: 1113\n",
      "##########################################################\n",
      "Epoch 20/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.702119827270508 - val_metric: 0.1226 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 51, 84, 73, 97, 153, 277, 375], total units: 1113\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.7021210193634033 - val_metric: 0.1226 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 71, 104, 93, 117, 183, 332, 450], total units: 1353\n",
      "Before pruning:\n",
      "loss: 3.8192262649536133 - metric: 0.09638000279664993 - val_loss: 3.8502883911132812 - val_metric: 0.0959 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 71, 104, 93, 117, 183, 332, 450], total units: 1353\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.846165180206299 - val_metric: 0.0968 - penalty: 0.00035\n",
      "hidden layer sizes: [3, 54, 75, 68, 74, 151, 285, 399], total units: 1109\n",
      "##########################################################\n",
      "Epoch 21/40\n",
      "loss: 3.5308122634887695 - metric: 0.14688000082969666 - val_loss: 3.248661518096924 - val_metric: 0.1972 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 75, 68, 74, 151, 285, 399], total units: 1109\n",
      "##########################################################\n",
      "Epoch 22/40\n",
      "loss: 3.0878422260284424 - metric: 0.2261199951171875 - val_loss: 2.962479591369629 - val_metric: 0.2537 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 75, 68, 74, 151, 285, 399], total units: 1109\n",
      "##########################################################\n",
      "Epoch 23/40\n",
      "loss: 2.868180990219116 - metric: 0.2697399854660034 - val_loss: 2.7777504920959473 - val_metric: 0.3006 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 75, 68, 74, 151, 285, 399], total units: 1109\n",
      "##########################################################\n",
      "Epoch 24/40\n",
      "loss: 2.7211523056030273 - metric: 0.2999800145626068 - val_loss: 2.5076723098754883 - val_metric: 0.3449 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 75, 68, 74, 151, 285, 399], total units: 1109\n",
      "##########################################################\n",
      "Epoch 25/40\n",
      "loss: 2.6007611751556396 - metric: 0.32642000913619995 - val_loss: 2.434220314025879 - val_metric: 0.3617 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 75, 68, 74, 151, 285, 399], total units: 1109\n",
      "##########################################################\n",
      "Epoch 26/40\n",
      "loss: 2.5097155570983887 - metric: 0.3459399938583374 - val_loss: 2.3353092670440674 - val_metric: 0.3832 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 75, 68, 74, 151, 285, 399], total units: 1109\n",
      "##########################################################\n",
      "Epoch 27/40\n",
      "loss: 2.4479269981384277 - metric: 0.3607400059700012 - val_loss: 2.3630638122558594 - val_metric: 0.3806 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 75, 68, 74, 151, 285, 399], total units: 1109\n",
      "##########################################################\n",
      "Epoch 28/40\n",
      "loss: 2.378209114074707 - metric: 0.37338000535964966 - val_loss: 2.4060566425323486 - val_metric: 0.377 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 75, 68, 74, 151, 285, 399], total units: 1109\n",
      "##########################################################\n",
      "Epoch 29/40\n",
      "loss: 2.3286120891571045 - metric: 0.38359999656677246 - val_loss: 2.243743658065796 - val_metric: 0.4087 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 75, 68, 74, 151, 285, 399], total units: 1109\n",
      "##########################################################\n",
      "Epoch 30/40\n",
      "loss: 2.281747341156006 - metric: 0.39375999569892883 - val_loss: 2.213308811187744 - val_metric: 0.4135 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 75, 68, 74, 151, 285, 399], total units: 1109\n",
      "##########################################################\n",
      "Epoch 31/40\n",
      "loss: 2.2332603931427 - metric: 0.4054799973964691 - val_loss: 2.169912815093994 - val_metric: 0.4239 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 75, 68, 74, 151, 285, 399], total units: 1109\n",
      "##########################################################\n",
      "Epoch 32/40\n",
      "loss: 2.206631660461426 - metric: 0.41161999106407166 - val_loss: 2.1073875427246094 - val_metric: 0.4392 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 75, 68, 74, 151, 285, 399], total units: 1109\n",
      "##########################################################\n",
      "Epoch 33/40\n",
      "loss: 2.15791916847229 - metric: 0.4217199981212616 - val_loss: 2.1168649196624756 - val_metric: 0.4377 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 75, 68, 74, 151, 285, 399], total units: 1109\n",
      "##########################################################\n",
      "Epoch 34/40\n",
      "loss: 2.1240034103393555 - metric: 0.42961999773979187 - val_loss: 2.078886032104492 - val_metric: 0.4467 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 75, 68, 74, 151, 285, 399], total units: 1109\n",
      "##########################################################\n",
      "Epoch 35/40\n",
      "loss: 2.0935168266296387 - metric: 0.4353399872779846 - val_loss: 2.0304198265075684 - val_metric: 0.4582 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 75, 68, 74, 151, 285, 399], total units: 1109\n",
      "##########################################################\n",
      "Epoch 36/40\n",
      "loss: 2.065370798110962 - metric: 0.44113999605178833 - val_loss: 2.0394675731658936 - val_metric: 0.4577 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 75, 68, 74, 151, 285, 399], total units: 1109\n",
      "##########################################################\n",
      "Epoch 37/40\n",
      "loss: 2.031012535095215 - metric: 0.4482400119304657 - val_loss: 2.0366621017456055 - val_metric: 0.4544 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 75, 68, 74, 151, 285, 399], total units: 1109\n",
      "##########################################################\n",
      "Epoch 38/40\n",
      "loss: 2.0115878582000732 - metric: 0.45405998826026917 - val_loss: 2.0227715969085693 - val_metric: 0.4621 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 75, 68, 74, 151, 285, 399], total units: 1109\n",
      "##########################################################\n",
      "Epoch 39/40\n",
      "loss: 1.978129506111145 - metric: 0.462119996547699 - val_loss: 1.9912117719650269 - val_metric: 0.4703 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 75, 68, 74, 151, 285, 399], total units: 1109\n",
      "##########################################################\n",
      "Epoch 40/40\n",
      "loss: 1.9602103233337402 - metric: 0.46720001101493835 - val_loss: 1.967511534690857 - val_metric: 0.4751 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 75, 68, 74, 151, 285, 399], total units: 1109\n",
      "CPU times: user 5min 7s, sys: 9.26 s, total: 5min 16s\n",
      "Wall time: 5min 7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [4.733028888702393,\n",
       "  4.432036876678467,\n",
       "  4.257425308227539,\n",
       "  4.147165298461914,\n",
       "  4.070200443267822,\n",
       "  4.038814544677734,\n",
       "  4.002682685852051,\n",
       "  3.984564781188965,\n",
       "  3.9531188011169434,\n",
       "  3.9488308429718018,\n",
       "  3.9352946281433105,\n",
       "  3.912813663482666,\n",
       "  3.8895275592803955,\n",
       "  3.887681245803833,\n",
       "  3.876310348510742,\n",
       "  3.850679636001587,\n",
       "  3.8487446308135986,\n",
       "  3.831327199935913,\n",
       "  3.81691312789917,\n",
       "  3.8192262649536133,\n",
       "  3.5308122634887695,\n",
       "  3.0878422260284424,\n",
       "  2.868180990219116,\n",
       "  2.7211523056030273,\n",
       "  2.6007611751556396,\n",
       "  2.5097155570983887,\n",
       "  2.4479269981384277,\n",
       "  2.378209114074707,\n",
       "  2.3286120891571045,\n",
       "  2.281747341156006,\n",
       "  2.2332603931427,\n",
       "  2.206631660461426,\n",
       "  2.15791916847229,\n",
       "  2.1240034103393555,\n",
       "  2.0935168266296387,\n",
       "  2.065370798110962,\n",
       "  2.031012535095215,\n",
       "  2.0115878582000732,\n",
       "  1.978129506111145,\n",
       "  1.9602103233337402],\n",
       " 'metric': [0.038120001554489136,\n",
       "  0.04312000051140785,\n",
       "  0.049240000545978546,\n",
       "  0.05640000104904175,\n",
       "  0.06430000066757202,\n",
       "  0.06718000024557114,\n",
       "  0.06830000132322311,\n",
       "  0.0729999989271164,\n",
       "  0.07320000231266022,\n",
       "  0.07354000210762024,\n",
       "  0.07819999754428864,\n",
       "  0.07801999896764755,\n",
       "  0.08596000075340271,\n",
       "  0.08414000272750854,\n",
       "  0.08618000149726868,\n",
       "  0.08748000115156174,\n",
       "  0.08801999688148499,\n",
       "  0.0908999964594841,\n",
       "  0.09285999834537506,\n",
       "  0.09638000279664993,\n",
       "  0.14688000082969666,\n",
       "  0.2261199951171875,\n",
       "  0.2697399854660034,\n",
       "  0.2999800145626068,\n",
       "  0.32642000913619995,\n",
       "  0.3459399938583374,\n",
       "  0.3607400059700012,\n",
       "  0.37338000535964966,\n",
       "  0.38359999656677246,\n",
       "  0.39375999569892883,\n",
       "  0.4054799973964691,\n",
       "  0.41161999106407166,\n",
       "  0.4217199981212616,\n",
       "  0.42961999773979187,\n",
       "  0.4353399872779846,\n",
       "  0.44113999605178833,\n",
       "  0.4482400119304657,\n",
       "  0.45405998826026917,\n",
       "  0.462119996547699,\n",
       "  0.46720001101493835],\n",
       " 'val_loss': [4.57942008972168,\n",
       "  4.328681468963623,\n",
       "  4.254485607147217,\n",
       "  4.195013046264648,\n",
       "  4.062140941619873,\n",
       "  3.9747512340545654,\n",
       "  3.9536120891571045,\n",
       "  3.981092691421509,\n",
       "  3.994173049926758,\n",
       "  3.9183218479156494,\n",
       "  3.98376727104187,\n",
       "  4.038660526275635,\n",
       "  3.9314136505126953,\n",
       "  3.891528606414795,\n",
       "  3.9099936485290527,\n",
       "  3.861614942550659,\n",
       "  3.7560176849365234,\n",
       "  3.8437862396240234,\n",
       "  3.702119827270508,\n",
       "  3.846165180206299,\n",
       "  3.248661518096924,\n",
       "  2.962479591369629,\n",
       "  2.7777504920959473,\n",
       "  2.5076723098754883,\n",
       "  2.434220314025879,\n",
       "  2.3353092670440674,\n",
       "  2.3630638122558594,\n",
       "  2.4060566425323486,\n",
       "  2.243743658065796,\n",
       "  2.213308811187744,\n",
       "  2.169912815093994,\n",
       "  2.1073875427246094,\n",
       "  2.1168649196624756,\n",
       "  2.078886032104492,\n",
       "  2.0304198265075684,\n",
       "  2.0394675731658936,\n",
       "  2.0366621017456055,\n",
       "  2.0227715969085693,\n",
       "  1.9912117719650269,\n",
       "  1.967511534690857],\n",
       " 'val_metric': [0.0099,\n",
       "  0.0493,\n",
       "  0.0531,\n",
       "  0.0516,\n",
       "  0.0749,\n",
       "  0.0856,\n",
       "  0.0882,\n",
       "  0.0789,\n",
       "  0.0775,\n",
       "  0.0829,\n",
       "  0.0775,\n",
       "  0.069,\n",
       "  0.0772,\n",
       "  0.0898,\n",
       "  0.0899,\n",
       "  0.1069,\n",
       "  0.1123,\n",
       "  0.1104,\n",
       "  0.1226,\n",
       "  0.0968,\n",
       "  0.1972,\n",
       "  0.2537,\n",
       "  0.3006,\n",
       "  0.3449,\n",
       "  0.3617,\n",
       "  0.3832,\n",
       "  0.3806,\n",
       "  0.377,\n",
       "  0.4087,\n",
       "  0.4135,\n",
       "  0.4239,\n",
       "  0.4392,\n",
       "  0.4377,\n",
       "  0.4467,\n",
       "  0.4582,\n",
       "  0.4577,\n",
       "  0.4544,\n",
       "  0.4621,\n",
       "  0.4703,\n",
       "  0.4751],\n",
       " 'hidden_layer_sizes': [[3, 51, 95, 91, 86, 105, 244, 341],\n",
       "  [3, 57, 76, 83, 87, 124, 258, 352],\n",
       "  [3, 35, 74, 66, 94, 137, 216, 364],\n",
       "  [3, 43, 71, 59, 73, 115, 176, 382],\n",
       "  [3, 41, 67, 75, 89, 128, 190, 369],\n",
       "  [3, 38, 75, 66, 78, 131, 204, 379],\n",
       "  [3, 43, 68, 63, 78, 133, 208, 356],\n",
       "  [3, 47, 61, 47, 75, 126, 216, 353],\n",
       "  [3, 46, 65, 63, 85, 143, 225, 357],\n",
       "  [3, 49, 77, 70, 87, 141, 234, 353],\n",
       "  [3, 48, 75, 54, 78, 126, 233, 382],\n",
       "  [3, 46, 56, 43, 52, 138, 249, 377],\n",
       "  [3, 47, 76, 62, 71, 160, 251, 382],\n",
       "  [3, 37, 55, 64, 88, 169, 260, 387],\n",
       "  [3, 34, 58, 54, 80, 149, 263, 381],\n",
       "  [3, 46, 73, 53, 80, 154, 261, 387],\n",
       "  [3, 56, 88, 73, 93, 156, 271, 391],\n",
       "  [3, 51, 75, 63, 84, 154, 249, 412],\n",
       "  [3, 51, 84, 73, 97, 153, 277, 375],\n",
       "  [3, 54, 75, 68, 74, 151, 285, 399],\n",
       "  [3, 54, 75, 68, 74, 151, 285, 399],\n",
       "  [3, 54, 75, 68, 74, 151, 285, 399],\n",
       "  [3, 54, 75, 68, 74, 151, 285, 399],\n",
       "  [3, 54, 75, 68, 74, 151, 285, 399],\n",
       "  [3, 54, 75, 68, 74, 151, 285, 399],\n",
       "  [3, 54, 75, 68, 74, 151, 285, 399],\n",
       "  [3, 54, 75, 68, 74, 151, 285, 399],\n",
       "  [3, 54, 75, 68, 74, 151, 285, 399],\n",
       "  [3, 54, 75, 68, 74, 151, 285, 399],\n",
       "  [3, 54, 75, 68, 74, 151, 285, 399],\n",
       "  [3, 54, 75, 68, 74, 151, 285, 399],\n",
       "  [3, 54, 75, 68, 74, 151, 285, 399],\n",
       "  [3, 54, 75, 68, 74, 151, 285, 399],\n",
       "  [3, 54, 75, 68, 74, 151, 285, 399],\n",
       "  [3, 54, 75, 68, 74, 151, 285, 399],\n",
       "  [3, 54, 75, 68, 74, 151, 285, 399],\n",
       "  [3, 54, 75, 68, 74, 151, 285, 399],\n",
       "  [3, 54, 75, 68, 74, 151, 285, 399],\n",
       "  [3, 54, 75, 68, 74, 151, 285, 399],\n",
       "  [3, 54, 75, 68, 74, 151, 285, 399]]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "schedule = [DynamicEpoch(0.00035, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20\n",
    "train_fn_conv(x=cifar100.X_train_norm, y=cifar100.y_train, \n",
    "              validation_data=(cifar100.X_test_norm, cifar100.y_test), learning_rate=0.0006, \n",
    "              schedule=schedule, layer_sizes=layer_sizes, output_neurons=100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42ec23db-6993-43ae-9caa-b504af4bb33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################################\n",
      "Epoch 1/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 5.217994213104248 - val_metric: 0.0099 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 5.217991352081299 - val_metric: 0.0099 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 52, 105, 153, 153, 105, 409, 409], total units: 1389\n",
      "Before pruning:\n",
      "loss: 4.638937473297119 - metric: 0.04355999827384949 - val_loss: 4.523640155792236 - val_metric: 0.0209 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 52, 105, 153, 153, 105, 409, 409], total units: 1389\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.5245361328125 - val_metric: 0.0213 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 50, 103, 135, 139, 105, 372, 362], total units: 1269\n",
      "##########################################################\n",
      "Epoch 2/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.5245361328125 - val_metric: 0.0213 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 50, 103, 135, 139, 105, 372, 362], total units: 1269\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.524534225463867 - val_metric: 0.0213 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 70, 123, 162, 166, 126, 446, 434], total units: 1530\n",
      "Before pruning:\n",
      "loss: 4.386452674865723 - metric: 0.04678000137209892 - val_loss: 4.175529479980469 - val_metric: 0.0564 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 70, 123, 162, 166, 126, 446, 434], total units: 1530\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.183597087860107 - val_metric: 0.0553 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 58, 120, 142, 137, 126, 349, 418], total units: 1353\n",
      "##########################################################\n",
      "Epoch 3/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.183597087860107 - val_metric: 0.0553 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 58, 120, 142, 137, 126, 349, 418], total units: 1353\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.183594226837158 - val_metric: 0.0552 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 78, 144, 170, 164, 151, 418, 501], total units: 1629\n",
      "Before pruning:\n",
      "loss: 4.269255638122559 - metric: 0.051259998232126236 - val_loss: 4.1021318435668945 - val_metric: 0.0691 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 78, 144, 170, 164, 151, 418, 501], total units: 1629\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.112740993499756 - val_metric: 0.0681 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 60, 112, 147, 138, 151, 299, 484], total units: 1394\n",
      "##########################################################\n",
      "Epoch 4/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.112740993499756 - val_metric: 0.0681 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 60, 112, 147, 138, 151, 299, 484], total units: 1394\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.112741947174072 - val_metric: 0.0681 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 80, 134, 176, 165, 181, 358, 580], total units: 1677\n",
      "Before pruning:\n",
      "loss: 4.157797813415527 - metric: 0.057440001517534256 - val_loss: 4.171339988708496 - val_metric: 0.057 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 80, 134, 176, 165, 181, 358, 580], total units: 1677\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.152124404907227 - val_metric: 0.0592 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 61, 110, 105, 130, 180, 254, 544], total units: 1387\n",
      "##########################################################\n",
      "Epoch 5/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.152124404907227 - val_metric: 0.0592 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 61, 110, 105, 130, 180, 254, 544], total units: 1387\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.152125358581543 - val_metric: 0.0593 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 81, 132, 126, 156, 216, 304, 652], total units: 1670\n",
      "Before pruning:\n",
      "loss: 4.099251747131348 - metric: 0.06232000142335892 - val_loss: 4.06503963470459 - val_metric: 0.0723 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 81, 132, 126, 156, 216, 304, 652], total units: 1670\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.055368900299072 - val_metric: 0.0731 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 51, 96, 93, 122, 177, 267, 594], total units: 1403\n",
      "##########################################################\n",
      "Epoch 6/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.055368900299072 - val_metric: 0.0731 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 51, 96, 93, 122, 177, 267, 594], total units: 1403\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.0553693771362305 - val_metric: 0.0731 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 71, 116, 113, 146, 212, 320, 712], total units: 1693\n",
      "Before pruning:\n",
      "loss: 4.045512676239014 - metric: 0.0670199990272522 - val_loss: 3.9405696392059326 - val_metric: 0.0806 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 71, 116, 113, 146, 212, 320, 712], total units: 1693\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.9384405612945557 - val_metric: 0.0832 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 60, 104, 105, 129, 189, 285, 597], total units: 1472\n",
      "##########################################################\n",
      "Epoch 7/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.9384405612945557 - val_metric: 0.0832 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 60, 104, 105, 129, 189, 285, 597], total units: 1472\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.938441514968872 - val_metric: 0.0832 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 80, 124, 126, 154, 226, 342, 716], total units: 1771\n",
      "Before pruning:\n",
      "loss: 4.023414611816406 - metric: 0.06972000002861023 - val_loss: 3.8675520420074463 - val_metric: 0.0976 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 80, 124, 126, 154, 226, 342, 716], total units: 1771\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.8746094703674316 - val_metric: 0.0986 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 63, 119, 113, 146, 204, 260, 545], total units: 1453\n",
      "##########################################################\n",
      "Epoch 8/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.8746094703674316 - val_metric: 0.0986 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 63, 119, 113, 146, 204, 260, 545], total units: 1453\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.874610185623169 - val_metric: 0.0987 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 83, 142, 135, 175, 244, 312, 654], total units: 1748\n",
      "Before pruning:\n",
      "loss: 3.9845218658447266 - metric: 0.07274000346660614 - val_loss: 3.823270320892334 - val_metric: 0.1129 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 83, 142, 135, 175, 244, 312, 654], total units: 1748\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.8180344104766846 - val_metric: 0.1109 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 48, 111, 105, 114, 193, 282, 516], total units: 1372\n",
      "##########################################################\n",
      "Epoch 9/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.8180344104766846 - val_metric: 0.1109 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 48, 111, 105, 114, 193, 282, 516], total units: 1372\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.8180601596832275 - val_metric: 0.1108 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 68, 133, 126, 136, 231, 338, 619], total units: 1654\n",
      "Before pruning:\n",
      "loss: 3.9461774826049805 - metric: 0.07880000025033951 - val_loss: 3.8163647651672363 - val_metric: 0.1054 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 68, 133, 126, 136, 231, 338, 619], total units: 1654\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.811715602874756 - val_metric: 0.1037 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 63, 108, 106, 126, 201, 303, 532], total units: 1442\n",
      "##########################################################\n",
      "Epoch 10/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.811715602874756 - val_metric: 0.1037 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 63, 108, 106, 126, 201, 303, 532], total units: 1442\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.8117172718048096 - val_metric: 0.1037 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 83, 129, 127, 151, 241, 363, 638], total units: 1735\n",
      "Before pruning:\n",
      "loss: 3.938030958175659 - metric: 0.07896000146865845 - val_loss: 3.902869462966919 - val_metric: 0.0945 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 83, 129, 127, 151, 241, 363, 638], total units: 1735\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.8989479541778564 - val_metric: 0.0951 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 52, 77, 54, 84, 194, 318, 554], total units: 1336\n",
      "##########################################################\n",
      "Epoch 11/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.8989479541778564 - val_metric: 0.0951 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 52, 77, 54, 84, 194, 318, 554], total units: 1336\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.8988046646118164 - val_metric: 0.095 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 72, 97, 74, 104, 232, 381, 664], total units: 1627\n",
      "Before pruning:\n",
      "loss: 3.901484489440918 - metric: 0.08253999799489975 - val_loss: 3.7820687294006348 - val_metric: 0.1153 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 72, 97, 74, 104, 232, 381, 664], total units: 1627\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.7765979766845703 - val_metric: 0.1166 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 61, 94, 71, 102, 213, 347, 528], total units: 1419\n",
      "##########################################################\n",
      "Epoch 12/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.7765979766845703 - val_metric: 0.1166 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 61, 94, 71, 102, 213, 347, 528], total units: 1419\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.776599645614624 - val_metric: 0.1166 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 81, 114, 91, 122, 255, 416, 633], total units: 1715\n",
      "Before pruning:\n",
      "loss: 3.891890525817871 - metric: 0.08501999825239182 - val_loss: 3.8133633136749268 - val_metric: 0.1002 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 81, 114, 91, 122, 255, 416, 633], total units: 1715\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.8103346824645996 - val_metric: 0.0982 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 54, 86, 82, 119, 223, 358, 544], total units: 1469\n",
      "##########################################################\n",
      "Epoch 13/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.8103346824645996 - val_metric: 0.0982 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 54, 86, 82, 119, 223, 358, 544], total units: 1469\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.810394048690796 - val_metric: 0.0982 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 74, 106, 102, 142, 267, 429, 652], total units: 1775\n",
      "Before pruning:\n",
      "loss: 3.887558698654175 - metric: 0.08541999757289886 - val_loss: 3.7299206256866455 - val_metric: 0.1188 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 74, 106, 102, 142, 267, 429, 652], total units: 1775\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.7290894985198975 - val_metric: 0.1173 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 56, 96, 88, 119, 219, 328, 522], total units: 1431\n",
      "##########################################################\n",
      "Epoch 14/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.7290894985198975 - val_metric: 0.1173 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 56, 96, 88, 119, 219, 328, 522], total units: 1431\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.729104995727539 - val_metric: 0.1174 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 76, 116, 108, 142, 262, 393, 626], total units: 1726\n",
      "Before pruning:\n",
      "loss: 3.8758761882781982 - metric: 0.08414000272750854 - val_loss: 3.708125114440918 - val_metric: 0.1235 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 76, 116, 108, 142, 262, 393, 626], total units: 1726\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.704116106033325 - val_metric: 0.1211 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 57, 98, 81, 117, 211, 365, 541], total units: 1473\n",
      "##########################################################\n",
      "Epoch 15/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.704116106033325 - val_metric: 0.1211 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 57, 98, 81, 117, 211, 365, 541], total units: 1473\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.7041172981262207 - val_metric: 0.1211 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 77, 118, 101, 140, 253, 438, 649], total units: 1779\n",
      "Before pruning:\n",
      "loss: 3.85817551612854 - metric: 0.08894000202417374 - val_loss: 3.7817437648773193 - val_metric: 0.1078 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 77, 118, 101, 140, 253, 438, 649], total units: 1779\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.78104305267334 - val_metric: 0.109 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 59, 78, 55, 92, 227, 392, 545], total units: 1451\n",
      "##########################################################\n",
      "Epoch 16/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.78104305267334 - val_metric: 0.109 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 59, 78, 55, 92, 227, 392, 545], total units: 1451\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.781038999557495 - val_metric: 0.109 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 79, 98, 75, 112, 272, 470, 654], total units: 1763\n",
      "Before pruning:\n",
      "loss: 3.8377163410186768 - metric: 0.09328000247478485 - val_loss: 3.7893948554992676 - val_metric: 0.1074 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 79, 98, 75, 112, 272, 470, 654], total units: 1763\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.794956922531128 - val_metric: 0.1094 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 55, 91, 73, 105, 231, 388, 552], total units: 1498\n",
      "##########################################################\n",
      "Epoch 17/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.794956922531128 - val_metric: 0.1094 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 55, 91, 73, 105, 231, 388, 552], total units: 1498\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.794959306716919 - val_metric: 0.1094 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 75, 111, 93, 126, 277, 465, 662], total units: 1812\n",
      "Before pruning:\n",
      "loss: 3.8327889442443848 - metric: 0.09331999719142914 - val_loss: 3.7427186965942383 - val_metric: 0.1196 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 75, 111, 93, 126, 277, 465, 662], total units: 1812\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.7405195236206055 - val_metric: 0.1211 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 63, 109, 90, 116, 235, 368, 559], total units: 1543\n",
      "##########################################################\n",
      "Epoch 18/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.7405195236206055 - val_metric: 0.1211 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 63, 109, 90, 116, 235, 368, 559], total units: 1543\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.7405200004577637 - val_metric: 0.1211 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 83, 130, 110, 139, 282, 441, 670], total units: 1858\n",
      "Before pruning:\n",
      "loss: 3.828516960144043 - metric: 0.09254000335931778 - val_loss: 3.6974356174468994 - val_metric: 0.118 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 83, 130, 110, 139, 282, 441, 670], total units: 1858\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.693851947784424 - val_metric: 0.1217 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 73, 115, 101, 131, 239, 393, 550], total units: 1605\n",
      "##########################################################\n",
      "Epoch 19/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.693851947784424 - val_metric: 0.1217 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 73, 115, 101, 131, 239, 393, 550], total units: 1605\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.693854570388794 - val_metric: 0.1217 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 93, 138, 121, 157, 286, 471, 660], total units: 1929\n",
      "Before pruning:\n",
      "loss: 3.820986032485962 - metric: 0.09613999724388123 - val_loss: 3.6505355834960938 - val_metric: 0.1284 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 93, 138, 121, 157, 286, 471, 660], total units: 1929\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.648515224456787 - val_metric: 0.1282 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 66, 112, 85, 101, 234, 399, 554], total units: 1554\n",
      "##########################################################\n",
      "Epoch 20/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.648515224456787 - val_metric: 0.1282 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 66, 112, 85, 101, 234, 399, 554], total units: 1554\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.6485655307769775 - val_metric: 0.1282 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 86, 134, 105, 121, 280, 478, 664], total units: 1871\n",
      "Before pruning:\n",
      "loss: 3.8063247203826904 - metric: 0.09880000352859497 - val_loss: 3.7810022830963135 - val_metric: 0.1137 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 86, 134, 105, 121, 280, 478, 664], total units: 1871\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.785128593444824 - val_metric: 0.1129 - penalty: 0.0002\n",
      "hidden layer sizes: [3, 54, 98, 82, 113, 249, 407, 570], total units: 1576\n",
      "##########################################################\n",
      "Epoch 21/40\n",
      "loss: 3.4776875972747803 - metric: 0.15851999819278717 - val_loss: 3.1679909229278564 - val_metric: 0.2142 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 98, 82, 113, 249, 407, 570], total units: 1576\n",
      "##########################################################\n",
      "Epoch 22/40\n",
      "loss: 3.0310635566711426 - metric: 0.24196000397205353 - val_loss: 2.989863395690918 - val_metric: 0.2574 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 98, 82, 113, 249, 407, 570], total units: 1576\n",
      "##########################################################\n",
      "Epoch 23/40\n",
      "loss: 2.765700340270996 - metric: 0.292820006608963 - val_loss: 2.5834848880767822 - val_metric: 0.3347 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 98, 82, 113, 249, 407, 570], total units: 1576\n",
      "##########################################################\n",
      "Epoch 24/40\n",
      "loss: 2.5944135189056396 - metric: 0.33017998933792114 - val_loss: 2.466364860534668 - val_metric: 0.3604 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 98, 82, 113, 249, 407, 570], total units: 1576\n",
      "##########################################################\n",
      "Epoch 25/40\n",
      "loss: 2.468325138092041 - metric: 0.3535600006580353 - val_loss: 2.3602969646453857 - val_metric: 0.3887 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 98, 82, 113, 249, 407, 570], total units: 1576\n",
      "##########################################################\n",
      "Epoch 26/40\n",
      "loss: 2.3688883781433105 - metric: 0.3771600127220154 - val_loss: 2.3557515144348145 - val_metric: 0.3901 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 98, 82, 113, 249, 407, 570], total units: 1576\n",
      "##########################################################\n",
      "Epoch 27/40\n",
      "loss: 2.275552272796631 - metric: 0.39465999603271484 - val_loss: 2.281644582748413 - val_metric: 0.4015 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 98, 82, 113, 249, 407, 570], total units: 1576\n",
      "##########################################################\n",
      "Epoch 28/40\n",
      "loss: 2.203190565109253 - metric: 0.41218000650405884 - val_loss: 2.153202533721924 - val_metric: 0.4305 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 98, 82, 113, 249, 407, 570], total units: 1576\n",
      "##########################################################\n",
      "Epoch 29/40\n",
      "loss: 2.1348254680633545 - metric: 0.4268200099468231 - val_loss: 2.2915279865264893 - val_metric: 0.4045 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 98, 82, 113, 249, 407, 570], total units: 1576\n",
      "##########################################################\n",
      "Epoch 30/40\n",
      "loss: 2.084277868270874 - metric: 0.438620001077652 - val_loss: 2.0835859775543213 - val_metric: 0.4516 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 98, 82, 113, 249, 407, 570], total units: 1576\n",
      "##########################################################\n",
      "Epoch 31/40\n",
      "loss: 2.020404815673828 - metric: 0.45302000641822815 - val_loss: 2.073101282119751 - val_metric: 0.4482 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 98, 82, 113, 249, 407, 570], total units: 1576\n",
      "##########################################################\n",
      "Epoch 32/40\n",
      "loss: 1.9769299030303955 - metric: 0.46083998680114746 - val_loss: 1.9789851903915405 - val_metric: 0.4729 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 98, 82, 113, 249, 407, 570], total units: 1576\n",
      "##########################################################\n",
      "Epoch 33/40\n",
      "loss: 1.922609567642212 - metric: 0.4731000065803528 - val_loss: 1.9627536535263062 - val_metric: 0.4736 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 98, 82, 113, 249, 407, 570], total units: 1576\n",
      "##########################################################\n",
      "Epoch 34/40\n",
      "loss: 1.8850443363189697 - metric: 0.48284000158309937 - val_loss: 1.9980380535125732 - val_metric: 0.471 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 98, 82, 113, 249, 407, 570], total units: 1576\n",
      "##########################################################\n",
      "Epoch 35/40\n",
      "loss: 1.8426486253738403 - metric: 0.49094000458717346 - val_loss: 2.0003409385681152 - val_metric: 0.4703 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 98, 82, 113, 249, 407, 570], total units: 1576\n",
      "##########################################################\n",
      "Epoch 36/40\n",
      "loss: 1.8001407384872437 - metric: 0.5012400150299072 - val_loss: 1.9436626434326172 - val_metric: 0.4861 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 98, 82, 113, 249, 407, 570], total units: 1576\n",
      "##########################################################\n",
      "Epoch 37/40\n",
      "loss: 1.7582627534866333 - metric: 0.511139988899231 - val_loss: 1.8643767833709717 - val_metric: 0.5005 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 98, 82, 113, 249, 407, 570], total units: 1576\n",
      "##########################################################\n",
      "Epoch 38/40\n",
      "loss: 1.7126846313476562 - metric: 0.5198799967765808 - val_loss: 1.886903166770935 - val_metric: 0.4985 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 98, 82, 113, 249, 407, 570], total units: 1576\n",
      "##########################################################\n",
      "Epoch 39/40\n",
      "loss: 1.6846064329147339 - metric: 0.5266199707984924 - val_loss: 1.8788400888442993 - val_metric: 0.4998 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 98, 82, 113, 249, 407, 570], total units: 1576\n",
      "##########################################################\n",
      "Epoch 40/40\n",
      "loss: 1.649818778038025 - metric: 0.5355600118637085 - val_loss: 1.8430901765823364 - val_metric: 0.5105 - penalty: 0.0\n",
      "hidden layer sizes: [3, 54, 98, 82, 113, 249, 407, 570], total units: 1576\n",
      "CPU times: user 5min 12s, sys: 10.1 s, total: 5min 22s\n",
      "Wall time: 5min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [4.638937473297119,\n",
       "  4.386452674865723,\n",
       "  4.269255638122559,\n",
       "  4.157797813415527,\n",
       "  4.099251747131348,\n",
       "  4.045512676239014,\n",
       "  4.023414611816406,\n",
       "  3.9845218658447266,\n",
       "  3.9461774826049805,\n",
       "  3.938030958175659,\n",
       "  3.901484489440918,\n",
       "  3.891890525817871,\n",
       "  3.887558698654175,\n",
       "  3.8758761882781982,\n",
       "  3.85817551612854,\n",
       "  3.8377163410186768,\n",
       "  3.8327889442443848,\n",
       "  3.828516960144043,\n",
       "  3.820986032485962,\n",
       "  3.8063247203826904,\n",
       "  3.4776875972747803,\n",
       "  3.0310635566711426,\n",
       "  2.765700340270996,\n",
       "  2.5944135189056396,\n",
       "  2.468325138092041,\n",
       "  2.3688883781433105,\n",
       "  2.275552272796631,\n",
       "  2.203190565109253,\n",
       "  2.1348254680633545,\n",
       "  2.084277868270874,\n",
       "  2.020404815673828,\n",
       "  1.9769299030303955,\n",
       "  1.922609567642212,\n",
       "  1.8850443363189697,\n",
       "  1.8426486253738403,\n",
       "  1.8001407384872437,\n",
       "  1.7582627534866333,\n",
       "  1.7126846313476562,\n",
       "  1.6846064329147339,\n",
       "  1.649818778038025],\n",
       " 'metric': [0.04355999827384949,\n",
       "  0.04678000137209892,\n",
       "  0.051259998232126236,\n",
       "  0.057440001517534256,\n",
       "  0.06232000142335892,\n",
       "  0.0670199990272522,\n",
       "  0.06972000002861023,\n",
       "  0.07274000346660614,\n",
       "  0.07880000025033951,\n",
       "  0.07896000146865845,\n",
       "  0.08253999799489975,\n",
       "  0.08501999825239182,\n",
       "  0.08541999757289886,\n",
       "  0.08414000272750854,\n",
       "  0.08894000202417374,\n",
       "  0.09328000247478485,\n",
       "  0.09331999719142914,\n",
       "  0.09254000335931778,\n",
       "  0.09613999724388123,\n",
       "  0.09880000352859497,\n",
       "  0.15851999819278717,\n",
       "  0.24196000397205353,\n",
       "  0.292820006608963,\n",
       "  0.33017998933792114,\n",
       "  0.3535600006580353,\n",
       "  0.3771600127220154,\n",
       "  0.39465999603271484,\n",
       "  0.41218000650405884,\n",
       "  0.4268200099468231,\n",
       "  0.438620001077652,\n",
       "  0.45302000641822815,\n",
       "  0.46083998680114746,\n",
       "  0.4731000065803528,\n",
       "  0.48284000158309937,\n",
       "  0.49094000458717346,\n",
       "  0.5012400150299072,\n",
       "  0.511139988899231,\n",
       "  0.5198799967765808,\n",
       "  0.5266199707984924,\n",
       "  0.5355600118637085],\n",
       " 'val_loss': [4.5245361328125,\n",
       "  4.183597087860107,\n",
       "  4.112740993499756,\n",
       "  4.152124404907227,\n",
       "  4.055368900299072,\n",
       "  3.9384405612945557,\n",
       "  3.8746094703674316,\n",
       "  3.8180344104766846,\n",
       "  3.811715602874756,\n",
       "  3.8989479541778564,\n",
       "  3.7765979766845703,\n",
       "  3.8103346824645996,\n",
       "  3.7290894985198975,\n",
       "  3.704116106033325,\n",
       "  3.78104305267334,\n",
       "  3.794956922531128,\n",
       "  3.7405195236206055,\n",
       "  3.693851947784424,\n",
       "  3.648515224456787,\n",
       "  3.785128593444824,\n",
       "  3.1679909229278564,\n",
       "  2.989863395690918,\n",
       "  2.5834848880767822,\n",
       "  2.466364860534668,\n",
       "  2.3602969646453857,\n",
       "  2.3557515144348145,\n",
       "  2.281644582748413,\n",
       "  2.153202533721924,\n",
       "  2.2915279865264893,\n",
       "  2.0835859775543213,\n",
       "  2.073101282119751,\n",
       "  1.9789851903915405,\n",
       "  1.9627536535263062,\n",
       "  1.9980380535125732,\n",
       "  2.0003409385681152,\n",
       "  1.9436626434326172,\n",
       "  1.8643767833709717,\n",
       "  1.886903166770935,\n",
       "  1.8788400888442993,\n",
       "  1.8430901765823364],\n",
       " 'val_metric': [0.0213,\n",
       "  0.0553,\n",
       "  0.0681,\n",
       "  0.0592,\n",
       "  0.0731,\n",
       "  0.0832,\n",
       "  0.0986,\n",
       "  0.1109,\n",
       "  0.1037,\n",
       "  0.0951,\n",
       "  0.1166,\n",
       "  0.0982,\n",
       "  0.1173,\n",
       "  0.1211,\n",
       "  0.109,\n",
       "  0.1094,\n",
       "  0.1211,\n",
       "  0.1217,\n",
       "  0.1282,\n",
       "  0.1129,\n",
       "  0.2142,\n",
       "  0.2574,\n",
       "  0.3347,\n",
       "  0.3604,\n",
       "  0.3887,\n",
       "  0.3901,\n",
       "  0.4015,\n",
       "  0.4305,\n",
       "  0.4045,\n",
       "  0.4516,\n",
       "  0.4482,\n",
       "  0.4729,\n",
       "  0.4736,\n",
       "  0.471,\n",
       "  0.4703,\n",
       "  0.4861,\n",
       "  0.5005,\n",
       "  0.4985,\n",
       "  0.4998,\n",
       "  0.5105],\n",
       " 'hidden_layer_sizes': [[3, 50, 103, 135, 139, 105, 372, 362],\n",
       "  [3, 58, 120, 142, 137, 126, 349, 418],\n",
       "  [3, 60, 112, 147, 138, 151, 299, 484],\n",
       "  [3, 61, 110, 105, 130, 180, 254, 544],\n",
       "  [3, 51, 96, 93, 122, 177, 267, 594],\n",
       "  [3, 60, 104, 105, 129, 189, 285, 597],\n",
       "  [3, 63, 119, 113, 146, 204, 260, 545],\n",
       "  [3, 48, 111, 105, 114, 193, 282, 516],\n",
       "  [3, 63, 108, 106, 126, 201, 303, 532],\n",
       "  [3, 52, 77, 54, 84, 194, 318, 554],\n",
       "  [3, 61, 94, 71, 102, 213, 347, 528],\n",
       "  [3, 54, 86, 82, 119, 223, 358, 544],\n",
       "  [3, 56, 96, 88, 119, 219, 328, 522],\n",
       "  [3, 57, 98, 81, 117, 211, 365, 541],\n",
       "  [3, 59, 78, 55, 92, 227, 392, 545],\n",
       "  [3, 55, 91, 73, 105, 231, 388, 552],\n",
       "  [3, 63, 109, 90, 116, 235, 368, 559],\n",
       "  [3, 73, 115, 101, 131, 239, 393, 550],\n",
       "  [3, 66, 112, 85, 101, 234, 399, 554],\n",
       "  [3, 54, 98, 82, 113, 249, 407, 570],\n",
       "  [3, 54, 98, 82, 113, 249, 407, 570],\n",
       "  [3, 54, 98, 82, 113, 249, 407, 570],\n",
       "  [3, 54, 98, 82, 113, 249, 407, 570],\n",
       "  [3, 54, 98, 82, 113, 249, 407, 570],\n",
       "  [3, 54, 98, 82, 113, 249, 407, 570],\n",
       "  [3, 54, 98, 82, 113, 249, 407, 570],\n",
       "  [3, 54, 98, 82, 113, 249, 407, 570],\n",
       "  [3, 54, 98, 82, 113, 249, 407, 570],\n",
       "  [3, 54, 98, 82, 113, 249, 407, 570],\n",
       "  [3, 54, 98, 82, 113, 249, 407, 570],\n",
       "  [3, 54, 98, 82, 113, 249, 407, 570],\n",
       "  [3, 54, 98, 82, 113, 249, 407, 570],\n",
       "  [3, 54, 98, 82, 113, 249, 407, 570],\n",
       "  [3, 54, 98, 82, 113, 249, 407, 570],\n",
       "  [3, 54, 98, 82, 113, 249, 407, 570],\n",
       "  [3, 54, 98, 82, 113, 249, 407, 570],\n",
       "  [3, 54, 98, 82, 113, 249, 407, 570],\n",
       "  [3, 54, 98, 82, 113, 249, 407, 570],\n",
       "  [3, 54, 98, 82, 113, 249, 407, 570],\n",
       "  [3, 54, 98, 82, 113, 249, 407, 570]]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "schedule = [DynamicEpoch(0.0002, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20\n",
    "train_fn_conv(x=cifar100.X_train_norm, y=cifar100.y_train, \n",
    "              validation_data=(cifar100.X_test_norm, cifar100.y_test), learning_rate=0.0006, \n",
    "              schedule=schedule, layer_sizes=layer_sizes, output_neurons=100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "972551ff-b166-4895-b0fe-21a2d8e7ee1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################################\n",
      "Epoch 1/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 5.341501712799072 - val_metric: 0.0103 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 5.3414998054504395 - val_metric: 0.0103 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 52, 105, 153, 153, 105, 409, 409], total units: 1389\n",
      "Before pruning:\n",
      "loss: 4.549084186553955 - metric: 0.05186000093817711 - val_loss: 4.464568138122559 - val_metric: 0.0325 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 52, 105, 153, 153, 105, 409, 409], total units: 1389\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.465632915496826 - val_metric: 0.032 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 51, 105, 147, 151, 105, 407, 404], total units: 1373\n",
      "##########################################################\n",
      "Epoch 2/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.465632915496826 - val_metric: 0.032 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 51, 105, 147, 151, 105, 407, 404], total units: 1373\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.465633392333984 - val_metric: 0.032 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 71, 126, 176, 181, 126, 488, 484], total units: 1655\n",
      "Before pruning:\n",
      "loss: 4.352813720703125 - metric: 0.050680000334978104 - val_loss: 4.1309943199157715 - val_metric: 0.0737 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 71, 126, 176, 181, 126, 488, 484], total units: 1655\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.1423444747924805 - val_metric: 0.0729 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 64, 123, 141, 144, 126, 431, 482], total units: 1514\n",
      "##########################################################\n",
      "Epoch 3/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.1423444747924805 - val_metric: 0.0729 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 64, 123, 141, 144, 126, 431, 482], total units: 1514\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.1423444747924805 - val_metric: 0.0729 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 84, 147, 169, 172, 151, 517, 578], total units: 1821\n",
      "Before pruning:\n",
      "loss: 4.194449424743652 - metric: 0.059459999203681946 - val_loss: 4.072908878326416 - val_metric: 0.0679 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 84, 147, 169, 172, 151, 517, 578], total units: 1821\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.066018581390381 - val_metric: 0.0685 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 65, 143, 165, 167, 151, 406, 575], total units: 1675\n",
      "##########################################################\n",
      "Epoch 4/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.066018581390381 - val_metric: 0.0685 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 65, 143, 165, 167, 151, 406, 575], total units: 1675\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.0660200119018555 - val_metric: 0.0685 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 85, 171, 198, 200, 181, 487, 690], total units: 2015\n",
      "Before pruning:\n",
      "loss: 4.140896320343018 - metric: 0.062059998512268066 - val_loss: 3.9879672527313232 - val_metric: 0.0715 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 85, 171, 198, 200, 181, 487, 690], total units: 2015\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.97802472114563 - val_metric: 0.0739 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 80, 164, 184, 180, 181, 395, 684], total units: 1871\n",
      "##########################################################\n",
      "Epoch 5/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.97802472114563 - val_metric: 0.0739 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 80, 164, 184, 180, 181, 395, 684], total units: 1871\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.9780256748199463 - val_metric: 0.0739 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 100, 196, 220, 216, 217, 474, 820], total units: 2246\n",
      "Before pruning:\n",
      "loss: 4.111460208892822 - metric: 0.06452000141143799 - val_loss: 3.932852268218994 - val_metric: 0.088 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 100, 196, 220, 216, 217, 474, 820], total units: 2246\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.9297356605529785 - val_metric: 0.0894 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 65, 127, 103, 142, 215, 360, 793], total units: 1808\n",
      "##########################################################\n",
      "Epoch 6/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.9297356605529785 - val_metric: 0.0894 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 65, 127, 103, 142, 215, 360, 793], total units: 1808\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.9297358989715576 - val_metric: 0.0894 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 85, 152, 123, 170, 258, 432, 951], total units: 2174\n",
      "Before pruning:\n",
      "loss: 4.025782585144043 - metric: 0.07028000056743622 - val_loss: 3.875669479370117 - val_metric: 0.0865 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 85, 152, 123, 170, 258, 432, 951], total units: 2174\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.8688793182373047 - val_metric: 0.0892 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 70, 144, 122, 166, 248, 347, 803], total units: 1903\n",
      "##########################################################\n",
      "Epoch 7/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.8688793182373047 - val_metric: 0.0892 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 70, 144, 122, 166, 248, 347, 803], total units: 1903\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.8688788414001465 - val_metric: 0.0892 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 90, 172, 146, 199, 297, 416, 963], total units: 2286\n",
      "Before pruning:\n",
      "loss: 3.9784977436065674 - metric: 0.07398000359535217 - val_loss: 3.8360371589660645 - val_metric: 0.1013 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 90, 172, 146, 199, 297, 416, 963], total units: 2286\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.832895278930664 - val_metric: 0.1036 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 82, 132, 135, 173, 245, 356, 730], total units: 1856\n",
      "##########################################################\n",
      "Epoch 8/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.832895278930664 - val_metric: 0.1036 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 82, 132, 135, 173, 245, 356, 730], total units: 1856\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.832890272140503 - val_metric: 0.1037 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 102, 158, 162, 207, 294, 427, 876], total units: 2229\n",
      "Before pruning:\n",
      "loss: 3.9471466541290283 - metric: 0.07992000132799149 - val_loss: 3.815781354904175 - val_metric: 0.1089 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 102, 158, 162, 207, 294, 427, 876], total units: 2229\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.799229621887207 - val_metric: 0.1128 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 74, 142, 138, 167, 265, 360, 678], total units: 1827\n",
      "##########################################################\n",
      "Epoch 9/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.799229621887207 - val_metric: 0.1128 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 74, 142, 138, 167, 265, 360, 678], total units: 1827\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.799233913421631 - val_metric: 0.1128 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 94, 170, 165, 200, 318, 432, 813], total units: 2195\n",
      "Before pruning:\n",
      "loss: 3.920301675796509 - metric: 0.08364000171422958 - val_loss: 3.7596254348754883 - val_metric: 0.1136 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 94, 170, 165, 200, 318, 432, 813], total units: 2195\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.756282091140747 - val_metric: 0.1134 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 65, 156, 145, 154, 285, 396, 700], total units: 1904\n",
      "##########################################################\n",
      "Epoch 10/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.756282091140747 - val_metric: 0.1134 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 65, 156, 145, 154, 285, 396, 700], total units: 1904\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.75628399848938 - val_metric: 0.1134 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 85, 187, 174, 184, 342, 475, 840], total units: 2290\n",
      "Before pruning:\n",
      "loss: 3.908858060836792 - metric: 0.08483999967575073 - val_loss: 3.83746337890625 - val_metric: 0.1074 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 85, 187, 174, 184, 342, 475, 840], total units: 2290\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.8367104530334473 - val_metric: 0.1108 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 70, 135, 131, 165, 272, 421, 708], total units: 1905\n",
      "##########################################################\n",
      "Epoch 11/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.8367104530334473 - val_metric: 0.1108 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 70, 135, 131, 165, 272, 421, 708], total units: 1905\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.8367085456848145 - val_metric: 0.1108 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 90, 162, 157, 198, 326, 505, 849], total units: 2290\n",
      "Before pruning:\n",
      "loss: 3.8858792781829834 - metric: 0.08873999863862991 - val_loss: 3.697063684463501 - val_metric: 0.1358 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 90, 162, 157, 198, 326, 505, 849], total units: 2290\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.692204713821411 - val_metric: 0.1344 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 78, 155, 153, 186, 292, 421, 729], total units: 2017\n",
      "##########################################################\n",
      "Epoch 12/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.692204713821411 - val_metric: 0.1344 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 78, 155, 153, 186, 292, 421, 729], total units: 2017\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.6922085285186768 - val_metric: 0.1344 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 98, 186, 183, 223, 350, 505, 874], total units: 2422\n",
      "Before pruning:\n",
      "loss: 3.8829972743988037 - metric: 0.08709999918937683 - val_loss: 3.722365617752075 - val_metric: 0.1126 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 98, 186, 183, 223, 350, 505, 874], total units: 2422\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.7087230682373047 - val_metric: 0.1165 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 83, 147, 164, 197, 297, 437, 724], total units: 2052\n",
      "##########################################################\n",
      "Epoch 13/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.7087230682373047 - val_metric: 0.1165 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 83, 147, 164, 197, 297, 437, 724], total units: 2052\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.7087242603302 - val_metric: 0.1165 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 103, 176, 196, 236, 356, 524, 868], total units: 2462\n",
      "Before pruning:\n",
      "loss: 3.8720591068267822 - metric: 0.09008000046014786 - val_loss: 3.685220241546631 - val_metric: 0.1302 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 103, 176, 196, 236, 356, 524, 868], total units: 2462\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.692894220352173 - val_metric: 0.1278 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 86, 154, 166, 178, 258, 454, 710], total units: 2009\n",
      "##########################################################\n",
      "Epoch 14/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.692894220352173 - val_metric: 0.1278 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 86, 154, 166, 178, 258, 454, 710], total units: 2009\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.692894220352173 - val_metric: 0.1278 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 106, 184, 199, 213, 309, 544, 852], total units: 2410\n",
      "Before pruning:\n",
      "loss: 3.847320318222046 - metric: 0.0919400006532669 - val_loss: 3.82372784614563 - val_metric: 0.1029 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 106, 184, 199, 213, 309, 544, 852], total units: 2410\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.811278820037842 - val_metric: 0.1038 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 77, 108, 88, 151, 290, 471, 722], total units: 1910\n",
      "##########################################################\n",
      "Epoch 15/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.811278820037842 - val_metric: 0.1038 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 77, 108, 88, 151, 290, 471, 722], total units: 1910\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.8112733364105225 - val_metric: 0.1038 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 97, 129, 108, 181, 348, 565, 866], total units: 2297\n",
      "Before pruning:\n",
      "loss: 3.813478469848633 - metric: 0.097120001912117 - val_loss: 3.6100573539733887 - val_metric: 0.1506 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 97, 129, 108, 181, 348, 565, 866], total units: 2297\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.6043882369995117 - val_metric: 0.1503 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 82, 113, 103, 171, 317, 487, 703], total units: 1979\n",
      "##########################################################\n",
      "Epoch 16/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.6043882369995117 - val_metric: 0.1503 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 82, 113, 103, 171, 317, 487, 703], total units: 1979\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.6043856143951416 - val_metric: 0.1503 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 102, 135, 123, 205, 380, 584, 843], total units: 2375\n",
      "Before pruning:\n",
      "loss: 3.814519166946411 - metric: 0.09638000279664993 - val_loss: 3.712383985519409 - val_metric: 0.1224 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 102, 135, 123, 205, 380, 584, 843], total units: 2375\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.7086899280548096 - val_metric: 0.1236 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 91, 123, 116, 186, 318, 495, 685], total units: 2017\n",
      "##########################################################\n",
      "Epoch 17/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.7086899280548096 - val_metric: 0.1236 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 91, 123, 116, 186, 318, 495, 685], total units: 2017\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.708691358566284 - val_metric: 0.1237 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 111, 147, 139, 223, 381, 594, 822], total units: 2420\n",
      "Before pruning:\n",
      "loss: 3.802786350250244 - metric: 0.09852000325918198 - val_loss: 3.630858898162842 - val_metric: 0.1331 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 111, 147, 139, 223, 381, 594, 822], total units: 2420\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.6256062984466553 - val_metric: 0.1366 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 71, 114, 88, 148, 282, 495, 703], total units: 1904\n",
      "##########################################################\n",
      "Epoch 18/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.6256062984466553 - val_metric: 0.1366 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 71, 114, 88, 148, 282, 495, 703], total units: 1904\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.625607490539551 - val_metric: 0.1366 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 91, 136, 108, 177, 338, 594, 843], total units: 2290\n",
      "Before pruning:\n",
      "loss: 3.768878221511841 - metric: 0.10249999910593033 - val_loss: 3.598912000656128 - val_metric: 0.1466 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 91, 136, 108, 177, 338, 594, 843], total units: 2290\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.5938992500305176 - val_metric: 0.1474 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 82, 121, 107, 171, 314, 526, 698], total units: 2022\n",
      "##########################################################\n",
      "Epoch 19/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.5938992500305176 - val_metric: 0.1474 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 82, 121, 107, 171, 314, 526, 698], total units: 2022\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.593895196914673 - val_metric: 0.1474 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 102, 145, 128, 205, 376, 631, 837], total units: 2427\n",
      "Before pruning:\n",
      "loss: 3.7788732051849365 - metric: 0.1008400022983551 - val_loss: 3.6275129318237305 - val_metric: 0.1327 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 102, 145, 128, 205, 376, 631, 837], total units: 2427\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.6267952919006348 - val_metric: 0.1344 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 91, 138, 123, 189, 312, 518, 709], total units: 2083\n",
      "##########################################################\n",
      "Epoch 20/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.6267952919006348 - val_metric: 0.1344 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 91, 138, 123, 189, 312, 518, 709], total units: 2083\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.626797676086426 - val_metric: 0.1345 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 111, 165, 147, 226, 374, 621, 850], total units: 2497\n",
      "Before pruning:\n",
      "loss: 3.7652781009674072 - metric: 0.10369999706745148 - val_loss: 3.554232120513916 - val_metric: 0.1536 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 111, 165, 147, 226, 374, 621, 850], total units: 2497\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.5533480644226074 - val_metric: 0.1531 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 89, 158, 144, 204, 321, 519, 687], total units: 2125\n",
      "##########################################################\n",
      "Epoch 21/40\n",
      "loss: 3.4471065998077393 - metric: 0.16186000406742096 - val_loss: 3.0648484230041504 - val_metric: 0.2322 - penalty: 0.0\n",
      "hidden layer sizes: [3, 89, 158, 144, 204, 321, 519, 687], total units: 2125\n",
      "##########################################################\n",
      "Epoch 22/40\n",
      "loss: 2.944631338119507 - metric: 0.2567000091075897 - val_loss: 2.719862699508667 - val_metric: 0.3081 - penalty: 0.0\n",
      "hidden layer sizes: [3, 89, 158, 144, 204, 321, 519, 687], total units: 2125\n",
      "##########################################################\n",
      "Epoch 23/40\n",
      "loss: 2.700770616531372 - metric: 0.302700012922287 - val_loss: 2.5450117588043213 - val_metric: 0.3471 - penalty: 0.0\n",
      "hidden layer sizes: [3, 89, 158, 144, 204, 321, 519, 687], total units: 2125\n",
      "##########################################################\n",
      "Epoch 24/40\n",
      "loss: 2.5264780521392822 - metric: 0.3410399854183197 - val_loss: 2.4292871952056885 - val_metric: 0.371 - penalty: 0.0\n",
      "hidden layer sizes: [3, 89, 158, 144, 204, 321, 519, 687], total units: 2125\n",
      "##########################################################\n",
      "Epoch 25/40\n",
      "loss: 2.3887054920196533 - metric: 0.37143999338150024 - val_loss: 2.345032215118408 - val_metric: 0.3911 - penalty: 0.0\n",
      "hidden layer sizes: [3, 89, 158, 144, 204, 321, 519, 687], total units: 2125\n",
      "##########################################################\n",
      "Epoch 26/40\n",
      "loss: 2.2742366790771484 - metric: 0.39660000801086426 - val_loss: 2.256612539291382 - val_metric: 0.4126 - penalty: 0.0\n",
      "hidden layer sizes: [3, 89, 158, 144, 204, 321, 519, 687], total units: 2125\n",
      "##########################################################\n",
      "Epoch 27/40\n",
      "loss: 2.176234483718872 - metric: 0.4205400049686432 - val_loss: 2.1865227222442627 - val_metric: 0.4279 - penalty: 0.0\n",
      "hidden layer sizes: [3, 89, 158, 144, 204, 321, 519, 687], total units: 2125\n",
      "##########################################################\n",
      "Epoch 28/40\n",
      "loss: 2.083613157272339 - metric: 0.4372200071811676 - val_loss: 2.0992138385772705 - val_metric: 0.4477 - penalty: 0.0\n",
      "hidden layer sizes: [3, 89, 158, 144, 204, 321, 519, 687], total units: 2125\n",
      "##########################################################\n",
      "Epoch 29/40\n",
      "loss: 2.000044345855713 - metric: 0.45781999826431274 - val_loss: 2.120802640914917 - val_metric: 0.4451 - penalty: 0.0\n",
      "hidden layer sizes: [3, 89, 158, 144, 204, 321, 519, 687], total units: 2125\n",
      "##########################################################\n",
      "Epoch 30/40\n",
      "loss: 1.9322329759597778 - metric: 0.47181999683380127 - val_loss: 1.9588580131530762 - val_metric: 0.4739 - penalty: 0.0\n",
      "hidden layer sizes: [3, 89, 158, 144, 204, 321, 519, 687], total units: 2125\n",
      "##########################################################\n",
      "Epoch 31/40\n",
      "loss: 1.846045732498169 - metric: 0.4932200014591217 - val_loss: 1.9708806276321411 - val_metric: 0.4725 - penalty: 0.0\n",
      "hidden layer sizes: [3, 89, 158, 144, 204, 321, 519, 687], total units: 2125\n",
      "##########################################################\n",
      "Epoch 32/40\n",
      "loss: 1.7894470691680908 - metric: 0.5055400133132935 - val_loss: 1.9567883014678955 - val_metric: 0.4814 - penalty: 0.0\n",
      "hidden layer sizes: [3, 89, 158, 144, 204, 321, 519, 687], total units: 2125\n",
      "##########################################################\n",
      "Epoch 33/40\n",
      "loss: 1.7177040576934814 - metric: 0.5210800170898438 - val_loss: 1.8834822177886963 - val_metric: 0.4894 - penalty: 0.0\n",
      "hidden layer sizes: [3, 89, 158, 144, 204, 321, 519, 687], total units: 2125\n",
      "##########################################################\n",
      "Epoch 34/40\n",
      "loss: 1.6557029485702515 - metric: 0.5372400283813477 - val_loss: 1.903448224067688 - val_metric: 0.495 - penalty: 0.0\n",
      "hidden layer sizes: [3, 89, 158, 144, 204, 321, 519, 687], total units: 2125\n",
      "##########################################################\n",
      "Epoch 35/40\n",
      "loss: 1.5930652618408203 - metric: 0.5517799854278564 - val_loss: 1.8187925815582275 - val_metric: 0.513 - penalty: 0.0\n",
      "hidden layer sizes: [3, 89, 158, 144, 204, 321, 519, 687], total units: 2125\n",
      "##########################################################\n",
      "Epoch 36/40\n",
      "loss: 1.5415548086166382 - metric: 0.5649399757385254 - val_loss: 1.8320294618606567 - val_metric: 0.5109 - penalty: 0.0\n",
      "hidden layer sizes: [3, 89, 158, 144, 204, 321, 519, 687], total units: 2125\n",
      "##########################################################\n",
      "Epoch 37/40\n",
      "loss: 1.4836082458496094 - metric: 0.576960027217865 - val_loss: 1.8722691535949707 - val_metric: 0.5104 - penalty: 0.0\n",
      "hidden layer sizes: [3, 89, 158, 144, 204, 321, 519, 687], total units: 2125\n",
      "##########################################################\n",
      "Epoch 38/40\n",
      "loss: 1.4333453178405762 - metric: 0.5881999731063843 - val_loss: 1.8320789337158203 - val_metric: 0.524 - penalty: 0.0\n",
      "hidden layer sizes: [3, 89, 158, 144, 204, 321, 519, 687], total units: 2125\n",
      "##########################################################\n",
      "Epoch 39/40\n",
      "loss: 1.3831912279129028 - metric: 0.5992599725723267 - val_loss: 1.8067773580551147 - val_metric: 0.5279 - penalty: 0.0\n",
      "hidden layer sizes: [3, 89, 158, 144, 204, 321, 519, 687], total units: 2125\n",
      "##########################################################\n",
      "Epoch 40/40\n",
      "loss: 1.328616738319397 - metric: 0.612280011177063 - val_loss: 1.8226581811904907 - val_metric: 0.5282 - penalty: 0.0\n",
      "hidden layer sizes: [3, 89, 158, 144, 204, 321, 519, 687], total units: 2125\n",
      "CPU times: user 5min 20s, sys: 13 s, total: 5min 33s\n",
      "Wall time: 5min 30s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [4.549084186553955,\n",
       "  4.352813720703125,\n",
       "  4.194449424743652,\n",
       "  4.140896320343018,\n",
       "  4.111460208892822,\n",
       "  4.025782585144043,\n",
       "  3.9784977436065674,\n",
       "  3.9471466541290283,\n",
       "  3.920301675796509,\n",
       "  3.908858060836792,\n",
       "  3.8858792781829834,\n",
       "  3.8829972743988037,\n",
       "  3.8720591068267822,\n",
       "  3.847320318222046,\n",
       "  3.813478469848633,\n",
       "  3.814519166946411,\n",
       "  3.802786350250244,\n",
       "  3.768878221511841,\n",
       "  3.7788732051849365,\n",
       "  3.7652781009674072,\n",
       "  3.4471065998077393,\n",
       "  2.944631338119507,\n",
       "  2.700770616531372,\n",
       "  2.5264780521392822,\n",
       "  2.3887054920196533,\n",
       "  2.2742366790771484,\n",
       "  2.176234483718872,\n",
       "  2.083613157272339,\n",
       "  2.000044345855713,\n",
       "  1.9322329759597778,\n",
       "  1.846045732498169,\n",
       "  1.7894470691680908,\n",
       "  1.7177040576934814,\n",
       "  1.6557029485702515,\n",
       "  1.5930652618408203,\n",
       "  1.5415548086166382,\n",
       "  1.4836082458496094,\n",
       "  1.4333453178405762,\n",
       "  1.3831912279129028,\n",
       "  1.328616738319397],\n",
       " 'metric': [0.05186000093817711,\n",
       "  0.050680000334978104,\n",
       "  0.059459999203681946,\n",
       "  0.062059998512268066,\n",
       "  0.06452000141143799,\n",
       "  0.07028000056743622,\n",
       "  0.07398000359535217,\n",
       "  0.07992000132799149,\n",
       "  0.08364000171422958,\n",
       "  0.08483999967575073,\n",
       "  0.08873999863862991,\n",
       "  0.08709999918937683,\n",
       "  0.09008000046014786,\n",
       "  0.0919400006532669,\n",
       "  0.097120001912117,\n",
       "  0.09638000279664993,\n",
       "  0.09852000325918198,\n",
       "  0.10249999910593033,\n",
       "  0.1008400022983551,\n",
       "  0.10369999706745148,\n",
       "  0.16186000406742096,\n",
       "  0.2567000091075897,\n",
       "  0.302700012922287,\n",
       "  0.3410399854183197,\n",
       "  0.37143999338150024,\n",
       "  0.39660000801086426,\n",
       "  0.4205400049686432,\n",
       "  0.4372200071811676,\n",
       "  0.45781999826431274,\n",
       "  0.47181999683380127,\n",
       "  0.4932200014591217,\n",
       "  0.5055400133132935,\n",
       "  0.5210800170898438,\n",
       "  0.5372400283813477,\n",
       "  0.5517799854278564,\n",
       "  0.5649399757385254,\n",
       "  0.576960027217865,\n",
       "  0.5881999731063843,\n",
       "  0.5992599725723267,\n",
       "  0.612280011177063],\n",
       " 'val_loss': [4.465632915496826,\n",
       "  4.1423444747924805,\n",
       "  4.066018581390381,\n",
       "  3.97802472114563,\n",
       "  3.9297356605529785,\n",
       "  3.8688793182373047,\n",
       "  3.832895278930664,\n",
       "  3.799229621887207,\n",
       "  3.756282091140747,\n",
       "  3.8367104530334473,\n",
       "  3.692204713821411,\n",
       "  3.7087230682373047,\n",
       "  3.692894220352173,\n",
       "  3.811278820037842,\n",
       "  3.6043882369995117,\n",
       "  3.7086899280548096,\n",
       "  3.6256062984466553,\n",
       "  3.5938992500305176,\n",
       "  3.6267952919006348,\n",
       "  3.5533480644226074,\n",
       "  3.0648484230041504,\n",
       "  2.719862699508667,\n",
       "  2.5450117588043213,\n",
       "  2.4292871952056885,\n",
       "  2.345032215118408,\n",
       "  2.256612539291382,\n",
       "  2.1865227222442627,\n",
       "  2.0992138385772705,\n",
       "  2.120802640914917,\n",
       "  1.9588580131530762,\n",
       "  1.9708806276321411,\n",
       "  1.9567883014678955,\n",
       "  1.8834822177886963,\n",
       "  1.903448224067688,\n",
       "  1.8187925815582275,\n",
       "  1.8320294618606567,\n",
       "  1.8722691535949707,\n",
       "  1.8320789337158203,\n",
       "  1.8067773580551147,\n",
       "  1.8226581811904907],\n",
       " 'val_metric': [0.032,\n",
       "  0.0729,\n",
       "  0.0685,\n",
       "  0.0739,\n",
       "  0.0894,\n",
       "  0.0892,\n",
       "  0.1036,\n",
       "  0.1128,\n",
       "  0.1134,\n",
       "  0.1108,\n",
       "  0.1344,\n",
       "  0.1165,\n",
       "  0.1278,\n",
       "  0.1038,\n",
       "  0.1503,\n",
       "  0.1236,\n",
       "  0.1366,\n",
       "  0.1474,\n",
       "  0.1344,\n",
       "  0.1531,\n",
       "  0.2322,\n",
       "  0.3081,\n",
       "  0.3471,\n",
       "  0.371,\n",
       "  0.3911,\n",
       "  0.4126,\n",
       "  0.4279,\n",
       "  0.4477,\n",
       "  0.4451,\n",
       "  0.4739,\n",
       "  0.4725,\n",
       "  0.4814,\n",
       "  0.4894,\n",
       "  0.495,\n",
       "  0.513,\n",
       "  0.5109,\n",
       "  0.5104,\n",
       "  0.524,\n",
       "  0.5279,\n",
       "  0.5282],\n",
       " 'hidden_layer_sizes': [[3, 51, 105, 147, 151, 105, 407, 404],\n",
       "  [3, 64, 123, 141, 144, 126, 431, 482],\n",
       "  [3, 65, 143, 165, 167, 151, 406, 575],\n",
       "  [3, 80, 164, 184, 180, 181, 395, 684],\n",
       "  [3, 65, 127, 103, 142, 215, 360, 793],\n",
       "  [3, 70, 144, 122, 166, 248, 347, 803],\n",
       "  [3, 82, 132, 135, 173, 245, 356, 730],\n",
       "  [3, 74, 142, 138, 167, 265, 360, 678],\n",
       "  [3, 65, 156, 145, 154, 285, 396, 700],\n",
       "  [3, 70, 135, 131, 165, 272, 421, 708],\n",
       "  [3, 78, 155, 153, 186, 292, 421, 729],\n",
       "  [3, 83, 147, 164, 197, 297, 437, 724],\n",
       "  [3, 86, 154, 166, 178, 258, 454, 710],\n",
       "  [3, 77, 108, 88, 151, 290, 471, 722],\n",
       "  [3, 82, 113, 103, 171, 317, 487, 703],\n",
       "  [3, 91, 123, 116, 186, 318, 495, 685],\n",
       "  [3, 71, 114, 88, 148, 282, 495, 703],\n",
       "  [3, 82, 121, 107, 171, 314, 526, 698],\n",
       "  [3, 91, 138, 123, 189, 312, 518, 709],\n",
       "  [3, 89, 158, 144, 204, 321, 519, 687],\n",
       "  [3, 89, 158, 144, 204, 321, 519, 687],\n",
       "  [3, 89, 158, 144, 204, 321, 519, 687],\n",
       "  [3, 89, 158, 144, 204, 321, 519, 687],\n",
       "  [3, 89, 158, 144, 204, 321, 519, 687],\n",
       "  [3, 89, 158, 144, 204, 321, 519, 687],\n",
       "  [3, 89, 158, 144, 204, 321, 519, 687],\n",
       "  [3, 89, 158, 144, 204, 321, 519, 687],\n",
       "  [3, 89, 158, 144, 204, 321, 519, 687],\n",
       "  [3, 89, 158, 144, 204, 321, 519, 687],\n",
       "  [3, 89, 158, 144, 204, 321, 519, 687],\n",
       "  [3, 89, 158, 144, 204, 321, 519, 687],\n",
       "  [3, 89, 158, 144, 204, 321, 519, 687],\n",
       "  [3, 89, 158, 144, 204, 321, 519, 687],\n",
       "  [3, 89, 158, 144, 204, 321, 519, 687],\n",
       "  [3, 89, 158, 144, 204, 321, 519, 687],\n",
       "  [3, 89, 158, 144, 204, 321, 519, 687],\n",
       "  [3, 89, 158, 144, 204, 321, 519, 687],\n",
       "  [3, 89, 158, 144, 204, 321, 519, 687],\n",
       "  [3, 89, 158, 144, 204, 321, 519, 687],\n",
       "  [3, 89, 158, 144, 204, 321, 519, 687]]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "schedule = [DynamicEpoch(0.00013, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20\n",
    "train_fn_conv(x=cifar100.X_train_norm, y=cifar100.y_train, \n",
    "              validation_data=(cifar100.X_test_norm, cifar100.y_test), learning_rate=0.0006, \n",
    "              schedule=schedule, layer_sizes=layer_sizes, output_neurons=100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2be2f29f-5332-484e-9d6d-0f6f5abd0953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################################\n",
      "Epoch 1/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 5.2073259353637695 - val_metric: 0.0111 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 5.207330703735352 - val_metric: 0.0111 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 52, 105, 153, 153, 105, 409, 409], total units: 1389\n",
      "Before pruning:\n",
      "loss: 4.56595516204834 - metric: 0.05435999855399132 - val_loss: 4.533403396606445 - val_metric: 0.0181 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 52, 105, 153, 153, 105, 409, 409], total units: 1389\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.533565044403076 - val_metric: 0.0182 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 32, 105, 151, 139, 105, 407, 356], total units: 1298\n",
      "##########################################################\n",
      "Epoch 2/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.533565044403076 - val_metric: 0.0182 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 32, 105, 151, 139, 105, 407, 356], total units: 1298\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.533564567565918 - val_metric: 0.0182 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 52, 126, 181, 166, 126, 488, 427], total units: 1569\n",
      "Before pruning:\n",
      "loss: 4.334947109222412 - metric: 0.055879998952150345 - val_loss: 4.360044002532959 - val_metric: 0.0353 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 52, 126, 181, 166, 126, 488, 427], total units: 1569\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.357755661010742 - val_metric: 0.0354 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 48, 120, 128, 139, 126, 375, 386], total units: 1325\n",
      "##########################################################\n",
      "Epoch 3/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.357755661010742 - val_metric: 0.0354 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 48, 120, 128, 139, 126, 375, 386], total units: 1325\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.357693195343018 - val_metric: 0.0354 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 68, 144, 153, 166, 151, 450, 463], total units: 1598\n",
      "Before pruning:\n",
      "loss: 4.149134635925293 - metric: 0.06809999793767929 - val_loss: 4.059686660766602 - val_metric: 0.0697 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 68, 144, 153, 166, 151, 450, 463], total units: 1598\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.072337627410889 - val_metric: 0.0691 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 55, 132, 125, 127, 151, 356, 437], total units: 1386\n",
      "##########################################################\n",
      "Epoch 4/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.072337627410889 - val_metric: 0.0691 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 55, 132, 125, 127, 151, 356, 437], total units: 1386\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.0723443031311035 - val_metric: 0.0691 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 75, 158, 150, 152, 181, 427, 524], total units: 1670\n",
      "Before pruning:\n",
      "loss: 4.035033226013184 - metric: 0.07562000304460526 - val_loss: 3.8558297157287598 - val_metric: 0.1068 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 75, 158, 150, 152, 181, 427, 524], total units: 1670\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.8721773624420166 - val_metric: 0.1074 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 63, 143, 135, 139, 181, 327, 503], total units: 1494\n",
      "##########################################################\n",
      "Epoch 5/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.8721773624420166 - val_metric: 0.1074 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 63, 143, 135, 139, 181, 327, 503], total units: 1494\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.8721811771392822 - val_metric: 0.1074 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 83, 171, 162, 166, 217, 392, 603], total units: 1797\n",
      "Before pruning:\n",
      "loss: 3.983527183532715 - metric: 0.08033999800682068 - val_loss: 3.806844472885132 - val_metric: 0.0977 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 83, 171, 162, 166, 217, 392, 603], total units: 1797\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.8007469177246094 - val_metric: 0.1026 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 71, 137, 129, 142, 201, 304, 544], total units: 1531\n",
      "##########################################################\n",
      "Epoch 6/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.8007469177246094 - val_metric: 0.1026 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 71, 137, 129, 142, 201, 304, 544], total units: 1531\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.8007452487945557 - val_metric: 0.1027 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 91, 164, 154, 170, 241, 364, 652], total units: 1839\n",
      "Before pruning:\n",
      "loss: 3.9143450260162354 - metric: 0.08845999836921692 - val_loss: 3.828291893005371 - val_metric: 0.1111 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 91, 164, 154, 170, 241, 364, 652], total units: 1839\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.8409407138824463 - val_metric: 0.1101 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 69, 127, 127, 132, 199, 309, 586], total units: 1552\n",
      "##########################################################\n",
      "Epoch 7/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.8409407138824463 - val_metric: 0.1101 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 69, 127, 127, 132, 199, 309, 586], total units: 1552\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.8409407138824463 - val_metric: 0.1101 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 89, 152, 152, 158, 238, 370, 703], total units: 1865\n",
      "Before pruning:\n",
      "loss: 3.8631889820098877 - metric: 0.09573999792337418 - val_loss: 3.733489513397217 - val_metric: 0.1108 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 89, 152, 152, 158, 238, 370, 703], total units: 1865\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.7325520515441895 - val_metric: 0.113 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 64, 126, 112, 147, 208, 316, 614], total units: 1590\n",
      "##########################################################\n",
      "Epoch 8/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.7325520515441895 - val_metric: 0.113 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 64, 126, 112, 147, 208, 316, 614], total units: 1590\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.7325522899627686 - val_metric: 0.1129 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 84, 151, 134, 176, 249, 379, 736], total units: 1912\n",
      "Before pruning:\n",
      "loss: 3.8141353130340576 - metric: 0.09967999905347824 - val_loss: 3.7120718955993652 - val_metric: 0.1343 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 84, 151, 134, 176, 249, 379, 736], total units: 1912\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.723306179046631 - val_metric: 0.1341 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 58, 121, 110, 113, 191, 310, 626], total units: 1532\n",
      "##########################################################\n",
      "Epoch 9/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.723306179046631 - val_metric: 0.1341 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 58, 121, 110, 113, 191, 310, 626], total units: 1532\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.723389148712158 - val_metric: 0.1342 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 78, 145, 132, 135, 229, 372, 751], total units: 1845\n",
      "Before pruning:\n",
      "loss: 3.765327215194702 - metric: 0.10670000314712524 - val_loss: 3.6606078147888184 - val_metric: 0.1368 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 78, 145, 132, 135, 229, 372, 751], total units: 1845\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.655850410461426 - val_metric: 0.1375 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 55, 114, 113, 129, 212, 316, 620], total units: 1562\n",
      "##########################################################\n",
      "Epoch 10/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.655850410461426 - val_metric: 0.1375 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 55, 114, 113, 129, 212, 316, 620], total units: 1562\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.655850410461426 - val_metric: 0.1375 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 75, 136, 135, 154, 254, 379, 744], total units: 1880\n",
      "Before pruning:\n",
      "loss: 3.742379665374756 - metric: 0.10943999886512756 - val_loss: 3.673434257507324 - val_metric: 0.1401 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 75, 136, 135, 154, 254, 379, 744], total units: 1880\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.675335645675659 - val_metric: 0.1407 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 61, 130, 121, 131, 185, 317, 599], total units: 1547\n",
      "##########################################################\n",
      "Epoch 11/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.675335645675659 - val_metric: 0.1407 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 61, 130, 121, 131, 185, 317, 599], total units: 1547\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.6753363609313965 - val_metric: 0.1407 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 81, 156, 145, 157, 222, 380, 718], total units: 1862\n",
      "Before pruning:\n",
      "loss: 3.707782506942749 - metric: 0.11444000154733658 - val_loss: 3.7352139949798584 - val_metric: 0.123 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 81, 156, 145, 157, 222, 380, 718], total units: 1862\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.730436325073242 - val_metric: 0.1241 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 62, 133, 124, 151, 204, 338, 596], total units: 1611\n",
      "##########################################################\n",
      "Epoch 12/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.730436325073242 - val_metric: 0.1241 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 62, 133, 124, 151, 204, 338, 596], total units: 1611\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.7304413318634033 - val_metric: 0.1241 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 82, 159, 148, 181, 244, 405, 715], total units: 1937\n",
      "Before pruning:\n",
      "loss: 3.703932285308838 - metric: 0.1170400008559227 - val_loss: 3.5647504329681396 - val_metric: 0.1586 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 82, 159, 148, 181, 244, 405, 715], total units: 1937\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.564068078994751 - val_metric: 0.1579 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 56, 144, 124, 132, 189, 327, 611], total units: 1586\n",
      "##########################################################\n",
      "Epoch 13/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.564068078994751 - val_metric: 0.1579 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 56, 144, 124, 132, 189, 327, 611], total units: 1586\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.5641651153564453 - val_metric: 0.158 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 76, 172, 148, 158, 226, 392, 733], total units: 1908\n",
      "Before pruning:\n",
      "loss: 3.672991991043091 - metric: 0.1200999990105629 - val_loss: 3.4905011653900146 - val_metric: 0.165 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 76, 172, 148, 158, 226, 392, 733], total units: 1908\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.484483480453491 - val_metric: 0.1703 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 63, 140, 133, 144, 210, 353, 622], total units: 1668\n",
      "##########################################################\n",
      "Epoch 14/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.484483480453491 - val_metric: 0.1703 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 63, 140, 133, 144, 210, 353, 622], total units: 1668\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.4844777584075928 - val_metric: 0.1702 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 83, 168, 159, 172, 252, 423, 746], total units: 2006\n",
      "Before pruning:\n",
      "loss: 3.650932550430298 - metric: 0.12080000340938568 - val_loss: 3.46354341506958 - val_metric: 0.1797 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 83, 168, 159, 172, 252, 423, 746], total units: 2006\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.4538416862487793 - val_metric: 0.1808 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 66, 129, 137, 144, 213, 368, 644], total units: 1704\n",
      "##########################################################\n",
      "Epoch 15/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.4538416862487793 - val_metric: 0.1808 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 66, 129, 137, 144, 213, 368, 644], total units: 1704\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.4538464546203613 - val_metric: 0.1807 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 86, 154, 164, 172, 255, 441, 772], total units: 2047\n",
      "Before pruning:\n",
      "loss: 3.627408981323242 - metric: 0.12647999823093414 - val_loss: 3.478297710418701 - val_metric: 0.1646 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 86, 154, 164, 172, 255, 441, 772], total units: 2047\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.479189872741699 - val_metric: 0.1665 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 63, 121, 79, 109, 179, 347, 646], total units: 1547\n",
      "##########################################################\n",
      "Epoch 16/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.479189872741699 - val_metric: 0.1665 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 63, 121, 79, 109, 179, 347, 646], total units: 1547\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.479186773300171 - val_metric: 0.1666 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 83, 145, 99, 130, 214, 416, 775], total units: 1865\n",
      "Before pruning:\n",
      "loss: 3.572431802749634 - metric: 0.1325400024652481 - val_loss: 3.3756749629974365 - val_metric: 0.181 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 83, 145, 99, 130, 214, 416, 775], total units: 1865\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.370507001876831 - val_metric: 0.1838 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 61, 122, 97, 127, 208, 359, 644], total units: 1621\n",
      "##########################################################\n",
      "Epoch 17/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.370507001876831 - val_metric: 0.1838 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 61, 122, 97, 127, 208, 359, 644], total units: 1621\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.3705077171325684 - val_metric: 0.1838 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 81, 146, 117, 152, 249, 430, 772], total units: 1950\n",
      "Before pruning:\n",
      "loss: 3.5746312141418457 - metric: 0.13490000367164612 - val_loss: 3.474834442138672 - val_metric: 0.1653 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 81, 146, 117, 152, 249, 430, 772], total units: 1950\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.468026876449585 - val_metric: 0.1688 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 59, 120, 105, 134, 175, 348, 633], total units: 1577\n",
      "##########################################################\n",
      "Epoch 18/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.468026876449585 - val_metric: 0.1688 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 59, 120, 105, 134, 175, 348, 633], total units: 1577\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.468029260635376 - val_metric: 0.1688 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 79, 144, 126, 160, 210, 417, 759], total units: 1898\n",
      "Before pruning:\n",
      "loss: 3.559032917022705 - metric: 0.13680000603199005 - val_loss: 3.3406808376312256 - val_metric: 0.1929 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 79, 144, 126, 160, 210, 417, 759], total units: 1898\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.337322950363159 - val_metric: 0.1909 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 58, 138, 119, 152, 202, 368, 629], total units: 1669\n",
      "##########################################################\n",
      "Epoch 19/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.337322950363159 - val_metric: 0.1909 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 58, 138, 119, 152, 202, 368, 629], total units: 1669\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.337358236312866 - val_metric: 0.191 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 78, 165, 142, 182, 242, 441, 754], total units: 2007\n",
      "Before pruning:\n",
      "loss: 3.5527536869049072 - metric: 0.1379999965429306 - val_loss: 3.4898881912231445 - val_metric: 0.1602 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 78, 165, 142, 182, 242, 441, 754], total units: 2007\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.4862191677093506 - val_metric: 0.1658 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 54, 99, 120, 126, 185, 370, 655], total units: 1612\n",
      "##########################################################\n",
      "Epoch 20/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.4862191677093506 - val_metric: 0.1658 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 54, 99, 120, 126, 185, 370, 655], total units: 1612\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.4864137172698975 - val_metric: 0.1658 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 74, 119, 144, 151, 222, 444, 786], total units: 1943\n",
      "Before pruning:\n",
      "loss: 3.5288827419281006 - metric: 0.14059999585151672 - val_loss: 3.5763046741485596 - val_metric: 0.1524 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 74, 119, 144, 151, 222, 444, 786], total units: 1943\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.5697214603424072 - val_metric: 0.1538 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 61, 116, 121, 136, 208, 373, 663], total units: 1681\n",
      "##########################################################\n",
      "Epoch 21/40\n",
      "loss: 3.244096517562866 - metric: 0.19740000367164612 - val_loss: 2.833209991455078 - val_metric: 0.2676 - penalty: 0.0\n",
      "hidden layer sizes: [3, 61, 116, 121, 136, 208, 373, 663], total units: 1681\n",
      "##########################################################\n",
      "Epoch 22/40\n",
      "loss: 2.8027663230895996 - metric: 0.2815999984741211 - val_loss: 2.6360116004943848 - val_metric: 0.3201 - penalty: 0.0\n",
      "hidden layer sizes: [3, 61, 116, 121, 136, 208, 373, 663], total units: 1681\n",
      "##########################################################\n",
      "Epoch 23/40\n",
      "loss: 2.596278190612793 - metric: 0.3278000056743622 - val_loss: 2.477787971496582 - val_metric: 0.3567 - penalty: 0.0\n",
      "hidden layer sizes: [3, 61, 116, 121, 136, 208, 373, 663], total units: 1681\n",
      "##########################################################\n",
      "Epoch 24/40\n",
      "loss: 2.458275556564331 - metric: 0.3566800057888031 - val_loss: 2.434131622314453 - val_metric: 0.3656 - penalty: 0.0\n",
      "hidden layer sizes: [3, 61, 116, 121, 136, 208, 373, 663], total units: 1681\n",
      "##########################################################\n",
      "Epoch 25/40\n",
      "loss: 2.3498642444610596 - metric: 0.38166001439094543 - val_loss: 2.334613561630249 - val_metric: 0.3923 - penalty: 0.0\n",
      "hidden layer sizes: [3, 61, 116, 121, 136, 208, 373, 663], total units: 1681\n",
      "##########################################################\n",
      "Epoch 26/40\n",
      "loss: 2.2647039890289307 - metric: 0.3984000086784363 - val_loss: 2.2814321517944336 - val_metric: 0.4008 - penalty: 0.0\n",
      "hidden layer sizes: [3, 61, 116, 121, 136, 208, 373, 663], total units: 1681\n",
      "##########################################################\n",
      "Epoch 27/40\n",
      "loss: 2.191380739212036 - metric: 0.4139400124549866 - val_loss: 2.1509900093078613 - val_metric: 0.4375 - penalty: 0.0\n",
      "hidden layer sizes: [3, 61, 116, 121, 136, 208, 373, 663], total units: 1681\n",
      "##########################################################\n",
      "Epoch 28/40\n",
      "loss: 2.12186598777771 - metric: 0.43101999163627625 - val_loss: 2.1419639587402344 - val_metric: 0.4341 - penalty: 0.0\n",
      "hidden layer sizes: [3, 61, 116, 121, 136, 208, 373, 663], total units: 1681\n",
      "##########################################################\n",
      "Epoch 29/40\n",
      "loss: 2.051474094390869 - metric: 0.44398000836372375 - val_loss: 2.0756211280822754 - val_metric: 0.4504 - penalty: 0.0\n",
      "hidden layer sizes: [3, 61, 116, 121, 136, 208, 373, 663], total units: 1681\n",
      "##########################################################\n",
      "Epoch 30/40\n",
      "loss: 1.9984978437423706 - metric: 0.45983999967575073 - val_loss: 2.0403194427490234 - val_metric: 0.4579 - penalty: 0.0\n",
      "hidden layer sizes: [3, 61, 116, 121, 136, 208, 373, 663], total units: 1681\n",
      "##########################################################\n",
      "Epoch 31/40\n",
      "loss: 1.9519572257995605 - metric: 0.4672600030899048 - val_loss: 1.9883804321289062 - val_metric: 0.4708 - penalty: 0.0\n",
      "hidden layer sizes: [3, 61, 116, 121, 136, 208, 373, 663], total units: 1681\n",
      "##########################################################\n",
      "Epoch 32/40\n",
      "loss: 1.8952778577804565 - metric: 0.48201999068260193 - val_loss: 2.053596019744873 - val_metric: 0.4551 - penalty: 0.0\n",
      "hidden layer sizes: [3, 61, 116, 121, 136, 208, 373, 663], total units: 1681\n",
      "##########################################################\n",
      "Epoch 33/40\n",
      "loss: 1.8562084436416626 - metric: 0.48980000615119934 - val_loss: 1.9112166166305542 - val_metric: 0.4902 - penalty: 0.0\n",
      "hidden layer sizes: [3, 61, 116, 121, 136, 208, 373, 663], total units: 1681\n",
      "##########################################################\n",
      "Epoch 34/40\n",
      "loss: 1.8159375190734863 - metric: 0.49775999784469604 - val_loss: 1.8600844144821167 - val_metric: 0.4948 - penalty: 0.0\n",
      "hidden layer sizes: [3, 61, 116, 121, 136, 208, 373, 663], total units: 1681\n",
      "##########################################################\n",
      "Epoch 35/40\n",
      "loss: 1.7736674547195435 - metric: 0.5082799792289734 - val_loss: 1.9016777276992798 - val_metric: 0.4871 - penalty: 0.0\n",
      "hidden layer sizes: [3, 61, 116, 121, 136, 208, 373, 663], total units: 1681\n",
      "##########################################################\n",
      "Epoch 36/40\n",
      "loss: 1.739377498626709 - metric: 0.5165600180625916 - val_loss: 1.8812140226364136 - val_metric: 0.5002 - penalty: 0.0\n",
      "hidden layer sizes: [3, 61, 116, 121, 136, 208, 373, 663], total units: 1681\n",
      "##########################################################\n",
      "Epoch 37/40\n",
      "loss: 1.687158226966858 - metric: 0.5278400182723999 - val_loss: 1.8507622480392456 - val_metric: 0.5057 - penalty: 0.0\n",
      "hidden layer sizes: [3, 61, 116, 121, 136, 208, 373, 663], total units: 1681\n",
      "##########################################################\n",
      "Epoch 38/40\n",
      "loss: 1.656922698020935 - metric: 0.5355600118637085 - val_loss: 1.8818191289901733 - val_metric: 0.5012 - penalty: 0.0\n",
      "hidden layer sizes: [3, 61, 116, 121, 136, 208, 373, 663], total units: 1681\n",
      "##########################################################\n",
      "Epoch 39/40\n",
      "loss: 1.631765604019165 - metric: 0.5422199964523315 - val_loss: 1.8042794466018677 - val_metric: 0.5205 - penalty: 0.0\n",
      "hidden layer sizes: [3, 61, 116, 121, 136, 208, 373, 663], total units: 1681\n",
      "##########################################################\n",
      "Epoch 40/40\n",
      "loss: 1.5926710367202759 - metric: 0.5515599846839905 - val_loss: 1.8276747465133667 - val_metric: 0.5109 - penalty: 0.0\n",
      "hidden layer sizes: [3, 61, 116, 121, 136, 208, 373, 663], total units: 1681\n",
      "CPU times: user 5min 4s, sys: 10.8 s, total: 5min 15s\n",
      "Wall time: 4min 48s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [4.56595516204834,\n",
       "  4.334947109222412,\n",
       "  4.149134635925293,\n",
       "  4.035033226013184,\n",
       "  3.983527183532715,\n",
       "  3.9143450260162354,\n",
       "  3.8631889820098877,\n",
       "  3.8141353130340576,\n",
       "  3.765327215194702,\n",
       "  3.742379665374756,\n",
       "  3.707782506942749,\n",
       "  3.703932285308838,\n",
       "  3.672991991043091,\n",
       "  3.650932550430298,\n",
       "  3.627408981323242,\n",
       "  3.572431802749634,\n",
       "  3.5746312141418457,\n",
       "  3.559032917022705,\n",
       "  3.5527536869049072,\n",
       "  3.5288827419281006,\n",
       "  3.244096517562866,\n",
       "  2.8027663230895996,\n",
       "  2.596278190612793,\n",
       "  2.458275556564331,\n",
       "  2.3498642444610596,\n",
       "  2.2647039890289307,\n",
       "  2.191380739212036,\n",
       "  2.12186598777771,\n",
       "  2.051474094390869,\n",
       "  1.9984978437423706,\n",
       "  1.9519572257995605,\n",
       "  1.8952778577804565,\n",
       "  1.8562084436416626,\n",
       "  1.8159375190734863,\n",
       "  1.7736674547195435,\n",
       "  1.739377498626709,\n",
       "  1.687158226966858,\n",
       "  1.656922698020935,\n",
       "  1.631765604019165,\n",
       "  1.5926710367202759],\n",
       " 'metric': [0.05435999855399132,\n",
       "  0.055879998952150345,\n",
       "  0.06809999793767929,\n",
       "  0.07562000304460526,\n",
       "  0.08033999800682068,\n",
       "  0.08845999836921692,\n",
       "  0.09573999792337418,\n",
       "  0.09967999905347824,\n",
       "  0.10670000314712524,\n",
       "  0.10943999886512756,\n",
       "  0.11444000154733658,\n",
       "  0.1170400008559227,\n",
       "  0.1200999990105629,\n",
       "  0.12080000340938568,\n",
       "  0.12647999823093414,\n",
       "  0.1325400024652481,\n",
       "  0.13490000367164612,\n",
       "  0.13680000603199005,\n",
       "  0.1379999965429306,\n",
       "  0.14059999585151672,\n",
       "  0.19740000367164612,\n",
       "  0.2815999984741211,\n",
       "  0.3278000056743622,\n",
       "  0.3566800057888031,\n",
       "  0.38166001439094543,\n",
       "  0.3984000086784363,\n",
       "  0.4139400124549866,\n",
       "  0.43101999163627625,\n",
       "  0.44398000836372375,\n",
       "  0.45983999967575073,\n",
       "  0.4672600030899048,\n",
       "  0.48201999068260193,\n",
       "  0.48980000615119934,\n",
       "  0.49775999784469604,\n",
       "  0.5082799792289734,\n",
       "  0.5165600180625916,\n",
       "  0.5278400182723999,\n",
       "  0.5355600118637085,\n",
       "  0.5422199964523315,\n",
       "  0.5515599846839905],\n",
       " 'val_loss': [4.533565044403076,\n",
       "  4.357755661010742,\n",
       "  4.072337627410889,\n",
       "  3.8721773624420166,\n",
       "  3.8007469177246094,\n",
       "  3.8409407138824463,\n",
       "  3.7325520515441895,\n",
       "  3.723306179046631,\n",
       "  3.655850410461426,\n",
       "  3.675335645675659,\n",
       "  3.730436325073242,\n",
       "  3.564068078994751,\n",
       "  3.484483480453491,\n",
       "  3.4538416862487793,\n",
       "  3.479189872741699,\n",
       "  3.370507001876831,\n",
       "  3.468026876449585,\n",
       "  3.337322950363159,\n",
       "  3.4862191677093506,\n",
       "  3.5697214603424072,\n",
       "  2.833209991455078,\n",
       "  2.6360116004943848,\n",
       "  2.477787971496582,\n",
       "  2.434131622314453,\n",
       "  2.334613561630249,\n",
       "  2.2814321517944336,\n",
       "  2.1509900093078613,\n",
       "  2.1419639587402344,\n",
       "  2.0756211280822754,\n",
       "  2.0403194427490234,\n",
       "  1.9883804321289062,\n",
       "  2.053596019744873,\n",
       "  1.9112166166305542,\n",
       "  1.8600844144821167,\n",
       "  1.9016777276992798,\n",
       "  1.8812140226364136,\n",
       "  1.8507622480392456,\n",
       "  1.8818191289901733,\n",
       "  1.8042794466018677,\n",
       "  1.8276747465133667],\n",
       " 'val_metric': [0.0182,\n",
       "  0.0354,\n",
       "  0.0691,\n",
       "  0.1074,\n",
       "  0.1026,\n",
       "  0.1101,\n",
       "  0.113,\n",
       "  0.1341,\n",
       "  0.1375,\n",
       "  0.1407,\n",
       "  0.1241,\n",
       "  0.1579,\n",
       "  0.1703,\n",
       "  0.1808,\n",
       "  0.1665,\n",
       "  0.1838,\n",
       "  0.1688,\n",
       "  0.1909,\n",
       "  0.1658,\n",
       "  0.1538,\n",
       "  0.2676,\n",
       "  0.3201,\n",
       "  0.3567,\n",
       "  0.3656,\n",
       "  0.3923,\n",
       "  0.4008,\n",
       "  0.4375,\n",
       "  0.4341,\n",
       "  0.4504,\n",
       "  0.4579,\n",
       "  0.4708,\n",
       "  0.4551,\n",
       "  0.4902,\n",
       "  0.4948,\n",
       "  0.4871,\n",
       "  0.5002,\n",
       "  0.5057,\n",
       "  0.5012,\n",
       "  0.5205,\n",
       "  0.5109],\n",
       " 'hidden_layer_sizes': [[3, 32, 105, 151, 139, 105, 407, 356],\n",
       "  [3, 48, 120, 128, 139, 126, 375, 386],\n",
       "  [3, 55, 132, 125, 127, 151, 356, 437],\n",
       "  [3, 63, 143, 135, 139, 181, 327, 503],\n",
       "  [3, 71, 137, 129, 142, 201, 304, 544],\n",
       "  [3, 69, 127, 127, 132, 199, 309, 586],\n",
       "  [3, 64, 126, 112, 147, 208, 316, 614],\n",
       "  [3, 58, 121, 110, 113, 191, 310, 626],\n",
       "  [3, 55, 114, 113, 129, 212, 316, 620],\n",
       "  [3, 61, 130, 121, 131, 185, 317, 599],\n",
       "  [3, 62, 133, 124, 151, 204, 338, 596],\n",
       "  [3, 56, 144, 124, 132, 189, 327, 611],\n",
       "  [3, 63, 140, 133, 144, 210, 353, 622],\n",
       "  [3, 66, 129, 137, 144, 213, 368, 644],\n",
       "  [3, 63, 121, 79, 109, 179, 347, 646],\n",
       "  [3, 61, 122, 97, 127, 208, 359, 644],\n",
       "  [3, 59, 120, 105, 134, 175, 348, 633],\n",
       "  [3, 58, 138, 119, 152, 202, 368, 629],\n",
       "  [3, 54, 99, 120, 126, 185, 370, 655],\n",
       "  [3, 61, 116, 121, 136, 208, 373, 663],\n",
       "  [3, 61, 116, 121, 136, 208, 373, 663],\n",
       "  [3, 61, 116, 121, 136, 208, 373, 663],\n",
       "  [3, 61, 116, 121, 136, 208, 373, 663],\n",
       "  [3, 61, 116, 121, 136, 208, 373, 663],\n",
       "  [3, 61, 116, 121, 136, 208, 373, 663],\n",
       "  [3, 61, 116, 121, 136, 208, 373, 663],\n",
       "  [3, 61, 116, 121, 136, 208, 373, 663],\n",
       "  [3, 61, 116, 121, 136, 208, 373, 663],\n",
       "  [3, 61, 116, 121, 136, 208, 373, 663],\n",
       "  [3, 61, 116, 121, 136, 208, 373, 663],\n",
       "  [3, 61, 116, 121, 136, 208, 373, 663],\n",
       "  [3, 61, 116, 121, 136, 208, 373, 663],\n",
       "  [3, 61, 116, 121, 136, 208, 373, 663],\n",
       "  [3, 61, 116, 121, 136, 208, 373, 663],\n",
       "  [3, 61, 116, 121, 136, 208, 373, 663],\n",
       "  [3, 61, 116, 121, 136, 208, 373, 663],\n",
       "  [3, 61, 116, 121, 136, 208, 373, 663],\n",
       "  [3, 61, 116, 121, 136, 208, 373, 663],\n",
       "  [3, 61, 116, 121, 136, 208, 373, 663],\n",
       "  [3, 61, 116, 121, 136, 208, 373, 663]]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "schedule = [DynamicEpoch(0.00013, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20\n",
    "train_fn_conv(x=cifar100.X_train_norm, y=cifar100.y_train, \n",
    "              validation_data=(cifar100.X_test_norm, cifar100.y_test), learning_rate=0.0004, \n",
    "              schedule=schedule, layer_sizes=layer_sizes, output_neurons=100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64ecd9b4-8509-4615-a801-82741291cd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################################\n",
      "Epoch 1/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 5.303699016571045 - val_metric: 0.0097 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 5.303708553314209 - val_metric: 0.0097 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 52, 105, 153, 153, 105, 409, 409], total units: 1389\n",
      "Before pruning:\n",
      "loss: 5.139209270477295 - metric: 0.025259999558329582 - val_loss: 4.1934590339660645 - val_metric: 0.083 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 52, 105, 153, 153, 105, 409, 409], total units: 1389\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.193662643432617 - val_metric: 0.0831 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 2/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.193662643432617 - val_metric: 0.0831 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.193663597106934 - val_metric: 0.083 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 52, 105, 153, 153, 105, 409, 409], total units: 1389\n",
      "Before pruning:\n",
      "loss: 4.282550811767578 - metric: 0.07541999965906143 - val_loss: 4.424419403076172 - val_metric: 0.0372 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 52, 105, 153, 153, 105, 409, 409], total units: 1389\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.424328327178955 - val_metric: 0.0373 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 105, 341, 341], total units: 1163\n",
      "##########################################################\n",
      "Epoch 3/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.424328327178955 - val_metric: 0.0373 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 105, 341, 341], total units: 1163\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.424328327178955 - val_metric: 0.0373 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 52, 105, 153, 153, 126, 409, 409], total units: 1410\n",
      "Before pruning:\n",
      "loss: 4.098367691040039 - metric: 0.08767999708652496 - val_loss: 4.251391410827637 - val_metric: 0.0466 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 52, 105, 153, 153, 126, 409, 409], total units: 1410\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.2489237785339355 - val_metric: 0.0461 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 32, 88, 113, 120, 125, 279, 341], total units: 1101\n",
      "##########################################################\n",
      "Epoch 4/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.2489237785339355 - val_metric: 0.0461 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 32, 88, 113, 120, 125, 279, 341], total units: 1101\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.2489237785339355 - val_metric: 0.0461 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 52, 108, 135, 144, 150, 334, 409], total units: 1335\n",
      "Before pruning:\n",
      "loss: 3.9473702907562256 - metric: 0.09904000163078308 - val_loss: 4.1036601066589355 - val_metric: 0.0699 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 52, 108, 135, 144, 150, 334, 409], total units: 1335\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.1110968589782715 - val_metric: 0.0663 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 32, 86, 94, 99, 123, 227, 341], total units: 1005\n",
      "##########################################################\n",
      "Epoch 5/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.1110968589782715 - val_metric: 0.0663 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 32, 86, 94, 99, 123, 227, 341], total units: 1005\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.111098289489746 - val_metric: 0.0663 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 52, 106, 114, 119, 147, 272, 409], total units: 1222\n",
      "Before pruning:\n",
      "loss: 3.817727565765381 - metric: 0.11271999776363373 - val_loss: 3.862060070037842 - val_metric: 0.1047 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 52, 106, 114, 119, 147, 272, 409], total units: 1222\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.8588175773620605 - val_metric: 0.1036 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 37, 85, 82, 79, 111, 220, 341], total units: 958\n",
      "##########################################################\n",
      "Epoch 6/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.8588175773620605 - val_metric: 0.1036 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 37, 85, 82, 79, 111, 220, 341], total units: 958\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.8588180541992188 - val_metric: 0.1036 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 57, 105, 102, 99, 133, 264, 409], total units: 1172\n",
      "Before pruning:\n",
      "loss: 3.713214635848999 - metric: 0.12544000148773193 - val_loss: 3.812802314758301 - val_metric: 0.1137 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 57, 105, 102, 99, 133, 264, 409], total units: 1172\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.7918214797973633 - val_metric: 0.117 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 36, 84, 78, 83, 118, 212, 341], total units: 955\n",
      "##########################################################\n",
      "Epoch 7/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.7918214797973633 - val_metric: 0.117 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 36, 84, 78, 83, 118, 212, 341], total units: 955\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.791823387145996 - val_metric: 0.117 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 56, 104, 98, 103, 141, 254, 409], total units: 1168\n",
      "Before pruning:\n",
      "loss: 3.63161039352417 - metric: 0.13592000305652618 - val_loss: 3.7374770641326904 - val_metric: 0.1229 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 56, 104, 98, 103, 141, 254, 409], total units: 1168\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.725651979446411 - val_metric: 0.1275 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 32, 83, 72, 81, 118, 217, 341], total units: 947\n",
      "##########################################################\n",
      "Epoch 8/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.725651979446411 - val_metric: 0.1275 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 32, 83, 72, 81, 118, 217, 341], total units: 947\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.7256574630737305 - val_metric: 0.1275 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 52, 103, 92, 101, 141, 260, 409], total units: 1161\n",
      "Before pruning:\n",
      "loss: 3.573876142501831 - metric: 0.14441999793052673 - val_loss: 3.6637628078460693 - val_metric: 0.144 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 52, 103, 92, 101, 141, 260, 409], total units: 1161\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.675023078918457 - val_metric: 0.1428 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 36, 81, 74, 77, 109, 218, 341], total units: 939\n",
      "##########################################################\n",
      "Epoch 9/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.675023078918457 - val_metric: 0.1428 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 36, 81, 74, 77, 109, 218, 341], total units: 939\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.6750237941741943 - val_metric: 0.1428 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 56, 101, 94, 97, 130, 261, 409], total units: 1151\n",
      "Before pruning:\n",
      "loss: 3.515458106994629 - metric: 0.15272000432014465 - val_loss: 3.4391722679138184 - val_metric: 0.1876 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 56, 101, 94, 97, 130, 261, 409], total units: 1151\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.466456174850464 - val_metric: 0.1861 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 32, 82, 68, 85, 107, 205, 340], total units: 922\n",
      "##########################################################\n",
      "Epoch 10/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.466456174850464 - val_metric: 0.1861 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 32, 82, 68, 85, 107, 205, 340], total units: 922\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.466461658477783 - val_metric: 0.186 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 52, 102, 88, 105, 128, 246, 408], total units: 1132\n",
      "Before pruning:\n",
      "loss: 3.462778091430664 - metric: 0.16166000068187714 - val_loss: 3.480165958404541 - val_metric: 0.1801 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 52, 102, 88, 105, 128, 246, 408], total units: 1132\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.4828686714172363 - val_metric: 0.1769 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 36, 80, 68, 79, 111, 200, 337], total units: 914\n",
      "##########################################################\n",
      "Epoch 11/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.4828686714172363 - val_metric: 0.1769 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 36, 80, 68, 79, 111, 200, 337], total units: 914\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.482875108718872 - val_metric: 0.1768 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 56, 100, 88, 99, 133, 240, 404], total units: 1123\n",
      "Before pruning:\n",
      "loss: 3.4102041721343994 - metric: 0.1695999950170517 - val_loss: 3.4164905548095703 - val_metric: 0.1795 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 56, 100, 88, 99, 133, 240, 404], total units: 1123\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.4259836673736572 - val_metric: 0.1782 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 33, 76, 59, 72, 110, 191, 332], total units: 876\n",
      "##########################################################\n",
      "Epoch 12/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.4259836673736572 - val_metric: 0.1782 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 33, 76, 59, 72, 110, 191, 332], total units: 876\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.4259660243988037 - val_metric: 0.1782 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 53, 96, 79, 92, 132, 229, 398], total units: 1082\n",
      "Before pruning:\n",
      "loss: 3.368546485900879 - metric: 0.17292000353336334 - val_loss: 3.376969575881958 - val_metric: 0.2001 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 53, 96, 79, 92, 132, 229, 398], total units: 1082\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.3794753551483154 - val_metric: 0.2012 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 33, 75, 62, 71, 101, 195, 330], total units: 870\n",
      "##########################################################\n",
      "Epoch 13/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.3794753551483154 - val_metric: 0.2012 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 33, 75, 62, 71, 101, 195, 330], total units: 870\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.379434823989868 - val_metric: 0.2011 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 53, 95, 82, 91, 121, 234, 396], total units: 1075\n",
      "Before pruning:\n",
      "loss: 3.330777168273926 - metric: 0.18211999535560608 - val_loss: 3.2945921421051025 - val_metric: 0.1994 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 53, 95, 82, 91, 121, 234, 396], total units: 1075\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.2944722175598145 - val_metric: 0.2026 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 37, 70, 60, 67, 104, 177, 326], total units: 844\n",
      "##########################################################\n",
      "Epoch 14/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.2944722175598145 - val_metric: 0.2026 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 37, 70, 60, 67, 104, 177, 326], total units: 844\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.2944746017456055 - val_metric: 0.2026 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 57, 90, 80, 87, 124, 212, 391], total units: 1044\n",
      "Before pruning:\n",
      "loss: 3.304774761199951 - metric: 0.18821999430656433 - val_loss: 3.378815174102783 - val_metric: 0.2015 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 57, 90, 80, 87, 124, 212, 391], total units: 1044\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.368662118911743 - val_metric: 0.1996 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 35, 69, 60, 63, 89, 183, 318], total units: 820\n",
      "##########################################################\n",
      "Epoch 15/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.368662118911743 - val_metric: 0.1996 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 35, 69, 60, 63, 89, 183, 318], total units: 820\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.368666410446167 - val_metric: 0.1996 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 55, 89, 80, 83, 109, 219, 381], total units: 1019\n",
      "Before pruning:\n",
      "loss: 3.272791862487793 - metric: 0.1942799985408783 - val_loss: 3.3511242866516113 - val_metric: 0.1915 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 55, 89, 80, 83, 109, 219, 381], total units: 1019\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.349904775619507 - val_metric: 0.1913 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 39, 68, 65, 72, 107, 181, 307], total units: 842\n",
      "##########################################################\n",
      "Epoch 16/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.349904775619507 - val_metric: 0.1913 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 39, 68, 65, 72, 107, 181, 307], total units: 842\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.349907875061035 - val_metric: 0.1912 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 59, 88, 85, 92, 128, 217, 368], total units: 1040\n",
      "Before pruning:\n",
      "loss: 3.253862142562866 - metric: 0.19660000503063202 - val_loss: 3.2448737621307373 - val_metric: 0.2057 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 59, 88, 85, 92, 128, 217, 368], total units: 1040\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.2473130226135254 - val_metric: 0.206 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 38, 67, 60, 67, 94, 175, 297], total units: 801\n",
      "##########################################################\n",
      "Epoch 17/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.2473130226135254 - val_metric: 0.206 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 38, 67, 60, 67, 94, 175, 297], total units: 801\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.2473039627075195 - val_metric: 0.206 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 58, 87, 80, 87, 114, 210, 356], total units: 995\n",
      "Before pruning:\n",
      "loss: 3.2242653369903564 - metric: 0.2018599957227707 - val_loss: 3.359748125076294 - val_metric: 0.1883 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 58, 87, 80, 87, 114, 210, 356], total units: 995\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.3555819988250732 - val_metric: 0.1898 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 33, 65, 60, 56, 95, 172, 283], total units: 767\n",
      "##########################################################\n",
      "Epoch 18/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.3555819988250732 - val_metric: 0.1898 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 33, 65, 60, 56, 95, 172, 283], total units: 767\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.3555729389190674 - val_metric: 0.1898 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 53, 85, 80, 76, 115, 206, 339], total units: 957\n",
      "Before pruning:\n",
      "loss: 3.2118144035339355 - metric: 0.2041199952363968 - val_loss: 3.518359422683716 - val_metric: 0.1724 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 53, 85, 80, 76, 115, 206, 339], total units: 957\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.512687921524048 - val_metric: 0.1729 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 33, 66, 69, 72, 108, 168, 278], total units: 797\n",
      "##########################################################\n",
      "Epoch 19/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.512687921524048 - val_metric: 0.1729 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 33, 66, 69, 72, 108, 168, 278], total units: 797\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.5126757621765137 - val_metric: 0.1729 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 53, 86, 89, 92, 129, 201, 333], total units: 986\n",
      "Before pruning:\n",
      "loss: 3.1950929164886475 - metric: 0.2078000009059906 - val_loss: 3.1008944511413574 - val_metric: 0.2434 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 53, 86, 89, 92, 129, 201, 333], total units: 986\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.106849431991577 - val_metric: 0.2392 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 38, 64, 59, 64, 99, 178, 270], total units: 775\n",
      "##########################################################\n",
      "Epoch 20/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.106849431991577 - val_metric: 0.2392 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 38, 64, 59, 64, 99, 178, 270], total units: 775\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.1068530082702637 - val_metric: 0.2392 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 58, 84, 79, 84, 119, 213, 324], total units: 964\n",
      "Before pruning:\n",
      "loss: 3.170907735824585 - metric: 0.2132200002670288 - val_loss: 3.125703811645508 - val_metric: 0.2382 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 58, 84, 79, 84, 119, 213, 324], total units: 964\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.142089366912842 - val_metric: 0.2365 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 35, 63, 62, 64, 100, 170, 268], total units: 765\n",
      "##########################################################\n",
      "Epoch 21/40\n",
      "loss: 3.0061044692993164 - metric: 0.24879999458789825 - val_loss: 3.197854518890381 - val_metric: 0.2461 - penalty: 0.0\n",
      "hidden layer sizes: [3, 35, 63, 62, 64, 100, 170, 268], total units: 765\n",
      "##########################################################\n",
      "Epoch 22/40\n",
      "loss: 2.8003909587860107 - metric: 0.28891998529434204 - val_loss: 2.7522058486938477 - val_metric: 0.3085 - penalty: 0.0\n",
      "hidden layer sizes: [3, 35, 63, 62, 64, 100, 170, 268], total units: 765\n",
      "##########################################################\n",
      "Epoch 23/40\n",
      "loss: 2.728278160095215 - metric: 0.3056800067424774 - val_loss: 2.9944076538085938 - val_metric: 0.2797 - penalty: 0.0\n",
      "hidden layer sizes: [3, 35, 63, 62, 64, 100, 170, 268], total units: 765\n",
      "##########################################################\n",
      "Epoch 24/40\n",
      "loss: 2.673301935195923 - metric: 0.31679999828338623 - val_loss: 2.6643946170806885 - val_metric: 0.323 - penalty: 0.0\n",
      "hidden layer sizes: [3, 35, 63, 62, 64, 100, 170, 268], total units: 765\n",
      "##########################################################\n",
      "Epoch 25/40\n",
      "loss: 2.626842737197876 - metric: 0.326119989156723 - val_loss: 2.7350075244903564 - val_metric: 0.3163 - penalty: 0.0\n",
      "hidden layer sizes: [3, 35, 63, 62, 64, 100, 170, 268], total units: 765\n",
      "##########################################################\n",
      "Epoch 26/40\n",
      "loss: 2.5961828231811523 - metric: 0.3334999978542328 - val_loss: 2.668752908706665 - val_metric: 0.3294 - penalty: 0.0\n",
      "hidden layer sizes: [3, 35, 63, 62, 64, 100, 170, 268], total units: 765\n",
      "##########################################################\n",
      "Epoch 27/40\n",
      "loss: 2.5646309852600098 - metric: 0.3396199941635132 - val_loss: 2.6115148067474365 - val_metric: 0.3405 - penalty: 0.0\n",
      "hidden layer sizes: [3, 35, 63, 62, 64, 100, 170, 268], total units: 765\n",
      "##########################################################\n",
      "Epoch 28/40\n",
      "loss: 2.536334753036499 - metric: 0.3440200090408325 - val_loss: 2.6853842735290527 - val_metric: 0.3208 - penalty: 0.0\n",
      "hidden layer sizes: [3, 35, 63, 62, 64, 100, 170, 268], total units: 765\n",
      "##########################################################\n",
      "Epoch 29/40\n",
      "loss: 2.510082244873047 - metric: 0.3499000072479248 - val_loss: 2.542630195617676 - val_metric: 0.3445 - penalty: 0.0\n",
      "hidden layer sizes: [3, 35, 63, 62, 64, 100, 170, 268], total units: 765\n",
      "##########################################################\n",
      "Epoch 30/40\n",
      "loss: 2.4837191104888916 - metric: 0.3580000102519989 - val_loss: 2.580733299255371 - val_metric: 0.3472 - penalty: 0.0\n",
      "hidden layer sizes: [3, 35, 63, 62, 64, 100, 170, 268], total units: 765\n",
      "##########################################################\n",
      "Epoch 31/40\n",
      "loss: 2.4619791507720947 - metric: 0.3596999943256378 - val_loss: 2.540576696395874 - val_metric: 0.3555 - penalty: 0.0\n",
      "hidden layer sizes: [3, 35, 63, 62, 64, 100, 170, 268], total units: 765\n",
      "##########################################################\n",
      "Epoch 32/40\n",
      "loss: 2.4447641372680664 - metric: 0.36528000235557556 - val_loss: 2.5335590839385986 - val_metric: 0.3586 - penalty: 0.0\n",
      "hidden layer sizes: [3, 35, 63, 62, 64, 100, 170, 268], total units: 765\n",
      "##########################################################\n",
      "Epoch 33/40\n",
      "loss: 2.420140027999878 - metric: 0.36970001459121704 - val_loss: 2.496124505996704 - val_metric: 0.3647 - penalty: 0.0\n",
      "hidden layer sizes: [3, 35, 63, 62, 64, 100, 170, 268], total units: 765\n",
      "##########################################################\n",
      "Epoch 34/40\n",
      "loss: 2.399810314178467 - metric: 0.375900000333786 - val_loss: 2.3894577026367188 - val_metric: 0.3799 - penalty: 0.0\n",
      "hidden layer sizes: [3, 35, 63, 62, 64, 100, 170, 268], total units: 765\n",
      "##########################################################\n",
      "Epoch 35/40\n",
      "loss: 2.394115686416626 - metric: 0.37676000595092773 - val_loss: 2.412736177444458 - val_metric: 0.376 - penalty: 0.0\n",
      "hidden layer sizes: [3, 35, 63, 62, 64, 100, 170, 268], total units: 765\n",
      "##########################################################\n",
      "Epoch 36/40\n",
      "loss: 2.3706796169281006 - metric: 0.3799799978733063 - val_loss: 2.539755344390869 - val_metric: 0.3571 - penalty: 0.0\n",
      "hidden layer sizes: [3, 35, 63, 62, 64, 100, 170, 268], total units: 765\n",
      "##########################################################\n",
      "Epoch 37/40\n",
      "loss: 2.3632805347442627 - metric: 0.3831399977207184 - val_loss: 2.5635626316070557 - val_metric: 0.3562 - penalty: 0.0\n",
      "hidden layer sizes: [3, 35, 63, 62, 64, 100, 170, 268], total units: 765\n",
      "##########################################################\n",
      "Epoch 38/40\n",
      "loss: 2.342867374420166 - metric: 0.38947999477386475 - val_loss: 2.4153385162353516 - val_metric: 0.3751 - penalty: 0.0\n",
      "hidden layer sizes: [3, 35, 63, 62, 64, 100, 170, 268], total units: 765\n",
      "##########################################################\n",
      "Epoch 39/40\n",
      "loss: 2.3285250663757324 - metric: 0.3913399875164032 - val_loss: 2.4656240940093994 - val_metric: 0.372 - penalty: 0.0\n",
      "hidden layer sizes: [3, 35, 63, 62, 64, 100, 170, 268], total units: 765\n",
      "##########################################################\n",
      "Epoch 40/40\n",
      "loss: 2.317141532897949 - metric: 0.390720009803772 - val_loss: 2.561814785003662 - val_metric: 0.3532 - penalty: 0.0\n",
      "hidden layer sizes: [3, 35, 63, 62, 64, 100, 170, 268], total units: 765\n",
      "CPU times: user 4min 55s, sys: 9.59 s, total: 5min 5s\n",
      "Wall time: 4min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [5.139209270477295,\n",
       "  4.282550811767578,\n",
       "  4.098367691040039,\n",
       "  3.9473702907562256,\n",
       "  3.817727565765381,\n",
       "  3.713214635848999,\n",
       "  3.63161039352417,\n",
       "  3.573876142501831,\n",
       "  3.515458106994629,\n",
       "  3.462778091430664,\n",
       "  3.4102041721343994,\n",
       "  3.368546485900879,\n",
       "  3.330777168273926,\n",
       "  3.304774761199951,\n",
       "  3.272791862487793,\n",
       "  3.253862142562866,\n",
       "  3.2242653369903564,\n",
       "  3.2118144035339355,\n",
       "  3.1950929164886475,\n",
       "  3.170907735824585,\n",
       "  3.0061044692993164,\n",
       "  2.8003909587860107,\n",
       "  2.728278160095215,\n",
       "  2.673301935195923,\n",
       "  2.626842737197876,\n",
       "  2.5961828231811523,\n",
       "  2.5646309852600098,\n",
       "  2.536334753036499,\n",
       "  2.510082244873047,\n",
       "  2.4837191104888916,\n",
       "  2.4619791507720947,\n",
       "  2.4447641372680664,\n",
       "  2.420140027999878,\n",
       "  2.399810314178467,\n",
       "  2.394115686416626,\n",
       "  2.3706796169281006,\n",
       "  2.3632805347442627,\n",
       "  2.342867374420166,\n",
       "  2.3285250663757324,\n",
       "  2.317141532897949],\n",
       " 'metric': [0.025259999558329582,\n",
       "  0.07541999965906143,\n",
       "  0.08767999708652496,\n",
       "  0.09904000163078308,\n",
       "  0.11271999776363373,\n",
       "  0.12544000148773193,\n",
       "  0.13592000305652618,\n",
       "  0.14441999793052673,\n",
       "  0.15272000432014465,\n",
       "  0.16166000068187714,\n",
       "  0.1695999950170517,\n",
       "  0.17292000353336334,\n",
       "  0.18211999535560608,\n",
       "  0.18821999430656433,\n",
       "  0.1942799985408783,\n",
       "  0.19660000503063202,\n",
       "  0.2018599957227707,\n",
       "  0.2041199952363968,\n",
       "  0.2078000009059906,\n",
       "  0.2132200002670288,\n",
       "  0.24879999458789825,\n",
       "  0.28891998529434204,\n",
       "  0.3056800067424774,\n",
       "  0.31679999828338623,\n",
       "  0.326119989156723,\n",
       "  0.3334999978542328,\n",
       "  0.3396199941635132,\n",
       "  0.3440200090408325,\n",
       "  0.3499000072479248,\n",
       "  0.3580000102519989,\n",
       "  0.3596999943256378,\n",
       "  0.36528000235557556,\n",
       "  0.36970001459121704,\n",
       "  0.375900000333786,\n",
       "  0.37676000595092773,\n",
       "  0.3799799978733063,\n",
       "  0.3831399977207184,\n",
       "  0.38947999477386475,\n",
       "  0.3913399875164032,\n",
       "  0.390720009803772],\n",
       " 'val_loss': [4.193662643432617,\n",
       "  4.424328327178955,\n",
       "  4.2489237785339355,\n",
       "  4.1110968589782715,\n",
       "  3.8588175773620605,\n",
       "  3.7918214797973633,\n",
       "  3.725651979446411,\n",
       "  3.675023078918457,\n",
       "  3.466456174850464,\n",
       "  3.4828686714172363,\n",
       "  3.4259836673736572,\n",
       "  3.3794753551483154,\n",
       "  3.2944722175598145,\n",
       "  3.368662118911743,\n",
       "  3.349904775619507,\n",
       "  3.2473130226135254,\n",
       "  3.3555819988250732,\n",
       "  3.512687921524048,\n",
       "  3.106849431991577,\n",
       "  3.142089366912842,\n",
       "  3.197854518890381,\n",
       "  2.7522058486938477,\n",
       "  2.9944076538085938,\n",
       "  2.6643946170806885,\n",
       "  2.7350075244903564,\n",
       "  2.668752908706665,\n",
       "  2.6115148067474365,\n",
       "  2.6853842735290527,\n",
       "  2.542630195617676,\n",
       "  2.580733299255371,\n",
       "  2.540576696395874,\n",
       "  2.5335590839385986,\n",
       "  2.496124505996704,\n",
       "  2.3894577026367188,\n",
       "  2.412736177444458,\n",
       "  2.539755344390869,\n",
       "  2.5635626316070557,\n",
       "  2.4153385162353516,\n",
       "  2.4656240940093994,\n",
       "  2.561814785003662],\n",
       " 'val_metric': [0.0831,\n",
       "  0.0373,\n",
       "  0.0461,\n",
       "  0.0663,\n",
       "  0.1036,\n",
       "  0.117,\n",
       "  0.1275,\n",
       "  0.1428,\n",
       "  0.1861,\n",
       "  0.1769,\n",
       "  0.1782,\n",
       "  0.2012,\n",
       "  0.2026,\n",
       "  0.1996,\n",
       "  0.1913,\n",
       "  0.206,\n",
       "  0.1898,\n",
       "  0.1729,\n",
       "  0.2392,\n",
       "  0.2365,\n",
       "  0.2461,\n",
       "  0.3085,\n",
       "  0.2797,\n",
       "  0.323,\n",
       "  0.3163,\n",
       "  0.3294,\n",
       "  0.3405,\n",
       "  0.3208,\n",
       "  0.3445,\n",
       "  0.3472,\n",
       "  0.3555,\n",
       "  0.3586,\n",
       "  0.3647,\n",
       "  0.3799,\n",
       "  0.376,\n",
       "  0.3571,\n",
       "  0.3562,\n",
       "  0.3751,\n",
       "  0.372,\n",
       "  0.3532],\n",
       " 'hidden_layer_sizes': [[3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 105, 341, 341],\n",
       "  [3, 32, 88, 113, 120, 125, 279, 341],\n",
       "  [3, 32, 86, 94, 99, 123, 227, 341],\n",
       "  [3, 37, 85, 82, 79, 111, 220, 341],\n",
       "  [3, 36, 84, 78, 83, 118, 212, 341],\n",
       "  [3, 32, 83, 72, 81, 118, 217, 341],\n",
       "  [3, 36, 81, 74, 77, 109, 218, 341],\n",
       "  [3, 32, 82, 68, 85, 107, 205, 340],\n",
       "  [3, 36, 80, 68, 79, 111, 200, 337],\n",
       "  [3, 33, 76, 59, 72, 110, 191, 332],\n",
       "  [3, 33, 75, 62, 71, 101, 195, 330],\n",
       "  [3, 37, 70, 60, 67, 104, 177, 326],\n",
       "  [3, 35, 69, 60, 63, 89, 183, 318],\n",
       "  [3, 39, 68, 65, 72, 107, 181, 307],\n",
       "  [3, 38, 67, 60, 67, 94, 175, 297],\n",
       "  [3, 33, 65, 60, 56, 95, 172, 283],\n",
       "  [3, 33, 66, 69, 72, 108, 168, 278],\n",
       "  [3, 38, 64, 59, 64, 99, 178, 270],\n",
       "  [3, 35, 63, 62, 64, 100, 170, 268],\n",
       "  [3, 35, 63, 62, 64, 100, 170, 268],\n",
       "  [3, 35, 63, 62, 64, 100, 170, 268],\n",
       "  [3, 35, 63, 62, 64, 100, 170, 268],\n",
       "  [3, 35, 63, 62, 64, 100, 170, 268],\n",
       "  [3, 35, 63, 62, 64, 100, 170, 268],\n",
       "  [3, 35, 63, 62, 64, 100, 170, 268],\n",
       "  [3, 35, 63, 62, 64, 100, 170, 268],\n",
       "  [3, 35, 63, 62, 64, 100, 170, 268],\n",
       "  [3, 35, 63, 62, 64, 100, 170, 268],\n",
       "  [3, 35, 63, 62, 64, 100, 170, 268],\n",
       "  [3, 35, 63, 62, 64, 100, 170, 268],\n",
       "  [3, 35, 63, 62, 64, 100, 170, 268],\n",
       "  [3, 35, 63, 62, 64, 100, 170, 268],\n",
       "  [3, 35, 63, 62, 64, 100, 170, 268],\n",
       "  [3, 35, 63, 62, 64, 100, 170, 268],\n",
       "  [3, 35, 63, 62, 64, 100, 170, 268],\n",
       "  [3, 35, 63, 62, 64, 100, 170, 268],\n",
       "  [3, 35, 63, 62, 64, 100, 170, 268],\n",
       "  [3, 35, 63, 62, 64, 100, 170, 268],\n",
       "  [3, 35, 63, 62, 64, 100, 170, 268]]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "schedule = [DynamicEpoch(0.00013, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20\n",
    "train_fn_conv(x=cifar100.X_train_norm, y=cifar100.y_train, \n",
    "              validation_data=(cifar100.X_test_norm, cifar100.y_test), learning_rate=0.0001, \n",
    "              schedule=schedule, layer_sizes=layer_sizes, output_neurons=100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "828c6156-05a7-4fb6-a31f-544419370aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################################\n",
      "Epoch 1/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 5.232725620269775 - val_metric: 0.0092 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 5.232727527618408 - val_metric: 0.0092 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 52, 105, 153, 153, 105, 409, 409], total units: 1389\n",
      "Before pruning:\n",
      "loss: 4.74235200881958 - metric: 0.045239999890327454 - val_loss: 4.390292644500732 - val_metric: 0.0529 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 52, 105, 153, 153, 105, 409, 409], total units: 1389\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.390239715576172 - val_metric: 0.0529 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 105, 341, 341], total units: 1163\n",
      "##########################################################\n",
      "Epoch 2/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.390239715576172 - val_metric: 0.0529 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 105, 341, 341], total units: 1163\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.390241622924805 - val_metric: 0.0529 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 52, 105, 153, 153, 126, 409, 409], total units: 1410\n",
      "Before pruning:\n",
      "loss: 4.24387788772583 - metric: 0.07344000041484833 - val_loss: 4.358275890350342 - val_metric: 0.0415 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 52, 105, 153, 153, 126, 409, 409], total units: 1410\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.361303329467773 - val_metric: 0.0388 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 40, 99, 125, 116, 125, 318, 341], total units: 1167\n",
      "##########################################################\n",
      "Epoch 3/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.361303329467773 - val_metric: 0.0388 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 40, 99, 125, 116, 125, 318, 341], total units: 1167\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.36132287979126 - val_metric: 0.0388 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 60, 119, 150, 139, 150, 381, 409], total units: 1411\n",
      "Before pruning:\n",
      "loss: 4.0667314529418945 - metric: 0.08489999920129776 - val_loss: 4.056520938873291 - val_metric: 0.0836 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 60, 119, 150, 139, 150, 381, 409], total units: 1411\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.040457248687744 - val_metric: 0.0844 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 40, 96, 102, 106, 143, 306, 341], total units: 1137\n",
      "##########################################################\n",
      "Epoch 4/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.040457248687744 - val_metric: 0.0844 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 40, 96, 102, 106, 143, 306, 341], total units: 1137\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.040472507476807 - val_metric: 0.0844 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 60, 116, 122, 127, 171, 367, 409], total units: 1375\n",
      "Before pruning:\n",
      "loss: 3.9167752265930176 - metric: 0.09864000231027603 - val_loss: 3.94783878326416 - val_metric: 0.0903 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 60, 116, 122, 127, 171, 367, 409], total units: 1375\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.951563596725464 - val_metric: 0.091 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 46, 99, 101, 108, 156, 272, 342], total units: 1127\n",
      "##########################################################\n",
      "Epoch 5/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.951563596725464 - val_metric: 0.091 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 46, 99, 101, 108, 156, 272, 342], total units: 1127\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.9515645503997803 - val_metric: 0.091 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 66, 119, 121, 129, 187, 326, 410], total units: 1361\n",
      "Before pruning:\n",
      "loss: 3.800334930419922 - metric: 0.10911999642848969 - val_loss: 3.6820762157440186 - val_metric: 0.1319 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 66, 119, 121, 129, 187, 326, 410], total units: 1361\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.6819121837615967 - val_metric: 0.1344 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 38, 92, 99, 110, 153, 279, 343], total units: 1117\n",
      "##########################################################\n",
      "Epoch 6/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.6819121837615967 - val_metric: 0.1344 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 38, 92, 99, 110, 153, 279, 343], total units: 1117\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.681915521621704 - val_metric: 0.1345 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 58, 112, 119, 132, 183, 334, 411], total units: 1352\n",
      "Before pruning:\n",
      "loss: 3.717158555984497 - metric: 0.12139999866485596 - val_loss: 3.674626111984253 - val_metric: 0.1569 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 58, 112, 119, 132, 183, 334, 411], total units: 1352\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.683936834335327 - val_metric: 0.1549 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 37, 89, 94, 103, 147, 253, 349], total units: 1075\n",
      "##########################################################\n",
      "Epoch 7/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.683936834335327 - val_metric: 0.1549 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 37, 89, 94, 103, 147, 253, 349], total units: 1075\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.6839375495910645 - val_metric: 0.1548 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 57, 109, 114, 123, 176, 303, 418], total units: 1303\n",
      "Before pruning:\n",
      "loss: 3.64562726020813 - metric: 0.1306000053882599 - val_loss: 3.577791452407837 - val_metric: 0.1478 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 57, 109, 114, 123, 176, 303, 418], total units: 1303\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.5994293689727783 - val_metric: 0.1463 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 40, 95, 100, 105, 148, 260, 351], total units: 1102\n",
      "##########################################################\n",
      "Epoch 8/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.5994293689727783 - val_metric: 0.1463 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 40, 95, 100, 105, 148, 260, 351], total units: 1102\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.599374294281006 - val_metric: 0.1464 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 60, 115, 120, 126, 177, 312, 421], total units: 1334\n",
      "Before pruning:\n",
      "loss: 3.6040778160095215 - metric: 0.13752000033855438 - val_loss: 3.6129684448242188 - val_metric: 0.1506 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 60, 115, 120, 126, 177, 312, 421], total units: 1334\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.6299526691436768 - val_metric: 0.15 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 46, 98, 98, 100, 146, 251, 347], total units: 1089\n",
      "##########################################################\n",
      "Epoch 9/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.6299526691436768 - val_metric: 0.15 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 46, 98, 98, 100, 146, 251, 347], total units: 1089\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.629955530166626 - val_metric: 0.15 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 66, 118, 118, 120, 175, 301, 416], total units: 1317\n",
      "Before pruning:\n",
      "loss: 3.562211036682129 - metric: 0.14229999482631683 - val_loss: 3.438857316970825 - val_metric: 0.1871 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 66, 118, 118, 120, 175, 301, 416], total units: 1317\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.4566996097564697 - val_metric: 0.1824 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 40, 86, 101, 90, 142, 231, 352], total units: 1045\n",
      "##########################################################\n",
      "Epoch 10/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.4566996097564697 - val_metric: 0.1824 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 40, 86, 101, 90, 142, 231, 352], total units: 1045\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.456664562225342 - val_metric: 0.1824 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 60, 106, 121, 110, 170, 277, 422], total units: 1269\n",
      "Before pruning:\n",
      "loss: 3.51827335357666 - metric: 0.14961999654769897 - val_loss: 3.528308629989624 - val_metric: 0.1594 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 60, 106, 121, 110, 170, 277, 422], total units: 1269\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.5314695835113525 - val_metric: 0.1586 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 40, 85, 102, 102, 157, 255, 348], total units: 1092\n",
      "##########################################################\n",
      "Epoch 11/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.5314695835113525 - val_metric: 0.1586 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 40, 85, 102, 102, 157, 255, 348], total units: 1092\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.531554698944092 - val_metric: 0.1586 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 60, 105, 122, 122, 188, 306, 417], total units: 1323\n",
      "Before pruning:\n",
      "loss: 3.5115718841552734 - metric: 0.15306000411510468 - val_loss: 3.455780506134033 - val_metric: 0.1833 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 60, 105, 122, 122, 188, 306, 417], total units: 1323\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.4809088706970215 - val_metric: 0.1764 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 47, 90, 96, 104, 142, 226, 347], total units: 1055\n",
      "##########################################################\n",
      "Epoch 12/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.4809088706970215 - val_metric: 0.1764 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 47, 90, 96, 104, 142, 226, 347], total units: 1055\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.480912923812866 - val_metric: 0.1764 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 67, 110, 116, 124, 170, 271, 416], total units: 1277\n",
      "Before pruning:\n",
      "loss: 3.477377414703369 - metric: 0.1565999984741211 - val_loss: 3.3728368282318115 - val_metric: 0.1916 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 67, 110, 116, 124, 170, 271, 416], total units: 1277\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.388599157333374 - val_metric: 0.188 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 39, 82, 82, 107, 144, 235, 337], total units: 1029\n",
      "##########################################################\n",
      "Epoch 13/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.388599157333374 - val_metric: 0.188 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 39, 82, 82, 107, 144, 235, 337], total units: 1029\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.3885984420776367 - val_metric: 0.1881 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 59, 102, 102, 128, 172, 282, 404], total units: 1252\n",
      "Before pruning:\n",
      "loss: 3.4543650150299072 - metric: 0.16096000373363495 - val_loss: 3.420041084289551 - val_metric: 0.1866 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 59, 102, 102, 128, 172, 282, 404], total units: 1252\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.4048635959625244 - val_metric: 0.1912 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 41, 93, 94, 115, 154, 227, 334], total units: 1061\n",
      "##########################################################\n",
      "Epoch 14/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.4048635959625244 - val_metric: 0.1912 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 41, 93, 94, 115, 154, 227, 334], total units: 1061\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.4048707485198975 - val_metric: 0.1913 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 61, 113, 114, 138, 184, 272, 400], total units: 1285\n",
      "Before pruning:\n",
      "loss: 3.436922073364258 - metric: 0.16434000432491302 - val_loss: 3.311605930328369 - val_metric: 0.2017 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 61, 113, 114, 138, 184, 272, 400], total units: 1285\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.345127820968628 - val_metric: 0.1949 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 43, 95, 99, 99, 121, 234, 344], total units: 1038\n",
      "##########################################################\n",
      "Epoch 15/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.345127820968628 - val_metric: 0.1949 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 43, 95, 99, 99, 121, 234, 344], total units: 1038\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.3451290130615234 - val_metric: 0.1949 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 63, 115, 119, 119, 145, 280, 412], total units: 1256\n",
      "Before pruning:\n",
      "loss: 3.409853458404541 - metric: 0.1706800013780594 - val_loss: 3.249103546142578 - val_metric: 0.2165 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 63, 115, 119, 119, 145, 280, 412], total units: 1256\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.2678215503692627 - val_metric: 0.2136 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 39, 84, 77, 88, 137, 251, 337], total units: 1016\n",
      "##########################################################\n",
      "Epoch 16/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.2678215503692627 - val_metric: 0.2136 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 39, 84, 77, 88, 137, 251, 337], total units: 1016\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.2678205966949463 - val_metric: 0.2136 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 59, 104, 97, 108, 164, 301, 404], total units: 1240\n",
      "Before pruning:\n",
      "loss: 3.383993148803711 - metric: 0.17057999968528748 - val_loss: 3.2975475788116455 - val_metric: 0.1941 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 59, 104, 97, 108, 164, 301, 404], total units: 1240\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.306558609008789 - val_metric: 0.1915 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 42, 87, 74, 93, 144, 237, 336], total units: 1016\n",
      "##########################################################\n",
      "Epoch 17/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.306558609008789 - val_metric: 0.1915 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 42, 87, 74, 93, 144, 237, 336], total units: 1016\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.3065593242645264 - val_metric: 0.1916 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 62, 107, 94, 113, 172, 284, 403], total units: 1238\n",
      "Before pruning:\n",
      "loss: 3.3652732372283936 - metric: 0.17613999545574188 - val_loss: 3.306046962738037 - val_metric: 0.2038 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 62, 107, 94, 113, 172, 284, 403], total units: 1238\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.3104679584503174 - val_metric: 0.2012 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 48, 85, 90, 102, 146, 235, 336], total units: 1045\n",
      "##########################################################\n",
      "Epoch 18/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.3104679584503174 - val_metric: 0.2012 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 48, 85, 90, 102, 146, 235, 336], total units: 1045\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.3106203079223633 - val_metric: 0.2012 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 68, 105, 110, 122, 175, 282, 403], total units: 1268\n",
      "Before pruning:\n",
      "loss: 3.3545265197753906 - metric: 0.17671999335289001 - val_loss: 3.2481095790863037 - val_metric: 0.2087 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 68, 105, 110, 122, 175, 282, 403], total units: 1268\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.2486956119537354 - val_metric: 0.2095 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 43, 88, 92, 99, 155, 246, 337], total units: 1063\n",
      "##########################################################\n",
      "Epoch 19/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.2486956119537354 - val_metric: 0.2095 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 43, 88, 92, 99, 155, 246, 337], total units: 1063\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.248694658279419 - val_metric: 0.2095 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 63, 108, 112, 119, 186, 295, 404], total units: 1290\n",
      "Before pruning:\n",
      "loss: 3.331529378890991 - metric: 0.18046000599861145 - val_loss: 3.3129003047943115 - val_metric: 0.1845 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 63, 108, 112, 119, 186, 295, 404], total units: 1290\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.3076436519622803 - val_metric: 0.1856 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 40, 89, 90, 104, 142, 247, 340], total units: 1055\n",
      "##########################################################\n",
      "Epoch 20/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.3076436519622803 - val_metric: 0.1856 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 40, 89, 90, 104, 142, 247, 340], total units: 1055\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.3075473308563232 - val_metric: 0.1856 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 60, 109, 110, 124, 170, 296, 408], total units: 1280\n",
      "Before pruning:\n",
      "loss: 3.326726198196411 - metric: 0.18343999981880188 - val_loss: 3.2771363258361816 - val_metric: 0.2013 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 60, 109, 110, 124, 170, 296, 408], total units: 1280\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.267207145690918 - val_metric: 0.202 - penalty: 0.00013\n",
      "hidden layer sizes: [3, 40, 92, 85, 91, 148, 243, 346], total units: 1048\n",
      "##########################################################\n",
      "Epoch 21/40\n",
      "loss: 3.109727382659912 - metric: 0.22154000401496887 - val_loss: 2.7101213932037354 - val_metric: 0.3088 - penalty: 0.0\n",
      "hidden layer sizes: [3, 40, 92, 85, 91, 148, 243, 346], total units: 1048\n",
      "##########################################################\n",
      "Epoch 22/40\n",
      "loss: 2.8160603046417236 - metric: 0.2845200002193451 - val_loss: 2.711970806121826 - val_metric: 0.3133 - penalty: 0.0\n",
      "hidden layer sizes: [3, 40, 92, 85, 91, 148, 243, 346], total units: 1048\n",
      "##########################################################\n",
      "Epoch 23/40\n",
      "loss: 2.6784749031066895 - metric: 0.3142400085926056 - val_loss: 2.773263454437256 - val_metric: 0.3138 - penalty: 0.0\n",
      "hidden layer sizes: [3, 40, 92, 85, 91, 148, 243, 346], total units: 1048\n",
      "##########################################################\n",
      "Epoch 24/40\n",
      "loss: 2.5852842330932617 - metric: 0.3325999975204468 - val_loss: 2.558119535446167 - val_metric: 0.3459 - penalty: 0.0\n",
      "hidden layer sizes: [3, 40, 92, 85, 91, 148, 243, 346], total units: 1048\n",
      "##########################################################\n",
      "Epoch 25/40\n",
      "loss: 2.5066444873809814 - metric: 0.3483999967575073 - val_loss: 2.439970016479492 - val_metric: 0.3724 - penalty: 0.0\n",
      "hidden layer sizes: [3, 40, 92, 85, 91, 148, 243, 346], total units: 1048\n",
      "##########################################################\n",
      "Epoch 26/40\n",
      "loss: 2.4502429962158203 - metric: 0.3628000020980835 - val_loss: 2.358698844909668 - val_metric: 0.3844 - penalty: 0.0\n",
      "hidden layer sizes: [3, 40, 92, 85, 91, 148, 243, 346], total units: 1048\n",
      "##########################################################\n",
      "Epoch 27/40\n",
      "loss: 2.3944365978240967 - metric: 0.37136000394821167 - val_loss: 2.3877251148223877 - val_metric: 0.3767 - penalty: 0.0\n",
      "hidden layer sizes: [3, 40, 92, 85, 91, 148, 243, 346], total units: 1048\n",
      "##########################################################\n",
      "Epoch 28/40\n",
      "loss: 2.34725022315979 - metric: 0.38486000895500183 - val_loss: 2.2567896842956543 - val_metric: 0.4138 - penalty: 0.0\n",
      "hidden layer sizes: [3, 40, 92, 85, 91, 148, 243, 346], total units: 1048\n",
      "##########################################################\n",
      "Epoch 29/40\n",
      "loss: 2.303640604019165 - metric: 0.39267998933792114 - val_loss: 2.3837108612060547 - val_metric: 0.3833 - penalty: 0.0\n",
      "hidden layer sizes: [3, 40, 92, 85, 91, 148, 243, 346], total units: 1048\n",
      "##########################################################\n",
      "Epoch 30/40\n",
      "loss: 2.2646522521972656 - metric: 0.4004400074481964 - val_loss: 2.2290029525756836 - val_metric: 0.4136 - penalty: 0.0\n",
      "hidden layer sizes: [3, 40, 92, 85, 91, 148, 243, 346], total units: 1048\n",
      "##########################################################\n",
      "Epoch 31/40\n",
      "loss: 2.223236560821533 - metric: 0.4071800112724304 - val_loss: 2.2097606658935547 - val_metric: 0.4135 - penalty: 0.0\n",
      "hidden layer sizes: [3, 40, 92, 85, 91, 148, 243, 346], total units: 1048\n",
      "##########################################################\n",
      "Epoch 32/40\n",
      "loss: 2.1964001655578613 - metric: 0.41760000586509705 - val_loss: 2.169727325439453 - val_metric: 0.4232 - penalty: 0.0\n",
      "hidden layer sizes: [3, 40, 92, 85, 91, 148, 243, 346], total units: 1048\n",
      "##########################################################\n",
      "Epoch 33/40\n",
      "loss: 2.1616852283477783 - metric: 0.4208599925041199 - val_loss: 2.1485908031463623 - val_metric: 0.4348 - penalty: 0.0\n",
      "hidden layer sizes: [3, 40, 92, 85, 91, 148, 243, 346], total units: 1048\n",
      "##########################################################\n",
      "Epoch 34/40\n",
      "loss: 2.130854606628418 - metric: 0.4307999908924103 - val_loss: 2.1822550296783447 - val_metric: 0.4256 - penalty: 0.0\n",
      "hidden layer sizes: [3, 40, 92, 85, 91, 148, 243, 346], total units: 1048\n",
      "##########################################################\n",
      "Epoch 35/40\n",
      "loss: 2.1043553352355957 - metric: 0.43630000948905945 - val_loss: 2.114947557449341 - val_metric: 0.4412 - penalty: 0.0\n",
      "hidden layer sizes: [3, 40, 92, 85, 91, 148, 243, 346], total units: 1048\n",
      "##########################################################\n",
      "Epoch 36/40\n",
      "loss: 2.07726788520813 - metric: 0.44161999225616455 - val_loss: 2.111579656600952 - val_metric: 0.4409 - penalty: 0.0\n",
      "hidden layer sizes: [3, 40, 92, 85, 91, 148, 243, 346], total units: 1048\n",
      "##########################################################\n",
      "Epoch 37/40\n",
      "loss: 2.045959949493408 - metric: 0.44764000177383423 - val_loss: 2.077411413192749 - val_metric: 0.4541 - penalty: 0.0\n",
      "hidden layer sizes: [3, 40, 92, 85, 91, 148, 243, 346], total units: 1048\n",
      "##########################################################\n",
      "Epoch 38/40\n",
      "loss: 2.0376808643341064 - metric: 0.45194000005722046 - val_loss: 2.1323673725128174 - val_metric: 0.4444 - penalty: 0.0\n",
      "hidden layer sizes: [3, 40, 92, 85, 91, 148, 243, 346], total units: 1048\n",
      "##########################################################\n",
      "Epoch 39/40\n",
      "loss: 2.0037434101104736 - metric: 0.4554400146007538 - val_loss: 2.036879062652588 - val_metric: 0.4624 - penalty: 0.0\n",
      "hidden layer sizes: [3, 40, 92, 85, 91, 148, 243, 346], total units: 1048\n",
      "##########################################################\n",
      "Epoch 40/40\n",
      "loss: 1.9790903329849243 - metric: 0.46540001034736633 - val_loss: 2.016235828399658 - val_metric: 0.4706 - penalty: 0.0\n",
      "hidden layer sizes: [3, 40, 92, 85, 91, 148, 243, 346], total units: 1048\n",
      "CPU times: user 4min 56s, sys: 8.81 s, total: 5min 5s\n",
      "Wall time: 4min 36s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [4.74235200881958,\n",
       "  4.24387788772583,\n",
       "  4.0667314529418945,\n",
       "  3.9167752265930176,\n",
       "  3.800334930419922,\n",
       "  3.717158555984497,\n",
       "  3.64562726020813,\n",
       "  3.6040778160095215,\n",
       "  3.562211036682129,\n",
       "  3.51827335357666,\n",
       "  3.5115718841552734,\n",
       "  3.477377414703369,\n",
       "  3.4543650150299072,\n",
       "  3.436922073364258,\n",
       "  3.409853458404541,\n",
       "  3.383993148803711,\n",
       "  3.3652732372283936,\n",
       "  3.3545265197753906,\n",
       "  3.331529378890991,\n",
       "  3.326726198196411,\n",
       "  3.109727382659912,\n",
       "  2.8160603046417236,\n",
       "  2.6784749031066895,\n",
       "  2.5852842330932617,\n",
       "  2.5066444873809814,\n",
       "  2.4502429962158203,\n",
       "  2.3944365978240967,\n",
       "  2.34725022315979,\n",
       "  2.303640604019165,\n",
       "  2.2646522521972656,\n",
       "  2.223236560821533,\n",
       "  2.1964001655578613,\n",
       "  2.1616852283477783,\n",
       "  2.130854606628418,\n",
       "  2.1043553352355957,\n",
       "  2.07726788520813,\n",
       "  2.045959949493408,\n",
       "  2.0376808643341064,\n",
       "  2.0037434101104736,\n",
       "  1.9790903329849243],\n",
       " 'metric': [0.045239999890327454,\n",
       "  0.07344000041484833,\n",
       "  0.08489999920129776,\n",
       "  0.09864000231027603,\n",
       "  0.10911999642848969,\n",
       "  0.12139999866485596,\n",
       "  0.1306000053882599,\n",
       "  0.13752000033855438,\n",
       "  0.14229999482631683,\n",
       "  0.14961999654769897,\n",
       "  0.15306000411510468,\n",
       "  0.1565999984741211,\n",
       "  0.16096000373363495,\n",
       "  0.16434000432491302,\n",
       "  0.1706800013780594,\n",
       "  0.17057999968528748,\n",
       "  0.17613999545574188,\n",
       "  0.17671999335289001,\n",
       "  0.18046000599861145,\n",
       "  0.18343999981880188,\n",
       "  0.22154000401496887,\n",
       "  0.2845200002193451,\n",
       "  0.3142400085926056,\n",
       "  0.3325999975204468,\n",
       "  0.3483999967575073,\n",
       "  0.3628000020980835,\n",
       "  0.37136000394821167,\n",
       "  0.38486000895500183,\n",
       "  0.39267998933792114,\n",
       "  0.4004400074481964,\n",
       "  0.4071800112724304,\n",
       "  0.41760000586509705,\n",
       "  0.4208599925041199,\n",
       "  0.4307999908924103,\n",
       "  0.43630000948905945,\n",
       "  0.44161999225616455,\n",
       "  0.44764000177383423,\n",
       "  0.45194000005722046,\n",
       "  0.4554400146007538,\n",
       "  0.46540001034736633],\n",
       " 'val_loss': [4.390239715576172,\n",
       "  4.361303329467773,\n",
       "  4.040457248687744,\n",
       "  3.951563596725464,\n",
       "  3.6819121837615967,\n",
       "  3.683936834335327,\n",
       "  3.5994293689727783,\n",
       "  3.6299526691436768,\n",
       "  3.4566996097564697,\n",
       "  3.5314695835113525,\n",
       "  3.4809088706970215,\n",
       "  3.388599157333374,\n",
       "  3.4048635959625244,\n",
       "  3.345127820968628,\n",
       "  3.2678215503692627,\n",
       "  3.306558609008789,\n",
       "  3.3104679584503174,\n",
       "  3.2486956119537354,\n",
       "  3.3076436519622803,\n",
       "  3.267207145690918,\n",
       "  2.7101213932037354,\n",
       "  2.711970806121826,\n",
       "  2.773263454437256,\n",
       "  2.558119535446167,\n",
       "  2.439970016479492,\n",
       "  2.358698844909668,\n",
       "  2.3877251148223877,\n",
       "  2.2567896842956543,\n",
       "  2.3837108612060547,\n",
       "  2.2290029525756836,\n",
       "  2.2097606658935547,\n",
       "  2.169727325439453,\n",
       "  2.1485908031463623,\n",
       "  2.1822550296783447,\n",
       "  2.114947557449341,\n",
       "  2.111579656600952,\n",
       "  2.077411413192749,\n",
       "  2.1323673725128174,\n",
       "  2.036879062652588,\n",
       "  2.016235828399658],\n",
       " 'val_metric': [0.0529,\n",
       "  0.0388,\n",
       "  0.0844,\n",
       "  0.091,\n",
       "  0.1344,\n",
       "  0.1549,\n",
       "  0.1463,\n",
       "  0.15,\n",
       "  0.1824,\n",
       "  0.1586,\n",
       "  0.1764,\n",
       "  0.188,\n",
       "  0.1912,\n",
       "  0.1949,\n",
       "  0.2136,\n",
       "  0.1915,\n",
       "  0.2012,\n",
       "  0.2095,\n",
       "  0.1856,\n",
       "  0.202,\n",
       "  0.3088,\n",
       "  0.3133,\n",
       "  0.3138,\n",
       "  0.3459,\n",
       "  0.3724,\n",
       "  0.3844,\n",
       "  0.3767,\n",
       "  0.4138,\n",
       "  0.3833,\n",
       "  0.4136,\n",
       "  0.4135,\n",
       "  0.4232,\n",
       "  0.4348,\n",
       "  0.4256,\n",
       "  0.4412,\n",
       "  0.4409,\n",
       "  0.4541,\n",
       "  0.4444,\n",
       "  0.4624,\n",
       "  0.4706],\n",
       " 'hidden_layer_sizes': [[3, 32, 85, 128, 128, 105, 341, 341],\n",
       "  [3, 40, 99, 125, 116, 125, 318, 341],\n",
       "  [3, 40, 96, 102, 106, 143, 306, 341],\n",
       "  [3, 46, 99, 101, 108, 156, 272, 342],\n",
       "  [3, 38, 92, 99, 110, 153, 279, 343],\n",
       "  [3, 37, 89, 94, 103, 147, 253, 349],\n",
       "  [3, 40, 95, 100, 105, 148, 260, 351],\n",
       "  [3, 46, 98, 98, 100, 146, 251, 347],\n",
       "  [3, 40, 86, 101, 90, 142, 231, 352],\n",
       "  [3, 40, 85, 102, 102, 157, 255, 348],\n",
       "  [3, 47, 90, 96, 104, 142, 226, 347],\n",
       "  [3, 39, 82, 82, 107, 144, 235, 337],\n",
       "  [3, 41, 93, 94, 115, 154, 227, 334],\n",
       "  [3, 43, 95, 99, 99, 121, 234, 344],\n",
       "  [3, 39, 84, 77, 88, 137, 251, 337],\n",
       "  [3, 42, 87, 74, 93, 144, 237, 336],\n",
       "  [3, 48, 85, 90, 102, 146, 235, 336],\n",
       "  [3, 43, 88, 92, 99, 155, 246, 337],\n",
       "  [3, 40, 89, 90, 104, 142, 247, 340],\n",
       "  [3, 40, 92, 85, 91, 148, 243, 346],\n",
       "  [3, 40, 92, 85, 91, 148, 243, 346],\n",
       "  [3, 40, 92, 85, 91, 148, 243, 346],\n",
       "  [3, 40, 92, 85, 91, 148, 243, 346],\n",
       "  [3, 40, 92, 85, 91, 148, 243, 346],\n",
       "  [3, 40, 92, 85, 91, 148, 243, 346],\n",
       "  [3, 40, 92, 85, 91, 148, 243, 346],\n",
       "  [3, 40, 92, 85, 91, 148, 243, 346],\n",
       "  [3, 40, 92, 85, 91, 148, 243, 346],\n",
       "  [3, 40, 92, 85, 91, 148, 243, 346],\n",
       "  [3, 40, 92, 85, 91, 148, 243, 346],\n",
       "  [3, 40, 92, 85, 91, 148, 243, 346],\n",
       "  [3, 40, 92, 85, 91, 148, 243, 346],\n",
       "  [3, 40, 92, 85, 91, 148, 243, 346],\n",
       "  [3, 40, 92, 85, 91, 148, 243, 346],\n",
       "  [3, 40, 92, 85, 91, 148, 243, 346],\n",
       "  [3, 40, 92, 85, 91, 148, 243, 346],\n",
       "  [3, 40, 92, 85, 91, 148, 243, 346],\n",
       "  [3, 40, 92, 85, 91, 148, 243, 346],\n",
       "  [3, 40, 92, 85, 91, 148, 243, 346],\n",
       "  [3, 40, 92, 85, 91, 148, 243, 346]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "schedule = [DynamicEpoch(0.00013, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20\n",
    "train_fn_conv(x=cifar100.X_train_norm, y=cifar100.y_train, \n",
    "              validation_data=(cifar100.X_test_norm, cifar100.y_test), learning_rate=0.0002, \n",
    "              schedule=schedule, layer_sizes=layer_sizes, output_neurons=100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc5c2fa5-3b74-4004-a920-b5aed952476b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################################\n",
      "Epoch 1/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 5.174106121063232 - val_metric: 0.0104 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cahlivoj/.miniconda3/envs/dynamic-auto-sizing/lib/python3.9/site-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer LecunNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n",
      "/home/cahlivoj/.miniconda3/envs/dynamic-auto-sizing/lib/python3.9/site-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After growing:\n",
      "loss: None - metric: None - val_loss: 5.174106121063232 - val_metric: 0.0104 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 52, 105, 153, 153, 105, 409, 409], total units: 1389\n",
      "Before pruning:\n",
      "loss: 4.700596332550049 - metric: 0.0494999997317791 - val_loss: 4.379430294036865 - val_metric: 0.0465 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 52, 105, 153, 153, 105, 409, 409], total units: 1389\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.378565788269043 - val_metric: 0.0462 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 105, 341, 344], total units: 1166\n",
      "##########################################################\n",
      "Epoch 2/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.378565788269043 - val_metric: 0.0462 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 105, 341, 344], total units: 1166\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.378568172454834 - val_metric: 0.0462 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 52, 105, 153, 153, 126, 409, 412], total units: 1413\n",
      "Before pruning:\n",
      "loss: 4.190736770629883 - metric: 0.07620000094175339 - val_loss: 4.323456764221191 - val_metric: 0.0303 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 52, 105, 153, 153, 126, 409, 412], total units: 1413\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.318184852600098 - val_metric: 0.0305 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 46, 105, 140, 134, 126, 366, 342], total units: 1262\n",
      "##########################################################\n",
      "Epoch 3/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.318184852600098 - val_metric: 0.0305 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 46, 105, 140, 134, 126, 366, 342], total units: 1262\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.318185806274414 - val_metric: 0.0305 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 66, 126, 168, 160, 151, 439, 410], total units: 1523\n",
      "Before pruning:\n",
      "loss: 4.046806335449219 - metric: 0.08764000236988068 - val_loss: 4.267313480377197 - val_metric: 0.0453 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 66, 126, 168, 160, 151, 439, 410], total units: 1523\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.235678672790527 - val_metric: 0.0474 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 42, 110, 132, 120, 150, 353, 343], total units: 1253\n",
      "##########################################################\n",
      "Epoch 4/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.235678672790527 - val_metric: 0.0474 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 42, 110, 132, 120, 150, 353, 343], total units: 1253\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.235679626464844 - val_metric: 0.0474 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 62, 132, 158, 144, 180, 423, 411], total units: 1513\n",
      "Before pruning:\n",
      "loss: 3.8893206119537354 - metric: 0.10289999842643738 - val_loss: 4.061122417449951 - val_metric: 0.0782 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 62, 132, 158, 144, 180, 423, 411], total units: 1513\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 4.054266929626465 - val_metric: 0.0793 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 51, 117, 121, 120, 174, 326, 351], total units: 1263\n",
      "##########################################################\n",
      "Epoch 5/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 4.054266929626465 - val_metric: 0.0793 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 51, 117, 121, 120, 174, 326, 351], total units: 1263\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 4.054266929626465 - val_metric: 0.0793 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 71, 140, 145, 144, 208, 391, 421], total units: 1523\n",
      "Before pruning:\n",
      "loss: 3.788820266723633 - metric: 0.11011999845504761 - val_loss: 3.8637733459472656 - val_metric: 0.1019 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 71, 140, 145, 144, 208, 391, 421], total units: 1523\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.8797781467437744 - val_metric: 0.1025 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 56, 115, 114, 116, 170, 312, 357], total units: 1243\n",
      "##########################################################\n",
      "Epoch 6/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.8797781467437744 - val_metric: 0.1025 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 56, 115, 114, 116, 170, 312, 357], total units: 1243\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.8797147274017334 - val_metric: 0.1025 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 76, 138, 136, 139, 204, 374, 428], total units: 1498\n",
      "Before pruning:\n",
      "loss: 3.7025256156921387 - metric: 0.12272000312805176 - val_loss: 3.7874789237976074 - val_metric: 0.124 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 76, 138, 136, 139, 204, 374, 428], total units: 1498\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.7691733837127686 - val_metric: 0.1241 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 46, 124, 115, 112, 174, 294, 363], total units: 1231\n",
      "##########################################################\n",
      "Epoch 7/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.7691733837127686 - val_metric: 0.1241 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 46, 124, 115, 112, 174, 294, 363], total units: 1231\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.7691752910614014 - val_metric: 0.1241 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 66, 148, 138, 134, 208, 352, 435], total units: 1484\n",
      "Before pruning:\n",
      "loss: 3.63857102394104 - metric: 0.12814000248908997 - val_loss: 3.600607395172119 - val_metric: 0.1484 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 66, 148, 138, 134, 208, 352, 435], total units: 1484\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.6054890155792236 - val_metric: 0.1506 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 39, 117, 108, 116, 172, 281, 365], total units: 1201\n",
      "##########################################################\n",
      "Epoch 8/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.6054890155792236 - val_metric: 0.1506 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 39, 117, 108, 116, 172, 281, 365], total units: 1201\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.605490207672119 - val_metric: 0.1505 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 59, 140, 129, 139, 206, 337, 438], total units: 1451\n",
      "Before pruning:\n",
      "loss: 3.560093402862549 - metric: 0.13950000703334808 - val_loss: 3.465203046798706 - val_metric: 0.1727 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 59, 140, 129, 139, 206, 337, 438], total units: 1451\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.469273805618286 - val_metric: 0.1719 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 44, 115, 108, 119, 182, 286, 384], total units: 1241\n",
      "##########################################################\n",
      "Epoch 9/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.469273805618286 - val_metric: 0.1719 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 44, 115, 108, 119, 182, 286, 384], total units: 1241\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.469273805618286 - val_metric: 0.1719 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 64, 138, 129, 142, 218, 343, 460], total units: 1497\n",
      "Before pruning:\n",
      "loss: 3.5176446437835693 - metric: 0.14630000293254852 - val_loss: 3.507291316986084 - val_metric: 0.1587 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 64, 138, 129, 142, 218, 343, 460], total units: 1497\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.5130043029785156 - val_metric: 0.1582 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 43, 124, 116, 106, 158, 286, 391], total units: 1227\n",
      "##########################################################\n",
      "Epoch 10/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.5130043029785156 - val_metric: 0.1582 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 43, 124, 116, 106, 158, 286, 391], total units: 1227\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.513007402420044 - val_metric: 0.1582 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 63, 148, 139, 127, 189, 343, 469], total units: 1481\n",
      "Before pruning:\n",
      "loss: 3.487985372543335 - metric: 0.15022000670433044 - val_loss: 3.560701608657837 - val_metric: 0.15 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 63, 148, 139, 127, 189, 343, 469], total units: 1481\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.565579652786255 - val_metric: 0.1495 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 44, 107, 103, 109, 170, 286, 394], total units: 1216\n",
      "##########################################################\n",
      "Epoch 11/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.565579652786255 - val_metric: 0.1495 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 44, 107, 103, 109, 170, 286, 394], total units: 1216\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.5656027793884277 - val_metric: 0.1495 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 64, 128, 123, 130, 204, 343, 472], total units: 1467\n",
      "Before pruning:\n",
      "loss: 3.4485270977020264 - metric: 0.15907999873161316 - val_loss: 3.391671895980835 - val_metric: 0.1906 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 64, 128, 123, 130, 204, 343, 472], total units: 1467\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.393320322036743 - val_metric: 0.191 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 47, 118, 112, 111, 177, 287, 394], total units: 1249\n",
      "##########################################################\n",
      "Epoch 12/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.393320322036743 - val_metric: 0.191 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 47, 118, 112, 111, 177, 287, 394], total units: 1249\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.3933210372924805 - val_metric: 0.191 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 67, 141, 134, 133, 212, 344, 472], total units: 1506\n",
      "Before pruning:\n",
      "loss: 3.4192769527435303 - metric: 0.16184000670909882 - val_loss: 3.536792278289795 - val_metric: 0.154 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 67, 141, 134, 133, 212, 344, 472], total units: 1506\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.5545527935028076 - val_metric: 0.1518 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 43, 118, 99, 108, 151, 261, 407], total units: 1190\n",
      "##########################################################\n",
      "Epoch 13/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.5545527935028076 - val_metric: 0.1518 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 43, 118, 99, 108, 151, 261, 407], total units: 1190\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.554550886154175 - val_metric: 0.1518 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 63, 141, 119, 129, 181, 313, 488], total units: 1437\n",
      "Before pruning:\n",
      "loss: 3.3848111629486084 - metric: 0.17003999650478363 - val_loss: 3.254643440246582 - val_metric: 0.2079 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 63, 141, 119, 129, 181, 313, 488], total units: 1437\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.2731380462646484 - val_metric: 0.204 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 44, 114, 109, 105, 165, 272, 406], total units: 1218\n",
      "##########################################################\n",
      "Epoch 14/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.2731380462646484 - val_metric: 0.204 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 44, 114, 109, 105, 165, 272, 406], total units: 1218\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.2731640338897705 - val_metric: 0.2042 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 64, 136, 130, 126, 198, 326, 487], total units: 1470\n",
      "Before pruning:\n",
      "loss: 3.3725855350494385 - metric: 0.17046000063419342 - val_loss: 3.2217538356781006 - val_metric: 0.2209 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 64, 136, 130, 126, 198, 326, 487], total units: 1470\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.2275686264038086 - val_metric: 0.2211 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 44, 119, 112, 119, 159, 260, 406], total units: 1222\n",
      "##########################################################\n",
      "Epoch 15/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.2275686264038086 - val_metric: 0.2211 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 44, 119, 112, 119, 159, 260, 406], total units: 1222\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.2274606227874756 - val_metric: 0.2212 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 64, 142, 134, 142, 190, 312, 487], total units: 1474\n",
      "Before pruning:\n",
      "loss: 3.35589599609375 - metric: 0.1746399998664856 - val_loss: 3.1453890800476074 - val_metric: 0.2283 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 64, 142, 134, 142, 190, 312, 487], total units: 1474\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.1485514640808105 - val_metric: 0.2288 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 45, 117, 96, 118, 172, 279, 412], total units: 1242\n",
      "##########################################################\n",
      "Epoch 16/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.1485514640808105 - val_metric: 0.2288 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 45, 117, 96, 118, 172, 279, 412], total units: 1242\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.1485514640808105 - val_metric: 0.2288 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 65, 140, 116, 141, 206, 334, 494], total units: 1499\n",
      "Before pruning:\n",
      "loss: 3.3305022716522217 - metric: 0.17890000343322754 - val_loss: 3.2073514461517334 - val_metric: 0.216 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 65, 140, 116, 141, 206, 334, 494], total units: 1499\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.2007200717926025 - val_metric: 0.2184 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 46, 111, 108, 120, 169, 263, 419], total units: 1239\n",
      "##########################################################\n",
      "Epoch 17/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.2007200717926025 - val_metric: 0.2184 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 46, 111, 108, 120, 169, 263, 419], total units: 1239\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.200721263885498 - val_metric: 0.2184 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 66, 133, 129, 144, 202, 315, 502], total units: 1494\n",
      "Before pruning:\n",
      "loss: 3.3145127296447754 - metric: 0.18243999779224396 - val_loss: 3.0988354682922363 - val_metric: 0.2344 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 66, 133, 129, 144, 202, 315, 502], total units: 1494\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.1058380603790283 - val_metric: 0.2343 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 42, 116, 111, 116, 165, 275, 434], total units: 1262\n",
      "##########################################################\n",
      "Epoch 18/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.1058380603790283 - val_metric: 0.2343 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 42, 116, 111, 116, 165, 275, 434], total units: 1262\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.105844497680664 - val_metric: 0.2344 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 62, 139, 133, 139, 198, 330, 520], total units: 1524\n",
      "Before pruning:\n",
      "loss: 3.29801344871521 - metric: 0.1835000067949295 - val_loss: 3.1630172729492188 - val_metric: 0.2185 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 62, 139, 133, 139, 198, 330, 520], total units: 1524\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.1706225872039795 - val_metric: 0.218 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 46, 117, 97, 107, 154, 265, 421], total units: 1210\n",
      "##########################################################\n",
      "Epoch 19/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.1706225872039795 - val_metric: 0.218 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 46, 117, 97, 107, 154, 265, 421], total units: 1210\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.170623302459717 - val_metric: 0.2181 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 66, 140, 117, 128, 184, 318, 505], total units: 1461\n",
      "Before pruning:\n",
      "loss: 3.2780520915985107 - metric: 0.18651999533176422 - val_loss: 3.115279197692871 - val_metric: 0.2328 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 66, 140, 117, 128, 184, 318, 505], total units: 1461\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.121046543121338 - val_metric: 0.232 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 42, 109, 102, 100, 157, 271, 426], total units: 1210\n",
      "##########################################################\n",
      "Epoch 20/40\n",
      "Before growing:\n",
      "loss: None - metric: None - val_loss: 3.121046543121338 - val_metric: 0.232 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 42, 109, 102, 100, 157, 271, 426], total units: 1210\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "After growing:\n",
      "loss: None - metric: None - val_loss: 3.1210477352142334 - val_metric: 0.232 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 62, 130, 122, 120, 188, 325, 511], total units: 1461\n",
      "Before pruning:\n",
      "loss: 3.265876054763794 - metric: 0.18719999492168427 - val_loss: 3.2448465824127197 - val_metric: 0.2053 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 62, 130, 122, 120, 188, 325, 511], total units: 1461\n",
      "After pruning:\n",
      "loss: None - metric: None - val_loss: 3.2331273555755615 - val_metric: 0.2075 - penalty: 0.0001\n",
      "hidden layer sizes: [3, 45, 113, 115, 115, 172, 257, 414], total units: 1234\n",
      "##########################################################\n",
      "Epoch 21/40\n",
      "loss: 3.0825679302215576 - metric: 0.22533999383449554 - val_loss: 2.7905235290527344 - val_metric: 0.2888 - penalty: 0.0\n",
      "hidden layer sizes: [3, 45, 113, 115, 115, 172, 257, 414], total units: 1234\n",
      "##########################################################\n",
      "Epoch 22/40\n",
      "loss: 2.752199649810791 - metric: 0.29618000984191895 - val_loss: 2.678389549255371 - val_metric: 0.3187 - penalty: 0.0\n",
      "hidden layer sizes: [3, 45, 113, 115, 115, 172, 257, 414], total units: 1234\n",
      "##########################################################\n",
      "Epoch 23/40\n",
      "loss: 2.627910852432251 - metric: 0.32269999384880066 - val_loss: 2.554034471511841 - val_metric: 0.3389 - penalty: 0.0\n",
      "hidden layer sizes: [3, 45, 113, 115, 115, 172, 257, 414], total units: 1234\n",
      "##########################################################\n",
      "Epoch 24/40\n",
      "loss: 2.514864921569824 - metric: 0.34700000286102295 - val_loss: 2.4786925315856934 - val_metric: 0.3637 - penalty: 0.0\n",
      "hidden layer sizes: [3, 45, 113, 115, 115, 172, 257, 414], total units: 1234\n",
      "##########################################################\n",
      "Epoch 25/40\n",
      "loss: 2.4339702129364014 - metric: 0.36469998955726624 - val_loss: 2.536928415298462 - val_metric: 0.3552 - penalty: 0.0\n",
      "hidden layer sizes: [3, 45, 113, 115, 115, 172, 257, 414], total units: 1234\n",
      "##########################################################\n",
      "Epoch 26/40\n",
      "loss: 2.3701765537261963 - metric: 0.3774600028991699 - val_loss: 2.4544243812561035 - val_metric: 0.3693 - penalty: 0.0\n",
      "hidden layer sizes: [3, 45, 113, 115, 115, 172, 257, 414], total units: 1234\n",
      "##########################################################\n",
      "Epoch 27/40\n",
      "loss: 2.3112807273864746 - metric: 0.3920600116252899 - val_loss: 2.4750640392303467 - val_metric: 0.3776 - penalty: 0.0\n",
      "hidden layer sizes: [3, 45, 113, 115, 115, 172, 257, 414], total units: 1234\n",
      "##########################################################\n",
      "Epoch 28/40\n",
      "loss: 2.2583844661712646 - metric: 0.4037800133228302 - val_loss: 2.2544260025024414 - val_metric: 0.4108 - penalty: 0.0\n",
      "hidden layer sizes: [3, 45, 113, 115, 115, 172, 257, 414], total units: 1234\n",
      "##########################################################\n",
      "Epoch 29/40\n",
      "loss: 2.219780445098877 - metric: 0.41043999791145325 - val_loss: 2.346768379211426 - val_metric: 0.3946 - penalty: 0.0\n",
      "hidden layer sizes: [3, 45, 113, 115, 115, 172, 257, 414], total units: 1234\n",
      "##########################################################\n",
      "Epoch 30/40\n",
      "loss: 2.173386335372925 - metric: 0.418720006942749 - val_loss: 2.2628488540649414 - val_metric: 0.4139 - penalty: 0.0\n",
      "hidden layer sizes: [3, 45, 113, 115, 115, 172, 257, 414], total units: 1234\n",
      "##########################################################\n",
      "Epoch 31/40\n",
      "loss: 2.1285793781280518 - metric: 0.4320800006389618 - val_loss: 2.1747350692749023 - val_metric: 0.4291 - penalty: 0.0\n",
      "hidden layer sizes: [3, 45, 113, 115, 115, 172, 257, 414], total units: 1234\n",
      "##########################################################\n",
      "Epoch 32/40\n",
      "loss: 2.0916271209716797 - metric: 0.43817999958992004 - val_loss: 2.2276687622070312 - val_metric: 0.4242 - penalty: 0.0\n",
      "hidden layer sizes: [3, 45, 113, 115, 115, 172, 257, 414], total units: 1234\n",
      "##########################################################\n",
      "Epoch 33/40\n",
      "loss: 2.054211139678955 - metric: 0.4477599859237671 - val_loss: 2.123002290725708 - val_metric: 0.4446 - penalty: 0.0\n",
      "hidden layer sizes: [3, 45, 113, 115, 115, 172, 257, 414], total units: 1234\n",
      "##########################################################\n",
      "Epoch 34/40\n",
      "loss: 2.0222327709198 - metric: 0.4512999951839447 - val_loss: 2.136176824569702 - val_metric: 0.4388 - penalty: 0.0\n",
      "hidden layer sizes: [3, 45, 113, 115, 115, 172, 257, 414], total units: 1234\n",
      "##########################################################\n",
      "Epoch 35/40\n",
      "loss: 1.9987478256225586 - metric: 0.4610599875450134 - val_loss: 2.110828399658203 - val_metric: 0.4501 - penalty: 0.0\n",
      "hidden layer sizes: [3, 45, 113, 115, 115, 172, 257, 414], total units: 1234\n",
      "##########################################################\n",
      "Epoch 36/40\n",
      "loss: 1.9568496942520142 - metric: 0.46869999170303345 - val_loss: 2.0324981212615967 - val_metric: 0.4622 - penalty: 0.0\n",
      "hidden layer sizes: [3, 45, 113, 115, 115, 172, 257, 414], total units: 1234\n",
      "##########################################################\n",
      "Epoch 37/40\n",
      "loss: 1.9436967372894287 - metric: 0.4702399969100952 - val_loss: 2.1013853549957275 - val_metric: 0.4491 - penalty: 0.0\n",
      "hidden layer sizes: [3, 45, 113, 115, 115, 172, 257, 414], total units: 1234\n",
      "##########################################################\n",
      "Epoch 38/40\n",
      "loss: 1.919737458229065 - metric: 0.4772599935531616 - val_loss: 2.0600640773773193 - val_metric: 0.4615 - penalty: 0.0\n",
      "hidden layer sizes: [3, 45, 113, 115, 115, 172, 257, 414], total units: 1234\n",
      "##########################################################\n",
      "Epoch 39/40\n",
      "loss: 1.8901749849319458 - metric: 0.4844200015068054 - val_loss: 1.9524552822113037 - val_metric: 0.4789 - penalty: 0.0\n",
      "hidden layer sizes: [3, 45, 113, 115, 115, 172, 257, 414], total units: 1234\n",
      "##########################################################\n",
      "Epoch 40/40\n",
      "loss: 1.873940110206604 - metric: 0.48611998558044434 - val_loss: 2.0260157585144043 - val_metric: 0.4656 - penalty: 0.0\n",
      "hidden layer sizes: [3, 45, 113, 115, 115, 172, 257, 414], total units: 1234\n",
      "CPU times: user 4min 58s, sys: 9.97 s, total: 5min 8s\n",
      "Wall time: 4min 38s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [4.700596332550049,\n",
       "  4.190736770629883,\n",
       "  4.046806335449219,\n",
       "  3.8893206119537354,\n",
       "  3.788820266723633,\n",
       "  3.7025256156921387,\n",
       "  3.63857102394104,\n",
       "  3.560093402862549,\n",
       "  3.5176446437835693,\n",
       "  3.487985372543335,\n",
       "  3.4485270977020264,\n",
       "  3.4192769527435303,\n",
       "  3.3848111629486084,\n",
       "  3.3725855350494385,\n",
       "  3.35589599609375,\n",
       "  3.3305022716522217,\n",
       "  3.3145127296447754,\n",
       "  3.29801344871521,\n",
       "  3.2780520915985107,\n",
       "  3.265876054763794,\n",
       "  3.0825679302215576,\n",
       "  2.752199649810791,\n",
       "  2.627910852432251,\n",
       "  2.514864921569824,\n",
       "  2.4339702129364014,\n",
       "  2.3701765537261963,\n",
       "  2.3112807273864746,\n",
       "  2.2583844661712646,\n",
       "  2.219780445098877,\n",
       "  2.173386335372925,\n",
       "  2.1285793781280518,\n",
       "  2.0916271209716797,\n",
       "  2.054211139678955,\n",
       "  2.0222327709198,\n",
       "  1.9987478256225586,\n",
       "  1.9568496942520142,\n",
       "  1.9436967372894287,\n",
       "  1.919737458229065,\n",
       "  1.8901749849319458,\n",
       "  1.873940110206604],\n",
       " 'metric': [0.0494999997317791,\n",
       "  0.07620000094175339,\n",
       "  0.08764000236988068,\n",
       "  0.10289999842643738,\n",
       "  0.11011999845504761,\n",
       "  0.12272000312805176,\n",
       "  0.12814000248908997,\n",
       "  0.13950000703334808,\n",
       "  0.14630000293254852,\n",
       "  0.15022000670433044,\n",
       "  0.15907999873161316,\n",
       "  0.16184000670909882,\n",
       "  0.17003999650478363,\n",
       "  0.17046000063419342,\n",
       "  0.1746399998664856,\n",
       "  0.17890000343322754,\n",
       "  0.18243999779224396,\n",
       "  0.1835000067949295,\n",
       "  0.18651999533176422,\n",
       "  0.18719999492168427,\n",
       "  0.22533999383449554,\n",
       "  0.29618000984191895,\n",
       "  0.32269999384880066,\n",
       "  0.34700000286102295,\n",
       "  0.36469998955726624,\n",
       "  0.3774600028991699,\n",
       "  0.3920600116252899,\n",
       "  0.4037800133228302,\n",
       "  0.41043999791145325,\n",
       "  0.418720006942749,\n",
       "  0.4320800006389618,\n",
       "  0.43817999958992004,\n",
       "  0.4477599859237671,\n",
       "  0.4512999951839447,\n",
       "  0.4610599875450134,\n",
       "  0.46869999170303345,\n",
       "  0.4702399969100952,\n",
       "  0.4772599935531616,\n",
       "  0.4844200015068054,\n",
       "  0.48611998558044434],\n",
       " 'val_loss': [4.378565788269043,\n",
       "  4.318184852600098,\n",
       "  4.235678672790527,\n",
       "  4.054266929626465,\n",
       "  3.8797781467437744,\n",
       "  3.7691733837127686,\n",
       "  3.6054890155792236,\n",
       "  3.469273805618286,\n",
       "  3.5130043029785156,\n",
       "  3.565579652786255,\n",
       "  3.393320322036743,\n",
       "  3.5545527935028076,\n",
       "  3.2731380462646484,\n",
       "  3.2275686264038086,\n",
       "  3.1485514640808105,\n",
       "  3.2007200717926025,\n",
       "  3.1058380603790283,\n",
       "  3.1706225872039795,\n",
       "  3.121046543121338,\n",
       "  3.2331273555755615,\n",
       "  2.7905235290527344,\n",
       "  2.678389549255371,\n",
       "  2.554034471511841,\n",
       "  2.4786925315856934,\n",
       "  2.536928415298462,\n",
       "  2.4544243812561035,\n",
       "  2.4750640392303467,\n",
       "  2.2544260025024414,\n",
       "  2.346768379211426,\n",
       "  2.2628488540649414,\n",
       "  2.1747350692749023,\n",
       "  2.2276687622070312,\n",
       "  2.123002290725708,\n",
       "  2.136176824569702,\n",
       "  2.110828399658203,\n",
       "  2.0324981212615967,\n",
       "  2.1013853549957275,\n",
       "  2.0600640773773193,\n",
       "  1.9524552822113037,\n",
       "  2.0260157585144043],\n",
       " 'val_metric': [0.0462,\n",
       "  0.0305,\n",
       "  0.0474,\n",
       "  0.0793,\n",
       "  0.1025,\n",
       "  0.1241,\n",
       "  0.1506,\n",
       "  0.1719,\n",
       "  0.1582,\n",
       "  0.1495,\n",
       "  0.191,\n",
       "  0.1518,\n",
       "  0.204,\n",
       "  0.2211,\n",
       "  0.2288,\n",
       "  0.2184,\n",
       "  0.2343,\n",
       "  0.218,\n",
       "  0.232,\n",
       "  0.2075,\n",
       "  0.2888,\n",
       "  0.3187,\n",
       "  0.3389,\n",
       "  0.3637,\n",
       "  0.3552,\n",
       "  0.3693,\n",
       "  0.3776,\n",
       "  0.4108,\n",
       "  0.3946,\n",
       "  0.4139,\n",
       "  0.4291,\n",
       "  0.4242,\n",
       "  0.4446,\n",
       "  0.4388,\n",
       "  0.4501,\n",
       "  0.4622,\n",
       "  0.4491,\n",
       "  0.4615,\n",
       "  0.4789,\n",
       "  0.4656],\n",
       " 'hidden_layer_sizes': [[3, 32, 85, 128, 128, 105, 341, 344],\n",
       "  [3, 46, 105, 140, 134, 126, 366, 342],\n",
       "  [3, 42, 110, 132, 120, 150, 353, 343],\n",
       "  [3, 51, 117, 121, 120, 174, 326, 351],\n",
       "  [3, 56, 115, 114, 116, 170, 312, 357],\n",
       "  [3, 46, 124, 115, 112, 174, 294, 363],\n",
       "  [3, 39, 117, 108, 116, 172, 281, 365],\n",
       "  [3, 44, 115, 108, 119, 182, 286, 384],\n",
       "  [3, 43, 124, 116, 106, 158, 286, 391],\n",
       "  [3, 44, 107, 103, 109, 170, 286, 394],\n",
       "  [3, 47, 118, 112, 111, 177, 287, 394],\n",
       "  [3, 43, 118, 99, 108, 151, 261, 407],\n",
       "  [3, 44, 114, 109, 105, 165, 272, 406],\n",
       "  [3, 44, 119, 112, 119, 159, 260, 406],\n",
       "  [3, 45, 117, 96, 118, 172, 279, 412],\n",
       "  [3, 46, 111, 108, 120, 169, 263, 419],\n",
       "  [3, 42, 116, 111, 116, 165, 275, 434],\n",
       "  [3, 46, 117, 97, 107, 154, 265, 421],\n",
       "  [3, 42, 109, 102, 100, 157, 271, 426],\n",
       "  [3, 45, 113, 115, 115, 172, 257, 414],\n",
       "  [3, 45, 113, 115, 115, 172, 257, 414],\n",
       "  [3, 45, 113, 115, 115, 172, 257, 414],\n",
       "  [3, 45, 113, 115, 115, 172, 257, 414],\n",
       "  [3, 45, 113, 115, 115, 172, 257, 414],\n",
       "  [3, 45, 113, 115, 115, 172, 257, 414],\n",
       "  [3, 45, 113, 115, 115, 172, 257, 414],\n",
       "  [3, 45, 113, 115, 115, 172, 257, 414],\n",
       "  [3, 45, 113, 115, 115, 172, 257, 414],\n",
       "  [3, 45, 113, 115, 115, 172, 257, 414],\n",
       "  [3, 45, 113, 115, 115, 172, 257, 414],\n",
       "  [3, 45, 113, 115, 115, 172, 257, 414],\n",
       "  [3, 45, 113, 115, 115, 172, 257, 414],\n",
       "  [3, 45, 113, 115, 115, 172, 257, 414],\n",
       "  [3, 45, 113, 115, 115, 172, 257, 414],\n",
       "  [3, 45, 113, 115, 115, 172, 257, 414],\n",
       "  [3, 45, 113, 115, 115, 172, 257, 414],\n",
       "  [3, 45, 113, 115, 115, 172, 257, 414],\n",
       "  [3, 45, 113, 115, 115, 172, 257, 414],\n",
       "  [3, 45, 113, 115, 115, 172, 257, 414],\n",
       "  [3, 45, 113, 115, 115, 172, 257, 414]]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "schedule = [DynamicEpoch(0.0001, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20\n",
    "train_fn_conv(x=cifar100.X_train_norm, y=cifar100.y_train, \n",
    "              validation_data=(cifar100.X_test_norm, cifar100.y_test), learning_rate=0.0002, \n",
    "              schedule=schedule, layer_sizes=layer_sizes, output_neurons=100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c380533f-1a6b-4da9-950c-8ad45f80bded",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-26 21:41:03.076045: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-26 21:41:03.606569: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-10-26 21:41:03.606619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38405 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:81:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################################\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-26 21:41:07.352084: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n",
      "2022-10-26 21:41:08.218878: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 3.926284074783325 - metric: 0.12173999845981598 - val_loss: 3.9560282230377197 - val_metric: 0.1444 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 2/40\n",
      "loss: 3.201998233795166 - metric: 0.22088000178337097 - val_loss: 3.2030768394470215 - val_metric: 0.2421 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 3/40\n",
      "loss: 2.8709194660186768 - metric: 0.27893999218940735 - val_loss: 2.780451536178589 - val_metric: 0.3129 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 4/40\n",
      "loss: 2.668593645095825 - metric: 0.3171600103378296 - val_loss: 2.692246198654175 - val_metric: 0.3296 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 5/40\n",
      "loss: 2.5336875915527344 - metric: 0.3456999957561493 - val_loss: 2.567523717880249 - val_metric: 0.363 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 6/40\n",
      "loss: 2.4174444675445557 - metric: 0.3686000108718872 - val_loss: 2.4207353591918945 - val_metric: 0.3816 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 7/40\n",
      "loss: 2.3264310359954834 - metric: 0.3877600133419037 - val_loss: 2.224299669265747 - val_metric: 0.4177 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 8/40\n",
      "loss: 2.252077102661133 - metric: 0.40167999267578125 - val_loss: 2.244826078414917 - val_metric: 0.4129 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 9/40\n",
      "loss: 2.1789052486419678 - metric: 0.41975998878479004 - val_loss: 2.198713541030884 - val_metric: 0.4201 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 10/40\n",
      "loss: 2.1313135623931885 - metric: 0.4280799925327301 - val_loss: 2.067431926727295 - val_metric: 0.4517 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 11/40\n",
      "loss: 2.0783913135528564 - metric: 0.4399999976158142 - val_loss: 2.0073764324188232 - val_metric: 0.4618 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 12/40\n",
      "loss: 2.035841464996338 - metric: 0.4509199857711792 - val_loss: 2.027926206588745 - val_metric: 0.4612 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 13/40\n",
      "loss: 1.985137701034546 - metric: 0.45974001288414 - val_loss: 2.039177417755127 - val_metric: 0.4662 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 14/40\n",
      "loss: 1.944941520690918 - metric: 0.4674000144004822 - val_loss: 1.9354850053787231 - val_metric: 0.4889 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 15/40\n",
      "loss: 1.9081014394760132 - metric: 0.47874000668525696 - val_loss: 1.9289076328277588 - val_metric: 0.4854 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 16/40\n",
      "loss: 1.8763595819473267 - metric: 0.48377999663352966 - val_loss: 1.881395697593689 - val_metric: 0.4989 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 17/40\n",
      "loss: 1.8311904668807983 - metric: 0.4914399981498718 - val_loss: 1.9219552278518677 - val_metric: 0.493 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 18/40\n",
      "loss: 1.8161189556121826 - metric: 0.4994800090789795 - val_loss: 1.8678843975067139 - val_metric: 0.5073 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 19/40\n",
      "loss: 1.779642939567566 - metric: 0.5042999982833862 - val_loss: 1.8558579683303833 - val_metric: 0.5059 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 20/40\n",
      "loss: 1.7653576135635376 - metric: 0.5091000199317932 - val_loss: 1.835455298423767 - val_metric: 0.513 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 21/40\n",
      "loss: 1.7308142185211182 - metric: 0.5167800188064575 - val_loss: 1.771752119064331 - val_metric: 0.5243 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 22/40\n",
      "loss: 1.7163195610046387 - metric: 0.5208399891853333 - val_loss: 1.8009871244430542 - val_metric: 0.5206 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 23/40\n",
      "loss: 1.6981054544448853 - metric: 0.5254200100898743 - val_loss: 1.7757956981658936 - val_metric: 0.5251 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 24/40\n",
      "loss: 1.669467806816101 - metric: 0.5303800106048584 - val_loss: 1.7815954685211182 - val_metric: 0.5267 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 25/40\n",
      "loss: 1.644593596458435 - metric: 0.5351799726486206 - val_loss: 1.7786917686462402 - val_metric: 0.5208 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 26/40\n",
      "loss: 1.6291009187698364 - metric: 0.5401800274848938 - val_loss: 1.8000543117523193 - val_metric: 0.5224 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 27/40\n",
      "loss: 1.6163413524627686 - metric: 0.5435199737548828 - val_loss: 1.7392783164978027 - val_metric: 0.534 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 28/40\n",
      "loss: 1.6001334190368652 - metric: 0.546500027179718 - val_loss: 1.763607382774353 - val_metric: 0.5294 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 29/40\n",
      "loss: 1.5760737657546997 - metric: 0.551859974861145 - val_loss: 1.721827507019043 - val_metric: 0.5406 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 30/40\n",
      "loss: 1.5588386058807373 - metric: 0.5572999715805054 - val_loss: 1.718127965927124 - val_metric: 0.5421 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 31/40\n",
      "loss: 1.541059970855713 - metric: 0.5608199834823608 - val_loss: 1.7373313903808594 - val_metric: 0.5415 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 32/40\n",
      "loss: 1.5276315212249756 - metric: 0.5669199824333191 - val_loss: 1.6851259469985962 - val_metric: 0.5446 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 33/40\n",
      "loss: 1.5169756412506104 - metric: 0.5658599734306335 - val_loss: 1.6669245958328247 - val_metric: 0.552 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 34/40\n",
      "loss: 1.5103368759155273 - metric: 0.571120023727417 - val_loss: 1.7321499586105347 - val_metric: 0.5396 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 35/40\n",
      "loss: 1.4949331283569336 - metric: 0.5733399987220764 - val_loss: 1.7066031694412231 - val_metric: 0.5455 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 36/40\n",
      "loss: 1.478987455368042 - metric: 0.5746200084686279 - val_loss: 1.7070664167404175 - val_metric: 0.5436 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 37/40\n",
      "loss: 1.4601340293884277 - metric: 0.5826399922370911 - val_loss: 1.6899535655975342 - val_metric: 0.5482 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 38/40\n",
      "loss: 1.4651128053665161 - metric: 0.5766599774360657 - val_loss: 1.7133431434631348 - val_metric: 0.5486 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 39/40\n",
      "loss: 1.4447171688079834 - metric: 0.583840012550354 - val_loss: 1.6622146368026733 - val_metric: 0.5529 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "##########################################################\n",
      "Epoch 40/40\n",
      "loss: 1.4324214458465576 - metric: 0.5892000198364258 - val_loss: 1.7312699556350708 - val_metric: 0.5419 - penalty: 0.0\n",
      "hidden layer sizes: [3, 32, 85, 128, 128, 85, 341, 341], total units: 1143\n",
      "CPU times: user 3min 19s, sys: 8.6 s, total: 3min 28s\n",
      "Wall time: 3min 5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [3.926284074783325,\n",
       "  3.201998233795166,\n",
       "  2.8709194660186768,\n",
       "  2.668593645095825,\n",
       "  2.5336875915527344,\n",
       "  2.4174444675445557,\n",
       "  2.3264310359954834,\n",
       "  2.252077102661133,\n",
       "  2.1789052486419678,\n",
       "  2.1313135623931885,\n",
       "  2.0783913135528564,\n",
       "  2.035841464996338,\n",
       "  1.985137701034546,\n",
       "  1.944941520690918,\n",
       "  1.9081014394760132,\n",
       "  1.8763595819473267,\n",
       "  1.8311904668807983,\n",
       "  1.8161189556121826,\n",
       "  1.779642939567566,\n",
       "  1.7653576135635376,\n",
       "  1.7308142185211182,\n",
       "  1.7163195610046387,\n",
       "  1.6981054544448853,\n",
       "  1.669467806816101,\n",
       "  1.644593596458435,\n",
       "  1.6291009187698364,\n",
       "  1.6163413524627686,\n",
       "  1.6001334190368652,\n",
       "  1.5760737657546997,\n",
       "  1.5588386058807373,\n",
       "  1.541059970855713,\n",
       "  1.5276315212249756,\n",
       "  1.5169756412506104,\n",
       "  1.5103368759155273,\n",
       "  1.4949331283569336,\n",
       "  1.478987455368042,\n",
       "  1.4601340293884277,\n",
       "  1.4651128053665161,\n",
       "  1.4447171688079834,\n",
       "  1.4324214458465576],\n",
       " 'metric': [0.12173999845981598,\n",
       "  0.22088000178337097,\n",
       "  0.27893999218940735,\n",
       "  0.3171600103378296,\n",
       "  0.3456999957561493,\n",
       "  0.3686000108718872,\n",
       "  0.3877600133419037,\n",
       "  0.40167999267578125,\n",
       "  0.41975998878479004,\n",
       "  0.4280799925327301,\n",
       "  0.4399999976158142,\n",
       "  0.4509199857711792,\n",
       "  0.45974001288414,\n",
       "  0.4674000144004822,\n",
       "  0.47874000668525696,\n",
       "  0.48377999663352966,\n",
       "  0.4914399981498718,\n",
       "  0.4994800090789795,\n",
       "  0.5042999982833862,\n",
       "  0.5091000199317932,\n",
       "  0.5167800188064575,\n",
       "  0.5208399891853333,\n",
       "  0.5254200100898743,\n",
       "  0.5303800106048584,\n",
       "  0.5351799726486206,\n",
       "  0.5401800274848938,\n",
       "  0.5435199737548828,\n",
       "  0.546500027179718,\n",
       "  0.551859974861145,\n",
       "  0.5572999715805054,\n",
       "  0.5608199834823608,\n",
       "  0.5669199824333191,\n",
       "  0.5658599734306335,\n",
       "  0.571120023727417,\n",
       "  0.5733399987220764,\n",
       "  0.5746200084686279,\n",
       "  0.5826399922370911,\n",
       "  0.5766599774360657,\n",
       "  0.583840012550354,\n",
       "  0.5892000198364258],\n",
       " 'val_loss': [3.9560282230377197,\n",
       "  3.2030768394470215,\n",
       "  2.780451536178589,\n",
       "  2.692246198654175,\n",
       "  2.567523717880249,\n",
       "  2.4207353591918945,\n",
       "  2.224299669265747,\n",
       "  2.244826078414917,\n",
       "  2.198713541030884,\n",
       "  2.067431926727295,\n",
       "  2.0073764324188232,\n",
       "  2.027926206588745,\n",
       "  2.039177417755127,\n",
       "  1.9354850053787231,\n",
       "  1.9289076328277588,\n",
       "  1.881395697593689,\n",
       "  1.9219552278518677,\n",
       "  1.8678843975067139,\n",
       "  1.8558579683303833,\n",
       "  1.835455298423767,\n",
       "  1.771752119064331,\n",
       "  1.8009871244430542,\n",
       "  1.7757956981658936,\n",
       "  1.7815954685211182,\n",
       "  1.7786917686462402,\n",
       "  1.8000543117523193,\n",
       "  1.7392783164978027,\n",
       "  1.763607382774353,\n",
       "  1.721827507019043,\n",
       "  1.718127965927124,\n",
       "  1.7373313903808594,\n",
       "  1.6851259469985962,\n",
       "  1.6669245958328247,\n",
       "  1.7321499586105347,\n",
       "  1.7066031694412231,\n",
       "  1.7070664167404175,\n",
       "  1.6899535655975342,\n",
       "  1.7133431434631348,\n",
       "  1.6622146368026733,\n",
       "  1.7312699556350708],\n",
       " 'val_metric': [0.1444,\n",
       "  0.2421,\n",
       "  0.3129,\n",
       "  0.3296,\n",
       "  0.363,\n",
       "  0.3816,\n",
       "  0.4177,\n",
       "  0.4129,\n",
       "  0.4201,\n",
       "  0.4517,\n",
       "  0.4618,\n",
       "  0.4612,\n",
       "  0.4662,\n",
       "  0.4889,\n",
       "  0.4854,\n",
       "  0.4989,\n",
       "  0.493,\n",
       "  0.5073,\n",
       "  0.5059,\n",
       "  0.513,\n",
       "  0.5243,\n",
       "  0.5206,\n",
       "  0.5251,\n",
       "  0.5267,\n",
       "  0.5208,\n",
       "  0.5224,\n",
       "  0.534,\n",
       "  0.5294,\n",
       "  0.5406,\n",
       "  0.5421,\n",
       "  0.5415,\n",
       "  0.5446,\n",
       "  0.552,\n",
       "  0.5396,\n",
       "  0.5455,\n",
       "  0.5436,\n",
       "  0.5482,\n",
       "  0.5486,\n",
       "  0.5529,\n",
       "  0.5419],\n",
       " 'hidden_layer_sizes': [[3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341],\n",
       "  [3, 32, 85, 128, 128, 85, 341, 341]]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "schedule = Schedule([StaticEpochNoRegularization()] * 40)\n",
    "train_fn_conv(x=cifar100.X_train_norm, y=cifar100.y_train, \n",
    "              validation_data=(cifar100.X_test_norm, cifar100.y_test), learning_rate=0.001, \n",
    "              schedule=schedule, layer_sizes=layer_sizes, output_neurons=100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce684671-bc1a-4b63-9bbb-5e3e247d3e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################################\n",
      "Epoch 1/40\n",
      "loss: 4.164563179016113 - metric: 0.1171799972653389 - val_loss: 4.554275989532471 - val_metric: 0.1434 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 2/40\n",
      "loss: 3.3377609252929688 - metric: 0.21318000555038452 - val_loss: 3.5045278072357178 - val_metric: 0.2326 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 3/40\n",
      "loss: 2.9550507068634033 - metric: 0.2761400043964386 - val_loss: 3.0465550422668457 - val_metric: 0.3036 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 4/40\n",
      "loss: 2.701124429702759 - metric: 0.3158800005912781 - val_loss: 2.7370235919952393 - val_metric: 0.3477 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 5/40\n",
      "loss: 2.4953885078430176 - metric: 0.3582000136375427 - val_loss: 2.6952080726623535 - val_metric: 0.3539 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 6/40\n",
      "loss: 2.3433902263641357 - metric: 0.38741999864578247 - val_loss: 2.462343692779541 - val_metric: 0.3981 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 7/40\n",
      "loss: 2.222804069519043 - metric: 0.41449999809265137 - val_loss: 2.2611353397369385 - val_metric: 0.4195 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 8/40\n",
      "loss: 2.1114468574523926 - metric: 0.43397998809814453 - val_loss: 2.329519271850586 - val_metric: 0.4221 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 9/40\n",
      "loss: 2.018197536468506 - metric: 0.45399999618530273 - val_loss: 2.129441499710083 - val_metric: 0.4502 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 10/40\n",
      "loss: 1.9336079359054565 - metric: 0.4733000099658966 - val_loss: 2.0682883262634277 - val_metric: 0.4616 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 11/40\n",
      "loss: 1.860167384147644 - metric: 0.4905799925327301 - val_loss: 1.979614019393921 - val_metric: 0.4791 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 12/40\n",
      "loss: 1.7841598987579346 - metric: 0.5075399875640869 - val_loss: 1.975751519203186 - val_metric: 0.4847 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 13/40\n",
      "loss: 1.7304868698120117 - metric: 0.5205199718475342 - val_loss: 1.9861687421798706 - val_metric: 0.4878 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 14/40\n",
      "loss: 1.6743803024291992 - metric: 0.530780017375946 - val_loss: 1.924804925918579 - val_metric: 0.5016 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 15/40\n",
      "loss: 1.6206616163253784 - metric: 0.5448200106620789 - val_loss: 1.873439073562622 - val_metric: 0.5141 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 16/40\n",
      "loss: 1.5723124742507935 - metric: 0.5571399927139282 - val_loss: 1.8757586479187012 - val_metric: 0.5164 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 17/40\n",
      "loss: 1.5143556594848633 - metric: 0.5683599710464478 - val_loss: 1.8468409776687622 - val_metric: 0.5233 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 18/40\n",
      "loss: 1.4662446975708008 - metric: 0.5814200043678284 - val_loss: 1.8844707012176514 - val_metric: 0.514 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 19/40\n",
      "loss: 1.4362691640853882 - metric: 0.5896400213241577 - val_loss: 1.7855619192123413 - val_metric: 0.5399 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 20/40\n",
      "loss: 1.3897252082824707 - metric: 0.5994399785995483 - val_loss: 1.8389984369277954 - val_metric: 0.5267 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 21/40\n",
      "loss: 1.3558814525604248 - metric: 0.6070600152015686 - val_loss: 1.792283535003662 - val_metric: 0.5402 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 22/40\n",
      "loss: 1.3159631490707397 - metric: 0.6165000200271606 - val_loss: 1.758955717086792 - val_metric: 0.5458 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 23/40\n",
      "loss: 1.282547116279602 - metric: 0.6223400235176086 - val_loss: 1.8370418548583984 - val_metric: 0.538 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 24/40\n",
      "loss: 1.2527399063110352 - metric: 0.6282399892807007 - val_loss: 1.787279486656189 - val_metric: 0.545 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 25/40\n",
      "loss: 1.2210615873336792 - metric: 0.63919997215271 - val_loss: 1.7691081762313843 - val_metric: 0.5465 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 26/40\n",
      "loss: 1.2001926898956299 - metric: 0.6452800035476685 - val_loss: 1.781398057937622 - val_metric: 0.5502 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 27/40\n",
      "loss: 1.1615076065063477 - metric: 0.656059980392456 - val_loss: 1.834904670715332 - val_metric: 0.5446 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 28/40\n",
      "loss: 1.130737066268921 - metric: 0.6616799831390381 - val_loss: 1.816506028175354 - val_metric: 0.548 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 29/40\n",
      "loss: 1.1033198833465576 - metric: 0.6673799753189087 - val_loss: 1.762529730796814 - val_metric: 0.5596 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 30/40\n",
      "loss: 1.0799574851989746 - metric: 0.6754999756813049 - val_loss: 1.788341760635376 - val_metric: 0.5569 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 31/40\n",
      "loss: 1.0673094987869263 - metric: 0.6765400171279907 - val_loss: 1.7922840118408203 - val_metric: 0.558 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 32/40\n",
      "loss: 1.0290958881378174 - metric: 0.6879799962043762 - val_loss: 1.814652681350708 - val_metric: 0.5569 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 33/40\n",
      "loss: 1.008555293083191 - metric: 0.6929200291633606 - val_loss: 1.779449462890625 - val_metric: 0.5625 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 34/40\n",
      "loss: 0.9994961619377136 - metric: 0.6942200064659119 - val_loss: 1.7505155801773071 - val_metric: 0.5666 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 35/40\n",
      "loss: 0.9761124849319458 - metric: 0.7009000182151794 - val_loss: 1.8000221252441406 - val_metric: 0.5595 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 36/40\n",
      "loss: 0.9613146185874939 - metric: 0.7058600187301636 - val_loss: 1.7974814176559448 - val_metric: 0.5656 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 37/40\n",
      "loss: 0.9395744800567627 - metric: 0.7095999717712402 - val_loss: 1.8462581634521484 - val_metric: 0.5596 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 38/40\n",
      "loss: 0.9266930222511292 - metric: 0.7168400287628174 - val_loss: 1.8270609378814697 - val_metric: 0.5638 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 39/40\n",
      "loss: 0.9204065799713135 - metric: 0.7160599827766418 - val_loss: 1.7986501455307007 - val_metric: 0.5677 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "##########################################################\n",
      "Epoch 40/40\n",
      "loss: 0.8923746943473816 - metric: 0.724399983882904 - val_loss: 1.8381491899490356 - val_metric: 0.5631 - penalty: 0.0\n",
      "hidden layer sizes: [32, 85, 128, 128, 85, 1365, 1365], total units: 3188\n",
      "CPU times: user 2min 46s, sys: 5.68 s, total: 2min 52s\n",
      "Wall time: 3min 31s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [4.164563179016113,\n",
       "  3.3377609252929688,\n",
       "  2.9550507068634033,\n",
       "  2.701124429702759,\n",
       "  2.4953885078430176,\n",
       "  2.3433902263641357,\n",
       "  2.222804069519043,\n",
       "  2.1114468574523926,\n",
       "  2.018197536468506,\n",
       "  1.9336079359054565,\n",
       "  1.860167384147644,\n",
       "  1.7841598987579346,\n",
       "  1.7304868698120117,\n",
       "  1.6743803024291992,\n",
       "  1.6206616163253784,\n",
       "  1.5723124742507935,\n",
       "  1.5143556594848633,\n",
       "  1.4662446975708008,\n",
       "  1.4362691640853882,\n",
       "  1.3897252082824707,\n",
       "  1.3558814525604248,\n",
       "  1.3159631490707397,\n",
       "  1.282547116279602,\n",
       "  1.2527399063110352,\n",
       "  1.2210615873336792,\n",
       "  1.2001926898956299,\n",
       "  1.1615076065063477,\n",
       "  1.130737066268921,\n",
       "  1.1033198833465576,\n",
       "  1.0799574851989746,\n",
       "  1.0673094987869263,\n",
       "  1.0290958881378174,\n",
       "  1.008555293083191,\n",
       "  0.9994961619377136,\n",
       "  0.9761124849319458,\n",
       "  0.9613146185874939,\n",
       "  0.9395744800567627,\n",
       "  0.9266930222511292,\n",
       "  0.9204065799713135,\n",
       "  0.8923746943473816],\n",
       " 'metric': [0.1171799972653389,\n",
       "  0.21318000555038452,\n",
       "  0.2761400043964386,\n",
       "  0.3158800005912781,\n",
       "  0.3582000136375427,\n",
       "  0.38741999864578247,\n",
       "  0.41449999809265137,\n",
       "  0.43397998809814453,\n",
       "  0.45399999618530273,\n",
       "  0.4733000099658966,\n",
       "  0.4905799925327301,\n",
       "  0.5075399875640869,\n",
       "  0.5205199718475342,\n",
       "  0.530780017375946,\n",
       "  0.5448200106620789,\n",
       "  0.5571399927139282,\n",
       "  0.5683599710464478,\n",
       "  0.5814200043678284,\n",
       "  0.5896400213241577,\n",
       "  0.5994399785995483,\n",
       "  0.6070600152015686,\n",
       "  0.6165000200271606,\n",
       "  0.6223400235176086,\n",
       "  0.6282399892807007,\n",
       "  0.63919997215271,\n",
       "  0.6452800035476685,\n",
       "  0.656059980392456,\n",
       "  0.6616799831390381,\n",
       "  0.6673799753189087,\n",
       "  0.6754999756813049,\n",
       "  0.6765400171279907,\n",
       "  0.6879799962043762,\n",
       "  0.6929200291633606,\n",
       "  0.6942200064659119,\n",
       "  0.7009000182151794,\n",
       "  0.7058600187301636,\n",
       "  0.7095999717712402,\n",
       "  0.7168400287628174,\n",
       "  0.7160599827766418,\n",
       "  0.724399983882904],\n",
       " 'val_loss': [4.554275989532471,\n",
       "  3.5045278072357178,\n",
       "  3.0465550422668457,\n",
       "  2.7370235919952393,\n",
       "  2.6952080726623535,\n",
       "  2.462343692779541,\n",
       "  2.2611353397369385,\n",
       "  2.329519271850586,\n",
       "  2.129441499710083,\n",
       "  2.0682883262634277,\n",
       "  1.979614019393921,\n",
       "  1.975751519203186,\n",
       "  1.9861687421798706,\n",
       "  1.924804925918579,\n",
       "  1.873439073562622,\n",
       "  1.8757586479187012,\n",
       "  1.8468409776687622,\n",
       "  1.8844707012176514,\n",
       "  1.7855619192123413,\n",
       "  1.8389984369277954,\n",
       "  1.792283535003662,\n",
       "  1.758955717086792,\n",
       "  1.8370418548583984,\n",
       "  1.787279486656189,\n",
       "  1.7691081762313843,\n",
       "  1.781398057937622,\n",
       "  1.834904670715332,\n",
       "  1.816506028175354,\n",
       "  1.762529730796814,\n",
       "  1.788341760635376,\n",
       "  1.7922840118408203,\n",
       "  1.814652681350708,\n",
       "  1.779449462890625,\n",
       "  1.7505155801773071,\n",
       "  1.8000221252441406,\n",
       "  1.7974814176559448,\n",
       "  1.8462581634521484,\n",
       "  1.8270609378814697,\n",
       "  1.7986501455307007,\n",
       "  1.8381491899490356],\n",
       " 'val_metric': [0.1434,\n",
       "  0.2326,\n",
       "  0.3036,\n",
       "  0.3477,\n",
       "  0.3539,\n",
       "  0.3981,\n",
       "  0.4195,\n",
       "  0.4221,\n",
       "  0.4502,\n",
       "  0.4616,\n",
       "  0.4791,\n",
       "  0.4847,\n",
       "  0.4878,\n",
       "  0.5016,\n",
       "  0.5141,\n",
       "  0.5164,\n",
       "  0.5233,\n",
       "  0.514,\n",
       "  0.5399,\n",
       "  0.5267,\n",
       "  0.5402,\n",
       "  0.5458,\n",
       "  0.538,\n",
       "  0.545,\n",
       "  0.5465,\n",
       "  0.5502,\n",
       "  0.5446,\n",
       "  0.548,\n",
       "  0.5596,\n",
       "  0.5569,\n",
       "  0.558,\n",
       "  0.5569,\n",
       "  0.5625,\n",
       "  0.5666,\n",
       "  0.5595,\n",
       "  0.5656,\n",
       "  0.5596,\n",
       "  0.5638,\n",
       "  0.5677,\n",
       "  0.5631],\n",
       " 'hidden_layer_sizes': [[32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365],\n",
       "  [32, 85, 128, 128, 85, 1365, 1365]]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "schedule = Schedule([StaticEpochNoRegularization()] * 40)\n",
    "train_fn_conv(x=cifar100.X_train_norm, y=cifar100.y_train, \n",
    "              validation_data=(cifar100.X_test_norm, cifar100.y_test), learning_rate=0.001, \n",
    "              schedule=schedule, layer_sizes=layer_sizes, output_neurons=100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe5bb57-fc12-4669-a46f-b3dd7f896b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
