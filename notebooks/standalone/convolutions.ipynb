{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_multi_layer_ssnet_inverse.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_deAUKlniFk",
        "outputId": "c46b812f-0683-499e-c29f-1cc5b2e5b6d7"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Oct  8 16:47:44 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKwUwV_NneIo"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOoXBq05neIt"
      },
      "source": [
        "dtype = 'float32'\n",
        "tf.keras.backend.set_floatx(dtype)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BrJPdkBneIv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "779376b6-d425-430a-c688-96026bb2cd92"
      },
      "source": [
        "cifar10 = tf.keras.datasets.cifar10\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "X_train = X_train.astype(dtype) / 255.0\n",
        "y_train = y_train.astype(dtype)\n",
        "X_test = X_test.astype(dtype)  / 255.0\n",
        "y_test = y_test.astype(dtype)\n",
        "\n",
        "X_train = np.reshape(X_train, (-1, 3072))\n",
        "X_test = np.reshape(X_test, (-1, 3072))\n",
        "\n",
        "X = np.concatenate((X_train, X_test), axis=0)\n",
        "y = np.concatenate((y_train, y_test), axis=0)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n",
            "170508288/170498071 [==============================] - 11s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5uTvu5kxF-b"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_norm = scaler.transform(X)\n",
        "X_train_norm = scaler.transform(X_train)\n",
        "X_test_norm = scaler.transform(X_test)\n",
        "\n",
        "X_norm = np.reshape(X_norm, (-1, 32, 32, 3))\n",
        "X_train_norm = np.reshape(X_train_norm, (-1, 32, 32, 3))\n",
        "X_test_norm = np.reshape(X_test_norm, (-1, 32, 32, 3))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTZq4KMpneIv"
      },
      "source": [
        "class Regularizer(tf.keras.regularizers.Regularizer):\n",
        "    def __init__(self, regularization_penalty, regularization_method):\n",
        "        self.regularization_penalty = regularization_penalty\n",
        "        self.regularization_method = regularization_method\n",
        "\n",
        "    def __call__(self, x):\n",
        "        if self.regularization_method == 'weighted_l1':\n",
        "            return self.weighted_l1(x)\n",
        "        elif self.regularization_method == 'group_sparsity':\n",
        "            return self.group_sparsity(x)\n",
        "        else:\n",
        "            raise NotImplementedError(f\"Unknown regularization method {self.regularization_method}\")\n",
        "    \n",
        "    def weighted_l1(self, x):\n",
        "        # I.e. for a parameter matrix of 4 input and 10 output neurons:\n",
        "        #\n",
        "        # [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]\n",
        "        #\n",
        "        # the scaling tensor, as well as the resulting weighted values, could be:\n",
        "        #\n",
        "        # [[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
        "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
        "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
        "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]\n",
        "        #\n",
        "        # Therefore every additional output neuron is regularized more.\n",
        "\n",
        "        scaling_tensor = tf.cumsum(tf.constant(self.regularization_penalty, shape=x.shape, dtype=dtype), axis=-1)\n",
        "        weighted_values = scaling_tensor * tf.abs(x)\n",
        "        return tf.reduce_sum(weighted_values)\n",
        "    \n",
        "    def group_sparsity(self, x):\n",
        "        # I.e. for a parameter matrix of 3 input and 5 output neurons:\n",
        "        #\n",
        "        # [[1., 1., 1., 1., 1.],\n",
        "        #  [1., 2., 2., 1., 2.],\n",
        "        #  [2., 2., 3., 1., 3.]]\n",
        "        #\n",
        "        # The resulting vector of group norms is [2., 2., 3., 1., 3.], therefore for\n",
        "        # every output neuron, its incoming connections form a group.\n",
        "\n",
        "        # TODO implement for Conv2D layers\n",
        "        group_norms = tf.norm(x, ord=2, axis=0)\n",
        "        # assert group_norms.shape[0] == x.shape[1]\n",
        "        return self.regularization_penalty * tf.reduce_sum(group_norms)\n",
        "\n",
        "    def get_config(self):\n",
        "        return {'regularization_penalty': float(self.regularization_penalty)}\n",
        "\n",
        "\n",
        "class ModelReference:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "\n",
        "class CustomLayer(tf.keras.Model):\n",
        "    def __init__(self, input_shape):\n",
        "        super().__init__()\n",
        "\n",
        "        self.inpt_shp = input_shape\n",
        "    \n",
        "    def configure(self, model):\n",
        "        self.mr = ModelReference(model)\n",
        "    \n",
        "    def get_input_shape(self):\n",
        "        if self.inpt_shp is not None:\n",
        "            return self.inpt_shp\n",
        "        \n",
        "        return self.mr.model.get_layer_input_shape(self)\n",
        "    \n",
        "    def get_output_shape(self):\n",
        "        return self.mr.model.get_layer_output_shape(self)\n",
        "\n",
        "\n",
        "class Dense(CustomLayer):\n",
        "    def __init__(self, units, activation, regularization_penalty=0.01, \n",
        "                 regularization_method='weighted_l1', kernel_initializer='glorot_uniform', \n",
        "                 bias_initializer='zeros', input_shape=None, fixed_size=False):\n",
        "        super().__init__(input_shape)\n",
        "\n",
        "        self.units = units\n",
        "        self.activation = activation\n",
        "        self.regularization_penalty = regularization_penalty\n",
        "        self.regularization_method = regularization_method\n",
        "        self.kernel_initializer = kernel_initializer\n",
        "        self.bias_initializer = bias_initializer\n",
        "        self.fixed_size = fixed_size\n",
        "        \n",
        "        self.A = tf.keras.activations.get(activation)\n",
        "        self.W_init = tf.keras.initializers.get(kernel_initializer)\n",
        "        self.b_init = tf.keras.initializers.get(bias_initializer)\n",
        "        self.regularizer = Regularizer(self.regularization_penalty, self.regularization_method)\n",
        "    \n",
        "    def configure(self, model):\n",
        "        super().configure(model)\n",
        "\n",
        "        input_units = self.get_input_units_count()\n",
        "\n",
        "        self.W = tf.Variable(\n",
        "            name='W',\n",
        "            initial_value=self.W_init(shape=(input_units, self.units), dtype=dtype),\n",
        "            trainable=True)\n",
        "        \n",
        "        self.b = tf.Variable(\n",
        "            name='b',\n",
        "            initial_value=self.b_init(shape=(self.units,), dtype=dtype),\n",
        "            trainable=True)\n",
        "        \n",
        "        if self.regularization_method is not None:\n",
        "            self.add_loss(lambda: self.regularizer(tf.concat([self.W, tf.reshape(self.b, (1, -1))], axis=0)))\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        return self.A(tf.matmul(inputs, self.W) + self.b)\n",
        "    \n",
        "    def copy_without_regularization(self):\n",
        "        # TODO fix\n",
        "        copy = Dense(\n",
        "            self.input_units, \n",
        "            self.units, \n",
        "            self.activation, \n",
        "            regularization_penalty=self.regularization_penalty, \n",
        "            regularization_method=None, \n",
        "            kernel_initializer=self.kernel_initializer, \n",
        "            bias_initializer=self.bias_initializer\n",
        "        )\n",
        "        copy.W = self.W\n",
        "        copy.b = self.b\n",
        "        return copy\n",
        "    \n",
        "    def get_input_units_count(self):\n",
        "        input_shape = self.get_input_shape()\n",
        "        if len(input_shape) != 1:\n",
        "            raise Exception(f\"Invalid input shape {input_shape}.\")\n",
        "        return input_shape[0]\n",
        "    \n",
        "    def get_size(self):\n",
        "        return self.get_input_units_count(), self.W.shape[1]\n",
        "    \n",
        "    def prune(self, threshold, active_input_units_indices):\n",
        "        # Remove connections from pruned units in previous layer\n",
        "        new_W = tf.gather(self.W.value(), active_input_units_indices, axis=0)\n",
        "\n",
        "        if self.fixed_size:\n",
        "            active_output_neurons_indices = list(range(new_W.shape[1]))\n",
        "        else:\n",
        "            # Prune units in this layer\n",
        "            weights_with_biases = tf.concat([new_W, tf.reshape(self.b.value(), (1, -1))], axis=0)\n",
        "            neurons_are_active = tf.math.reduce_max(tf.abs(weights_with_biases), axis=0) >= threshold\n",
        "            active_output_neurons_indices = tf.reshape(tf.where(neurons_are_active), (-1,))\n",
        "            \n",
        "            new_W = tf.gather(new_W, active_output_neurons_indices, axis=1)\n",
        "            new_b = tf.gather(self.b.value(), active_output_neurons_indices, axis=0)\n",
        "\n",
        "            self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
        "\n",
        "        self.W = tf.Variable(name='W', initial_value=new_W, trainable=True)\n",
        "\n",
        "        return active_output_neurons_indices\n",
        "    \n",
        "    def grow(self, n_new_input_units, percentage, min_new_units, scaling_factor):\n",
        "        if n_new_input_units > 0:\n",
        "            # Add connections to grown units in previous layer\n",
        "            W_growth = self.W_init(shape=(self.W.shape[0] + n_new_input_units, self.W.shape[1]), dtype=dtype)[-n_new_input_units:, :] * scaling_factor  # TODO is it better to be multiplying here by scaling_factor? It does help with not increasing the max weights of existing neurons when new neurons are added.\n",
        "            new_W = tf.concat([self.W.value(), W_growth], axis=0)\n",
        "        else:\n",
        "            new_W = self.W.value()\n",
        "\n",
        "        if self.fixed_size:\n",
        "            n_new_output_units = 0\n",
        "        else:\n",
        "            # Grow new units in this layer\n",
        "            n_new_output_units = max(min_new_units, int(new_W.shape[1] * percentage))\n",
        "            W_growth = self.W_init(shape=(new_W.shape[0], new_W.shape[1] + n_new_output_units), dtype=dtype)[:, -n_new_output_units:] * scaling_factor\n",
        "            b_growth = self.b_init(shape=(n_new_output_units,), dtype=dtype)  # TODO for all possible bias initializers to work properly, the whole bias vector should be initialized at once\n",
        "            new_W = tf.concat([new_W, W_growth], axis=1)\n",
        "            new_b = tf.concat([self.b.value(), b_growth], axis=0)\n",
        "\n",
        "            self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
        "\n",
        "        self.W = tf.Variable(name='W', initial_value=new_W, trainable=True)\n",
        "\n",
        "        return n_new_output_units\n",
        "    \n",
        "    def get_param_string():\n",
        "        param_string = \"\"\n",
        "        weights_with_bias = tf.concat([self.W, tf.reshape(self.b, (1, -1))], axis=0)\n",
        "        max_parameters = tf.math.reduce_max(tf.abs(weights_with_bias), axis=0).numpy()\n",
        "        magnitudes = np.floor(np.log10(max_parameters))\n",
        "        for m in magnitudes:\n",
        "            if m > 0:\n",
        "                m = 0\n",
        "            param_string += str(int(-m))\n",
        "        return param_string\n",
        "\n",
        "\n",
        "class Conv2D(CustomLayer):\n",
        "    def __init__(self, filters, filter_size, activation, strides=(1, 1), \n",
        "                 padding='SAME', regularization_penalty=0.01, \n",
        "                 regularization_method='weighted_l1', kernel_initializer='glorot_uniform',\n",
        "                 bias_initializer='zeros', input_shape=None, fixed_size=False):\n",
        "        super().__init__(input_shape)\n",
        "    \n",
        "        self.filters = filters\n",
        "        self.filter_size = filter_size\n",
        "        self.activation = activation\n",
        "        self.strides = strides\n",
        "        self.padding = padding\n",
        "        self.regularization_penalty = regularization_penalty\n",
        "        self.regularization_method = regularization_method\n",
        "        self.kernel_initializer = kernel_initializer\n",
        "        self.bias_initializer = bias_initializer\n",
        "        self.fixed_size = fixed_size\n",
        "        \n",
        "        self.A = tf.keras.activations.get(activation)\n",
        "        self.F_init = tf.keras.initializers.get(kernel_initializer)\n",
        "        self.b_init = tf.keras.initializers.get(bias_initializer)\n",
        "        self.regularizer = Regularizer(self.regularization_penalty, self.regularization_method)\n",
        "    \n",
        "    def configure(self, model):\n",
        "        super().configure(model)\n",
        "\n",
        "        input_filters = self.get_input_filters_count()\n",
        "\n",
        "        self.F = tf.Variable(\n",
        "            name='F',\n",
        "            initial_value=self.F_init(\n",
        "                shape=(self.filter_size[0], self.filter_size[1], input_filters, self.filters), dtype=dtype\n",
        "            ),\n",
        "            trainable=True)\n",
        "        \n",
        "        self.b = tf.Variable(\n",
        "            name='b',\n",
        "            initial_value=self.b_init(shape=(self.filters,), dtype=dtype),\n",
        "            trainable=True)\n",
        "\n",
        "        if self.regularization_method is not None:\n",
        "            self.add_loss(lambda: self.regularizer(tf.concat([tf.reshape(self.F, (-1, self.F.shape[-1])), tf.reshape(self.b, (1, -1))], axis=0)))\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        y = tf.nn.conv2d(inputs, self.F, strides=self.strides, padding=self.padding)\n",
        "        y = tf.nn.bias_add(y, self.b)\n",
        "        y = self.A(y)\n",
        "        return y\n",
        "    \n",
        "    def copy_without_regularization(self):\n",
        "        # TODO fix\n",
        "        copy = Conv2D(\n",
        "            self.input_filters,\n",
        "            self.filters,\n",
        "            self.filter_size,\n",
        "            self.activation, \n",
        "            strides=self.strides, \n",
        "            padding=self.padding, \n",
        "            kernel_initializer=self.kernel_initializer, \n",
        "            bias_initializer=self.bias_initializer \n",
        "        )\n",
        "        copy.F = self.F\n",
        "        copy.b = self.b\n",
        "        return copy\n",
        "    \n",
        "    def get_input_filters_count(self):\n",
        "        input_shape = self.get_input_shape()\n",
        "        return input_shape[-1]\n",
        "    \n",
        "    def get_size(self):\n",
        "        return self.get_input_filters_count(), self.F.shape[-1]\n",
        "    \n",
        "    def prune(self, threshold, active_input_units_indices):\n",
        "        # Remove connections from pruned units in previous layer\n",
        "        new_F = tf.gather(self.F.value(), active_input_units_indices, axis=-2)\n",
        "\n",
        "        if self.fixed_size:\n",
        "            active_output_filters_indices = list(range(new_F.shape[-1]))\n",
        "        else:\n",
        "            # Prune units in this layer\n",
        "            F_reduced_max = tf.reshape(tf.math.reduce_max(tf.abs(new_F), axis=(0, 1, 2)), (1, -1))\n",
        "            F_reduced_max_with_biases = tf.concat([F_reduced_max, tf.reshape(self.b.value(), (1, -1))], axis=0)\n",
        "            filters_are_active = tf.math.reduce_max(tf.abs(F_reduced_max_with_biases), axis=0) >= threshold\n",
        "            active_output_filters_indices = tf.reshape(tf.where(filters_are_active), (-1,))\n",
        "            \n",
        "            new_F = tf.gather(new_F, active_output_filters_indices, axis=-1)\n",
        "            new_b = tf.gather(self.b.value(), active_output_filters_indices, axis=0)\n",
        "\n",
        "            self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
        "\n",
        "        self.F = tf.Variable(name='F', initial_value=new_F, trainable=True)\n",
        "\n",
        "        return active_output_filters_indices\n",
        "\n",
        "    def grow(self, n_new_input_units, percentage, min_new_units, scaling_factor):\n",
        "        if n_new_input_units > 0:\n",
        "            # Add connections to grown units in previous layer\n",
        "            F_growth = self.F_init(shape=(self.F.shape[0], self.F.shape[1], self.F.shape[2] + n_new_input_units, self.F.shape[3]), dtype=dtype)[:, :, -n_new_input_units:, :] * scaling_factor  # TODO is it better to be multiplying here by scaling_factor? It does help with not increasing the max weights of existing neurons when new neurons are added.\n",
        "            new_F = tf.concat([self.F.value(), F_growth], axis=-2)\n",
        "        else:\n",
        "            new_F = self.F.value()\n",
        "\n",
        "        if self.fixed_size:\n",
        "            n_new_output_units = 0\n",
        "        else:\n",
        "            # Grow new units in this layer\n",
        "            n_new_output_units = max(min_new_units, int(new_F.shape[-1] * percentage))\n",
        "            F_growth = self.F_init(shape=(new_F.shape[0], new_F.shape[1], new_F.shape[2], new_F.shape[3] + n_new_output_units), dtype=dtype)[:, :, :, -n_new_output_units:] * scaling_factor\n",
        "            b_growth = self.b_init(shape=(n_new_output_units,), dtype=dtype)  # TODO for all possible bias initializers to work properly, the whole bias vector should be initialized at once\n",
        "            new_F = tf.concat([new_F, F_growth], axis=-1)\n",
        "            new_b = tf.concat([self.b.value(), b_growth], axis=0)\n",
        "\n",
        "            self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
        "\n",
        "        self.F = tf.Variable(name='F', initial_value=new_F, trainable=True)\n",
        "\n",
        "        return n_new_output_units\n",
        "\n",
        "    def get_param_string():\n",
        "        param_string = \"\"\n",
        "        # TODO\n",
        "        return param_string\n",
        "\n",
        "\n",
        "class Flatten(tf.keras.Model):\n",
        "    def call(self, inputs):\n",
        "        return tf.reshape(tf.transpose(inputs, perm=[0, 3, 1, 2]), (inputs.shape[0], -1))\n",
        "\n",
        "\n",
        "class Sequential(tf.keras.Model):\n",
        "    def __init__(self, layers, activation=None):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.lrs = list()\n",
        "        for layer in layers:\n",
        "            self.lrs.append(layer)\n",
        "            if isinstance(layer, CustomLayer):\n",
        "                layer.configure(self)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs\n",
        "        for layer in self.lrs:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "    \n",
        "    def get_layer_input_shape(self, target_layer):\n",
        "        input = np.random.normal(size=(1,) + self.lrs[0].inpt_shp)\n",
        "        for layer in self.lrs:\n",
        "            if layer is target_layer:\n",
        "                return tuple(input.shape[1:])\n",
        "            input = layer(input)\n",
        "        raise Exception(\"Layer not found in the model.\")\n",
        "\n",
        "    def get_layer_output_shape(self, target_layer):\n",
        "        input = np.random.normal(size=(1,) + self.lrs[0].inpt_shp)\n",
        "        for layer in self.lrs:\n",
        "            output = layer(input)\n",
        "            if layer is target_layer:\n",
        "                return tuple(output.shape[1:])\n",
        "            input = output\n",
        "        raise Exception(\"Layer not found in the model.\")\n",
        "    \n",
        "    def get_layer_sizes(self):\n",
        "        \"\"\"\n",
        "        Returns the sizes of all layers in the model, including the input and output layer.\n",
        "        \"\"\"\n",
        "        layer_sizes = list()\n",
        "        first_layer = True\n",
        "        for l in range(len(self.lrs)):\n",
        "            layer = self.lrs[l]\n",
        "            if isinstance(layer, CustomLayer):\n",
        "                layer_size = layer.get_size()\n",
        "                if first_layer:\n",
        "                    layer_sizes.append(layer_size[0])\n",
        "                    first_layer = False\n",
        "                layer_sizes.append(layer_size[1])\n",
        "        return layer_sizes\n",
        "    \n",
        "    def get_hidden_layer_sizes(self):\n",
        "        return self.get_layer_sizes()[1:-1]\n",
        "    \n",
        "    def remove_regularization(self):\n",
        "        # for l in range(len(self.lrs)):\n",
        "        #     layer = self.lrs[l]\n",
        "        #     if isinstance(layer, CustomLayer):\n",
        "        #         self.lrs[l] = layer.copy_without_regularization()\n",
        "        self.set_regularization_penalty(0.)\n",
        "    \n",
        "    def get_regularization_penalty(self):\n",
        "        return self.lrs[-2].regularizer.regularization_penalty\n",
        "    \n",
        "    def set_regularization_penalty(self, regularization_penalty):\n",
        "        for layer in self.lrs:\n",
        "            if isinstance(layer, CustomLayer) and not layer.fixed_size:\n",
        "                layer.regularizer.regularization_penalty = regularization_penalty\n",
        "    \n",
        "    def prune(self, threshold=0.001):\n",
        "        # for l in range(len(self.lrs) - 1):\n",
        "        #     layer1 = self.lrs[l]\n",
        "        #     layer2 = self.lrs[l + 1]\n",
        "            \n",
        "        #     W1 = layer1.W.value()\n",
        "        #     b1 = layer1.b.value()\n",
        "        #     W2 = layer2.W.value()\n",
        "\n",
        "        #     weights_with_biases = tf.concat([W1, tf.reshape(b1, (1, -1))], axis=0)\n",
        "        #     neurons_are_active = tf.math.reduce_max(tf.abs(weights_with_biases), axis=0) >= threshold\n",
        "        #     active_neurons_indices = tf.reshape(tf.where(neurons_are_active), (-1,))\n",
        "            \n",
        "        #     new_W1 = tf.gather(W1, active_neurons_indices, axis=1)\n",
        "        #     new_b1 = tf.gather(b1, active_neurons_indices, axis=0)\n",
        "        #     new_W2 = tf.gather(W2, active_neurons_indices, axis=0)\n",
        "\n",
        "        #     layer1.W = tf.Variable(name='W', initial_value=new_W1, trainable=True)\n",
        "        #     layer1.b = tf.Variable(name='b', initial_value=new_b1, trainable=True)\n",
        "        #     layer2.W = tf.Variable(name='W', initial_value=new_W2, trainable=True)\n",
        "        input_shape = self.lrs[0].get_input_shape()\n",
        "        n_input_units = input_shape[-1]\n",
        "        active_units_indices = list(range(n_input_units))\n",
        "\n",
        "        last_custom_layer = None\n",
        "        for layer in self.lrs:\n",
        "            if isinstance(layer, CustomLayer):\n",
        "                if last_custom_layer is not None and type(last_custom_layer) != type(layer):\n",
        "                    if type(last_custom_layer) == Conv2D and type(layer) == Dense:\n",
        "                        convolutional_shape = last_custom_layer.get_output_shape()\n",
        "                        active_units_indices = self.convert_channel_indices_to_flattened_indices(active_units_indices, convolutional_shape)\n",
        "                    else:\n",
        "                        raise Exception(\"Incorrect order of custom layer types.\")\n",
        "                active_units_indices = layer.prune(threshold, active_units_indices)\n",
        "                last_custom_layer = layer\n",
        "    \n",
        "    def grow(self, percentage, min_new_neurons=5, scaling_factor=0.001):   \n",
        "        # for l in range(len(self.lrs) - 1):\n",
        "        #     layer1 = self.lrs[l]\n",
        "        #     layer2 = self.lrs[l + 1]\n",
        "       \n",
        "        #     W1 = layer1.W.value()\n",
        "        #     b1 = layer1.b.value()\n",
        "        #     W2 = layer2.W.value()\n",
        "\n",
        "        #     n_new_neurons = max(min_new_neurons, int(W1.shape[1] * percentage))\n",
        "\n",
        "        #     W1_growth = layer1.W_init(shape=(W1.shape[0], W1.shape[1] + n_new_neurons), dtype=dtype)[:, -n_new_neurons:] * scaling_factor\n",
        "        #     b1_growth = layer1.b_init(shape=(n_new_neurons,), dtype=dtype)\n",
        "        #     W2_growth = layer2.W_init(shape=(W2.shape[0] + n_new_neurons, W2.shape[1]), dtype=dtype)[-n_new_neurons:, :] * scaling_factor  # TODO is it better to be multiplying here by scaling_factor? It does help with not increasing the max weights of existing neurons when new neurons are added.\n",
        "\n",
        "        #     new_W1 = tf.concat([W1, W1_growth], axis=1)\n",
        "        #     new_b1 = tf.concat([b1, b1_growth], axis=0)\n",
        "        #     new_W2 = tf.concat([W2, W2_growth], axis=0)\n",
        "\n",
        "        #     layer1.W = tf.Variable(name='W1', initial_value=new_W1, trainable=True)\n",
        "        #     layer1.b = tf.Variable(name='b1', initial_value=new_b1, trainable=True)\n",
        "        #     layer2.W = tf.Variable(name='W2', initial_value=new_W2, trainable=True)\n",
        "        n_new_units = 0\n",
        "\n",
        "        last_custom_layer = None\n",
        "        for layer in self.lrs:\n",
        "            if isinstance(layer, CustomLayer):\n",
        "                if last_custom_layer is not None and type(last_custom_layer) != type(layer):\n",
        "                    if type(last_custom_layer) == Conv2D and type(layer) == Dense:\n",
        "                        convolutional_shape = last_custom_layer.get_output_shape()\n",
        "                        n_new_units = n_new_units * convolutional_shape[0] * convolutional_shape[1]\n",
        "                    else:\n",
        "                        raise Exception(\"Incorrect order of custom layer types.\")\n",
        "                n_new_units = layer.grow(n_new_units, percentage, min_new_units=min_new_neurons, scaling_factor=scaling_factor)\n",
        "                last_custom_layer = layer\n",
        "    \n",
        "    @staticmethod\n",
        "    def convert_channel_indices_to_flattened_indices(channel_indices, convolutional_shape):\n",
        "        dense_indices = list()\n",
        "        units_per_channel = convolutional_shape[0] * convolutional_shape[1]\n",
        "        for channel_index in channel_indices:\n",
        "            for iter in range(units_per_channel):\n",
        "                dense_indices.append(channel_index * units_per_channel + iter)\n",
        "        return dense_indices\n",
        "    \n",
        "    def print_neurons(self):\n",
        "        for layer in self.lrs[:-1]:\n",
        "            print(layer.get_param_string())\n",
        "    \n",
        "    def evaluate(self, x, y, summed_training_loss, summed_training_accuracy, val_dataset):\n",
        "        # Calculate training loss and accuracy\n",
        "        if summed_training_loss is not None:\n",
        "            loss = summed_training_loss / x.shape[0]\n",
        "        else:\n",
        "            loss = None\n",
        "        \n",
        "        if summed_training_accuracy is not None:\n",
        "            accuracy = summed_training_accuracy / x.shape[0]\n",
        "        else:\n",
        "            accuracy = None\n",
        "        \n",
        "        # Calculate val loss and accuracy\n",
        "        summed_val_loss = 0\n",
        "        summed_val_accuracy = 0\n",
        "        n_val_instances = 0\n",
        "        \n",
        "        for step, (x_batch, y_batch) in enumerate(val_dataset):\n",
        "            y_pred = self(x_batch)\n",
        "            summed_val_loss += tf.reduce_sum(tf.keras.losses.sparse_categorical_crossentropy(y_batch, y_pred))\n",
        "            summed_val_accuracy += float(tf.reduce_sum(tf.keras.metrics.sparse_categorical_accuracy(y_batch, y_pred)))\n",
        "            n_val_instances += x_batch.shape[0]\n",
        "        \n",
        "        val_loss = summed_val_loss / n_val_instances\n",
        "        val_accuracy = summed_val_accuracy / n_val_instances\n",
        "\n",
        "        return loss, accuracy, val_loss, val_accuracy\n",
        "    \n",
        "    def print_epoch_statistics(self, x, y, summed_training_loss, summed_training_accuracy, val_dataset, print_neurons):\n",
        "        loss, accuracy, val_loss, val_accuracy = self.evaluate(x, y, summed_training_loss, summed_training_accuracy, val_dataset)\n",
        "        print(f\"loss: {loss} - accuracy: {accuracy} - val_loss: {val_loss} - val_accuracy: {val_accuracy} - penalty: {model.get_regularization_penalty()}\")\n",
        "        hidden_layer_sizes = self.get_hidden_layer_sizes()\n",
        "        print(f\"hidden layer sizes: {hidden_layer_sizes}, total units: {sum(hidden_layer_sizes)}\")\n",
        "        if print_neurons:\n",
        "            self.print_neurons()\n",
        "    \n",
        "    def update_history(self, x, y, summed_loss, summed_accuracy, val_dataset, history):\n",
        "        loss, accuracy, val_loss, val_accuracy = self.evaluate(x, y, summed_loss, summed_accuracy, val_dataset)\n",
        "        history['loss'].append(loss)\n",
        "        history['accuracy'].append(accuracy)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_accuracy'].append(val_accuracy)\n",
        "\n",
        "    def fit(self, x, y, optimizer, epochs, self_scaling_epochs, batch_size, min_new_neurons, validation_data, pruning_threshold=0.001, \n",
        "            regularization_penalty_multiplier=1., stall_coefficient=1, growth_percentage=0.2, mini_epochs_per_epoch=1, verbose=True, print_neurons=False):\n",
        "        train_dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "        train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "        val_dataset = tf.data.Dataset.from_tensor_slices(validation_data).batch(batch_size)\n",
        "\n",
        "        history = {\n",
        "            'loss': list(),\n",
        "            'accuracy': list(),\n",
        "            'val_loss': list(),\n",
        "            'val_accuracy': list(),\n",
        "        }\n",
        "\n",
        "        best_val_loss = np.inf\n",
        "        training_stalled = False\n",
        "        for epoch in range(epochs):\n",
        "            summed_loss = 0\n",
        "            summed_accuracy = 0\n",
        "\n",
        "            if verbose:\n",
        "                print(\"##########################################################\")\n",
        "                print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "            if epoch < self_scaling_epochs:\n",
        "                if verbose:\n",
        "                    print(\"Before growing:\")\n",
        "                    self.print_epoch_statistics(x, y, None, None, val_dataset, print_neurons)\n",
        "\n",
        "                loss, accuracy, val_loss, val_accuracy = self.evaluate(x, y, summed_loss, summed_accuracy, val_dataset)\n",
        "                if regularization_penalty_multiplier != 1. and val_loss >= best_val_loss * stall_coefficient:\n",
        "                    if not training_stalled:\n",
        "                        penalty = self.get_regularization_penalty() * regularization_penalty_multiplier\n",
        "                        print(\"Changing penalty...\")\n",
        "                        # TODO this must be modified, penalty can differ for each layer\n",
        "                        self.set_regularization_penalty(penalty)\n",
        "                        training_stalled = True\n",
        "                else:\n",
        "                    best_val_loss = val_loss\n",
        "                    training_stalled = False\n",
        "\n",
        "                self.grow(percentage=growth_percentage, min_new_neurons=min_new_neurons, scaling_factor=pruning_threshold)\n",
        "                if verbose:\n",
        "                    print(\"After growing:\")\n",
        "                    self.print_epoch_statistics(x, y, None, None, val_dataset, print_neurons)\n",
        "            \n",
        "            if epoch == self_scaling_epochs:\n",
        "                self.remove_regularization()\n",
        "\n",
        "            for mini_epoch in range(mini_epochs_per_epoch):\n",
        "                for step, (x_batch, y_batch) in enumerate(train_dataset):\n",
        "                    with tf.GradientTape() as tape:\n",
        "                        y_pred = self(x_batch, training=True)\n",
        "                        raw_loss = tf.keras.losses.sparse_categorical_crossentropy(y_batch, y_pred)\n",
        "                        loss_value = tf.reduce_mean(raw_loss)\n",
        "                        loss_value += sum(self.losses)  # Add losses registered by model.add_loss\n",
        "\n",
        "                        summed_loss += tf.reduce_sum(raw_loss)\n",
        "                        summed_accuracy += float(tf.reduce_sum(tf.keras.metrics.sparse_categorical_accuracy(y_batch, y_pred)))\n",
        "\n",
        "                    grads = tape.gradient(loss_value, self.trainable_variables)\n",
        "                    optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
        "            \n",
        "            if epoch < self_scaling_epochs:\n",
        "                if verbose:\n",
        "                    print(\"Before pruning:\")\n",
        "                    self.print_epoch_statistics(x, y, summed_loss, summed_accuracy, val_dataset, print_neurons)\n",
        "                self.prune(threshold=pruning_threshold)\n",
        "                if verbose:\n",
        "                    print(\"After pruning:\")\n",
        "                    self.print_epoch_statistics(x, y, None, None, val_dataset, print_neurons)\n",
        "            else:\n",
        "                if verbose:\n",
        "                    self.print_epoch_statistics(x, y, summed_loss, summed_accuracy, val_dataset, print_neurons)\n",
        "            \n",
        "            self.update_history(x, y, summed_loss, summed_accuracy, val_dataset, history)\n",
        "\n",
        "        return history"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1MrQXUTFwOe"
      },
      "source": [
        "# Convolutions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByLRkOAPoGcc"
      },
      "source": [
        "epochs = 20\n",
        "self_scaling_epochs = 20\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "382QHGlZvyl9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "337ec911-97e2-447f-867d-a77870803f61"
      },
      "source": [
        "model = Sequential([\n",
        "        Dense(20, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal', input_shape=X_train_norm[0, :].shape),\n",
        "        Dense(20, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        Dense(20, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        Dense(20, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None, fixed_size=True),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.847022533416748 - val_accuracy: 0.0938 - penalty: 1e-06\n",
            "hidden layer sizes: [20, 20, 20, 20], total units: 80\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.84702205657959 - val_accuracy: 0.0938 - penalty: 1e-06\n",
            "hidden layer sizes: [40, 40, 40, 40], total units: 160\n",
            "Before pruning:\n",
            "loss: 1.9452203512191772 - accuracy: 0.32256 - val_loss: 1.7487735748291016 - val_accuracy: 0.3872 - penalty: 1e-06\n",
            "hidden layer sizes: [40, 40, 40, 40], total units: 160\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.7487735748291016 - val_accuracy: 0.3872 - penalty: 1e-06\n",
            "hidden layer sizes: [40, 40, 40, 40], total units: 160\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.7487735748291016 - val_accuracy: 0.3872 - penalty: 1e-06\n",
            "hidden layer sizes: [40, 40, 40, 40], total units: 160\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.7487735748291016 - val_accuracy: 0.3872 - penalty: 1e-06\n",
            "hidden layer sizes: [60, 60, 60, 60], total units: 240\n",
            "Before pruning:\n",
            "loss: 1.6932038068771362 - accuracy: 0.40406 - val_loss: 1.617717981338501 - val_accuracy: 0.432 - penalty: 1e-06\n",
            "hidden layer sizes: [60, 60, 60, 60], total units: 240\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.617717981338501 - val_accuracy: 0.432 - penalty: 1e-06\n",
            "hidden layer sizes: [60, 60, 60, 60], total units: 240\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.617717981338501 - val_accuracy: 0.432 - penalty: 1e-06\n",
            "hidden layer sizes: [60, 60, 60, 60], total units: 240\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.617717981338501 - val_accuracy: 0.432 - penalty: 1e-06\n",
            "hidden layer sizes: [80, 80, 80, 80], total units: 320\n",
            "Before pruning:\n",
            "loss: 1.5950701236724854 - accuracy: 0.43732 - val_loss: 1.5567930936813354 - val_accuracy: 0.4541 - penalty: 1e-06\n",
            "hidden layer sizes: [80, 80, 80, 80], total units: 320\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.5567940473556519 - val_accuracy: 0.4542 - penalty: 1e-06\n",
            "hidden layer sizes: [78, 80, 80, 80], total units: 318\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.5567940473556519 - val_accuracy: 0.4542 - penalty: 1e-06\n",
            "hidden layer sizes: [78, 80, 80, 80], total units: 318\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.5567940473556519 - val_accuracy: 0.4542 - penalty: 1e-06\n",
            "hidden layer sizes: [98, 100, 100, 100], total units: 398\n",
            "Before pruning:\n",
            "loss: 1.531063437461853 - accuracy: 0.46044 - val_loss: 1.5098843574523926 - val_accuracy: 0.4652 - penalty: 1e-06\n",
            "hidden layer sizes: [98, 100, 100, 100], total units: 398\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.509883165359497 - val_accuracy: 0.4651 - penalty: 1e-06\n",
            "hidden layer sizes: [98, 100, 92, 96], total units: 386\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.509883165359497 - val_accuracy: 0.4651 - penalty: 1e-06\n",
            "hidden layer sizes: [98, 100, 92, 96], total units: 386\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.5098830461502075 - val_accuracy: 0.4651 - penalty: 1e-06\n",
            "hidden layer sizes: [118, 120, 112, 116], total units: 466\n",
            "Before pruning:\n",
            "loss: 1.486151933670044 - accuracy: 0.47494 - val_loss: 1.4772998094558716 - val_accuracy: 0.48 - penalty: 1e-06\n",
            "hidden layer sizes: [118, 120, 112, 116], total units: 466\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4772988557815552 - val_accuracy: 0.48 - penalty: 1e-06\n",
            "hidden layer sizes: [114, 120, 103, 103], total units: 440\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4772988557815552 - val_accuracy: 0.48 - penalty: 1e-06\n",
            "hidden layer sizes: [114, 120, 103, 103], total units: 440\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4772988557815552 - val_accuracy: 0.48 - penalty: 1e-06\n",
            "hidden layer sizes: [136, 144, 123, 123], total units: 526\n",
            "Before pruning:\n",
            "loss: 1.4510244131088257 - accuracy: 0.48604 - val_loss: 1.4682587385177612 - val_accuracy: 0.4808 - penalty: 1e-06\n",
            "hidden layer sizes: [136, 144, 123, 123], total units: 526\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4682543277740479 - val_accuracy: 0.4807 - penalty: 1e-06\n",
            "hidden layer sizes: [132, 144, 114, 111], total units: 501\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4682543277740479 - val_accuracy: 0.4807 - penalty: 1e-06\n",
            "hidden layer sizes: [132, 144, 114, 111], total units: 501\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4682543277740479 - val_accuracy: 0.4807 - penalty: 1e-06\n",
            "hidden layer sizes: [158, 172, 136, 133], total units: 599\n",
            "Before pruning:\n",
            "loss: 1.4220269918441772 - accuracy: 0.49738 - val_loss: 1.4586914777755737 - val_accuracy: 0.4828 - penalty: 1e-06\n",
            "hidden layer sizes: [158, 172, 136, 133], total units: 599\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4587644338607788 - val_accuracy: 0.4828 - penalty: 1e-06\n",
            "hidden layer sizes: [148, 168, 122, 116], total units: 554\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4587644338607788 - val_accuracy: 0.4828 - penalty: 1e-06\n",
            "hidden layer sizes: [148, 168, 122, 116], total units: 554\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4587644338607788 - val_accuracy: 0.4828 - penalty: 1e-06\n",
            "hidden layer sizes: [177, 201, 146, 139], total units: 663\n",
            "Before pruning:\n",
            "loss: 1.3944101333618164 - accuracy: 0.50546 - val_loss: 1.4363137483596802 - val_accuracy: 0.4952 - penalty: 1e-06\n",
            "hidden layer sizes: [177, 201, 146, 139], total units: 663\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4362996816635132 - val_accuracy: 0.495 - penalty: 1e-06\n",
            "hidden layer sizes: [172, 196, 134, 110], total units: 612\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4362996816635132 - val_accuracy: 0.495 - penalty: 1e-06\n",
            "hidden layer sizes: [172, 196, 134, 110], total units: 612\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4362998008728027 - val_accuracy: 0.495 - penalty: 1e-06\n",
            "hidden layer sizes: [206, 235, 160, 132], total units: 733\n",
            "Before pruning:\n",
            "loss: 1.3739022016525269 - accuracy: 0.51368 - val_loss: 1.4447834491729736 - val_accuracy: 0.4908 - penalty: 1e-06\n",
            "hidden layer sizes: [206, 235, 160, 132], total units: 733\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4447710514068604 - val_accuracy: 0.4908 - penalty: 1e-06\n",
            "hidden layer sizes: [194, 218, 131, 118], total units: 661\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4447710514068604 - val_accuracy: 0.4908 - penalty: 1e-06\n",
            "hidden layer sizes: [194, 218, 131, 118], total units: 661\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.44477117061615 - val_accuracy: 0.4908 - penalty: 1e-06\n",
            "hidden layer sizes: [232, 261, 157, 141], total units: 791\n",
            "Before pruning:\n",
            "loss: 1.3534380197525024 - accuracy: 0.51908 - val_loss: 1.426801085472107 - val_accuracy: 0.4967 - penalty: 1e-06\n",
            "hidden layer sizes: [232, 261, 157, 141], total units: 791\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4268704652786255 - val_accuracy: 0.4968 - penalty: 1e-06\n",
            "hidden layer sizes: [203, 217, 125, 119], total units: 664\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4268704652786255 - val_accuracy: 0.4968 - penalty: 1e-06\n",
            "hidden layer sizes: [203, 217, 125, 119], total units: 664\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.426870584487915 - val_accuracy: 0.4968 - penalty: 1e-06\n",
            "hidden layer sizes: [243, 260, 150, 142], total units: 795\n",
            "Before pruning:\n",
            "loss: 1.3362910747528076 - accuracy: 0.52698 - val_loss: 1.4262040853500366 - val_accuracy: 0.4949 - penalty: 1e-06\n",
            "hidden layer sizes: [243, 260, 150, 142], total units: 795\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4262185096740723 - val_accuracy: 0.4946 - penalty: 1e-06\n",
            "hidden layer sizes: [228, 210, 132, 128], total units: 698\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4262185096740723 - val_accuracy: 0.4946 - penalty: 1e-06\n",
            "hidden layer sizes: [228, 210, 132, 128], total units: 698\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4262185096740723 - val_accuracy: 0.4946 - penalty: 1e-06\n",
            "hidden layer sizes: [273, 252, 158, 153], total units: 836\n",
            "Before pruning:\n",
            "loss: 1.3206266164779663 - accuracy: 0.53322 - val_loss: 1.4255939722061157 - val_accuracy: 0.4931 - penalty: 1e-06\n",
            "hidden layer sizes: [273, 252, 158, 153], total units: 836\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4254165887832642 - val_accuracy: 0.4928 - penalty: 1e-06\n",
            "hidden layer sizes: [212, 229, 120, 130], total units: 691\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4254165887832642 - val_accuracy: 0.4928 - penalty: 1e-06\n",
            "hidden layer sizes: [212, 229, 120, 130], total units: 691\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4254164695739746 - val_accuracy: 0.4928 - penalty: 1e-06\n",
            "hidden layer sizes: [254, 274, 144, 156], total units: 828\n",
            "Before pruning:\n",
            "loss: 1.305312156677246 - accuracy: 0.53872 - val_loss: 1.4191508293151855 - val_accuracy: 0.5 - penalty: 1e-06\n",
            "hidden layer sizes: [254, 274, 144, 156], total units: 828\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4190995693206787 - val_accuracy: 0.4999 - penalty: 1e-06\n",
            "hidden layer sizes: [238, 263, 121, 129], total units: 751\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4190995693206787 - val_accuracy: 0.4999 - penalty: 1e-06\n",
            "hidden layer sizes: [238, 263, 121, 129], total units: 751\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4190994501113892 - val_accuracy: 0.4999 - penalty: 1e-06\n",
            "hidden layer sizes: [285, 315, 145, 154], total units: 899\n",
            "Before pruning:\n",
            "loss: 1.2916194200515747 - accuracy: 0.54382 - val_loss: 1.417806625366211 - val_accuracy: 0.4987 - penalty: 1e-06\n",
            "hidden layer sizes: [285, 315, 145, 154], total units: 899\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.417663335800171 - val_accuracy: 0.4989 - penalty: 1e-06\n",
            "hidden layer sizes: [241, 293, 121, 140], total units: 795\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.417663335800171 - val_accuracy: 0.4989 - penalty: 1e-06\n",
            "hidden layer sizes: [241, 293, 121, 140], total units: 795\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4176632165908813 - val_accuracy: 0.4989 - penalty: 1e-06\n",
            "hidden layer sizes: [289, 351, 145, 168], total units: 953\n",
            "Before pruning:\n",
            "loss: 1.27534019947052 - accuracy: 0.55034 - val_loss: 1.413841962814331 - val_accuracy: 0.4989 - penalty: 1e-06\n",
            "hidden layer sizes: [289, 351, 145, 168], total units: 953\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4138699769973755 - val_accuracy: 0.4987 - penalty: 1e-06\n",
            "hidden layer sizes: [267, 288, 115, 139], total units: 809\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4138699769973755 - val_accuracy: 0.4987 - penalty: 1e-06\n",
            "hidden layer sizes: [267, 288, 115, 139], total units: 809\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4138699769973755 - val_accuracy: 0.4987 - penalty: 1e-06\n",
            "hidden layer sizes: [320, 345, 138, 166], total units: 969\n",
            "Before pruning:\n",
            "loss: 1.260942816734314 - accuracy: 0.55546 - val_loss: 1.4225391149520874 - val_accuracy: 0.4966 - penalty: 1e-06\n",
            "hidden layer sizes: [320, 345, 138, 166], total units: 969\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4219051599502563 - val_accuracy: 0.4971 - penalty: 1e-06\n",
            "hidden layer sizes: [268, 299, 131, 158], total units: 856\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4219051599502563 - val_accuracy: 0.4971 - penalty: 1e-06\n",
            "hidden layer sizes: [268, 299, 131, 158], total units: 856\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4219053983688354 - val_accuracy: 0.4971 - penalty: 1e-06\n",
            "hidden layer sizes: [321, 358, 157, 189], total units: 1025\n",
            "Before pruning:\n",
            "loss: 1.2511773109436035 - accuracy: 0.55652 - val_loss: 1.413221836090088 - val_accuracy: 0.4987 - penalty: 1e-06\n",
            "hidden layer sizes: [321, 358, 157, 189], total units: 1025\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4132758378982544 - val_accuracy: 0.4986 - penalty: 1e-06\n",
            "hidden layer sizes: [298, 316, 143, 161], total units: 918\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4132758378982544 - val_accuracy: 0.4986 - penalty: 1e-06\n",
            "hidden layer sizes: [298, 316, 143, 161], total units: 918\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4132758378982544 - val_accuracy: 0.4986 - penalty: 1e-06\n",
            "hidden layer sizes: [357, 379, 171, 193], total units: 1100\n",
            "Before pruning:\n",
            "loss: 1.2374706268310547 - accuracy: 0.5622 - val_loss: 1.4080685377120972 - val_accuracy: 0.4979 - penalty: 1e-06\n",
            "hidden layer sizes: [357, 379, 171, 193], total units: 1100\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4082773923873901 - val_accuracy: 0.4976 - penalty: 1e-06\n",
            "hidden layer sizes: [250, 323, 141, 174], total units: 888\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4082773923873901 - val_accuracy: 0.4976 - penalty: 1e-06\n",
            "hidden layer sizes: [250, 323, 141, 174], total units: 888\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4082773923873901 - val_accuracy: 0.4976 - penalty: 1e-06\n",
            "hidden layer sizes: [300, 387, 169, 208], total units: 1064\n",
            "Before pruning:\n",
            "loss: 1.2334518432617188 - accuracy: 0.56502 - val_loss: 1.4120644330978394 - val_accuracy: 0.4982 - penalty: 1e-06\n",
            "hidden layer sizes: [300, 387, 169, 208], total units: 1064\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4121218919754028 - val_accuracy: 0.498 - penalty: 1e-06\n",
            "hidden layer sizes: [262, 311, 146, 156], total units: 875\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4121218919754028 - val_accuracy: 0.498 - penalty: 1e-06\n",
            "hidden layer sizes: [262, 311, 146, 156], total units: 875\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4121216535568237 - val_accuracy: 0.498 - penalty: 1e-06\n",
            "hidden layer sizes: [314, 373, 175, 187], total units: 1049\n",
            "Before pruning:\n",
            "loss: 1.2193961143493652 - accuracy: 0.56912 - val_loss: 1.4202760457992554 - val_accuracy: 0.4993 - penalty: 1e-06\n",
            "hidden layer sizes: [314, 373, 175, 187], total units: 1049\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4200063943862915 - val_accuracy: 0.4996 - penalty: 1e-06\n",
            "hidden layer sizes: [274, 319, 153, 152], total units: 898\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.32256,\n",
              "  0.40406,\n",
              "  0.43732,\n",
              "  0.46044,\n",
              "  0.47494,\n",
              "  0.48604,\n",
              "  0.49738,\n",
              "  0.50546,\n",
              "  0.51368,\n",
              "  0.51908,\n",
              "  0.52698,\n",
              "  0.53322,\n",
              "  0.53872,\n",
              "  0.54382,\n",
              "  0.55034,\n",
              "  0.55546,\n",
              "  0.55652,\n",
              "  0.5622,\n",
              "  0.56502,\n",
              "  0.56912],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.9452204>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.6932038>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.5950701>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.5310634>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4861519>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4510244>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.422027>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3944101>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3739022>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.353438>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3362911>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3206266>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3053122>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2916194>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2753402>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2609428>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2511773>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2374706>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2334518>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2193961>],\n",
              " 'val_accuracy': [0.3872,\n",
              "  0.432,\n",
              "  0.4542,\n",
              "  0.4651,\n",
              "  0.48,\n",
              "  0.4807,\n",
              "  0.4828,\n",
              "  0.495,\n",
              "  0.4908,\n",
              "  0.4968,\n",
              "  0.4946,\n",
              "  0.4928,\n",
              "  0.4999,\n",
              "  0.4989,\n",
              "  0.4987,\n",
              "  0.4971,\n",
              "  0.4986,\n",
              "  0.4976,\n",
              "  0.498,\n",
              "  0.4996],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.7487736>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.617718>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.556794>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.5098832>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4772989>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4682543>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4587644>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4362997>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.444771>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4268705>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4262185>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4254166>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4190996>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4176633>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.41387>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4219052>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4132758>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4082774>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4121219>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4200064>]}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C3tMuzb7m2s"
      },
      "source": [
        "model = Sequential([\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        # tf.keras.layers.Flatten(),\n",
        "        Dense(256, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None, fixed_size=True),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-suYTV264gm"
      },
      "source": [
        "# 74.5 % vs 71.5 % accuracy in the following two models - 3 % boost! (output lost)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6J2bR2B9Zam"
      },
      "source": [
        "## Dynamic models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68VYqDLJ969f"
      },
      "source": [
        "epochs = 20\n",
        "self_scaling_epochs = 20\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQnJaU_Ray-V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d5e40e3-5223-4fe1-c01a-a267f89be8bd"
      },
      "source": [
        "model = Sequential([\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None, fixed_size=True),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.963027238845825 - val_accuracy: 0.0795 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.963027238845825 - val_accuracy: 0.0795 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.8671212196350098 - accuracy: 0.38654 - val_loss: 1.3841943740844727 - val_accuracy: 0.5051 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.3840810060501099 - val_accuracy: 0.5043 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 257], total units: 1025\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.3840810060501099 - val_accuracy: 0.5043 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 257], total units: 1025\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.3840810060501099 - val_accuracy: 0.5043 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 308], total units: 1228\n",
            "Before pruning:\n",
            "loss: 1.5167487859725952 - accuracy: 0.45996 - val_loss: 1.304641842842102 - val_accuracy: 0.5286 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 308], total units: 1228\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.304631233215332 - val_accuracy: 0.5282 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 199, 256], total units: 1031\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.304631233215332 - val_accuracy: 0.5282 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 199, 256], total units: 1031\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.304631233215332 - val_accuracy: 0.5282 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 238, 307], total units: 1235\n",
            "Before pruning:\n",
            "loss: 1.3350378274917603 - accuracy: 0.5233 - val_loss: 1.1858943700790405 - val_accuracy: 0.5726 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 238, 307], total units: 1235\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1857129335403442 - val_accuracy: 0.5728 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 193, 259], total units: 1028\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1857129335403442 - val_accuracy: 0.5728 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 193, 259], total units: 1028\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1857129335403442 - val_accuracy: 0.5728 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 231, 310], total units: 1231\n",
            "Before pruning:\n",
            "loss: 1.2161905765533447 - accuracy: 0.56528 - val_loss: 1.1129087209701538 - val_accuracy: 0.5999 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 231, 310], total units: 1231\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1126041412353516 - val_accuracy: 0.6004 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 180, 182, 192, 258], total units: 1004\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1126041412353516 - val_accuracy: 0.6004 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 180, 182, 192, 258], total units: 1004\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1126041412353516 - val_accuracy: 0.6004 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 216, 218, 230, 309], total units: 1203\n",
            "Before pruning:\n",
            "loss: 1.1187293529510498 - accuracy: 0.60158 - val_loss: 1.0171185731887817 - val_accuracy: 0.6407 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 216, 218, 230, 309], total units: 1203\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0162806510925293 - val_accuracy: 0.6403 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 131, 165, 194, 285], total units: 967\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0162806510925293 - val_accuracy: 0.6403 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 131, 165, 194, 285], total units: 967\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0162804126739502 - val_accuracy: 0.6403 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 157, 198, 232, 342], total units: 1159\n",
            "Before pruning:\n",
            "loss: 1.0229793787002563 - accuracy: 0.6377 - val_loss: 0.947227954864502 - val_accuracy: 0.6621 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 157, 198, 232, 342], total units: 1159\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9468349814414978 - val_accuracy: 0.663 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 94, 156, 199, 268], total units: 909\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9468349814414978 - val_accuracy: 0.663 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 94, 156, 199, 268], total units: 909\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9468348622322083 - val_accuracy: 0.663 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 114, 187, 238, 321], total units: 1090\n",
            "Before pruning:\n",
            "loss: 0.9530110359191895 - accuracy: 0.66296 - val_loss: 0.8898763656616211 - val_accuracy: 0.6846 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 114, 187, 238, 321], total units: 1090\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8898091912269592 - val_accuracy: 0.6844 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 86, 139, 208, 275], total units: 900\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8898091912269592 - val_accuracy: 0.6844 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 86, 139, 208, 275], total units: 900\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8898091912269592 - val_accuracy: 0.6844 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 106, 166, 249, 330], total units: 1081\n",
            "Before pruning:\n",
            "loss: 0.8919062614440918 - accuracy: 0.68452 - val_loss: 0.8546335101127625 - val_accuracy: 0.6997 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 106, 166, 249, 330], total units: 1081\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8546062707901001 - val_accuracy: 0.6996 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 75, 124, 225, 291], total units: 907\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8546062707901001 - val_accuracy: 0.6996 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 75, 124, 225, 291], total units: 907\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8546061515808105 - val_accuracy: 0.6996 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 95, 148, 270, 349], total units: 1092\n",
            "Before pruning:\n",
            "loss: 0.8516693115234375 - accuracy: 0.69782 - val_loss: 0.8437287211418152 - val_accuracy: 0.7068 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 95, 148, 270, 349], total units: 1092\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8436052799224854 - val_accuracy: 0.7069 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 71, 115, 241, 328], total units: 946\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8436052799224854 - val_accuracy: 0.7069 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 71, 115, 241, 328], total units: 946\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8436052799224854 - val_accuracy: 0.7069 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 91, 138, 289, 393], total units: 1140\n",
            "Before pruning:\n",
            "loss: 0.8148197531700134 - accuracy: 0.71044 - val_loss: 0.8297868967056274 - val_accuracy: 0.7061 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 91, 138, 289, 393], total units: 1140\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8295626044273376 - val_accuracy: 0.7058 - penalty: 1e-06\n",
            "hidden layer sizes: [187, 66, 104, 250, 352], total units: 959\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8295626044273376 - val_accuracy: 0.7058 - penalty: 1e-06\n",
            "hidden layer sizes: [187, 66, 104, 250, 352], total units: 959\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8295627236366272 - val_accuracy: 0.7057 - penalty: 1e-06\n",
            "hidden layer sizes: [224, 86, 124, 300, 422], total units: 1156\n",
            "Before pruning:\n",
            "loss: 0.7849943041801453 - accuracy: 0.72276 - val_loss: 0.8167417645454407 - val_accuracy: 0.7146 - penalty: 1e-06\n",
            "hidden layer sizes: [224, 86, 124, 300, 422], total units: 1156\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8165286183357239 - val_accuracy: 0.7148 - penalty: 1e-06\n",
            "hidden layer sizes: [184, 62, 93, 254, 369], total units: 962\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8165286183357239 - val_accuracy: 0.7148 - penalty: 1e-06\n",
            "hidden layer sizes: [184, 62, 93, 254, 369], total units: 962\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8165287375450134 - val_accuracy: 0.7148 - penalty: 1e-06\n",
            "hidden layer sizes: [220, 82, 113, 304, 442], total units: 1161\n",
            "Before pruning:\n",
            "loss: 0.7655342221260071 - accuracy: 0.72994 - val_loss: 0.7894124984741211 - val_accuracy: 0.7225 - penalty: 1e-06\n",
            "hidden layer sizes: [220, 82, 113, 304, 442], total units: 1161\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7893617153167725 - val_accuracy: 0.7225 - penalty: 1e-06\n",
            "hidden layer sizes: [179, 59, 91, 249, 381], total units: 959\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7893617153167725 - val_accuracy: 0.7225 - penalty: 1e-06\n",
            "hidden layer sizes: [179, 59, 91, 249, 381], total units: 959\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7893617153167725 - val_accuracy: 0.7225 - penalty: 1e-06\n",
            "hidden layer sizes: [214, 79, 111, 298, 457], total units: 1159\n",
            "Before pruning:\n",
            "loss: 0.7458457946777344 - accuracy: 0.73536 - val_loss: 0.7913826704025269 - val_accuracy: 0.7198 - penalty: 1e-06\n",
            "hidden layer sizes: [214, 79, 111, 298, 457], total units: 1159\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7913693189620972 - val_accuracy: 0.7198 - penalty: 1e-06\n",
            "hidden layer sizes: [173, 58, 89, 255, 398], total units: 973\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7913693189620972 - val_accuracy: 0.7198 - penalty: 1e-06\n",
            "hidden layer sizes: [173, 58, 89, 255, 398], total units: 973\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7913693189620972 - val_accuracy: 0.7198 - penalty: 1e-06\n",
            "hidden layer sizes: [207, 78, 109, 306, 477], total units: 1177\n",
            "Before pruning:\n",
            "loss: 0.7267219424247742 - accuracy: 0.74644 - val_loss: 0.7885811924934387 - val_accuracy: 0.7245 - penalty: 1e-06\n",
            "hidden layer sizes: [207, 78, 109, 306, 477], total units: 1177\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7886152267456055 - val_accuracy: 0.7244 - penalty: 1e-06\n",
            "hidden layer sizes: [169, 58, 81, 260, 360], total units: 928\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7886152267456055 - val_accuracy: 0.7244 - penalty: 1e-06\n",
            "hidden layer sizes: [169, 58, 81, 260, 360], total units: 928\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7886152863502502 - val_accuracy: 0.7244 - penalty: 1e-06\n",
            "hidden layer sizes: [202, 78, 101, 312, 432], total units: 1125\n",
            "Before pruning:\n",
            "loss: 0.7069907188415527 - accuracy: 0.75044 - val_loss: 0.7790190577507019 - val_accuracy: 0.726 - penalty: 1e-06\n",
            "hidden layer sizes: [202, 78, 101, 312, 432], total units: 1125\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7788867354393005 - val_accuracy: 0.7262 - penalty: 1e-06\n",
            "hidden layer sizes: [159, 55, 84, 273, 355], total units: 926\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7788867354393005 - val_accuracy: 0.7262 - penalty: 1e-06\n",
            "hidden layer sizes: [159, 55, 84, 273, 355], total units: 926\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7788867354393005 - val_accuracy: 0.7262 - penalty: 1e-06\n",
            "hidden layer sizes: [190, 75, 104, 327, 426], total units: 1122\n",
            "Before pruning:\n",
            "loss: 0.6895431280136108 - accuracy: 0.75626 - val_loss: 0.7799628376960754 - val_accuracy: 0.725 - penalty: 1e-06\n",
            "hidden layer sizes: [190, 75, 104, 327, 426], total units: 1122\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7800217270851135 - val_accuracy: 0.7249 - penalty: 1e-06\n",
            "hidden layer sizes: [152, 56, 78, 272, 362], total units: 920\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7800217270851135 - val_accuracy: 0.7249 - penalty: 1e-06\n",
            "hidden layer sizes: [152, 56, 78, 272, 362], total units: 920\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7800217270851135 - val_accuracy: 0.7249 - penalty: 1e-06\n",
            "hidden layer sizes: [182, 76, 98, 326, 434], total units: 1116\n",
            "Before pruning:\n",
            "loss: 0.6785920262336731 - accuracy: 0.75946 - val_loss: 0.7791489958763123 - val_accuracy: 0.733 - penalty: 1e-06\n",
            "hidden layer sizes: [182, 76, 98, 326, 434], total units: 1116\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7789269685745239 - val_accuracy: 0.7329 - penalty: 1e-06\n",
            "hidden layer sizes: [149, 63, 74, 272, 420], total units: 978\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7789269685745239 - val_accuracy: 0.7329 - penalty: 1e-06\n",
            "hidden layer sizes: [149, 63, 74, 272, 420], total units: 978\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7789270281791687 - val_accuracy: 0.7329 - penalty: 1e-06\n",
            "hidden layer sizes: [178, 83, 94, 326, 504], total units: 1185\n",
            "Before pruning:\n",
            "loss: 0.6671287417411804 - accuracy: 0.7638 - val_loss: 0.7715978622436523 - val_accuracy: 0.734 - penalty: 1e-06\n",
            "hidden layer sizes: [178, 83, 94, 326, 504], total units: 1185\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7713760137557983 - val_accuracy: 0.7337 - penalty: 1e-06\n",
            "hidden layer sizes: [146, 54, 85, 270, 470], total units: 1025\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7713760137557983 - val_accuracy: 0.7337 - penalty: 1e-06\n",
            "hidden layer sizes: [146, 54, 85, 270, 470], total units: 1025\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7713760137557983 - val_accuracy: 0.7337 - penalty: 1e-06\n",
            "hidden layer sizes: [175, 74, 105, 324, 564], total units: 1242\n",
            "Before pruning:\n",
            "loss: 0.6534648537635803 - accuracy: 0.76808 - val_loss: 0.7684080004692078 - val_accuracy: 0.731 - penalty: 1e-06\n",
            "hidden layer sizes: [175, 74, 105, 324, 564], total units: 1242\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7684280276298523 - val_accuracy: 0.7306 - penalty: 1e-06\n",
            "hidden layer sizes: [139, 56, 71, 268, 424], total units: 958\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7684280276298523 - val_accuracy: 0.7306 - penalty: 1e-06\n",
            "hidden layer sizes: [139, 56, 71, 268, 424], total units: 958\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7684279680252075 - val_accuracy: 0.7306 - penalty: 1e-06\n",
            "hidden layer sizes: [166, 76, 91, 321, 508], total units: 1162\n",
            "Before pruning:\n",
            "loss: 0.6403169631958008 - accuracy: 0.77302 - val_loss: 0.775848388671875 - val_accuracy: 0.7316 - penalty: 1e-06\n",
            "hidden layer sizes: [166, 76, 91, 321, 508], total units: 1162\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.775759220123291 - val_accuracy: 0.7313 - penalty: 1e-06\n",
            "hidden layer sizes: [131, 51, 72, 277, 438], total units: 969\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.38654,\n",
              "  0.45996,\n",
              "  0.5233,\n",
              "  0.56528,\n",
              "  0.60158,\n",
              "  0.6377,\n",
              "  0.66296,\n",
              "  0.68452,\n",
              "  0.69782,\n",
              "  0.71044,\n",
              "  0.72276,\n",
              "  0.72994,\n",
              "  0.73536,\n",
              "  0.74644,\n",
              "  0.75044,\n",
              "  0.75626,\n",
              "  0.75946,\n",
              "  0.7638,\n",
              "  0.76808,\n",
              "  0.77302],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.8671212>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.5167488>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3350378>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2161906>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1187294>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0229794>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.95301104>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.89190626>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8516693>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.81481975>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7849943>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7655342>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7458458>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.72672194>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7069907>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6895431>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.678592>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.66712874>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.65346485>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.64031696>],\n",
              " 'val_accuracy': [0.5043,\n",
              "  0.5282,\n",
              "  0.5728,\n",
              "  0.6004,\n",
              "  0.6403,\n",
              "  0.663,\n",
              "  0.6844,\n",
              "  0.6996,\n",
              "  0.7069,\n",
              "  0.7058,\n",
              "  0.7148,\n",
              "  0.7225,\n",
              "  0.7198,\n",
              "  0.7244,\n",
              "  0.7262,\n",
              "  0.7249,\n",
              "  0.7329,\n",
              "  0.7337,\n",
              "  0.7306,\n",
              "  0.7313],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.384081>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3046312>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1857129>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1126041>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0162807>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.946835>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8898092>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8546063>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8436053>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8295626>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8165286>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7893617>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7913693>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7886152>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.77888674>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7800217>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.77892697>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.771376>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.768428>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7757592>]}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGgplqnH-u3F"
      },
      "source": [
        "epochs = 30\n",
        "self_scaling_epochs = 20\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXZ6L4WZ-yP0",
        "outputId": "ad7c9cdd-25c4-41f2-e697-d89662c29885"
      },
      "source": [
        "%%time\n",
        "\n",
        "model = Sequential([\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None, fixed_size=True),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.981550693511963 - val_accuracy: 0.1077 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.9815502166748047 - val_accuracy: 0.1077 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.9397608041763306 - accuracy: 0.37282 - val_loss: 1.468695878982544 - val_accuracy: 0.4728 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.466652512550354 - val_accuracy: 0.4743 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 257], total units: 1025\n",
            "##########################################################\n",
            "Epoch 2/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.466652512550354 - val_accuracy: 0.4743 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 257], total units: 1025\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.466652512550354 - val_accuracy: 0.4743 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 308], total units: 1228\n",
            "Before pruning:\n",
            "loss: 1.4807912111282349 - accuracy: 0.46946 - val_loss: 1.2618108987808228 - val_accuracy: 0.546 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 308], total units: 1228\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.2617000341415405 - val_accuracy: 0.5454 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "##########################################################\n",
            "Epoch 3/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2617000341415405 - val_accuracy: 0.5454 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2616997957229614 - val_accuracy: 0.5454 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.3149170875549316 - accuracy: 0.52978 - val_loss: 1.1797462701797485 - val_accuracy: 0.5731 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1797510385513306 - val_accuracy: 0.5731 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 191, 192, 256], total units: 1023\n",
            "##########################################################\n",
            "Epoch 4/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1797510385513306 - val_accuracy: 0.5731 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 191, 192, 256], total units: 1023\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1797510385513306 - val_accuracy: 0.5731 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 229, 230, 307], total units: 1226\n",
            "Before pruning:\n",
            "loss: 1.2272284030914307 - accuracy: 0.56092 - val_loss: 1.118367075920105 - val_accuracy: 0.6004 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 229, 230, 307], total units: 1226\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1182119846343994 - val_accuracy: 0.6003 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 188, 182, 192, 256], total units: 1010\n",
            "##########################################################\n",
            "Epoch 5/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1182119846343994 - val_accuracy: 0.6003 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 188, 182, 192, 256], total units: 1010\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1182119846343994 - val_accuracy: 0.6003 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 225, 218, 230, 307], total units: 1210\n",
            "Before pruning:\n",
            "loss: 1.1295233964920044 - accuracy: 0.59674 - val_loss: 1.0207881927490234 - val_accuracy: 0.6397 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 225, 218, 230, 307], total units: 1210\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0207505226135254 - val_accuracy: 0.6398 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 144, 167, 196, 272], total units: 971\n",
            "##########################################################\n",
            "Epoch 6/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0207505226135254 - val_accuracy: 0.6398 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 144, 167, 196, 272], total units: 971\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0207505226135254 - val_accuracy: 0.6398 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 172, 200, 235, 326], total units: 1163\n",
            "Before pruning:\n",
            "loss: 1.0411803722381592 - accuracy: 0.6291 - val_loss: 0.9394251704216003 - val_accuracy: 0.6648 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 172, 200, 235, 326], total units: 1163\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9395999908447266 - val_accuracy: 0.6647 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 108, 146, 201, 272], total units: 919\n",
            "##########################################################\n",
            "Epoch 7/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9395999908447266 - val_accuracy: 0.6647 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 108, 146, 201, 272], total units: 919\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9395999312400818 - val_accuracy: 0.6647 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 129, 175, 241, 326], total units: 1101\n",
            "Before pruning:\n",
            "loss: 0.9616180658340454 - accuracy: 0.65746 - val_loss: 0.9002341032028198 - val_accuracy: 0.6833 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 129, 175, 241, 326], total units: 1101\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9000447392463684 - val_accuracy: 0.6835 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 90, 129, 210, 279], total units: 900\n",
            "##########################################################\n",
            "Epoch 8/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9000447392463684 - val_accuracy: 0.6835 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 90, 129, 210, 279], total units: 900\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9000446200370789 - val_accuracy: 0.6835 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 110, 154, 252, 334], total units: 1080\n",
            "Before pruning:\n",
            "loss: 0.902674674987793 - accuracy: 0.68116 - val_loss: 0.8729541301727295 - val_accuracy: 0.6905 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 110, 154, 252, 334], total units: 1080\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8726800680160522 - val_accuracy: 0.6903 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 84, 120, 216, 310], total units: 922\n",
            "##########################################################\n",
            "Epoch 9/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8726800680160522 - val_accuracy: 0.6903 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 84, 120, 216, 310], total units: 922\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8726800680160522 - val_accuracy: 0.6903 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 104, 144, 259, 372], total units: 1109\n",
            "Before pruning:\n",
            "loss: 0.8531241416931152 - accuracy: 0.69906 - val_loss: 0.831206738948822 - val_accuracy: 0.7087 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 104, 144, 259, 372], total units: 1109\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8309826254844666 - val_accuracy: 0.7089 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 70, 113, 222, 331], total units: 927\n",
            "##########################################################\n",
            "Epoch 10/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8309826254844666 - val_accuracy: 0.7089 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 70, 113, 222, 331], total units: 927\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8309826254844666 - val_accuracy: 0.7089 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 90, 135, 266, 397], total units: 1117\n",
            "Before pruning:\n",
            "loss: 0.8163864612579346 - accuracy: 0.7139 - val_loss: 0.824816107749939 - val_accuracy: 0.7106 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 90, 135, 266, 397], total units: 1117\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8248475790023804 - val_accuracy: 0.7106 - penalty: 1e-06\n",
            "hidden layer sizes: [188, 68, 104, 231, 308], total units: 899\n",
            "##########################################################\n",
            "Epoch 11/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8248475790023804 - val_accuracy: 0.7106 - penalty: 1e-06\n",
            "hidden layer sizes: [188, 68, 104, 231, 308], total units: 899\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8248475790023804 - val_accuracy: 0.7106 - penalty: 1e-06\n",
            "hidden layer sizes: [225, 88, 124, 277, 369], total units: 1083\n",
            "Before pruning:\n",
            "loss: 0.7877901792526245 - accuracy: 0.72248 - val_loss: 0.7913133502006531 - val_accuracy: 0.7224 - penalty: 1e-06\n",
            "hidden layer sizes: [225, 88, 124, 277, 369], total units: 1083\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7912328839302063 - val_accuracy: 0.7222 - penalty: 1e-06\n",
            "hidden layer sizes: [181, 68, 89, 238, 353], total units: 929\n",
            "##########################################################\n",
            "Epoch 12/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7912328839302063 - val_accuracy: 0.7222 - penalty: 1e-06\n",
            "hidden layer sizes: [181, 68, 89, 238, 353], total units: 929\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7912328839302063 - val_accuracy: 0.7222 - penalty: 1e-06\n",
            "hidden layer sizes: [217, 88, 109, 285, 423], total units: 1122\n",
            "Before pruning:\n",
            "loss: 0.762523353099823 - accuracy: 0.73294 - val_loss: 0.7897791266441345 - val_accuracy: 0.724 - penalty: 1e-06\n",
            "hidden layer sizes: [217, 88, 109, 285, 423], total units: 1122\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.789566159248352 - val_accuracy: 0.7238 - penalty: 1e-06\n",
            "hidden layer sizes: [181, 58, 90, 243, 316], total units: 888\n",
            "##########################################################\n",
            "Epoch 13/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.789566159248352 - val_accuracy: 0.7238 - penalty: 1e-06\n",
            "hidden layer sizes: [181, 58, 90, 243, 316], total units: 888\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.789566159248352 - val_accuracy: 0.7238 - penalty: 1e-06\n",
            "hidden layer sizes: [217, 78, 110, 291, 379], total units: 1075\n",
            "Before pruning:\n",
            "loss: 0.7492730617523193 - accuracy: 0.73312 - val_loss: 0.7913304567337036 - val_accuracy: 0.7189 - penalty: 1e-06\n",
            "hidden layer sizes: [217, 78, 110, 291, 379], total units: 1075\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.791149914264679 - val_accuracy: 0.7191 - penalty: 1e-06\n",
            "hidden layer sizes: [172, 58, 87, 259, 323], total units: 899\n",
            "##########################################################\n",
            "Epoch 14/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.791149914264679 - val_accuracy: 0.7191 - penalty: 1e-06\n",
            "hidden layer sizes: [172, 58, 87, 259, 323], total units: 899\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.791149914264679 - val_accuracy: 0.7191 - penalty: 1e-06\n",
            "hidden layer sizes: [206, 78, 107, 310, 387], total units: 1088\n",
            "Before pruning:\n",
            "loss: 0.726068377494812 - accuracy: 0.74564 - val_loss: 0.7764206528663635 - val_accuracy: 0.7293 - penalty: 1e-06\n",
            "hidden layer sizes: [206, 78, 107, 310, 387], total units: 1088\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7763060927391052 - val_accuracy: 0.7293 - penalty: 1e-06\n",
            "hidden layer sizes: [165, 57, 82, 259, 328], total units: 891\n",
            "##########################################################\n",
            "Epoch 15/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7763060927391052 - val_accuracy: 0.7293 - penalty: 1e-06\n",
            "hidden layer sizes: [165, 57, 82, 259, 328], total units: 891\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.77630615234375 - val_accuracy: 0.7293 - penalty: 1e-06\n",
            "hidden layer sizes: [198, 77, 102, 310, 393], total units: 1080\n",
            "Before pruning:\n",
            "loss: 0.7061242461204529 - accuracy: 0.75106 - val_loss: 0.7667677402496338 - val_accuracy: 0.7346 - penalty: 1e-06\n",
            "hidden layer sizes: [198, 77, 102, 310, 393], total units: 1080\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7667813301086426 - val_accuracy: 0.7347 - penalty: 1e-06\n",
            "hidden layer sizes: [156, 54, 80, 261, 315], total units: 866\n",
            "##########################################################\n",
            "Epoch 16/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7667813301086426 - val_accuracy: 0.7347 - penalty: 1e-06\n",
            "hidden layer sizes: [156, 54, 80, 261, 315], total units: 866\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7667813301086426 - val_accuracy: 0.7347 - penalty: 1e-06\n",
            "hidden layer sizes: [187, 74, 100, 313, 378], total units: 1052\n",
            "Before pruning:\n",
            "loss: 0.6909617185592651 - accuracy: 0.75636 - val_loss: 0.7694360613822937 - val_accuracy: 0.7301 - penalty: 1e-06\n",
            "hidden layer sizes: [187, 74, 100, 313, 378], total units: 1052\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7693437933921814 - val_accuracy: 0.7303 - penalty: 1e-06\n",
            "hidden layer sizes: [153, 51, 77, 261, 348], total units: 890\n",
            "##########################################################\n",
            "Epoch 17/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7693437933921814 - val_accuracy: 0.7303 - penalty: 1e-06\n",
            "hidden layer sizes: [153, 51, 77, 261, 348], total units: 890\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7693438529968262 - val_accuracy: 0.7303 - penalty: 1e-06\n",
            "hidden layer sizes: [183, 71, 97, 313, 417], total units: 1081\n",
            "Before pruning:\n",
            "loss: 0.6765366196632385 - accuracy: 0.76104 - val_loss: 0.7720710039138794 - val_accuracy: 0.7341 - penalty: 1e-06\n",
            "hidden layer sizes: [183, 71, 97, 313, 417], total units: 1081\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7719346284866333 - val_accuracy: 0.7341 - penalty: 1e-06\n",
            "hidden layer sizes: [149, 54, 77, 265, 391], total units: 936\n",
            "##########################################################\n",
            "Epoch 18/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7719346284866333 - val_accuracy: 0.7341 - penalty: 1e-06\n",
            "hidden layer sizes: [149, 54, 77, 265, 391], total units: 936\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7719345688819885 - val_accuracy: 0.7341 - penalty: 1e-06\n",
            "hidden layer sizes: [178, 74, 97, 318, 469], total units: 1136\n",
            "Before pruning:\n",
            "loss: 0.6684851050376892 - accuracy: 0.76466 - val_loss: 0.7688155174255371 - val_accuracy: 0.7322 - penalty: 1e-06\n",
            "hidden layer sizes: [178, 74, 97, 318, 469], total units: 1136\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7686088681221008 - val_accuracy: 0.7323 - penalty: 1e-06\n",
            "hidden layer sizes: [147, 50, 76, 261, 401], total units: 935\n",
            "##########################################################\n",
            "Epoch 19/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7686088681221008 - val_accuracy: 0.7323 - penalty: 1e-06\n",
            "hidden layer sizes: [147, 50, 76, 261, 401], total units: 935\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.768608808517456 - val_accuracy: 0.7323 - penalty: 1e-06\n",
            "hidden layer sizes: [176, 70, 96, 313, 481], total units: 1136\n",
            "Before pruning:\n",
            "loss: 0.6598419547080994 - accuracy: 0.76774 - val_loss: 0.7720143795013428 - val_accuracy: 0.7352 - penalty: 1e-06\n",
            "hidden layer sizes: [176, 70, 96, 313, 481], total units: 1136\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.771572470664978 - val_accuracy: 0.7351 - penalty: 1e-06\n",
            "hidden layer sizes: [135, 55, 78, 269, 434], total units: 971\n",
            "##########################################################\n",
            "Epoch 20/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.771572470664978 - val_accuracy: 0.7351 - penalty: 1e-06\n",
            "hidden layer sizes: [135, 55, 78, 269, 434], total units: 971\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7715725302696228 - val_accuracy: 0.7351 - penalty: 1e-06\n",
            "hidden layer sizes: [162, 75, 98, 322, 520], total units: 1177\n",
            "Before pruning:\n",
            "loss: 0.6403027772903442 - accuracy: 0.77302 - val_loss: 0.7476063370704651 - val_accuracy: 0.7417 - penalty: 1e-06\n",
            "hidden layer sizes: [162, 75, 98, 322, 520], total units: 1177\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7475026845932007 - val_accuracy: 0.7422 - penalty: 1e-06\n",
            "hidden layer sizes: [128, 47, 76, 261, 403], total units: 915\n",
            "##########################################################\n",
            "Epoch 21/30\n",
            "loss: 0.6905576586723328 - accuracy: 0.758 - val_loss: 0.7947068214416504 - val_accuracy: 0.7297 - penalty: 0.0\n",
            "hidden layer sizes: [128, 47, 76, 261, 403], total units: 915\n",
            "##########################################################\n",
            "Epoch 22/30\n",
            "loss: 0.5230312347412109 - accuracy: 0.81654 - val_loss: 0.7862727642059326 - val_accuracy: 0.7373 - penalty: 0.0\n",
            "hidden layer sizes: [128, 47, 76, 261, 403], total units: 915\n",
            "##########################################################\n",
            "Epoch 23/30\n",
            "loss: 0.437581866979599 - accuracy: 0.8445 - val_loss: 0.7970138788223267 - val_accuracy: 0.7428 - penalty: 0.0\n",
            "hidden layer sizes: [128, 47, 76, 261, 403], total units: 915\n",
            "##########################################################\n",
            "Epoch 24/30\n",
            "loss: 0.36869922280311584 - accuracy: 0.86788 - val_loss: 0.8064722418785095 - val_accuracy: 0.7444 - penalty: 0.0\n",
            "hidden layer sizes: [128, 47, 76, 261, 403], total units: 915\n",
            "##########################################################\n",
            "Epoch 25/30\n",
            "loss: 0.29893743991851807 - accuracy: 0.89448 - val_loss: 0.8496243953704834 - val_accuracy: 0.7471 - penalty: 0.0\n",
            "hidden layer sizes: [128, 47, 76, 261, 403], total units: 915\n",
            "##########################################################\n",
            "Epoch 26/30\n",
            "loss: 0.2373628318309784 - accuracy: 0.91586 - val_loss: 0.8795489072799683 - val_accuracy: 0.7501 - penalty: 0.0\n",
            "hidden layer sizes: [128, 47, 76, 261, 403], total units: 915\n",
            "##########################################################\n",
            "Epoch 27/30\n",
            "loss: 0.18967582285404205 - accuracy: 0.93244 - val_loss: 0.9448572993278503 - val_accuracy: 0.7454 - penalty: 0.0\n",
            "hidden layer sizes: [128, 47, 76, 261, 403], total units: 915\n",
            "##########################################################\n",
            "Epoch 28/30\n",
            "loss: 0.15700817108154297 - accuracy: 0.94524 - val_loss: 0.9655168652534485 - val_accuracy: 0.7461 - penalty: 0.0\n",
            "hidden layer sizes: [128, 47, 76, 261, 403], total units: 915\n",
            "##########################################################\n",
            "Epoch 29/30\n",
            "loss: 0.13683070242404938 - accuracy: 0.95218 - val_loss: 0.9902599453926086 - val_accuracy: 0.7479 - penalty: 0.0\n",
            "hidden layer sizes: [128, 47, 76, 261, 403], total units: 915\n",
            "##########################################################\n",
            "Epoch 30/30\n",
            "loss: 0.11411120742559433 - accuracy: 0.96046 - val_loss: 1.0252476930618286 - val_accuracy: 0.7496 - penalty: 0.0\n",
            "hidden layer sizes: [128, 47, 76, 261, 403], total units: 915\n",
            "CPU times: user 7min 27s, sys: 6.99 s, total: 7min 34s\n",
            "Wall time: 9min 19s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hK4EQfq6-tny"
      },
      "source": [
        "epochs = 20\n",
        "self_scaling_epochs = 20\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0z5bWkr98dk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b69fadc-acd4-4517-c8dc-e6469aac4ef2"
      },
      "source": [
        "model = Sequential([\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None, fixed_size=True),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.965449810028076 - val_accuracy: 0.0943 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.9654500484466553 - val_accuracy: 0.0943 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.9078271389007568 - accuracy: 0.38218 - val_loss: 1.427015781402588 - val_accuracy: 0.4892 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.426162838935852 - val_accuracy: 0.4891 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 261], total units: 1029\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.426162838935852 - val_accuracy: 0.4891 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 261], total units: 1029\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4261629581451416 - val_accuracy: 0.4891 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 313], total units: 1233\n",
            "Before pruning:\n",
            "loss: 1.4895902872085571 - accuracy: 0.47094 - val_loss: 1.263016700744629 - val_accuracy: 0.5462 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 313], total units: 1233\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.2628270387649536 - val_accuracy: 0.546 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2628270387649536 - val_accuracy: 0.546 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2628271579742432 - val_accuracy: 0.546 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.3357962369918823 - accuracy: 0.52314 - val_loss: 1.1886502504348755 - val_accuracy: 0.5717 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.188405990600586 - val_accuracy: 0.5719 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.188405990600586 - val_accuracy: 0.5719 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.188405990600586 - val_accuracy: 0.5719 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.2331066131591797 - accuracy: 0.56054 - val_loss: 1.107539415359497 - val_accuracy: 0.6053 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1074802875518799 - val_accuracy: 0.6056 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 184, 189, 192, 265], total units: 1022\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1074802875518799 - val_accuracy: 0.6056 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 184, 189, 192, 265], total units: 1022\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1074801683425903 - val_accuracy: 0.6056 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 220, 226, 230, 318], total units: 1224\n",
            "Before pruning:\n",
            "loss: 1.1451588869094849 - accuracy: 0.591 - val_loss: 1.029172420501709 - val_accuracy: 0.6346 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 220, 226, 230, 318], total units: 1224\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0291587114334106 - val_accuracy: 0.6349 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 144, 175, 192, 269], total units: 972\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0291587114334106 - val_accuracy: 0.6349 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 144, 175, 192, 269], total units: 972\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0291587114334106 - val_accuracy: 0.6349 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 172, 210, 230, 322], total units: 1164\n",
            "Before pruning:\n",
            "loss: 1.0575878620147705 - accuracy: 0.6224 - val_loss: 0.9810765385627747 - val_accuracy: 0.653 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 172, 210, 230, 322], total units: 1164\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9812194108963013 - val_accuracy: 0.6526 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 100, 164, 197, 259], total units: 912\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9812194108963013 - val_accuracy: 0.6526 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 100, 164, 197, 259], total units: 912\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9812195301055908 - val_accuracy: 0.6526 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 120, 196, 236, 310], total units: 1092\n",
            "Before pruning:\n",
            "loss: 0.9986783862113953 - accuracy: 0.64552 - val_loss: 0.923439621925354 - val_accuracy: 0.6735 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 120, 196, 236, 310], total units: 1092\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9232416152954102 - val_accuracy: 0.6736 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 80, 158, 199, 263], total units: 892\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9232416152954102 - val_accuracy: 0.6736 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 80, 158, 199, 263], total units: 892\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9232416152954102 - val_accuracy: 0.6736 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 100, 189, 238, 315], total units: 1072\n",
            "Before pruning:\n",
            "loss: 0.9431843757629395 - accuracy: 0.66534 - val_loss: 0.8951692581176758 - val_accuracy: 0.6828 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 100, 189, 238, 315], total units: 1072\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8949394822120667 - val_accuracy: 0.6831 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 74, 139, 209, 268], total units: 882\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8949394822120667 - val_accuracy: 0.6831 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 74, 139, 209, 268], total units: 882\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8949394822120667 - val_accuracy: 0.6831 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 94, 166, 250, 321], total units: 1061\n",
            "Before pruning:\n",
            "loss: 0.8991597890853882 - accuracy: 0.68246 - val_loss: 0.8602918982505798 - val_accuracy: 0.6969 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 94, 166, 250, 321], total units: 1061\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8602458238601685 - val_accuracy: 0.6968 - penalty: 1e-06\n",
            "hidden layer sizes: [190, 66, 127, 212, 268], total units: 863\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8602458238601685 - val_accuracy: 0.6968 - penalty: 1e-06\n",
            "hidden layer sizes: [190, 66, 127, 212, 268], total units: 863\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8602458238601685 - val_accuracy: 0.6968 - penalty: 1e-06\n",
            "hidden layer sizes: [228, 86, 152, 254, 321], total units: 1041\n",
            "Before pruning:\n",
            "loss: 0.8475485444068909 - accuracy: 0.69776 - val_loss: 0.8503279089927673 - val_accuracy: 0.7027 - penalty: 1e-06\n",
            "hidden layer sizes: [228, 86, 152, 254, 321], total units: 1041\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8499798774719238 - val_accuracy: 0.7032 - penalty: 1e-06\n",
            "hidden layer sizes: [188, 63, 122, 219, 279], total units: 871\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8499798774719238 - val_accuracy: 0.7032 - penalty: 1e-06\n",
            "hidden layer sizes: [188, 63, 122, 219, 279], total units: 871\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8499798774719238 - val_accuracy: 0.7032 - penalty: 1e-06\n",
            "hidden layer sizes: [225, 83, 146, 262, 334], total units: 1050\n",
            "Before pruning:\n",
            "loss: 0.8216924071311951 - accuracy: 0.71072 - val_loss: 0.8132625818252563 - val_accuracy: 0.7194 - penalty: 1e-06\n",
            "hidden layer sizes: [225, 83, 146, 262, 334], total units: 1050\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8130559921264648 - val_accuracy: 0.7192 - penalty: 1e-06\n",
            "hidden layer sizes: [184, 51, 101, 222, 299], total units: 857\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8130559921264648 - val_accuracy: 0.7192 - penalty: 1e-06\n",
            "hidden layer sizes: [184, 51, 101, 222, 299], total units: 857\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8130559325218201 - val_accuracy: 0.7192 - penalty: 1e-06\n",
            "hidden layer sizes: [220, 71, 121, 266, 358], total units: 1036\n",
            "Before pruning:\n",
            "loss: 0.7910312414169312 - accuracy: 0.71876 - val_loss: 0.8092338442802429 - val_accuracy: 0.7172 - penalty: 1e-06\n",
            "hidden layer sizes: [220, 71, 121, 266, 358], total units: 1036\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8090081214904785 - val_accuracy: 0.7178 - penalty: 1e-06\n",
            "hidden layer sizes: [176, 56, 93, 234, 338], total units: 897\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8090081214904785 - val_accuracy: 0.7178 - penalty: 1e-06\n",
            "hidden layer sizes: [176, 56, 93, 234, 338], total units: 897\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8090081214904785 - val_accuracy: 0.7178 - penalty: 1e-06\n",
            "hidden layer sizes: [211, 76, 113, 280, 405], total units: 1085\n",
            "Before pruning:\n",
            "loss: 0.7626461982727051 - accuracy: 0.73006 - val_loss: 0.7829939723014832 - val_accuracy: 0.73 - penalty: 1e-06\n",
            "hidden layer sizes: [211, 76, 113, 280, 405], total units: 1085\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7829059362411499 - val_accuracy: 0.73 - penalty: 1e-06\n",
            "hidden layer sizes: [171, 59, 91, 236, 338], total units: 895\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7829059362411499 - val_accuracy: 0.73 - penalty: 1e-06\n",
            "hidden layer sizes: [171, 59, 91, 236, 338], total units: 895\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7829058766365051 - val_accuracy: 0.73 - penalty: 1e-06\n",
            "hidden layer sizes: [205, 79, 111, 283, 405], total units: 1083\n",
            "Before pruning:\n",
            "loss: 0.747941255569458 - accuracy: 0.73512 - val_loss: 0.788496732711792 - val_accuracy: 0.7303 - penalty: 1e-06\n",
            "hidden layer sizes: [205, 79, 111, 283, 405], total units: 1083\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.788341224193573 - val_accuracy: 0.7305 - penalty: 1e-06\n",
            "hidden layer sizes: [167, 55, 86, 234, 337], total units: 879\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.788341224193573 - val_accuracy: 0.7305 - penalty: 1e-06\n",
            "hidden layer sizes: [167, 55, 86, 234, 337], total units: 879\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7883412837982178 - val_accuracy: 0.7305 - penalty: 1e-06\n",
            "hidden layer sizes: [200, 75, 106, 280, 404], total units: 1065\n",
            "Before pruning:\n",
            "loss: 0.7217869758605957 - accuracy: 0.7463 - val_loss: 0.7700600624084473 - val_accuracy: 0.7306 - penalty: 1e-06\n",
            "hidden layer sizes: [200, 75, 106, 280, 404], total units: 1065\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7700117826461792 - val_accuracy: 0.7305 - penalty: 1e-06\n",
            "hidden layer sizes: [159, 47, 84, 236, 366], total units: 892\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7700117826461792 - val_accuracy: 0.7305 - penalty: 1e-06\n",
            "hidden layer sizes: [159, 47, 84, 236, 366], total units: 892\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.770011842250824 - val_accuracy: 0.7305 - penalty: 1e-06\n",
            "hidden layer sizes: [190, 67, 104, 283, 439], total units: 1083\n",
            "Before pruning:\n",
            "loss: 0.7126347422599792 - accuracy: 0.74762 - val_loss: 0.7778818607330322 - val_accuracy: 0.7315 - penalty: 1e-06\n",
            "hidden layer sizes: [190, 67, 104, 283, 439], total units: 1083\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7775612473487854 - val_accuracy: 0.7315 - penalty: 1e-06\n",
            "hidden layer sizes: [156, 49, 85, 239, 374], total units: 903\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7775612473487854 - val_accuracy: 0.7315 - penalty: 1e-06\n",
            "hidden layer sizes: [156, 49, 85, 239, 374], total units: 903\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7775613069534302 - val_accuracy: 0.7315 - penalty: 1e-06\n",
            "hidden layer sizes: [187, 69, 105, 286, 448], total units: 1095\n",
            "Before pruning:\n",
            "loss: 0.6926641464233398 - accuracy: 0.75674 - val_loss: 0.7840036153793335 - val_accuracy: 0.7295 - penalty: 1e-06\n",
            "hidden layer sizes: [187, 69, 105, 286, 448], total units: 1095\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7838205695152283 - val_accuracy: 0.7297 - penalty: 1e-06\n",
            "hidden layer sizes: [142, 44, 86, 242, 366], total units: 880\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7838205695152283 - val_accuracy: 0.7297 - penalty: 1e-06\n",
            "hidden layer sizes: [142, 44, 86, 242, 366], total units: 880\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7838205099105835 - val_accuracy: 0.7297 - penalty: 1e-06\n",
            "hidden layer sizes: [170, 64, 106, 290, 439], total units: 1069\n",
            "Before pruning:\n",
            "loss: 0.6821691393852234 - accuracy: 0.75832 - val_loss: 0.7603672742843628 - val_accuracy: 0.7394 - penalty: 1e-06\n",
            "hidden layer sizes: [170, 64, 106, 290, 439], total units: 1069\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7601619958877563 - val_accuracy: 0.7399 - penalty: 1e-06\n",
            "hidden layer sizes: [135, 46, 80, 242, 395], total units: 898\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7601619958877563 - val_accuracy: 0.7399 - penalty: 1e-06\n",
            "hidden layer sizes: [135, 46, 80, 242, 395], total units: 898\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7601619362831116 - val_accuracy: 0.7399 - penalty: 1e-06\n",
            "hidden layer sizes: [162, 66, 100, 290, 474], total units: 1092\n",
            "Before pruning:\n",
            "loss: 0.6606719493865967 - accuracy: 0.7673 - val_loss: 0.7607381343841553 - val_accuracy: 0.7379 - penalty: 1e-06\n",
            "hidden layer sizes: [162, 66, 100, 290, 474], total units: 1092\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7606223225593567 - val_accuracy: 0.7381 - penalty: 1e-06\n",
            "hidden layer sizes: [131, 45, 85, 241, 433], total units: 935\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7606223225593567 - val_accuracy: 0.7381 - penalty: 1e-06\n",
            "hidden layer sizes: [131, 45, 85, 241, 433], total units: 935\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7606223821640015 - val_accuracy: 0.7381 - penalty: 1e-06\n",
            "hidden layer sizes: [157, 65, 105, 289, 519], total units: 1135\n",
            "Before pruning:\n",
            "loss: 0.651715099811554 - accuracy: 0.76898 - val_loss: 0.7393239736557007 - val_accuracy: 0.7467 - penalty: 1e-06\n",
            "hidden layer sizes: [157, 65, 105, 289, 519], total units: 1135\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7391284108161926 - val_accuracy: 0.7462 - penalty: 1e-06\n",
            "hidden layer sizes: [130, 45, 88, 244, 434], total units: 941\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.38218,\n",
              "  0.47094,\n",
              "  0.52314,\n",
              "  0.56054,\n",
              "  0.591,\n",
              "  0.6224,\n",
              "  0.64552,\n",
              "  0.66534,\n",
              "  0.68246,\n",
              "  0.69776,\n",
              "  0.71072,\n",
              "  0.71876,\n",
              "  0.73006,\n",
              "  0.73512,\n",
              "  0.7463,\n",
              "  0.74762,\n",
              "  0.75674,\n",
              "  0.75832,\n",
              "  0.7673,\n",
              "  0.76898],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.9078271>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4895903>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3357962>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2331066>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1451589>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0575879>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9986784>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9431844>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8991598>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.84754854>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8216924>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.79103124>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7626462>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.74794126>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.721787>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.71263474>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.69266415>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.68216914>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.66067195>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6517151>],\n",
              " 'val_accuracy': [0.4891,\n",
              "  0.546,\n",
              "  0.5719,\n",
              "  0.6056,\n",
              "  0.6349,\n",
              "  0.6526,\n",
              "  0.6736,\n",
              "  0.6831,\n",
              "  0.6968,\n",
              "  0.7032,\n",
              "  0.7192,\n",
              "  0.7178,\n",
              "  0.73,\n",
              "  0.7305,\n",
              "  0.7305,\n",
              "  0.7315,\n",
              "  0.7297,\n",
              "  0.7399,\n",
              "  0.7381,\n",
              "  0.7462],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.4261628>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.262827>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.188406>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1074803>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0291587>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9812194>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9232416>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8949395>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8602458>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8499799>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.813056>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8090081>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.78290594>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7883412>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7700118>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.77756125>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.78382057>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.760162>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7606223>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7391284>]}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tBv3VFqCRVs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46674f2e-2f54-4201-c93c-ad179a9efd8e"
      },
      "source": [
        "model = Sequential([\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None, fixed_size=True),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.840655565261841 - val_accuracy: 0.1002 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.84065580368042 - val_accuracy: 0.1002 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.9883681535720825 - accuracy: 0.36158 - val_loss: 1.4862158298492432 - val_accuracy: 0.476 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4863176345825195 - val_accuracy: 0.4759 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4863176345825195 - val_accuracy: 0.4759 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4863176345825195 - val_accuracy: 0.4759 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.526109218597412 - accuracy: 0.4584 - val_loss: 1.3053607940673828 - val_accuracy: 0.5293 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.3052390813827515 - val_accuracy: 0.53 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.3052390813827515 - val_accuracy: 0.53 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.305239200592041 - val_accuracy: 0.53 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.341887354850769 - accuracy: 0.52154 - val_loss: 1.2112756967544556 - val_accuracy: 0.5627 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.2109817266464233 - val_accuracy: 0.5624 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2109817266464233 - val_accuracy: 0.5624 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2109817266464233 - val_accuracy: 0.5624 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.2322930097579956 - accuracy: 0.55994 - val_loss: 1.1409339904785156 - val_accuracy: 0.5877 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1409472227096558 - val_accuracy: 0.5877 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1409472227096558 - val_accuracy: 0.5877 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1409472227096558 - val_accuracy: 0.5877 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.1574097871780396 - accuracy: 0.58706 - val_loss: 1.0995608568191528 - val_accuracy: 0.6056 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0991530418395996 - val_accuracy: 0.6058 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 191, 192, 256], total units: 1023\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0991530418395996 - val_accuracy: 0.6058 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 191, 192, 256], total units: 1023\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0991530418395996 - val_accuracy: 0.6058 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 229, 230, 307], total units: 1226\n",
            "Before pruning:\n",
            "loss: 1.081053614616394 - accuracy: 0.61628 - val_loss: 1.0199790000915527 - val_accuracy: 0.6364 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 229, 230, 307], total units: 1226\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.019527792930603 - val_accuracy: 0.6365 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 169, 172, 192, 256], total units: 981\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.019527792930603 - val_accuracy: 0.6365 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 169, 172, 192, 256], total units: 981\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.019527554512024 - val_accuracy: 0.6365 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 202, 206, 230, 307], total units: 1175\n",
            "Before pruning:\n",
            "loss: 0.9990887641906738 - accuracy: 0.64598 - val_loss: 0.9820299744606018 - val_accuracy: 0.6491 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 202, 206, 230, 307], total units: 1175\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9819338917732239 - val_accuracy: 0.6489 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 137, 155, 191, 256], total units: 931\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9819338917732239 - val_accuracy: 0.6489 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 137, 155, 191, 256], total units: 931\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9819337725639343 - val_accuracy: 0.6489 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 164, 186, 229, 307], total units: 1116\n",
            "Before pruning:\n",
            "loss: 0.9280332922935486 - accuracy: 0.67044 - val_loss: 0.914259672164917 - val_accuracy: 0.6777 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 164, 186, 229, 307], total units: 1116\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9142920970916748 - val_accuracy: 0.6773 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 112, 140, 190, 256], total units: 890\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9142920970916748 - val_accuracy: 0.6773 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 112, 140, 190, 256], total units: 890\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9142920970916748 - val_accuracy: 0.6773 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 134, 168, 228, 307], total units: 1067\n",
            "Before pruning:\n",
            "loss: 0.8665342926979065 - accuracy: 0.69346 - val_loss: 0.877951979637146 - val_accuracy: 0.6883 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 134, 168, 228, 307], total units: 1067\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8776419162750244 - val_accuracy: 0.6883 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 100, 127, 192, 256], total units: 867\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8776419162750244 - val_accuracy: 0.6883 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 100, 127, 192, 256], total units: 867\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8776419758796692 - val_accuracy: 0.6883 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 120, 152, 230, 307], total units: 1039\n",
            "Before pruning:\n",
            "loss: 0.812792956829071 - accuracy: 0.7153 - val_loss: 0.8443649411201477 - val_accuracy: 0.7006 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 120, 152, 230, 307], total units: 1039\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8443865180015564 - val_accuracy: 0.7008 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 90, 119, 191, 260], total units: 852\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8443865180015564 - val_accuracy: 0.7008 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 90, 119, 191, 260], total units: 852\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8443865180015564 - val_accuracy: 0.7008 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 110, 142, 229, 312], total units: 1023\n",
            "Before pruning:\n",
            "loss: 0.7686486840248108 - accuracy: 0.72814 - val_loss: 0.824310839176178 - val_accuracy: 0.711 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 110, 142, 229, 312], total units: 1023\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8240812420845032 - val_accuracy: 0.7112 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 78, 109, 190, 266], total units: 835\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8240812420845032 - val_accuracy: 0.7112 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 78, 109, 190, 266], total units: 835\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8240812420845032 - val_accuracy: 0.7112 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 98, 130, 228, 319], total units: 1005\n",
            "Before pruning:\n",
            "loss: 0.7316874861717224 - accuracy: 0.7413 - val_loss: 0.8030737638473511 - val_accuracy: 0.718 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 98, 130, 228, 319], total units: 1005\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8030152916908264 - val_accuracy: 0.718 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 75, 103, 191, 261], total units: 822\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8030152916908264 - val_accuracy: 0.718 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 75, 103, 191, 261], total units: 822\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8030153512954712 - val_accuracy: 0.718 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 95, 123, 229, 313], total units: 990\n",
            "Before pruning:\n",
            "loss: 0.7004841566085815 - accuracy: 0.75176 - val_loss: 0.7907684445381165 - val_accuracy: 0.7236 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 95, 123, 229, 313], total units: 990\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7906835675239563 - val_accuracy: 0.7235 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 68, 96, 192, 262], total units: 810\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7906835675239563 - val_accuracy: 0.7235 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 68, 96, 192, 262], total units: 810\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7906835675239563 - val_accuracy: 0.7235 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 88, 116, 230, 314], total units: 978\n",
            "Before pruning:\n",
            "loss: 0.6733863949775696 - accuracy: 0.76094 - val_loss: 0.7818681597709656 - val_accuracy: 0.7237 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 88, 116, 230, 314], total units: 978\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7817997336387634 - val_accuracy: 0.7236 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 61, 90, 191, 266], total units: 800\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7817997336387634 - val_accuracy: 0.7236 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 61, 90, 191, 266], total units: 800\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7817997336387634 - val_accuracy: 0.7236 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 81, 110, 229, 319], total units: 969\n",
            "Before pruning:\n",
            "loss: 0.6478533744812012 - accuracy: 0.77142 - val_loss: 0.7860833406448364 - val_accuracy: 0.7273 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 81, 110, 229, 319], total units: 969\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.786094069480896 - val_accuracy: 0.7273 - penalty: 1e-06\n",
            "hidden layer sizes: [190, 61, 86, 193, 271], total units: 801\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.786094069480896 - val_accuracy: 0.7273 - penalty: 1e-06\n",
            "hidden layer sizes: [190, 61, 86, 193, 271], total units: 801\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7860941290855408 - val_accuracy: 0.7273 - penalty: 1e-06\n",
            "hidden layer sizes: [228, 81, 106, 231, 325], total units: 971\n",
            "Before pruning:\n",
            "loss: 0.6264689564704895 - accuracy: 0.77972 - val_loss: 0.7853912115097046 - val_accuracy: 0.7256 - penalty: 1e-06\n",
            "hidden layer sizes: [228, 81, 106, 231, 325], total units: 971\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7853613495826721 - val_accuracy: 0.7256 - penalty: 1e-06\n",
            "hidden layer sizes: [190, 62, 82, 191, 268], total units: 793\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7853613495826721 - val_accuracy: 0.7256 - penalty: 1e-06\n",
            "hidden layer sizes: [190, 62, 82, 191, 268], total units: 793\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7853613495826721 - val_accuracy: 0.7256 - penalty: 1e-06\n",
            "hidden layer sizes: [228, 82, 102, 229, 321], total units: 962\n",
            "Before pruning:\n",
            "loss: 0.6101464629173279 - accuracy: 0.78484 - val_loss: 0.780669629573822 - val_accuracy: 0.7258 - penalty: 1e-06\n",
            "hidden layer sizes: [228, 82, 102, 229, 321], total units: 962\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7803981304168701 - val_accuracy: 0.7259 - penalty: 1e-06\n",
            "hidden layer sizes: [188, 56, 81, 191, 268], total units: 784\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7803981304168701 - val_accuracy: 0.7259 - penalty: 1e-06\n",
            "hidden layer sizes: [188, 56, 81, 191, 268], total units: 784\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7803981304168701 - val_accuracy: 0.7259 - penalty: 1e-06\n",
            "hidden layer sizes: [225, 76, 101, 229, 321], total units: 952\n",
            "Before pruning:\n",
            "loss: 0.5904771685600281 - accuracy: 0.79202 - val_loss: 0.7718416452407837 - val_accuracy: 0.7303 - penalty: 1e-06\n",
            "hidden layer sizes: [225, 76, 101, 229, 321], total units: 952\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7717891931533813 - val_accuracy: 0.7302 - penalty: 1e-06\n",
            "hidden layer sizes: [182, 56, 79, 197, 280], total units: 794\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7717891931533813 - val_accuracy: 0.7302 - penalty: 1e-06\n",
            "hidden layer sizes: [182, 56, 79, 197, 280], total units: 794\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7717891335487366 - val_accuracy: 0.7302 - penalty: 1e-06\n",
            "hidden layer sizes: [218, 76, 99, 236, 336], total units: 965\n",
            "Before pruning:\n",
            "loss: 0.5727397799491882 - accuracy: 0.79806 - val_loss: 0.7796993255615234 - val_accuracy: 0.7292 - penalty: 1e-06\n",
            "hidden layer sizes: [218, 76, 99, 236, 336], total units: 965\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7791340947151184 - val_accuracy: 0.7287 - penalty: 1e-06\n",
            "hidden layer sizes: [177, 54, 73, 196, 274], total units: 774\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7791340947151184 - val_accuracy: 0.7287 - penalty: 1e-06\n",
            "hidden layer sizes: [177, 54, 73, 196, 274], total units: 774\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7791340947151184 - val_accuracy: 0.7287 - penalty: 1e-06\n",
            "hidden layer sizes: [212, 74, 93, 235, 328], total units: 942\n",
            "Before pruning:\n",
            "loss: 0.5618031024932861 - accuracy: 0.80034 - val_loss: 0.7752525210380554 - val_accuracy: 0.7357 - penalty: 1e-06\n",
            "hidden layer sizes: [212, 74, 93, 235, 328], total units: 942\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7751069068908691 - val_accuracy: 0.7361 - penalty: 1e-06\n",
            "hidden layer sizes: [174, 54, 71, 200, 279], total units: 778\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.36158,\n",
              "  0.4584,\n",
              "  0.52154,\n",
              "  0.55994,\n",
              "  0.58706,\n",
              "  0.61628,\n",
              "  0.64598,\n",
              "  0.67044,\n",
              "  0.69346,\n",
              "  0.7153,\n",
              "  0.72814,\n",
              "  0.7413,\n",
              "  0.75176,\n",
              "  0.76094,\n",
              "  0.77142,\n",
              "  0.77972,\n",
              "  0.78484,\n",
              "  0.79202,\n",
              "  0.79806,\n",
              "  0.80034],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.9883682>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.5261092>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3418874>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.232293>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1574098>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0810536>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.99908876>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9280333>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8665343>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.81279296>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7686487>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7316875>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.70048416>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6733864>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6478534>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.62646896>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.61014646>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.59047717>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5727398>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5618031>],\n",
              " 'val_accuracy': [0.4759,\n",
              "  0.53,\n",
              "  0.5624,\n",
              "  0.5877,\n",
              "  0.6058,\n",
              "  0.6365,\n",
              "  0.6489,\n",
              "  0.6773,\n",
              "  0.6883,\n",
              "  0.7008,\n",
              "  0.7112,\n",
              "  0.718,\n",
              "  0.7235,\n",
              "  0.7236,\n",
              "  0.7273,\n",
              "  0.7256,\n",
              "  0.7259,\n",
              "  0.7302,\n",
              "  0.7287,\n",
              "  0.7361],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.4863176>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3052391>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2109817>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1409472>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.099153>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0195278>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9819339>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9142921>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8776419>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8443865>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.82408124>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8030153>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.79068357>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.78179973>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.78609407>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.78536135>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.78039813>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7717892>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7791341>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7751069>]}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdlIlwQIFPaL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e07c8bfd-f6f1-471f-a7af-06d568e77ad4"
      },
      "source": [
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7751069068908691 - val_accuracy: 0.7361 - penalty: 1e-06\n",
            "hidden layer sizes: [174, 54, 71, 200, 279], total units: 778\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7751069664955139 - val_accuracy: 0.7361 - penalty: 1e-06\n",
            "hidden layer sizes: [208, 74, 91, 240, 334], total units: 947\n",
            "Before pruning:\n",
            "loss: 0.5426346063613892 - accuracy: 0.80752 - val_loss: 0.7737799882888794 - val_accuracy: 0.7273 - penalty: 1e-06\n",
            "hidden layer sizes: [208, 74, 91, 240, 334], total units: 947\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7737587690353394 - val_accuracy: 0.7271 - penalty: 1e-06\n",
            "hidden layer sizes: [168, 52, 68, 196, 273], total units: 757\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7737587690353394 - val_accuracy: 0.7271 - penalty: 1e-06\n",
            "hidden layer sizes: [168, 52, 68, 196, 273], total units: 757\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7737588286399841 - val_accuracy: 0.7271 - penalty: 1e-06\n",
            "hidden layer sizes: [201, 72, 88, 235, 327], total units: 923\n",
            "Before pruning:\n",
            "loss: 0.5328280329704285 - accuracy: 0.80988 - val_loss: 0.7777541279792786 - val_accuracy: 0.734 - penalty: 1e-06\n",
            "hidden layer sizes: [201, 72, 88, 235, 327], total units: 923\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.777652382850647 - val_accuracy: 0.7343 - penalty: 1e-06\n",
            "hidden layer sizes: [164, 53, 68, 205, 301], total units: 791\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.777652382850647 - val_accuracy: 0.7343 - penalty: 1e-06\n",
            "hidden layer sizes: [164, 53, 68, 205, 301], total units: 791\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7776523232460022 - val_accuracy: 0.7343 - penalty: 1e-06\n",
            "hidden layer sizes: [196, 73, 88, 246, 361], total units: 964\n",
            "Before pruning:\n",
            "loss: 0.5252960920333862 - accuracy: 0.81346 - val_loss: 0.7779180407524109 - val_accuracy: 0.7349 - penalty: 1e-06\n",
            "hidden layer sizes: [196, 73, 88, 246, 361], total units: 964\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7780272364616394 - val_accuracy: 0.7349 - penalty: 1e-06\n",
            "hidden layer sizes: [163, 52, 67, 200, 288], total units: 770\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7780272364616394 - val_accuracy: 0.7349 - penalty: 1e-06\n",
            "hidden layer sizes: [163, 52, 67, 200, 288], total units: 770\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7780271768569946 - val_accuracy: 0.7349 - penalty: 1e-06\n",
            "hidden layer sizes: [195, 72, 87, 240, 345], total units: 939\n",
            "Before pruning:\n",
            "loss: 0.5142058730125427 - accuracy: 0.8191 - val_loss: 0.7818767428398132 - val_accuracy: 0.7315 - penalty: 1e-06\n",
            "hidden layer sizes: [195, 72, 87, 240, 345], total units: 939\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7818840146064758 - val_accuracy: 0.7315 - penalty: 1e-06\n",
            "hidden layer sizes: [161, 52, 65, 208, 301], total units: 787\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7818840146064758 - val_accuracy: 0.7315 - penalty: 1e-06\n",
            "hidden layer sizes: [161, 52, 65, 208, 301], total units: 787\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7818840742111206 - val_accuracy: 0.7315 - penalty: 1e-06\n",
            "hidden layer sizes: [193, 72, 85, 249, 361], total units: 960\n",
            "Before pruning:\n",
            "loss: 0.503919243812561 - accuracy: 0.82134 - val_loss: 0.7824618816375732 - val_accuracy: 0.7312 - penalty: 1e-06\n",
            "hidden layer sizes: [193, 72, 85, 249, 361], total units: 960\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7824063301086426 - val_accuracy: 0.7312 - penalty: 1e-06\n",
            "hidden layer sizes: [157, 51, 65, 212, 308], total units: 793\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7824063301086426 - val_accuracy: 0.7312 - penalty: 1e-06\n",
            "hidden layer sizes: [157, 51, 65, 212, 308], total units: 793\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7824063301086426 - val_accuracy: 0.7312 - penalty: 1e-06\n",
            "hidden layer sizes: [188, 71, 85, 254, 369], total units: 967\n",
            "Before pruning:\n",
            "loss: 0.4920761287212372 - accuracy: 0.8247 - val_loss: 0.7799797058105469 - val_accuracy: 0.7349 - penalty: 1e-06\n",
            "hidden layer sizes: [188, 71, 85, 254, 369], total units: 967\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7798812985420227 - val_accuracy: 0.7347 - penalty: 1e-06\n",
            "hidden layer sizes: [150, 51, 62, 212, 284], total units: 759\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7798812985420227 - val_accuracy: 0.7347 - penalty: 1e-06\n",
            "hidden layer sizes: [150, 51, 62, 212, 284], total units: 759\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7798811793327332 - val_accuracy: 0.7347 - penalty: 1e-06\n",
            "hidden layer sizes: [180, 71, 82, 254, 340], total units: 927\n",
            "Before pruning:\n",
            "loss: 0.48363596200942993 - accuracy: 0.82708 - val_loss: 0.7864531874656677 - val_accuracy: 0.7367 - penalty: 1e-06\n",
            "hidden layer sizes: [180, 71, 82, 254, 340], total units: 927\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7863690853118896 - val_accuracy: 0.7368 - penalty: 1e-06\n",
            "hidden layer sizes: [150, 52, 62, 212, 292], total units: 768\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7863690853118896 - val_accuracy: 0.7368 - penalty: 1e-06\n",
            "hidden layer sizes: [150, 52, 62, 212, 292], total units: 768\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7863691449165344 - val_accuracy: 0.7368 - penalty: 1e-06\n",
            "hidden layer sizes: [180, 72, 82, 254, 350], total units: 938\n",
            "Before pruning:\n",
            "loss: 0.47302472591400146 - accuracy: 0.83188 - val_loss: 0.7918798923492432 - val_accuracy: 0.7347 - penalty: 1e-06\n",
            "hidden layer sizes: [180, 72, 82, 254, 350], total units: 938\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7916135787963867 - val_accuracy: 0.7354 - penalty: 1e-06\n",
            "hidden layer sizes: [144, 54, 62, 205, 300], total units: 765\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7916135787963867 - val_accuracy: 0.7354 - penalty: 1e-06\n",
            "hidden layer sizes: [144, 54, 62, 205, 300], total units: 765\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7916135787963867 - val_accuracy: 0.7354 - penalty: 1e-06\n",
            "hidden layer sizes: [172, 74, 82, 246, 360], total units: 934\n",
            "Before pruning:\n",
            "loss: 0.4719679653644562 - accuracy: 0.83242 - val_loss: 0.7959504127502441 - val_accuracy: 0.735 - penalty: 1e-06\n",
            "hidden layer sizes: [172, 74, 82, 246, 360], total units: 934\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.795958936214447 - val_accuracy: 0.7346 - penalty: 1e-06\n",
            "hidden layer sizes: [140, 51, 61, 210, 310], total units: 772\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.795958936214447 - val_accuracy: 0.7346 - penalty: 1e-06\n",
            "hidden layer sizes: [140, 51, 61, 210, 310], total units: 772\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7959590554237366 - val_accuracy: 0.7346 - penalty: 1e-06\n",
            "hidden layer sizes: [168, 71, 81, 252, 372], total units: 944\n",
            "Before pruning:\n",
            "loss: 0.4619728922843933 - accuracy: 0.83558 - val_loss: 0.7854200601577759 - val_accuracy: 0.7372 - penalty: 1e-06\n",
            "hidden layer sizes: [168, 71, 81, 252, 372], total units: 944\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7852558493614197 - val_accuracy: 0.737 - penalty: 1e-06\n",
            "hidden layer sizes: [137, 53, 61, 216, 279], total units: 746\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7852558493614197 - val_accuracy: 0.737 - penalty: 1e-06\n",
            "hidden layer sizes: [137, 53, 61, 216, 279], total units: 746\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7852558493614197 - val_accuracy: 0.737 - penalty: 1e-06\n",
            "hidden layer sizes: [164, 73, 81, 259, 334], total units: 911\n",
            "Before pruning:\n",
            "loss: 0.45086032152175903 - accuracy: 0.83914 - val_loss: 0.7889162302017212 - val_accuracy: 0.7364 - penalty: 1e-06\n",
            "hidden layer sizes: [164, 73, 81, 259, 334], total units: 911\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7889137864112854 - val_accuracy: 0.7367 - penalty: 1e-06\n",
            "hidden layer sizes: [131, 50, 57, 208, 281], total units: 727\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7889137864112854 - val_accuracy: 0.7367 - penalty: 1e-06\n",
            "hidden layer sizes: [131, 50, 57, 208, 281], total units: 727\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7889138460159302 - val_accuracy: 0.7367 - penalty: 1e-06\n",
            "hidden layer sizes: [157, 70, 77, 249, 337], total units: 890\n",
            "Before pruning:\n",
            "loss: 0.4474680721759796 - accuracy: 0.84106 - val_loss: 0.789192795753479 - val_accuracy: 0.7345 - penalty: 1e-06\n",
            "hidden layer sizes: [157, 70, 77, 249, 337], total units: 890\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7891157269477844 - val_accuracy: 0.7344 - penalty: 1e-06\n",
            "hidden layer sizes: [128, 57, 57, 215, 310], total units: 767\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7891157269477844 - val_accuracy: 0.7344 - penalty: 1e-06\n",
            "hidden layer sizes: [128, 57, 57, 215, 310], total units: 767\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7891157865524292 - val_accuracy: 0.7344 - penalty: 1e-06\n",
            "hidden layer sizes: [153, 77, 77, 258, 372], total units: 937\n",
            "Before pruning:\n",
            "loss: 0.44540679454803467 - accuracy: 0.84198 - val_loss: 0.7925061583518982 - val_accuracy: 0.7376 - penalty: 1e-06\n",
            "hidden layer sizes: [153, 77, 77, 258, 372], total units: 937\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7924822568893433 - val_accuracy: 0.7377 - penalty: 1e-06\n",
            "hidden layer sizes: [125, 50, 61, 216, 331], total units: 783\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7924822568893433 - val_accuracy: 0.7377 - penalty: 1e-06\n",
            "hidden layer sizes: [125, 50, 61, 216, 331], total units: 783\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.792482316493988 - val_accuracy: 0.7377 - penalty: 1e-06\n",
            "hidden layer sizes: [150, 70, 81, 259, 397], total units: 957\n",
            "Before pruning:\n",
            "loss: 0.43666866421699524 - accuracy: 0.84404 - val_loss: 0.8057506084442139 - val_accuracy: 0.7326 - penalty: 1e-06\n",
            "hidden layer sizes: [150, 70, 81, 259, 397], total units: 957\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8053776621818542 - val_accuracy: 0.7328 - penalty: 1e-06\n",
            "hidden layer sizes: [124, 52, 58, 213, 330], total units: 777\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8053776621818542 - val_accuracy: 0.7328 - penalty: 1e-06\n",
            "hidden layer sizes: [124, 52, 58, 213, 330], total units: 777\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8053776621818542 - val_accuracy: 0.7328 - penalty: 1e-06\n",
            "hidden layer sizes: [148, 72, 78, 255, 396], total units: 949\n",
            "Before pruning:\n",
            "loss: 0.4306914508342743 - accuracy: 0.84692 - val_loss: 0.789804220199585 - val_accuracy: 0.7399 - penalty: 1e-06\n",
            "hidden layer sizes: [148, 72, 78, 255, 396], total units: 949\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7897264957427979 - val_accuracy: 0.7397 - penalty: 1e-06\n",
            "hidden layer sizes: [116, 54, 57, 210, 286], total units: 723\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7897264957427979 - val_accuracy: 0.7397 - penalty: 1e-06\n",
            "hidden layer sizes: [116, 54, 57, 210, 286], total units: 723\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7897264361381531 - val_accuracy: 0.7397 - penalty: 1e-06\n",
            "hidden layer sizes: [139, 74, 77, 252, 343], total units: 885\n",
            "Before pruning:\n",
            "loss: 0.4283207356929779 - accuracy: 0.84924 - val_loss: 0.805580198764801 - val_accuracy: 0.7356 - penalty: 1e-06\n",
            "hidden layer sizes: [139, 74, 77, 252, 343], total units: 885\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.805504560470581 - val_accuracy: 0.7356 - penalty: 1e-06\n",
            "hidden layer sizes: [116, 51, 59, 221, 316], total units: 763\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.805504560470581 - val_accuracy: 0.7356 - penalty: 1e-06\n",
            "hidden layer sizes: [116, 51, 59, 221, 316], total units: 763\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.805504560470581 - val_accuracy: 0.7356 - penalty: 1e-06\n",
            "hidden layer sizes: [139, 71, 79, 265, 379], total units: 933\n",
            "Before pruning:\n",
            "loss: 0.42126989364624023 - accuracy: 0.84984 - val_loss: 0.8015350699424744 - val_accuracy: 0.738 - penalty: 1e-06\n",
            "hidden layer sizes: [139, 71, 79, 265, 379], total units: 933\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8013960719108582 - val_accuracy: 0.7377 - penalty: 1e-06\n",
            "hidden layer sizes: [113, 52, 54, 220, 330], total units: 769\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8013960719108582 - val_accuracy: 0.7377 - penalty: 1e-06\n",
            "hidden layer sizes: [113, 52, 54, 220, 330], total units: 769\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8013960719108582 - val_accuracy: 0.7377 - penalty: 1e-06\n",
            "hidden layer sizes: [135, 72, 74, 264, 396], total units: 941\n",
            "Before pruning:\n",
            "loss: 0.41100624203681946 - accuracy: 0.85484 - val_loss: 0.800648033618927 - val_accuracy: 0.7427 - penalty: 1e-06\n",
            "hidden layer sizes: [135, 72, 74, 264, 396], total units: 941\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8006948828697205 - val_accuracy: 0.7424 - penalty: 1e-06\n",
            "hidden layer sizes: [110, 49, 52, 208, 317], total units: 736\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8006948828697205 - val_accuracy: 0.7424 - penalty: 1e-06\n",
            "hidden layer sizes: [110, 49, 52, 208, 317], total units: 736\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8006948232650757 - val_accuracy: 0.7424 - penalty: 1e-06\n",
            "hidden layer sizes: [132, 69, 72, 249, 380], total units: 902\n",
            "Before pruning:\n",
            "loss: 0.40971723198890686 - accuracy: 0.8535 - val_loss: 0.7981252074241638 - val_accuracy: 0.7404 - penalty: 1e-06\n",
            "hidden layer sizes: [132, 69, 72, 249, 380], total units: 902\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7980993390083313 - val_accuracy: 0.7402 - penalty: 1e-06\n",
            "hidden layer sizes: [110, 49, 52, 220, 344], total units: 775\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7980993390083313 - val_accuracy: 0.7402 - penalty: 1e-06\n",
            "hidden layer sizes: [110, 49, 52, 220, 344], total units: 775\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7980993390083313 - val_accuracy: 0.7402 - penalty: 1e-06\n",
            "hidden layer sizes: [132, 69, 72, 264, 412], total units: 949\n",
            "Before pruning:\n",
            "loss: 0.40532195568084717 - accuracy: 0.8566 - val_loss: 0.8091340661048889 - val_accuracy: 0.7397 - penalty: 1e-06\n",
            "hidden layer sizes: [132, 69, 72, 264, 412], total units: 949\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8090648651123047 - val_accuracy: 0.7397 - penalty: 1e-06\n",
            "hidden layer sizes: [107, 51, 58, 212, 310], total units: 738\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.80752,\n",
              "  0.80988,\n",
              "  0.81346,\n",
              "  0.8191,\n",
              "  0.82134,\n",
              "  0.8247,\n",
              "  0.82708,\n",
              "  0.83188,\n",
              "  0.83242,\n",
              "  0.83558,\n",
              "  0.83914,\n",
              "  0.84106,\n",
              "  0.84198,\n",
              "  0.84404,\n",
              "  0.84692,\n",
              "  0.84924,\n",
              "  0.84984,\n",
              "  0.85484,\n",
              "  0.8535,\n",
              "  0.8566],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=0.5426346>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.53282803>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5252961>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5142059>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.50391924>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.49207613>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.48363596>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.47302473>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.47196797>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.4619729>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.45086032>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.44746807>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.4454068>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.43666866>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.43069145>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.42832074>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.4212699>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.41100624>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.40971723>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.40532196>],\n",
              " 'val_accuracy': [0.7271,\n",
              "  0.7343,\n",
              "  0.7349,\n",
              "  0.7315,\n",
              "  0.7312,\n",
              "  0.7347,\n",
              "  0.7368,\n",
              "  0.7354,\n",
              "  0.7346,\n",
              "  0.737,\n",
              "  0.7367,\n",
              "  0.7344,\n",
              "  0.7377,\n",
              "  0.7328,\n",
              "  0.7397,\n",
              "  0.7356,\n",
              "  0.7377,\n",
              "  0.7424,\n",
              "  0.7402,\n",
              "  0.7397],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=0.77375877>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7776524>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.77802724>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.781884>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.78240633>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7798813>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7863691>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7916136>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.79595894>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.78525585>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7889138>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7891157>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.79248226>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.80537766>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7897265>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.80550456>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8013961>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8006949>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.79809934>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.80906487>]}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bdv3hFwfOmBM"
      },
      "source": [
        "epochs = 30\n",
        "self_scaling_epochs = 20\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPU9oQTSO02S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcda428e-adbd-4c8d-e8c3-8a36ff80afee"
      },
      "source": [
        "model = Sequential([\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None, fixed_size=True),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.9966039657592773 - val_accuracy: 0.095 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.9966037273406982 - val_accuracy: 0.095 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.9035162925720215 - accuracy: 0.38132 - val_loss: 1.4311473369598389 - val_accuracy: 0.4863 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4304295778274536 - val_accuracy: 0.488 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "##########################################################\n",
            "Epoch 2/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4304295778274536 - val_accuracy: 0.488 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4304296970367432 - val_accuracy: 0.488 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.4815970659255981 - accuracy: 0.47052 - val_loss: 1.2382206916809082 - val_accuracy: 0.5544 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.2381744384765625 - val_accuracy: 0.5544 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "##########################################################\n",
            "Epoch 3/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2381744384765625 - val_accuracy: 0.5544 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2381744384765625 - val_accuracy: 0.5544 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.2890013456344604 - accuracy: 0.53864 - val_loss: 1.1519461870193481 - val_accuracy: 0.5823 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1516029834747314 - val_accuracy: 0.5818 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 193, 256], total units: 1025\n",
            "##########################################################\n",
            "Epoch 4/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1516029834747314 - val_accuracy: 0.5818 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 193, 256], total units: 1025\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1516029834747314 - val_accuracy: 0.5818 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 231, 307], total units: 1228\n",
            "Before pruning:\n",
            "loss: 1.184485912322998 - accuracy: 0.57584 - val_loss: 1.0725525617599487 - val_accuracy: 0.6154 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 231, 307], total units: 1228\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0723928213119507 - val_accuracy: 0.6156 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 178, 189, 195, 258], total units: 1012\n",
            "##########################################################\n",
            "Epoch 5/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0723928213119507 - val_accuracy: 0.6156 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 178, 189, 195, 258], total units: 1012\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0723928213119507 - val_accuracy: 0.6156 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 213, 226, 234, 309], total units: 1212\n",
            "Before pruning:\n",
            "loss: 1.0812360048294067 - accuracy: 0.61424 - val_loss: 0.9862753748893738 - val_accuracy: 0.6524 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 213, 226, 234, 309], total units: 1212\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9857228398323059 - val_accuracy: 0.6527 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 124, 169, 202, 276], total units: 963\n",
            "##########################################################\n",
            "Epoch 6/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9857228398323059 - val_accuracy: 0.6527 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 124, 169, 202, 276], total units: 963\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9857228398323059 - val_accuracy: 0.6527 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 148, 202, 242, 331], total units: 1153\n",
            "Before pruning:\n",
            "loss: 0.9936506152153015 - accuracy: 0.64546 - val_loss: 0.9009475708007812 - val_accuracy: 0.6848 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 148, 202, 242, 331], total units: 1153\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9009442329406738 - val_accuracy: 0.6846 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 101, 153, 214, 297], total units: 957\n",
            "##########################################################\n",
            "Epoch 7/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9009442329406738 - val_accuracy: 0.6846 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 101, 153, 214, 297], total units: 957\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9009442329406738 - val_accuracy: 0.6846 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 121, 183, 256, 356], total units: 1146\n",
            "Before pruning:\n",
            "loss: 0.9322214126586914 - accuracy: 0.66984 - val_loss: 0.878605842590332 - val_accuracy: 0.6906 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 121, 183, 256, 356], total units: 1146\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8786243200302124 - val_accuracy: 0.6907 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 89, 138, 223, 270], total units: 912\n",
            "##########################################################\n",
            "Epoch 8/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8786243200302124 - val_accuracy: 0.6907 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 89, 138, 223, 270], total units: 912\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.878624439239502 - val_accuracy: 0.6907 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 109, 165, 267, 324], total units: 1095\n",
            "Before pruning:\n",
            "loss: 0.8767426013946533 - accuracy: 0.68944 - val_loss: 0.8341246843338013 - val_accuracy: 0.7084 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 109, 165, 267, 324], total units: 1095\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8341604471206665 - val_accuracy: 0.7083 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 75, 134, 227, 279], total units: 907\n",
            "##########################################################\n",
            "Epoch 9/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8341604471206665 - val_accuracy: 0.7083 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 75, 134, 227, 279], total units: 907\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8341604471206665 - val_accuracy: 0.7083 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 95, 160, 272, 334], total units: 1091\n",
            "Before pruning:\n",
            "loss: 0.8339406251907349 - accuracy: 0.70474 - val_loss: 0.8075234293937683 - val_accuracy: 0.7168 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 95, 160, 272, 334], total units: 1091\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8072875142097473 - val_accuracy: 0.7167 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 66, 122, 241, 282], total units: 902\n",
            "##########################################################\n",
            "Epoch 10/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8072875142097473 - val_accuracy: 0.7167 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 66, 122, 241, 282], total units: 902\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8072875142097473 - val_accuracy: 0.7167 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 86, 146, 289, 338], total units: 1088\n",
            "Before pruning:\n",
            "loss: 0.7909952402114868 - accuracy: 0.719 - val_loss: 0.8035134077072144 - val_accuracy: 0.7163 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 86, 146, 289, 338], total units: 1088\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8033929467201233 - val_accuracy: 0.7168 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 62, 109, 246, 316], total units: 924\n",
            "##########################################################\n",
            "Epoch 11/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8033929467201233 - val_accuracy: 0.7168 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 62, 109, 246, 316], total units: 924\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8033929467201233 - val_accuracy: 0.7168 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 82, 130, 295, 379], total units: 1115\n",
            "Before pruning:\n",
            "loss: 0.7663810849189758 - accuracy: 0.72956 - val_loss: 0.7877995371818542 - val_accuracy: 0.7237 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 82, 130, 295, 379], total units: 1115\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7873464822769165 - val_accuracy: 0.7235 - penalty: 1e-06\n",
            "hidden layer sizes: [188, 63, 109, 247, 311], total units: 918\n",
            "##########################################################\n",
            "Epoch 12/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7873464822769165 - val_accuracy: 0.7235 - penalty: 1e-06\n",
            "hidden layer sizes: [188, 63, 109, 247, 311], total units: 918\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7873464822769165 - val_accuracy: 0.7235 - penalty: 1e-06\n",
            "hidden layer sizes: [225, 83, 130, 296, 373], total units: 1107\n",
            "Before pruning:\n",
            "loss: 0.7398622632026672 - accuracy: 0.73654 - val_loss: 0.7899677157402039 - val_accuracy: 0.7259 - penalty: 1e-06\n",
            "hidden layer sizes: [225, 83, 130, 296, 373], total units: 1107\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7897037267684937 - val_accuracy: 0.7259 - penalty: 1e-06\n",
            "hidden layer sizes: [184, 58, 94, 254, 324], total units: 914\n",
            "##########################################################\n",
            "Epoch 13/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7897037267684937 - val_accuracy: 0.7259 - penalty: 1e-06\n",
            "hidden layer sizes: [184, 58, 94, 254, 324], total units: 914\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7897036075592041 - val_accuracy: 0.7259 - penalty: 1e-06\n",
            "hidden layer sizes: [220, 78, 114, 304, 388], total units: 1104\n",
            "Before pruning:\n",
            "loss: 0.7175453305244446 - accuracy: 0.74674 - val_loss: 0.7621151208877563 - val_accuracy: 0.7377 - penalty: 1e-06\n",
            "hidden layer sizes: [220, 78, 114, 304, 388], total units: 1104\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7620356678962708 - val_accuracy: 0.7373 - penalty: 1e-06\n",
            "hidden layer sizes: [180, 61, 91, 253, 348], total units: 933\n",
            "##########################################################\n",
            "Epoch 14/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7620356678962708 - val_accuracy: 0.7373 - penalty: 1e-06\n",
            "hidden layer sizes: [180, 61, 91, 253, 348], total units: 933\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7620358467102051 - val_accuracy: 0.7373 - penalty: 1e-06\n",
            "hidden layer sizes: [216, 81, 111, 303, 417], total units: 1128\n",
            "Before pruning:\n",
            "loss: 0.6981886625289917 - accuracy: 0.75508 - val_loss: 0.7666155099868774 - val_accuracy: 0.731 - penalty: 1e-06\n",
            "hidden layer sizes: [216, 81, 111, 303, 417], total units: 1128\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7664950489997864 - val_accuracy: 0.731 - penalty: 1e-06\n",
            "hidden layer sizes: [178, 62, 87, 264, 378], total units: 969\n",
            "##########################################################\n",
            "Epoch 15/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7664950489997864 - val_accuracy: 0.731 - penalty: 1e-06\n",
            "hidden layer sizes: [178, 62, 87, 264, 378], total units: 969\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7664950489997864 - val_accuracy: 0.731 - penalty: 1e-06\n",
            "hidden layer sizes: [213, 82, 107, 316, 453], total units: 1171\n",
            "Before pruning:\n",
            "loss: 0.6880046725273132 - accuracy: 0.75548 - val_loss: 0.7561757564544678 - val_accuracy: 0.7337 - penalty: 1e-06\n",
            "hidden layer sizes: [213, 82, 107, 316, 453], total units: 1171\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7562063932418823 - val_accuracy: 0.7336 - penalty: 1e-06\n",
            "hidden layer sizes: [171, 49, 82, 262, 364], total units: 928\n",
            "##########################################################\n",
            "Epoch 16/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7562063932418823 - val_accuracy: 0.7336 - penalty: 1e-06\n",
            "hidden layer sizes: [171, 49, 82, 262, 364], total units: 928\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7562063336372375 - val_accuracy: 0.7336 - penalty: 1e-06\n",
            "hidden layer sizes: [205, 69, 102, 314, 436], total units: 1126\n",
            "Before pruning:\n",
            "loss: 0.6694562435150146 - accuracy: 0.76352 - val_loss: 0.7817996144294739 - val_accuracy: 0.7274 - penalty: 1e-06\n",
            "hidden layer sizes: [205, 69, 102, 314, 436], total units: 1126\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7814444303512573 - val_accuracy: 0.7276 - penalty: 1e-06\n",
            "hidden layer sizes: [159, 50, 85, 258, 401], total units: 953\n",
            "##########################################################\n",
            "Epoch 17/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7814444303512573 - val_accuracy: 0.7276 - penalty: 1e-06\n",
            "hidden layer sizes: [159, 50, 85, 258, 401], total units: 953\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7814444303512573 - val_accuracy: 0.7276 - penalty: 1e-06\n",
            "hidden layer sizes: [190, 70, 105, 309, 481], total units: 1155\n",
            "Before pruning:\n",
            "loss: 0.6558962464332581 - accuracy: 0.76712 - val_loss: 0.7513936758041382 - val_accuracy: 0.7383 - penalty: 1e-06\n",
            "hidden layer sizes: [190, 70, 105, 309, 481], total units: 1155\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7513830065727234 - val_accuracy: 0.7383 - penalty: 1e-06\n",
            "hidden layer sizes: [153, 50, 74, 254, 397], total units: 928\n",
            "##########################################################\n",
            "Epoch 18/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7513830065727234 - val_accuracy: 0.7383 - penalty: 1e-06\n",
            "hidden layer sizes: [153, 50, 74, 254, 397], total units: 928\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7513830065727234 - val_accuracy: 0.7383 - penalty: 1e-06\n",
            "hidden layer sizes: [183, 70, 94, 304, 476], total units: 1127\n",
            "Before pruning:\n",
            "loss: 0.6457028388977051 - accuracy: 0.77214 - val_loss: 0.7543075680732727 - val_accuracy: 0.7383 - penalty: 1e-06\n",
            "hidden layer sizes: [183, 70, 94, 304, 476], total units: 1127\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7542768716812134 - val_accuracy: 0.7381 - penalty: 1e-06\n",
            "hidden layer sizes: [148, 44, 67, 253, 430], total units: 942\n",
            "##########################################################\n",
            "Epoch 19/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7542768716812134 - val_accuracy: 0.7381 - penalty: 1e-06\n",
            "hidden layer sizes: [148, 44, 67, 253, 430], total units: 942\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7542769312858582 - val_accuracy: 0.7381 - penalty: 1e-06\n",
            "hidden layer sizes: [177, 64, 87, 303, 516], total units: 1147\n",
            "Before pruning:\n",
            "loss: 0.6329159140586853 - accuracy: 0.77766 - val_loss: 0.7475136518478394 - val_accuracy: 0.7409 - penalty: 1e-06\n",
            "hidden layer sizes: [177, 64, 87, 303, 516], total units: 1147\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7475546598434448 - val_accuracy: 0.7409 - penalty: 1e-06\n",
            "hidden layer sizes: [141, 50, 76, 259, 404], total units: 930\n",
            "##########################################################\n",
            "Epoch 20/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7475546598434448 - val_accuracy: 0.7409 - penalty: 1e-06\n",
            "hidden layer sizes: [141, 50, 76, 259, 404], total units: 930\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7475546598434448 - val_accuracy: 0.7409 - penalty: 1e-06\n",
            "hidden layer sizes: [169, 70, 96, 310, 484], total units: 1129\n",
            "Before pruning:\n",
            "loss: 0.6243708729743958 - accuracy: 0.77822 - val_loss: 0.7408627867698669 - val_accuracy: 0.7426 - penalty: 1e-06\n",
            "hidden layer sizes: [169, 70, 96, 310, 484], total units: 1129\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7406055927276611 - val_accuracy: 0.7428 - penalty: 1e-06\n",
            "hidden layer sizes: [137, 50, 72, 253, 431], total units: 943\n",
            "##########################################################\n",
            "Epoch 21/30\n",
            "loss: 0.6657538414001465 - accuracy: 0.76752 - val_loss: 0.7742445468902588 - val_accuracy: 0.7296 - penalty: 0.0\n",
            "hidden layer sizes: [137, 50, 72, 253, 431], total units: 943\n",
            "##########################################################\n",
            "Epoch 22/30\n",
            "loss: 0.510741651058197 - accuracy: 0.81886 - val_loss: 0.7856537103652954 - val_accuracy: 0.7381 - penalty: 0.0\n",
            "hidden layer sizes: [137, 50, 72, 253, 431], total units: 943\n",
            "##########################################################\n",
            "Epoch 23/30\n",
            "loss: 0.42453768849372864 - accuracy: 0.84902 - val_loss: 0.7928207516670227 - val_accuracy: 0.7432 - penalty: 0.0\n",
            "hidden layer sizes: [137, 50, 72, 253, 431], total units: 943\n",
            "##########################################################\n",
            "Epoch 24/30\n",
            "loss: 0.35585126280784607 - accuracy: 0.87342 - val_loss: 0.8148535490036011 - val_accuracy: 0.7401 - penalty: 0.0\n",
            "hidden layer sizes: [137, 50, 72, 253, 431], total units: 943\n",
            "##########################################################\n",
            "Epoch 25/30\n",
            "loss: 0.2869917154312134 - accuracy: 0.89744 - val_loss: 0.8468588590621948 - val_accuracy: 0.7458 - penalty: 0.0\n",
            "hidden layer sizes: [137, 50, 72, 253, 431], total units: 943\n",
            "##########################################################\n",
            "Epoch 26/30\n",
            "loss: 0.24149714410305023 - accuracy: 0.91382 - val_loss: 0.869026243686676 - val_accuracy: 0.7466 - penalty: 0.0\n",
            "hidden layer sizes: [137, 50, 72, 253, 431], total units: 943\n",
            "##########################################################\n",
            "Epoch 27/30\n",
            "loss: 0.1891796886920929 - accuracy: 0.93306 - val_loss: 0.946753203868866 - val_accuracy: 0.7455 - penalty: 0.0\n",
            "hidden layer sizes: [137, 50, 72, 253, 431], total units: 943\n",
            "##########################################################\n",
            "Epoch 28/30\n",
            "loss: 0.15514622628688812 - accuracy: 0.94566 - val_loss: 0.9624152183532715 - val_accuracy: 0.7517 - penalty: 0.0\n",
            "hidden layer sizes: [137, 50, 72, 253, 431], total units: 943\n",
            "##########################################################\n",
            "Epoch 29/30\n",
            "loss: 0.12853001058101654 - accuracy: 0.95534 - val_loss: 1.004549264907837 - val_accuracy: 0.7492 - penalty: 0.0\n",
            "hidden layer sizes: [137, 50, 72, 253, 431], total units: 943\n",
            "##########################################################\n",
            "Epoch 30/30\n",
            "loss: 0.10986413061618805 - accuracy: 0.96172 - val_loss: 1.0249000787734985 - val_accuracy: 0.7561 - penalty: 0.0\n",
            "hidden layer sizes: [137, 50, 72, 253, 431], total units: 943\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.38132,\n",
              "  0.47052,\n",
              "  0.53864,\n",
              "  0.57584,\n",
              "  0.61424,\n",
              "  0.64546,\n",
              "  0.66984,\n",
              "  0.68944,\n",
              "  0.70474,\n",
              "  0.719,\n",
              "  0.72956,\n",
              "  0.73654,\n",
              "  0.74674,\n",
              "  0.75508,\n",
              "  0.75548,\n",
              "  0.76352,\n",
              "  0.76712,\n",
              "  0.77214,\n",
              "  0.77766,\n",
              "  0.77822,\n",
              "  0.76752,\n",
              "  0.81886,\n",
              "  0.84902,\n",
              "  0.87342,\n",
              "  0.89744,\n",
              "  0.91382,\n",
              "  0.93306,\n",
              "  0.94566,\n",
              "  0.95534,\n",
              "  0.96172],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.9035163>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4815971>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2890013>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1844859>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.081236>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9936506>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9322214>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8767426>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8339406>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.79099524>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7663811>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.73986226>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.71754533>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.69818866>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6880047>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.66945624>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.65589625>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.64570284>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6329159>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6243709>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.66575384>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.51074165>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.4245377>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.35585126>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.28699172>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.24149714>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.18917969>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.15514623>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.12853001>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.10986413>],\n",
              " 'val_accuracy': [0.488,\n",
              "  0.5544,\n",
              "  0.5818,\n",
              "  0.6156,\n",
              "  0.6527,\n",
              "  0.6846,\n",
              "  0.6907,\n",
              "  0.7083,\n",
              "  0.7167,\n",
              "  0.7168,\n",
              "  0.7235,\n",
              "  0.7259,\n",
              "  0.7373,\n",
              "  0.731,\n",
              "  0.7336,\n",
              "  0.7276,\n",
              "  0.7383,\n",
              "  0.7381,\n",
              "  0.7409,\n",
              "  0.7428,\n",
              "  0.7296,\n",
              "  0.7381,\n",
              "  0.7432,\n",
              "  0.7401,\n",
              "  0.7458,\n",
              "  0.7466,\n",
              "  0.7455,\n",
              "  0.7517,\n",
              "  0.7492,\n",
              "  0.7561],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.4304296>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2381744>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.151603>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0723928>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.98572284>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.90094423>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8786243>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.83416045>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8072875>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.80339295>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7873465>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7897037>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.76203567>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.76649505>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7562064>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.78144443>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.751383>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7542769>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.74755466>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7406056>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.77424455>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7856537>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.79282075>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.81485355>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.84685886>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.86902624>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9467532>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9624152>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0045493>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0249001>]}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrcVbyP7QYXg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cacab1da-2c06-43ed-c92c-723826eea8fb"
      },
      "source": [
        "model = Sequential([\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None, fixed_size=True),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.983743667602539 - val_accuracy: 0.1149 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.983743906021118 - val_accuracy: 0.1149 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.9288136959075928 - accuracy: 0.37844 - val_loss: 1.4544951915740967 - val_accuracy: 0.4809 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4529860019683838 - val_accuracy: 0.4821 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "##########################################################\n",
            "Epoch 2/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4529860019683838 - val_accuracy: 0.4821 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4529860019683838 - val_accuracy: 0.4821 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.5003464221954346 - accuracy: 0.46592 - val_loss: 1.273173451423645 - val_accuracy: 0.5368 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.2731773853302002 - val_accuracy: 0.5364 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "##########################################################\n",
            "Epoch 3/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2731773853302002 - val_accuracy: 0.5364 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2731773853302002 - val_accuracy: 0.5364 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.3108245134353638 - accuracy: 0.53098 - val_loss: 1.1865636110305786 - val_accuracy: 0.5708 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1864274740219116 - val_accuracy: 0.5706 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "##########################################################\n",
            "Epoch 4/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1864274740219116 - val_accuracy: 0.5706 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.186427354812622 - val_accuracy: 0.5706 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.1894413232803345 - accuracy: 0.5748 - val_loss: 1.0617703199386597 - val_accuracy: 0.622 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0615702867507935 - val_accuracy: 0.6217 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 166, 181, 191, 258], total units: 988\n",
            "##########################################################\n",
            "Epoch 5/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0615702867507935 - val_accuracy: 0.6217 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 166, 181, 191, 258], total units: 988\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.061570167541504 - val_accuracy: 0.6217 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 199, 217, 229, 309], total units: 1184\n",
            "Before pruning:\n",
            "loss: 1.0909630060195923 - accuracy: 0.60972 - val_loss: 1.001274585723877 - val_accuracy: 0.6471 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 199, 217, 229, 309], total units: 1184\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.001535177230835 - val_accuracy: 0.6468 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 117, 158, 197, 284], total units: 948\n",
            "##########################################################\n",
            "Epoch 6/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.001535177230835 - val_accuracy: 0.6468 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 117, 158, 197, 284], total units: 948\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.001535177230835 - val_accuracy: 0.6468 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 140, 189, 236, 340], total units: 1135\n",
            "Before pruning:\n",
            "loss: 1.0069819688796997 - accuracy: 0.6425 - val_loss: 0.9350489974021912 - val_accuracy: 0.67 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 140, 189, 236, 340], total units: 1135\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9349101781845093 - val_accuracy: 0.6701 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 96, 137, 197, 272], total units: 894\n",
            "##########################################################\n",
            "Epoch 7/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9349101781845093 - val_accuracy: 0.6701 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 96, 137, 197, 272], total units: 894\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9349101781845093 - val_accuracy: 0.6701 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 116, 164, 236, 326], total units: 1072\n",
            "Before pruning:\n",
            "loss: 0.9389311671257019 - accuracy: 0.66636 - val_loss: 0.8998627662658691 - val_accuracy: 0.6817 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 116, 164, 236, 326], total units: 1072\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8994801044464111 - val_accuracy: 0.682 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 85, 121, 208, 284], total units: 890\n",
            "##########################################################\n",
            "Epoch 8/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8994801044464111 - val_accuracy: 0.682 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 85, 121, 208, 284], total units: 890\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8994799852371216 - val_accuracy: 0.682 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 105, 145, 249, 340], total units: 1069\n",
            "Before pruning:\n",
            "loss: 0.8841295838356018 - accuracy: 0.68794 - val_loss: 0.8493033051490784 - val_accuracy: 0.705 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 105, 145, 249, 340], total units: 1069\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8491409420967102 - val_accuracy: 0.7056 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 75, 106, 215, 281], total units: 868\n",
            "##########################################################\n",
            "Epoch 9/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8491409420967102 - val_accuracy: 0.7056 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 75, 106, 215, 281], total units: 868\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.849141001701355 - val_accuracy: 0.7056 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 95, 127, 258, 337], total units: 1046\n",
            "Before pruning:\n",
            "loss: 0.8387278318405151 - accuracy: 0.70252 - val_loss: 0.8214557766914368 - val_accuracy: 0.7128 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 95, 127, 258, 337], total units: 1046\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.821336030960083 - val_accuracy: 0.713 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 73, 100, 231, 302], total units: 897\n",
            "##########################################################\n",
            "Epoch 10/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.821336030960083 - val_accuracy: 0.713 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 73, 100, 231, 302], total units: 897\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.821336030960083 - val_accuracy: 0.713 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 93, 120, 277, 362], total units: 1081\n",
            "Before pruning:\n",
            "loss: 0.8099547028541565 - accuracy: 0.71222 - val_loss: 0.8064177632331848 - val_accuracy: 0.7201 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 93, 120, 277, 362], total units: 1081\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8063188791275024 - val_accuracy: 0.7196 - penalty: 1e-06\n",
            "hidden layer sizes: [188, 70, 87, 242, 322], total units: 909\n",
            "##########################################################\n",
            "Epoch 11/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8063188791275024 - val_accuracy: 0.7196 - penalty: 1e-06\n",
            "hidden layer sizes: [188, 70, 87, 242, 322], total units: 909\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8063188791275024 - val_accuracy: 0.7196 - penalty: 1e-06\n",
            "hidden layer sizes: [225, 90, 107, 290, 386], total units: 1098\n",
            "Before pruning:\n",
            "loss: 0.7798410654067993 - accuracy: 0.72336 - val_loss: 0.8011629581451416 - val_accuracy: 0.7208 - penalty: 1e-06\n",
            "hidden layer sizes: [225, 90, 107, 290, 386], total units: 1098\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8010385036468506 - val_accuracy: 0.7212 - penalty: 1e-06\n",
            "hidden layer sizes: [187, 70, 83, 243, 332], total units: 915\n",
            "##########################################################\n",
            "Epoch 12/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8010385036468506 - val_accuracy: 0.7212 - penalty: 1e-06\n",
            "hidden layer sizes: [187, 70, 83, 243, 332], total units: 915\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8010385036468506 - val_accuracy: 0.7212 - penalty: 1e-06\n",
            "hidden layer sizes: [224, 90, 103, 291, 398], total units: 1106\n",
            "Before pruning:\n",
            "loss: 0.7496861219406128 - accuracy: 0.73368 - val_loss: 0.7774808406829834 - val_accuracy: 0.7272 - penalty: 1e-06\n",
            "hidden layer sizes: [224, 90, 103, 291, 398], total units: 1106\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.777439534664154 - val_accuracy: 0.7276 - penalty: 1e-06\n",
            "hidden layer sizes: [182, 61, 78, 249, 331], total units: 901\n",
            "##########################################################\n",
            "Epoch 13/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.777439534664154 - val_accuracy: 0.7276 - penalty: 1e-06\n",
            "hidden layer sizes: [182, 61, 78, 249, 331], total units: 901\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7774396538734436 - val_accuracy: 0.7276 - penalty: 1e-06\n",
            "hidden layer sizes: [218, 81, 98, 298, 397], total units: 1092\n",
            "Before pruning:\n",
            "loss: 0.7353717684745789 - accuracy: 0.73852 - val_loss: 0.7796745896339417 - val_accuracy: 0.7279 - penalty: 1e-06\n",
            "hidden layer sizes: [218, 81, 98, 298, 397], total units: 1092\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7796557545661926 - val_accuracy: 0.7282 - penalty: 1e-06\n",
            "hidden layer sizes: [170, 57, 77, 257, 322], total units: 883\n",
            "##########################################################\n",
            "Epoch 14/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7796557545661926 - val_accuracy: 0.7282 - penalty: 1e-06\n",
            "hidden layer sizes: [170, 57, 77, 257, 322], total units: 883\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7796558141708374 - val_accuracy: 0.7282 - penalty: 1e-06\n",
            "hidden layer sizes: [204, 77, 97, 308, 386], total units: 1072\n",
            "Before pruning:\n",
            "loss: 0.7121407985687256 - accuracy: 0.7498 - val_loss: 0.7689936757087708 - val_accuracy: 0.7289 - penalty: 1e-06\n",
            "hidden layer sizes: [204, 77, 97, 308, 386], total units: 1072\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7690028548240662 - val_accuracy: 0.7289 - penalty: 1e-06\n",
            "hidden layer sizes: [167, 57, 72, 257, 366], total units: 919\n",
            "##########################################################\n",
            "Epoch 15/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7690028548240662 - val_accuracy: 0.7289 - penalty: 1e-06\n",
            "hidden layer sizes: [167, 57, 72, 257, 366], total units: 919\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7690028548240662 - val_accuracy: 0.7289 - penalty: 1e-06\n",
            "hidden layer sizes: [200, 77, 92, 308, 439], total units: 1116\n",
            "Before pruning:\n",
            "loss: 0.6919641494750977 - accuracy: 0.75436 - val_loss: 0.7647964358329773 - val_accuracy: 0.7348 - penalty: 1e-06\n",
            "hidden layer sizes: [200, 77, 92, 308, 439], total units: 1116\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.764499306678772 - val_accuracy: 0.7351 - penalty: 1e-06\n",
            "hidden layer sizes: [160, 59, 72, 258, 383], total units: 932\n",
            "##########################################################\n",
            "Epoch 16/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.764499306678772 - val_accuracy: 0.7351 - penalty: 1e-06\n",
            "hidden layer sizes: [160, 59, 72, 258, 383], total units: 932\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.764499306678772 - val_accuracy: 0.7351 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 79, 92, 309, 459], total units: 1131\n",
            "Before pruning:\n",
            "loss: 0.6801711916923523 - accuracy: 0.76042 - val_loss: 0.7700462341308594 - val_accuracy: 0.7336 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 79, 92, 309, 459], total units: 1131\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7697965502738953 - val_accuracy: 0.7337 - penalty: 1e-06\n",
            "hidden layer sizes: [153, 54, 68, 259, 399], total units: 933\n",
            "##########################################################\n",
            "Epoch 17/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7697965502738953 - val_accuracy: 0.7337 - penalty: 1e-06\n",
            "hidden layer sizes: [153, 54, 68, 259, 399], total units: 933\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7697965502738953 - val_accuracy: 0.7337 - penalty: 1e-06\n",
            "hidden layer sizes: [183, 74, 88, 310, 478], total units: 1133\n",
            "Before pruning:\n",
            "loss: 0.6661350727081299 - accuracy: 0.7648 - val_loss: 0.7700350284576416 - val_accuracy: 0.7337 - penalty: 1e-06\n",
            "hidden layer sizes: [183, 74, 88, 310, 478], total units: 1133\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7698341012001038 - val_accuracy: 0.7334 - penalty: 1e-06\n",
            "hidden layer sizes: [146, 55, 70, 259, 441], total units: 971\n",
            "##########################################################\n",
            "Epoch 18/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7698341012001038 - val_accuracy: 0.7334 - penalty: 1e-06\n",
            "hidden layer sizes: [146, 55, 70, 259, 441], total units: 971\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7698341012001038 - val_accuracy: 0.7334 - penalty: 1e-06\n",
            "hidden layer sizes: [175, 75, 90, 310, 529], total units: 1179\n",
            "Before pruning:\n",
            "loss: 0.6538716554641724 - accuracy: 0.7687 - val_loss: 0.7591924071311951 - val_accuracy: 0.737 - penalty: 1e-06\n",
            "hidden layer sizes: [175, 75, 90, 310, 529], total units: 1179\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7590632438659668 - val_accuracy: 0.7373 - penalty: 1e-06\n",
            "hidden layer sizes: [141, 53, 68, 260, 428], total units: 950\n",
            "##########################################################\n",
            "Epoch 19/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7590632438659668 - val_accuracy: 0.7373 - penalty: 1e-06\n",
            "hidden layer sizes: [141, 53, 68, 260, 428], total units: 950\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7590632438659668 - val_accuracy: 0.7373 - penalty: 1e-06\n",
            "hidden layer sizes: [169, 73, 88, 312, 513], total units: 1155\n",
            "Before pruning:\n",
            "loss: 0.6393699049949646 - accuracy: 0.7746 - val_loss: 0.7619454860687256 - val_accuracy: 0.7368 - penalty: 1e-06\n",
            "hidden layer sizes: [169, 73, 88, 312, 513], total units: 1155\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7618334293365479 - val_accuracy: 0.7363 - penalty: 1e-06\n",
            "hidden layer sizes: [132, 55, 66, 259, 438], total units: 950\n",
            "##########################################################\n",
            "Epoch 20/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7618334293365479 - val_accuracy: 0.7363 - penalty: 1e-06\n",
            "hidden layer sizes: [132, 55, 66, 259, 438], total units: 950\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7618333697319031 - val_accuracy: 0.7363 - penalty: 1e-06\n",
            "hidden layer sizes: [158, 75, 86, 310, 525], total units: 1154\n",
            "Before pruning:\n",
            "loss: 0.6292902827262878 - accuracy: 0.7785 - val_loss: 0.7493035197257996 - val_accuracy: 0.7445 - penalty: 1e-06\n",
            "hidden layer sizes: [158, 75, 86, 310, 525], total units: 1154\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7494103908538818 - val_accuracy: 0.7442 - penalty: 1e-06\n",
            "hidden layer sizes: [128, 53, 73, 262, 489], total units: 1005\n",
            "##########################################################\n",
            "Epoch 21/30\n",
            "loss: 0.6712389588356018 - accuracy: 0.76604 - val_loss: 0.7921534180641174 - val_accuracy: 0.7277 - penalty: 0.0\n",
            "hidden layer sizes: [128, 53, 73, 262, 489], total units: 1005\n",
            "##########################################################\n",
            "Epoch 22/30\n",
            "loss: 0.5169544219970703 - accuracy: 0.815 - val_loss: 0.783096969127655 - val_accuracy: 0.7396 - penalty: 0.0\n",
            "hidden layer sizes: [128, 53, 73, 262, 489], total units: 1005\n",
            "##########################################################\n",
            "Epoch 23/30\n",
            "loss: 0.43144160509109497 - accuracy: 0.8464 - val_loss: 0.7942081093788147 - val_accuracy: 0.7405 - penalty: 0.0\n",
            "hidden layer sizes: [128, 53, 73, 262, 489], total units: 1005\n",
            "##########################################################\n",
            "Epoch 24/30\n",
            "loss: 0.3458555042743683 - accuracy: 0.8779 - val_loss: 0.8367624878883362 - val_accuracy: 0.7415 - penalty: 0.0\n",
            "hidden layer sizes: [128, 53, 73, 262, 489], total units: 1005\n",
            "##########################################################\n",
            "Epoch 25/30\n",
            "loss: 0.2707514762878418 - accuracy: 0.90406 - val_loss: 0.8694369196891785 - val_accuracy: 0.7461 - penalty: 0.0\n",
            "hidden layer sizes: [128, 53, 73, 262, 489], total units: 1005\n",
            "##########################################################\n",
            "Epoch 26/30\n",
            "loss: 0.21049128472805023 - accuracy: 0.92654 - val_loss: 0.9012873768806458 - val_accuracy: 0.7467 - penalty: 0.0\n",
            "hidden layer sizes: [128, 53, 73, 262, 489], total units: 1005\n",
            "##########################################################\n",
            "Epoch 27/30\n",
            "loss: 0.16451993584632874 - accuracy: 0.94354 - val_loss: 0.9772655963897705 - val_accuracy: 0.746 - penalty: 0.0\n",
            "hidden layer sizes: [128, 53, 73, 262, 489], total units: 1005\n",
            "##########################################################\n",
            "Epoch 28/30\n",
            "loss: 0.13301429152488708 - accuracy: 0.95464 - val_loss: 1.0230374336242676 - val_accuracy: 0.7463 - penalty: 0.0\n",
            "hidden layer sizes: [128, 53, 73, 262, 489], total units: 1005\n",
            "##########################################################\n",
            "Epoch 29/30\n",
            "loss: 0.11242907494306564 - accuracy: 0.96162 - val_loss: 1.0425822734832764 - val_accuracy: 0.7494 - penalty: 0.0\n",
            "hidden layer sizes: [128, 53, 73, 262, 489], total units: 1005\n",
            "##########################################################\n",
            "Epoch 30/30\n",
            "loss: 0.0937553122639656 - accuracy: 0.96782 - val_loss: 1.0605627298355103 - val_accuracy: 0.7491 - penalty: 0.0\n",
            "hidden layer sizes: [128, 53, 73, 262, 489], total units: 1005\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.37844,\n",
              "  0.46592,\n",
              "  0.53098,\n",
              "  0.5748,\n",
              "  0.60972,\n",
              "  0.6425,\n",
              "  0.66636,\n",
              "  0.68794,\n",
              "  0.70252,\n",
              "  0.71222,\n",
              "  0.72336,\n",
              "  0.73368,\n",
              "  0.73852,\n",
              "  0.7498,\n",
              "  0.75436,\n",
              "  0.76042,\n",
              "  0.7648,\n",
              "  0.7687,\n",
              "  0.7746,\n",
              "  0.7785,\n",
              "  0.76604,\n",
              "  0.815,\n",
              "  0.8464,\n",
              "  0.8779,\n",
              "  0.90406,\n",
              "  0.92654,\n",
              "  0.94354,\n",
              "  0.95464,\n",
              "  0.96162,\n",
              "  0.96782],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.9288137>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.5003464>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3108245>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1894413>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.090963>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.006982>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.93893117>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8841296>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.83872783>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8099547>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.77984107>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7496861>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.73537177>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7121408>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.69196415>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6801712>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6661351>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.65387166>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6393699>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6292903>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.67123896>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5169544>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.4314416>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.3458555>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.27075148>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.21049128>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.16451994>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.13301429>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.112429075>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.09375531>],\n",
              " 'val_accuracy': [0.4821,\n",
              "  0.5364,\n",
              "  0.5706,\n",
              "  0.6217,\n",
              "  0.6468,\n",
              "  0.6701,\n",
              "  0.682,\n",
              "  0.7056,\n",
              "  0.713,\n",
              "  0.7196,\n",
              "  0.7212,\n",
              "  0.7276,\n",
              "  0.7282,\n",
              "  0.7289,\n",
              "  0.7351,\n",
              "  0.7337,\n",
              "  0.7334,\n",
              "  0.7373,\n",
              "  0.7363,\n",
              "  0.7442,\n",
              "  0.7277,\n",
              "  0.7396,\n",
              "  0.7405,\n",
              "  0.7415,\n",
              "  0.7461,\n",
              "  0.7467,\n",
              "  0.746,\n",
              "  0.7463,\n",
              "  0.7494,\n",
              "  0.7491],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.452986>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2731774>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1864275>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0615703>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0015352>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9349102>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8994801>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.84914094>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.82133603>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8063189>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8010385>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.77743953>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.77965575>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.76900285>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7644993>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.76979655>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7698341>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.75906324>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7618334>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7494104>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7921534>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.78309697>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7942081>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8367625>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8694369>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9012874>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9772656>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0230374>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0425823>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0605627>]}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmgHRLNJ9cEM"
      },
      "source": [
        "## Static models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjsCq-6j7vI2"
      },
      "source": [
        "epochs = 20\n",
        "self_scaling_epochs = 0\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQrzS2PLHysw"
      },
      "source": [
        "# Final layer sizes of dynamic models\n",
        "[131, 51, 72, 277, 438]\n",
        "[130, 45, 88, 244, 434]\n",
        "[107, 51, 58, 212, 310]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zomuwg35LG6R"
      },
      "source": [
        "### Layer sizes set to the architecture discovered by auto-sizing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpeSlT3CLizZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95b26d31-157b-429a-b539-da0427b50be0"
      },
      "source": [
        "%%time\n",
        "\n",
        "model = Sequential([\n",
        "        Conv2D(130, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(50, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(80, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Conv2D(250, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(430, activation='selu', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "loss: 3.542296886444092 - accuracy: 0.10588 - val_loss: 2.349604606628418 - val_accuracy: 0.1 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "loss: 2.3350794315338135 - accuracy: 0.10072 - val_loss: 2.341313362121582 - val_accuracy: 0.1002 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "loss: 2.322622299194336 - accuracy: 0.11064 - val_loss: 2.151273727416992 - val_accuracy: 0.1587 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "loss: 2.028930187225342 - accuracy: 0.1828 - val_loss: 1.8920965194702148 - val_accuracy: 0.1908 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "loss: 1.7598954439163208 - accuracy: 0.29744 - val_loss: 1.567871332168579 - val_accuracy: 0.3852 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "loss: 1.4557782411575317 - accuracy: 0.44832 - val_loss: 1.3415145874023438 - val_accuracy: 0.5022 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "loss: 1.3105548620224 - accuracy: 0.51294 - val_loss: 1.3159866333007812 - val_accuracy: 0.5299 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "loss: 1.1933603286743164 - accuracy: 0.56258 - val_loss: 1.148223876953125 - val_accuracy: 0.5822 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "loss: 1.098826289176941 - accuracy: 0.5981 - val_loss: 1.0770899057388306 - val_accuracy: 0.6176 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "loss: 1.0256305932998657 - accuracy: 0.62944 - val_loss: 1.0650094747543335 - val_accuracy: 0.6292 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "loss: 0.9596800804138184 - accuracy: 0.66138 - val_loss: 0.9870801568031311 - val_accuracy: 0.6731 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "loss: 0.8893182873725891 - accuracy: 0.68966 - val_loss: 0.9066979289054871 - val_accuracy: 0.6982 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "loss: 0.844311535358429 - accuracy: 0.70426 - val_loss: 0.9533615112304688 - val_accuracy: 0.6851 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "loss: 0.7950552105903625 - accuracy: 0.72374 - val_loss: 0.9299074411392212 - val_accuracy: 0.6977 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "loss: 0.7652485966682434 - accuracy: 0.73516 - val_loss: 0.8921818137168884 - val_accuracy: 0.7132 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "loss: 0.7335625290870667 - accuracy: 0.74742 - val_loss: 0.8883573412895203 - val_accuracy: 0.7149 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "loss: 0.7036364078521729 - accuracy: 0.75782 - val_loss: 0.9330236315727234 - val_accuracy: 0.7075 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "loss: 0.6641353368759155 - accuracy: 0.77294 - val_loss: 0.8753843903541565 - val_accuracy: 0.7262 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "loss: 0.6394566297531128 - accuracy: 0.78166 - val_loss: 0.8594812750816345 - val_accuracy: 0.7327 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "loss: 0.6381580829620361 - accuracy: 0.78208 - val_loss: 0.9548560380935669 - val_accuracy: 0.7193 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "CPU times: user 2min 38s, sys: 3.28 s, total: 2min 41s\n",
            "Wall time: 3min 2s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2DBXrAtIEVw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7c10081-b5b2-4e02-8be4-4efc9fed6d38"
      },
      "source": [
        "%%time\n",
        "\n",
        "model = Sequential([\n",
        "        Conv2D(130, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(50, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(80, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Conv2D(250, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(430, activation='selu', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "loss: 2.307016611099243 - accuracy: 0.36996 - val_loss: 1.4811290502548218 - val_accuracy: 0.457 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "loss: 1.4038615226745605 - accuracy: 0.49278 - val_loss: 1.2863517999649048 - val_accuracy: 0.5352 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "loss: 1.2491425275802612 - accuracy: 0.55084 - val_loss: 1.1936345100402832 - val_accuracy: 0.5744 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "loss: 1.1316972970962524 - accuracy: 0.59534 - val_loss: 1.1694689989089966 - val_accuracy: 0.5793 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "loss: 1.019073486328125 - accuracy: 0.6355 - val_loss: 1.0789142847061157 - val_accuracy: 0.6232 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "loss: 0.9088562726974487 - accuracy: 0.67686 - val_loss: 1.0609148740768433 - val_accuracy: 0.6466 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "loss: 0.8106961846351624 - accuracy: 0.7126 - val_loss: 1.0519739389419556 - val_accuracy: 0.6571 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "loss: 0.7255057096481323 - accuracy: 0.7433 - val_loss: 1.0838028192520142 - val_accuracy: 0.6652 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "loss: 0.6549095511436462 - accuracy: 0.76922 - val_loss: 1.0932139158248901 - val_accuracy: 0.6736 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "loss: 0.5864938497543335 - accuracy: 0.79342 - val_loss: 1.1260793209075928 - val_accuracy: 0.6714 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "loss: 0.5393314361572266 - accuracy: 0.81242 - val_loss: 1.1495566368103027 - val_accuracy: 0.685 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "loss: 0.4936266541481018 - accuracy: 0.82566 - val_loss: 1.1411411762237549 - val_accuracy: 0.6876 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "loss: 0.44394850730895996 - accuracy: 0.84316 - val_loss: 1.132514238357544 - val_accuracy: 0.6931 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "loss: 0.4059078097343445 - accuracy: 0.8601 - val_loss: 1.1951543092727661 - val_accuracy: 0.6862 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "loss: 0.3730584681034088 - accuracy: 0.86916 - val_loss: 1.170699119567871 - val_accuracy: 0.6986 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "loss: 0.3675439953804016 - accuracy: 0.87296 - val_loss: 1.2077562808990479 - val_accuracy: 0.6927 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "loss: 0.33543598651885986 - accuracy: 0.88378 - val_loss: 1.3065261840820312 - val_accuracy: 0.6909 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "loss: 0.31193506717681885 - accuracy: 0.89282 - val_loss: 1.389482855796814 - val_accuracy: 0.6922 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "loss: 0.2900753319263458 - accuracy: 0.90106 - val_loss: 1.3118497133255005 - val_accuracy: 0.7009 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "loss: 0.2800607681274414 - accuracy: 0.90562 - val_loss: 1.3819533586502075 - val_accuracy: 0.6867 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "CPU times: user 2min 40s, sys: 3.63 s, total: 2min 44s\n",
            "Wall time: 3min 4s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHZO6wDRK5nE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3a5e411-86f2-46b5-9da5-21c028febc02"
      },
      "source": [
        "%%time\n",
        "\n",
        "model = Sequential([\n",
        "        Conv2D(130, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(50, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(80, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Conv2D(250, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(430, activation='selu', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "loss: 1.9652268886566162 - accuracy: 0.39594 - val_loss: 1.4078832864761353 - val_accuracy: 0.4997 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "loss: 1.3558696508407593 - accuracy: 0.51694 - val_loss: 1.286001443862915 - val_accuracy: 0.5464 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "loss: 1.2024716138839722 - accuracy: 0.57148 - val_loss: 1.1833745241165161 - val_accuracy: 0.5795 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "loss: 1.061343789100647 - accuracy: 0.6232 - val_loss: 1.1501379013061523 - val_accuracy: 0.5953 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "loss: 0.922852098941803 - accuracy: 0.67318 - val_loss: 1.1511390209197998 - val_accuracy: 0.6108 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "loss: 0.7912628650665283 - accuracy: 0.71992 - val_loss: 1.1361163854599 - val_accuracy: 0.6187 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "loss: 0.6588713526725769 - accuracy: 0.76658 - val_loss: 1.2003930807113647 - val_accuracy: 0.6344 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "loss: 0.5527268648147583 - accuracy: 0.8031 - val_loss: 1.2076102495193481 - val_accuracy: 0.6385 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "loss: 0.4640187919139862 - accuracy: 0.83704 - val_loss: 1.2885226011276245 - val_accuracy: 0.6339 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "loss: 0.37477973103523254 - accuracy: 0.86736 - val_loss: 1.3218116760253906 - val_accuracy: 0.6506 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "loss: 0.32981929183006287 - accuracy: 0.88506 - val_loss: 1.4347448348999023 - val_accuracy: 0.6471 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "loss: 0.28487178683280945 - accuracy: 0.9009 - val_loss: 1.4376320838928223 - val_accuracy: 0.6525 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "loss: 0.2514776289463043 - accuracy: 0.91248 - val_loss: 1.5086326599121094 - val_accuracy: 0.6481 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "loss: 0.22519056499004364 - accuracy: 0.9227 - val_loss: 1.5170361995697021 - val_accuracy: 0.6486 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "loss: 0.2004801630973816 - accuracy: 0.93098 - val_loss: 1.6709601879119873 - val_accuracy: 0.6472 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "loss: 0.1883498579263687 - accuracy: 0.93642 - val_loss: 1.7348310947418213 - val_accuracy: 0.661 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "loss: 0.17838351428508759 - accuracy: 0.93942 - val_loss: 1.7377312183380127 - val_accuracy: 0.6594 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "loss: 0.16687171161174774 - accuracy: 0.94378 - val_loss: 1.8090025186538696 - val_accuracy: 0.6717 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "loss: 0.15447545051574707 - accuracy: 0.94752 - val_loss: 1.7867709398269653 - val_accuracy: 0.6654 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "loss: 0.14759458601474762 - accuracy: 0.9517 - val_loss: 1.8556467294692993 - val_accuracy: 0.6664 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "CPU times: user 2min 38s, sys: 3.37 s, total: 2min 42s\n",
            "Wall time: 3min 2s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Vcban4zKEv1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fed09eb7-d77d-4bd8-8529-34ae53b75d72"
      },
      "source": [
        "%%time\n",
        "\n",
        "model = Sequential([\n",
        "        Conv2D(130, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(50, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(80, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Conv2D(250, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(430, activation='selu', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "loss: 2.064971685409546 - accuracy: 0.3657 - val_loss: 1.4674673080444336 - val_accuracy: 0.477 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "loss: 1.4317291975021362 - accuracy: 0.49284 - val_loss: 1.3502579927444458 - val_accuracy: 0.5144 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "loss: 1.2809815406799316 - accuracy: 0.5453 - val_loss: 1.278853416442871 - val_accuracy: 0.5474 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "loss: 1.1600797176361084 - accuracy: 0.58854 - val_loss: 1.1908364295959473 - val_accuracy: 0.5767 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "loss: 1.0447736978530884 - accuracy: 0.63098 - val_loss: 1.156123161315918 - val_accuracy: 0.597 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "loss: 0.9252257943153381 - accuracy: 0.67272 - val_loss: 1.126400351524353 - val_accuracy: 0.6074 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "loss: 0.8046407103538513 - accuracy: 0.71718 - val_loss: 1.1198372840881348 - val_accuracy: 0.6179 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "loss: 0.6971640586853027 - accuracy: 0.75288 - val_loss: 1.1441832780838013 - val_accuracy: 0.6281 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "loss: 0.5893728137016296 - accuracy: 0.79322 - val_loss: 1.1488935947418213 - val_accuracy: 0.6311 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "loss: 0.4847254753112793 - accuracy: 0.82932 - val_loss: 1.2176817655563354 - val_accuracy: 0.6327 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "loss: 0.41446205973625183 - accuracy: 0.85586 - val_loss: 1.2500206232070923 - val_accuracy: 0.6369 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "loss: 0.33975690603256226 - accuracy: 0.88168 - val_loss: 1.282813549041748 - val_accuracy: 0.6346 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "loss: 0.2850266993045807 - accuracy: 0.8997 - val_loss: 1.3853214979171753 - val_accuracy: 0.6394 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "loss: 0.24025051295757294 - accuracy: 0.91662 - val_loss: 1.4497275352478027 - val_accuracy: 0.6414 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "loss: 0.20378732681274414 - accuracy: 0.93024 - val_loss: 1.4719005823135376 - val_accuracy: 0.6405 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "loss: 0.17931272089481354 - accuracy: 0.93778 - val_loss: 1.5043904781341553 - val_accuracy: 0.6432 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "loss: 0.15186503529548645 - accuracy: 0.94868 - val_loss: 1.5284686088562012 - val_accuracy: 0.6443 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "loss: 0.13846157491207123 - accuracy: 0.95188 - val_loss: 1.6347123384475708 - val_accuracy: 0.6408 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "loss: 0.13032525777816772 - accuracy: 0.95502 - val_loss: 1.633957028388977 - val_accuracy: 0.6389 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "loss: 0.10857569426298141 - accuracy: 0.96344 - val_loss: 1.7090785503387451 - val_accuracy: 0.6509 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "CPU times: user 2min 39s, sys: 3.53 s, total: 2min 43s\n",
            "Wall time: 3min 3s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGcN0_PqLRlV"
      },
      "source": [
        "### Layer sizes set manually"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoJydQX7bsmq",
        "scrolled": false,
        "outputId": "c83f7f79-7bf7-4370-e9b4-33dcfad8d311"
      },
      "source": [
        "%%time\n",
        "\n",
        "model = Sequential([\n",
        "        Conv2D(3, 96, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(96, 96, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(96, 192, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', kernel_initializer='lecun_normal'),\n",
        "        Conv2D(96, 192, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(12288, 256, activation='selu', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Dense(256, 10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/25\n",
            "loss: 2.1398861408233643 - accuracy: 0.39144 - val_loss: 1.3741620779037476 - val_accuracy: 0.5007 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 2/25\n",
            "loss: 1.3535252809524536 - accuracy: 0.51546 - val_loss: 1.268190860748291 - val_accuracy: 0.5486 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 3/25\n",
            "loss: 1.1914558410644531 - accuracy: 0.5725 - val_loss: 1.166611671447754 - val_accuracy: 0.5835 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 4/25\n",
            "loss: 1.0351282358169556 - accuracy: 0.63084 - val_loss: 1.087954044342041 - val_accuracy: 0.623 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 5/25\n",
            "loss: 0.9159864783287048 - accuracy: 0.67614 - val_loss: 0.9969214797019958 - val_accuracy: 0.6613 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 6/25\n",
            "loss: 0.8134353160858154 - accuracy: 0.7108 - val_loss: 1.0081638097763062 - val_accuracy: 0.6658 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 7/25\n",
            "loss: 0.7176882028579712 - accuracy: 0.74724 - val_loss: 0.9864904284477234 - val_accuracy: 0.675 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 8/25\n",
            "loss: 0.6499534249305725 - accuracy: 0.76928 - val_loss: 0.973360538482666 - val_accuracy: 0.6957 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 9/25\n",
            "loss: 0.5757144093513489 - accuracy: 0.79518 - val_loss: 1.0311030149459839 - val_accuracy: 0.6877 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 10/25\n",
            "loss: 0.5312620997428894 - accuracy: 0.8151 - val_loss: 1.0731127262115479 - val_accuracy: 0.6944 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 11/25\n",
            "loss: 0.49278587102890015 - accuracy: 0.82826 - val_loss: 1.1032124757766724 - val_accuracy: 0.6912 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 12/25\n",
            "loss: 0.45533832907676697 - accuracy: 0.83932 - val_loss: 1.1450512409210205 - val_accuracy: 0.6946 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 13/25\n",
            "loss: 0.417134165763855 - accuracy: 0.8523 - val_loss: 1.137213945388794 - val_accuracy: 0.6986 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 14/25\n",
            "loss: 0.39540520310401917 - accuracy: 0.8612 - val_loss: 1.1061996221542358 - val_accuracy: 0.7029 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 15/25\n",
            "loss: 0.37588027119636536 - accuracy: 0.87056 - val_loss: 1.133886694908142 - val_accuracy: 0.7044 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 16/25\n",
            "loss: 0.34373739361763 - accuracy: 0.88308 - val_loss: 1.1591758728027344 - val_accuracy: 0.7147 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 17/25\n",
            "loss: 0.3225548565387726 - accuracy: 0.88992 - val_loss: 1.190388560295105 - val_accuracy: 0.711 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 18/25\n",
            "loss: 0.3176613748073578 - accuracy: 0.89348 - val_loss: 1.1829746961593628 - val_accuracy: 0.7074 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 19/25\n",
            "loss: 0.28977060317993164 - accuracy: 0.90038 - val_loss: 1.396437168121338 - val_accuracy: 0.7148 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 20/25\n",
            "loss: 0.28722086548805237 - accuracy: 0.90372 - val_loss: 1.291654348373413 - val_accuracy: 0.7115 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 21/25\n",
            "loss: 0.26941731572151184 - accuracy: 0.90884 - val_loss: 1.4155263900756836 - val_accuracy: 0.7053 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 22/25\n",
            "loss: 0.26944756507873535 - accuracy: 0.90862 - val_loss: 1.2642757892608643 - val_accuracy: 0.7172 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 23/25\n",
            "loss: 0.2647763788700104 - accuracy: 0.91274 - val_loss: 1.3459445238113403 - val_accuracy: 0.6958 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 24/25\n",
            "loss: 0.2519494593143463 - accuracy: 0.91652 - val_loss: 1.2954438924789429 - val_accuracy: 0.7191 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 25/25\n",
            "loss: 0.23448781669139862 - accuracy: 0.92198 - val_loss: 1.3476343154907227 - val_accuracy: 0.7157 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "CPU times: user 4min 53s, sys: 4 s, total: 4min 57s\n",
            "Wall time: 6min 27s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mjBr84v6Ktk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21ea0c14-2b46-405d-fc56-371ee2d2856f"
      },
      "source": [
        "%%time\n",
        "\n",
        "model = Sequential([\n",
        "        Conv2D(96, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(96, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='selu', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "loss: 2.116030216217041 - accuracy: 0.38428 - val_loss: 1.3876560926437378 - val_accuracy: 0.4998 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "loss: 1.360109567642212 - accuracy: 0.5092 - val_loss: 1.2392711639404297 - val_accuracy: 0.5579 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "loss: 1.202415108680725 - accuracy: 0.56706 - val_loss: 1.117976427078247 - val_accuracy: 0.5957 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "loss: 1.0698447227478027 - accuracy: 0.6183 - val_loss: 1.0646827220916748 - val_accuracy: 0.6295 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "loss: 0.9639225006103516 - accuracy: 0.65716 - val_loss: 0.9881615042686462 - val_accuracy: 0.6582 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "loss: 0.8609135746955872 - accuracy: 0.69368 - val_loss: 1.0106662511825562 - val_accuracy: 0.6663 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "loss: 0.7895837426185608 - accuracy: 0.72044 - val_loss: 0.9579691290855408 - val_accuracy: 0.6829 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "loss: 0.7255645394325256 - accuracy: 0.742 - val_loss: 0.9203139543533325 - val_accuracy: 0.6933 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "loss: 0.6741765737533569 - accuracy: 0.76052 - val_loss: 0.9133610129356384 - val_accuracy: 0.7121 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "loss: 0.6124322414398193 - accuracy: 0.78406 - val_loss: 0.9261025190353394 - val_accuracy: 0.7036 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "loss: 0.5763772130012512 - accuracy: 0.796 - val_loss: 0.9831997156143188 - val_accuracy: 0.7048 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "loss: 0.5292472839355469 - accuracy: 0.81348 - val_loss: 0.940315842628479 - val_accuracy: 0.7109 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "loss: 0.49868765473365784 - accuracy: 0.82296 - val_loss: 0.9559101462364197 - val_accuracy: 0.7194 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "loss: 0.46681809425354004 - accuracy: 0.8339 - val_loss: 0.9786410927772522 - val_accuracy: 0.7113 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "loss: 0.4455386698246002 - accuracy: 0.84384 - val_loss: 1.0370675325393677 - val_accuracy: 0.7156 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "loss: 0.431081086397171 - accuracy: 0.84874 - val_loss: 0.9598382115364075 - val_accuracy: 0.7327 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "loss: 0.39421042799949646 - accuracy: 0.86204 - val_loss: 0.9601312279701233 - val_accuracy: 0.7233 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "loss: 0.3889602720737457 - accuracy: 0.86446 - val_loss: 0.9993749260902405 - val_accuracy: 0.7196 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "loss: 0.3769107460975647 - accuracy: 0.86922 - val_loss: 1.0717551708221436 - val_accuracy: 0.7291 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "loss: 0.3443959653377533 - accuracy: 0.88068 - val_loss: 1.1164978742599487 - val_accuracy: 0.719 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "CPU times: user 2min 32s, sys: 4.41 s, total: 2min 37s\n",
            "Wall time: 3min 3s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFl0fNzo9tTT"
      },
      "source": [
        "### Lower learning rates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve0vEDGlNag4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2d30051-3219-4c2d-ab7d-438ffffc5b95"
      },
      "source": [
        "%%time\n",
        "\n",
        "model = Sequential([\n",
        "        Conv2D(96, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(96, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='selu', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "loss: 3.6364753246307373 - accuracy: 0.13834 - val_loss: 2.038997173309326 - val_accuracy: 0.1937 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "loss: 1.8863511085510254 - accuracy: 0.24728 - val_loss: 1.6929947137832642 - val_accuracy: 0.3369 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "loss: 1.5627237558364868 - accuracy: 0.40592 - val_loss: 1.4371005296707153 - val_accuracy: 0.4556 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "loss: 1.4159406423568726 - accuracy: 0.47122 - val_loss: 1.3222863674163818 - val_accuracy: 0.5077 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "loss: 1.2911038398742676 - accuracy: 0.52424 - val_loss: 1.2030831575393677 - val_accuracy: 0.5573 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "loss: 1.194854974746704 - accuracy: 0.56558 - val_loss: 1.162782907485962 - val_accuracy: 0.5652 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "loss: 1.1220676898956299 - accuracy: 0.59142 - val_loss: 1.115524172782898 - val_accuracy: 0.5981 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "loss: 1.0569331645965576 - accuracy: 0.61752 - val_loss: 1.0428560972213745 - val_accuracy: 0.6176 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "loss: 0.9967590570449829 - accuracy: 0.638 - val_loss: 1.0251280069351196 - val_accuracy: 0.6366 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "loss: 0.9514718651771545 - accuracy: 0.6595 - val_loss: 0.9853264689445496 - val_accuracy: 0.6495 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "loss: 0.8963597416877747 - accuracy: 0.67962 - val_loss: 0.9651879072189331 - val_accuracy: 0.6638 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "loss: 0.8530036211013794 - accuracy: 0.69698 - val_loss: 0.9137949347496033 - val_accuracy: 0.683 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "loss: 0.8059719800949097 - accuracy: 0.71514 - val_loss: 0.8971531987190247 - val_accuracy: 0.6994 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "loss: 0.7699702382087708 - accuracy: 0.73044 - val_loss: 0.9172139763832092 - val_accuracy: 0.6992 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "loss: 0.74892258644104 - accuracy: 0.7383 - val_loss: 0.9431652426719666 - val_accuracy: 0.6993 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "loss: 0.6957507729530334 - accuracy: 0.75576 - val_loss: 0.8777626752853394 - val_accuracy: 0.7111 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "loss: 0.696088969707489 - accuracy: 0.75654 - val_loss: 0.9330437779426575 - val_accuracy: 0.7144 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "loss: 0.6720901727676392 - accuracy: 0.76816 - val_loss: 0.9006590843200684 - val_accuracy: 0.7177 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "loss: 0.651520848274231 - accuracy: 0.77566 - val_loss: 0.8798283934593201 - val_accuracy: 0.7325 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "loss: 0.6420966982841492 - accuracy: 0.77946 - val_loss: 0.9747942090034485 - val_accuracy: 0.6975 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "CPU times: user 2min 32s, sys: 3 s, total: 2min 35s\n",
            "Wall time: 3min 1s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aduJ_eed85hy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86922ff3-dc1c-4f7a-dcee-4b132b2c5bcb"
      },
      "source": [
        "%%time\n",
        "\n",
        "model = Sequential([\n",
        "        Conv2D(96, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(96, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='selu', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "loss: 1.9364395141601562 - accuracy: 0.37422 - val_loss: 1.4458012580871582 - val_accuracy: 0.485 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "loss: 1.4242712259292603 - accuracy: 0.49284 - val_loss: 1.3421002626419067 - val_accuracy: 0.5156 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "loss: 1.289955735206604 - accuracy: 0.54334 - val_loss: 1.2476561069488525 - val_accuracy: 0.5556 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "loss: 1.170866847038269 - accuracy: 0.58414 - val_loss: 1.1811169385910034 - val_accuracy: 0.5738 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "loss: 1.0659559965133667 - accuracy: 0.6197 - val_loss: 1.1238079071044922 - val_accuracy: 0.6009 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "loss: 0.9630758762359619 - accuracy: 0.65902 - val_loss: 1.1032953262329102 - val_accuracy: 0.6142 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "loss: 0.8649547100067139 - accuracy: 0.69482 - val_loss: 1.086409330368042 - val_accuracy: 0.6278 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "loss: 0.7637264728546143 - accuracy: 0.72968 - val_loss: 1.088549256324768 - val_accuracy: 0.6318 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "loss: 0.6691085696220398 - accuracy: 0.76486 - val_loss: 1.1164265871047974 - val_accuracy: 0.636 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "loss: 0.5807543992996216 - accuracy: 0.79298 - val_loss: 1.1370887756347656 - val_accuracy: 0.6419 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "loss: 0.5004003047943115 - accuracy: 0.82274 - val_loss: 1.1191058158874512 - val_accuracy: 0.6532 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "loss: 0.42416244745254517 - accuracy: 0.84982 - val_loss: 1.1677745580673218 - val_accuracy: 0.6552 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "loss: 0.3670492470264435 - accuracy: 0.87066 - val_loss: 1.2148022651672363 - val_accuracy: 0.6517 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "loss: 0.3215842843055725 - accuracy: 0.88494 - val_loss: 1.2641360759735107 - val_accuracy: 0.6618 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "loss: 0.2755711078643799 - accuracy: 0.90228 - val_loss: 1.2828997373580933 - val_accuracy: 0.6633 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "loss: 0.2423623651266098 - accuracy: 0.91376 - val_loss: 1.343477487564087 - val_accuracy: 0.6669 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "loss: 0.21431538462638855 - accuracy: 0.92396 - val_loss: 1.3868709802627563 - val_accuracy: 0.6588 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "loss: 0.18811562657356262 - accuracy: 0.93352 - val_loss: 1.4123141765594482 - val_accuracy: 0.6678 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "loss: 0.16785545647144318 - accuracy: 0.94086 - val_loss: 1.4013440608978271 - val_accuracy: 0.6716 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "loss: 0.15461832284927368 - accuracy: 0.9453 - val_loss: 1.5946664810180664 - val_accuracy: 0.6722 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "CPU times: user 2min 30s, sys: 10.6 s, total: 2min 41s\n",
            "Wall time: 3min 6s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-k3hAil5L51"
      },
      "source": [
        "## Cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y2__LWC5PZ9"
      },
      "source": [
        "epochs = 35\n",
        "self_scaling_epochs = 20\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4Bu2ni558t9",
        "outputId": "604e37e3-f42c-4882-fd6e-8d469e75cc73"
      },
      "source": [
        "%%time\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
        "\n",
        "best_val_accuracies = list()\n",
        "layer_sizes = list()\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X_norm)):\n",
        "    xtrain, xtest = X_norm[train_index], X_norm[test_index]\n",
        "    ytrain, ytest = y[train_index], y[test_index]\n",
        "\n",
        "    model = Sequential([\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None, fixed_size=True),\n",
        "    ])\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "    history = model.fit(xtrain, ytrain, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "              min_new_neurons, validation_data=(xtest, ytest), verbose=False)\n",
        "    best_val_accuracy = max(history['val_accuracy'])\n",
        "    current_layer_sizes = model.get_layer_sizes()\n",
        "    best_val_accuracies.append(best_val_accuracy)\n",
        "    layer_sizes.append(current_layer_sizes)\n",
        "    print(f\"Run {i} completed, best val accuracy: {best_val_accuracy}, layer sizes: {current_layer_sizes}\")\n",
        "\n",
        "print(f'val accuracies: {best_val_accuracies}')\n",
        "print(f'mean val accuracy: {np.mean(best_val_accuracies)}')\n",
        "\n",
        "print(f'mean layer sizes: {[np.mean(layer) for layer in list(zip(*layer_sizes))]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best val accuracy: 0.7553, layer sizes: [3, 132, 58, 74, 266, 444, 10]\n",
            "Run 1 completed, best val accuracy: 0.7542, layer sizes: [3, 125, 51, 69, 275, 427, 10]\n",
            "Run 2 completed, best val accuracy: 0.7571, layer sizes: [3, 135, 46, 76, 269, 446, 10]\n",
            "Run 3 completed, best val accuracy: 0.7636, layer sizes: [3, 135, 59, 77, 257, 410, 10]\n",
            "Run 4 completed, best val accuracy: 0.7635, layer sizes: [3, 130, 39, 84, 266, 469, 10]\n",
            "Run 5 completed, best val accuracy: 0.7495, layer sizes: [3, 127, 52, 54, 279, 403, 10]\n",
            "val accuracies: [0.7553, 0.7542, 0.7571, 0.7636, 0.7635, 0.7495]\n",
            "mean val accuracy: 0.7572\n",
            "mean layer sizes: [3.0, 130.66666666666666, 50.833333333333336, 72.33333333333333, 268.6666666666667, 433.1666666666667, 10.0]\n",
            "CPU times: user 44min 48s, sys: 34.8 s, total: 45min 23s\n",
            "Wall time: 52min 53s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1o_W2WhYDWh"
      },
      "source": [
        "epochs = 50\n",
        "self_scaling_epochs = 25\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeAx_rDdYESI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "386e69d9-bb2b-48d3-8e42-65b4e81d93c9"
      },
      "source": [
        "%%time\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
        "\n",
        "best_val_accuracies = list()\n",
        "layer_sizes = list()\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X_norm)):\n",
        "    xtrain, xtest = X_norm[train_index], X_norm[test_index]\n",
        "    ytrain, ytest = y[train_index], y[test_index]\n",
        "\n",
        "    model = Sequential([\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None, fixed_size=True),\n",
        "    ])\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "    history = model.fit(xtrain, ytrain, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "              min_new_neurons, validation_data=(xtest, ytest), verbose=False)\n",
        "    best_val_accuracy = max(history['val_accuracy'])\n",
        "    current_layer_sizes = model.get_layer_sizes()\n",
        "    best_val_accuracies.append(best_val_accuracy)\n",
        "    layer_sizes.append(current_layer_sizes)\n",
        "    print(f\"Run {i} completed, best val accuracy: {best_val_accuracy}, layer sizes: {current_layer_sizes}\")\n",
        "\n",
        "print(f'val accuracies: {best_val_accuracies}')\n",
        "print(f'mean val accuracy: {np.mean(best_val_accuracies)}')\n",
        "\n",
        "print(f'mean layer sizes: {[np.mean(layer) for layer in list(zip(*layer_sizes))]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best val accuracy: 0.7643, layer sizes: [3, 98, 48, 75, 263, 481, 10]\n",
            "Run 1 completed, best val accuracy: 0.7576, layer sizes: [3, 119, 40, 72, 269, 470, 10]\n",
            "Run 2 completed, best val accuracy: 0.7596, layer sizes: [3, 119, 48, 78, 274, 443, 10]\n",
            "Run 3 completed, best val accuracy: 0.7656, layer sizes: [3, 119, 45, 77, 263, 484, 10]\n",
            "Run 4 completed, best val accuracy: 0.7702, layer sizes: [3, 117, 47, 75, 275, 466, 10]\n",
            "Run 5 completed, best val accuracy: 0.759, layer sizes: [3, 110, 44, 81, 255, 457, 10]\n",
            "val accuracies: [0.7643, 0.7576, 0.7596, 0.7656, 0.7702, 0.759]\n",
            "mean val accuracy: 0.7627166666666668\n",
            "mean layer sizes: [3.0, 113.66666666666667, 45.333333333333336, 76.33333333333333, 266.5, 466.8333333333333, 10.0]\n",
            "CPU times: user 50min 16s, sys: 58.8 s, total: 51min 14s\n",
            "Wall time: 1h 2min 29s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h5QqE-Qm-Jx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79e506c0-59b4-4c57-8a7c-eccf3e24cd2a"
      },
      "source": [
        "model = Sequential([\n",
        "        Conv2D(114, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(45, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(76, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Conv2D(267, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(467, activation='selu', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "history = model.fit(xtrain, ytrain, optimizer, 1, 0, batch_size, \n",
        "          min_new_neurons, validation_data=(xtest, ytest))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/1\n",
            "loss: 1.965653419494629 - accuracy: 0.37426 - val_loss: 1.4655945301055908 - val_accuracy: 0.4803 - penalty: 0.0\n",
            "hidden layer sizes: [114, 45, 76, 267, 467], total units: 969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tlm8zKmxnD8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cd8d9e0-4f69-496f-bf61-429041b494c4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_36 (Conv2D)           multiple                  3192      \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           multiple                  46215     \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           multiple                  30856     \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           multiple                  182895    \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             multiple                  7980563   \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             multiple                  4680      \n",
            "=================================================================\n",
            "Total params: 8,248,401\n",
            "Trainable params: 8,248,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8xaPCR1oXDf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e0f9c09-9c43-4bf1-feb1-a3c7dbfff163"
      },
      "source": [
        "model = Sequential([\n",
        "        Conv2D(230, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(230, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(230, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Conv2D(230, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(467, activation='selu', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "history = model.fit(xtrain, ytrain, optimizer, 1, 0, batch_size, \n",
        "          min_new_neurons, validation_data=(xtest, ytest))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/1\n",
            "loss: 1.9921919107437134 - accuracy: 0.37894 - val_loss: 1.4179928302764893 - val_accuracy: 0.4905 - penalty: 0.0\n",
            "hidden layer sizes: [230, 230, 230, 230, 467], total units: 1387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLux4rF1og7W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d400498-da04-4d03-e933-960f83a8439d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_60 (Conv2D)           multiple                  6440      \n",
            "_________________________________________________________________\n",
            "conv2d_61 (Conv2D)           multiple                  476330    \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv2d_62 (Conv2D)           multiple                  476330    \n",
            "_________________________________________________________________\n",
            "conv2d_63 (Conv2D)           multiple                  476330    \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten_15 (Flatten)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             multiple                  6874707   \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             multiple                  4680      \n",
            "=================================================================\n",
            "Total params: 8,314,817\n",
            "Trainable params: 8,314,817\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaIceDYnqfW2"
      },
      "source": [
        "epochs = 50\n",
        "self_scaling_epochs = 0\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xViY1-jSqbC7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00e374b7-7822-483a-a57f-4b91f15b55be"
      },
      "source": [
        "%%time\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
        "\n",
        "best_val_accuracies = list()\n",
        "layer_sizes = list()\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X_norm)):\n",
        "    xtrain, xtest = X_norm[train_index], X_norm[test_index]\n",
        "    ytrain, ytest = y[train_index], y[test_index]\n",
        "\n",
        "    model = Sequential([\n",
        "        Conv2D(160, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(160, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(160, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Conv2D(160, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(467, activation='selu', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None),\n",
        "    ])\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.002)\n",
        "\n",
        "    history = model.fit(xtrain, ytrain, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "              min_new_neurons, validation_data=(xtest, ytest), verbose=False)\n",
        "    best_val_accuracy = max(history['val_accuracy'])\n",
        "    current_layer_sizes = model.get_layer_sizes()\n",
        "    best_val_accuracies.append(best_val_accuracy)\n",
        "    layer_sizes.append(current_layer_sizes)\n",
        "    print(f\"Run {i} completed, best val accuracy: {best_val_accuracy}, layer sizes: {current_layer_sizes}\")\n",
        "\n",
        "print(f'val accuracies: {best_val_accuracies}')\n",
        "print(f'mean val accuracy: {np.mean(best_val_accuracies)}')\n",
        "\n",
        "print(f'mean layer sizes: {[np.mean(layer) for layer in list(zip(*layer_sizes))]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best val accuracy: 0.7513, layer sizes: [3, 160, 160, 160, 160, 467, 10]\n",
            "Run 1 completed, best val accuracy: 0.7603, layer sizes: [3, 160, 160, 160, 160, 467, 10]\n",
            "Run 2 completed, best val accuracy: 0.7592, layer sizes: [3, 160, 160, 160, 160, 467, 10]\n",
            "Run 3 completed, best val accuracy: 0.7576, layer sizes: [3, 160, 160, 160, 160, 467, 10]\n",
            "Run 4 completed, best val accuracy: 0.7612, layer sizes: [3, 160, 160, 160, 160, 467, 10]\n",
            "Run 5 completed, best val accuracy: 0.1059, layer sizes: [3, 160, 160, 160, 160, 467, 10]\n",
            "val accuracies: [0.7513, 0.7603, 0.7592, 0.7576, 0.7612, 0.1059]\n",
            "mean val accuracy: 0.64925\n",
            "mean layer sizes: [3.0, 160.0, 160.0, 160.0, 160.0, 467.0, 10.0]\n",
            "CPU times: user 45min 40s, sys: 30.3 s, total: 46min 11s\n",
            "Wall time: 1h 46s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fc5eI_Mc4oG_"
      },
      "source": [
        "epochs = 50\n",
        "self_scaling_epochs = 25\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciCjJU8k4uCh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dce0f272-8798-45cb-d6b6-1b20eab9d0ec"
      },
      "source": [
        "model = Sequential([\n",
        "        Conv2D(384, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(384, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(384, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        Conv2D(384, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(512, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None, fixed_size=True),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.874368906021118 - val_accuracy: 0.1249 - penalty: 1e-06\n",
            "hidden layer sizes: [384, 384, 384, 384, 512], total units: 2048\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.874368667602539 - val_accuracy: 0.1249 - penalty: 1e-06\n",
            "hidden layer sizes: [460, 460, 460, 460, 614], total units: 2454\n",
            "Before pruning:\n",
            "loss: 2.0449135303497314 - accuracy: 0.39778 - val_loss: 1.3934240341186523 - val_accuracy: 0.4986 - penalty: 1e-06\n",
            "hidden layer sizes: [460, 460, 460, 460, 614], total units: 2454\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.3925364017486572 - val_accuracy: 0.4994 - penalty: 1e-06\n",
            "hidden layer sizes: [384, 384, 384, 384, 512], total units: 2048\n",
            "##########################################################\n",
            "Epoch 2/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.3925364017486572 - val_accuracy: 0.4994 - penalty: 1e-06\n",
            "hidden layer sizes: [384, 384, 384, 384, 512], total units: 2048\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.3925364017486572 - val_accuracy: 0.4994 - penalty: 1e-06\n",
            "hidden layer sizes: [460, 460, 460, 460, 614], total units: 2454\n",
            "Before pruning:\n",
            "loss: 1.68781316280365 - accuracy: 0.4063 - val_loss: 1.4149715900421143 - val_accuracy: 0.4873 - penalty: 1e-06\n",
            "hidden layer sizes: [460, 460, 460, 460, 614], total units: 2454\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.414810061454773 - val_accuracy: 0.4872 - penalty: 1e-06\n",
            "hidden layer sizes: [384, 380, 384, 384, 538], total units: 2070\n",
            "##########################################################\n",
            "Epoch 3/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.414810061454773 - val_accuracy: 0.4872 - penalty: 1e-06\n",
            "hidden layer sizes: [384, 380, 384, 384, 538], total units: 2070\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.414810061454773 - val_accuracy: 0.4872 - penalty: 1e-06\n",
            "hidden layer sizes: [460, 456, 460, 460, 645], total units: 2481\n",
            "Before pruning:\n",
            "loss: 1.4132434129714966 - accuracy: 0.49126 - val_loss: 1.233077883720398 - val_accuracy: 0.5541 - penalty: 1e-06\n",
            "hidden layer sizes: [460, 456, 460, 460, 645], total units: 2481\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.2322417497634888 - val_accuracy: 0.555 - penalty: 1e-06\n",
            "hidden layer sizes: [384, 143, 263, 227, 518], total units: 1535\n",
            "##########################################################\n",
            "Epoch 4/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2322417497634888 - val_accuracy: 0.555 - penalty: 1e-06\n",
            "hidden layer sizes: [384, 143, 263, 227, 518], total units: 1535\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2322419881820679 - val_accuracy: 0.555 - penalty: 1e-06\n",
            "hidden layer sizes: [460, 171, 315, 272, 621], total units: 1839\n",
            "Before pruning:\n",
            "loss: 1.2615054845809937 - accuracy: 0.54666 - val_loss: 1.1507588624954224 - val_accuracy: 0.5888 - penalty: 1e-06\n",
            "hidden layer sizes: [460, 171, 315, 272, 621], total units: 1839\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1491756439208984 - val_accuracy: 0.5893 - penalty: 1e-06\n",
            "hidden layer sizes: [384, 82, 151, 156, 512], total units: 1285\n",
            "##########################################################\n",
            "Epoch 5/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1491756439208984 - val_accuracy: 0.5893 - penalty: 1e-06\n",
            "hidden layer sizes: [384, 82, 151, 156, 512], total units: 1285\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1491756439208984 - val_accuracy: 0.5893 - penalty: 1e-06\n",
            "hidden layer sizes: [460, 102, 181, 187, 614], total units: 1544\n",
            "Before pruning:\n",
            "loss: 1.163135290145874 - accuracy: 0.57992 - val_loss: 1.0606696605682373 - val_accuracy: 0.6195 - penalty: 1e-06\n",
            "hidden layer sizes: [460, 102, 181, 187, 614], total units: 1544\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.059525728225708 - val_accuracy: 0.62 - penalty: 1e-06\n",
            "hidden layer sizes: [383, 63, 112, 158, 515], total units: 1231\n",
            "##########################################################\n",
            "Epoch 6/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.059525728225708 - val_accuracy: 0.62 - penalty: 1e-06\n",
            "hidden layer sizes: [383, 63, 112, 158, 515], total units: 1231\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.059525728225708 - val_accuracy: 0.62 - penalty: 1e-06\n",
            "hidden layer sizes: [459, 83, 134, 189, 618], total units: 1483\n",
            "Before pruning:\n",
            "loss: 1.091322422027588 - accuracy: 0.6089 - val_loss: 0.997189462184906 - val_accuracy: 0.6414 - penalty: 1e-06\n",
            "hidden layer sizes: [459, 83, 134, 189, 618], total units: 1483\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9965173602104187 - val_accuracy: 0.6411 - penalty: 1e-06\n",
            "hidden layer sizes: [373, 51, 93, 162, 525], total units: 1204\n",
            "##########################################################\n",
            "Epoch 7/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9965173602104187 - val_accuracy: 0.6411 - penalty: 1e-06\n",
            "hidden layer sizes: [373, 51, 93, 162, 525], total units: 1204\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9965173602104187 - val_accuracy: 0.6411 - penalty: 1e-06\n",
            "hidden layer sizes: [447, 71, 113, 194, 630], total units: 1455\n",
            "Before pruning:\n",
            "loss: 1.0395821332931519 - accuracy: 0.62752 - val_loss: 0.9697657227516174 - val_accuracy: 0.6522 - penalty: 1e-06\n",
            "hidden layer sizes: [447, 71, 113, 194, 630], total units: 1455\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9696459770202637 - val_accuracy: 0.6527 - penalty: 1e-06\n",
            "hidden layer sizes: [343, 42, 85, 161, 531], total units: 1162\n",
            "##########################################################\n",
            "Epoch 8/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9696459770202637 - val_accuracy: 0.6527 - penalty: 1e-06\n",
            "hidden layer sizes: [343, 42, 85, 161, 531], total units: 1162\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9696460962295532 - val_accuracy: 0.6527 - penalty: 1e-06\n",
            "hidden layer sizes: [411, 62, 105, 193, 637], total units: 1408\n",
            "Before pruning:\n",
            "loss: 0.9998885989189148 - accuracy: 0.64256 - val_loss: 0.9444265365600586 - val_accuracy: 0.6589 - penalty: 1e-06\n",
            "hidden layer sizes: [411, 62, 105, 193, 637], total units: 1408\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9442426562309265 - val_accuracy: 0.659 - penalty: 1e-06\n",
            "hidden layer sizes: [301, 38, 79, 166, 556], total units: 1140\n",
            "##########################################################\n",
            "Epoch 9/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9442426562309265 - val_accuracy: 0.659 - penalty: 1e-06\n",
            "hidden layer sizes: [301, 38, 79, 166, 556], total units: 1140\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9442425966262817 - val_accuracy: 0.659 - penalty: 1e-06\n",
            "hidden layer sizes: [361, 58, 99, 199, 667], total units: 1384\n",
            "Before pruning:\n",
            "loss: 0.9640464782714844 - accuracy: 0.65582 - val_loss: 0.9058793187141418 - val_accuracy: 0.6685 - penalty: 1e-06\n",
            "hidden layer sizes: [361, 58, 99, 199, 667], total units: 1384\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.905951976776123 - val_accuracy: 0.6681 - penalty: 1e-06\n",
            "hidden layer sizes: [266, 36, 77, 186, 541], total units: 1106\n",
            "##########################################################\n",
            "Epoch 10/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.905951976776123 - val_accuracy: 0.6681 - penalty: 1e-06\n",
            "hidden layer sizes: [266, 36, 77, 186, 541], total units: 1106\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9059520363807678 - val_accuracy: 0.6681 - penalty: 1e-06\n",
            "hidden layer sizes: [319, 56, 97, 223, 649], total units: 1344\n",
            "Before pruning:\n",
            "loss: 0.9322066307067871 - accuracy: 0.66938 - val_loss: 0.8975723385810852 - val_accuracy: 0.679 - penalty: 1e-06\n",
            "hidden layer sizes: [319, 56, 97, 223, 649], total units: 1344\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8972094655036926 - val_accuracy: 0.6793 - penalty: 1e-06\n",
            "hidden layer sizes: [233, 39, 75, 190, 545], total units: 1082\n",
            "##########################################################\n",
            "Epoch 11/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8972094655036926 - val_accuracy: 0.6793 - penalty: 1e-06\n",
            "hidden layer sizes: [233, 39, 75, 190, 545], total units: 1082\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8972094655036926 - val_accuracy: 0.6793 - penalty: 1e-06\n",
            "hidden layer sizes: [279, 59, 95, 228, 654], total units: 1315\n",
            "Before pruning:\n",
            "loss: 0.8989497423171997 - accuracy: 0.67968 - val_loss: 0.8723036050796509 - val_accuracy: 0.6891 - penalty: 1e-06\n",
            "hidden layer sizes: [279, 59, 95, 228, 654], total units: 1315\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.871769905090332 - val_accuracy: 0.6893 - penalty: 1e-06\n",
            "hidden layer sizes: [212, 34, 69, 187, 555], total units: 1057\n",
            "##########################################################\n",
            "Epoch 12/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.871769905090332 - val_accuracy: 0.6893 - penalty: 1e-06\n",
            "hidden layer sizes: [212, 34, 69, 187, 555], total units: 1057\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.871769905090332 - val_accuracy: 0.6893 - penalty: 1e-06\n",
            "hidden layer sizes: [254, 54, 89, 224, 666], total units: 1287\n",
            "Before pruning:\n",
            "loss: 0.8731729984283447 - accuracy: 0.6897 - val_loss: 0.8531659245491028 - val_accuracy: 0.7034 - penalty: 1e-06\n",
            "hidden layer sizes: [254, 54, 89, 224, 666], total units: 1287\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8530040979385376 - val_accuracy: 0.7033 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 36, 65, 204, 570], total units: 1066\n",
            "##########################################################\n",
            "Epoch 13/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8530040979385376 - val_accuracy: 0.7033 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 36, 65, 204, 570], total units: 1066\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8530040979385376 - val_accuracy: 0.7033 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 56, 85, 244, 684], total units: 1298\n",
            "Before pruning:\n",
            "loss: 0.8479366302490234 - accuracy: 0.70082 - val_loss: 0.8303901553153992 - val_accuracy: 0.7132 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 56, 85, 244, 684], total units: 1298\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8298168182373047 - val_accuracy: 0.7131 - penalty: 1e-06\n",
            "hidden layer sizes: [171, 32, 61, 211, 565], total units: 1040\n",
            "##########################################################\n",
            "Epoch 14/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8298168182373047 - val_accuracy: 0.7131 - penalty: 1e-06\n",
            "hidden layer sizes: [171, 32, 61, 211, 565], total units: 1040\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8298168778419495 - val_accuracy: 0.7131 - penalty: 1e-06\n",
            "hidden layer sizes: [205, 52, 81, 253, 678], total units: 1269\n",
            "Before pruning:\n",
            "loss: 0.8248564600944519 - accuracy: 0.70782 - val_loss: 0.8222730755805969 - val_accuracy: 0.7176 - penalty: 1e-06\n",
            "hidden layer sizes: [205, 52, 81, 253, 678], total units: 1269\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8218467831611633 - val_accuracy: 0.7178 - penalty: 1e-06\n",
            "hidden layer sizes: [166, 33, 61, 210, 548], total units: 1018\n",
            "##########################################################\n",
            "Epoch 15/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8218467831611633 - val_accuracy: 0.7178 - penalty: 1e-06\n",
            "hidden layer sizes: [166, 33, 61, 210, 548], total units: 1018\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8218469023704529 - val_accuracy: 0.7178 - penalty: 1e-06\n",
            "hidden layer sizes: [199, 53, 81, 252, 657], total units: 1242\n",
            "Before pruning:\n",
            "loss: 0.8047822713851929 - accuracy: 0.71652 - val_loss: 0.8008055686950684 - val_accuracy: 0.7212 - penalty: 1e-06\n",
            "hidden layer sizes: [199, 53, 81, 252, 657], total units: 1242\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8007141947746277 - val_accuracy: 0.721 - penalty: 1e-06\n",
            "hidden layer sizes: [164, 32, 58, 212, 550], total units: 1016\n",
            "##########################################################\n",
            "Epoch 16/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8007141947746277 - val_accuracy: 0.721 - penalty: 1e-06\n",
            "hidden layer sizes: [164, 32, 58, 212, 550], total units: 1016\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8007141947746277 - val_accuracy: 0.721 - penalty: 1e-06\n",
            "hidden layer sizes: [196, 52, 78, 254, 660], total units: 1240\n",
            "Before pruning:\n",
            "loss: 0.7872124314308167 - accuracy: 0.72222 - val_loss: 0.7919053435325623 - val_accuracy: 0.7227 - penalty: 1e-06\n",
            "hidden layer sizes: [196, 52, 78, 254, 660], total units: 1240\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7915626764297485 - val_accuracy: 0.7227 - penalty: 1e-06\n",
            "hidden layer sizes: [157, 33, 57, 218, 584], total units: 1049\n",
            "##########################################################\n",
            "Epoch 17/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7915626764297485 - val_accuracy: 0.7227 - penalty: 1e-06\n",
            "hidden layer sizes: [157, 33, 57, 218, 584], total units: 1049\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7915626764297485 - val_accuracy: 0.7227 - penalty: 1e-06\n",
            "hidden layer sizes: [188, 53, 77, 261, 700], total units: 1279\n",
            "Before pruning:\n",
            "loss: 0.7659136056900024 - accuracy: 0.72836 - val_loss: 0.7867453098297119 - val_accuracy: 0.7249 - penalty: 1e-06\n",
            "hidden layer sizes: [188, 53, 77, 261, 700], total units: 1279\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7865752577781677 - val_accuracy: 0.7247 - penalty: 1e-06\n",
            "hidden layer sizes: [149, 31, 56, 224, 547], total units: 1007\n",
            "##########################################################\n",
            "Epoch 18/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7865752577781677 - val_accuracy: 0.7247 - penalty: 1e-06\n",
            "hidden layer sizes: [149, 31, 56, 224, 547], total units: 1007\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7865751385688782 - val_accuracy: 0.7247 - penalty: 1e-06\n",
            "hidden layer sizes: [178, 51, 76, 268, 656], total units: 1229\n",
            "Before pruning:\n",
            "loss: 0.7590831518173218 - accuracy: 0.73202 - val_loss: 0.7937287092208862 - val_accuracy: 0.7223 - penalty: 1e-06\n",
            "hidden layer sizes: [178, 51, 76, 268, 656], total units: 1229\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7932314276695251 - val_accuracy: 0.7223 - penalty: 1e-06\n",
            "hidden layer sizes: [142, 36, 57, 222, 564], total units: 1021\n",
            "##########################################################\n",
            "Epoch 19/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7932314276695251 - val_accuracy: 0.7223 - penalty: 1e-06\n",
            "hidden layer sizes: [142, 36, 57, 222, 564], total units: 1021\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7932314276695251 - val_accuracy: 0.7223 - penalty: 1e-06\n",
            "hidden layer sizes: [170, 56, 77, 266, 676], total units: 1245\n",
            "Before pruning:\n",
            "loss: 0.7401538491249084 - accuracy: 0.73874 - val_loss: 0.8013793230056763 - val_accuracy: 0.7184 - penalty: 1e-06\n",
            "hidden layer sizes: [170, 56, 77, 266, 676], total units: 1245\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.800962507724762 - val_accuracy: 0.7183 - penalty: 1e-06\n",
            "hidden layer sizes: [136, 33, 53, 230, 607], total units: 1059\n",
            "##########################################################\n",
            "Epoch 20/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.800962507724762 - val_accuracy: 0.7183 - penalty: 1e-06\n",
            "hidden layer sizes: [136, 33, 53, 230, 607], total units: 1059\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8009623885154724 - val_accuracy: 0.7183 - penalty: 1e-06\n",
            "hidden layer sizes: [163, 53, 73, 276, 728], total units: 1293\n",
            "Before pruning:\n",
            "loss: 0.7263115644454956 - accuracy: 0.74252 - val_loss: 0.7856735587120056 - val_accuracy: 0.7261 - penalty: 1e-06\n",
            "hidden layer sizes: [163, 53, 73, 276, 728], total units: 1293\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7851793169975281 - val_accuracy: 0.7264 - penalty: 1e-06\n",
            "hidden layer sizes: [135, 31, 52, 224, 626], total units: 1068\n",
            "##########################################################\n",
            "Epoch 21/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7851793169975281 - val_accuracy: 0.7264 - penalty: 1e-06\n",
            "hidden layer sizes: [135, 31, 52, 224, 626], total units: 1068\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7851793766021729 - val_accuracy: 0.7264 - penalty: 1e-06\n",
            "hidden layer sizes: [162, 51, 72, 268, 751], total units: 1304\n",
            "Before pruning:\n",
            "loss: 0.7165889739990234 - accuracy: 0.74462 - val_loss: 0.7876863479614258 - val_accuracy: 0.7239 - penalty: 1e-06\n",
            "hidden layer sizes: [162, 51, 72, 268, 751], total units: 1304\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7867887616157532 - val_accuracy: 0.7245 - penalty: 1e-06\n",
            "hidden layer sizes: [130, 33, 55, 226, 622], total units: 1066\n",
            "##########################################################\n",
            "Epoch 22/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7867887616157532 - val_accuracy: 0.7245 - penalty: 1e-06\n",
            "hidden layer sizes: [130, 33, 55, 226, 622], total units: 1066\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7867888808250427 - val_accuracy: 0.7245 - penalty: 1e-06\n",
            "hidden layer sizes: [156, 53, 75, 271, 746], total units: 1301\n",
            "Before pruning:\n",
            "loss: 0.7094374895095825 - accuracy: 0.75038 - val_loss: 0.7761440873146057 - val_accuracy: 0.7304 - penalty: 1e-06\n",
            "hidden layer sizes: [156, 53, 75, 271, 746], total units: 1301\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7757372260093689 - val_accuracy: 0.7305 - penalty: 1e-06\n",
            "hidden layer sizes: [125, 31, 61, 226, 601], total units: 1044\n",
            "##########################################################\n",
            "Epoch 23/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7757372260093689 - val_accuracy: 0.7305 - penalty: 1e-06\n",
            "hidden layer sizes: [125, 31, 61, 226, 601], total units: 1044\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7757372260093689 - val_accuracy: 0.7305 - penalty: 1e-06\n",
            "hidden layer sizes: [150, 51, 81, 271, 721], total units: 1274\n",
            "Before pruning:\n",
            "loss: 0.6973488330841064 - accuracy: 0.75194 - val_loss: 0.7685597538948059 - val_accuracy: 0.7339 - penalty: 1e-06\n",
            "hidden layer sizes: [150, 51, 81, 271, 721], total units: 1274\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7685316205024719 - val_accuracy: 0.7337 - penalty: 1e-06\n",
            "hidden layer sizes: [119, 31, 55, 227, 626], total units: 1058\n",
            "##########################################################\n",
            "Epoch 24/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7685316205024719 - val_accuracy: 0.7337 - penalty: 1e-06\n",
            "hidden layer sizes: [119, 31, 55, 227, 626], total units: 1058\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7685315608978271 - val_accuracy: 0.7337 - penalty: 1e-06\n",
            "hidden layer sizes: [142, 51, 75, 272, 751], total units: 1291\n",
            "Before pruning:\n",
            "loss: 0.690315842628479 - accuracy: 0.75536 - val_loss: 0.7655007243156433 - val_accuracy: 0.733 - penalty: 1e-06\n",
            "hidden layer sizes: [142, 51, 75, 272, 751], total units: 1291\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7653404474258423 - val_accuracy: 0.7326 - penalty: 1e-06\n",
            "hidden layer sizes: [111, 29, 59, 231, 688], total units: 1118\n",
            "##########################################################\n",
            "Epoch 25/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7653404474258423 - val_accuracy: 0.7326 - penalty: 1e-06\n",
            "hidden layer sizes: [111, 29, 59, 231, 688], total units: 1118\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7653404474258423 - val_accuracy: 0.7326 - penalty: 1e-06\n",
            "hidden layer sizes: [133, 49, 79, 277, 825], total units: 1363\n",
            "Before pruning:\n",
            "loss: 0.6783690452575684 - accuracy: 0.75854 - val_loss: 0.7644909024238586 - val_accuracy: 0.7365 - penalty: 1e-06\n",
            "hidden layer sizes: [133, 49, 79, 277, 825], total units: 1363\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.76437908411026 - val_accuracy: 0.7365 - penalty: 1e-06\n",
            "hidden layer sizes: [111, 33, 55, 233, 636], total units: 1068\n",
            "##########################################################\n",
            "Epoch 26/50\n",
            "loss: 0.7044782638549805 - accuracy: 0.75156 - val_loss: 0.8295121788978577 - val_accuracy: 0.7192 - penalty: 0.0\n",
            "hidden layer sizes: [111, 33, 55, 233, 636], total units: 1068\n",
            "##########################################################\n",
            "Epoch 27/50\n",
            "loss: 0.5847506523132324 - accuracy: 0.79178 - val_loss: 0.7885305285453796 - val_accuracy: 0.7322 - penalty: 0.0\n",
            "hidden layer sizes: [111, 33, 55, 233, 636], total units: 1068\n",
            "##########################################################\n",
            "Epoch 28/50\n",
            "loss: 0.5221880078315735 - accuracy: 0.81344 - val_loss: 0.7804585695266724 - val_accuracy: 0.7446 - penalty: 0.0\n",
            "hidden layer sizes: [111, 33, 55, 233, 636], total units: 1068\n",
            "##########################################################\n",
            "Epoch 29/50\n",
            "loss: 0.44434401392936707 - accuracy: 0.842 - val_loss: 0.8183581829071045 - val_accuracy: 0.7409 - penalty: 0.0\n",
            "hidden layer sizes: [111, 33, 55, 233, 636], total units: 1068\n",
            "##########################################################\n",
            "Epoch 30/50\n",
            "loss: 0.37124761939048767 - accuracy: 0.86708 - val_loss: 0.8379212617874146 - val_accuracy: 0.7458 - penalty: 0.0\n",
            "hidden layer sizes: [111, 33, 55, 233, 636], total units: 1068\n",
            "##########################################################\n",
            "Epoch 31/50\n",
            "loss: 0.30291858315467834 - accuracy: 0.89244 - val_loss: 0.8625260591506958 - val_accuracy: 0.7434 - penalty: 0.0\n",
            "hidden layer sizes: [111, 33, 55, 233, 636], total units: 1068\n",
            "##########################################################\n",
            "Epoch 32/50\n",
            "loss: 0.23863212764263153 - accuracy: 0.9152 - val_loss: 0.908597469329834 - val_accuracy: 0.7428 - penalty: 0.0\n",
            "hidden layer sizes: [111, 33, 55, 233, 636], total units: 1068\n",
            "##########################################################\n",
            "Epoch 33/50\n",
            "loss: 0.19340381026268005 - accuracy: 0.93094 - val_loss: 0.9479236602783203 - val_accuracy: 0.7463 - penalty: 0.0\n",
            "hidden layer sizes: [111, 33, 55, 233, 636], total units: 1068\n",
            "##########################################################\n",
            "Epoch 34/50\n",
            "loss: 0.15692651271820068 - accuracy: 0.94568 - val_loss: 0.9734090566635132 - val_accuracy: 0.7466 - penalty: 0.0\n",
            "hidden layer sizes: [111, 33, 55, 233, 636], total units: 1068\n",
            "##########################################################\n",
            "Epoch 35/50\n",
            "loss: 0.12823988497257233 - accuracy: 0.95574 - val_loss: 1.0230493545532227 - val_accuracy: 0.7431 - penalty: 0.0\n",
            "hidden layer sizes: [111, 33, 55, 233, 636], total units: 1068\n",
            "##########################################################\n",
            "Epoch 36/50\n",
            "loss: 0.10347722470760345 - accuracy: 0.96488 - val_loss: 1.0517081022262573 - val_accuracy: 0.7482 - penalty: 0.0\n",
            "hidden layer sizes: [111, 33, 55, 233, 636], total units: 1068\n",
            "##########################################################\n",
            "Epoch 37/50\n",
            "loss: 0.08937457203865051 - accuracy: 0.96984 - val_loss: 1.097827434539795 - val_accuracy: 0.7449 - penalty: 0.0\n",
            "hidden layer sizes: [111, 33, 55, 233, 636], total units: 1068\n",
            "##########################################################\n",
            "Epoch 38/50\n",
            "loss: 0.0834687203168869 - accuracy: 0.9715 - val_loss: 1.1035391092300415 - val_accuracy: 0.7487 - penalty: 0.0\n",
            "hidden layer sizes: [111, 33, 55, 233, 636], total units: 1068\n",
            "##########################################################\n",
            "Epoch 39/50\n",
            "loss: 0.06904247403144836 - accuracy: 0.97664 - val_loss: 1.1535557508468628 - val_accuracy: 0.7507 - penalty: 0.0\n",
            "hidden layer sizes: [111, 33, 55, 233, 636], total units: 1068\n",
            "##########################################################\n",
            "Epoch 40/50\n",
            "loss: 0.06247430294752121 - accuracy: 0.97932 - val_loss: 1.1486716270446777 - val_accuracy: 0.7516 - penalty: 0.0\n",
            "hidden layer sizes: [111, 33, 55, 233, 636], total units: 1068\n",
            "##########################################################\n",
            "Epoch 41/50\n",
            "loss: 0.05621672049164772 - accuracy: 0.98076 - val_loss: 1.1837782859802246 - val_accuracy: 0.7513 - penalty: 0.0\n",
            "hidden layer sizes: [111, 33, 55, 233, 636], total units: 1068\n",
            "##########################################################\n",
            "Epoch 42/50\n",
            "loss: 0.050902631133794785 - accuracy: 0.98276 - val_loss: 1.2030081748962402 - val_accuracy: 0.7451 - penalty: 0.0\n",
            "hidden layer sizes: [111, 33, 55, 233, 636], total units: 1068\n",
            "##########################################################\n",
            "Epoch 43/50\n",
            "loss: 0.05156989395618439 - accuracy: 0.983 - val_loss: 1.2390072345733643 - val_accuracy: 0.7469 - penalty: 0.0\n",
            "hidden layer sizes: [111, 33, 55, 233, 636], total units: 1068\n",
            "##########################################################\n",
            "Epoch 44/50\n",
            "loss: 0.04661528393626213 - accuracy: 0.9847 - val_loss: 1.2622178792953491 - val_accuracy: 0.7542 - penalty: 0.0\n",
            "hidden layer sizes: [111, 33, 55, 233, 636], total units: 1068\n",
            "##########################################################\n",
            "Epoch 45/50\n",
            "loss: 0.04249925911426544 - accuracy: 0.98592 - val_loss: 1.313523769378662 - val_accuracy: 0.7465 - penalty: 0.0\n",
            "hidden layer sizes: [111, 33, 55, 233, 636], total units: 1068\n",
            "##########################################################\n",
            "Epoch 46/50\n",
            "loss: 0.04243222996592522 - accuracy: 0.98574 - val_loss: 1.2938168048858643 - val_accuracy: 0.751 - penalty: 0.0\n",
            "hidden layer sizes: [111, 33, 55, 233, 636], total units: 1068\n",
            "##########################################################\n",
            "Epoch 47/50\n",
            "loss: 0.03970065340399742 - accuracy: 0.9865 - val_loss: 1.2990233898162842 - val_accuracy: 0.7529 - penalty: 0.0\n",
            "hidden layer sizes: [111, 33, 55, 233, 636], total units: 1068\n",
            "##########################################################\n",
            "Epoch 48/50\n",
            "loss: 0.03375698998570442 - accuracy: 0.98864 - val_loss: 1.303160309791565 - val_accuracy: 0.7575 - penalty: 0.0\n",
            "hidden layer sizes: [111, 33, 55, 233, 636], total units: 1068\n",
            "##########################################################\n",
            "Epoch 49/50\n",
            "loss: 0.03560483083128929 - accuracy: 0.98778 - val_loss: 1.331072211265564 - val_accuracy: 0.7547 - penalty: 0.0\n",
            "hidden layer sizes: [111, 33, 55, 233, 636], total units: 1068\n",
            "##########################################################\n",
            "Epoch 50/50\n",
            "loss: 0.03539261594414711 - accuracy: 0.98772 - val_loss: 1.3683093786239624 - val_accuracy: 0.7553 - penalty: 0.0\n",
            "hidden layer sizes: [111, 33, 55, 233, 636], total units: 1068\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.39778,\n",
              "  0.4063,\n",
              "  0.49126,\n",
              "  0.54666,\n",
              "  0.57992,\n",
              "  0.6089,\n",
              "  0.62752,\n",
              "  0.64256,\n",
              "  0.65582,\n",
              "  0.66938,\n",
              "  0.67968,\n",
              "  0.6897,\n",
              "  0.70082,\n",
              "  0.70782,\n",
              "  0.71652,\n",
              "  0.72222,\n",
              "  0.72836,\n",
              "  0.73202,\n",
              "  0.73874,\n",
              "  0.74252,\n",
              "  0.74462,\n",
              "  0.75038,\n",
              "  0.75194,\n",
              "  0.75536,\n",
              "  0.75854,\n",
              "  0.75156,\n",
              "  0.79178,\n",
              "  0.81344,\n",
              "  0.842,\n",
              "  0.86708,\n",
              "  0.89244,\n",
              "  0.9152,\n",
              "  0.93094,\n",
              "  0.94568,\n",
              "  0.95574,\n",
              "  0.96488,\n",
              "  0.96984,\n",
              "  0.9715,\n",
              "  0.97664,\n",
              "  0.97932,\n",
              "  0.98076,\n",
              "  0.98276,\n",
              "  0.983,\n",
              "  0.9847,\n",
              "  0.98592,\n",
              "  0.98574,\n",
              "  0.9865,\n",
              "  0.98864,\n",
              "  0.98778,\n",
              "  0.98772],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=2.0449135>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.6878132>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4132434>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2615055>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1631353>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0913224>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0395821>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9998886>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9640465>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.93220663>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.89894974>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.873173>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.84793663>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.82485646>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8047823>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.78721243>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7659136>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.75908315>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.74015385>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.72631156>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.716589>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7094375>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.69734883>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.69031584>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.67836905>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.70447826>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.58475065>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.522188>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.444344>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.37124762>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.30291858>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.23863213>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.19340381>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.15692651>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.12823988>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.103477225>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.08937457>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.08346872>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.069042474>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.062474303>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.05621672>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.05090263>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.051569894>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.046615284>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.04249926>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.04243223>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.039700653>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.03375699>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.03560483>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.035392616>],\n",
              " 'val_accuracy': [0.4994,\n",
              "  0.4872,\n",
              "  0.555,\n",
              "  0.5893,\n",
              "  0.62,\n",
              "  0.6411,\n",
              "  0.6527,\n",
              "  0.659,\n",
              "  0.6681,\n",
              "  0.6793,\n",
              "  0.6893,\n",
              "  0.7033,\n",
              "  0.7131,\n",
              "  0.7178,\n",
              "  0.721,\n",
              "  0.7227,\n",
              "  0.7247,\n",
              "  0.7223,\n",
              "  0.7183,\n",
              "  0.7264,\n",
              "  0.7245,\n",
              "  0.7305,\n",
              "  0.7337,\n",
              "  0.7326,\n",
              "  0.7365,\n",
              "  0.7192,\n",
              "  0.7322,\n",
              "  0.7446,\n",
              "  0.7409,\n",
              "  0.7458,\n",
              "  0.7434,\n",
              "  0.7428,\n",
              "  0.7463,\n",
              "  0.7466,\n",
              "  0.7431,\n",
              "  0.7482,\n",
              "  0.7449,\n",
              "  0.7487,\n",
              "  0.7507,\n",
              "  0.7516,\n",
              "  0.7513,\n",
              "  0.7451,\n",
              "  0.7469,\n",
              "  0.7542,\n",
              "  0.7465,\n",
              "  0.751,\n",
              "  0.7529,\n",
              "  0.7575,\n",
              "  0.7547,\n",
              "  0.7553],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.3925364>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4148101>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2322417>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1491756>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0595257>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.99651736>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.969646>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.94424266>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.905952>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.89720947>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8717699>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8530041>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8298168>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8218468>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8007142>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7915627>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.78657526>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7932314>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8009625>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7851793>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.78678876>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7757372>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7685316>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.76534045>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7643791>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8295122>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7885305>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.78045857>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8183582>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.83792126>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.86252606>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.90859747>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.94792366>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.97340906>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0230494>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0517081>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0978274>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1035391>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1535558>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1486716>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1837783>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2030082>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2390072>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2622179>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3135238>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2938168>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2990234>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3031603>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3310722>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3683094>]}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gUdydYyOJLG"
      },
      "source": [
        "epochs = 35\n",
        "self_scaling_epochs = 0\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY87lU5jOfMA",
        "outputId": "b1fa2d1a-ca79-4b77-e554-5dec792e24ba"
      },
      "source": [
        "%%time\n",
        "\n",
        "model = Sequential([\n",
        "        Conv2D(131, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(51, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(72, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Conv2D(269, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(433, activation='selu', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/35\n",
            "loss: 3.3303887844085693 - accuracy: 0.172 - val_loss: 1.9711984395980835 - val_accuracy: 0.1993 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 2/35\n",
            "loss: 1.861918568611145 - accuracy: 0.26646 - val_loss: 1.6706897020339966 - val_accuracy: 0.3534 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 3/35\n",
            "loss: 1.5982861518859863 - accuracy: 0.38692 - val_loss: 1.555314540863037 - val_accuracy: 0.4114 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 4/35\n",
            "loss: 1.469883918762207 - accuracy: 0.44616 - val_loss: 1.3724000453948975 - val_accuracy: 0.4939 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 5/35\n",
            "loss: 1.368893027305603 - accuracy: 0.49092 - val_loss: 1.311629056930542 - val_accuracy: 0.5209 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 6/35\n",
            "loss: 1.2993316650390625 - accuracy: 0.51896 - val_loss: 1.2309292554855347 - val_accuracy: 0.5459 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 7/35\n",
            "loss: 1.214298963546753 - accuracy: 0.5518 - val_loss: 1.2292019128799438 - val_accuracy: 0.5494 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 8/35\n",
            "loss: 1.1415259838104248 - accuracy: 0.58176 - val_loss: 1.0902358293533325 - val_accuracy: 0.6087 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 9/35\n",
            "loss: 1.0774801969528198 - accuracy: 0.60988 - val_loss: 1.0445513725280762 - val_accuracy: 0.6332 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 10/35\n",
            "loss: 1.0176527500152588 - accuracy: 0.63836 - val_loss: 1.0018057823181152 - val_accuracy: 0.6552 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 11/35\n",
            "loss: 0.9585468173027039 - accuracy: 0.6613 - val_loss: 0.9614112377166748 - val_accuracy: 0.6689 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 12/35\n",
            "loss: 0.8800806403160095 - accuracy: 0.6923 - val_loss: 0.959611713886261 - val_accuracy: 0.6723 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 13/35\n",
            "loss: 0.836613655090332 - accuracy: 0.70578 - val_loss: 0.9540223479270935 - val_accuracy: 0.6822 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 14/35\n",
            "loss: 0.8087471127510071 - accuracy: 0.71962 - val_loss: 0.9382273554801941 - val_accuracy: 0.6915 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 15/35\n",
            "loss: 0.7765933871269226 - accuracy: 0.73142 - val_loss: 0.8964450359344482 - val_accuracy: 0.7065 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 16/35\n",
            "loss: 0.7405356764793396 - accuracy: 0.74406 - val_loss: 0.9311743378639221 - val_accuracy: 0.7005 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 17/35\n",
            "loss: 0.7078545093536377 - accuracy: 0.75608 - val_loss: 0.9871382117271423 - val_accuracy: 0.69 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 18/35\n",
            "loss: 0.6861432790756226 - accuracy: 0.76334 - val_loss: 0.9679903388023376 - val_accuracy: 0.6938 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 19/35\n",
            "loss: 0.6649909615516663 - accuracy: 0.7734 - val_loss: 0.8843273520469666 - val_accuracy: 0.7142 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 20/35\n",
            "loss: 0.6475785970687866 - accuracy: 0.7801 - val_loss: 0.9845741391181946 - val_accuracy: 0.7033 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 21/35\n",
            "loss: 0.6426968574523926 - accuracy: 0.78104 - val_loss: 0.9664629101753235 - val_accuracy: 0.7073 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 22/35\n",
            "loss: 0.6112226843833923 - accuracy: 0.7924 - val_loss: 1.0151145458221436 - val_accuracy: 0.7045 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 23/35\n",
            "loss: 0.601813018321991 - accuracy: 0.7951 - val_loss: 0.9852314591407776 - val_accuracy: 0.7102 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 24/35\n",
            "loss: 0.5705451369285583 - accuracy: 0.8055 - val_loss: 0.928831934928894 - val_accuracy: 0.7179 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 25/35\n",
            "loss: 0.5714550614356995 - accuracy: 0.80664 - val_loss: 0.9701643586158752 - val_accuracy: 0.7334 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 26/35\n",
            "loss: 0.5530850291252136 - accuracy: 0.81596 - val_loss: 0.8676319122314453 - val_accuracy: 0.7288 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 27/35\n",
            "loss: 0.5616199970245361 - accuracy: 0.81302 - val_loss: 0.9009310603141785 - val_accuracy: 0.7353 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 28/35\n",
            "loss: 0.5562765002250671 - accuracy: 0.81238 - val_loss: 0.9538912177085876 - val_accuracy: 0.7334 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 29/35\n",
            "loss: 0.5408499836921692 - accuracy: 0.82072 - val_loss: 0.9302458167076111 - val_accuracy: 0.7273 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 30/35\n",
            "loss: 0.605393648147583 - accuracy: 0.80014 - val_loss: 0.9489383697509766 - val_accuracy: 0.7294 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 31/35\n",
            "loss: 0.524761438369751 - accuracy: 0.82504 - val_loss: 0.9537306427955627 - val_accuracy: 0.7236 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 32/35\n",
            "loss: 0.4922718107700348 - accuracy: 0.83554 - val_loss: 0.9442076086997986 - val_accuracy: 0.7394 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 33/35\n",
            "loss: 0.4831934869289398 - accuracy: 0.83974 - val_loss: 0.9911905527114868 - val_accuracy: 0.7306 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 34/35\n",
            "loss: 0.4870276153087616 - accuracy: 0.83996 - val_loss: 0.9411500096321106 - val_accuracy: 0.7401 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 35/35\n",
            "loss: 0.4995448887348175 - accuracy: 0.83724 - val_loss: 1.0855623483657837 - val_accuracy: 0.7169 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "CPU times: user 4min 42s, sys: 5.21 s, total: 4min 47s\n",
            "Wall time: 5min 25s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqJTmu4iQgVs",
        "outputId": "5ebd5ea5-a232-4d6e-b6bf-a1d4c17c17d9"
      },
      "source": [
        "%%time\n",
        "\n",
        "model = Sequential([\n",
        "        Conv2D(131, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(51, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(72, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Conv2D(269, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(433, activation='selu', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/35\n",
            "loss: 2.0328404903411865 - accuracy: 0.37484 - val_loss: 1.457927942276001 - val_accuracy: 0.4813 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 2/35\n",
            "loss: 1.4127466678619385 - accuracy: 0.49816 - val_loss: 1.3177306652069092 - val_accuracy: 0.53 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 3/35\n",
            "loss: 1.2605280876159668 - accuracy: 0.5524 - val_loss: 1.2345070838928223 - val_accuracy: 0.5626 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 4/35\n",
            "loss: 1.1346594095230103 - accuracy: 0.59756 - val_loss: 1.1762573719024658 - val_accuracy: 0.5885 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 5/35\n",
            "loss: 1.0124701261520386 - accuracy: 0.6428 - val_loss: 1.140716552734375 - val_accuracy: 0.6045 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 6/35\n",
            "loss: 0.8920853734016418 - accuracy: 0.68568 - val_loss: 1.1547824144363403 - val_accuracy: 0.6101 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 7/35\n",
            "loss: 0.7728664875030518 - accuracy: 0.72478 - val_loss: 1.1471792459487915 - val_accuracy: 0.6095 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 8/35\n",
            "loss: 0.6648824214935303 - accuracy: 0.7646 - val_loss: 1.1598000526428223 - val_accuracy: 0.627 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 9/35\n",
            "loss: 0.5517282485961914 - accuracy: 0.80446 - val_loss: 1.182341456413269 - val_accuracy: 0.6307 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 10/35\n",
            "loss: 0.4574851989746094 - accuracy: 0.84034 - val_loss: 1.2155256271362305 - val_accuracy: 0.6344 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 11/35\n",
            "loss: 0.3764790892601013 - accuracy: 0.8661 - val_loss: 1.280443549156189 - val_accuracy: 0.6324 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 12/35\n",
            "loss: 0.3099316656589508 - accuracy: 0.89248 - val_loss: 1.379215955734253 - val_accuracy: 0.6431 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 13/35\n",
            "loss: 0.24920302629470825 - accuracy: 0.91464 - val_loss: 1.3835749626159668 - val_accuracy: 0.6399 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 14/35\n",
            "loss: 0.21111607551574707 - accuracy: 0.92694 - val_loss: 1.483492374420166 - val_accuracy: 0.6419 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 15/35\n",
            "loss: 0.18044690787792206 - accuracy: 0.93768 - val_loss: 1.4665954113006592 - val_accuracy: 0.6419 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 16/35\n",
            "loss: 0.15341852605342865 - accuracy: 0.94748 - val_loss: 1.5367794036865234 - val_accuracy: 0.6409 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 17/35\n",
            "loss: 0.13643431663513184 - accuracy: 0.954 - val_loss: 1.5919077396392822 - val_accuracy: 0.6463 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 18/35\n",
            "loss: 0.11841882020235062 - accuracy: 0.95966 - val_loss: 1.6307436227798462 - val_accuracy: 0.6467 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 19/35\n",
            "loss: 0.10512492060661316 - accuracy: 0.96454 - val_loss: 1.665505290031433 - val_accuracy: 0.645 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 20/35\n",
            "loss: 0.1001741960644722 - accuracy: 0.96534 - val_loss: 1.6992778778076172 - val_accuracy: 0.649 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 21/35\n",
            "loss: 0.09518413990736008 - accuracy: 0.96748 - val_loss: 1.7839000225067139 - val_accuracy: 0.6468 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 22/35\n",
            "loss: 0.09019418805837631 - accuracy: 0.96936 - val_loss: 1.762025237083435 - val_accuracy: 0.6498 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 23/35\n",
            "loss: 0.08714549988508224 - accuracy: 0.96986 - val_loss: 1.8349545001983643 - val_accuracy: 0.6574 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 24/35\n",
            "loss: 0.07789076864719391 - accuracy: 0.97322 - val_loss: 1.883741855621338 - val_accuracy: 0.6492 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 25/35\n",
            "loss: 0.073130764067173 - accuracy: 0.97514 - val_loss: 1.905730128288269 - val_accuracy: 0.6486 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 26/35\n",
            "loss: 0.06872671842575073 - accuracy: 0.97616 - val_loss: 1.9459552764892578 - val_accuracy: 0.647 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 27/35\n",
            "loss: 0.06838065385818481 - accuracy: 0.97602 - val_loss: 1.9395809173583984 - val_accuracy: 0.6516 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 28/35\n",
            "loss: 0.06623446941375732 - accuracy: 0.97734 - val_loss: 1.9719597101211548 - val_accuracy: 0.6536 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 29/35\n",
            "loss: 0.06509263813495636 - accuracy: 0.97728 - val_loss: 2.123093843460083 - val_accuracy: 0.6536 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 30/35\n",
            "loss: 0.06164572760462761 - accuracy: 0.97942 - val_loss: 2.0245509147644043 - val_accuracy: 0.6539 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 31/35\n",
            "loss: 0.05963115394115448 - accuracy: 0.97958 - val_loss: 2.0505638122558594 - val_accuracy: 0.6558 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 32/35\n",
            "loss: 0.0613582618534565 - accuracy: 0.97886 - val_loss: 2.1514034271240234 - val_accuracy: 0.6594 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 33/35\n",
            "loss: 0.05630898475646973 - accuracy: 0.9808 - val_loss: 2.092595338821411 - val_accuracy: 0.6475 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 34/35\n",
            "loss: 0.05838419124484062 - accuracy: 0.9807 - val_loss: 2.1862881183624268 - val_accuracy: 0.6553 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "##########################################################\n",
            "Epoch 35/35\n",
            "loss: 0.05405441299080849 - accuracy: 0.98136 - val_loss: 2.139467716217041 - val_accuracy: 0.6563 - penalty: 0.0\n",
            "hidden layer sizes: [131, 51, 72, 269, 433], total units: 956\n",
            "CPU times: user 4min 42s, sys: 4.96 s, total: 4min 47s\n",
            "Wall time: 5min 25s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpAgrUAQSX8O",
        "outputId": "95a1006c-baa6-414f-e3de-cc72d19b4be1"
      },
      "source": [
        "%%time\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
        "\n",
        "best_val_accuracies = list()\n",
        "layer_sizes = list()\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X_norm)):\n",
        "    xtrain, xtest = X_norm[train_index], X_norm[test_index]\n",
        "    ytrain, ytest = y[train_index], y[test_index]\n",
        "\n",
        "    model = Sequential([\n",
        "            Conv2D(131, filter_size=(3, 3), activation='selu', \n",
        "                strides=(1, 1), padding='SAME', regularization_penalty=0., regularization_method=None, \n",
        "                kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "            Conv2D(51, filter_size=(3, 3), activation='selu', \n",
        "                strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "                regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "            tf.keras.layers.Dropout(0.2),\n",
        "            Conv2D(72, filter_size=(3, 3), activation='selu', \n",
        "                strides=(1, 1), padding='SAME', regularization_penalty=0., \n",
        "                regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "            Conv2D(269, filter_size=(3, 3), activation='selu', \n",
        "                strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "                regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "            Flatten(),\n",
        "            Dense(433, activation='selu', regularization_penalty=0., \n",
        "                regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "            Dense(10, activation='softmax', regularization_penalty=0., \n",
        "                regularization_method=None),\n",
        "        ])\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.002)\n",
        "\n",
        "    history = model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "              min_new_neurons, validation_data=(X_test_norm, y_test), verbose=False)\n",
        "    best_val_accuracy = max(history['val_accuracy'])\n",
        "    current_layer_sizes = model.get_layer_sizes()\n",
        "    best_val_accuracies.append(best_val_accuracy)\n",
        "    layer_sizes.append(current_layer_sizes)\n",
        "    print(f\"Run {i} completed, best val accuracy: {best_val_accuracy}, layer sizes: {current_layer_sizes}\")\n",
        "\n",
        "print(f'val accuracies: {best_val_accuracies}')\n",
        "print(f'mean val accuracy: {np.mean(best_val_accuracies)}')\n",
        "\n",
        "print(f'mean layer sizes: {[np.mean(layer) for layer in list(zip(*layer_sizes))]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best val accuracy: 0.7389, layer sizes: [3, 131, 51, 72, 269, 433, 10]\n",
            "Run 1 completed, best val accuracy: 0.732, layer sizes: [3, 131, 51, 72, 269, 433, 10]\n",
            "Run 2 completed, best val accuracy: 0.7356, layer sizes: [3, 131, 51, 72, 269, 433, 10]\n",
            "Run 3 completed, best val accuracy: 0.1007, layer sizes: [3, 131, 51, 72, 269, 433, 10]\n",
            "Run 4 completed, best val accuracy: 0.7336, layer sizes: [3, 131, 51, 72, 269, 433, 10]\n",
            "Run 5 completed, best val accuracy: 0.7404, layer sizes: [3, 131, 51, 72, 269, 433, 10]\n",
            "val accuracies: [0.7389, 0.732, 0.7356, 0.1007, 0.7336, 0.7404]\n",
            "mean val accuracy: 0.6302\n",
            "mean layer sizes: [3.0, 131.0, 51.0, 72.0, 269.0, 433.0, 10.0]\n",
            "CPU times: user 26min 36s, sys: 25.4 s, total: 27min 2s\n",
            "Wall time: 30min 19s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMozNaYHUQL6"
      },
      "source": [
        "epochs = 50\n",
        "self_scaling_epochs = 0\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lxhnN8OURsq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a50c29b-37eb-47a0-b1ee-876bc9565398"
      },
      "source": [
        "%%time\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
        "\n",
        "best_val_accuracies = list()\n",
        "layer_sizes = list()\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X_norm)):\n",
        "    xtrain, xtest = X_norm[train_index], X_norm[test_index]\n",
        "    ytrain, ytest = y[train_index], y[test_index]\n",
        "\n",
        "    model = Sequential([\n",
        "            Conv2D(131, filter_size=(3, 3), activation='selu', \n",
        "                strides=(1, 1), padding='SAME', regularization_penalty=0., regularization_method=None, \n",
        "                kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "            Conv2D(51, filter_size=(3, 3), activation='selu', \n",
        "                strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "                regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "            tf.keras.layers.Dropout(0.2),\n",
        "            Conv2D(72, filter_size=(3, 3), activation='selu', \n",
        "                strides=(1, 1), padding='SAME', regularization_penalty=0., \n",
        "                regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "            Conv2D(269, filter_size=(3, 3), activation='selu', \n",
        "                strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "                regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "            Flatten(),\n",
        "            Dense(433, activation='selu', regularization_penalty=0., \n",
        "                regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "            Dense(10, activation='softmax', regularization_penalty=0., \n",
        "                regularization_method=None),\n",
        "        ])\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.002)\n",
        "\n",
        "    history = model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "              min_new_neurons, validation_data=(X_test_norm, y_test), verbose=False)\n",
        "    best_val_accuracy = max(history['val_accuracy'])\n",
        "    current_layer_sizes = model.get_layer_sizes()\n",
        "    best_val_accuracies.append(best_val_accuracy)\n",
        "    layer_sizes.append(current_layer_sizes)\n",
        "    print(f\"Run {i} completed, best val accuracy: {best_val_accuracy}, layer sizes: {current_layer_sizes}\")\n",
        "\n",
        "print(f'val accuracies: {best_val_accuracies}')\n",
        "print(f'mean val accuracy: {np.mean(best_val_accuracies)}')\n",
        "\n",
        "print(f'mean layer sizes: {[np.mean(layer) for layer in list(zip(*layer_sizes))]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best val accuracy: 0.7614, layer sizes: [3, 131, 51, 72, 269, 433, 10]\n",
            "Run 1 completed, best val accuracy: 0.755, layer sizes: [3, 131, 51, 72, 269, 433, 10]\n",
            "Run 2 completed, best val accuracy: 0.7405, layer sizes: [3, 131, 51, 72, 269, 433, 10]\n",
            "Run 3 completed, best val accuracy: 0.746, layer sizes: [3, 131, 51, 72, 269, 433, 10]\n",
            "Run 4 completed, best val accuracy: 0.7456, layer sizes: [3, 131, 51, 72, 269, 433, 10]\n",
            "Run 5 completed, best val accuracy: 0.7559, layer sizes: [3, 131, 51, 72, 269, 433, 10]\n",
            "val accuracies: [0.7614, 0.755, 0.7405, 0.746, 0.7456, 0.7559]\n",
            "mean val accuracy: 0.7507333333333334\n",
            "mean layer sizes: [3.0, 131.0, 51.0, 72.0, 269.0, 433.0, 10.0]\n",
            "CPU times: user 37min 52s, sys: 33.8 s, total: 38min 26s\n",
            "Wall time: 43min 11s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF0jG5aI_LK5"
      },
      "source": [
        "### Smaller models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-ZmSSxP_fh5"
      },
      "source": [
        "epochs = 50\n",
        "self_scaling_epochs = 25\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZeSiUJ1_Ms4",
        "outputId": "58c66df9-a807-4731-98bb-95e3324f63f1"
      },
      "source": [
        "%%time\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(100, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "        regularization_penalty=0.00002, regularization_method='weighted_l1', \n",
        "        kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "    Conv2D(100, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "        regularization_penalty=0.00002, regularization_method='weighted_l1', \n",
        "        kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    Conv2D(100, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "        regularization_penalty=0.00002, regularization_method='weighted_l1', \n",
        "        kernel_initializer='lecun_normal'),\n",
        "    Conv2D(100, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "        regularization_penalty=0.00002, regularization_method='weighted_l1', \n",
        "        kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    Flatten(),\n",
        "    Dense(100, activation='selu', regularization_penalty=0.00002, \n",
        "        regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "    Dense(10, activation='softmax', regularization_penalty=0., \n",
        "        regularization_method=None, fixed_size=True),\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.7962162494659424 - val_accuracy: 0.0995 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.7962160110473633 - val_accuracy: 0.0995 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "Before pruning:\n",
            "loss: 1.899720311164856 - accuracy: 0.35714 - val_loss: 1.5077276229858398 - val_accuracy: 0.4642 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.5077192783355713 - val_accuracy: 0.4641 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 2/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.5077192783355713 - val_accuracy: 0.4641 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.5077192783355713 - val_accuracy: 0.4641 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "Before pruning:\n",
            "loss: 1.5467103719711304 - accuracy: 0.4453 - val_loss: 1.4271390438079834 - val_accuracy: 0.4744 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4270646572113037 - val_accuracy: 0.4741 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 3/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4270646572113037 - val_accuracy: 0.4741 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4270646572113037 - val_accuracy: 0.4741 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "Before pruning:\n",
            "loss: 1.4346868991851807 - accuracy: 0.48108 - val_loss: 1.3009510040283203 - val_accuracy: 0.524 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.300900936126709 - val_accuracy: 0.5244 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 4/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.300900936126709 - val_accuracy: 0.5244 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.300900936126709 - val_accuracy: 0.5244 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "Before pruning:\n",
            "loss: 1.3496294021606445 - accuracy: 0.5157 - val_loss: 1.2392170429229736 - val_accuracy: 0.5584 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.2392102479934692 - val_accuracy: 0.5589 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 97, 89, 91, 100], total units: 477\n",
            "##########################################################\n",
            "Epoch 5/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2392102479934692 - val_accuracy: 0.5589 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 97, 89, 91, 100], total units: 477\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2392102479934692 - val_accuracy: 0.5589 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 117, 109, 111, 120], total units: 577\n",
            "Before pruning:\n",
            "loss: 1.30233895778656 - accuracy: 0.53158 - val_loss: 1.210319995880127 - val_accuracy: 0.5672 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 117, 109, 111, 120], total units: 577\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.2100210189819336 - val_accuracy: 0.5676 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 79, 75, 74, 100], total units: 428\n",
            "##########################################################\n",
            "Epoch 6/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2100210189819336 - val_accuracy: 0.5676 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 79, 75, 74, 100], total units: 428\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2100210189819336 - val_accuracy: 0.5676 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 99, 95, 94, 120], total units: 528\n",
            "Before pruning:\n",
            "loss: 1.2625066041946411 - accuracy: 0.5484 - val_loss: 1.1715128421783447 - val_accuracy: 0.5782 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 99, 95, 94, 120], total units: 528\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1716516017913818 - val_accuracy: 0.5778 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 65, 68, 67, 97], total units: 397\n",
            "##########################################################\n",
            "Epoch 7/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1716516017913818 - val_accuracy: 0.5778 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 65, 68, 67, 97], total units: 397\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1716516017913818 - val_accuracy: 0.5778 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 85, 88, 87, 117], total units: 497\n",
            "Before pruning:\n",
            "loss: 1.216607928276062 - accuracy: 0.5655 - val_loss: 1.1327694654464722 - val_accuracy: 0.5976 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 85, 88, 87, 117], total units: 497\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1322956085205078 - val_accuracy: 0.5981 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 57, 60, 66, 92], total units: 375\n",
            "##########################################################\n",
            "Epoch 8/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1322956085205078 - val_accuracy: 0.5981 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 57, 60, 66, 92], total units: 375\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1322954893112183 - val_accuracy: 0.5981 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 77, 80, 86, 112], total units: 475\n",
            "Before pruning:\n",
            "loss: 1.1741713285446167 - accuracy: 0.57982 - val_loss: 1.091637372970581 - val_accuracy: 0.6059 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 77, 80, 86, 112], total units: 475\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0915120840072632 - val_accuracy: 0.6062 - penalty: 2e-05\n",
            "hidden layer sizes: [99, 51, 52, 64, 83], total units: 349\n",
            "##########################################################\n",
            "Epoch 9/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0915120840072632 - val_accuracy: 0.6062 - penalty: 2e-05\n",
            "hidden layer sizes: [99, 51, 52, 64, 83], total units: 349\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0915119647979736 - val_accuracy: 0.6062 - penalty: 2e-05\n",
            "hidden layer sizes: [119, 71, 72, 84, 103], total units: 449\n",
            "Before pruning:\n",
            "loss: 1.1384648084640503 - accuracy: 0.59442 - val_loss: 1.0492545366287231 - val_accuracy: 0.6251 - penalty: 2e-05\n",
            "hidden layer sizes: [119, 71, 72, 84, 103], total units: 449\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0493048429489136 - val_accuracy: 0.625 - penalty: 2e-05\n",
            "hidden layer sizes: [98, 45, 47, 60, 73], total units: 323\n",
            "##########################################################\n",
            "Epoch 10/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0493048429489136 - val_accuracy: 0.625 - penalty: 2e-05\n",
            "hidden layer sizes: [98, 45, 47, 60, 73], total units: 323\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0493048429489136 - val_accuracy: 0.625 - penalty: 2e-05\n",
            "hidden layer sizes: [118, 65, 67, 80, 93], total units: 423\n",
            "Before pruning:\n",
            "loss: 1.1128387451171875 - accuracy: 0.60134 - val_loss: 1.018314003944397 - val_accuracy: 0.6375 - penalty: 2e-05\n",
            "hidden layer sizes: [118, 65, 67, 80, 93], total units: 423\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.018358588218689 - val_accuracy: 0.6376 - penalty: 2e-05\n",
            "hidden layer sizes: [97, 42, 39, 60, 83], total units: 321\n",
            "##########################################################\n",
            "Epoch 11/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.018358588218689 - val_accuracy: 0.6376 - penalty: 2e-05\n",
            "hidden layer sizes: [97, 42, 39, 60, 83], total units: 321\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.018358588218689 - val_accuracy: 0.6376 - penalty: 2e-05\n",
            "hidden layer sizes: [117, 62, 59, 80, 103], total units: 421\n",
            "Before pruning:\n",
            "loss: 1.0785919427871704 - accuracy: 0.61668 - val_loss: 0.9840892553329468 - val_accuracy: 0.6514 - penalty: 2e-05\n",
            "hidden layer sizes: [117, 62, 59, 80, 103], total units: 421\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9841114282608032 - val_accuracy: 0.6516 - penalty: 2e-05\n",
            "hidden layer sizes: [90, 39, 38, 60, 89], total units: 316\n",
            "##########################################################\n",
            "Epoch 12/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9841114282608032 - val_accuracy: 0.6516 - penalty: 2e-05\n",
            "hidden layer sizes: [90, 39, 38, 60, 89], total units: 316\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9841114282608032 - val_accuracy: 0.6516 - penalty: 2e-05\n",
            "hidden layer sizes: [110, 59, 58, 80, 109], total units: 416\n",
            "Before pruning:\n",
            "loss: 1.0530885457992554 - accuracy: 0.6252 - val_loss: 0.9696304798126221 - val_accuracy: 0.6556 - penalty: 2e-05\n",
            "hidden layer sizes: [110, 59, 58, 80, 109], total units: 416\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9695069193840027 - val_accuracy: 0.6557 - penalty: 2e-05\n",
            "hidden layer sizes: [88, 35, 38, 58, 92], total units: 311\n",
            "##########################################################\n",
            "Epoch 13/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9695069193840027 - val_accuracy: 0.6557 - penalty: 2e-05\n",
            "hidden layer sizes: [88, 35, 38, 58, 92], total units: 311\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9695069193840027 - val_accuracy: 0.6557 - penalty: 2e-05\n",
            "hidden layer sizes: [108, 55, 58, 78, 112], total units: 411\n",
            "Before pruning:\n",
            "loss: 1.0312920808792114 - accuracy: 0.63496 - val_loss: 0.9539196491241455 - val_accuracy: 0.6618 - penalty: 2e-05\n",
            "hidden layer sizes: [108, 55, 58, 78, 112], total units: 411\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.953895092010498 - val_accuracy: 0.6617 - penalty: 2e-05\n",
            "hidden layer sizes: [87, 32, 34, 60, 90], total units: 303\n",
            "##########################################################\n",
            "Epoch 14/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.953895092010498 - val_accuracy: 0.6617 - penalty: 2e-05\n",
            "hidden layer sizes: [87, 32, 34, 60, 90], total units: 303\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.953895092010498 - val_accuracy: 0.6617 - penalty: 2e-05\n",
            "hidden layer sizes: [107, 52, 54, 80, 110], total units: 403\n",
            "Before pruning:\n",
            "loss: 1.01198410987854 - accuracy: 0.6413 - val_loss: 0.9416135549545288 - val_accuracy: 0.6673 - penalty: 2e-05\n",
            "hidden layer sizes: [107, 52, 54, 80, 110], total units: 403\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9416651129722595 - val_accuracy: 0.6671 - penalty: 2e-05\n",
            "hidden layer sizes: [83, 31, 34, 60, 84], total units: 292\n",
            "##########################################################\n",
            "Epoch 15/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9416651129722595 - val_accuracy: 0.6671 - penalty: 2e-05\n",
            "hidden layer sizes: [83, 31, 34, 60, 84], total units: 292\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9416650533676147 - val_accuracy: 0.6671 - penalty: 2e-05\n",
            "hidden layer sizes: [103, 51, 54, 80, 104], total units: 392\n",
            "Before pruning:\n",
            "loss: 1.0016621351242065 - accuracy: 0.64622 - val_loss: 0.9247231483459473 - val_accuracy: 0.6721 - penalty: 2e-05\n",
            "hidden layer sizes: [103, 51, 54, 80, 104], total units: 392\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9247037172317505 - val_accuracy: 0.6721 - penalty: 2e-05\n",
            "hidden layer sizes: [78, 31, 33, 59, 101], total units: 302\n",
            "##########################################################\n",
            "Epoch 16/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9247037172317505 - val_accuracy: 0.6721 - penalty: 2e-05\n",
            "hidden layer sizes: [78, 31, 33, 59, 101], total units: 302\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9247037172317505 - val_accuracy: 0.6721 - penalty: 2e-05\n",
            "hidden layer sizes: [98, 51, 53, 79, 121], total units: 402\n",
            "Before pruning:\n",
            "loss: 0.9835081100463867 - accuracy: 0.65094 - val_loss: 0.9103999137878418 - val_accuracy: 0.6791 - penalty: 2e-05\n",
            "hidden layer sizes: [98, 51, 53, 79, 121], total units: 402\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9104635715484619 - val_accuracy: 0.6788 - penalty: 2e-05\n",
            "hidden layer sizes: [75, 27, 31, 61, 95], total units: 289\n",
            "##########################################################\n",
            "Epoch 17/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9104635715484619 - val_accuracy: 0.6788 - penalty: 2e-05\n",
            "hidden layer sizes: [75, 27, 31, 61, 95], total units: 289\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9104635715484619 - val_accuracy: 0.6788 - penalty: 2e-05\n",
            "hidden layer sizes: [95, 47, 51, 81, 115], total units: 389\n",
            "Before pruning:\n",
            "loss: 0.9754018783569336 - accuracy: 0.6543 - val_loss: 0.8988252878189087 - val_accuracy: 0.6847 - penalty: 2e-05\n",
            "hidden layer sizes: [95, 47, 51, 81, 115], total units: 389\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8989594578742981 - val_accuracy: 0.6844 - penalty: 2e-05\n",
            "hidden layer sizes: [71, 27, 31, 61, 86], total units: 276\n",
            "##########################################################\n",
            "Epoch 18/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8989594578742981 - val_accuracy: 0.6844 - penalty: 2e-05\n",
            "hidden layer sizes: [71, 27, 31, 61, 86], total units: 276\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8989594578742981 - val_accuracy: 0.6844 - penalty: 2e-05\n",
            "hidden layer sizes: [91, 47, 51, 81, 106], total units: 376\n",
            "Before pruning:\n",
            "loss: 0.9558937549591064 - accuracy: 0.65946 - val_loss: 0.8902881145477295 - val_accuracy: 0.687 - penalty: 2e-05\n",
            "hidden layer sizes: [91, 47, 51, 81, 106], total units: 376\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8903127908706665 - val_accuracy: 0.687 - penalty: 2e-05\n",
            "hidden layer sizes: [67, 26, 29, 57, 101], total units: 280\n",
            "##########################################################\n",
            "Epoch 19/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8903127908706665 - val_accuracy: 0.687 - penalty: 2e-05\n",
            "hidden layer sizes: [67, 26, 29, 57, 101], total units: 280\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8903127908706665 - val_accuracy: 0.687 - penalty: 2e-05\n",
            "hidden layer sizes: [87, 46, 49, 77, 121], total units: 380\n",
            "Before pruning:\n",
            "loss: 0.9482754468917847 - accuracy: 0.66482 - val_loss: 0.874788761138916 - val_accuracy: 0.6944 - penalty: 2e-05\n",
            "hidden layer sizes: [87, 46, 49, 77, 121], total units: 380\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.874910831451416 - val_accuracy: 0.6947 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 24, 28, 56, 97], total units: 269\n",
            "##########################################################\n",
            "Epoch 20/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.874910831451416 - val_accuracy: 0.6947 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 24, 28, 56, 97], total units: 269\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8749106526374817 - val_accuracy: 0.6947 - penalty: 2e-05\n",
            "hidden layer sizes: [84, 44, 48, 76, 117], total units: 369\n",
            "Before pruning:\n",
            "loss: 0.9395233392715454 - accuracy: 0.66506 - val_loss: 0.8656566143035889 - val_accuracy: 0.6964 - penalty: 2e-05\n",
            "hidden layer sizes: [84, 44, 48, 76, 117], total units: 369\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8657038807868958 - val_accuracy: 0.6964 - penalty: 2e-05\n",
            "hidden layer sizes: [62, 23, 27, 57, 95], total units: 264\n",
            "##########################################################\n",
            "Epoch 21/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8657038807868958 - val_accuracy: 0.6964 - penalty: 2e-05\n",
            "hidden layer sizes: [62, 23, 27, 57, 95], total units: 264\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8657039999961853 - val_accuracy: 0.6964 - penalty: 2e-05\n",
            "hidden layer sizes: [82, 43, 47, 77, 115], total units: 364\n",
            "Before pruning:\n",
            "loss: 0.9288864135742188 - accuracy: 0.67328 - val_loss: 0.8522875905036926 - val_accuracy: 0.7004 - penalty: 2e-05\n",
            "hidden layer sizes: [82, 43, 47, 77, 115], total units: 364\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8522470593452454 - val_accuracy: 0.7004 - penalty: 2e-05\n",
            "hidden layer sizes: [61, 23, 25, 56, 100], total units: 265\n",
            "##########################################################\n",
            "Epoch 22/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8522470593452454 - val_accuracy: 0.7004 - penalty: 2e-05\n",
            "hidden layer sizes: [61, 23, 25, 56, 100], total units: 265\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8522470593452454 - val_accuracy: 0.7004 - penalty: 2e-05\n",
            "hidden layer sizes: [81, 43, 45, 76, 120], total units: 365\n",
            "Before pruning:\n",
            "loss: 0.9192480444908142 - accuracy: 0.6749 - val_loss: 0.8506520390510559 - val_accuracy: 0.6996 - penalty: 2e-05\n",
            "hidden layer sizes: [81, 43, 45, 76, 120], total units: 365\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8508342504501343 - val_accuracy: 0.6997 - penalty: 2e-05\n",
            "hidden layer sizes: [59, 22, 25, 57, 102], total units: 265\n",
            "##########################################################\n",
            "Epoch 23/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8508342504501343 - val_accuracy: 0.6997 - penalty: 2e-05\n",
            "hidden layer sizes: [59, 22, 25, 57, 102], total units: 265\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8508341908454895 - val_accuracy: 0.6997 - penalty: 2e-05\n",
            "hidden layer sizes: [79, 42, 45, 77, 122], total units: 365\n",
            "Before pruning:\n",
            "loss: 0.9139088988304138 - accuracy: 0.67844 - val_loss: 0.8469036817550659 - val_accuracy: 0.7031 - penalty: 2e-05\n",
            "hidden layer sizes: [79, 42, 45, 77, 122], total units: 365\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8470054864883423 - val_accuracy: 0.7033 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 22, 22, 57, 86], total units: 244\n",
            "##########################################################\n",
            "Epoch 24/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8470054864883423 - val_accuracy: 0.7033 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 22, 22, 57, 86], total units: 244\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8470055460929871 - val_accuracy: 0.7033 - penalty: 2e-05\n",
            "hidden layer sizes: [77, 42, 42, 77, 106], total units: 344\n",
            "Before pruning:\n",
            "loss: 0.9033827185630798 - accuracy: 0.67826 - val_loss: 0.8360834121704102 - val_accuracy: 0.7049 - penalty: 2e-05\n",
            "hidden layer sizes: [77, 42, 42, 77, 106], total units: 344\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8361183404922485 - val_accuracy: 0.705 - penalty: 2e-05\n",
            "hidden layer sizes: [55, 22, 22, 57, 101], total units: 257\n",
            "##########################################################\n",
            "Epoch 25/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8361183404922485 - val_accuracy: 0.705 - penalty: 2e-05\n",
            "hidden layer sizes: [55, 22, 22, 57, 101], total units: 257\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8361182808876038 - val_accuracy: 0.705 - penalty: 2e-05\n",
            "hidden layer sizes: [75, 42, 42, 77, 121], total units: 357\n",
            "Before pruning:\n",
            "loss: 0.8995484113693237 - accuracy: 0.6819 - val_loss: 0.8314265608787537 - val_accuracy: 0.7047 - penalty: 2e-05\n",
            "hidden layer sizes: [75, 42, 42, 77, 121], total units: 357\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.831375002861023 - val_accuracy: 0.7048 - penalty: 2e-05\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 26/50\n",
            "loss: 0.8928292393684387 - accuracy: 0.6849 - val_loss: 0.8145801424980164 - val_accuracy: 0.7139 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 27/50\n",
            "loss: 0.8198391199111938 - accuracy: 0.71052 - val_loss: 0.79979008436203 - val_accuracy: 0.7222 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 28/50\n",
            "loss: 0.7858142852783203 - accuracy: 0.72298 - val_loss: 0.7861253619194031 - val_accuracy: 0.7267 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 29/50\n",
            "loss: 0.7607550621032715 - accuracy: 0.7297 - val_loss: 0.7780837416648865 - val_accuracy: 0.7284 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 30/50\n",
            "loss: 0.7357679009437561 - accuracy: 0.73958 - val_loss: 0.7684502601623535 - val_accuracy: 0.7323 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 31/50\n",
            "loss: 0.7067182064056396 - accuracy: 0.7484 - val_loss: 0.7618026733398438 - val_accuracy: 0.7336 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 32/50\n",
            "loss: 0.6843199729919434 - accuracy: 0.75628 - val_loss: 0.7498724460601807 - val_accuracy: 0.7374 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 33/50\n",
            "loss: 0.6566869020462036 - accuracy: 0.76708 - val_loss: 0.7388412356376648 - val_accuracy: 0.7436 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 34/50\n",
            "loss: 0.6367307901382446 - accuracy: 0.77372 - val_loss: 0.7313559055328369 - val_accuracy: 0.7446 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 35/50\n",
            "loss: 0.606386125087738 - accuracy: 0.78712 - val_loss: 0.724138617515564 - val_accuracy: 0.7502 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 36/50\n",
            "loss: 0.5848320126533508 - accuracy: 0.79204 - val_loss: 0.7262690663337708 - val_accuracy: 0.749 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 37/50\n",
            "loss: 0.5621241927146912 - accuracy: 0.79928 - val_loss: 0.7201882004737854 - val_accuracy: 0.7515 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 38/50\n",
            "loss: 0.54599529504776 - accuracy: 0.80652 - val_loss: 0.7200842499732971 - val_accuracy: 0.7553 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 39/50\n",
            "loss: 0.5262752175331116 - accuracy: 0.81076 - val_loss: 0.7235957384109497 - val_accuracy: 0.7542 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 40/50\n",
            "loss: 0.5020548701286316 - accuracy: 0.82092 - val_loss: 0.7269538044929504 - val_accuracy: 0.7528 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 41/50\n",
            "loss: 0.4841298460960388 - accuracy: 0.82862 - val_loss: 0.7290686964988708 - val_accuracy: 0.7594 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 42/50\n",
            "loss: 0.4696904420852661 - accuracy: 0.83126 - val_loss: 0.7296384572982788 - val_accuracy: 0.7596 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 43/50\n",
            "loss: 0.45258834958076477 - accuracy: 0.83844 - val_loss: 0.7257636785507202 - val_accuracy: 0.7589 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 44/50\n",
            "loss: 0.44098231196403503 - accuracy: 0.84358 - val_loss: 0.7304508090019226 - val_accuracy: 0.7604 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 45/50\n",
            "loss: 0.42533040046691895 - accuracy: 0.84874 - val_loss: 0.7385472059249878 - val_accuracy: 0.7595 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 46/50\n",
            "loss: 0.41192948818206787 - accuracy: 0.8548 - val_loss: 0.7408872842788696 - val_accuracy: 0.7619 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 47/50\n",
            "loss: 0.39736637473106384 - accuracy: 0.8587 - val_loss: 0.7436830401420593 - val_accuracy: 0.7584 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 48/50\n",
            "loss: 0.3868235945701599 - accuracy: 0.86106 - val_loss: 0.7424144744873047 - val_accuracy: 0.7614 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 49/50\n",
            "loss: 0.37437745928764343 - accuracy: 0.86648 - val_loss: 0.7600334286689758 - val_accuracy: 0.7584 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 50/50\n",
            "loss: 0.36468973755836487 - accuracy: 0.86956 - val_loss: 0.754867672920227 - val_accuracy: 0.7617 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "CPU times: user 5min 56s, sys: 5.6 s, total: 6min 2s\n",
            "Wall time: 6min 30s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HLbLMRhZo56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bf356aa-5d82-4028-dae0-ce2fd0aa95da"
      },
      "source": [
        "%%time\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(100, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "        regularization_penalty=0.00002, regularization_method='weighted_l1', \n",
        "        kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "    Conv2D(100, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "        regularization_penalty=0.00002, regularization_method='weighted_l1', \n",
        "        kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    Conv2D(100, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "        regularization_penalty=0.00002, regularization_method='weighted_l1', \n",
        "        kernel_initializer='lecun_normal'),\n",
        "    Conv2D(100, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "        regularization_penalty=0.00002, regularization_method='weighted_l1', \n",
        "        kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    Flatten(),\n",
        "    Dense(100, activation='selu', regularization_penalty=0.0002, \n",
        "        regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "    Dense(10, activation='softmax', regularization_penalty=0., \n",
        "        regularization_method=None, fixed_size=True),\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8716301918029785 - val_accuracy: 0.0951 - penalty: 0.0002\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8716301918029785 - val_accuracy: 0.0951 - penalty: 0.0002\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "Before pruning:\n",
            "loss: 1.8507962226867676 - accuracy: 0.36176 - val_loss: 1.5996650457382202 - val_accuracy: 0.4303 - penalty: 0.0002\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.5933966636657715 - val_accuracy: 0.4357 - penalty: 0.0002\n",
            "hidden layer sizes: [100, 100, 100, 100, 71], total units: 471\n",
            "##########################################################\n",
            "Epoch 2/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.5933966636657715 - val_accuracy: 0.4357 - penalty: 0.0002\n",
            "hidden layer sizes: [100, 100, 100, 100, 71], total units: 471\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.593396544456482 - val_accuracy: 0.4357 - penalty: 0.0002\n",
            "hidden layer sizes: [120, 120, 120, 120, 91], total units: 571\n",
            "Before pruning:\n",
            "loss: 1.5697004795074463 - accuracy: 0.43432 - val_loss: 1.4562495946884155 - val_accuracy: 0.4771 - penalty: 0.0002\n",
            "hidden layer sizes: [120, 120, 120, 120, 91], total units: 571\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4556201696395874 - val_accuracy: 0.4785 - penalty: 0.0002\n",
            "hidden layer sizes: [100, 100, 100, 100, 69], total units: 469\n",
            "##########################################################\n",
            "Epoch 3/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4556201696395874 - val_accuracy: 0.4785 - penalty: 0.0002\n",
            "hidden layer sizes: [100, 100, 100, 100, 69], total units: 469\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4556201696395874 - val_accuracy: 0.4785 - penalty: 0.0002\n",
            "hidden layer sizes: [120, 120, 120, 120, 89], total units: 569\n",
            "Before pruning:\n",
            "loss: 1.4561599493026733 - accuracy: 0.4747 - val_loss: 1.351845622062683 - val_accuracy: 0.5085 - penalty: 0.0002\n",
            "hidden layer sizes: [120, 120, 120, 120, 89], total units: 569\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.3511247634887695 - val_accuracy: 0.5093 - penalty: 0.0002\n",
            "hidden layer sizes: [100, 97, 94, 73, 65], total units: 429\n",
            "##########################################################\n",
            "Epoch 4/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.3511247634887695 - val_accuracy: 0.5093 - penalty: 0.0002\n",
            "hidden layer sizes: [100, 97, 94, 73, 65], total units: 429\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.3511247634887695 - val_accuracy: 0.5093 - penalty: 0.0002\n",
            "hidden layer sizes: [120, 117, 114, 93, 85], total units: 529\n",
            "Before pruning:\n",
            "loss: 1.3878568410873413 - accuracy: 0.50008 - val_loss: 1.2975493669509888 - val_accuracy: 0.5327 - penalty: 0.0002\n",
            "hidden layer sizes: [120, 117, 114, 93, 85], total units: 529\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.297021508216858 - val_accuracy: 0.5321 - penalty: 0.0002\n",
            "hidden layer sizes: [100, 69, 77, 43, 65], total units: 354\n",
            "##########################################################\n",
            "Epoch 5/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.297021508216858 - val_accuracy: 0.5321 - penalty: 0.0002\n",
            "hidden layer sizes: [100, 69, 77, 43, 65], total units: 354\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.297021508216858 - val_accuracy: 0.5321 - penalty: 0.0002\n",
            "hidden layer sizes: [120, 89, 97, 63, 85], total units: 454\n",
            "Before pruning:\n",
            "loss: 1.3473299741744995 - accuracy: 0.51652 - val_loss: 1.2636339664459229 - val_accuracy: 0.5476 - penalty: 0.0002\n",
            "hidden layer sizes: [120, 89, 97, 63, 85], total units: 454\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.262658953666687 - val_accuracy: 0.5474 - penalty: 0.0002\n",
            "hidden layer sizes: [100, 53, 61, 37, 59], total units: 310\n",
            "##########################################################\n",
            "Epoch 6/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.262658953666687 - val_accuracy: 0.5474 - penalty: 0.0002\n",
            "hidden layer sizes: [100, 53, 61, 37, 59], total units: 310\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2626588344573975 - val_accuracy: 0.5474 - penalty: 0.0002\n",
            "hidden layer sizes: [120, 73, 81, 57, 79], total units: 410\n",
            "Before pruning:\n",
            "loss: 1.3186217546463013 - accuracy: 0.52638 - val_loss: 1.2190613746643066 - val_accuracy: 0.5675 - penalty: 0.0002\n",
            "hidden layer sizes: [120, 73, 81, 57, 79], total units: 410\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.218947410583496 - val_accuracy: 0.568 - penalty: 0.0002\n",
            "hidden layer sizes: [100, 42, 56, 33, 55], total units: 286\n",
            "##########################################################\n",
            "Epoch 7/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.218947410583496 - val_accuracy: 0.568 - penalty: 0.0002\n",
            "hidden layer sizes: [100, 42, 56, 33, 55], total units: 286\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.218947410583496 - val_accuracy: 0.568 - penalty: 0.0002\n",
            "hidden layer sizes: [120, 62, 76, 53, 75], total units: 386\n",
            "Before pruning:\n",
            "loss: 1.2806891202926636 - accuracy: 0.54082 - val_loss: 1.1773254871368408 - val_accuracy: 0.5821 - penalty: 0.0002\n",
            "hidden layer sizes: [120, 62, 76, 53, 75], total units: 386\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.177266001701355 - val_accuracy: 0.5823 - penalty: 0.0002\n",
            "hidden layer sizes: [100, 37, 48, 32, 49], total units: 266\n",
            "##########################################################\n",
            "Epoch 8/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.177266001701355 - val_accuracy: 0.5823 - penalty: 0.0002\n",
            "hidden layer sizes: [100, 37, 48, 32, 49], total units: 266\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.177266001701355 - val_accuracy: 0.5823 - penalty: 0.0002\n",
            "hidden layer sizes: [120, 57, 68, 52, 69], total units: 366\n",
            "Before pruning:\n",
            "loss: 1.2442739009857178 - accuracy: 0.55602 - val_loss: 1.1379311084747314 - val_accuracy: 0.5961 - penalty: 0.0002\n",
            "hidden layer sizes: [120, 57, 68, 52, 69], total units: 366\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1379812955856323 - val_accuracy: 0.5956 - penalty: 0.0002\n",
            "hidden layer sizes: [98, 34, 45, 31, 39], total units: 247\n",
            "##########################################################\n",
            "Epoch 9/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1379812955856323 - val_accuracy: 0.5956 - penalty: 0.0002\n",
            "hidden layer sizes: [98, 34, 45, 31, 39], total units: 247\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1379812955856323 - val_accuracy: 0.5956 - penalty: 0.0002\n",
            "hidden layer sizes: [118, 54, 65, 51, 59], total units: 347\n",
            "Before pruning:\n",
            "loss: 1.2137062549591064 - accuracy: 0.5667 - val_loss: 1.105705976486206 - val_accuracy: 0.6077 - penalty: 0.0002\n",
            "hidden layer sizes: [118, 54, 65, 51, 59], total units: 347\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.105811357498169 - val_accuracy: 0.6081 - penalty: 0.0002\n",
            "hidden layer sizes: [96, 33, 44, 29, 36], total units: 238\n",
            "##########################################################\n",
            "Epoch 10/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.105811357498169 - val_accuracy: 0.6081 - penalty: 0.0002\n",
            "hidden layer sizes: [96, 33, 44, 29, 36], total units: 238\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1058114767074585 - val_accuracy: 0.6081 - penalty: 0.0002\n",
            "hidden layer sizes: [116, 53, 64, 49, 56], total units: 338\n",
            "Before pruning:\n",
            "loss: 1.1909208297729492 - accuracy: 0.57556 - val_loss: 1.087236762046814 - val_accuracy: 0.6156 - penalty: 0.0002\n",
            "hidden layer sizes: [116, 53, 64, 49, 56], total units: 338\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0873011350631714 - val_accuracy: 0.6153 - penalty: 0.0002\n",
            "hidden layer sizes: [90, 31, 39, 27, 34], total units: 221\n",
            "##########################################################\n",
            "Epoch 11/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0873011350631714 - val_accuracy: 0.6153 - penalty: 0.0002\n",
            "hidden layer sizes: [90, 31, 39, 27, 34], total units: 221\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0873010158538818 - val_accuracy: 0.6153 - penalty: 0.0002\n",
            "hidden layer sizes: [110, 51, 59, 47, 54], total units: 321\n",
            "Before pruning:\n",
            "loss: 1.1674894094467163 - accuracy: 0.58482 - val_loss: 1.0676466226577759 - val_accuracy: 0.6222 - penalty: 0.0002\n",
            "hidden layer sizes: [110, 51, 59, 47, 54], total units: 321\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0675175189971924 - val_accuracy: 0.6219 - penalty: 0.0002\n",
            "hidden layer sizes: [86, 29, 38, 28, 30], total units: 211\n",
            "##########################################################\n",
            "Epoch 12/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0675175189971924 - val_accuracy: 0.6219 - penalty: 0.0002\n",
            "hidden layer sizes: [86, 29, 38, 28, 30], total units: 211\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0675175189971924 - val_accuracy: 0.6219 - penalty: 0.0002\n",
            "hidden layer sizes: [106, 49, 58, 48, 50], total units: 311\n",
            "Before pruning:\n",
            "loss: 1.1460075378417969 - accuracy: 0.59268 - val_loss: 1.046798586845398 - val_accuracy: 0.6255 - penalty: 0.0002\n",
            "hidden layer sizes: [106, 49, 58, 48, 50], total units: 311\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0469427108764648 - val_accuracy: 0.6255 - penalty: 0.0002\n",
            "hidden layer sizes: [83, 28, 37, 28, 28], total units: 204\n",
            "##########################################################\n",
            "Epoch 13/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0469427108764648 - val_accuracy: 0.6255 - penalty: 0.0002\n",
            "hidden layer sizes: [83, 28, 37, 28, 28], total units: 204\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0469427108764648 - val_accuracy: 0.6255 - penalty: 0.0002\n",
            "hidden layer sizes: [103, 48, 57, 48, 48], total units: 304\n",
            "Before pruning:\n",
            "loss: 1.1275900602340698 - accuracy: 0.6019 - val_loss: 1.026125431060791 - val_accuracy: 0.6346 - penalty: 0.0002\n",
            "hidden layer sizes: [103, 48, 57, 48, 48], total units: 304\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0261081457138062 - val_accuracy: 0.6345 - penalty: 0.0002\n",
            "hidden layer sizes: [78, 25, 37, 27, 27], total units: 194\n",
            "##########################################################\n",
            "Epoch 14/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0261081457138062 - val_accuracy: 0.6345 - penalty: 0.0002\n",
            "hidden layer sizes: [78, 25, 37, 27, 27], total units: 194\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0261082649230957 - val_accuracy: 0.6345 - penalty: 0.0002\n",
            "hidden layer sizes: [98, 45, 57, 47, 47], total units: 294\n",
            "Before pruning:\n",
            "loss: 1.1047941446304321 - accuracy: 0.60612 - val_loss: 1.0176721811294556 - val_accuracy: 0.6375 - penalty: 0.0002\n",
            "hidden layer sizes: [98, 45, 57, 47, 47], total units: 294\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0178762674331665 - val_accuracy: 0.637 - penalty: 0.0002\n",
            "hidden layer sizes: [72, 25, 34, 28, 26], total units: 185\n",
            "##########################################################\n",
            "Epoch 15/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0178762674331665 - val_accuracy: 0.637 - penalty: 0.0002\n",
            "hidden layer sizes: [72, 25, 34, 28, 26], total units: 185\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.017876148223877 - val_accuracy: 0.637 - penalty: 0.0002\n",
            "hidden layer sizes: [92, 45, 54, 48, 46], total units: 285\n",
            "Before pruning:\n",
            "loss: 1.0923577547073364 - accuracy: 0.6104 - val_loss: 0.9848825931549072 - val_accuracy: 0.6495 - penalty: 0.0002\n",
            "hidden layer sizes: [92, 45, 54, 48, 46], total units: 285\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9850684404373169 - val_accuracy: 0.6493 - penalty: 0.0002\n",
            "hidden layer sizes: [69, 25, 34, 28, 26], total units: 182\n",
            "##########################################################\n",
            "Epoch 16/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9850684404373169 - val_accuracy: 0.6493 - penalty: 0.0002\n",
            "hidden layer sizes: [69, 25, 34, 28, 26], total units: 182\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9850684404373169 - val_accuracy: 0.6493 - penalty: 0.0002\n",
            "hidden layer sizes: [89, 45, 54, 48, 46], total units: 282\n",
            "Before pruning:\n",
            "loss: 1.080136775970459 - accuracy: 0.61782 - val_loss: 0.9830233454704285 - val_accuracy: 0.6553 - penalty: 0.0002\n",
            "hidden layer sizes: [89, 45, 54, 48, 46], total units: 282\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9833043813705444 - val_accuracy: 0.6552 - penalty: 0.0002\n",
            "hidden layer sizes: [69, 23, 32, 27, 24], total units: 175\n",
            "##########################################################\n",
            "Epoch 17/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9833043813705444 - val_accuracy: 0.6552 - penalty: 0.0002\n",
            "hidden layer sizes: [69, 23, 32, 27, 24], total units: 175\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9833043813705444 - val_accuracy: 0.6552 - penalty: 0.0002\n",
            "hidden layer sizes: [89, 43, 52, 47, 44], total units: 275\n",
            "Before pruning:\n",
            "loss: 1.0672467947006226 - accuracy: 0.62264 - val_loss: 0.9682396650314331 - val_accuracy: 0.6583 - penalty: 0.0002\n",
            "hidden layer sizes: [89, 43, 52, 47, 44], total units: 275\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9684367179870605 - val_accuracy: 0.6573 - penalty: 0.0002\n",
            "hidden layer sizes: [68, 22, 30, 30, 26], total units: 176\n",
            "##########################################################\n",
            "Epoch 18/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9684367179870605 - val_accuracy: 0.6573 - penalty: 0.0002\n",
            "hidden layer sizes: [68, 22, 30, 30, 26], total units: 176\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9684367179870605 - val_accuracy: 0.6573 - penalty: 0.0002\n",
            "hidden layer sizes: [88, 42, 50, 50, 46], total units: 276\n",
            "Before pruning:\n",
            "loss: 1.0592597723007202 - accuracy: 0.62734 - val_loss: 0.9603596925735474 - val_accuracy: 0.6646 - penalty: 0.0002\n",
            "hidden layer sizes: [88, 42, 50, 50, 46], total units: 276\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9605136513710022 - val_accuracy: 0.6642 - penalty: 0.0002\n",
            "hidden layer sizes: [67, 22, 30, 28, 22], total units: 169\n",
            "##########################################################\n",
            "Epoch 19/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9605136513710022 - val_accuracy: 0.6642 - penalty: 0.0002\n",
            "hidden layer sizes: [67, 22, 30, 28, 22], total units: 169\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9605136513710022 - val_accuracy: 0.6642 - penalty: 0.0002\n",
            "hidden layer sizes: [87, 42, 50, 48, 42], total units: 269\n",
            "Before pruning:\n",
            "loss: 1.0443825721740723 - accuracy: 0.62868 - val_loss: 0.9420485496520996 - val_accuracy: 0.6709 - penalty: 0.0002\n",
            "hidden layer sizes: [87, 42, 50, 48, 42], total units: 269\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.942162036895752 - val_accuracy: 0.6708 - penalty: 0.0002\n",
            "hidden layer sizes: [63, 22, 29, 30, 22], total units: 166\n",
            "##########################################################\n",
            "Epoch 20/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.942162036895752 - val_accuracy: 0.6708 - penalty: 0.0002\n",
            "hidden layer sizes: [63, 22, 29, 30, 22], total units: 166\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9421619176864624 - val_accuracy: 0.6708 - penalty: 0.0002\n",
            "hidden layer sizes: [83, 42, 49, 50, 42], total units: 266\n",
            "Before pruning:\n",
            "loss: 1.037490963935852 - accuracy: 0.63402 - val_loss: 0.9362900257110596 - val_accuracy: 0.6695 - penalty: 0.0002\n",
            "hidden layer sizes: [83, 42, 49, 50, 42], total units: 266\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9363817572593689 - val_accuracy: 0.6697 - penalty: 0.0002\n",
            "hidden layer sizes: [62, 22, 29, 29, 23], total units: 165\n",
            "##########################################################\n",
            "Epoch 21/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9363817572593689 - val_accuracy: 0.6697 - penalty: 0.0002\n",
            "hidden layer sizes: [62, 22, 29, 29, 23], total units: 165\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9363818168640137 - val_accuracy: 0.6697 - penalty: 0.0002\n",
            "hidden layer sizes: [82, 42, 49, 49, 43], total units: 265\n",
            "Before pruning:\n",
            "loss: 1.0275501012802124 - accuracy: 0.63732 - val_loss: 0.9363196492195129 - val_accuracy: 0.67 - penalty: 0.0002\n",
            "hidden layer sizes: [82, 42, 49, 49, 43], total units: 265\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.936357319355011 - val_accuracy: 0.6698 - penalty: 0.0002\n",
            "hidden layer sizes: [60, 22, 28, 31, 23], total units: 164\n",
            "##########################################################\n",
            "Epoch 22/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.936357319355011 - val_accuracy: 0.6698 - penalty: 0.0002\n",
            "hidden layer sizes: [60, 22, 28, 31, 23], total units: 164\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.936357319355011 - val_accuracy: 0.6698 - penalty: 0.0002\n",
            "hidden layer sizes: [80, 42, 48, 51, 43], total units: 264\n",
            "Before pruning:\n",
            "loss: 1.021601915359497 - accuracy: 0.63812 - val_loss: 0.9173516631126404 - val_accuracy: 0.6795 - penalty: 0.0002\n",
            "hidden layer sizes: [80, 42, 48, 51, 43], total units: 264\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9175514578819275 - val_accuracy: 0.6793 - penalty: 0.0002\n",
            "hidden layer sizes: [58, 22, 28, 29, 26], total units: 163\n",
            "##########################################################\n",
            "Epoch 23/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9175514578819275 - val_accuracy: 0.6793 - penalty: 0.0002\n",
            "hidden layer sizes: [58, 22, 28, 29, 26], total units: 163\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.917551577091217 - val_accuracy: 0.6793 - penalty: 0.0002\n",
            "hidden layer sizes: [78, 42, 48, 49, 46], total units: 263\n",
            "Before pruning:\n",
            "loss: 1.0130118131637573 - accuracy: 0.64108 - val_loss: 0.9113852381706238 - val_accuracy: 0.6819 - penalty: 0.0002\n",
            "hidden layer sizes: [78, 42, 48, 49, 46], total units: 263\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9115383625030518 - val_accuracy: 0.6825 - penalty: 0.0002\n",
            "hidden layer sizes: [57, 21, 27, 28, 23], total units: 156\n",
            "##########################################################\n",
            "Epoch 24/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9115383625030518 - val_accuracy: 0.6825 - penalty: 0.0002\n",
            "hidden layer sizes: [57, 21, 27, 28, 23], total units: 156\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9115384817123413 - val_accuracy: 0.6825 - penalty: 0.0002\n",
            "hidden layer sizes: [77, 41, 47, 48, 43], total units: 256\n",
            "Before pruning:\n",
            "loss: 1.0069270133972168 - accuracy: 0.64346 - val_loss: 0.9062437415122986 - val_accuracy: 0.6844 - penalty: 0.0002\n",
            "hidden layer sizes: [77, 41, 47, 48, 43], total units: 256\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9062957167625427 - val_accuracy: 0.6842 - penalty: 0.0002\n",
            "hidden layer sizes: [55, 20, 23, 30, 23], total units: 151\n",
            "##########################################################\n",
            "Epoch 25/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9062957167625427 - val_accuracy: 0.6842 - penalty: 0.0002\n",
            "hidden layer sizes: [55, 20, 23, 30, 23], total units: 151\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9062957167625427 - val_accuracy: 0.6842 - penalty: 0.0002\n",
            "hidden layer sizes: [75, 40, 43, 50, 43], total units: 251\n",
            "Before pruning:\n",
            "loss: 1.0006380081176758 - accuracy: 0.64622 - val_loss: 0.9033715724945068 - val_accuracy: 0.6889 - penalty: 0.0002\n",
            "hidden layer sizes: [75, 40, 43, 50, 43], total units: 251\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9034029245376587 - val_accuracy: 0.6886 - penalty: 0.0002\n",
            "hidden layer sizes: [55, 20, 23, 32, 18], total units: 148\n",
            "##########################################################\n",
            "Epoch 26/50\n",
            "loss: 1.0002225637435913 - accuracy: 0.64704 - val_loss: 0.8806334733963013 - val_accuracy: 0.6916 - penalty: 0.0\n",
            "hidden layer sizes: [55, 20, 23, 32, 18], total units: 148\n",
            "##########################################################\n",
            "Epoch 27/50\n",
            "loss: 0.9270644783973694 - accuracy: 0.67368 - val_loss: 0.8560546636581421 - val_accuracy: 0.702 - penalty: 0.0\n",
            "hidden layer sizes: [55, 20, 23, 32, 18], total units: 148\n",
            "##########################################################\n",
            "Epoch 28/50\n",
            "loss: 0.9033069014549255 - accuracy: 0.68122 - val_loss: 0.8488941192626953 - val_accuracy: 0.7061 - penalty: 0.0\n",
            "hidden layer sizes: [55, 20, 23, 32, 18], total units: 148\n",
            "##########################################################\n",
            "Epoch 29/50\n",
            "loss: 0.8893980979919434 - accuracy: 0.68562 - val_loss: 0.8359463810920715 - val_accuracy: 0.7098 - penalty: 0.0\n",
            "hidden layer sizes: [55, 20, 23, 32, 18], total units: 148\n",
            "##########################################################\n",
            "Epoch 30/50\n",
            "loss: 0.8708996772766113 - accuracy: 0.69278 - val_loss: 0.8274732232093811 - val_accuracy: 0.7134 - penalty: 0.0\n",
            "hidden layer sizes: [55, 20, 23, 32, 18], total units: 148\n",
            "##########################################################\n",
            "Epoch 31/50\n",
            "loss: 0.8657953143119812 - accuracy: 0.69456 - val_loss: 0.8208012580871582 - val_accuracy: 0.7143 - penalty: 0.0\n",
            "hidden layer sizes: [55, 20, 23, 32, 18], total units: 148\n",
            "##########################################################\n",
            "Epoch 32/50\n",
            "loss: 0.8520475029945374 - accuracy: 0.6994 - val_loss: 0.8205234408378601 - val_accuracy: 0.7133 - penalty: 0.0\n",
            "hidden layer sizes: [55, 20, 23, 32, 18], total units: 148\n",
            "##########################################################\n",
            "Epoch 33/50\n",
            "loss: 0.8457399010658264 - accuracy: 0.70086 - val_loss: 0.8157749772071838 - val_accuracy: 0.7157 - penalty: 0.0\n",
            "hidden layer sizes: [55, 20, 23, 32, 18], total units: 148\n",
            "##########################################################\n",
            "Epoch 34/50\n",
            "loss: 0.8388468623161316 - accuracy: 0.70294 - val_loss: 0.8066560626029968 - val_accuracy: 0.7204 - penalty: 0.0\n",
            "hidden layer sizes: [55, 20, 23, 32, 18], total units: 148\n",
            "##########################################################\n",
            "Epoch 35/50\n",
            "loss: 0.8347657322883606 - accuracy: 0.70628 - val_loss: 0.8076861500740051 - val_accuracy: 0.7179 - penalty: 0.0\n",
            "hidden layer sizes: [55, 20, 23, 32, 18], total units: 148\n",
            "##########################################################\n",
            "Epoch 36/50\n",
            "loss: 0.8206713795661926 - accuracy: 0.70988 - val_loss: 0.8070495128631592 - val_accuracy: 0.7191 - penalty: 0.0\n",
            "hidden layer sizes: [55, 20, 23, 32, 18], total units: 148\n",
            "##########################################################\n",
            "Epoch 37/50\n",
            "loss: 0.8196030259132385 - accuracy: 0.70846 - val_loss: 0.7940528988838196 - val_accuracy: 0.7256 - penalty: 0.0\n",
            "hidden layer sizes: [55, 20, 23, 32, 18], total units: 148\n",
            "##########################################################\n",
            "Epoch 38/50\n",
            "loss: 0.8133401274681091 - accuracy: 0.71158 - val_loss: 0.7960644960403442 - val_accuracy: 0.7228 - penalty: 0.0\n",
            "hidden layer sizes: [55, 20, 23, 32, 18], total units: 148\n",
            "##########################################################\n",
            "Epoch 39/50\n",
            "loss: 0.812664270401001 - accuracy: 0.7117 - val_loss: 0.7934231758117676 - val_accuracy: 0.7226 - penalty: 0.0\n",
            "hidden layer sizes: [55, 20, 23, 32, 18], total units: 148\n",
            "##########################################################\n",
            "Epoch 40/50\n",
            "loss: 0.8028182983398438 - accuracy: 0.71566 - val_loss: 0.7923672795295715 - val_accuracy: 0.724 - penalty: 0.0\n",
            "hidden layer sizes: [55, 20, 23, 32, 18], total units: 148\n",
            "##########################################################\n",
            "Epoch 41/50\n",
            "loss: 0.7998282313346863 - accuracy: 0.7175 - val_loss: 0.7850451469421387 - val_accuracy: 0.7317 - penalty: 0.0\n",
            "hidden layer sizes: [55, 20, 23, 32, 18], total units: 148\n",
            "##########################################################\n",
            "Epoch 42/50\n",
            "loss: 0.7963330745697021 - accuracy: 0.71862 - val_loss: 0.7870863080024719 - val_accuracy: 0.7297 - penalty: 0.0\n",
            "hidden layer sizes: [55, 20, 23, 32, 18], total units: 148\n",
            "##########################################################\n",
            "Epoch 43/50\n",
            "loss: 0.7929406762123108 - accuracy: 0.72052 - val_loss: 0.7810430526733398 - val_accuracy: 0.7308 - penalty: 0.0\n",
            "hidden layer sizes: [55, 20, 23, 32, 18], total units: 148\n",
            "##########################################################\n",
            "Epoch 44/50\n",
            "loss: 0.7829212546348572 - accuracy: 0.72548 - val_loss: 0.7797870635986328 - val_accuracy: 0.7301 - penalty: 0.0\n",
            "hidden layer sizes: [55, 20, 23, 32, 18], total units: 148\n",
            "##########################################################\n",
            "Epoch 45/50\n",
            "loss: 0.7827578783035278 - accuracy: 0.72402 - val_loss: 0.7801023721694946 - val_accuracy: 0.7299 - penalty: 0.0\n",
            "hidden layer sizes: [55, 20, 23, 32, 18], total units: 148\n",
            "##########################################################\n",
            "Epoch 46/50\n",
            "loss: 0.7821564674377441 - accuracy: 0.72328 - val_loss: 0.7767571806907654 - val_accuracy: 0.732 - penalty: 0.0\n",
            "hidden layer sizes: [55, 20, 23, 32, 18], total units: 148\n",
            "##########################################################\n",
            "Epoch 47/50\n",
            "loss: 0.7791732549667358 - accuracy: 0.72392 - val_loss: 0.7741668820381165 - val_accuracy: 0.7282 - penalty: 0.0\n",
            "hidden layer sizes: [55, 20, 23, 32, 18], total units: 148\n",
            "##########################################################\n",
            "Epoch 48/50\n",
            "loss: 0.777328372001648 - accuracy: 0.72562 - val_loss: 0.779535710811615 - val_accuracy: 0.7311 - penalty: 0.0\n",
            "hidden layer sizes: [55, 20, 23, 32, 18], total units: 148\n",
            "##########################################################\n",
            "Epoch 49/50\n",
            "loss: 0.7720319628715515 - accuracy: 0.72892 - val_loss: 0.7734729051589966 - val_accuracy: 0.7323 - penalty: 0.0\n",
            "hidden layer sizes: [55, 20, 23, 32, 18], total units: 148\n",
            "##########################################################\n",
            "Epoch 50/50\n",
            "loss: 0.7650901079177856 - accuracy: 0.72992 - val_loss: 0.7660950422286987 - val_accuracy: 0.7355 - penalty: 0.0\n",
            "hidden layer sizes: [55, 20, 23, 32, 18], total units: 148\n",
            "CPU times: user 5min 57s, sys: 11.7 s, total: 6min 9s\n",
            "Wall time: 6min 43s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uTtm0MPka-J",
        "outputId": "b53ebc21-8c87-487e-ad6d-1c74c71927e4"
      },
      "source": [
        "%%time\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(50, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "        regularization_penalty=0.00004, regularization_method='weighted_l1', \n",
        "        kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "    Conv2D(50, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "        regularization_penalty=0.00004, regularization_method='weighted_l1', \n",
        "        kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    Conv2D(50, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "        regularization_penalty=0.00004, regularization_method='weighted_l1', \n",
        "        kernel_initializer='lecun_normal'),\n",
        "    Conv2D(50, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "        regularization_penalty=0.00004, regularization_method='weighted_l1', \n",
        "        kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    Conv2D(50, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "        regularization_penalty=0.00004, regularization_method='weighted_l1', \n",
        "        kernel_initializer='lecun_normal'),\n",
        "    Conv2D(50, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "        regularization_penalty=0.00004, regularization_method='weighted_l1', \n",
        "        kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    Flatten(),\n",
        "    Dense(50, activation='selu', regularization_penalty=0.00004, \n",
        "        regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "    Dense(10, activation='softmax', regularization_penalty=0., \n",
        "        regularization_method=None, fixed_size=True),\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.6487672328948975 - val_accuracy: 0.1297 - penalty: 4e-05\n",
            "hidden layer sizes: [50, 50, 50, 50, 50, 50, 50], total units: 350\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.6487674713134766 - val_accuracy: 0.1297 - penalty: 4e-05\n",
            "hidden layer sizes: [70, 70, 70, 70, 70, 70, 70], total units: 490\n",
            "Before pruning:\n",
            "loss: 2.1266281604766846 - accuracy: 0.28182 - val_loss: 1.653368353843689 - val_accuracy: 0.4168 - penalty: 4e-05\n",
            "hidden layer sizes: [70, 70, 70, 70, 70, 70, 70], total units: 490\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.6533691883087158 - val_accuracy: 0.4168 - penalty: 4e-05\n",
            "hidden layer sizes: [50, 50, 50, 50, 50, 50, 50], total units: 350\n",
            "##########################################################\n",
            "Epoch 2/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.6533691883087158 - val_accuracy: 0.4168 - penalty: 4e-05\n",
            "hidden layer sizes: [50, 50, 50, 50, 50, 50, 50], total units: 350\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.6533691883087158 - val_accuracy: 0.4168 - penalty: 4e-05\n",
            "hidden layer sizes: [70, 70, 70, 70, 70, 70, 70], total units: 490\n",
            "Before pruning:\n",
            "loss: 1.6825937032699585 - accuracy: 0.39572 - val_loss: 1.4909276962280273 - val_accuracy: 0.4677 - penalty: 4e-05\n",
            "hidden layer sizes: [70, 70, 70, 70, 70, 70, 70], total units: 490\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4909265041351318 - val_accuracy: 0.4677 - penalty: 4e-05\n",
            "hidden layer sizes: [50, 50, 50, 50, 50, 50, 50], total units: 350\n",
            "##########################################################\n",
            "Epoch 3/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4909265041351318 - val_accuracy: 0.4677 - penalty: 4e-05\n",
            "hidden layer sizes: [50, 50, 50, 50, 50, 50, 50], total units: 350\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4909265041351318 - val_accuracy: 0.4677 - penalty: 4e-05\n",
            "hidden layer sizes: [70, 70, 70, 70, 70, 70, 70], total units: 490\n",
            "Before pruning:\n",
            "loss: 1.5351753234863281 - accuracy: 0.445 - val_loss: 1.4170289039611816 - val_accuracy: 0.4893 - penalty: 4e-05\n",
            "hidden layer sizes: [70, 70, 70, 70, 70, 70, 70], total units: 490\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4170310497283936 - val_accuracy: 0.4894 - penalty: 4e-05\n",
            "hidden layer sizes: [50, 50, 50, 50, 50, 50, 50], total units: 350\n",
            "##########################################################\n",
            "Epoch 4/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4170310497283936 - val_accuracy: 0.4894 - penalty: 4e-05\n",
            "hidden layer sizes: [50, 50, 50, 50, 50, 50, 50], total units: 350\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4170310497283936 - val_accuracy: 0.4894 - penalty: 4e-05\n",
            "hidden layer sizes: [70, 70, 70, 70, 70, 70, 70], total units: 490\n",
            "Before pruning:\n",
            "loss: 1.4900881052017212 - accuracy: 0.46062 - val_loss: 1.4108303785324097 - val_accuracy: 0.4909 - penalty: 4e-05\n",
            "hidden layer sizes: [70, 70, 70, 70, 70, 70, 70], total units: 490\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4107903242111206 - val_accuracy: 0.4909 - penalty: 4e-05\n",
            "hidden layer sizes: [50, 50, 49, 50, 50, 50, 50], total units: 349\n",
            "##########################################################\n",
            "Epoch 5/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4107903242111206 - val_accuracy: 0.4909 - penalty: 4e-05\n",
            "hidden layer sizes: [50, 50, 49, 50, 50, 50, 50], total units: 349\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4107903242111206 - val_accuracy: 0.4909 - penalty: 4e-05\n",
            "hidden layer sizes: [70, 70, 69, 70, 70, 70, 70], total units: 489\n",
            "Before pruning:\n",
            "loss: 1.457450032234192 - accuracy: 0.47228 - val_loss: 1.3624565601348877 - val_accuracy: 0.5027 - penalty: 4e-05\n",
            "hidden layer sizes: [70, 70, 69, 70, 70, 70, 70], total units: 489\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.3624625205993652 - val_accuracy: 0.5027 - penalty: 4e-05\n",
            "hidden layer sizes: [50, 49, 45, 46, 46, 50, 50], total units: 336\n",
            "##########################################################\n",
            "Epoch 6/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.3624625205993652 - val_accuracy: 0.5027 - penalty: 4e-05\n",
            "hidden layer sizes: [50, 49, 45, 46, 46, 50, 50], total units: 336\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.3624625205993652 - val_accuracy: 0.5027 - penalty: 4e-05\n",
            "hidden layer sizes: [70, 69, 65, 66, 66, 70, 70], total units: 476\n",
            "Before pruning:\n",
            "loss: 1.419637680053711 - accuracy: 0.4869 - val_loss: 1.3173587322235107 - val_accuracy: 0.5246 - penalty: 4e-05\n",
            "hidden layer sizes: [70, 69, 65, 66, 66, 70, 70], total units: 476\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.317304253578186 - val_accuracy: 0.5248 - penalty: 4e-05\n",
            "hidden layer sizes: [50, 44, 36, 43, 41, 50, 50], total units: 314\n",
            "##########################################################\n",
            "Epoch 7/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.317304253578186 - val_accuracy: 0.5248 - penalty: 4e-05\n",
            "hidden layer sizes: [50, 44, 36, 43, 41, 50, 50], total units: 314\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.317304253578186 - val_accuracy: 0.5248 - penalty: 4e-05\n",
            "hidden layer sizes: [70, 64, 56, 63, 61, 70, 70], total units: 454\n",
            "Before pruning:\n",
            "loss: 1.3897186517715454 - accuracy: 0.49718 - val_loss: 1.2939305305480957 - val_accuracy: 0.5339 - penalty: 4e-05\n",
            "hidden layer sizes: [70, 64, 56, 63, 61, 70, 70], total units: 454\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.2939828634262085 - val_accuracy: 0.5337 - penalty: 4e-05\n",
            "hidden layer sizes: [50, 38, 35, 41, 33, 50, 51], total units: 298\n",
            "##########################################################\n",
            "Epoch 8/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2939828634262085 - val_accuracy: 0.5337 - penalty: 4e-05\n",
            "hidden layer sizes: [50, 38, 35, 41, 33, 50, 51], total units: 298\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.293982744216919 - val_accuracy: 0.5337 - penalty: 4e-05\n",
            "hidden layer sizes: [70, 58, 55, 61, 53, 70, 71], total units: 438\n",
            "Before pruning:\n",
            "loss: 1.3647747039794922 - accuracy: 0.5055 - val_loss: 1.2796485424041748 - val_accuracy: 0.537 - penalty: 4e-05\n",
            "hidden layer sizes: [70, 58, 55, 61, 53, 70, 71], total units: 438\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.2796357870101929 - val_accuracy: 0.5371 - penalty: 4e-05\n",
            "hidden layer sizes: [50, 32, 32, 41, 32, 47, 51], total units: 285\n",
            "##########################################################\n",
            "Epoch 9/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2796357870101929 - val_accuracy: 0.5371 - penalty: 4e-05\n",
            "hidden layer sizes: [50, 32, 32, 41, 32, 47, 51], total units: 285\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2796357870101929 - val_accuracy: 0.5371 - penalty: 4e-05\n",
            "hidden layer sizes: [70, 52, 52, 61, 52, 67, 71], total units: 425\n",
            "Before pruning:\n",
            "loss: 1.3408184051513672 - accuracy: 0.51556 - val_loss: 1.2426038980484009 - val_accuracy: 0.5508 - penalty: 4e-05\n",
            "hidden layer sizes: [70, 52, 52, 61, 52, 67, 71], total units: 425\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.2426137924194336 - val_accuracy: 0.5506 - penalty: 4e-05\n",
            "hidden layer sizes: [50, 29, 30, 38, 30, 45, 50], total units: 272\n",
            "##########################################################\n",
            "Epoch 10/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2426137924194336 - val_accuracy: 0.5506 - penalty: 4e-05\n",
            "hidden layer sizes: [50, 29, 30, 38, 30, 45, 50], total units: 272\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.242613673210144 - val_accuracy: 0.5506 - penalty: 4e-05\n",
            "hidden layer sizes: [70, 49, 50, 58, 50, 65, 70], total units: 412\n",
            "Before pruning:\n",
            "loss: 1.3196830749511719 - accuracy: 0.52538 - val_loss: 1.2196946144104004 - val_accuracy: 0.5636 - penalty: 4e-05\n",
            "hidden layer sizes: [70, 49, 50, 58, 50, 65, 70], total units: 412\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.219699501991272 - val_accuracy: 0.5635 - penalty: 4e-05\n",
            "hidden layer sizes: [49, 29, 26, 36, 25, 45, 52], total units: 262\n",
            "##########################################################\n",
            "Epoch 11/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.219699501991272 - val_accuracy: 0.5635 - penalty: 4e-05\n",
            "hidden layer sizes: [49, 29, 26, 36, 25, 45, 52], total units: 262\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2196993827819824 - val_accuracy: 0.5635 - penalty: 4e-05\n",
            "hidden layer sizes: [69, 49, 46, 56, 45, 65, 72], total units: 402\n",
            "Before pruning:\n",
            "loss: 1.299443244934082 - accuracy: 0.53066 - val_loss: 1.1968152523040771 - val_accuracy: 0.5712 - penalty: 4e-05\n",
            "hidden layer sizes: [69, 49, 46, 56, 45, 65, 72], total units: 402\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.196844220161438 - val_accuracy: 0.5712 - penalty: 4e-05\n",
            "hidden layer sizes: [49, 29, 21, 36, 24, 45, 50], total units: 254\n",
            "##########################################################\n",
            "Epoch 12/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.196844220161438 - val_accuracy: 0.5712 - penalty: 4e-05\n",
            "hidden layer sizes: [49, 29, 21, 36, 24, 45, 50], total units: 254\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.196844220161438 - val_accuracy: 0.5712 - penalty: 4e-05\n",
            "hidden layer sizes: [69, 49, 41, 56, 44, 65, 70], total units: 394\n",
            "Before pruning:\n",
            "loss: 1.274126410484314 - accuracy: 0.54046 - val_loss: 1.1794997453689575 - val_accuracy: 0.5796 - penalty: 4e-05\n",
            "hidden layer sizes: [69, 49, 41, 56, 44, 65, 70], total units: 394\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1795613765716553 - val_accuracy: 0.5795 - penalty: 4e-05\n",
            "hidden layer sizes: [49, 24, 21, 35, 23, 44, 49], total units: 245\n",
            "##########################################################\n",
            "Epoch 13/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1795613765716553 - val_accuracy: 0.5795 - penalty: 4e-05\n",
            "hidden layer sizes: [49, 24, 21, 35, 23, 44, 49], total units: 245\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1795614957809448 - val_accuracy: 0.5795 - penalty: 4e-05\n",
            "hidden layer sizes: [69, 44, 41, 55, 43, 64, 69], total units: 385\n",
            "Before pruning:\n",
            "loss: 1.252400279045105 - accuracy: 0.54774 - val_loss: 1.154573678970337 - val_accuracy: 0.5895 - penalty: 4e-05\n",
            "hidden layer sizes: [69, 44, 41, 55, 43, 64, 69], total units: 385\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1545917987823486 - val_accuracy: 0.5896 - penalty: 4e-05\n",
            "hidden layer sizes: [49, 23, 20, 35, 22, 44, 48], total units: 241\n",
            "##########################################################\n",
            "Epoch 14/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1545917987823486 - val_accuracy: 0.5896 - penalty: 4e-05\n",
            "hidden layer sizes: [49, 23, 20, 35, 22, 44, 48], total units: 241\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.154591679573059 - val_accuracy: 0.5896 - penalty: 4e-05\n",
            "hidden layer sizes: [69, 43, 40, 55, 42, 64, 68], total units: 381\n",
            "Before pruning:\n",
            "loss: 1.2304483652114868 - accuracy: 0.55918 - val_loss: 1.1273924112319946 - val_accuracy: 0.5957 - penalty: 4e-05\n",
            "hidden layer sizes: [69, 43, 40, 55, 42, 64, 68], total units: 381\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.127418041229248 - val_accuracy: 0.596 - penalty: 4e-05\n",
            "hidden layer sizes: [48, 23, 20, 35, 21, 44, 53], total units: 244\n",
            "##########################################################\n",
            "Epoch 15/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.127418041229248 - val_accuracy: 0.596 - penalty: 4e-05\n",
            "hidden layer sizes: [48, 23, 20, 35, 21, 44, 53], total units: 244\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.127418041229248 - val_accuracy: 0.596 - penalty: 4e-05\n",
            "hidden layer sizes: [68, 43, 40, 55, 41, 64, 73], total units: 384\n",
            "Before pruning:\n",
            "loss: 1.2080329656600952 - accuracy: 0.5632 - val_loss: 1.1066416501998901 - val_accuracy: 0.6084 - penalty: 4e-05\n",
            "hidden layer sizes: [68, 43, 40, 55, 41, 64, 73], total units: 384\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1066651344299316 - val_accuracy: 0.6086 - penalty: 4e-05\n",
            "hidden layer sizes: [48, 22, 20, 34, 21, 44, 50], total units: 239\n",
            "##########################################################\n",
            "Epoch 16/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1066651344299316 - val_accuracy: 0.6086 - penalty: 4e-05\n",
            "hidden layer sizes: [48, 22, 20, 34, 21, 44, 50], total units: 239\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.106665015220642 - val_accuracy: 0.6086 - penalty: 4e-05\n",
            "hidden layer sizes: [68, 42, 40, 54, 41, 64, 70], total units: 379\n",
            "Before pruning:\n",
            "loss: 1.190979242324829 - accuracy: 0.57128 - val_loss: 1.0837960243225098 - val_accuracy: 0.6132 - penalty: 4e-05\n",
            "hidden layer sizes: [68, 42, 40, 54, 41, 64, 70], total units: 379\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0838782787322998 - val_accuracy: 0.6138 - penalty: 4e-05\n",
            "hidden layer sizes: [46, 22, 20, 33, 21, 43, 43], total units: 228\n",
            "##########################################################\n",
            "Epoch 17/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0838782787322998 - val_accuracy: 0.6138 - penalty: 4e-05\n",
            "hidden layer sizes: [46, 22, 20, 33, 21, 43, 43], total units: 228\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0838781595230103 - val_accuracy: 0.6138 - penalty: 4e-05\n",
            "hidden layer sizes: [66, 42, 40, 53, 41, 63, 63], total units: 368\n",
            "Before pruning:\n",
            "loss: 1.1690682172775269 - accuracy: 0.58136 - val_loss: 1.059781789779663 - val_accuracy: 0.6256 - penalty: 4e-05\n",
            "hidden layer sizes: [66, 42, 40, 53, 41, 63, 63], total units: 368\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0598065853118896 - val_accuracy: 0.6255 - penalty: 4e-05\n",
            "hidden layer sizes: [46, 21, 20, 33, 19, 43, 45], total units: 227\n",
            "##########################################################\n",
            "Epoch 18/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0598065853118896 - val_accuracy: 0.6255 - penalty: 4e-05\n",
            "hidden layer sizes: [46, 21, 20, 33, 19, 43, 45], total units: 227\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0598067045211792 - val_accuracy: 0.6255 - penalty: 4e-05\n",
            "hidden layer sizes: [66, 41, 40, 53, 39, 63, 65], total units: 367\n",
            "Before pruning:\n",
            "loss: 1.1578845977783203 - accuracy: 0.58506 - val_loss: 1.0547500848770142 - val_accuracy: 0.6256 - penalty: 4e-05\n",
            "hidden layer sizes: [66, 41, 40, 53, 39, 63, 65], total units: 367\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0547735691070557 - val_accuracy: 0.6255 - penalty: 4e-05\n",
            "hidden layer sizes: [43, 21, 20, 32, 19, 43, 52], total units: 230\n",
            "##########################################################\n",
            "Epoch 19/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0547735691070557 - val_accuracy: 0.6255 - penalty: 4e-05\n",
            "hidden layer sizes: [43, 21, 20, 32, 19, 43, 52], total units: 230\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0547736883163452 - val_accuracy: 0.6255 - penalty: 4e-05\n",
            "hidden layer sizes: [63, 41, 40, 52, 39, 63, 72], total units: 370\n",
            "Before pruning:\n",
            "loss: 1.1418640613555908 - accuracy: 0.59228 - val_loss: 1.0326076745986938 - val_accuracy: 0.636 - penalty: 4e-05\n",
            "hidden layer sizes: [63, 41, 40, 52, 39, 63, 72], total units: 370\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0326138734817505 - val_accuracy: 0.6363 - penalty: 4e-05\n",
            "hidden layer sizes: [42, 21, 20, 32, 17, 43, 44], total units: 219\n",
            "##########################################################\n",
            "Epoch 20/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0326138734817505 - val_accuracy: 0.6363 - penalty: 4e-05\n",
            "hidden layer sizes: [42, 21, 20, 32, 17, 43, 44], total units: 219\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.032613754272461 - val_accuracy: 0.6363 - penalty: 4e-05\n",
            "hidden layer sizes: [62, 41, 40, 52, 37, 63, 64], total units: 359\n",
            "Before pruning:\n",
            "loss: 1.1219505071640015 - accuracy: 0.59648 - val_loss: 1.0230308771133423 - val_accuracy: 0.638 - penalty: 4e-05\n",
            "hidden layer sizes: [62, 41, 40, 52, 37, 63, 64], total units: 359\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0230482816696167 - val_accuracy: 0.6382 - penalty: 4e-05\n",
            "hidden layer sizes: [42, 21, 20, 32, 17, 43, 42], total units: 217\n",
            "##########################################################\n",
            "Epoch 21/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0230482816696167 - val_accuracy: 0.6382 - penalty: 4e-05\n",
            "hidden layer sizes: [42, 21, 20, 32, 17, 43, 42], total units: 217\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0230481624603271 - val_accuracy: 0.6382 - penalty: 4e-05\n",
            "hidden layer sizes: [62, 41, 40, 52, 37, 63, 62], total units: 357\n",
            "Before pruning:\n",
            "loss: 1.1085336208343506 - accuracy: 0.60444 - val_loss: 1.0039783716201782 - val_accuracy: 0.6461 - penalty: 4e-05\n",
            "hidden layer sizes: [62, 41, 40, 52, 37, 63, 62], total units: 357\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0039743185043335 - val_accuracy: 0.6462 - penalty: 4e-05\n",
            "hidden layer sizes: [41, 20, 20, 31, 17, 43, 43], total units: 215\n",
            "##########################################################\n",
            "Epoch 22/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0039743185043335 - val_accuracy: 0.6462 - penalty: 4e-05\n",
            "hidden layer sizes: [41, 20, 20, 31, 17, 43, 43], total units: 215\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.003974437713623 - val_accuracy: 0.6462 - penalty: 4e-05\n",
            "hidden layer sizes: [61, 40, 40, 51, 37, 63, 63], total units: 355\n",
            "Before pruning:\n",
            "loss: 1.099334478378296 - accuracy: 0.60742 - val_loss: 0.9970114231109619 - val_accuracy: 0.6461 - penalty: 4e-05\n",
            "hidden layer sizes: [61, 40, 40, 51, 37, 63, 63], total units: 355\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9970340132713318 - val_accuracy: 0.6463 - penalty: 4e-05\n",
            "hidden layer sizes: [38, 20, 19, 29, 17, 43, 43], total units: 209\n",
            "##########################################################\n",
            "Epoch 23/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9970340132713318 - val_accuracy: 0.6463 - penalty: 4e-05\n",
            "hidden layer sizes: [38, 20, 19, 29, 17, 43, 43], total units: 209\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9970340728759766 - val_accuracy: 0.6463 - penalty: 4e-05\n",
            "hidden layer sizes: [58, 40, 39, 49, 37, 63, 63], total units: 349\n",
            "Before pruning:\n",
            "loss: 1.0899943113327026 - accuracy: 0.60874 - val_loss: 0.9895387887954712 - val_accuracy: 0.6507 - penalty: 4e-05\n",
            "hidden layer sizes: [58, 40, 39, 49, 37, 63, 63], total units: 349\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9895815253257751 - val_accuracy: 0.6506 - penalty: 4e-05\n",
            "hidden layer sizes: [38, 19, 20, 30, 16, 43, 48], total units: 214\n",
            "##########################################################\n",
            "Epoch 24/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9895815253257751 - val_accuracy: 0.6506 - penalty: 4e-05\n",
            "hidden layer sizes: [38, 19, 20, 30, 16, 43, 48], total units: 214\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9895816445350647 - val_accuracy: 0.6506 - penalty: 4e-05\n",
            "hidden layer sizes: [58, 39, 40, 50, 36, 63, 68], total units: 354\n",
            "Before pruning:\n",
            "loss: 1.0749529600143433 - accuracy: 0.61546 - val_loss: 0.9756425023078918 - val_accuracy: 0.6538 - penalty: 4e-05\n",
            "hidden layer sizes: [58, 39, 40, 50, 36, 63, 68], total units: 354\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9756567478179932 - val_accuracy: 0.654 - penalty: 4e-05\n",
            "hidden layer sizes: [37, 19, 19, 29, 16, 43, 43], total units: 206\n",
            "##########################################################\n",
            "Epoch 25/50\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9756567478179932 - val_accuracy: 0.654 - penalty: 4e-05\n",
            "hidden layer sizes: [37, 19, 19, 29, 16, 43, 43], total units: 206\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9756566286087036 - val_accuracy: 0.654 - penalty: 4e-05\n",
            "hidden layer sizes: [57, 39, 39, 49, 36, 63, 63], total units: 346\n",
            "Before pruning:\n",
            "loss: 1.0717589855194092 - accuracy: 0.61544 - val_loss: 0.9652131795883179 - val_accuracy: 0.6589 - penalty: 4e-05\n",
            "hidden layer sizes: [57, 39, 39, 49, 36, 63, 63], total units: 346\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9651671051979065 - val_accuracy: 0.6592 - penalty: 4e-05\n",
            "hidden layer sizes: [37, 19, 19, 29, 16, 43, 44], total units: 207\n",
            "##########################################################\n",
            "Epoch 26/50\n",
            "loss: 1.0570859909057617 - accuracy: 0.6248 - val_loss: 0.9401509761810303 - val_accuracy: 0.6658 - penalty: 0.0\n",
            "hidden layer sizes: [37, 19, 19, 29, 16, 43, 44], total units: 207\n",
            "##########################################################\n",
            "Epoch 27/50\n",
            "loss: 1.0079418420791626 - accuracy: 0.6413 - val_loss: 0.9231654405593872 - val_accuracy: 0.6742 - penalty: 0.0\n",
            "hidden layer sizes: [37, 19, 19, 29, 16, 43, 44], total units: 207\n",
            "##########################################################\n",
            "Epoch 28/50\n",
            "loss: 0.9841890335083008 - accuracy: 0.64728 - val_loss: 0.9095240235328674 - val_accuracy: 0.6773 - penalty: 0.0\n",
            "hidden layer sizes: [37, 19, 19, 29, 16, 43, 44], total units: 207\n",
            "##########################################################\n",
            "Epoch 29/50\n",
            "loss: 0.9738069772720337 - accuracy: 0.6512 - val_loss: 0.9038110375404358 - val_accuracy: 0.6776 - penalty: 0.0\n",
            "hidden layer sizes: [37, 19, 19, 29, 16, 43, 44], total units: 207\n",
            "##########################################################\n",
            "Epoch 30/50\n",
            "loss: 0.961307168006897 - accuracy: 0.65646 - val_loss: 0.8926622271537781 - val_accuracy: 0.6843 - penalty: 0.0\n",
            "hidden layer sizes: [37, 19, 19, 29, 16, 43, 44], total units: 207\n",
            "##########################################################\n",
            "Epoch 31/50\n",
            "loss: 0.9521803259849548 - accuracy: 0.65972 - val_loss: 0.8812605738639832 - val_accuracy: 0.6883 - penalty: 0.0\n",
            "hidden layer sizes: [37, 19, 19, 29, 16, 43, 44], total units: 207\n",
            "##########################################################\n",
            "Epoch 32/50\n",
            "loss: 0.9431283473968506 - accuracy: 0.66452 - val_loss: 0.8753944039344788 - val_accuracy: 0.6913 - penalty: 0.0\n",
            "hidden layer sizes: [37, 19, 19, 29, 16, 43, 44], total units: 207\n",
            "##########################################################\n",
            "Epoch 33/50\n",
            "loss: 0.935064435005188 - accuracy: 0.66664 - val_loss: 0.8712375164031982 - val_accuracy: 0.6942 - penalty: 0.0\n",
            "hidden layer sizes: [37, 19, 19, 29, 16, 43, 44], total units: 207\n",
            "##########################################################\n",
            "Epoch 34/50\n",
            "loss: 0.930364191532135 - accuracy: 0.66978 - val_loss: 0.8663395643234253 - val_accuracy: 0.6958 - penalty: 0.0\n",
            "hidden layer sizes: [37, 19, 19, 29, 16, 43, 44], total units: 207\n",
            "##########################################################\n",
            "Epoch 35/50\n",
            "loss: 0.9167850613594055 - accuracy: 0.67232 - val_loss: 0.8594712615013123 - val_accuracy: 0.6958 - penalty: 0.0\n",
            "hidden layer sizes: [37, 19, 19, 29, 16, 43, 44], total units: 207\n",
            "##########################################################\n",
            "Epoch 36/50\n",
            "loss: 0.9142414331436157 - accuracy: 0.67594 - val_loss: 0.8549419641494751 - val_accuracy: 0.6962 - penalty: 0.0\n",
            "hidden layer sizes: [37, 19, 19, 29, 16, 43, 44], total units: 207\n",
            "##########################################################\n",
            "Epoch 37/50\n",
            "loss: 0.9086212515830994 - accuracy: 0.67718 - val_loss: 0.8503959774971008 - val_accuracy: 0.6966 - penalty: 0.0\n",
            "hidden layer sizes: [37, 19, 19, 29, 16, 43, 44], total units: 207\n",
            "##########################################################\n",
            "Epoch 38/50\n",
            "loss: 0.9017905592918396 - accuracy: 0.67754 - val_loss: 0.8437998294830322 - val_accuracy: 0.7013 - penalty: 0.0\n",
            "hidden layer sizes: [37, 19, 19, 29, 16, 43, 44], total units: 207\n",
            "##########################################################\n",
            "Epoch 39/50\n",
            "loss: 0.8942519426345825 - accuracy: 0.68114 - val_loss: 0.8373317122459412 - val_accuracy: 0.7048 - penalty: 0.0\n",
            "hidden layer sizes: [37, 19, 19, 29, 16, 43, 44], total units: 207\n",
            "##########################################################\n",
            "Epoch 40/50\n",
            "loss: 0.8938478827476501 - accuracy: 0.68334 - val_loss: 0.8315481543540955 - val_accuracy: 0.7078 - penalty: 0.0\n",
            "hidden layer sizes: [37, 19, 19, 29, 16, 43, 44], total units: 207\n",
            "##########################################################\n",
            "Epoch 41/50\n",
            "loss: 0.887730062007904 - accuracy: 0.6838 - val_loss: 0.8294550776481628 - val_accuracy: 0.7068 - penalty: 0.0\n",
            "hidden layer sizes: [37, 19, 19, 29, 16, 43, 44], total units: 207\n",
            "##########################################################\n",
            "Epoch 42/50\n",
            "loss: 0.8836736679077148 - accuracy: 0.68692 - val_loss: 0.8257164359092712 - val_accuracy: 0.7106 - penalty: 0.0\n",
            "hidden layer sizes: [37, 19, 19, 29, 16, 43, 44], total units: 207\n",
            "##########################################################\n",
            "Epoch 43/50\n",
            "loss: 0.8737338781356812 - accuracy: 0.6894 - val_loss: 0.8262076377868652 - val_accuracy: 0.7092 - penalty: 0.0\n",
            "hidden layer sizes: [37, 19, 19, 29, 16, 43, 44], total units: 207\n",
            "##########################################################\n",
            "Epoch 44/50\n",
            "loss: 0.8717999458312988 - accuracy: 0.68968 - val_loss: 0.8160963654518127 - val_accuracy: 0.7103 - penalty: 0.0\n",
            "hidden layer sizes: [37, 19, 19, 29, 16, 43, 44], total units: 207\n",
            "##########################################################\n",
            "Epoch 45/50\n",
            "loss: 0.8679945468902588 - accuracy: 0.69002 - val_loss: 0.814414381980896 - val_accuracy: 0.7144 - penalty: 0.0\n",
            "hidden layer sizes: [37, 19, 19, 29, 16, 43, 44], total units: 207\n",
            "##########################################################\n",
            "Epoch 46/50\n",
            "loss: 0.8614490628242493 - accuracy: 0.69388 - val_loss: 0.8105058073997498 - val_accuracy: 0.713 - penalty: 0.0\n",
            "hidden layer sizes: [37, 19, 19, 29, 16, 43, 44], total units: 207\n",
            "##########################################################\n",
            "Epoch 47/50\n",
            "loss: 0.8585900664329529 - accuracy: 0.69502 - val_loss: 0.8048900365829468 - val_accuracy: 0.7159 - penalty: 0.0\n",
            "hidden layer sizes: [37, 19, 19, 29, 16, 43, 44], total units: 207\n",
            "##########################################################\n",
            "Epoch 48/50\n",
            "loss: 0.8547783493995667 - accuracy: 0.69546 - val_loss: 0.8069562315940857 - val_accuracy: 0.7145 - penalty: 0.0\n",
            "hidden layer sizes: [37, 19, 19, 29, 16, 43, 44], total units: 207\n",
            "##########################################################\n",
            "Epoch 49/50\n",
            "loss: 0.8495194315910339 - accuracy: 0.6984 - val_loss: 0.8015580773353577 - val_accuracy: 0.7189 - penalty: 0.0\n",
            "hidden layer sizes: [37, 19, 19, 29, 16, 43, 44], total units: 207\n",
            "##########################################################\n",
            "Epoch 50/50\n",
            "loss: 0.8486019372940063 - accuracy: 0.69798 - val_loss: 0.7987015843391418 - val_accuracy: 0.719 - penalty: 0.0\n",
            "hidden layer sizes: [37, 19, 19, 29, 16, 43, 44], total units: 207\n",
            "CPU times: user 6min 13s, sys: 7.36 s, total: 6min 20s\n",
            "Wall time: 6min 15s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPs6By3mMWI0",
        "outputId": "dd75c9c4-13a1-4f4f-c327-b82bfd52844c"
      },
      "source": [
        "%%time\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
        "\n",
        "best_val_accuracies = list()\n",
        "layer_sizes = list()\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X_norm)):\n",
        "    xtrain, xtest = X_norm[train_index], X_norm[test_index]\n",
        "    ytrain, ytest = y[train_index], y[test_index]\n",
        "\n",
        "    model = Sequential([\n",
        "        Conv2D(100, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.00002, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(100, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.00002, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(100, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.00002, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        Conv2D(100, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.00002, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(100, activation='selu', regularization_penalty=0.00002, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None, fixed_size=True),\n",
        "    ])\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "    history = model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "              min_new_neurons, validation_data=(X_test_norm, y_test), verbose=False)\n",
        "    best_val_accuracy = max(history['val_accuracy'])\n",
        "    current_layer_sizes = model.get_layer_sizes()\n",
        "    best_val_accuracies.append(best_val_accuracy)\n",
        "    layer_sizes.append(current_layer_sizes)\n",
        "    print(f\"Run {i} completed, best val accuracy: {best_val_accuracy}, layer sizes: {current_layer_sizes}\")\n",
        "\n",
        "print(f'val accuracies: {best_val_accuracies}')\n",
        "print(f'mean val accuracy: {np.mean(best_val_accuracies)}')\n",
        "\n",
        "print(f'mean layer sizes: {[np.mean(layer) for layer in list(zip(*layer_sizes))]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best val accuracy: 0.7636, layer sizes: [3, 62, 22, 27, 54, 98, 10]\n",
            "Run 1 completed, best val accuracy: 0.7498, layer sizes: [3, 56, 21, 25, 56, 96, 10]\n",
            "Run 2 completed, best val accuracy: 0.755, layer sizes: [3, 63, 20, 25, 49, 100, 10]\n",
            "Run 3 completed, best val accuracy: 0.7514, layer sizes: [3, 61, 25, 30, 48, 89, 10]\n",
            "Run 4 completed, best val accuracy: 0.7523, layer sizes: [3, 61, 24, 25, 55, 76, 10]\n",
            "Run 5 completed, best val accuracy: 0.7526, layer sizes: [3, 57, 19, 26, 58, 99, 10]\n",
            "val accuracies: [0.7636, 0.7498, 0.755, 0.7514, 0.7523, 0.7526]\n",
            "mean val accuracy: 0.7541166666666665\n",
            "mean layer sizes: [3.0, 60.0, 21.833333333333332, 26.333333333333332, 53.333333333333336, 93.0, 10.0]\n",
            "CPU times: user 31min 18s, sys: 33.6 s, total: 31min 52s\n",
            "Wall time: 33min 51s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI7mmTVBJcXc"
      },
      "source": [
        "epochs = 50\n",
        "self_scaling_epochs = 0\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syBV5yB9Jag8",
        "outputId": "4d79b782-534e-436e-8936-0a5590738528"
      },
      "source": [
        "%%time\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(55, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "        regularization_penalty=0., regularization_method=None, \n",
        "        kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "    Conv2D(25, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "        regularization_penalty=0., regularization_method=None, \n",
        "        kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    Conv2D(22, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "        regularization_penalty=0., regularization_method=None, \n",
        "        kernel_initializer='lecun_normal'),\n",
        "    Conv2D(58, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "        regularization_penalty=0., regularization_method=None, \n",
        "        kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    Flatten(),\n",
        "    Dense(119, activation='selu', regularization_penalty=0., \n",
        "        regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "    Dense(10, activation='softmax', regularization_penalty=0., \n",
        "        regularization_method=None, fixed_size=True),\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/50\n",
            "loss: 1.9990990161895752 - accuracy: 0.32738 - val_loss: 1.599170446395874 - val_accuracy: 0.4403 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 2/50\n",
            "loss: 1.6486480236053467 - accuracy: 0.419 - val_loss: 1.4694571495056152 - val_accuracy: 0.4777 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 3/50\n",
            "loss: 1.5221965312957764 - accuracy: 0.46136 - val_loss: 1.3948599100112915 - val_accuracy: 0.5049 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 4/50\n",
            "loss: 1.4431824684143066 - accuracy: 0.4875 - val_loss: 1.354522466659546 - val_accuracy: 0.5179 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 5/50\n",
            "loss: 1.3819899559020996 - accuracy: 0.50786 - val_loss: 1.3181591033935547 - val_accuracy: 0.5338 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 6/50\n",
            "loss: 1.3257880210876465 - accuracy: 0.52628 - val_loss: 1.2753374576568604 - val_accuracy: 0.5467 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 7/50\n",
            "loss: 1.2806510925292969 - accuracy: 0.54222 - val_loss: 1.242064356803894 - val_accuracy: 0.5584 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 8/50\n",
            "loss: 1.2469924688339233 - accuracy: 0.55798 - val_loss: 1.2142194509506226 - val_accuracy: 0.5728 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 9/50\n",
            "loss: 1.2046267986297607 - accuracy: 0.57374 - val_loss: 1.1980724334716797 - val_accuracy: 0.5755 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 10/50\n",
            "loss: 1.169944167137146 - accuracy: 0.58716 - val_loss: 1.1627548933029175 - val_accuracy: 0.5892 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 11/50\n",
            "loss: 1.1447315216064453 - accuracy: 0.59178 - val_loss: 1.1406850814819336 - val_accuracy: 0.5952 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 12/50\n",
            "loss: 1.1180191040039062 - accuracy: 0.60418 - val_loss: 1.1289639472961426 - val_accuracy: 0.5992 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 13/50\n",
            "loss: 1.0869059562683105 - accuracy: 0.6174 - val_loss: 1.1083115339279175 - val_accuracy: 0.6069 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 14/50\n",
            "loss: 1.0636745691299438 - accuracy: 0.62272 - val_loss: 1.098393440246582 - val_accuracy: 0.6102 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 15/50\n",
            "loss: 1.0412286520004272 - accuracy: 0.63224 - val_loss: 1.1034859418869019 - val_accuracy: 0.6114 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 16/50\n",
            "loss: 1.014727234840393 - accuracy: 0.64026 - val_loss: 1.1010584831237793 - val_accuracy: 0.6104 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 17/50\n",
            "loss: 1.0008751153945923 - accuracy: 0.647 - val_loss: 1.0659785270690918 - val_accuracy: 0.6251 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 18/50\n",
            "loss: 0.9717618227005005 - accuracy: 0.65776 - val_loss: 1.074166178703308 - val_accuracy: 0.6182 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 19/50\n",
            "loss: 0.9614270925521851 - accuracy: 0.6584 - val_loss: 1.0662871599197388 - val_accuracy: 0.627 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 20/50\n",
            "loss: 0.9481448531150818 - accuracy: 0.66656 - val_loss: 1.0518814325332642 - val_accuracy: 0.6337 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 21/50\n",
            "loss: 0.9222423434257507 - accuracy: 0.67596 - val_loss: 1.0505702495574951 - val_accuracy: 0.6308 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 22/50\n",
            "loss: 0.9006955623626709 - accuracy: 0.6818 - val_loss: 1.0224162340164185 - val_accuracy: 0.6385 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 23/50\n",
            "loss: 0.8837893605232239 - accuracy: 0.68688 - val_loss: 1.0278074741363525 - val_accuracy: 0.6434 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 24/50\n",
            "loss: 0.8709795475006104 - accuracy: 0.69252 - val_loss: 1.042336106300354 - val_accuracy: 0.6349 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 25/50\n",
            "loss: 0.8572096824645996 - accuracy: 0.6972 - val_loss: 1.0252044200897217 - val_accuracy: 0.6464 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 26/50\n",
            "loss: 0.8345277905464172 - accuracy: 0.70476 - val_loss: 1.0235220193862915 - val_accuracy: 0.6424 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 27/50\n",
            "loss: 0.828245222568512 - accuracy: 0.7063 - val_loss: 1.0223288536071777 - val_accuracy: 0.6454 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 28/50\n",
            "loss: 0.8061819672584534 - accuracy: 0.71394 - val_loss: 1.0212088823318481 - val_accuracy: 0.6462 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 29/50\n",
            "loss: 0.7964605689048767 - accuracy: 0.71794 - val_loss: 1.0407055616378784 - val_accuracy: 0.6413 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 30/50\n",
            "loss: 0.7767307758331299 - accuracy: 0.72218 - val_loss: 1.020138144493103 - val_accuracy: 0.6493 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 31/50\n",
            "loss: 0.7679877281188965 - accuracy: 0.7273 - val_loss: 1.0175909996032715 - val_accuracy: 0.6518 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 32/50\n",
            "loss: 0.7538284659385681 - accuracy: 0.73304 - val_loss: 1.0118147134780884 - val_accuracy: 0.6569 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 33/50\n",
            "loss: 0.7434443831443787 - accuracy: 0.73686 - val_loss: 1.0158100128173828 - val_accuracy: 0.653 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 34/50\n",
            "loss: 0.7264682650566101 - accuracy: 0.74286 - val_loss: 1.0188874006271362 - val_accuracy: 0.6509 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 35/50\n",
            "loss: 0.7192188501358032 - accuracy: 0.74344 - val_loss: 1.012286901473999 - val_accuracy: 0.6541 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 36/50\n",
            "loss: 0.7033214569091797 - accuracy: 0.7505 - val_loss: 1.0136823654174805 - val_accuracy: 0.6518 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 37/50\n",
            "loss: 0.6928548216819763 - accuracy: 0.75438 - val_loss: 1.0202292203903198 - val_accuracy: 0.652 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 38/50\n",
            "loss: 0.6864122152328491 - accuracy: 0.75514 - val_loss: 1.020311713218689 - val_accuracy: 0.6563 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 39/50\n",
            "loss: 0.6670423150062561 - accuracy: 0.76094 - val_loss: 1.0189563035964966 - val_accuracy: 0.6545 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 40/50\n",
            "loss: 0.6696322560310364 - accuracy: 0.76242 - val_loss: 1.0281952619552612 - val_accuracy: 0.6561 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 41/50\n",
            "loss: 0.6539120674133301 - accuracy: 0.76836 - val_loss: 1.0273916721343994 - val_accuracy: 0.6646 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 42/50\n",
            "loss: 0.6402376890182495 - accuracy: 0.76978 - val_loss: 1.020710825920105 - val_accuracy: 0.6644 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 43/50\n",
            "loss: 0.6340433359146118 - accuracy: 0.77444 - val_loss: 1.0389459133148193 - val_accuracy: 0.6594 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 44/50\n",
            "loss: 0.6235389113426208 - accuracy: 0.77742 - val_loss: 1.0370410680770874 - val_accuracy: 0.6606 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 45/50\n",
            "loss: 0.6157682538032532 - accuracy: 0.78152 - val_loss: 1.0608776807785034 - val_accuracy: 0.6565 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 46/50\n",
            "loss: 0.6004067659378052 - accuracy: 0.78448 - val_loss: 1.0399127006530762 - val_accuracy: 0.6579 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 47/50\n",
            "loss: 0.5989149212837219 - accuracy: 0.787 - val_loss: 1.0392881631851196 - val_accuracy: 0.6581 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 48/50\n",
            "loss: 0.5953251123428345 - accuracy: 0.78748 - val_loss: 1.0585551261901855 - val_accuracy: 0.6617 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 49/50\n",
            "loss: 0.5778113603591919 - accuracy: 0.79318 - val_loss: 1.0549027919769287 - val_accuracy: 0.6563 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 50/50\n",
            "loss: 0.5735008716583252 - accuracy: 0.7951 - val_loss: 1.0554035902023315 - val_accuracy: 0.6578 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "CPU times: user 3min 21s, sys: 3.43 s, total: 3min 24s\n",
            "Wall time: 3min 20s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb0pHgrMJqaH",
        "outputId": "dc648363-d0c8-4438-c285-b4020eba40e6"
      },
      "source": [
        "%%time\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(55, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "        regularization_penalty=0., regularization_method=None, \n",
        "        kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "    Conv2D(25, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "        regularization_penalty=0., regularization_method=None, \n",
        "        kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    Conv2D(22, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "        regularization_penalty=0., regularization_method=None, \n",
        "        kernel_initializer='lecun_normal'),\n",
        "    Conv2D(58, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "        regularization_penalty=0., regularization_method=None, \n",
        "        kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    Flatten(),\n",
        "    Dense(119, activation='selu', regularization_penalty=0., \n",
        "        regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "    Dense(10, activation='softmax', regularization_penalty=0., \n",
        "        regularization_method=None, fixed_size=True),\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/50\n",
            "loss: 1.915075421333313 - accuracy: 0.37872 - val_loss: 1.4394313097000122 - val_accuracy: 0.4697 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 2/50\n",
            "loss: 1.4282904863357544 - accuracy: 0.48744 - val_loss: 1.291615605354309 - val_accuracy: 0.5308 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 3/50\n",
            "loss: 1.2970649003982544 - accuracy: 0.5344 - val_loss: 1.2015643119812012 - val_accuracy: 0.5672 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 4/50\n",
            "loss: 1.2019590139389038 - accuracy: 0.56988 - val_loss: 1.1591837406158447 - val_accuracy: 0.584 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 5/50\n",
            "loss: 1.128372311592102 - accuracy: 0.59888 - val_loss: 1.1157585382461548 - val_accuracy: 0.6036 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 6/50\n",
            "loss: 1.0607378482818604 - accuracy: 0.6242 - val_loss: 1.0583068132400513 - val_accuracy: 0.6238 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 7/50\n",
            "loss: 1.0087007284164429 - accuracy: 0.64184 - val_loss: 1.0305343866348267 - val_accuracy: 0.638 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 8/50\n",
            "loss: 0.9440087676048279 - accuracy: 0.66116 - val_loss: 0.9640686511993408 - val_accuracy: 0.6597 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 9/50\n",
            "loss: 0.9042539596557617 - accuracy: 0.68002 - val_loss: 0.9810402393341064 - val_accuracy: 0.6518 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 10/50\n",
            "loss: 0.857810378074646 - accuracy: 0.6974 - val_loss: 0.920746386051178 - val_accuracy: 0.6819 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 11/50\n",
            "loss: 0.8205680251121521 - accuracy: 0.7099 - val_loss: 0.8951819539070129 - val_accuracy: 0.6858 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 12/50\n",
            "loss: 0.8008299469947815 - accuracy: 0.7164 - val_loss: 0.9033854603767395 - val_accuracy: 0.6888 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 13/50\n",
            "loss: 0.7729120254516602 - accuracy: 0.7272 - val_loss: 0.9155036211013794 - val_accuracy: 0.6856 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 14/50\n",
            "loss: 0.754785418510437 - accuracy: 0.73272 - val_loss: 0.9120608568191528 - val_accuracy: 0.6926 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 15/50\n",
            "loss: 0.7343584299087524 - accuracy: 0.74182 - val_loss: 0.9175431728363037 - val_accuracy: 0.6854 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 16/50\n",
            "loss: 0.7152019739151001 - accuracy: 0.74984 - val_loss: 0.8825807571411133 - val_accuracy: 0.7046 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 17/50\n",
            "loss: 0.6888958811759949 - accuracy: 0.7548 - val_loss: 0.8935097455978394 - val_accuracy: 0.7003 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 18/50\n",
            "loss: 0.6792892813682556 - accuracy: 0.7605 - val_loss: 0.9122950434684753 - val_accuracy: 0.699 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 19/50\n",
            "loss: 0.6660126447677612 - accuracy: 0.7654 - val_loss: 0.8813966512680054 - val_accuracy: 0.7096 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 20/50\n",
            "loss: 0.6476748585700989 - accuracy: 0.77232 - val_loss: 0.9021477699279785 - val_accuracy: 0.7075 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 21/50\n",
            "loss: 0.6339086890220642 - accuracy: 0.77644 - val_loss: 0.8931130170822144 - val_accuracy: 0.7112 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 22/50\n",
            "loss: 0.626730740070343 - accuracy: 0.77956 - val_loss: 0.9182817339897156 - val_accuracy: 0.7042 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 23/50\n",
            "loss: 0.6215802431106567 - accuracy: 0.78278 - val_loss: 0.9082286357879639 - val_accuracy: 0.7086 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 24/50\n",
            "loss: 0.6110655665397644 - accuracy: 0.78608 - val_loss: 0.8735010027885437 - val_accuracy: 0.7128 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 25/50\n",
            "loss: 0.5976380705833435 - accuracy: 0.7897 - val_loss: 0.9097871780395508 - val_accuracy: 0.712 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 26/50\n",
            "loss: 0.5851418375968933 - accuracy: 0.79512 - val_loss: 0.9087548851966858 - val_accuracy: 0.7099 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 27/50\n",
            "loss: 0.5790197253227234 - accuracy: 0.7975 - val_loss: 0.8885515332221985 - val_accuracy: 0.725 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 28/50\n",
            "loss: 0.5690442323684692 - accuracy: 0.80092 - val_loss: 0.8937551975250244 - val_accuracy: 0.7185 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 29/50\n",
            "loss: 0.5674926042556763 - accuracy: 0.80166 - val_loss: 0.930346667766571 - val_accuracy: 0.7194 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 30/50\n",
            "loss: 0.5686367750167847 - accuracy: 0.80312 - val_loss: 0.8964343667030334 - val_accuracy: 0.7278 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 31/50\n",
            "loss: 0.5622591376304626 - accuracy: 0.80482 - val_loss: 0.873735249042511 - val_accuracy: 0.724 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 32/50\n",
            "loss: 0.5335666537284851 - accuracy: 0.81414 - val_loss: 0.8995046019554138 - val_accuracy: 0.7135 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 33/50\n",
            "loss: 0.5459182262420654 - accuracy: 0.8103 - val_loss: 0.880293071269989 - val_accuracy: 0.7232 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 34/50\n",
            "loss: 0.5367486476898193 - accuracy: 0.81288 - val_loss: 0.8834089040756226 - val_accuracy: 0.727 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 35/50\n",
            "loss: 0.5346971750259399 - accuracy: 0.81604 - val_loss: 0.8931938409805298 - val_accuracy: 0.7198 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 36/50\n",
            "loss: 0.5275968313217163 - accuracy: 0.81872 - val_loss: 0.8964415788650513 - val_accuracy: 0.7214 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 37/50\n",
            "loss: 0.5205106735229492 - accuracy: 0.82112 - val_loss: 0.9066748023033142 - val_accuracy: 0.7189 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 38/50\n",
            "loss: 0.5183306932449341 - accuracy: 0.8197 - val_loss: 0.916569709777832 - val_accuracy: 0.7201 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 39/50\n",
            "loss: 0.5124198794364929 - accuracy: 0.82274 - val_loss: 0.9280585050582886 - val_accuracy: 0.7289 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 40/50\n",
            "loss: 0.5062956809997559 - accuracy: 0.82452 - val_loss: 0.8943594694137573 - val_accuracy: 0.7219 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 41/50\n",
            "loss: 0.502351701259613 - accuracy: 0.82684 - val_loss: 0.9489201903343201 - val_accuracy: 0.7271 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 42/50\n",
            "loss: 0.5089143514633179 - accuracy: 0.82586 - val_loss: 0.9258681535720825 - val_accuracy: 0.7218 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 43/50\n",
            "loss: 0.49321410059928894 - accuracy: 0.82942 - val_loss: 0.9025313258171082 - val_accuracy: 0.7342 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 44/50\n",
            "loss: 0.4913790225982666 - accuracy: 0.83206 - val_loss: 0.9394014477729797 - val_accuracy: 0.7301 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 45/50\n",
            "loss: 0.4996979832649231 - accuracy: 0.8273 - val_loss: 0.9302628040313721 - val_accuracy: 0.7253 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 46/50\n",
            "loss: 0.4868151545524597 - accuracy: 0.83296 - val_loss: 0.9098135828971863 - val_accuracy: 0.7265 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 47/50\n",
            "loss: 0.47610756754875183 - accuracy: 0.83686 - val_loss: 0.899819016456604 - val_accuracy: 0.7248 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 48/50\n",
            "loss: 0.48566845059394836 - accuracy: 0.8341 - val_loss: 0.9195400476455688 - val_accuracy: 0.7197 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 49/50\n",
            "loss: 0.4862934350967407 - accuracy: 0.83426 - val_loss: 0.9070791006088257 - val_accuracy: 0.7219 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "##########################################################\n",
            "Epoch 50/50\n",
            "loss: 0.47450730204582214 - accuracy: 0.83932 - val_loss: 0.9534910321235657 - val_accuracy: 0.727 - penalty: 0.0\n",
            "hidden layer sizes: [55, 25, 22, 58, 119], total units: 279\n",
            "CPU times: user 3min 21s, sys: 3.36 s, total: 3min 24s\n",
            "Wall time: 3min 20s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAwrLzo7XIZ9"
      },
      "source": [
        "60.0, 21.833333333333332, 26.333333333333332, 53.333333333333336, 93.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTDqbz3DXLX-"
      },
      "source": [
        "epochs = 50\n",
        "self_scaling_epochs = 0\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldRPVIrtW7fv",
        "outputId": "7112a41b-15fc-4c5c-fefe-e1bdd0b823fc"
      },
      "source": [
        "%%time\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
        "\n",
        "best_val_accuracies = list()\n",
        "layer_sizes = list()\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X_norm)):\n",
        "    xtrain, xtest = X_norm[train_index], X_norm[test_index]\n",
        "    ytrain, ytest = y[train_index], y[test_index]\n",
        "\n",
        "    model = Sequential([\n",
        "        Conv2D(60, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(22, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(26, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        Conv2D(53, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(93, activation='selu', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None, fixed_size=True),\n",
        "    ])\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.002)\n",
        "\n",
        "    history = model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "              min_new_neurons, validation_data=(X_test_norm, y_test), verbose=False)\n",
        "    best_val_accuracy = max(history['val_accuracy'])\n",
        "    current_layer_sizes = model.get_layer_sizes()\n",
        "    best_val_accuracies.append(best_val_accuracy)\n",
        "    layer_sizes.append(current_layer_sizes)\n",
        "    print(f\"Run {i} completed, best val accuracy: {best_val_accuracy}, layer sizes: {current_layer_sizes}\")\n",
        "\n",
        "print(f'val accuracies: {best_val_accuracies}')\n",
        "print(f'mean val accuracy: {np.mean(best_val_accuracies)}')\n",
        "\n",
        "print(f'mean layer sizes: {[np.mean(layer) for layer in list(zip(*layer_sizes))]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best val accuracy: 0.7457, layer sizes: [3, 60, 22, 26, 53, 93, 10]\n",
            "Run 1 completed, best val accuracy: 0.7405, layer sizes: [3, 60, 22, 26, 53, 93, 10]\n",
            "Run 2 completed, best val accuracy: 0.7495, layer sizes: [3, 60, 22, 26, 53, 93, 10]\n",
            "Run 3 completed, best val accuracy: 0.7346, layer sizes: [3, 60, 22, 26, 53, 93, 10]\n",
            "Run 4 completed, best val accuracy: 0.7457, layer sizes: [3, 60, 22, 26, 53, 93, 10]\n",
            "Run 5 completed, best val accuracy: 0.7428, layer sizes: [3, 60, 22, 26, 53, 93, 10]\n",
            "val accuracies: [0.7457, 0.7405, 0.7495, 0.7346, 0.7457, 0.7428]\n",
            "mean val accuracy: 0.7431333333333333\n",
            "mean layer sizes: [3.0, 60.0, 22.0, 26.0, 53.0, 93.0, 10.0]\n",
            "CPU times: user 18min 49s, sys: 26.3 s, total: 19min 16s\n",
            "Wall time: 19min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfe0hEVzdcpS",
        "outputId": "5a6502ae-1784-4bc9-cacd-34b4f58ab7fc"
      },
      "source": [
        "model = Sequential([\n",
        "    Conv2D(60, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "        regularization_penalty=0., regularization_method=None, \n",
        "        kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "    Conv2D(22, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "        regularization_penalty=0., regularization_method=None, \n",
        "        kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    Conv2D(26, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "        regularization_penalty=0., regularization_method=None, \n",
        "        kernel_initializer='lecun_normal'),\n",
        "    Conv2D(53, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "        regularization_penalty=0., regularization_method=None, \n",
        "        kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    Flatten(),\n",
        "    Dense(93, activation='selu', regularization_penalty=0., \n",
        "        regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "    Dense(10, activation='softmax', regularization_penalty=0., \n",
        "        regularization_method=None, fixed_size=True),\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, 1, 0, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/1\n",
            "loss: 1.8548481464385986 - accuracy: 0.37878 - val_loss: 1.4617165327072144 - val_accuracy: 0.4825 - penalty: 0.0\n",
            "hidden layer sizes: [60, 22, 26, 53, 93], total units: 254\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.37878],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.8548481>],\n",
              " 'val_accuracy': [0.4825],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.4617165>]}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjsEnEWMdkmc",
        "outputId": "ebf7b735-05a3-469e-9603-cd67a3e92f33"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_82 (Conv2D)           multiple                  1680      \n",
            "_________________________________________________________________\n",
            "conv2d_83 (Conv2D)           multiple                  11902     \n",
            "_________________________________________________________________\n",
            "dropout_41 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv2d_84 (Conv2D)           multiple                  5174      \n",
            "_________________________________________________________________\n",
            "conv2d_85 (Conv2D)           multiple                  12455     \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten_20 (Flatten)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             multiple                  315549    \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             multiple                  940       \n",
            "=================================================================\n",
            "Total params: 347,700\n",
            "Trainable params: 347,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0Dxecy2dmrF",
        "outputId": "81c2b122-b58a-4d4e-c048-8b2916f24644"
      },
      "source": [
        "model = Sequential([\n",
        "    Conv2D(47, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "        regularization_penalty=0., regularization_method=None, \n",
        "        kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "    Conv2D(47, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "        regularization_penalty=0., regularization_method=None, \n",
        "        kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    Conv2D(47, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "        regularization_penalty=0., regularization_method=None, \n",
        "        kernel_initializer='lecun_normal'),\n",
        "    Conv2D(47, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "        regularization_penalty=0., regularization_method=None, \n",
        "        kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    Flatten(),\n",
        "    Dense(93, activation='selu', regularization_penalty=0., \n",
        "        regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "    Dense(10, activation='softmax', regularization_penalty=0., \n",
        "        regularization_method=None, fixed_size=True),\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, 1, 0, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/1\n",
            "loss: 1.851806402206421 - accuracy: 0.3832 - val_loss: 1.3940980434417725 - val_accuracy: 0.4944 - penalty: 0.0\n",
            "hidden layer sizes: [47, 47, 47, 47, 93], total units: 281\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.3832],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.8518064>],\n",
              " 'val_accuracy': [0.4944],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.394098>]}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnm3uhisdtA3",
        "outputId": "ee6a162e-156e-4c5b-d18e-1c1336c22598"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_94 (Conv2D)           multiple                  1316      \n",
            "_________________________________________________________________\n",
            "conv2d_95 (Conv2D)           multiple                  19928     \n",
            "_________________________________________________________________\n",
            "dropout_47 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv2d_96 (Conv2D)           multiple                  19928     \n",
            "_________________________________________________________________\n",
            "conv2d_97 (Conv2D)           multiple                  19928     \n",
            "_________________________________________________________________\n",
            "dropout_48 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten_23 (Flatten)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             multiple                  279837    \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             multiple                  940       \n",
            "=================================================================\n",
            "Total params: 341,877\n",
            "Trainable params: 341,877\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cONggsINePB6",
        "outputId": "df279abb-0741-4d8c-a858-b2d27a4da13e"
      },
      "source": [
        "%%time\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
        "\n",
        "best_val_accuracies = list()\n",
        "layer_sizes = list()\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X_norm)):\n",
        "    xtrain, xtest = X_norm[train_index], X_norm[test_index]\n",
        "    ytrain, ytest = y[train_index], y[test_index]\n",
        "\n",
        "    model = Sequential([\n",
        "        Conv2D(47, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(47, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(47, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        Conv2D(47, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(93, activation='selu', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None, fixed_size=True),\n",
        "    ])\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.002)\n",
        "\n",
        "    history = model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "              min_new_neurons, validation_data=(X_test_norm, y_test), verbose=False)\n",
        "    best_val_accuracy = max(history['val_accuracy'])\n",
        "    current_layer_sizes = model.get_layer_sizes()\n",
        "    best_val_accuracies.append(best_val_accuracy)\n",
        "    layer_sizes.append(current_layer_sizes)\n",
        "    print(f\"Run {i} completed, best val accuracy: {best_val_accuracy}, layer sizes: {current_layer_sizes}\")\n",
        "\n",
        "print(f'val accuracies: {best_val_accuracies}')\n",
        "print(f'mean val accuracy: {np.mean(best_val_accuracies)}')\n",
        "\n",
        "print(f'mean layer sizes: {[np.mean(layer) for layer in list(zip(*layer_sizes))]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best val accuracy: 0.7522, layer sizes: [3, 47, 47, 47, 47, 93, 10]\n",
            "Run 1 completed, best val accuracy: 0.7639, layer sizes: [3, 47, 47, 47, 47, 93, 10]\n",
            "Run 2 completed, best val accuracy: 0.7548, layer sizes: [3, 47, 47, 47, 47, 93, 10]\n",
            "Run 3 completed, best val accuracy: 0.7611, layer sizes: [3, 47, 47, 47, 47, 93, 10]\n",
            "Run 4 completed, best val accuracy: 0.7567, layer sizes: [3, 47, 47, 47, 47, 93, 10]\n",
            "Run 5 completed, best val accuracy: 0.7612, layer sizes: [3, 47, 47, 47, 47, 93, 10]\n",
            "val accuracies: [0.7522, 0.7639, 0.7548, 0.7611, 0.7567, 0.7612]\n",
            "mean val accuracy: 0.7583166666666666\n",
            "mean layer sizes: [3.0, 47.0, 47.0, 47.0, 47.0, 93.0, 10.0]\n",
            "CPU times: user 19min 51s, sys: 26 s, total: 20min 17s\n",
            "Wall time: 20min 12s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwNfV7WmWw-r"
      },
      "source": [
        "# Deeper architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9Gd_Iy4WzYa"
      },
      "source": [
        "epochs = 20\n",
        "self_scaling_epochs = 20\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42AZfDwfW3lB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe71eb32-de9f-4067-9b24-f73bed8e3380"
      },
      "source": [
        "model = Sequential([\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Dense(256, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None, fixed_size=True),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.811230182647705 - val_accuracy: 0.0935 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 192, 256, 256], total units: 1472\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.811230182647705 - val_accuracy: 0.0935 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 307, 307], total units: 1764\n",
            "Before pruning:\n",
            "loss: 2.0089962482452393 - accuracy: 0.34114 - val_loss: 1.4994239807128906 - val_accuracy: 0.4688 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 307, 307], total units: 1764\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4994170665740967 - val_accuracy: 0.4687 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 192, 267, 288], total units: 1515\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4994170665740967 - val_accuracy: 0.4687 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 192, 267, 288], total units: 1515\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4994169473648071 - val_accuracy: 0.4687 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 320, 345], total units: 1815\n",
            "Before pruning:\n",
            "loss: 1.612258791923523 - accuracy: 0.42356 - val_loss: 1.3127188682556152 - val_accuracy: 0.525 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 320, 345], total units: 1815\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.3126733303070068 - val_accuracy: 0.5246 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 192, 261, 262], total units: 1483\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.3126733303070068 - val_accuracy: 0.5246 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 192, 261, 262], total units: 1483\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.3126733303070068 - val_accuracy: 0.5246 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 313, 314], total units: 1777\n",
            "Before pruning:\n",
            "loss: 1.409425973892212 - accuracy: 0.49296 - val_loss: 1.1963850259780884 - val_accuracy: 0.5684 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 313, 314], total units: 1777\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.196353554725647 - val_accuracy: 0.5684 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 192, 265, 256], total units: 1481\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.196353554725647 - val_accuracy: 0.5684 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 192, 265, 256], total units: 1481\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1963534355163574 - val_accuracy: 0.5684 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 318, 307], total units: 1775\n",
            "Before pruning:\n",
            "loss: 1.3170057535171509 - accuracy: 0.52344 - val_loss: 1.137181043624878 - val_accuracy: 0.5886 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 318, 307], total units: 1775\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1368311643600464 - val_accuracy: 0.5884 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 157, 170, 191, 192, 257, 256], total units: 1415\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1368311643600464 - val_accuracy: 0.5884 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 157, 170, 191, 192, 257, 256], total units: 1415\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1368311643600464 - val_accuracy: 0.5884 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 188, 204, 229, 230, 308, 307], total units: 1696\n",
            "Before pruning:\n",
            "loss: 1.2247231006622314 - accuracy: 0.56212 - val_loss: 1.0706379413604736 - val_accuracy: 0.6184 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 188, 204, 229, 230, 308, 307], total units: 1696\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0698719024658203 - val_accuracy: 0.6187 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 102, 151, 184, 192, 259, 256], total units: 1336\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0698719024658203 - val_accuracy: 0.6187 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 102, 151, 184, 192, 259, 256], total units: 1336\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0698719024658203 - val_accuracy: 0.6187 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 122, 181, 220, 230, 310, 307], total units: 1600\n",
            "Before pruning:\n",
            "loss: 1.1484946012496948 - accuracy: 0.58804 - val_loss: 1.0001367330551147 - val_accuracy: 0.6428 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 122, 181, 220, 230, 310, 307], total units: 1600\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9998205304145813 - val_accuracy: 0.6429 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 85, 139, 174, 192, 258, 257], total units: 1297\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9998205304145813 - val_accuracy: 0.6429 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 85, 139, 174, 192, 258, 257], total units: 1297\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9998205304145813 - val_accuracy: 0.6429 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 105, 166, 208, 230, 309, 308], total units: 1556\n",
            "Before pruning:\n",
            "loss: 1.0888670682907104 - accuracy: 0.6061 - val_loss: 0.9619160294532776 - val_accuracy: 0.6585 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 105, 166, 208, 230, 309, 308], total units: 1556\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9617174863815308 - val_accuracy: 0.6588 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 68, 128, 160, 191, 263, 269], total units: 1271\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9617174863815308 - val_accuracy: 0.6588 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 68, 128, 160, 191, 263, 269], total units: 1271\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9617174863815308 - val_accuracy: 0.6588 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 88, 153, 192, 229, 315, 322], total units: 1529\n",
            "Before pruning:\n",
            "loss: 1.0441266298294067 - accuracy: 0.62636 - val_loss: 0.9099509716033936 - val_accuracy: 0.6748 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 88, 153, 192, 229, 315, 322], total units: 1529\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9098342657089233 - val_accuracy: 0.6747 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 77, 106, 150, 190, 260, 259], total units: 1234\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9098342657089233 - val_accuracy: 0.6747 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 77, 106, 150, 190, 260, 259], total units: 1234\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9098342061042786 - val_accuracy: 0.6747 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 97, 127, 180, 228, 312, 310], total units: 1484\n",
            "Before pruning:\n",
            "loss: 1.013214111328125 - accuracy: 0.63776 - val_loss: 0.869118869304657 - val_accuracy: 0.6918 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 97, 127, 180, 228, 312, 310], total units: 1484\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8689793944358826 - val_accuracy: 0.6921 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 56, 102, 143, 186, 262, 259], total units: 1200\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8689793944358826 - val_accuracy: 0.6921 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 56, 102, 143, 186, 262, 259], total units: 1200\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8689793944358826 - val_accuracy: 0.6921 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 76, 122, 171, 223, 314, 310], total units: 1446\n",
            "Before pruning:\n",
            "loss: 0.97169429063797 - accuracy: 0.65238 - val_loss: 0.8336386680603027 - val_accuracy: 0.7022 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 76, 122, 171, 223, 314, 310], total units: 1446\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8336556553840637 - val_accuracy: 0.7027 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 52, 92, 136, 186, 264, 286], total units: 1207\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8336556553840637 - val_accuracy: 0.7027 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 52, 92, 136, 186, 264, 286], total units: 1207\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.833655595779419 - val_accuracy: 0.7027 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 72, 112, 163, 223, 316, 343], total units: 1458\n",
            "Before pruning:\n",
            "loss: 0.9481240510940552 - accuracy: 0.66166 - val_loss: 0.8369192481040955 - val_accuracy: 0.7028 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 72, 112, 163, 223, 316, 343], total units: 1458\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8368337154388428 - val_accuracy: 0.7025 - penalty: 1e-06\n",
            "hidden layer sizes: [189, 48, 87, 139, 185, 258, 287], total units: 1193\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8368337154388428 - val_accuracy: 0.7025 - penalty: 1e-06\n",
            "hidden layer sizes: [189, 48, 87, 139, 185, 258, 287], total units: 1193\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8368335962295532 - val_accuracy: 0.7025 - penalty: 1e-06\n",
            "hidden layer sizes: [226, 68, 107, 166, 222, 309, 344], total units: 1442\n",
            "Before pruning:\n",
            "loss: 0.9240742921829224 - accuracy: 0.67162 - val_loss: 0.8032433390617371 - val_accuracy: 0.7169 - penalty: 1e-06\n",
            "hidden layer sizes: [226, 68, 107, 166, 222, 309, 344], total units: 1442\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.803183376789093 - val_accuracy: 0.7171 - penalty: 1e-06\n",
            "hidden layer sizes: [186, 46, 76, 128, 185, 262, 267], total units: 1150\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.803183376789093 - val_accuracy: 0.7171 - penalty: 1e-06\n",
            "hidden layer sizes: [186, 46, 76, 128, 185, 262, 267], total units: 1150\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.803183376789093 - val_accuracy: 0.7171 - penalty: 1e-06\n",
            "hidden layer sizes: [223, 66, 96, 153, 222, 314, 320], total units: 1394\n",
            "Before pruning:\n",
            "loss: 0.9034700989723206 - accuracy: 0.67804 - val_loss: 0.7776550650596619 - val_accuracy: 0.7242 - penalty: 1e-06\n",
            "hidden layer sizes: [223, 66, 96, 153, 222, 314, 320], total units: 1394\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7774673104286194 - val_accuracy: 0.7244 - penalty: 1e-06\n",
            "hidden layer sizes: [180, 42, 75, 118, 185, 264, 278], total units: 1142\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7774673104286194 - val_accuracy: 0.7244 - penalty: 1e-06\n",
            "hidden layer sizes: [180, 42, 75, 118, 185, 264, 278], total units: 1142\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7774673104286194 - val_accuracy: 0.7244 - penalty: 1e-06\n",
            "hidden layer sizes: [216, 62, 95, 141, 222, 316, 333], total units: 1385\n",
            "Before pruning:\n",
            "loss: 0.8772387504577637 - accuracy: 0.68804 - val_loss: 0.7489398717880249 - val_accuracy: 0.7386 - penalty: 1e-06\n",
            "hidden layer sizes: [216, 62, 95, 141, 222, 316, 333], total units: 1385\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7489501237869263 - val_accuracy: 0.7387 - penalty: 1e-06\n",
            "hidden layer sizes: [177, 41, 70, 118, 182, 259, 282], total units: 1129\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7489501237869263 - val_accuracy: 0.7387 - penalty: 1e-06\n",
            "hidden layer sizes: [177, 41, 70, 118, 182, 259, 282], total units: 1129\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7489501237869263 - val_accuracy: 0.7387 - penalty: 1e-06\n",
            "hidden layer sizes: [212, 61, 90, 141, 218, 310, 338], total units: 1370\n",
            "Before pruning:\n",
            "loss: 0.8636115789413452 - accuracy: 0.6946 - val_loss: 0.7495485544204712 - val_accuracy: 0.7355 - penalty: 1e-06\n",
            "hidden layer sizes: [212, 61, 90, 141, 218, 310, 338], total units: 1370\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.749462366104126 - val_accuracy: 0.7358 - penalty: 1e-06\n",
            "hidden layer sizes: [174, 41, 63, 114, 180, 257, 267], total units: 1096\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.749462366104126 - val_accuracy: 0.7358 - penalty: 1e-06\n",
            "hidden layer sizes: [174, 41, 63, 114, 180, 257, 267], total units: 1096\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.749462366104126 - val_accuracy: 0.7358 - penalty: 1e-06\n",
            "hidden layer sizes: [208, 61, 83, 136, 216, 308, 320], total units: 1332\n",
            "Before pruning:\n",
            "loss: 0.8472725749015808 - accuracy: 0.69908 - val_loss: 0.7357000112533569 - val_accuracy: 0.7389 - penalty: 1e-06\n",
            "hidden layer sizes: [208, 61, 83, 136, 216, 308, 320], total units: 1332\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7356984615325928 - val_accuracy: 0.7389 - penalty: 1e-06\n",
            "hidden layer sizes: [168, 38, 61, 110, 179, 260, 272], total units: 1088\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7356984615325928 - val_accuracy: 0.7389 - penalty: 1e-06\n",
            "hidden layer sizes: [168, 38, 61, 110, 179, 260, 272], total units: 1088\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7356985211372375 - val_accuracy: 0.7389 - penalty: 1e-06\n",
            "hidden layer sizes: [201, 58, 81, 132, 214, 312, 326], total units: 1324\n",
            "Before pruning:\n",
            "loss: 0.8326897025108337 - accuracy: 0.70398 - val_loss: 0.7290319204330444 - val_accuracy: 0.7409 - penalty: 1e-06\n",
            "hidden layer sizes: [201, 58, 81, 132, 214, 312, 326], total units: 1324\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7290802001953125 - val_accuracy: 0.741 - penalty: 1e-06\n",
            "hidden layer sizes: [160, 35, 73, 111, 179, 260, 283], total units: 1101\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7290802001953125 - val_accuracy: 0.741 - penalty: 1e-06\n",
            "hidden layer sizes: [160, 35, 73, 111, 179, 260, 283], total units: 1101\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7290802001953125 - val_accuracy: 0.741 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 55, 93, 133, 214, 312, 339], total units: 1338\n",
            "Before pruning:\n",
            "loss: 0.8206173181533813 - accuracy: 0.7088 - val_loss: 0.7184113264083862 - val_accuracy: 0.7458 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 55, 93, 133, 214, 312, 339], total units: 1338\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7183603644371033 - val_accuracy: 0.746 - penalty: 1e-06\n",
            "hidden layer sizes: [150, 35, 60, 110, 177, 260, 286], total units: 1078\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7183603644371033 - val_accuracy: 0.746 - penalty: 1e-06\n",
            "hidden layer sizes: [150, 35, 60, 110, 177, 260, 286], total units: 1078\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7183603644371033 - val_accuracy: 0.746 - penalty: 1e-06\n",
            "hidden layer sizes: [180, 55, 80, 132, 212, 312, 343], total units: 1314\n",
            "Before pruning:\n",
            "loss: 0.8056330680847168 - accuracy: 0.71256 - val_loss: 0.7085071206092834 - val_accuracy: 0.7483 - penalty: 1e-06\n",
            "hidden layer sizes: [180, 55, 80, 132, 212, 312, 343], total units: 1314\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7085568308830261 - val_accuracy: 0.7484 - penalty: 1e-06\n",
            "hidden layer sizes: [146, 36, 60, 108, 176, 256, 273], total units: 1055\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7085568308830261 - val_accuracy: 0.7484 - penalty: 1e-06\n",
            "hidden layer sizes: [146, 36, 60, 108, 176, 256, 273], total units: 1055\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7085567116737366 - val_accuracy: 0.7484 - penalty: 1e-06\n",
            "hidden layer sizes: [175, 56, 80, 129, 211, 307, 327], total units: 1285\n",
            "Before pruning:\n",
            "loss: 0.8015623688697815 - accuracy: 0.71304 - val_loss: 0.6991947293281555 - val_accuracy: 0.7521 - penalty: 1e-06\n",
            "hidden layer sizes: [175, 56, 80, 129, 211, 307, 327], total units: 1285\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.6991751194000244 - val_accuracy: 0.7523 - penalty: 1e-06\n",
            "hidden layer sizes: [141, 33, 58, 110, 174, 259, 279], total units: 1054\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.34114,\n",
              "  0.42356,\n",
              "  0.49296,\n",
              "  0.52344,\n",
              "  0.56212,\n",
              "  0.58804,\n",
              "  0.6061,\n",
              "  0.62636,\n",
              "  0.63776,\n",
              "  0.65238,\n",
              "  0.66166,\n",
              "  0.67162,\n",
              "  0.67804,\n",
              "  0.68804,\n",
              "  0.6946,\n",
              "  0.69908,\n",
              "  0.70398,\n",
              "  0.7088,\n",
              "  0.71256,\n",
              "  0.71304],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=2.0089962>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.6122588>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.409426>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3170058>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2247231>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1484946>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0888671>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0441266>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0132141>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9716943>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.94812405>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9240743>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9034701>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.87723875>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8636116>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8472726>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8326897>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8206173>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.80563307>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.80156237>],\n",
              " 'val_accuracy': [0.4687,\n",
              "  0.5246,\n",
              "  0.5684,\n",
              "  0.5884,\n",
              "  0.6187,\n",
              "  0.6429,\n",
              "  0.6588,\n",
              "  0.6747,\n",
              "  0.6921,\n",
              "  0.7027,\n",
              "  0.7025,\n",
              "  0.7171,\n",
              "  0.7244,\n",
              "  0.7387,\n",
              "  0.7358,\n",
              "  0.7389,\n",
              "  0.741,\n",
              "  0.746,\n",
              "  0.7484,\n",
              "  0.7523],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.4994171>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3126733>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1963536>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1368312>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0698719>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.99982053>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9617175>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.90983427>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8689794>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.83365566>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8368337>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8031834>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7774673>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7489501>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.74946237>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.73569846>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7290802>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.71836036>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.70855683>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6991751>]}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSZZ2dUyZHCS"
      },
      "source": [
        "epochs = 15\n",
        "self_scaling_epochs = 5\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIQQanw_ZJWc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2064462c-4dbe-45a8-833d-1c841bc26e36"
      },
      "source": [
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/15\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.6991751194000244 - val_accuracy: 0.7523 - penalty: 1e-06\n",
            "hidden layer sizes: [141, 33, 58, 110, 174, 259, 279], total units: 1054\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.699175238609314 - val_accuracy: 0.7523 - penalty: 1e-06\n",
            "hidden layer sizes: [169, 53, 78, 132, 208, 310, 334], total units: 1284\n",
            "Before pruning:\n",
            "loss: 0.7891672849655151 - accuracy: 0.72078 - val_loss: 0.6832705736160278 - val_accuracy: 0.7585 - penalty: 1e-06\n",
            "hidden layer sizes: [169, 53, 78, 132, 208, 310, 334], total units: 1284\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.6832776069641113 - val_accuracy: 0.7585 - penalty: 1e-06\n",
            "hidden layer sizes: [137, 33, 59, 104, 172, 259, 277], total units: 1041\n",
            "##########################################################\n",
            "Epoch 2/15\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.6832776069641113 - val_accuracy: 0.7585 - penalty: 1e-06\n",
            "hidden layer sizes: [137, 33, 59, 104, 172, 259, 277], total units: 1041\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.6832776069641113 - val_accuracy: 0.7585 - penalty: 1e-06\n",
            "hidden layer sizes: [164, 53, 79, 124, 206, 310, 332], total units: 1268\n",
            "Before pruning:\n",
            "loss: 0.7766771912574768 - accuracy: 0.7243 - val_loss: 0.6783956289291382 - val_accuracy: 0.7604 - penalty: 1e-06\n",
            "hidden layer sizes: [164, 53, 79, 124, 206, 310, 332], total units: 1268\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.6784159541130066 - val_accuracy: 0.7605 - penalty: 1e-06\n",
            "hidden layer sizes: [132, 40, 62, 106, 170, 264, 281], total units: 1055\n",
            "##########################################################\n",
            "Epoch 3/15\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.6784159541130066 - val_accuracy: 0.7605 - penalty: 1e-06\n",
            "hidden layer sizes: [132, 40, 62, 106, 170, 264, 281], total units: 1055\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.6784160733222961 - val_accuracy: 0.7605 - penalty: 1e-06\n",
            "hidden layer sizes: [158, 60, 82, 127, 204, 316, 337], total units: 1284\n",
            "Before pruning:\n",
            "loss: 0.7725674510002136 - accuracy: 0.72684 - val_loss: 0.6934359669685364 - val_accuracy: 0.7559 - penalty: 1e-06\n",
            "hidden layer sizes: [158, 60, 82, 127, 204, 316, 337], total units: 1284\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.6933403015136719 - val_accuracy: 0.7562 - penalty: 1e-06\n",
            "hidden layer sizes: [129, 30, 56, 103, 168, 257, 271], total units: 1014\n",
            "##########################################################\n",
            "Epoch 4/15\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.6933403015136719 - val_accuracy: 0.7562 - penalty: 1e-06\n",
            "hidden layer sizes: [129, 30, 56, 103, 168, 257, 271], total units: 1014\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.6933403015136719 - val_accuracy: 0.7562 - penalty: 1e-06\n",
            "hidden layer sizes: [154, 50, 76, 123, 201, 308, 325], total units: 1237\n",
            "Before pruning:\n",
            "loss: 0.7668255567550659 - accuracy: 0.72658 - val_loss: 0.6771217584609985 - val_accuracy: 0.7637 - penalty: 1e-06\n",
            "hidden layer sizes: [154, 50, 76, 123, 201, 308, 325], total units: 1237\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.6770637035369873 - val_accuracy: 0.7636 - penalty: 1e-06\n",
            "hidden layer sizes: [124, 32, 57, 113, 164, 257, 295], total units: 1042\n",
            "##########################################################\n",
            "Epoch 5/15\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.6770637035369873 - val_accuracy: 0.7636 - penalty: 1e-06\n",
            "hidden layer sizes: [124, 32, 57, 113, 164, 257, 295], total units: 1042\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.6770636439323425 - val_accuracy: 0.7636 - penalty: 1e-06\n",
            "hidden layer sizes: [148, 52, 77, 135, 196, 308, 354], total units: 1270\n",
            "Before pruning:\n",
            "loss: 0.759740948677063 - accuracy: 0.73046 - val_loss: 0.677257239818573 - val_accuracy: 0.7621 - penalty: 1e-06\n",
            "hidden layer sizes: [148, 52, 77, 135, 196, 308, 354], total units: 1270\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.6771854758262634 - val_accuracy: 0.7621 - penalty: 1e-06\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n",
            "##########################################################\n",
            "Epoch 6/15\n",
            "loss: 0.7706327438354492 - accuracy: 0.72782 - val_loss: 0.6531803011894226 - val_accuracy: 0.7702 - penalty: 0.0\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n",
            "##########################################################\n",
            "Epoch 7/15\n",
            "loss: 0.6665133833885193 - accuracy: 0.76208 - val_loss: 0.6348080039024353 - val_accuracy: 0.7746 - penalty: 0.0\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n",
            "##########################################################\n",
            "Epoch 8/15\n",
            "loss: 0.6215977668762207 - accuracy: 0.77934 - val_loss: 0.6211541295051575 - val_accuracy: 0.7833 - penalty: 0.0\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n",
            "##########################################################\n",
            "Epoch 9/15\n",
            "loss: 0.5899196267127991 - accuracy: 0.78992 - val_loss: 0.6109042763710022 - val_accuracy: 0.787 - penalty: 0.0\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n",
            "##########################################################\n",
            "Epoch 10/15\n",
            "loss: 0.5648033022880554 - accuracy: 0.79692 - val_loss: 0.6114565134048462 - val_accuracy: 0.785 - penalty: 0.0\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n",
            "##########################################################\n",
            "Epoch 11/15\n",
            "loss: 0.5411083102226257 - accuracy: 0.80594 - val_loss: 0.6017608046531677 - val_accuracy: 0.7917 - penalty: 0.0\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n",
            "##########################################################\n",
            "Epoch 12/15\n",
            "loss: 0.5241559147834778 - accuracy: 0.81288 - val_loss: 0.5970019102096558 - val_accuracy: 0.7926 - penalty: 0.0\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n",
            "##########################################################\n",
            "Epoch 13/15\n",
            "loss: 0.5056828260421753 - accuracy: 0.81928 - val_loss: 0.5944268107414246 - val_accuracy: 0.7944 - penalty: 0.0\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n",
            "##########################################################\n",
            "Epoch 14/15\n",
            "loss: 0.4884328842163086 - accuracy: 0.82528 - val_loss: 0.592613935470581 - val_accuracy: 0.7971 - penalty: 0.0\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n",
            "##########################################################\n",
            "Epoch 15/15\n",
            "loss: 0.4726400077342987 - accuracy: 0.82962 - val_loss: 0.5901088118553162 - val_accuracy: 0.7994 - penalty: 0.0\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.72078,\n",
              "  0.7243,\n",
              "  0.72684,\n",
              "  0.72658,\n",
              "  0.73046,\n",
              "  0.72782,\n",
              "  0.76208,\n",
              "  0.77934,\n",
              "  0.78992,\n",
              "  0.79692,\n",
              "  0.80594,\n",
              "  0.81288,\n",
              "  0.81928,\n",
              "  0.82528,\n",
              "  0.82962],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=0.7891673>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7766772>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.77256745>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.76682556>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.75974095>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.77063274>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6665134>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.62159777>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5899196>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5648033>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5411083>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5241559>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5056828>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.48843288>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.47264>],\n",
              " 'val_accuracy': [0.7585,\n",
              "  0.7605,\n",
              "  0.7562,\n",
              "  0.7636,\n",
              "  0.7621,\n",
              "  0.7702,\n",
              "  0.7746,\n",
              "  0.7833,\n",
              "  0.787,\n",
              "  0.785,\n",
              "  0.7917,\n",
              "  0.7926,\n",
              "  0.7944,\n",
              "  0.7971,\n",
              "  0.7994],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=0.6832776>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.67841595>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6933403>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6770637>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6771855>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6531803>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.634808>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6211541>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6109043>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6114565>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6017608>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5970019>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5944268>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.59261394>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5901088>]}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "If4nQnREaAFT"
      },
      "source": [
        "epochs = 5\n",
        "self_scaling_epochs = 0\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avuOu4GtaEdy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "844805d4-588a-489e-efbf-77c0bd302893"
      },
      "source": [
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/5\n",
            "loss: 0.4571080803871155 - accuracy: 0.8337 - val_loss: 0.5971691608428955 - val_accuracy: 0.7968 - penalty: 0.0\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n",
            "##########################################################\n",
            "Epoch 2/5\n",
            "loss: 0.44272705912590027 - accuracy: 0.83764 - val_loss: 0.5940378904342651 - val_accuracy: 0.7997 - penalty: 0.0\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n",
            "##########################################################\n",
            "Epoch 3/5\n",
            "loss: 0.4271366000175476 - accuracy: 0.84598 - val_loss: 0.5995334982872009 - val_accuracy: 0.7945 - penalty: 0.0\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n",
            "##########################################################\n",
            "Epoch 4/5\n",
            "loss: 0.4159424602985382 - accuracy: 0.84966 - val_loss: 0.5943306684494019 - val_accuracy: 0.798 - penalty: 0.0\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n",
            "##########################################################\n",
            "Epoch 5/5\n",
            "loss: 0.40201738476753235 - accuracy: 0.85598 - val_loss: 0.5975359082221985 - val_accuracy: 0.7967 - penalty: 0.0\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.8337, 0.83764, 0.84598, 0.84966, 0.85598],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=0.45710808>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.44272706>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.4271366>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.41594246>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.40201738>],\n",
              " 'val_accuracy': [0.7968, 0.7997, 0.7945, 0.798, 0.7967],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=0.59716916>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5940379>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5995335>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.59433067>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5975359>]}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xasW23EaV9M"
      },
      "source": [
        "epochs = 25\n",
        "self_scaling_epochs = 25\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQW7p9k4acEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "effcd6cb-9913-4fb7-e7eb-32c5c96a570e"
      },
      "source": [
        "model = Sequential([\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Dense(256, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Dense(256, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None, fixed_size=True),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.79923677444458 - val_accuracy: 0.1137 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 192, 192, 256, 256, 256], total units: 1920\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.799236297607422 - val_accuracy: 0.1137 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 230, 307, 307, 307], total units: 2301\n",
            "Before pruning:\n",
            "loss: 2.1290526390075684 - accuracy: 0.29672 - val_loss: 1.5416100025177002 - val_accuracy: 0.4397 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 230, 307, 307, 307], total units: 2301\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.541624665260315 - val_accuracy: 0.4397 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 192, 192, 256, 256, 307], total units: 1971\n",
            "##########################################################\n",
            "Epoch 2/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.541624665260315 - val_accuracy: 0.4397 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 192, 192, 256, 256, 307], total units: 1971\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.541624665260315 - val_accuracy: 0.4397 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 230, 307, 307, 368], total units: 2362\n",
            "Before pruning:\n",
            "loss: 1.7051478624343872 - accuracy: 0.38644 - val_loss: 1.3967374563217163 - val_accuracy: 0.4933 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 230, 307, 307, 368], total units: 2362\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.3967136144638062 - val_accuracy: 0.4932 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 192, 192, 256, 256, 286], total units: 1950\n",
            "##########################################################\n",
            "Epoch 3/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.3967136144638062 - val_accuracy: 0.4932 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 192, 192, 256, 256, 286], total units: 1950\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.3967136144638062 - val_accuracy: 0.4932 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 230, 307, 307, 343], total units: 2337\n",
            "Before pruning:\n",
            "loss: 1.5092018842697144 - accuracy: 0.45368 - val_loss: 1.260297417640686 - val_accuracy: 0.5449 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 230, 307, 307, 343], total units: 2337\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.2603567838668823 - val_accuracy: 0.5448 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 192, 192, 256, 256, 256], total units: 1920\n",
            "##########################################################\n",
            "Epoch 4/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2603567838668823 - val_accuracy: 0.5448 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 192, 192, 256, 256, 256], total units: 1920\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2603567838668823 - val_accuracy: 0.5448 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 230, 307, 307, 307], total units: 2301\n",
            "Before pruning:\n",
            "loss: 1.3749382495880127 - accuracy: 0.50138 - val_loss: 1.1972721815109253 - val_accuracy: 0.5648 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 230, 307, 307, 307], total units: 2301\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1960912942886353 - val_accuracy: 0.565 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 164, 157, 191, 192, 192, 256, 256, 257], total units: 1857\n",
            "##########################################################\n",
            "Epoch 5/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1960912942886353 - val_accuracy: 0.565 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 164, 157, 191, 192, 192, 256, 256, 257], total units: 1857\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1960911750793457 - val_accuracy: 0.565 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 196, 188, 229, 230, 230, 307, 307, 308], total units: 2225\n",
            "Before pruning:\n",
            "loss: 1.276135802268982 - accuracy: 0.53902 - val_loss: 1.089812994003296 - val_accuracy: 0.6017 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 196, 188, 229, 230, 230, 307, 307, 308], total units: 2225\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0896503925323486 - val_accuracy: 0.6018 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 107, 131, 186, 192, 192, 256, 256, 261], total units: 1773\n",
            "##########################################################\n",
            "Epoch 6/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0896503925323486 - val_accuracy: 0.6018 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 107, 131, 186, 192, 192, 256, 256, 261], total units: 1773\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0896501541137695 - val_accuracy: 0.6018 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 128, 157, 223, 230, 230, 307, 307, 313], total units: 2125\n",
            "Before pruning:\n",
            "loss: 1.1796029806137085 - accuracy: 0.57974 - val_loss: 1.0209232568740845 - val_accuracy: 0.6357 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 128, 157, 223, 230, 230, 307, 307, 313], total units: 2125\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0206140279769897 - val_accuracy: 0.6363 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 88, 116, 175, 184, 192, 256, 256, 258], total units: 1717\n",
            "##########################################################\n",
            "Epoch 7/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0206140279769897 - val_accuracy: 0.6363 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 88, 116, 175, 184, 192, 256, 256, 258], total units: 1717\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0206140279769897 - val_accuracy: 0.6363 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 108, 139, 210, 220, 230, 307, 307, 309], total units: 2060\n",
            "Before pruning:\n",
            "loss: 1.10708749294281 - accuracy: 0.60538 - val_loss: 0.9520258903503418 - val_accuracy: 0.6628 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 108, 139, 210, 220, 230, 307, 307, 309], total units: 2060\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9518150687217712 - val_accuracy: 0.6631 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 69, 105, 173, 166, 191, 256, 256, 256], total units: 1664\n",
            "##########################################################\n",
            "Epoch 8/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9518150687217712 - val_accuracy: 0.6631 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 69, 105, 173, 166, 191, 256, 256, 256], total units: 1664\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9518150687217712 - val_accuracy: 0.6631 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 89, 126, 207, 199, 229, 307, 307, 307], total units: 2001\n",
            "Before pruning:\n",
            "loss: 1.0561540126800537 - accuracy: 0.6235 - val_loss: 0.9148663878440857 - val_accuracy: 0.6802 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 89, 126, 207, 199, 229, 307, 307, 307], total units: 2001\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9148054718971252 - val_accuracy: 0.6802 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 69, 90, 164, 145, 191, 256, 256, 256], total units: 1618\n",
            "##########################################################\n",
            "Epoch 9/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9148054718971252 - val_accuracy: 0.6802 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 69, 90, 164, 145, 191, 256, 256, 256], total units: 1618\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9148053526878357 - val_accuracy: 0.6802 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 89, 110, 196, 174, 229, 307, 307, 307], total units: 1948\n",
            "Before pruning:\n",
            "loss: 1.0170271396636963 - accuracy: 0.6395 - val_loss: 0.879567563533783 - val_accuracy: 0.6913 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 89, 110, 196, 174, 229, 307, 307, 307], total units: 1948\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8795211911201477 - val_accuracy: 0.6912 - penalty: 1e-06\n",
            "hidden layer sizes: [189, 59, 86, 155, 130, 188, 256, 256, 257], total units: 1576\n",
            "##########################################################\n",
            "Epoch 10/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8795211911201477 - val_accuracy: 0.6912 - penalty: 1e-06\n",
            "hidden layer sizes: [189, 59, 86, 155, 130, 188, 256, 256, 257], total units: 1576\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8795211911201477 - val_accuracy: 0.6912 - penalty: 1e-06\n",
            "hidden layer sizes: [226, 79, 106, 186, 156, 225, 307, 307, 308], total units: 1900\n",
            "Before pruning:\n",
            "loss: 0.983442485332489 - accuracy: 0.65214 - val_loss: 0.8580209016799927 - val_accuracy: 0.6959 - penalty: 1e-06\n",
            "hidden layer sizes: [226, 79, 106, 186, 156, 225, 307, 307, 308], total units: 1900\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8579892516136169 - val_accuracy: 0.6958 - penalty: 1e-06\n",
            "hidden layer sizes: [187, 55, 78, 150, 125, 185, 256, 256, 273], total units: 1565\n",
            "##########################################################\n",
            "Epoch 11/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8579892516136169 - val_accuracy: 0.6958 - penalty: 1e-06\n",
            "hidden layer sizes: [187, 55, 78, 150, 125, 185, 256, 256, 273], total units: 1565\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8579890727996826 - val_accuracy: 0.6958 - penalty: 1e-06\n",
            "hidden layer sizes: [224, 75, 98, 180, 150, 222, 307, 307, 327], total units: 1890\n",
            "Before pruning:\n",
            "loss: 0.9523352384567261 - accuracy: 0.6635 - val_loss: 0.8428192138671875 - val_accuracy: 0.7033 - penalty: 1e-06\n",
            "hidden layer sizes: [224, 75, 98, 180, 150, 222, 307, 307, 327], total units: 1890\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8427272439002991 - val_accuracy: 0.703 - penalty: 1e-06\n",
            "hidden layer sizes: [178, 55, 74, 150, 119, 183, 256, 256, 268], total units: 1539\n",
            "##########################################################\n",
            "Epoch 12/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8427272439002991 - val_accuracy: 0.703 - penalty: 1e-06\n",
            "hidden layer sizes: [178, 55, 74, 150, 119, 183, 256, 256, 268], total units: 1539\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8427272439002991 - val_accuracy: 0.703 - penalty: 1e-06\n",
            "hidden layer sizes: [213, 75, 94, 180, 142, 219, 307, 307, 321], total units: 1858\n",
            "Before pruning:\n",
            "loss: 0.9347068667411804 - accuracy: 0.66914 - val_loss: 0.8179975748062134 - val_accuracy: 0.7125 - penalty: 1e-06\n",
            "hidden layer sizes: [213, 75, 94, 180, 142, 219, 307, 307, 321], total units: 1858\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8179476857185364 - val_accuracy: 0.7124 - penalty: 1e-06\n",
            "hidden layer sizes: [172, 52, 67, 145, 106, 174, 255, 255, 255], total units: 1481\n",
            "##########################################################\n",
            "Epoch 13/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8179476857185364 - val_accuracy: 0.7124 - penalty: 1e-06\n",
            "hidden layer sizes: [172, 52, 67, 145, 106, 174, 255, 255, 255], total units: 1481\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8179476857185364 - val_accuracy: 0.7124 - penalty: 1e-06\n",
            "hidden layer sizes: [206, 72, 87, 174, 127, 208, 306, 306, 306], total units: 1792\n",
            "Before pruning:\n",
            "loss: 0.9060376286506653 - accuracy: 0.68018 - val_loss: 0.8045517802238464 - val_accuracy: 0.715 - penalty: 1e-06\n",
            "hidden layer sizes: [206, 72, 87, 174, 127, 208, 306, 306, 306], total units: 1792\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8044756054878235 - val_accuracy: 0.7149 - penalty: 1e-06\n",
            "hidden layer sizes: [166, 48, 67, 140, 100, 170, 248, 254, 257], total units: 1450\n",
            "##########################################################\n",
            "Epoch 14/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8044756054878235 - val_accuracy: 0.7149 - penalty: 1e-06\n",
            "hidden layer sizes: [166, 48, 67, 140, 100, 170, 248, 254, 257], total units: 1450\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8044756054878235 - val_accuracy: 0.7149 - penalty: 1e-06\n",
            "hidden layer sizes: [199, 68, 87, 168, 120, 204, 297, 304, 308], total units: 1755\n",
            "Before pruning:\n",
            "loss: 0.8920026421546936 - accuracy: 0.68618 - val_loss: 0.8184489607810974 - val_accuracy: 0.7113 - penalty: 1e-06\n",
            "hidden layer sizes: [199, 68, 87, 168, 120, 204, 297, 304, 308], total units: 1755\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8182895183563232 - val_accuracy: 0.7113 - penalty: 1e-06\n",
            "hidden layer sizes: [163, 45, 62, 139, 91, 169, 235, 252, 254], total units: 1410\n",
            "##########################################################\n",
            "Epoch 15/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8182895183563232 - val_accuracy: 0.7113 - penalty: 1e-06\n",
            "hidden layer sizes: [163, 45, 62, 139, 91, 169, 235, 252, 254], total units: 1410\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8182895183563232 - val_accuracy: 0.7113 - penalty: 1e-06\n",
            "hidden layer sizes: [195, 65, 82, 166, 111, 202, 282, 302, 304], total units: 1709\n",
            "Before pruning:\n",
            "loss: 0.8783363103866577 - accuracy: 0.69182 - val_loss: 0.7755981087684631 - val_accuracy: 0.726 - penalty: 1e-06\n",
            "hidden layer sizes: [195, 65, 82, 166, 111, 202, 282, 302, 304], total units: 1709\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7755541801452637 - val_accuracy: 0.7263 - penalty: 1e-06\n",
            "hidden layer sizes: [156, 44, 57, 139, 84, 161, 225, 245, 253], total units: 1364\n",
            "##########################################################\n",
            "Epoch 16/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7755541801452637 - val_accuracy: 0.7263 - penalty: 1e-06\n",
            "hidden layer sizes: [156, 44, 57, 139, 84, 161, 225, 245, 253], total units: 1364\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7755542993545532 - val_accuracy: 0.7263 - penalty: 1e-06\n",
            "hidden layer sizes: [187, 64, 77, 166, 104, 193, 270, 294, 303], total units: 1658\n",
            "Before pruning:\n",
            "loss: 0.8595612645149231 - accuracy: 0.69772 - val_loss: 0.7878279685974121 - val_accuracy: 0.7189 - penalty: 1e-06\n",
            "hidden layer sizes: [187, 64, 77, 166, 104, 193, 270, 294, 303], total units: 1658\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7878957986831665 - val_accuracy: 0.7189 - penalty: 1e-06\n",
            "hidden layer sizes: [150, 43, 57, 136, 88, 158, 215, 241, 258], total units: 1346\n",
            "##########################################################\n",
            "Epoch 17/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7878957986831665 - val_accuracy: 0.7189 - penalty: 1e-06\n",
            "hidden layer sizes: [150, 43, 57, 136, 88, 158, 215, 241, 258], total units: 1346\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7878957986831665 - val_accuracy: 0.7189 - penalty: 1e-06\n",
            "hidden layer sizes: [180, 63, 77, 163, 108, 189, 258, 289, 309], total units: 1636\n",
            "Before pruning:\n",
            "loss: 0.8419432044029236 - accuracy: 0.70522 - val_loss: 0.7699435949325562 - val_accuracy: 0.728 - penalty: 1e-06\n",
            "hidden layer sizes: [180, 63, 77, 163, 108, 189, 258, 289, 309], total units: 1636\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7699012160301208 - val_accuracy: 0.7284 - penalty: 1e-06\n",
            "hidden layer sizes: [151, 44, 54, 138, 93, 153, 205, 235, 275], total units: 1348\n",
            "##########################################################\n",
            "Epoch 18/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7699012160301208 - val_accuracy: 0.7284 - penalty: 1e-06\n",
            "hidden layer sizes: [151, 44, 54, 138, 93, 153, 205, 235, 275], total units: 1348\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7699012160301208 - val_accuracy: 0.7284 - penalty: 1e-06\n",
            "hidden layer sizes: [181, 64, 74, 165, 113, 183, 246, 282, 330], total units: 1638\n",
            "Before pruning:\n",
            "loss: 0.8274267911911011 - accuracy: 0.71006 - val_loss: 0.7582378387451172 - val_accuracy: 0.7332 - penalty: 1e-06\n",
            "hidden layer sizes: [181, 64, 74, 165, 113, 183, 246, 282, 330], total units: 1638\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7580767869949341 - val_accuracy: 0.7331 - penalty: 1e-06\n",
            "hidden layer sizes: [147, 43, 54, 136, 83, 150, 189, 228, 254], total units: 1284\n",
            "##########################################################\n",
            "Epoch 19/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7580767869949341 - val_accuracy: 0.7331 - penalty: 1e-06\n",
            "hidden layer sizes: [147, 43, 54, 136, 83, 150, 189, 228, 254], total units: 1284\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7580766677856445 - val_accuracy: 0.7331 - penalty: 1e-06\n",
            "hidden layer sizes: [176, 63, 74, 163, 103, 180, 226, 273, 304], total units: 1562\n",
            "Before pruning:\n",
            "loss: 0.8212050199508667 - accuracy: 0.71036 - val_loss: 0.7405781745910645 - val_accuracy: 0.7369 - penalty: 1e-06\n",
            "hidden layer sizes: [176, 63, 74, 163, 103, 180, 226, 273, 304], total units: 1562\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.740613579750061 - val_accuracy: 0.7367 - penalty: 1e-06\n",
            "hidden layer sizes: [143, 41, 57, 133, 78, 147, 180, 221, 250], total units: 1250\n",
            "##########################################################\n",
            "Epoch 20/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.740613579750061 - val_accuracy: 0.7367 - penalty: 1e-06\n",
            "hidden layer sizes: [143, 41, 57, 133, 78, 147, 180, 221, 250], total units: 1250\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.740613579750061 - val_accuracy: 0.7367 - penalty: 1e-06\n",
            "hidden layer sizes: [171, 61, 77, 159, 98, 176, 216, 265, 300], total units: 1523\n",
            "Before pruning:\n",
            "loss: 0.8128229975700378 - accuracy: 0.71452 - val_loss: 0.736884355545044 - val_accuracy: 0.7407 - penalty: 1e-06\n",
            "hidden layer sizes: [171, 61, 77, 159, 98, 176, 216, 265, 300], total units: 1523\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7368226647377014 - val_accuracy: 0.7409 - penalty: 1e-06\n",
            "hidden layer sizes: [140, 38, 54, 132, 82, 146, 174, 218, 219], total units: 1203\n",
            "##########################################################\n",
            "Epoch 21/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7368226647377014 - val_accuracy: 0.7409 - penalty: 1e-06\n",
            "hidden layer sizes: [140, 38, 54, 132, 82, 146, 174, 218, 219], total units: 1203\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7368226647377014 - val_accuracy: 0.7409 - penalty: 1e-06\n",
            "hidden layer sizes: [168, 58, 74, 158, 102, 175, 208, 261, 262], total units: 1466\n",
            "Before pruning:\n",
            "loss: 0.7998989224433899 - accuracy: 0.7186 - val_loss: 0.7281237840652466 - val_accuracy: 0.7442 - penalty: 1e-06\n",
            "hidden layer sizes: [168, 58, 74, 158, 102, 175, 208, 261, 262], total units: 1466\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7280671000480652 - val_accuracy: 0.7443 - penalty: 1e-06\n",
            "hidden layer sizes: [136, 38, 54, 129, 84, 142, 163, 209, 218], total units: 1173\n",
            "##########################################################\n",
            "Epoch 22/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7280671000480652 - val_accuracy: 0.7443 - penalty: 1e-06\n",
            "hidden layer sizes: [136, 38, 54, 129, 84, 142, 163, 209, 218], total units: 1173\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.72806715965271 - val_accuracy: 0.7443 - penalty: 1e-06\n",
            "hidden layer sizes: [163, 58, 74, 154, 104, 170, 195, 250, 261], total units: 1429\n",
            "Before pruning:\n",
            "loss: 0.7958008646965027 - accuracy: 0.72298 - val_loss: 0.7224709987640381 - val_accuracy: 0.75 - penalty: 1e-06\n",
            "hidden layer sizes: [163, 58, 74, 154, 104, 170, 195, 250, 261], total units: 1429\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7224716544151306 - val_accuracy: 0.7501 - penalty: 1e-06\n",
            "hidden layer sizes: [137, 42, 49, 136, 85, 142, 157, 203, 202], total units: 1153\n",
            "##########################################################\n",
            "Epoch 23/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7224716544151306 - val_accuracy: 0.7501 - penalty: 1e-06\n",
            "hidden layer sizes: [137, 42, 49, 136, 85, 142, 157, 203, 202], total units: 1153\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7224716544151306 - val_accuracy: 0.7501 - penalty: 1e-06\n",
            "hidden layer sizes: [164, 62, 69, 163, 105, 170, 188, 243, 242], total units: 1406\n",
            "Before pruning:\n",
            "loss: 0.7834238409996033 - accuracy: 0.72524 - val_loss: 0.7227911949157715 - val_accuracy: 0.7468 - penalty: 1e-06\n",
            "hidden layer sizes: [164, 62, 69, 163, 105, 170, 188, 243, 242], total units: 1406\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7227593064308167 - val_accuracy: 0.7469 - penalty: 1e-06\n",
            "hidden layer sizes: [131, 39, 50, 133, 81, 139, 156, 193, 229], total units: 1151\n",
            "##########################################################\n",
            "Epoch 24/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7227593064308167 - val_accuracy: 0.7469 - penalty: 1e-06\n",
            "hidden layer sizes: [131, 39, 50, 133, 81, 139, 156, 193, 229], total units: 1151\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7227591872215271 - val_accuracy: 0.7469 - penalty: 1e-06\n",
            "hidden layer sizes: [157, 59, 70, 159, 101, 166, 187, 231, 274], total units: 1404\n",
            "Before pruning:\n",
            "loss: 0.782342791557312 - accuracy: 0.7285 - val_loss: 0.7364693880081177 - val_accuracy: 0.7409 - penalty: 1e-06\n",
            "hidden layer sizes: [157, 59, 70, 159, 101, 166, 187, 231, 274], total units: 1404\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7363388538360596 - val_accuracy: 0.7409 - penalty: 1e-06\n",
            "hidden layer sizes: [126, 43, 48, 132, 78, 135, 153, 186, 210], total units: 1111\n",
            "##########################################################\n",
            "Epoch 25/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7363388538360596 - val_accuracy: 0.7409 - penalty: 1e-06\n",
            "hidden layer sizes: [126, 43, 48, 132, 78, 135, 153, 186, 210], total units: 1111\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7363388538360596 - val_accuracy: 0.7409 - penalty: 1e-06\n",
            "hidden layer sizes: [151, 63, 68, 158, 98, 162, 183, 223, 252], total units: 1358\n",
            "Before pruning:\n",
            "loss: 0.7712135910987854 - accuracy: 0.7303 - val_loss: 0.7229657769203186 - val_accuracy: 0.7482 - penalty: 1e-06\n",
            "hidden layer sizes: [151, 63, 68, 158, 98, 162, 183, 223, 252], total units: 1358\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7230144739151001 - val_accuracy: 0.7481 - penalty: 1e-06\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.29672,\n",
              "  0.38644,\n",
              "  0.45368,\n",
              "  0.50138,\n",
              "  0.53902,\n",
              "  0.57974,\n",
              "  0.60538,\n",
              "  0.6235,\n",
              "  0.6395,\n",
              "  0.65214,\n",
              "  0.6635,\n",
              "  0.66914,\n",
              "  0.68018,\n",
              "  0.68618,\n",
              "  0.69182,\n",
              "  0.69772,\n",
              "  0.70522,\n",
              "  0.71006,\n",
              "  0.71036,\n",
              "  0.71452,\n",
              "  0.7186,\n",
              "  0.72298,\n",
              "  0.72524,\n",
              "  0.7285,\n",
              "  0.7303],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=2.1290526>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.7051479>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.5092019>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3749382>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2761358>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.179603>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1070875>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.056154>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0170271>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9834425>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.95233524>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.93470687>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9060376>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.89200264>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8783363>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.85956126>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8419432>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8274268>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.821205>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.812823>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7998989>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.79580086>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.78342384>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7823428>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7712136>],\n",
              " 'val_accuracy': [0.4397,\n",
              "  0.4932,\n",
              "  0.5448,\n",
              "  0.565,\n",
              "  0.6018,\n",
              "  0.6363,\n",
              "  0.6631,\n",
              "  0.6802,\n",
              "  0.6912,\n",
              "  0.6958,\n",
              "  0.703,\n",
              "  0.7124,\n",
              "  0.7149,\n",
              "  0.7113,\n",
              "  0.7263,\n",
              "  0.7189,\n",
              "  0.7284,\n",
              "  0.7331,\n",
              "  0.7367,\n",
              "  0.7409,\n",
              "  0.7443,\n",
              "  0.7501,\n",
              "  0.7469,\n",
              "  0.7409,\n",
              "  0.7481],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.5416247>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3967136>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2603568>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1960913>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0896504>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.020614>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.95181507>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9148055>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8795212>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.85798925>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.84272724>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8179477>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8044756>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8182895>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7755542>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7878958>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7699012>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7580768>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7406136>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.73682266>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7280671>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.72247165>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7227593>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.73633885>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7230145>]}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVkEe121cwF-"
      },
      "source": [
        "epochs = 15\n",
        "self_scaling_epochs = 0\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXSU9LIvc0u4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7df21407-e1df-43c6-cfeb-5ca06a0dc2e1"
      },
      "source": [
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/15\n",
            "loss: 0.7808060646057129 - accuracy: 0.72632 - val_loss: 0.7153555750846863 - val_accuracy: 0.7517 - penalty: 0.0\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n",
            "##########################################################\n",
            "Epoch 2/15\n",
            "loss: 0.6949461102485657 - accuracy: 0.75636 - val_loss: 0.6902822256088257 - val_accuracy: 0.7567 - penalty: 0.0\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n",
            "##########################################################\n",
            "Epoch 3/15\n",
            "loss: 0.6561957597732544 - accuracy: 0.7704 - val_loss: 0.6762971878051758 - val_accuracy: 0.7636 - penalty: 0.0\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n",
            "##########################################################\n",
            "Epoch 4/15\n",
            "loss: 0.63089519739151 - accuracy: 0.78064 - val_loss: 0.6755340695381165 - val_accuracy: 0.7644 - penalty: 0.0\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n",
            "##########################################################\n",
            "Epoch 5/15\n",
            "loss: 0.6106624007225037 - accuracy: 0.78576 - val_loss: 0.6762180924415588 - val_accuracy: 0.766 - penalty: 0.0\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n",
            "##########################################################\n",
            "Epoch 6/15\n",
            "loss: 0.5878487229347229 - accuracy: 0.79436 - val_loss: 0.676163911819458 - val_accuracy: 0.7659 - penalty: 0.0\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n",
            "##########################################################\n",
            "Epoch 7/15\n",
            "loss: 0.5761703252792358 - accuracy: 0.79672 - val_loss: 0.6725249290466309 - val_accuracy: 0.7706 - penalty: 0.0\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n",
            "##########################################################\n",
            "Epoch 8/15\n",
            "loss: 0.5563377141952515 - accuracy: 0.80472 - val_loss: 0.6783761978149414 - val_accuracy: 0.7677 - penalty: 0.0\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n",
            "##########################################################\n",
            "Epoch 9/15\n",
            "loss: 0.5414478182792664 - accuracy: 0.81134 - val_loss: 0.6776442527770996 - val_accuracy: 0.7716 - penalty: 0.0\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n",
            "##########################################################\n",
            "Epoch 10/15\n",
            "loss: 0.532252311706543 - accuracy: 0.8133 - val_loss: 0.6709115505218506 - val_accuracy: 0.7726 - penalty: 0.0\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n",
            "##########################################################\n",
            "Epoch 11/15\n",
            "loss: 0.5087337493896484 - accuracy: 0.82136 - val_loss: 0.6741521954536438 - val_accuracy: 0.7707 - penalty: 0.0\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n",
            "##########################################################\n",
            "Epoch 12/15\n",
            "loss: 0.49994316697120667 - accuracy: 0.82398 - val_loss: 0.6821077466011047 - val_accuracy: 0.7748 - penalty: 0.0\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n",
            "##########################################################\n",
            "Epoch 13/15\n",
            "loss: 0.4876604378223419 - accuracy: 0.82932 - val_loss: 0.6888116002082825 - val_accuracy: 0.7735 - penalty: 0.0\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n",
            "##########################################################\n",
            "Epoch 14/15\n",
            "loss: 0.47158288955688477 - accuracy: 0.83464 - val_loss: 0.6917790174484253 - val_accuracy: 0.7754 - penalty: 0.0\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n",
            "##########################################################\n",
            "Epoch 15/15\n",
            "loss: 0.463847279548645 - accuracy: 0.83678 - val_loss: 0.6907138228416443 - val_accuracy: 0.772 - penalty: 0.0\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.72632,\n",
              "  0.75636,\n",
              "  0.7704,\n",
              "  0.78064,\n",
              "  0.78576,\n",
              "  0.79436,\n",
              "  0.79672,\n",
              "  0.80472,\n",
              "  0.81134,\n",
              "  0.8133,\n",
              "  0.82136,\n",
              "  0.82398,\n",
              "  0.82932,\n",
              "  0.83464,\n",
              "  0.83678],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=0.78080606>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6949461>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.65619576>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6308952>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6106624>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5878487>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5761703>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5563377>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5414478>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5322523>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.50873375>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.49994317>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.48766044>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.4715829>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.46384728>],\n",
              " 'val_accuracy': [0.7517,\n",
              "  0.7567,\n",
              "  0.7636,\n",
              "  0.7644,\n",
              "  0.766,\n",
              "  0.7659,\n",
              "  0.7706,\n",
              "  0.7677,\n",
              "  0.7716,\n",
              "  0.7726,\n",
              "  0.7707,\n",
              "  0.7748,\n",
              "  0.7735,\n",
              "  0.7754,\n",
              "  0.772],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=0.7153556>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6902822>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6762972>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.67553407>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6762181>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6761639>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6725249>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6783762>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.67764425>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.67091155>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6741522>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.68210775>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6888116>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.691779>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6907138>]}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X6oS2sRduEP"
      },
      "source": [
        "epochs = 25\n",
        "self_scaling_epochs = 0\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnxI6oiedsNS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3e5f7b0-52f3-4027-c84a-eeae60072c02"
      },
      "source": [
        "model = Sequential([\n",
        "        Conv2D(96, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(96, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='selu', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Dense(256, activation='selu', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None, fixed_size=True),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/25\n",
            "loss: 1.984422206878662 - accuracy: 0.34968 - val_loss: 1.4874681234359741 - val_accuracy: 0.4664 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 2/25\n",
            "loss: 1.534834861755371 - accuracy: 0.45358 - val_loss: 1.3034113645553589 - val_accuracy: 0.5236 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 3/25\n",
            "loss: 1.3513355255126953 - accuracy: 0.52156 - val_loss: 1.10728919506073 - val_accuracy: 0.5984 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 4/25\n",
            "loss: 1.1799495220184326 - accuracy: 0.5813 - val_loss: 1.0366899967193604 - val_accuracy: 0.6298 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 5/25\n",
            "loss: 1.0552955865859985 - accuracy: 0.62838 - val_loss: 0.9161049723625183 - val_accuracy: 0.6693 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 6/25\n",
            "loss: 0.9564655423164368 - accuracy: 0.66144 - val_loss: 0.8756198287010193 - val_accuracy: 0.6871 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 7/25\n",
            "loss: 0.8740798234939575 - accuracy: 0.69012 - val_loss: 0.8169200420379639 - val_accuracy: 0.7109 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 8/25\n",
            "loss: 0.8163473606109619 - accuracy: 0.71342 - val_loss: 0.7992860078811646 - val_accuracy: 0.7194 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 9/25\n",
            "loss: 0.7709840536117554 - accuracy: 0.729 - val_loss: 0.7689354419708252 - val_accuracy: 0.7309 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 10/25\n",
            "loss: 0.7252802848815918 - accuracy: 0.744 - val_loss: 0.7766849398612976 - val_accuracy: 0.7329 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 11/25\n",
            "loss: 0.6835195422172546 - accuracy: 0.75938 - val_loss: 0.7348169684410095 - val_accuracy: 0.7478 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 12/25\n",
            "loss: 0.6466548442840576 - accuracy: 0.77064 - val_loss: 0.7242235541343689 - val_accuracy: 0.7508 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 13/25\n",
            "loss: 0.6158807277679443 - accuracy: 0.78186 - val_loss: 0.7233321070671082 - val_accuracy: 0.7547 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 14/25\n",
            "loss: 0.5950009822845459 - accuracy: 0.78912 - val_loss: 0.6880744695663452 - val_accuracy: 0.7695 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 15/25\n",
            "loss: 0.5661211013793945 - accuracy: 0.79944 - val_loss: 0.7262626886367798 - val_accuracy: 0.754 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 16/25\n",
            "loss: 0.5497869253158569 - accuracy: 0.80594 - val_loss: 0.7028892636299133 - val_accuracy: 0.7621 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 17/25\n",
            "loss: 0.5240117311477661 - accuracy: 0.81474 - val_loss: 0.6905677318572998 - val_accuracy: 0.7726 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 18/25\n",
            "loss: 0.4997371733188629 - accuracy: 0.8237 - val_loss: 0.6828029155731201 - val_accuracy: 0.7726 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 19/25\n",
            "loss: 0.4856204390525818 - accuracy: 0.8286 - val_loss: 0.7016571164131165 - val_accuracy: 0.7706 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 20/25\n",
            "loss: 0.4724864065647125 - accuracy: 0.8348 - val_loss: 0.6981359124183655 - val_accuracy: 0.7696 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 21/25\n",
            "loss: 0.4563153088092804 - accuracy: 0.8404 - val_loss: 0.6709876656532288 - val_accuracy: 0.7836 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 22/25\n",
            "loss: 0.43065422773361206 - accuracy: 0.8476 - val_loss: 0.6945541501045227 - val_accuracy: 0.7817 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 23/25\n",
            "loss: 0.43342363834381104 - accuracy: 0.84858 - val_loss: 0.6721226572990417 - val_accuracy: 0.7836 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 24/25\n",
            "loss: 0.4119667708873749 - accuracy: 0.85546 - val_loss: 0.7576307058334351 - val_accuracy: 0.7687 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 25/25\n",
            "loss: 0.4089799225330353 - accuracy: 0.85678 - val_loss: 0.6862537264823914 - val_accuracy: 0.7867 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.34968,\n",
              "  0.45358,\n",
              "  0.52156,\n",
              "  0.5813,\n",
              "  0.62838,\n",
              "  0.66144,\n",
              "  0.69012,\n",
              "  0.71342,\n",
              "  0.729,\n",
              "  0.744,\n",
              "  0.75938,\n",
              "  0.77064,\n",
              "  0.78186,\n",
              "  0.78912,\n",
              "  0.79944,\n",
              "  0.80594,\n",
              "  0.81474,\n",
              "  0.8237,\n",
              "  0.8286,\n",
              "  0.8348,\n",
              "  0.8404,\n",
              "  0.8476,\n",
              "  0.84858,\n",
              "  0.85546,\n",
              "  0.85678],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.9844222>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.5348349>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3513355>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1799495>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0552956>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.95646554>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8740798>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.81634736>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.77098405>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7252803>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.68351954>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.64665484>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6158807>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.595001>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5661211>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5497869>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.52401173>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.49973717>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.48562044>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.4724864>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.4563153>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.43065423>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.43342364>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.41196677>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.40897992>],\n",
              " 'val_accuracy': [0.4664,\n",
              "  0.5236,\n",
              "  0.5984,\n",
              "  0.6298,\n",
              "  0.6693,\n",
              "  0.6871,\n",
              "  0.7109,\n",
              "  0.7194,\n",
              "  0.7309,\n",
              "  0.7329,\n",
              "  0.7478,\n",
              "  0.7508,\n",
              "  0.7547,\n",
              "  0.7695,\n",
              "  0.754,\n",
              "  0.7621,\n",
              "  0.7726,\n",
              "  0.7726,\n",
              "  0.7706,\n",
              "  0.7696,\n",
              "  0.7836,\n",
              "  0.7817,\n",
              "  0.7836,\n",
              "  0.7687,\n",
              "  0.7867],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.4874681>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3034114>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1072892>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.03669>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.916105>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8756198>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.81692004>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.799286>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.76893544>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.77668494>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.73481697>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.72422355>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7233321>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.68807447>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7262627>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.70288926>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.69056773>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6828029>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7016571>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6981359>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.67098767>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.69455415>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.67212266>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7576307>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6862537>]}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9b072cEgaoG"
      },
      "source": [
        "epochs = 5\n",
        "self_scaling_epochs = 0\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNoZd5Jqgdph",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cd267a6-7815-4d23-bb42-c32f1ebfbec3"
      },
      "source": [
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/5\n",
            "loss: 0.39268678426742554 - accuracy: 0.86314 - val_loss: 0.6829092502593994 - val_accuracy: 0.7872 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 2/5\n",
            "loss: 0.38751205801963806 - accuracy: 0.86366 - val_loss: 0.6914719343185425 - val_accuracy: 0.786 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 3/5\n",
            "loss: 0.37477293610572815 - accuracy: 0.86886 - val_loss: 0.6710387468338013 - val_accuracy: 0.7846 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 4/5\n",
            "loss: 0.3605235517024994 - accuracy: 0.87322 - val_loss: 0.7064102292060852 - val_accuracy: 0.7836 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 5/5\n",
            "loss: 0.35460370779037476 - accuracy: 0.87496 - val_loss: 0.7092626690864563 - val_accuracy: 0.7858 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.86314, 0.86366, 0.86886, 0.87322, 0.87496],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=0.39268678>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.38751206>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.37477294>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.36052355>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.3546037>],\n",
              " 'val_accuracy': [0.7872, 0.786, 0.7846, 0.7836, 0.7858],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=0.68290925>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.69147193>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.67103875>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7064102>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.70926267>]}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBhhkeEagsEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d6ff290-64b3-4d3c-a9cf-bd3bf4469105"
      },
      "source": [
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/5\n",
            "loss: 0.33835598826408386 - accuracy: 0.88252 - val_loss: 0.714992105960846 - val_accuracy: 0.7874 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 2/5\n",
            "loss: 0.330736368894577 - accuracy: 0.8855 - val_loss: 0.6770148277282715 - val_accuracy: 0.7953 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 3/5\n",
            "loss: 0.32952749729156494 - accuracy: 0.88678 - val_loss: 0.6777744889259338 - val_accuracy: 0.7953 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 4/5\n",
            "loss: 0.3210453391075134 - accuracy: 0.88998 - val_loss: 0.7147794961929321 - val_accuracy: 0.7926 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 5/5\n",
            "loss: 0.30810704827308655 - accuracy: 0.89438 - val_loss: 0.6910793781280518 - val_accuracy: 0.7971 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.88252, 0.8855, 0.88678, 0.88998, 0.89438],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=0.338356>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.33073637>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.3295275>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.32104534>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.30810705>],\n",
              " 'val_accuracy': [0.7874, 0.7953, 0.7953, 0.7926, 0.7971],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=0.7149921>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6770148>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6777745>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7147795>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6910794>]}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwJy2dDwg5dE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35c48950-df4e-4e56-c0cb-b3564ff30e2d"
      },
      "source": [
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/5\n",
            "loss: 0.30340513586997986 - accuracy: 0.8947 - val_loss: 0.7206469774246216 - val_accuracy: 0.7952 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 2/5\n",
            "loss: 0.2996048331260681 - accuracy: 0.89638 - val_loss: 0.7327336668968201 - val_accuracy: 0.7948 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 3/5\n",
            "loss: 0.2871343195438385 - accuracy: 0.90196 - val_loss: 0.7004775404930115 - val_accuracy: 0.7965 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 4/5\n",
            "loss: 0.2848021686077118 - accuracy: 0.90296 - val_loss: 0.7234101295471191 - val_accuracy: 0.7971 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 5/5\n",
            "loss: 0.2826383113861084 - accuracy: 0.90142 - val_loss: 0.7366238832473755 - val_accuracy: 0.7957 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.8947, 0.89638, 0.90196, 0.90296, 0.90142],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=0.30340514>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.29960483>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.28713432>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.28480217>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.2826383>],\n",
              " 'val_accuracy': [0.7952, 0.7948, 0.7965, 0.7971, 0.7957],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=0.720647>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.73273367>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.70047754>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7234101>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7366239>]}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0WN8L3tzphM"
      },
      "source": [
        "# Analysis of weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDExtCeMzrvr"
      },
      "source": [
        "epochs = 20\n",
        "self_scaling_epochs = 20\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFZUD5-nz2Yp",
        "outputId": "28df4ef9-8cb8-470c-d9a0-cd54caccc156",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(100, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "        regularization_penalty=0.00002, regularization_method='weighted_l1', \n",
        "        kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "    Conv2D(100, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "        regularization_penalty=0.00002, regularization_method='weighted_l1', \n",
        "        kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    Conv2D(100, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "        regularization_penalty=0.00002, regularization_method='weighted_l1', \n",
        "        kernel_initializer='lecun_normal'),\n",
        "    Conv2D(100, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "        regularization_penalty=0.00002, regularization_method='weighted_l1', \n",
        "        kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    Flatten(),\n",
        "    Dense(100, activation='selu', regularization_penalty=0.00002, \n",
        "        regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "    Dense(10, activation='softmax', regularization_penalty=0., \n",
        "        regularization_method=None, fixed_size=True),\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8500003814697266 - val_accuracy: 0.0787 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8500008583068848 - val_accuracy: 0.0787 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "Before pruning:\n",
            "loss: 1.8934062719345093 - accuracy: 0.3574 - val_loss: 1.5234546661376953 - val_accuracy: 0.4582 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.523479700088501 - val_accuracy: 0.4581 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.523479700088501 - val_accuracy: 0.4581 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.5234798192977905 - val_accuracy: 0.4581 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "Before pruning:\n",
            "loss: 1.5559521913528442 - accuracy: 0.44812 - val_loss: 1.4093033075332642 - val_accuracy: 0.4998 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.409316062927246 - val_accuracy: 0.4998 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.409316062927246 - val_accuracy: 0.4998 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.409316062927246 - val_accuracy: 0.4998 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "Before pruning:\n",
            "loss: 1.4391769170761108 - accuracy: 0.4843 - val_loss: 1.2813960313796997 - val_accuracy: 0.54 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.281412124633789 - val_accuracy: 0.5398 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.281412124633789 - val_accuracy: 0.5398 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2814120054244995 - val_accuracy: 0.5398 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "Before pruning:\n",
            "loss: 1.3625048398971558 - accuracy: 0.51026 - val_loss: 1.241075038909912 - val_accuracy: 0.5539 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.2410123348236084 - val_accuracy: 0.554 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 87, 87, 100], total units: 474\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2410123348236084 - val_accuracy: 0.554 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 87, 87, 100], total units: 474\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2410123348236084 - val_accuracy: 0.554 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 107, 107, 120], total units: 574\n",
            "Before pruning:\n",
            "loss: 1.3149276971817017 - accuracy: 0.52906 - val_loss: 1.2074002027511597 - val_accuracy: 0.5682 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 107, 107, 120], total units: 574\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.2069138288497925 - val_accuracy: 0.5678 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 83, 80, 72, 100], total units: 435\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2069138288497925 - val_accuracy: 0.5678 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 83, 80, 72, 100], total units: 435\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2069138288497925 - val_accuracy: 0.5678 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 103, 100, 92, 120], total units: 535\n",
            "Before pruning:\n",
            "loss: 1.2714347839355469 - accuracy: 0.54332 - val_loss: 1.1667252779006958 - val_accuracy: 0.5832 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 103, 100, 92, 120], total units: 535\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1665908098220825 - val_accuracy: 0.5844 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 62, 65, 65, 98], total units: 390\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1665908098220825 - val_accuracy: 0.5844 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 62, 65, 65, 98], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.166590690612793 - val_accuracy: 0.5844 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 82, 85, 85, 118], total units: 490\n",
            "Before pruning:\n",
            "loss: 1.223204255104065 - accuracy: 0.56428 - val_loss: 1.109971284866333 - val_accuracy: 0.6064 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 82, 85, 85, 118], total units: 490\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1099892854690552 - val_accuracy: 0.6063 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 52, 58, 61, 107], total units: 378\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1099892854690552 - val_accuracy: 0.6063 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 52, 58, 61, 107], total units: 378\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1099892854690552 - val_accuracy: 0.6063 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 72, 78, 81, 128], total units: 479\n",
            "Before pruning:\n",
            "loss: 1.1710293292999268 - accuracy: 0.58446 - val_loss: 1.0650156736373901 - val_accuracy: 0.6188 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 72, 78, 81, 128], total units: 479\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0649356842041016 - val_accuracy: 0.6181 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 44, 52, 60, 98], total units: 354\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0649356842041016 - val_accuracy: 0.6181 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 44, 52, 60, 98], total units: 354\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0649356842041016 - val_accuracy: 0.6181 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 64, 72, 80, 118], total units: 454\n",
            "Before pruning:\n",
            "loss: 1.1316215991973877 - accuracy: 0.59698 - val_loss: 1.0284397602081299 - val_accuracy: 0.6336 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 64, 72, 80, 118], total units: 454\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0284044742584229 - val_accuracy: 0.634 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 37, 50, 60, 88], total units: 335\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0284044742584229 - val_accuracy: 0.634 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 37, 50, 60, 88], total units: 335\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0284044742584229 - val_accuracy: 0.634 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 57, 70, 80, 108], total units: 435\n",
            "Before pruning:\n",
            "loss: 1.1053814888000488 - accuracy: 0.60742 - val_loss: 0.997591495513916 - val_accuracy: 0.6452 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 57, 70, 80, 108], total units: 435\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9976246356964111 - val_accuracy: 0.6451 - penalty: 2e-05\n",
            "hidden layer sizes: [97, 36, 45, 68, 88], total units: 334\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9976246356964111 - val_accuracy: 0.6451 - penalty: 2e-05\n",
            "hidden layer sizes: [97, 36, 45, 68, 88], total units: 334\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9976246356964111 - val_accuracy: 0.6451 - penalty: 2e-05\n",
            "hidden layer sizes: [117, 56, 65, 88, 108], total units: 434\n",
            "Before pruning:\n",
            "loss: 1.0794954299926758 - accuracy: 0.6151 - val_loss: 0.9799509644508362 - val_accuracy: 0.6501 - penalty: 2e-05\n",
            "hidden layer sizes: [117, 56, 65, 88, 108], total units: 434\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.979990541934967 - val_accuracy: 0.65 - penalty: 2e-05\n",
            "hidden layer sizes: [95, 33, 43, 66, 96], total units: 333\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.979990541934967 - val_accuracy: 0.65 - penalty: 2e-05\n",
            "hidden layer sizes: [95, 33, 43, 66, 96], total units: 333\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.979990541934967 - val_accuracy: 0.65 - penalty: 2e-05\n",
            "hidden layer sizes: [115, 53, 63, 86, 116], total units: 433\n",
            "Before pruning:\n",
            "loss: 1.0527862310409546 - accuracy: 0.62554 - val_loss: 0.9630931615829468 - val_accuracy: 0.6602 - penalty: 2e-05\n",
            "hidden layer sizes: [115, 53, 63, 86, 116], total units: 433\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9630421996116638 - val_accuracy: 0.6605 - penalty: 2e-05\n",
            "hidden layer sizes: [92, 31, 43, 65, 99], total units: 330\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9630421996116638 - val_accuracy: 0.6605 - penalty: 2e-05\n",
            "hidden layer sizes: [92, 31, 43, 65, 99], total units: 330\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9630421996116638 - val_accuracy: 0.6605 - penalty: 2e-05\n",
            "hidden layer sizes: [112, 51, 63, 85, 119], total units: 430\n",
            "Before pruning:\n",
            "loss: 1.0314384698867798 - accuracy: 0.63576 - val_loss: 0.9470083713531494 - val_accuracy: 0.6656 - penalty: 2e-05\n",
            "hidden layer sizes: [112, 51, 63, 85, 119], total units: 430\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9472136497497559 - val_accuracy: 0.6651 - penalty: 2e-05\n",
            "hidden layer sizes: [90, 31, 38, 63, 84], total units: 306\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9472136497497559 - val_accuracy: 0.6651 - penalty: 2e-05\n",
            "hidden layer sizes: [90, 31, 38, 63, 84], total units: 306\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9472135901451111 - val_accuracy: 0.6651 - penalty: 2e-05\n",
            "hidden layer sizes: [110, 51, 58, 83, 104], total units: 406\n",
            "Before pruning:\n",
            "loss: 1.0127902030944824 - accuracy: 0.6415 - val_loss: 0.9180535078048706 - val_accuracy: 0.6773 - penalty: 2e-05\n",
            "hidden layer sizes: [110, 51, 58, 83, 104], total units: 406\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9180088043212891 - val_accuracy: 0.6775 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 28, 34, 60, 93], total units: 300\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9180088043212891 - val_accuracy: 0.6775 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 28, 34, 60, 93], total units: 300\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9180088043212891 - val_accuracy: 0.6775 - penalty: 2e-05\n",
            "hidden layer sizes: [105, 48, 54, 80, 113], total units: 400\n",
            "Before pruning:\n",
            "loss: 0.9962262511253357 - accuracy: 0.64592 - val_loss: 0.9106624722480774 - val_accuracy: 0.6802 - penalty: 2e-05\n",
            "hidden layer sizes: [105, 48, 54, 80, 113], total units: 400\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9106848835945129 - val_accuracy: 0.6798 - penalty: 2e-05\n",
            "hidden layer sizes: [78, 27, 31, 61, 98], total units: 295\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9106848835945129 - val_accuracy: 0.6798 - penalty: 2e-05\n",
            "hidden layer sizes: [78, 27, 31, 61, 98], total units: 295\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9106848835945129 - val_accuracy: 0.6798 - penalty: 2e-05\n",
            "hidden layer sizes: [98, 47, 51, 81, 118], total units: 395\n",
            "Before pruning:\n",
            "loss: 0.9852250218391418 - accuracy: 0.65044 - val_loss: 0.892981767654419 - val_accuracy: 0.6884 - penalty: 2e-05\n",
            "hidden layer sizes: [98, 47, 51, 81, 118], total units: 395\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8930187225341797 - val_accuracy: 0.6886 - penalty: 2e-05\n",
            "hidden layer sizes: [74, 25, 29, 64, 106], total units: 298\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8930187225341797 - val_accuracy: 0.6886 - penalty: 2e-05\n",
            "hidden layer sizes: [74, 25, 29, 64, 106], total units: 298\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8930187225341797 - val_accuracy: 0.6886 - penalty: 2e-05\n",
            "hidden layer sizes: [94, 45, 49, 84, 127], total units: 399\n",
            "Before pruning:\n",
            "loss: 0.9642729163169861 - accuracy: 0.65652 - val_loss: 0.8815341591835022 - val_accuracy: 0.6911 - penalty: 2e-05\n",
            "hidden layer sizes: [94, 45, 49, 84, 127], total units: 399\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8815398216247559 - val_accuracy: 0.6909 - penalty: 2e-05\n",
            "hidden layer sizes: [73, 25, 29, 63, 98], total units: 288\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8815398216247559 - val_accuracy: 0.6909 - penalty: 2e-05\n",
            "hidden layer sizes: [73, 25, 29, 63, 98], total units: 288\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8815397620201111 - val_accuracy: 0.6909 - penalty: 2e-05\n",
            "hidden layer sizes: [93, 45, 49, 83, 118], total units: 388\n",
            "Before pruning:\n",
            "loss: 0.9524367451667786 - accuracy: 0.6607 - val_loss: 0.8714125752449036 - val_accuracy: 0.6958 - penalty: 2e-05\n",
            "hidden layer sizes: [93, 45, 49, 83, 118], total units: 388\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8715718984603882 - val_accuracy: 0.696 - penalty: 2e-05\n",
            "hidden layer sizes: [70, 25, 28, 63, 86], total units: 272\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8715718984603882 - val_accuracy: 0.696 - penalty: 2e-05\n",
            "hidden layer sizes: [70, 25, 28, 63, 86], total units: 272\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8715718984603882 - val_accuracy: 0.696 - penalty: 2e-05\n",
            "hidden layer sizes: [90, 45, 48, 83, 106], total units: 372\n",
            "Before pruning:\n",
            "loss: 0.9478726387023926 - accuracy: 0.6636 - val_loss: 0.8617385029792786 - val_accuracy: 0.7012 - penalty: 2e-05\n",
            "hidden layer sizes: [90, 45, 48, 83, 106], total units: 372\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8617660999298096 - val_accuracy: 0.7011 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 25, 27, 65, 90], total units: 275\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8617660999298096 - val_accuracy: 0.7011 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 25, 27, 65, 90], total units: 275\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8617662191390991 - val_accuracy: 0.7011 - penalty: 2e-05\n",
            "hidden layer sizes: [88, 45, 47, 85, 110], total units: 375\n",
            "Before pruning:\n",
            "loss: 0.9350135922431946 - accuracy: 0.66968 - val_loss: 0.8554466962814331 - val_accuracy: 0.7035 - penalty: 2e-05\n",
            "hidden layer sizes: [88, 45, 47, 85, 110], total units: 375\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8555995225906372 - val_accuracy: 0.7029 - penalty: 2e-05\n",
            "hidden layer sizes: [66, 24, 26, 63, 99], total units: 278\n",
            "CPU times: user 3min 57s, sys: 5.88 s, total: 4min 2s\n",
            "Wall time: 4min 17s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctMxPczL6I7U",
        "outputId": "e4c3dcaf-4220-4b65-e23f-c05391e81461",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "F_max = tf.math.reduce_max(tf.reshape(model.lrs[1].F, (-1, 24)), axis=0)\n",
        "F_max"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(24,), dtype=float32, numpy=\n",
              "array([0.2557953 , 0.32084802, 0.20654957, 0.18176152, 0.23293227,\n",
              "       0.30434278, 0.23326479, 0.37587985, 0.17162846, 0.242999  ,\n",
              "       0.31274992, 0.15017053, 0.16214521, 0.28741014, 0.17450476,\n",
              "       0.19815212, 0.19987217, 0.01359444, 0.18117794, 0.26616138,\n",
              "       0.01605158, 0.12180457, 0.00337833, 0.09020552], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak9iF-Cc2VwF",
        "outputId": "48e92a9d-9ce5-49e2-f65f-5e85d21ff850",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "plt.hist(F_max)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([3., 0., 1., 2., 5., 3., 4., 2., 3., 1.]),\n",
              " array([0.00337833, 0.04062848, 0.07787863, 0.11512879, 0.15237893,\n",
              "        0.1896291 , 0.22687924, 0.2641294 , 0.30137956, 0.3386297 ,\n",
              "        0.37587985], dtype=float32),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oazbbq5CW2L",
        "outputId": "2c774d76-fae4-4353-e3b8-f61225d1469e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tf.math.reduce_sum(model.lrs[1].F)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=28.996367>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HHcOVBn6BRa",
        "outputId": "3c7892ec-1c78-4eb1-a24c-d703f055c63f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "b_max = model.lrs[1].b\n",
        "b_max"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'b:0' shape=(24,) dtype=float32, numpy=\n",
              "array([-1.39534771e-02, -8.11492056e-02,  2.30627581e-02,  1.06229275e-01,\n",
              "        7.36065395e-03, -7.20906183e-02, -1.64083038e-02, -8.71820152e-02,\n",
              "       -6.31256551e-02,  1.54387951e-03, -1.02306843e-01,  6.62483927e-03,\n",
              "       -1.78761631e-01, -4.03573597e-03, -1.05459790e-03, -1.94715019e-02,\n",
              "       -2.98340563e-02,  6.84485276e-05,  8.16060521e-04,  7.12670386e-04,\n",
              "       -4.17634733e-02, -8.96751694e-03,  2.04557691e-05,  2.13898369e-04],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JumbXfqb2mBs",
        "outputId": "c51e191c-a225-4f0c-a8b6-3e48357a47f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "plt.hist(b_max)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 1.,  0.,  1.,  3.,  2.,  5., 10.,  1.,  0.,  1.]),\n",
              " array([-0.17876163, -0.15026253, -0.12176345, -0.09326436, -0.06476527,\n",
              "        -0.03626618, -0.00776709,  0.020732  ,  0.04923109,  0.07773019,\n",
              "         0.10622928], dtype=float32),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRJqz71CA4MB"
      },
      "source": [
        "epochs = 20\n",
        "self_scaling_epochs = 0\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKcyWGaZ815F",
        "outputId": "2433b2f5-edd1-4452-aa8e-9ba0dfad9371",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "loss: 0.9274218678474426 - accuracy: 0.66866 - val_loss: 0.8334266543388367 - val_accuracy: 0.7071 - penalty: 0.0\n",
            "hidden layer sizes: [66, 24, 26, 63, 99], total units: 278\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "loss: 0.8430859446525574 - accuracy: 0.7004 - val_loss: 0.8132927417755127 - val_accuracy: 0.7135 - penalty: 0.0\n",
            "hidden layer sizes: [66, 24, 26, 63, 99], total units: 278\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "loss: 0.798242449760437 - accuracy: 0.71796 - val_loss: 0.7980955243110657 - val_accuracy: 0.7235 - penalty: 0.0\n",
            "hidden layer sizes: [66, 24, 26, 63, 99], total units: 278\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "loss: 0.76285719871521 - accuracy: 0.72686 - val_loss: 0.7911869883537292 - val_accuracy: 0.7231 - penalty: 0.0\n",
            "hidden layer sizes: [66, 24, 26, 63, 99], total units: 278\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "loss: 0.7372441291809082 - accuracy: 0.73504 - val_loss: 0.7786753177642822 - val_accuracy: 0.7293 - penalty: 0.0\n",
            "hidden layer sizes: [66, 24, 26, 63, 99], total units: 278\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "loss: 0.7107423543930054 - accuracy: 0.74692 - val_loss: 0.7707407474517822 - val_accuracy: 0.7341 - penalty: 0.0\n",
            "hidden layer sizes: [66, 24, 26, 63, 99], total units: 278\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "loss: 0.6807641983032227 - accuracy: 0.75974 - val_loss: 0.7675769925117493 - val_accuracy: 0.7344 - penalty: 0.0\n",
            "hidden layer sizes: [66, 24, 26, 63, 99], total units: 278\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "loss: 0.6582093834877014 - accuracy: 0.76642 - val_loss: 0.7640209197998047 - val_accuracy: 0.7356 - penalty: 0.0\n",
            "hidden layer sizes: [66, 24, 26, 63, 99], total units: 278\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "loss: 0.6316851377487183 - accuracy: 0.77572 - val_loss: 0.7530366778373718 - val_accuracy: 0.7393 - penalty: 0.0\n",
            "hidden layer sizes: [66, 24, 26, 63, 99], total units: 278\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "loss: 0.6092785000801086 - accuracy: 0.78288 - val_loss: 0.7541403770446777 - val_accuracy: 0.7388 - penalty: 0.0\n",
            "hidden layer sizes: [66, 24, 26, 63, 99], total units: 278\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "loss: 0.5863292813301086 - accuracy: 0.7909 - val_loss: 0.7423780560493469 - val_accuracy: 0.744 - penalty: 0.0\n",
            "hidden layer sizes: [66, 24, 26, 63, 99], total units: 278\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "loss: 0.563401460647583 - accuracy: 0.79958 - val_loss: 0.7402411699295044 - val_accuracy: 0.7469 - penalty: 0.0\n",
            "hidden layer sizes: [66, 24, 26, 63, 99], total units: 278\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "loss: 0.5429107546806335 - accuracy: 0.8075 - val_loss: 0.7432302236557007 - val_accuracy: 0.7494 - penalty: 0.0\n",
            "hidden layer sizes: [66, 24, 26, 63, 99], total units: 278\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "loss: 0.5236311554908752 - accuracy: 0.81266 - val_loss: 0.7339450120925903 - val_accuracy: 0.7509 - penalty: 0.0\n",
            "hidden layer sizes: [66, 24, 26, 63, 99], total units: 278\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "loss: 0.508597731590271 - accuracy: 0.81936 - val_loss: 0.7409199476242065 - val_accuracy: 0.747 - penalty: 0.0\n",
            "hidden layer sizes: [66, 24, 26, 63, 99], total units: 278\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "loss: 0.49118730425834656 - accuracy: 0.82404 - val_loss: 0.7421850562095642 - val_accuracy: 0.7486 - penalty: 0.0\n",
            "hidden layer sizes: [66, 24, 26, 63, 99], total units: 278\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "loss: 0.47329628467559814 - accuracy: 0.83142 - val_loss: 0.7494286298751831 - val_accuracy: 0.7512 - penalty: 0.0\n",
            "hidden layer sizes: [66, 24, 26, 63, 99], total units: 278\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "loss: 0.45942988991737366 - accuracy: 0.83452 - val_loss: 0.7502403855323792 - val_accuracy: 0.7505 - penalty: 0.0\n",
            "hidden layer sizes: [66, 24, 26, 63, 99], total units: 278\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "loss: 0.44743335247039795 - accuracy: 0.8396 - val_loss: 0.7549312710762024 - val_accuracy: 0.7484 - penalty: 0.0\n",
            "hidden layer sizes: [66, 24, 26, 63, 99], total units: 278\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "loss: 0.43644067645072937 - accuracy: 0.84406 - val_loss: 0.761436402797699 - val_accuracy: 0.7471 - penalty: 0.0\n",
            "hidden layer sizes: [66, 24, 26, 63, 99], total units: 278\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.66866,\n",
              "  0.7004,\n",
              "  0.71796,\n",
              "  0.72686,\n",
              "  0.73504,\n",
              "  0.74692,\n",
              "  0.75974,\n",
              "  0.76642,\n",
              "  0.77572,\n",
              "  0.78288,\n",
              "  0.7909,\n",
              "  0.79958,\n",
              "  0.8075,\n",
              "  0.81266,\n",
              "  0.81936,\n",
              "  0.82404,\n",
              "  0.83142,\n",
              "  0.83452,\n",
              "  0.8396,\n",
              "  0.84406],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=0.92742187>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.84308594>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.79824245>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7628572>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7372441>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.71074235>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6807642>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6582094>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.63168514>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6092785>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5863293>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.56340146>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.54291075>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.52363116>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.50859773>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.4911873>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.47329628>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.4594299>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.44743335>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.43644068>],\n",
              " 'val_accuracy': [0.7071,\n",
              "  0.7135,\n",
              "  0.7235,\n",
              "  0.7231,\n",
              "  0.7293,\n",
              "  0.7341,\n",
              "  0.7344,\n",
              "  0.7356,\n",
              "  0.7393,\n",
              "  0.7388,\n",
              "  0.744,\n",
              "  0.7469,\n",
              "  0.7494,\n",
              "  0.7509,\n",
              "  0.747,\n",
              "  0.7486,\n",
              "  0.7512,\n",
              "  0.7505,\n",
              "  0.7484,\n",
              "  0.7471],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=0.83342665>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.81329274>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7980955>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.791187>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7786753>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.77074075>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.767577>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7640209>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7530367>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7541404>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.74237806>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.74024117>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7432302>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.733945>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.74091995>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.74218506>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.74942863>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7502404>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7549313>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7614364>]}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aPrNr7C86RY",
        "outputId": "a5735997-8bcf-4e18-96de-1dd0aab0d8e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "F_max = tf.math.reduce_max(tf.reshape(model.lrs[1].F, (-1, 24)), axis=0)\n",
        "F_max"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(24,), dtype=float32, numpy=\n",
              "array([0.2852508 , 0.39062864, 0.26719773, 0.20736325, 0.2963995 ,\n",
              "       0.42294604, 0.2650938 , 0.47059634, 0.21876326, 0.29584205,\n",
              "       0.3412175 , 0.20349829, 0.19333054, 0.38822642, 0.22182624,\n",
              "       0.2758319 , 0.2670268 , 0.15331937, 0.24605438, 0.3304207 ,\n",
              "       0.04936865, 0.1445164 , 0.14679813, 0.14567664], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEN500_a870Y",
        "outputId": "bbf13856-dbac-493c-e1f8-3552309fc0fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "plt.hist(F_max)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1., 0., 4., 3., 3., 7., 2., 0., 3., 1.]),\n",
              " array([0.04936865, 0.09149142, 0.1336142 , 0.17573696, 0.21785973,\n",
              "        0.2599825 , 0.30210528, 0.34422803, 0.3863508 , 0.42847356,\n",
              "        0.47059634], dtype=float32),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwfyb7ieDVaF",
        "outputId": "3b96beda-d142-49db-8ddf-82e600864ea7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tf.math.reduce_sum(model.lrs[1].F)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=54.194973>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXr5oKfk876G",
        "outputId": "0fc57b18-57a4-477c-e9c1-29eb6e1c85b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "b_max = model.lrs[1].b\n",
        "b_max"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'b:0' shape=(24,) dtype=float32, numpy=\n",
              "array([-0.00747755, -0.08080523,  0.02618667,  0.11587684,  0.00518507,\n",
              "       -0.0811644 , -0.02718006, -0.10063612, -0.07734868, -0.00177401,\n",
              "       -0.1137526 ,  0.00489218, -0.21278912, -0.0204876 ,  0.01462507,\n",
              "       -0.01291353, -0.03296454,  0.0084464 , -0.00314905, -0.00151894,\n",
              "       -0.0637429 , -0.0200336 ,  0.01901927,  0.0081754 ], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEeWa9Se8-NR",
        "outputId": "7e7a1863-a346-4cdd-b427-5df66429e186",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "plt.hist(b_max)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 1.,  0.,  0.,  2.,  4.,  4., 10.,  2.,  0.,  1.]),\n",
              " array([-0.21278912, -0.17992252, -0.14705592, -0.11418933, -0.08132274,\n",
              "        -0.04845614, -0.01558954,  0.01727705,  0.05014365,  0.08301024,\n",
              "         0.11587684], dtype=float32),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZT88_cT9yej"
      },
      "source": [
        "# Misc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWOQuGEVq6Gj"
      },
      "source": [
        "# Temto model je na Cifar10 jiz pomerne vyladeny\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(input_shape=X_train_norm[0,:,:,:].shape, filters=96, kernel_size=(3,3), activation='selu', kernel_initializer='lecun_normal'))\n",
        "model.add(tf.keras.layers.Conv2D(filters=96, kernel_size=(3,3), strides=2, activation='selu', kernel_initializer='lecun_normal'))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Conv2D(filters=192, kernel_size=(3,3), activation='selu', kernel_initializer='lecun_normal'))\n",
        "model.add(tf.keras.layers.Conv2D(filters=192, kernel_size=(3,3), strides=2, activation='selu', kernel_initializer='lecun_normal'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256, activation='selu', kernel_initializer='lecun_normal'))\n",
        "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDMBpQB1zkdk"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4l2I_etAZ4is",
        "outputId": "7ea71652-9e59-4a95-838d-fb4d06ccab0b"
      },
      "source": [
        "%%time\n",
        "\n",
        "model.fit(X_train_norm, y_train, epochs=25, batch_size=256, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "196/196 [==============================] - 9s 46ms/step - loss: 2.0276 - accuracy: 0.3617 - val_loss: 1.4487 - val_accuracy: 0.4768\n",
            "Epoch 2/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 1.4076 - accuracy: 0.4938 - val_loss: 1.3187 - val_accuracy: 0.5150\n",
            "Epoch 3/25\n",
            "196/196 [==============================] - 9s 46ms/step - loss: 1.2646 - accuracy: 0.5483 - val_loss: 1.1942 - val_accuracy: 0.5702\n",
            "Epoch 4/25\n",
            "196/196 [==============================] - 9s 46ms/step - loss: 1.1380 - accuracy: 0.5945 - val_loss: 1.1212 - val_accuracy: 0.5984\n",
            "Epoch 5/25\n",
            "196/196 [==============================] - 9s 46ms/step - loss: 1.0255 - accuracy: 0.6347 - val_loss: 1.0245 - val_accuracy: 0.6363\n",
            "Epoch 6/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 0.9390 - accuracy: 0.6672 - val_loss: 0.9999 - val_accuracy: 0.6479\n",
            "Epoch 7/25\n",
            "196/196 [==============================] - 9s 44ms/step - loss: 0.8667 - accuracy: 0.6939 - val_loss: 0.9372 - val_accuracy: 0.6731\n",
            "Epoch 8/25\n",
            "196/196 [==============================] - 9s 44ms/step - loss: 0.7990 - accuracy: 0.7169 - val_loss: 0.9421 - val_accuracy: 0.6771\n",
            "Epoch 9/25\n",
            "196/196 [==============================] - 9s 44ms/step - loss: 0.7508 - accuracy: 0.7351 - val_loss: 0.9119 - val_accuracy: 0.6902\n",
            "Epoch 10/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 0.6957 - accuracy: 0.7550 - val_loss: 0.8888 - val_accuracy: 0.7011\n",
            "Epoch 11/25\n",
            "196/196 [==============================] - 9s 44ms/step - loss: 0.6530 - accuracy: 0.7692 - val_loss: 0.8857 - val_accuracy: 0.7033\n",
            "Epoch 12/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 0.6118 - accuracy: 0.7842 - val_loss: 0.8710 - val_accuracy: 0.7076\n",
            "Epoch 13/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 0.5877 - accuracy: 0.7917 - val_loss: 0.9078 - val_accuracy: 0.7080\n",
            "Epoch 14/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 0.5419 - accuracy: 0.8086 - val_loss: 0.8814 - val_accuracy: 0.7109\n",
            "Epoch 15/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 0.5262 - accuracy: 0.8135 - val_loss: 0.9352 - val_accuracy: 0.7146\n",
            "Epoch 16/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 0.4963 - accuracy: 0.8243 - val_loss: 0.9018 - val_accuracy: 0.7223\n",
            "Epoch 17/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 0.4799 - accuracy: 0.8313 - val_loss: 0.9216 - val_accuracy: 0.7140\n",
            "Epoch 18/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 0.4564 - accuracy: 0.8392 - val_loss: 0.9259 - val_accuracy: 0.7286\n",
            "Epoch 19/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 0.4373 - accuracy: 0.8470 - val_loss: 0.9008 - val_accuracy: 0.7209\n",
            "Epoch 20/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 0.4227 - accuracy: 0.8521 - val_loss: 0.9384 - val_accuracy: 0.7263\n",
            "Epoch 21/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 0.3927 - accuracy: 0.8639 - val_loss: 0.9229 - val_accuracy: 0.7233\n",
            "Epoch 22/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 0.3971 - accuracy: 0.8618 - val_loss: 0.9479 - val_accuracy: 0.7231\n",
            "Epoch 23/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 0.3730 - accuracy: 0.8714 - val_loss: 0.9526 - val_accuracy: 0.7309\n",
            "Epoch 24/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 0.3650 - accuracy: 0.8750 - val_loss: 0.9737 - val_accuracy: 0.7286\n",
            "Epoch 25/25\n",
            "196/196 [==============================] - 9s 46ms/step - loss: 0.3604 - accuracy: 0.8747 - val_loss: 1.0245 - val_accuracy: 0.7315\n",
            "CPU times: user 3min 3s, sys: 6.67 s, total: 3min 9s\n",
            "Wall time: 3min 42s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc8d011d890>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_BvNnozaO0-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}