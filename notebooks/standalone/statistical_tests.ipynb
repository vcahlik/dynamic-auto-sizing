{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26791ae1-b105-40e0-bc77-be4e63499da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.stats import chisquare\n",
    "import os\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bbbbcec-0d79-4180-ab38-e95ad64f7850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency(x, size, n_splits):\n",
    "    x = np.array(x)\n",
    "    x = x * size / n_splits\n",
    "    x = x.astype(int)\n",
    "    matched = sum(x)\n",
    "    return [matched, size - matched]\n",
    "\n",
    "def get_frequencies(a, b, c, d, size, n_splits):\n",
    "    af = get_frequency(a, size, n_splits)\n",
    "    bf = get_frequency(b, size, n_splits)\n",
    "    cf = get_frequency(c, size, n_splits)\n",
    "    df = get_frequency(d, size, n_splits)\n",
    "    return af, bf, cf, df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9ae37e-ca8d-4a52-a286-48dcb3500925",
   "metadata": {},
   "source": [
    "# CIFAR-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a18f65de-5895-4c78-9891-c4455c075837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([27056, 32944], [19411, 40589], [21232, 38768], [23693, 36307])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [0.4428, 0.4512, 0.4484, 0.4485, 0.4577, 0.457]\n",
    "b = [0.3183, 0.3265, 0.3134, 0.3345, 0.325, 0.3234]\n",
    "c = [0.3412, 0.3624, 0.3531, 0.3609, 0.3543, 0.3513]\n",
    "d = [0.3857, 0.3949, 0.3937, 0.3897, 0.4124, 0.3929]\n",
    "af, bf, cf, df = get_frequencies(a, b, c, d, 60000, 6)\n",
    "af, bf, cf, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de64ddf0-1e5e-4535-bd7a-0e75dc158888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Power_divergenceResult(statistic=4450.921847019982, pvalue=0.0),\n",
       " Power_divergenceResult(statistic=2472.462314027122, pvalue=0.0),\n",
       " Power_divergenceResult(statistic=788.850246126827, pvalue=1.4329779284388962e-173))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chisquare(af, f_exp=bf), chisquare(af, f_exp=cf), chisquare(af, f_exp=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affd6d52-fe1a-4c94-a062-66cdf2741624",
   "metadata": {},
   "source": [
    "# SVHN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7903989c-ae6c-4ea7-9863-260a09440f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([92481, 6808], [90700, 8589], [91764, 7525], [91608, 7681])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [0.9326431132417516, 0.9331238417532833, 0.9300217548948514, 0.929981468052534]\n",
    "b = [0.9115739435201224, 0.9151559100797679, 0.9182177100958827, 0.9090725968898558]\n",
    "c = [0.925069492003384, 0.9253484811860446, 0.9239384417049392, 0.9225284022238337]\n",
    "d = [0.9249889215646779, 0.9247441785512851, 0.920554346950286, 0.9203126258963823]\n",
    "af, bf, cf, df = get_frequencies(a, b, c, d, 73257 + 26032, 4)\n",
    "af, bf, cf, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "641d70ed-15b2-4359-9582-0bcf75475406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Power_divergenceResult(statistic=404.2770479471512, pvalue=6.454866885149661e-90),\n",
       " Power_divergenceResult(statistic=73.91977010071047, pvalue=8.135738846697126e-18),\n",
       " Power_divergenceResult(statistic=107.54208626128928, pvalue=3.386374489248262e-25))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chisquare(af, f_exp=bf), chisquare(af, f_exp=cf), chisquare(af, f_exp=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e62b65-b61d-4022-ab78-6be56df33260",
   "metadata": {},
   "source": [
    "# CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd54b1e3-4095-444e-a6a7-25f07931433b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([46228, 13772], [43768, 16232], [45373, 14627], [43354, 16646])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [0.7729, 0.7684, 0.773, 0.7674, 0.7749, 0.7662]\n",
    "b = [0.7312, 0.7296, 0.7286, 0.7299, 0.7389, 0.7186]\n",
    "c = [0.7625, 0.7541, 0.7469, 0.7564, 0.7607, 0.7567]\n",
    "d = [0.7324, 0.7187, 0.7138, 0.7209, 0.7298, 0.7198]\n",
    "af, bf, cf, df = get_frequencies(a, b, c, d, 60000, 6)\n",
    "af, bf, cf, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "271da87a-57c4-4230-9780-89a1e282ff81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Power_divergenceResult(statistic=511.0845220990934, pvalue=3.683445058756479e-113),\n",
       " Power_divergenceResult(statistic=66.08923476468203, pvalue=4.3096318278006714e-16),\n",
       " Power_divergenceResult(statistic=686.7295166447416, pvalue=2.298779210820388e-151))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chisquare(af, f_exp=bf), chisquare(af, f_exp=cf), chisquare(af, f_exp=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3078d55b-3789-45a2-b198-cb4b5df43500",
   "metadata": {},
   "source": [
    "# Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "de71319e-56d2-489a-9fdb-bb78a0bd3dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([65288, 4712], [64675, 5325], [64929, 5071], [64467, 5533])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [0.9333, 0.9314, 0.9313, 0.9325, 0.9384, 0.9298, 0.9321]\n",
    "b = [0.923, 0.9246, 0.9233, 0.9269, 0.9218, 0.9249, 0.9231]\n",
    "c = [0.9259, 0.9275, 0.9257, 0.9297, 0.9311, 0.926, 0.9271]\n",
    "d = [0.9187, 0.9226, 0.9206, 0.9223, 0.9228, 0.9191, 0.9206]\n",
    "af, bf, cf, df = get_frequencies(a, b, c, d, 70000, 7)\n",
    "af, bf, cf, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f84c2f75-eb12-4748-ba14-a42931a359d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Power_divergenceResult(statistic=76.37706045576384, pvalue=2.3435787913350287e-18),\n",
       " Power_divergenceResult(statistic=27.40025549622777, pvalue=1.6540938236656524e-07),\n",
       " Power_divergenceResult(statistic=132.27757466499244, pvalue=1.3009578325038647e-30))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chisquare(af, f_exp=bf), chisquare(af, f_exp=cf), chisquare(af, f_exp=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725d1158-91f3-44ca-a12e-2c867e408756",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "32936a96-d5de-46e8-8f05-cc34b2682e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([69547, 453], [69535, 465], [69533, 467], [69443, 557])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [0.9926, 0.9936, 0.9928, 0.9938, 0.9946, 0.9933, 0.994]\n",
    "b = [0.9923, 0.9935, 0.9937, 0.9932, 0.9941, 0.9924, 0.9943]\n",
    "c = [0.9932, 0.9938, 0.9926, 0.9942, 0.9947, 0.9913, 0.9935]\n",
    "d = [0.9914, 0.993, 0.9926, 0.9923, 0.9929, 0.9907, 0.9914]\n",
    "af, bf, cf, df = get_frequencies(a, b, c, d, 70000, 7)\n",
    "af, bf, cf, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "745a1aba-1e90-4d33-9ed5-f7f44d73d2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Power_divergenceResult(statistic=0.31174831890182947, pvalue=0.576609323427017),\n",
       " Power_divergenceResult(statistic=0.42251901959204063, pvalue=0.5156827712976023),\n",
       " Power_divergenceResult(statistic=19.574066027467445, pvalue=9.677395049205175e-06))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chisquare(af, f_exp=bf), chisquare(af, f_exp=cf), chisquare(af, f_exp=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c548b639-ed6b-48cc-a023-1e2bb6cf6584",
   "metadata": {},
   "source": [
    "# Tiny ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de5c7259-6d80-4694-9403-b1490b0c79c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([20621, 89379], [12434, 97566], [12445, 97555], [18783, 91217])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [0.1862, 0.1854, 0.1917, 0.1792, 0.2002, 0.1792, 0.19, 0.213, 0.1825, 0.1743, 0.1804]\n",
    "b = [0.1087, 0.1094, 0.1176, 0.111, 0.1162, 0.1078, 0.1183, 0.1164, 0.1093, 0.1149, 0.1138]\n",
    "c = [0.1139, 0.1136, 0.1129, 0.1177, 0.1136, 0.1063, 0.115, 0.1142, 0.1077, 0.1128, 0.1168]\n",
    "d = [0.1786, 0.1581, 0.1702, 0.1729, 0.1791, 0.1723, 0.1706, 0.179, 0.1678, 0.1617, 0.168]\n",
    "af, bf, cf, df = get_frequencies(a, b, c, d, 110000, 11)\n",
    "af, bf, cf, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eae3e5e0-b7b6-44ea-8e72-c26a3d64134e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Power_divergenceResult(statistic=6077.61104577684, pvalue=0.0),\n",
       " Power_divergenceResult(statistic=6056.61567964288, pvalue=0.0),\n",
       " Power_divergenceResult(statistic=216.89171157633024, pvalue=4.309253518800172e-49))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chisquare(af, f_exp=bf), chisquare(af, f_exp=cf), chisquare(af, f_exp=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeef427b-85ab-46c3-94e0-94409f0dca7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36759810-f910-4420-a94b-ff94b732bc09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7b160e69-efa9-43eb-a810-1b89b4c77131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=788.850246126827, pvalue=1.4329779284388962e-173)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chisquare(af, f_exp=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9509cd-10f5-4b23-91ba-735145c304e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4998d57-e660-4820-9e5c-24da9e9c59ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4428., 4512., 4484., 4485., 4577., 4570.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "das_wl1 = np.array([0.4428, 0.4512, 0.4484, 0.4485, 0.4577, 0.457])\n",
    "size = 60000\n",
    "das_wl1 = das_wl1 * size / 6\n",
    "das_wl1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4eef8eac-efdc-44ac-8577-993e773612d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4428, 4512, 4484, 4485, 4577, 4570])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "das_wl1 = das_wl1.astype(int)\n",
    "das_wl1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3220bb12-c366-4938-8785-670b744038ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[27056, 32944]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed = sum(das_wl1)\n",
    "das_wl1_f = [summed, size - summed]\n",
    "das_wl1_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1360eb6d-fd7c-43eb-a3ab-48887a72c2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3183., 3265., 3134., 3345., 3250., 3234.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_a = np.array([0.3183, 0.3265, 0.3134, 0.3345, 0.325, 0.3234])\n",
    "size = 60000\n",
    "static_a = static_a * size / 6\n",
    "static_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "683d9abc-0442-43e5-88cd-58eef962fe80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3183, 3265, 3134, 3345, 3250, 3234])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_a = static_a.astype(int)\n",
    "static_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70e89a9d-aac0-4aee-8278-0dff2550fff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19411, 40589]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed = sum(static_a)\n",
    "static_a_f = [summed, size - summed]\n",
    "static_a_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b48c857-5d39-4786-bbaf-fd818f2d8ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e834b68c-cdf8-46db-971a-f14797c4d13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=4450.921847019982, pvalue=0.0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chisquare(das_wl1_f, f_exp=static_a_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a5ab948-69cc-4508-b391-55cdca10e68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, X_train, y_train, X_test, y_test, shape, shape_flattened):\n",
    "        X_train = X_train.astype(dtype) / 255.0\n",
    "        y_train = y_train.astype(dtype)\n",
    "        X_test = X_test.astype(dtype)  / 255.0\n",
    "        y_test = y_test.astype(dtype)\n",
    "\n",
    "        X_train = np.reshape(X_train, shape_flattened)\n",
    "        X_test = np.reshape(X_test, shape_flattened)\n",
    "\n",
    "        X = np.concatenate((X_train, X_test), axis=0)\n",
    "        y = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)  # Scaling each feature independently\n",
    "\n",
    "        X_norm = scaler.transform(X)\n",
    "        X_train_norm = scaler.transform(X_train)\n",
    "        X_test_norm = scaler.transform(X_test)\n",
    "\n",
    "        X_norm = np.reshape(X_norm, shape)\n",
    "        X_train_norm = np.reshape(X_train_norm, shape)\n",
    "        X_test_norm = np.reshape(X_test_norm, shape)\n",
    "\n",
    "        self.X_norm = X_norm\n",
    "        self.y = y\n",
    "        self.X_train_norm = X_train_norm\n",
    "        self.y_train = y_train\n",
    "        self.X_test_norm = X_test_norm\n",
    "        self.y_test = y_test\n",
    "\n",
    "\n",
    "def get_cifar_10_dataset():\n",
    "    cifar10 = tf.keras.datasets.cifar10\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "    shape = (-1, 32, 32, 3)\n",
    "    shape_flattened = (-1, 3072)  # Scaling each feature independently\n",
    "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened)\n",
    "\n",
    "\n",
    "def get_cifar_100_dataset():\n",
    "    cifar100 = tf.keras.datasets.cifar100\n",
    "    (X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
    "    shape = (-1, 32, 32, 3)\n",
    "    shape_flattened = (-1, 3072)  # Scaling each feature independently\n",
    "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened)\n",
    "\n",
    "\n",
    "def get_svhn_dataset():\n",
    "    from urllib.request import urlretrieve\n",
    "    from scipy import io\n",
    "\n",
    "    train_filename, _ = urlretrieve('http://ufldl.stanford.edu/housenumbers/train_32x32.mat')\n",
    "    test_filename, _ = urlretrieve('http://ufldl.stanford.edu/housenumbers/test_32x32.mat')\n",
    "\n",
    "    X_train = io.loadmat(train_filename, variable_names='X').get('X')\n",
    "    y_train = io.loadmat(train_filename, variable_names='y').get('y')\n",
    "    X_test = io.loadmat(test_filename, variable_names='X').get('X')\n",
    "    y_test = io.loadmat(test_filename, variable_names='y').get('y')\n",
    "\n",
    "    X_train = np.moveaxis(X_train, -1, 0)\n",
    "    y_train -= 1\n",
    "    X_test = np.moveaxis(X_test, -1, 0)\n",
    "    y_test -= 1\n",
    "\n",
    "    shape = (-1, 32, 32, 3)\n",
    "    shape_flattened = (-1, 3072)  # Scaling each feature independently\n",
    "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened)\n",
    "\n",
    "\n",
    "def get_tiny_imagenet_dataset():\n",
    "    \"\"\"\n",
    "    Original source: https://github.com/sonugiri1043/Train_ResNet_On_Tiny_ImageNet/blob/master/Train_ResNet_On_Tiny_ImageNet.ipynb\n",
    "    Original author: sonugiri1043@gmail.com\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.isdir('IMagenet'):\n",
    "        ! git clone https://github.com/seshuad/IMagenet\n",
    "\n",
    "    print(\"Processing the downloaded dataset...\")\n",
    "\n",
    "    path = 'IMagenet/tiny-imagenet-200/'\n",
    "\n",
    "    id_dict = {}\n",
    "    for i, line in enumerate(open(path + 'wnids.txt', 'r')):\n",
    "        id_dict[line.replace('\\n', '')] = i\n",
    "\n",
    "    train_data = list()\n",
    "    test_data = list()\n",
    "    train_labels = list()\n",
    "    test_labels = list()\n",
    "\n",
    "    for key, value in id_dict.items():\n",
    "        train_data += [imageio.imread(path + 'train/{}/images/{}_{}.JPEG'.format(key, key, str(i)), pilmode='RGB') for i in range(500)]\n",
    "        train_labels_ = np.array([[0]*200]*500)\n",
    "        train_labels_[:, value] = 1\n",
    "        train_labels += train_labels_.tolist()\n",
    "\n",
    "    for line in open(path + 'val/val_annotations.txt'):\n",
    "        img_name, class_id = line.split('\\t')[:2]\n",
    "        test_data.append(imageio.imread(path + 'val/images/{}'.format(img_name), pilmode='RGB'))\n",
    "        test_labels_ = np.array([[0]*200])\n",
    "        test_labels_[0, id_dict[class_id]] = 1\n",
    "        test_labels += test_labels_.tolist()\n",
    "\n",
    "    X_train = np.array(train_data)\n",
    "    y_train = np.argmax(np.array(train_labels), axis=1)\n",
    "    X_test = np.array(test_data)\n",
    "    y_test = np.argmax(np.array(test_labels), axis=1)\n",
    "\n",
    "    shape = (-1, 64, 64, 3)\n",
    "    shape_flattened = (-1, 12288)  # Scaling each feature independently\n",
    "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened)\n",
    "\n",
    "\n",
    "def get_mnist_dataset():\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    shape = (-1, 28, 28, 1)\n",
    "    shape_flattened = (-1, 1)  # Scaling all features together\n",
    "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened)\n",
    "\n",
    "\n",
    "def get_fashion_mnist_dataset():\n",
    "    fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "    (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "    shape = (-1, 28, 28, 1)\n",
    "    shape_flattened = (-1, 1)  # Scaling all features together\n",
    "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "77b6b0c6-7543-4da0-bcf5-8705afd4079d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m svhn \u001b[38;5;241m=\u001b[39m \u001b[43mget_svhn_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [48]\u001b[0m, in \u001b[0;36mget_svhn_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m urlretrieve\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m io\n\u001b[0;32m---> 55\u001b[0m train_filename, _ \u001b[38;5;241m=\u001b[39m \u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp://ufldl.stanford.edu/housenumbers/train_32x32.mat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m test_filename, _ \u001b[38;5;241m=\u001b[39m urlretrieve(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://ufldl.stanford.edu/housenumbers/test_32x32.mat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     58\u001b[0m X_train \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mloadmat(train_filename, variable_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.9/urllib/request.py:268\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    265\u001b[0m     reporthook(blocknum, bs, size)\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 268\u001b[0m     block \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m block:\n\u001b[1;32m    270\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.9/http/client.py:462\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;66;03m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[1;32m    461\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(amt)\n\u001b[0;32m--> 462\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b)[:n]\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.9/http/client.py:506\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    501\u001b[0m         b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(b)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength]\n\u001b[1;32m    503\u001b[0m \u001b[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;66;03m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[0;32m--> 506\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n \u001b[38;5;129;01mand\u001b[39;00m b:\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "svhn = get_svhn_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "758fe468-45d1-4241-9da0-7cf686908fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the downloaded dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3888/3161826999.py:96: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning dissapear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  train_data += [imageio.imread(path + 'train/{}/images/{}_{}.JPEG'.format(key, key, str(i)), pilmode='RGB') for i in range(500)]\n",
      "/tmp/ipykernel_3888/3161826999.py:103: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning dissapear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  test_data.append(imageio.imread(path + 'val/images/{}'.format(img_name), pilmode='RGB'))\n"
     ]
    }
   ],
   "source": [
    "dtype = 'float32'\n",
    "tiny_imagenet = get_tiny_imagenet_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a318645e-05e7-4d7e-bc48-29d4df6e656d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110000, 64, 64, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_imagenet.X_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcca459-5344-4cf5-ba83-fa3a77652bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
