{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = 'float32'\n",
    "tf.keras.backend.set_floatx(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "# (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# X_train = X_train.astype(dtype) / 255.0\n",
    "# y_train = y_train.astype(dtype)\n",
    "# X_test = X_test.astype(dtype)  / 255.0\n",
    "# y_test = y_test.astype(dtype)\n",
    "\n",
    "# X_train = np.reshape(X_train, (-1, 784))\n",
    "# X_test = np.reshape(X_test, (-1, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "X_train = X_train.astype(dtype) / 255.0\n",
    "y_train = y_train.astype(dtype)\n",
    "X_test = X_test.astype(dtype)  / 255.0\n",
    "y_test = y_test.astype(dtype)\n",
    "\n",
    "X_train = np.reshape(X_train, (-1, 3072))\n",
    "X_test = np.reshape(X_test, (-1, 3072))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSRegularizer(tf.keras.regularizers.Regularizer):\n",
    "    def __init__(self, l1):\n",
    "        self.l1 = l1\n",
    "\n",
    "    def __call__(self, x):\n",
    "        scaling_vector = tf.cumsum(tf.constant(self.l1, shape=(x.shape[-1],), dtype=dtype), axis=0) - self.l1\n",
    "        return tf.reduce_sum(scaling_vector * tf.abs(x))\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'l1': float(self.l1)}\n",
    "\n",
    "\n",
    "class SSLayer(tf.keras.Model):\n",
    "    def __init__(self, input_units, units, activation, l1, kernel_initializer, bias_initializer):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "        self.l1 = l1\n",
    "        self.kernel_initializer = tf.keras.initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = tf.keras.initializers.get(bias_initializer)\n",
    "        self.regularizer = SSRegularizer(self.l1)\n",
    "        \n",
    "        self.W = tf.Variable(\n",
    "            name='W',\n",
    "            initial_value=self.kernel_initializer(shape=(input_units, units), dtype=dtype),\n",
    "            trainable=True)\n",
    "        \n",
    "        self.b = tf.Variable(\n",
    "            name='b',\n",
    "            initial_value=self.bias_initializer(shape=(units,), dtype=dtype),\n",
    "            trainable=True)\n",
    "        \n",
    "        self.add_loss(lambda: self.regularizer(self.W))\n",
    "        self.add_loss(lambda: self.regularizer(self.b))\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return self.activation(tf.matmul(inputs, self.W) + self.b)\n",
    "\n",
    "\n",
    "class SSModel(tf.keras.Model):\n",
    "    def __init__(self, layer_sizes, activation=None, l1=0.01, kernel_initializer='glorot_uniform', bias_initializer='zeros'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.sslayers = list()\n",
    "        for l in range(len(layer_sizes) - 1):\n",
    "            input_units = layer_sizes[l]\n",
    "            units = layer_sizes[l + 1]\n",
    "            if l < len(layer_sizes) - 2:\n",
    "                layer = SSLayer(input_units, units, activation, l1, kernel_initializer, bias_initializer)\n",
    "            else:  # Last layer\n",
    "                layer = SSLayer(input_units, units, 'softmax', 0., kernel_initializer, bias_initializer)\n",
    "            self.sslayers.append(layer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.sslayers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def get_layer_sizes(self):\n",
    "        layer_sizes = list()\n",
    "        for l in range(len(self.sslayers)):\n",
    "            layer = self.sslayers[l]\n",
    "            layer_sizes.append(layer.W.shape[0])\n",
    "            if l == len(self.sslayers) - 1:  # Last layer\n",
    "                layer_sizes.append(layer.W.shape[1])\n",
    "        return layer_sizes\n",
    "    \n",
    "    def print_neurons(self):\n",
    "        for layer in self.sslayers:\n",
    "            print(get_param_string(layer.W, layer.b))\n",
    "    \n",
    "    def prune(self, threshold=0.001):\n",
    "        for l in range(len(self.sslayers) - 1):\n",
    "            layer1 = self.sslayers[l]\n",
    "            layer2 = self.sslayers[l + 1]\n",
    "            \n",
    "            W1 = layer1.W.value()\n",
    "            b1 = layer1.b.value()\n",
    "            W2 = layer2.W.value()\n",
    "\n",
    "            weights_with_biases = tf.concat([W1, tf.reshape(b1, (1, -1))], axis=0)\n",
    "            neurons_are_active = tf.math.reduce_max(tf.abs(weights_with_biases), axis=0) >= threshold\n",
    "            active_neurons_indices = tf.reshape(tf.where(neurons_are_active), (-1,))\n",
    "            \n",
    "            new_W1 = tf.gather(W1, active_neurons_indices, axis=1)\n",
    "            new_b1 = tf.gather(b1, active_neurons_indices, axis=0)\n",
    "            new_W2 = tf.gather(W2, active_neurons_indices, axis=0)\n",
    "\n",
    "            layer1.W = tf.Variable(name='W', initial_value=new_W1, trainable=True)\n",
    "            layer1.b = tf.Variable(name='b', initial_value=new_b1, trainable=True)\n",
    "            layer2.W = tf.Variable(name='W', initial_value=new_W2, trainable=True)\n",
    "    \n",
    "    def grow(self, min_new_neurons=5, scaling_factor=0.001):   \n",
    "        for l in range(len(self.sslayers) - 1):\n",
    "            layer1 = self.sslayers[l]\n",
    "            layer2 = self.sslayers[l + 1]\n",
    "       \n",
    "            W1 = layer1.W.value()\n",
    "            b1 = layer1.b.value()\n",
    "            W2 = layer2.W.value()\n",
    "\n",
    "            n_new_neurons = max(min_new_neurons, int(W1.shape[1] * 0.2))\n",
    "\n",
    "            W1_growth = layer1.kernel_initializer(shape=(W1.shape[0], W1.shape[1] + n_new_neurons), dtype=dtype)[:, -n_new_neurons:] * scaling_factor\n",
    "            b1_growth = layer1.bias_initializer(shape=(n_new_neurons,), dtype=dtype)\n",
    "            W2_growth = layer2.kernel_initializer(shape=(W2.shape[0] + n_new_neurons, W2.shape[1]), dtype=dtype)[-n_new_neurons:, :]\n",
    "\n",
    "            new_W1 = tf.concat([W1, W1_growth], axis=1)\n",
    "            new_b1 = tf.concat([b1, b1_growth], axis=0)\n",
    "            new_W2 = tf.concat([W2, W2_growth], axis=0)\n",
    "\n",
    "            layer1.W = tf.Variable(name='W1', initial_value=new_W1, trainable=True)\n",
    "            layer1.b = tf.Variable(name='b1', initial_value=new_b1, trainable=True)\n",
    "            layer2.W = tf.Variable(name='W2', initial_value=new_W2, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param_string(weights, bias):\n",
    "    param_string = \"\"\n",
    "    weights_with_bias = tf.concat([weights, tf.reshape(bias, (1, -1))], axis=0)\n",
    "    max_parameters = tf.math.reduce_max(tf.abs(weights_with_bias), axis=0).numpy()\n",
    "    magnitudes = np.floor(np.log10(max_parameters))\n",
    "    for m in magnitudes:\n",
    "        if m > 0:\n",
    "            m = 0\n",
    "        param_string += str(int(-m))\n",
    "    return param_string\n",
    "\n",
    "\n",
    "def print_epoch_statistics(model):\n",
    "    y_pred = model(X_train)\n",
    "    loss = tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(y_train, y_pred))\n",
    "    accuracy = tf.reduce_mean(tf.keras.metrics.sparse_categorical_accuracy(y_train, y_pred))\n",
    "    \n",
    "    y_pred_val = model(X_test)\n",
    "    val_loss = tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(y_test, y_pred_val))\n",
    "    val_accuracy = tf.reduce_mean(tf.keras.metrics.sparse_categorical_accuracy(y_test, y_pred_val))\n",
    "    print(f\"loss: {loss} - accuracy: {accuracy} - val_loss: {val_loss} - val_accuracy: {val_accuracy}\")\n",
    "    print(f\"layer sizes: {model.get_layer_sizes()}\")\n",
    "    model.print_neurons()\n",
    "    \n",
    "#     print(f\"units: {model.W1.shape[1]} - {get_param_string(model.W1)}\")\n",
    "    \n",
    "\n",
    "def train_model(model, optimizer, epochs, batch_size, train_dataset):\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        \n",
    "        print(\"Before growing:\")\n",
    "        print_epoch_statistics(model)\n",
    "        model.grow(min_new_neurons=10, scaling_factor=0.001)\n",
    "        print(\"After growing:\")\n",
    "        print_epoch_statistics(model)\n",
    "\n",
    "        for step, (x_batch, y_batch) in enumerate(train_dataset):\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_pred = model(x_batch, training=True)\n",
    "                loss_value = tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(y_batch, y_pred))\n",
    "                loss_value += sum(model.losses)\n",
    "\n",
    "            grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        \n",
    "        print(\"Before pruning:\")\n",
    "        print_epoch_statistics(model)\n",
    "        model.prune(threshold=0.001)\n",
    "        print(\"After pruning:\")\n",
    "        print_epoch_statistics(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Before growing:\n",
      "loss: 2.5018150806427 - accuracy: 0.10633999854326248 - val_loss: 2.501587390899658 - val_accuracy: 0.10719999670982361\n",
      "layer sizes: [3072, 100, 100, 10]\n",
      "2222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "1111111111\n",
      "After growing:\n",
      "loss: 2.501856565475464 - accuracy: 0.10639999806880951 - val_loss: 2.501626968383789 - val_accuracy: 0.10750000178813934\n",
      "layer sizes: [3072, 120, 120, 10]\n",
      "222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222255555555555555555555\n",
      "111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111144444444444444444444\n",
      "1111111111\n",
      "Before pruning:\n",
      "loss: 1.9681110382080078 - accuracy: 0.25519999861717224 - val_loss: 1.9679940938949585 - val_accuracy: 0.2513999938964844\n",
      "layer sizes: [3072, 120, 120, 10]\n",
      "233134331443443133444444444443444444444344444443444444444444444444444444444443444444444444444444444444444444444444444444\n",
      "111111111111131132312111223221322324222312112143312313411423411243332322223232444444333332232233144333433223324422433233\n",
      "1111111111\n",
      "After pruning:\n",
      "loss: 1.9623172283172607 - accuracy: 0.2587200105190277 - val_loss: 1.9621554613113403 - val_accuracy: 0.25369998812675476\n",
      "layer sizes: [3072, 17, 102, 10]\n",
      "23313331331333333\n",
      "111111121111131132313111223221322322223121121331231311231123332322223232333332232233133333223322233233\n",
      "1111111111\n",
      "Epoch 2/20\n",
      "Before growing:\n",
      "loss: 1.9623172283172607 - accuracy: 0.2587200105190277 - val_loss: 1.9621554613113403 - val_accuracy: 0.25369998812675476\n",
      "layer sizes: [3072, 17, 102, 10]\n",
      "23313331331333333\n",
      "111111121111131132313111223221322322223121121331231311231123332322223232333332232233133333223322233233\n",
      "1111111111\n",
      "After growing:\n",
      "loss: 1.9624611139297485 - accuracy: 0.2584800124168396 - val_loss: 1.9622999429702759 - val_accuracy: 0.2533000111579895\n",
      "layer sizes: [3072, 27, 122, 10]\n",
      "233133313313333335555555555\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111144444444444444444444\n",
      "1111111111\n",
      "Before pruning:\n",
      "loss: 1.9631609916687012 - accuracy: 0.24993999302387238 - val_loss: 1.963330864906311 - val_accuracy: 0.2524000108242035\n",
      "layer sizes: [3072, 27, 122, 10]\n",
      "233143314413343433334343333\n",
      "11111112111111113231311121212132131222312112143124231234123334343242443334333324433333433333323433433333234334344333343334\n",
      "1111111111\n",
      "After pruning:\n",
      "loss: 1.9631344079971313 - accuracy: 0.24981999397277832 - val_loss: 1.9632956981658936 - val_accuracy: 0.25220000743865967\n",
      "layer sizes: [3072, 20, 102, 10]\n",
      "23313311333333333333\n",
      "111111121111111232313111212121321312223121121312231231233333223333333233333333333233333333233333333333\n",
      "1111111111\n",
      "Epoch 3/20\n",
      "Before growing:\n",
      "loss: 1.9631344079971313 - accuracy: 0.24981999397277832 - val_loss: 1.9632956981658936 - val_accuracy: 0.25220000743865967\n",
      "layer sizes: [3072, 20, 102, 10]\n",
      "23313311333333333333\n",
      "111111121111111232313111212121321312223121121312231231233333223333333233333333333233333333233333333333\n",
      "1111111111\n",
      "After growing:\n",
      "loss: 1.963019847869873 - accuracy: 0.25025999546051025 - val_loss: 1.963180661201477 - val_accuracy: 0.2522999942302704\n",
      "layer sizes: [3072, 30, 122, 10]\n",
      "233133113333333333335555555555\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111144444444444444444444\n",
      "1111111111\n",
      "Before pruning:\n",
      "loss: 1.9351097345352173 - accuracy: 0.2663800120353699 - val_loss: 1.9320517778396606 - val_accuracy: 0.2644999921321869\n",
      "layer sizes: [3072, 30, 122, 10]\n",
      "233134111434343333333343343443\n",
      "11111112121113134111411123322111221112412122222223134122433433342344222443333422342334333334344333334334433343333333333433\n",
      "1111111111\n",
      "After pruning:\n",
      "loss: 1.9349218606948853 - accuracy: 0.26649999618530273 - val_loss: 1.9318275451660156 - val_accuracy: 0.2662999927997589\n",
      "layer sizes: [3072, 22, 100, 10]\n",
      "2331311133333333333333\n",
      "1111121212111313131111233221122221121212222222313122333332322233332232333333333333333333333333333333\n",
      "1111111111\n",
      "Epoch 4/20\n",
      "Before growing:\n",
      "loss: 1.9349218606948853 - accuracy: 0.26649999618530273 - val_loss: 1.9318275451660156 - val_accuracy: 0.2662999927997589\n",
      "layer sizes: [3072, 22, 100, 10]\n",
      "2331311133333333333333\n",
      "1111121212111313131111233221122221121212222222313122333332322233332232333333333333333333333333333333\n",
      "1111111111\n",
      "After growing:\n",
      "loss: 1.934968113899231 - accuracy: 0.266400009393692 - val_loss: 1.931882381439209 - val_accuracy: 0.2662999927997589\n",
      "layer sizes: [3072, 32, 120, 10]\n",
      "23313111333333333333335555555555\n",
      "111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111144444444444444444444\n",
      "1111111111\n",
      "Before pruning:\n",
      "loss: 1.9712121486663818 - accuracy: 0.27250000834465027 - val_loss: 1.9676953554153442 - val_accuracy: 0.2694000005722046\n",
      "layer sizes: [3072, 32, 120, 10]\n",
      "23444111443444343344433433333333\n",
      "111111121111231112111112132213113332121333332231311233333333323333222244344433333434444333334333333433343333433333333334\n",
      "1111111111\n",
      "After pruning:\n",
      "loss: 1.9710403680801392 - accuracy: 0.2722800076007843 - val_loss: 1.9675183296203613 - val_accuracy: 0.26919999718666077\n",
      "layer sizes: [3072, 19, 105, 10]\n",
      "2311133333333333333\n",
      "111111121111231112111112132213113332121333332231311233333333323333222233333333333333333333333333333333333\n",
      "1111111111\n",
      "Epoch 5/20\n",
      "Before growing:\n",
      "loss: 1.9710403680801392 - accuracy: 0.2722800076007843 - val_loss: 1.9675183296203613 - val_accuracy: 0.26919999718666077\n",
      "layer sizes: [3072, 19, 105, 10]\n",
      "2311133333333333333\n",
      "111111121111231112111112132213113332121333332231311233333333323333222233333333333333333333333333333333333\n",
      "1111111111\n",
      "After growing:\n",
      "loss: 1.9708681106567383 - accuracy: 0.2724199891090393 - val_loss: 1.9673511981964111 - val_accuracy: 0.2694999873638153\n",
      "layer sizes: [3072, 29, 126, 10]\n",
      "23111333333333333335555555555\n",
      "111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111444444444444444444444\n",
      "1111111111\n",
      "Before pruning:\n",
      "loss: 1.9345017671585083 - accuracy: 0.28812000155448914 - val_loss: 1.9289175271987915 - val_accuracy: 0.28769999742507935\n",
      "layer sizes: [3072, 29, 126, 10]\n",
      "23111423443341334443431434433\n",
      "111111111111111113211113223111134112331231433441321144413334333444333233333343343344323334333433444433344334333443333343333434\n",
      "1111111111\n",
      "After pruning:\n",
      "loss: 1.934671401977539 - accuracy: 0.28821998834609985 - val_loss: 1.929072618484497 - val_accuracy: 0.28790000081062317\n",
      "layer sizes: [3072, 18, 97, 10]\n",
      "231112333133331333\n",
      "1111111111111111132111132231111311233123133132111333333333233333333333233333333333333333333333333\n",
      "1111111111\n",
      "Epoch 6/20\n",
      "Before growing:\n",
      "loss: 1.934671401977539 - accuracy: 0.28821998834609985 - val_loss: 1.929072618484497 - val_accuracy: 0.28790000081062317\n",
      "layer sizes: [3072, 18, 97, 10]\n",
      "231112333133331333\n",
      "1111111111111111132111132231111311233123133132111333333333233333333333233333333333333333333333333\n",
      "1111111111\n",
      "After growing:\n",
      "loss: 1.9345799684524536 - accuracy: 0.28828001022338867 - val_loss: 1.9289859533309937 - val_accuracy: 0.28790000081062317\n",
      "layer sizes: [3072, 28, 116, 10]\n",
      "2311123331333313335555555555\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111114444444444444444444\n",
      "1111111111\n",
      "Before pruning:\n",
      "loss: 1.8647757768630981 - accuracy: 0.3237999975681305 - val_loss: 1.8610742092132568 - val_accuracy: 0.32179999351501465\n",
      "layer sizes: [3072, 28, 116, 10]\n",
      "2331114333333333444144333433\n",
      "11111111121113111221111311111111111111233321322223132231344333134334442443334433433334333334334333333334342243333344\n",
      "1111111111\n",
      "After pruning:\n",
      "loss: 1.8649412393569946 - accuracy: 0.32363998889923096 - val_loss: 1.8612430095672607 - val_accuracy: 0.3212999999523163\n",
      "layer sizes: [3072, 21, 97, 10]\n",
      "233111333333333133333\n",
      "1111111112111311122111131111111111111123332132222313223133331333233333333333333333333333332233333\n",
      "1111111111\n",
      "Epoch 7/20\n",
      "Before growing:\n",
      "loss: 1.8649412393569946 - accuracy: 0.32363998889923096 - val_loss: 1.8612430095672607 - val_accuracy: 0.3212999999523163\n",
      "layer sizes: [3072, 21, 97, 10]\n",
      "233111333333333133333\n",
      "1111111112111311122111131111111111111123332132222313223133331333233333333333333333333333332233333\n",
      "1111111111\n",
      "After growing:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.8649706840515137 - accuracy: 0.3234800100326538 - val_loss: 1.861268401145935 - val_accuracy: 0.32120001316070557\n",
      "layer sizes: [3072, 31, 116, 10]\n",
      "2331113333333331333335555555555\n",
      "11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111114444444444444444444\n",
      "1111111111\n",
      "Before pruning:\n",
      "loss: 1.8825409412384033 - accuracy: 0.30928000807762146 - val_loss: 1.8808683156967163 - val_accuracy: 0.3037000000476837\n",
      "layer sizes: [3072, 31, 116, 10]\n",
      "2331113433434413343343334333333\n",
      "11111111111112111211121333111212112133132331312333332332334434331334333334344434333333342432333344323433333433444333\n",
      "1111111111\n",
      "After pruning:\n",
      "loss: 1.8827027082443237 - accuracy: 0.3091199994087219 - val_loss: 1.881025791168213 - val_accuracy: 0.30410000681877136\n",
      "layer sizes: [3072, 24, 98, 10]\n",
      "233111333313333333333333\n",
      "11111111111112111211121333111212112133132331312333332332333331333333333333333323233333233333333333\n",
      "1111111111\n",
      "Epoch 8/20\n",
      "Before growing:\n",
      "loss: 1.8827027082443237 - accuracy: 0.3091199994087219 - val_loss: 1.881025791168213 - val_accuracy: 0.30410000681877136\n",
      "layer sizes: [3072, 24, 98, 10]\n",
      "233111333313333333333333\n",
      "11111111111112111211121333111212112133132331312333332332333331333333333333333323233333233333333333\n",
      "1111111111\n",
      "After growing:\n",
      "loss: 1.8826818466186523 - accuracy: 0.30913999676704407 - val_loss: 1.881007432937622 - val_accuracy: 0.30399999022483826\n",
      "layer sizes: [3072, 34, 117, 10]\n",
      "2331113333133333333333335555555555\n",
      "111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111114444444444444444444\n",
      "1111111111\n",
      "Before pruning:\n",
      "loss: 1.8533153533935547 - accuracy: 0.32651999592781067 - val_loss: 1.8506242036819458 - val_accuracy: 0.31869998574256897\n",
      "layer sizes: [3072, 34, 117, 10]\n",
      "2331113334144433433344343433433343\n",
      "111111111111121212111121322121142122311312313333231333223443333332434433333433333343333333433433333433433344343442333\n",
      "1111111111\n",
      "After pruning:\n",
      "loss: 1.8527735471725464 - accuracy: 0.32642000913619995 - val_loss: 1.850144863128662 - val_accuracy: 0.3179999887943268\n",
      "layer sizes: [3072, 23, 100, 10]\n",
      "23311133313333333333333\n",
      "1111111111111212121111213221211212231131231333323133322333333323333333333333333333333333333333332333\n",
      "1111111111\n",
      "Epoch 9/20\n",
      "Before growing:\n",
      "loss: 1.8527735471725464 - accuracy: 0.32642000913619995 - val_loss: 1.850144863128662 - val_accuracy: 0.3179999887943268\n",
      "layer sizes: [3072, 23, 100, 10]\n",
      "23311133313333333333333\n",
      "1111111111111212121111213221211212231131231333323133322333333323333333333333333333333333333333332333\n",
      "1111111111\n",
      "After growing:\n",
      "loss: 1.8528915643692017 - accuracy: 0.32635998725891113 - val_loss: 1.8502558469772339 - val_accuracy: 0.31839999556541443\n",
      "layer sizes: [3072, 33, 120, 10]\n",
      "233111333133333333333335555555555\n",
      "111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111144444444444444444444\n",
      "1111111111\n",
      "Before pruning:\n",
      "loss: 1.8476275205612183 - accuracy: 0.3375200033187866 - val_loss: 1.8461873531341553 - val_accuracy: 0.33660000562667847\n",
      "layer sizes: [3072, 33, 120, 10]\n",
      "233111443133333343344334333333334\n",
      "111111111111131112111233314111111431113213133423433342243332323433331333334333242324343333333333313343343443333343344344\n",
      "1111111111\n",
      "After pruning:\n",
      "loss: 1.8485029935836792 - accuracy: 0.33739998936653137 - val_loss: 1.8470627069473267 - val_accuracy: 0.33629998564720154\n",
      "layer sizes: [3072, 26, 100, 10]\n",
      "23311131333333333333333333\n",
      "1111111111111311121112333111111131113213133233332233323233333133333333223233333333333313333333333333\n",
      "1111111111\n",
      "Epoch 10/20\n",
      "Before growing:\n",
      "loss: 1.8485029935836792 - accuracy: 0.33739998936653137 - val_loss: 1.8470627069473267 - val_accuracy: 0.33629998564720154\n",
      "layer sizes: [3072, 26, 100, 10]\n",
      "23311131333333333333333333\n",
      "1111111111111311121112333111111131113213133233332233323233333133333333223233333333333313333333333333\n",
      "1111111111\n",
      "After growing:\n",
      "loss: 1.848545789718628 - accuracy: 0.3373199999332428 - val_loss: 1.8471046686172485 - val_accuracy: 0.3361999988555908\n",
      "layer sizes: [3072, 36, 120, 10]\n",
      "233111313333333333333333335555555555\n",
      "111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111144444444444444444444\n",
      "1111111111\n",
      "Before pruning:\n",
      "loss: 1.8284175395965576 - accuracy: 0.3337399959564209 - val_loss: 1.8284600973129272 - val_accuracy: 0.32749998569488525\n",
      "layer sizes: [3072, 36, 120, 10]\n",
      "223111313343333433333333344433344443\n",
      "111111111111121111111132411112113421434413232333333333434333433433334333334333344333443433434344244344443333443443434443\n",
      "1111111111\n",
      "After pruning:\n",
      "loss: 1.827892780303955 - accuracy: 0.33414000272750854 - val_loss: 1.8279199600219727 - val_accuracy: 0.3287000060081482\n",
      "layer sizes: [3072, 27, 86, 10]\n",
      "223111313333333333333333333\n",
      "11111111111112111111113211212113213132323333333333333333333333333333333333332333333333\n",
      "1111111111\n",
      "Epoch 11/20\n",
      "Before growing:\n",
      "loss: 1.827892780303955 - accuracy: 0.33414000272750854 - val_loss: 1.8279199600219727 - val_accuracy: 0.3287000060081482\n",
      "layer sizes: [3072, 27, 86, 10]\n",
      "223111313333333333333333333\n",
      "11111111111112111111113211212113213132323333333333333333333333333333333333332333333333\n",
      "1111111111\n",
      "After growing:\n",
      "loss: 1.8278489112854004 - accuracy: 0.3341200053691864 - val_loss: 1.8278769254684448 - val_accuracy: 0.3287000060081482\n",
      "layer sizes: [3072, 37, 103, 10]\n",
      "2231113133333333333333333335555555555\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111144444444444444444\n",
      "1111111111\n",
      "Before pruning:\n",
      "loss: 1.8311066627502441 - accuracy: 0.33823999762535095 - val_loss: 1.828344702720642 - val_accuracy: 0.3382999897003174\n",
      "layer sizes: [3072, 37, 103, 10]\n",
      "2331113132343344333343433343433433433\n",
      "1111111111111213111111333111221311213233233323343334334233333333444333333333333433343323344343324233333\n",
      "1111111111\n",
      "After pruning:\n",
      "loss: 1.8307034969329834 - accuracy: 0.33814001083374023 - val_loss: 1.8278812170028687 - val_accuracy: 0.33869999647140503\n",
      "layer sizes: [3072, 28, 91, 10]\n",
      "2331113132333333333333333333\n",
      "1111111111111213111112333111221311213233233323333333233333333333333333333333332333332233333\n",
      "1111111111\n",
      "Epoch 12/20\n",
      "Before growing:\n",
      "loss: 1.8307034969329834 - accuracy: 0.33814001083374023 - val_loss: 1.8278812170028687 - val_accuracy: 0.33869999647140503\n",
      "layer sizes: [3072, 28, 91, 10]\n",
      "2331113132333333333333333333\n",
      "1111111111111213111112333111221311213233233323333333233333333333333333333333332333332233333\n",
      "1111111111\n",
      "After growing:\n",
      "loss: 1.830668568611145 - accuracy: 0.33814001083374023 - val_loss: 1.8278398513793945 - val_accuracy: 0.33869999647140503\n",
      "layer sizes: [3072, 38, 109, 10]\n",
      "23311131323333333333333333335555555555\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111444444444444444444\n",
      "1111111111\n",
      "Before pruning:\n",
      "loss: 1.8475852012634277 - accuracy: 0.3304400146007538 - val_loss: 1.8463079929351807 - val_accuracy: 0.33000001311302185\n",
      "layer sizes: [3072, 38, 109, 10]\n",
      "24411131333433333443343433443333334344\n",
      "0111111111111313131113233131231331323333333333444334334332333343433433433333233333333334343334332434323344343\n",
      "1111111111\n",
      "After pruning:\n",
      "loss: 1.8481723070144653 - accuracy: 0.33028000593185425 - val_loss: 1.846849799156189 - val_accuracy: 0.3294999897480011\n",
      "layer sizes: [3072, 26, 92, 10]\n",
      "21113133333333333333333333\n",
      "01111111111113131311132331312313313233333333333333332333333333333332333333333333333323323333\n",
      "1111111111\n",
      "Epoch 13/20\n",
      "Before growing:\n",
      "loss: 1.8481723070144653 - accuracy: 0.33028000593185425 - val_loss: 1.846849799156189 - val_accuracy: 0.3294999897480011\n",
      "layer sizes: [3072, 26, 92, 10]\n",
      "21113133333333333333333333\n",
      "01111111111113131311132331312313313233333333333333332333333333333332333333333333333323323333\n",
      "1111111111\n",
      "After growing:\n",
      "loss: 1.8481453657150269 - accuracy: 0.33028000593185425 - val_loss: 1.8468284606933594 - val_accuracy: 0.329800009727478\n",
      "layer sizes: [3072, 36, 110, 10]\n",
      "211131333333333333333333335555555555\n",
      "01111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111444444444444444444\n",
      "1111111111\n",
      "Before pruning:\n",
      "loss: 1.8060383796691895 - accuracy: 0.34634000062942505 - val_loss: 1.8064374923706055 - val_accuracy: 0.33869999647140503\n",
      "layer sizes: [3072, 36, 110, 10]\n",
      "201131333433334333433333333344334343\n",
      "01111111111122122311132333212213114133333443343332343333434333333433333323343342333333334333333333333444233333\n",
      "1111111111\n",
      "After pruning:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.8060723543167114 - accuracy: 0.3462800085544586 - val_loss: 1.8064124584197998 - val_accuracy: 0.33959999680519104\n",
      "layer sizes: [3072, 29, 96, 10]\n",
      "20113133333333333333333333333\n",
      "011111111111221223111323332122132113333333333233333333333333333323333233333333333333333333233333\n",
      "1111111111\n",
      "Epoch 14/20\n",
      "Before growing:\n",
      "loss: 1.8060723543167114 - accuracy: 0.3462800085544586 - val_loss: 1.8064124584197998 - val_accuracy: 0.33959999680519104\n",
      "layer sizes: [3072, 29, 96, 10]\n",
      "20113133333333333333333333333\n",
      "011111111111221223111323332122132113333333333233333333333333333323333233333333333333333333233333\n",
      "1111111111\n",
      "After growing:\n",
      "loss: 1.806084394454956 - accuracy: 0.34615999460220337 - val_loss: 1.8064199686050415 - val_accuracy: 0.33959999680519104\n",
      "layer sizes: [3072, 39, 115, 10]\n",
      "201131333333333333333333333335555555555\n",
      "0111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111114444444444444444444\n",
      "1111111111\n",
      "Before pruning:\n",
      "loss: 1.7975218296051025 - accuracy: 0.3517799973487854 - val_loss: 1.7980268001556396 - val_accuracy: 0.3465999960899353\n",
      "layer sizes: [3072, 39, 115, 10]\n",
      "201131344343344333333333443433443434443\n",
      "0111111111112321231113343231331322133434323434343344323333333333243233232333334333323444433444333333333444444334433\n",
      "1111111111\n",
      "After pruning:\n",
      "loss: 1.7979692220687866 - accuracy: 0.35203999280929565 - val_loss: 1.7983894348144531 - val_accuracy: 0.3458000123500824\n",
      "layer sizes: [3072, 25, 90, 10]\n",
      "2011313333333333333333333\n",
      "011111111111232323111333231331322133332333333233333333332323323233333333323333333333333333\n",
      "1111111111\n",
      "Epoch 15/20\n",
      "Before growing:\n",
      "loss: 1.7979692220687866 - accuracy: 0.35203999280929565 - val_loss: 1.7983894348144531 - val_accuracy: 0.3458000123500824\n",
      "layer sizes: [3072, 25, 90, 10]\n",
      "2011313333333333333333333\n",
      "011111111111232323111333231331322133332333333233333333332323323233333333323333333333333333\n",
      "1111111111\n",
      "After growing:\n",
      "loss: 1.7979657649993896 - accuracy: 0.35203999280929565 - val_loss: 1.798387050628662 - val_accuracy: 0.3456000089645386\n",
      "layer sizes: [3072, 35, 108, 10]\n",
      "20113133333333333333333335555555555\n",
      "011111111111111111111111111111111111111111111111111111111111111111111111111111111111111111444444444444444444\n",
      "1111111111\n",
      "Before pruning:\n",
      "loss: 1.823235034942627 - accuracy: 0.33838000893592834 - val_loss: 1.824925422668457 - val_accuracy: 0.33059999346733093\n",
      "layer sizes: [3072, 35, 108, 10]\n",
      "20111133333433433333343433333343333\n",
      "010111111111121213111333121231411233333334433433323334333323333333333333324324332334333433332343333333434433\n",
      "1111111111\n",
      "After pruning:\n",
      "loss: 1.8230736255645752 - accuracy: 0.33842000365257263 - val_loss: 1.824785590171814 - val_accuracy: 0.3301999866962433\n",
      "layer sizes: [3072, 30, 95, 10]\n",
      "201111333333333333333333333333\n",
      "01011111111112121311133312123111233333333333323333333233333333333333232332333333333233333333333\n",
      "1111111111\n",
      "Epoch 16/20\n",
      "Before growing:\n",
      "loss: 1.8230736255645752 - accuracy: 0.33842000365257263 - val_loss: 1.824785590171814 - val_accuracy: 0.3301999866962433\n",
      "layer sizes: [3072, 30, 95, 10]\n",
      "201111333333333333333333333333\n",
      "01011111111112121311133312123111233333333333323333333233333333333333232332333333333233333333333\n",
      "1111111111\n",
      "After growing:\n",
      "loss: 1.8230915069580078 - accuracy: 0.33827999234199524 - val_loss: 1.824805498123169 - val_accuracy: 0.3301999866962433\n",
      "layer sizes: [3072, 40, 114, 10]\n",
      "2011113333333333333333333333335555555555\n",
      "010111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111114444444444444444444\n",
      "1111111111\n",
      "Before pruning:\n",
      "loss: 1.81638503074646 - accuracy: 0.3434000015258789 - val_loss: 1.816998839378357 - val_accuracy: 0.3422999978065491\n",
      "layer sizes: [3072, 40, 114, 10]\n",
      "2011134344344433443434343344444433444444\n",
      "010111201111231322111334121131333433444333333443344334443433344333333433333333333433333334434334433333343444434433\n",
      "1111111111\n",
      "After pruning:\n",
      "loss: 1.8173190355300903 - accuracy: 0.3428800106048584 - val_loss: 1.817931056022644 - val_accuracy: 0.3431999981403351\n",
      "layer sizes: [3072, 17, 85, 10]\n",
      "20111333333333333\n",
      "0101112011112323221113312123133333333333333333333333333333333333333333333333333333333\n",
      "1111111111\n",
      "Epoch 17/20\n",
      "Before growing:\n",
      "loss: 1.8173190355300903 - accuracy: 0.3428800106048584 - val_loss: 1.817931056022644 - val_accuracy: 0.3431999981403351\n",
      "layer sizes: [3072, 17, 85, 10]\n",
      "20111333333333333\n",
      "0101112011112323221113312123133333333333333333333333333333333333333333333333333333333\n",
      "1111111111\n",
      "After growing:\n",
      "loss: 1.8174461126327515 - accuracy: 0.3428399860858917 - val_loss: 1.8180484771728516 - val_accuracy: 0.3433000147342682\n",
      "layer sizes: [3072, 27, 102, 10]\n",
      "201113333333333335555555555\n",
      "010111101111111111111111111111111111111111111111111111111111111111111111111111111111144444444444444444\n",
      "1111111111\n",
      "Before pruning:\n",
      "loss: 1.8245126008987427 - accuracy: 0.33340001106262207 - val_loss: 1.8284724950790405 - val_accuracy: 0.3292999863624573\n",
      "layer sizes: [3072, 27, 102, 10]\n",
      "201123333334343441333334344\n",
      "010111111111111122111331312312233343433133333443343344344333333333433333333343334334333323333323333334\n",
      "1111111111\n",
      "After pruning:\n",
      "loss: 1.824503779411316 - accuracy: 0.33348000049591064 - val_loss: 1.828462839126587 - val_accuracy: 0.3294999897480011\n",
      "layer sizes: [3072, 20, 88, 10]\n",
      "20112333333331333333\n",
      "0101111111111112221113313123122333333133333333333333333333333333333333333332333332333333\n",
      "1111111111\n",
      "Epoch 18/20\n",
      "Before growing:\n",
      "loss: 1.824503779411316 - accuracy: 0.33348000049591064 - val_loss: 1.828462839126587 - val_accuracy: 0.3294999897480011\n",
      "layer sizes: [3072, 20, 88, 10]\n",
      "20112333333331333333\n",
      "0101111111111112221113313123122333333133333333333333333333333333333333333332333332333333\n",
      "1111111111\n",
      "After growing:\n",
      "loss: 1.8245184421539307 - accuracy: 0.3336400091648102 - val_loss: 1.8284789323806763 - val_accuracy: 0.3296000063419342\n",
      "layer sizes: [3072, 30, 105, 10]\n",
      "201123333333313333335555555555\n",
      "010111111111111111111111111111111111111111111111111111111111111111111111111111111111111144444444444444444\n",
      "1111111111\n",
      "Before pruning:\n",
      "loss: 1.7946447134017944 - accuracy: 0.35089999437332153 - val_loss: 1.7970062494277954 - val_accuracy: 0.3443000018596649\n",
      "layer sizes: [3072, 30, 105, 10]\n",
      "201113344434433333433334333333\n",
      "010111111111211213111331211312233333333433333333433333323334433333443443334343423333333443334343333333333\n",
      "0111111111\n",
      "After pruning:\n",
      "loss: 1.794660210609436 - accuracy: 0.35089999437332153 - val_loss: 1.7970281839370728 - val_accuracy: 0.34439998865127563\n",
      "layer sizes: [3072, 23, 90, 10]\n",
      "20111333333333333333333\n",
      "010111111111211213111331211312233333333333333333333332333333333333332333333333333333333333\n",
      "0111111111\n",
      "Epoch 19/20\n",
      "Before growing:\n",
      "loss: 1.794660210609436 - accuracy: 0.35089999437332153 - val_loss: 1.7970281839370728 - val_accuracy: 0.34439998865127563\n",
      "layer sizes: [3072, 23, 90, 10]\n",
      "20111333333333333333333\n",
      "010111111111211213111331211312233333333333333333333332333333333333332333333333333333333333\n",
      "0111111111\n",
      "After growing:\n",
      "loss: 1.794630765914917 - accuracy: 0.35085999965667725 - val_loss: 1.7969881296157837 - val_accuracy: 0.3441999852657318\n",
      "layer sizes: [3072, 33, 108, 10]\n",
      "201113333333333333333335555555555\n",
      "010111111111111111111111111111111111111111111111111111111111111111111111111111111111111111444444444444444444\n",
      "0111111111\n",
      "Before pruning:\n",
      "loss: 1.8299834728240967 - accuracy: 0.3361000120639801 - val_loss: 1.8334046602249146 - val_accuracy: 0.3262999951839447\n",
      "layer sizes: [3072, 33, 108, 10]\n",
      "201114443333343343433333333433333\n",
      "010111111111213232121332212313323232424333333244234433334333334443433333333333233433334443343324333333333333\n",
      "0111111111\n",
      "After pruning:\n",
      "loss: 1.8293070793151855 - accuracy: 0.33654001355171204 - val_loss: 1.83272385597229 - val_accuracy: 0.3257000148296356\n",
      "layer sizes: [3072, 26, 91, 10]\n",
      "20111333333333333333333333\n",
      "0101111111112132321213322123133232322333333223333333333333333333333233333333332333333333333\n",
      "0111111111\n",
      "Epoch 20/20\n",
      "Before growing:\n",
      "loss: 1.8293070793151855 - accuracy: 0.33654001355171204 - val_loss: 1.83272385597229 - val_accuracy: 0.3257000148296356\n",
      "layer sizes: [3072, 26, 91, 10]\n",
      "20111333333333333333333333\n",
      "0101111111112132321213322123133232322333333223333333333333333333333233333333332333333333333\n",
      "0111111111\n",
      "After growing:\n",
      "loss: 1.8292551040649414 - accuracy: 0.3366599977016449 - val_loss: 1.8326773643493652 - val_accuracy: 0.32580000162124634\n",
      "layer sizes: [3072, 36, 109, 10]\n",
      "201113333333333333333333335555555555\n",
      "0101111111111111111111111111111111111111111111111111111111111111111111111111111111111111111444444444444444444\n",
      "0111111111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before pruning:\n",
      "loss: 1.8113493919372559 - accuracy: 0.34536001086235046 - val_loss: 1.8152164220809937 - val_accuracy: 0.3402000069618225\n",
      "layer sizes: [3072, 36, 109, 10]\n",
      "200113333333433334333333443343443343\n",
      "0101111011113124231233341133133331333333333333333334333333333333433333333333333333333443333343433333334334334\n",
      "0111111111\n",
      "After pruning:\n",
      "loss: 1.8110742568969727 - accuracy: 0.34544000029563904 - val_loss: 1.8149316310882568 - val_accuracy: 0.3400999903678894\n",
      "layer sizes: [3072, 28, 98, 10]\n",
      "2001133333333333333333333333\n",
      "01011110111131223123331133133331333333333333333333333333333333333333333333333333333333333333333333\n",
      "0111111111\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "model = SSModel(layer_sizes=[3072, 100, 100, 10], activation='relu', l1=0.0001, kernel_initializer='he_normal')\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "train_model(model, optimizer, epochs, batch_size, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
