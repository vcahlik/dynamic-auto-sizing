{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f_deAUKlniFk",
    "outputId": "434f0bdd-1358-46dc-adc2-aee14230789c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yKwUwV_NneIo"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from enum import Enum\n",
    "import imageio\n",
    "import hashlib\n",
    "import copy\n",
    "import time\n",
    "import abc\n",
    "import random\n",
    "import collections\n",
    "import itertools\n",
    "import pickle\n",
    "import datetime\n",
    "from sklearn import model_selection\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "dtype = 'float32'\n",
    "tf.keras.backend.set_floatx(dtype)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "UTZq4KMpneIv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# DATASETS\n",
    "################################################################################\n",
    "\n",
    "\n",
    "def get_dataset_sample(X, y, fraction, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)  # Set random seed\n",
    "    selection = np.random.choice([True, False], len(X), p=[fraction, 1 - fraction])\n",
    "    if seed is not None:\n",
    "        np.random.seed()  # Unset random seed\n",
    "    X_sampled = X[selection]\n",
    "    y_sampled = y[selection]\n",
    "    return X_sampled, y_sampled\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, X_train, y_train, X_test, y_test, shape, shape_flattened, fraction, vision=True, standardize=True):\n",
    "        if fraction is not None:\n",
    "            X_train, y_train = get_dataset_sample(X_train, y_train, fraction, seed=42)\n",
    "            X_test, y_test = get_dataset_sample(X_test, y_test, fraction, seed=42)\n",
    "        \n",
    "        X_train = X_train.astype(dtype)\n",
    "        y_train = y_train.astype(dtype)\n",
    "        X_test = X_test.astype(dtype)\n",
    "        y_test = y_test.astype(dtype)\n",
    "\n",
    "        if vision:\n",
    "            X_train = X_train / 255.0\n",
    "            X_test = X_test / 255.0\n",
    "\n",
    "        X_train = np.reshape(X_train, shape_flattened)\n",
    "        X_test = np.reshape(X_test, shape_flattened)\n",
    "        \n",
    "        X = np.concatenate((X_train, X_test), axis=0)\n",
    "        y = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "        if standardize:\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(X_train)  # Scaling each feature independently\n",
    "\n",
    "            X_norm = scaler.transform(X)\n",
    "            X_train_norm = scaler.transform(X_train)\n",
    "            X_test_norm = scaler.transform(X_test)\n",
    "        else:\n",
    "            X_norm = X.copy()\n",
    "            X_train_norm = X_train.copy()\n",
    "            X_test_norm = X_test.copy()\n",
    "\n",
    "        X_norm = np.reshape(X_norm, shape)\n",
    "        X_train_norm = np.reshape(X_train_norm, shape)\n",
    "        X_test_norm = np.reshape(X_test_norm, shape)\n",
    "\n",
    "        del X, X_train, X_test\n",
    "        \n",
    "        # Shuffle X_norm and y\n",
    "        assert len(X_norm) == len(y)\n",
    "        p = np.random.permutation(len(X_norm))\n",
    "        X_norm, y = X_norm[p], y[p]\n",
    "\n",
    "        self.X_norm = X_norm\n",
    "        self.y = y\n",
    "        self.X_train_norm = X_train_norm\n",
    "        self.y_train = y_train\n",
    "        self.X_test_norm = X_test_norm\n",
    "        self.y_test = y_test\n",
    "\n",
    "\n",
    "def get_cifar_10_dataset(fraction=None):\n",
    "    cifar10 = tf.keras.datasets.cifar10\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "    shape = (-1, 32, 32, 3)\n",
    "    shape_flattened = (-1, 3072)  # Scaling each feature independently\n",
    "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened, fraction=fraction)\n",
    "\n",
    "\n",
    "def get_cifar_100_dataset(fraction=None):\n",
    "    cifar100 = tf.keras.datasets.cifar100\n",
    "    (X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
    "    shape = (-1, 32, 32, 3)\n",
    "    shape_flattened = (-1, 3072)  # Scaling each feature independently\n",
    "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened, fraction=fraction)\n",
    "\n",
    "\n",
    "def get_svhn_dataset(fraction=None):\n",
    "    from urllib.request import urlretrieve\n",
    "    from scipy import io\n",
    "\n",
    "    train_filename, _ = urlretrieve('http://ufldl.stanford.edu/housenumbers/train_32x32.mat')\n",
    "    test_filename, _ = urlretrieve('http://ufldl.stanford.edu/housenumbers/test_32x32.mat')\n",
    "\n",
    "    X_train = io.loadmat(train_filename, variable_names='X').get('X')\n",
    "    y_train = io.loadmat(train_filename, variable_names='y').get('y')\n",
    "    X_test = io.loadmat(test_filename, variable_names='X').get('X')\n",
    "    y_test = io.loadmat(test_filename, variable_names='y').get('y')\n",
    "\n",
    "    X_train = np.moveaxis(X_train, -1, 0)\n",
    "    y_train -= 1\n",
    "    X_test = np.moveaxis(X_test, -1, 0)\n",
    "    y_test -= 1\n",
    "\n",
    "    shape = (-1, 32, 32, 3)\n",
    "    shape_flattened = (-1, 3072)  # Scaling each feature independently\n",
    "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened, fraction=fraction)\n",
    "\n",
    "\n",
    "def get_tiny_imagenet_dataset(fraction=None):\n",
    "    \"\"\"\n",
    "    Original source: https://github.com/sonugiri1043/Train_ResNet_On_Tiny_ImageNet/blob/master/Train_ResNet_On_Tiny_ImageNet.ipynb\n",
    "    Original author: sonugiri1043@gmail.com\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.isdir('IMagenet'):\n",
    "        ! git clone https://github.com/seshuad/IMagenet\n",
    "\n",
    "    print(\"Processing the downloaded dataset...\")\n",
    "\n",
    "    path = 'IMagenet/tiny-imagenet-200/'\n",
    "\n",
    "    id_dict = {}\n",
    "    for i, line in enumerate(open(path + 'wnids.txt', 'r')):\n",
    "        id_dict[line.replace('\\n', '')] = i\n",
    "\n",
    "    train_data = list()\n",
    "    test_data = list()\n",
    "    train_labels = list()\n",
    "    test_labels = list()\n",
    "\n",
    "    for key, value in id_dict.items():\n",
    "        train_data += [imageio.imread(path + 'train/{}/images/{}_{}.JPEG'.format(key, key, str(i)), pilmode='RGB') for i in range(500)]\n",
    "        train_labels_ = np.array([[0]*200]*500)\n",
    "        train_labels_[:, value] = 1\n",
    "        train_labels += train_labels_.tolist()\n",
    "\n",
    "    for line in open(path + 'val/val_annotations.txt'):\n",
    "        img_name, class_id = line.split('\\t')[:2]\n",
    "        test_data.append(imageio.imread(path + 'val/images/{}'.format(img_name), pilmode='RGB'))\n",
    "        test_labels_ = np.array([[0]*200])\n",
    "        test_labels_[0, id_dict[class_id]] = 1\n",
    "        test_labels += test_labels_.tolist()\n",
    "\n",
    "    X_train = np.array(train_data)\n",
    "    y_train = np.argmax(np.array(train_labels), axis=1)\n",
    "    X_test = np.array(test_data)\n",
    "    y_test = np.argmax(np.array(test_labels), axis=1)\n",
    "\n",
    "    shape = (-1, 64, 64, 3)\n",
    "    shape_flattened = (-1, 12288)  # Scaling each feature independently\n",
    "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened, fraction=fraction)\n",
    "\n",
    "\n",
    "def get_mnist_dataset(fraction=None):\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    shape = (-1, 28, 28, 1)\n",
    "    shape_flattened = (-1, 1)  # Scaling all features together\n",
    "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened, fraction=fraction)\n",
    "\n",
    "\n",
    "def get_fashion_mnist_dataset(fraction=None):\n",
    "    fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "    (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "    shape = (-1, 28, 28, 1)\n",
    "    shape_flattened = (-1, 1)  # Scaling all features together\n",
    "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened, fraction=fraction)\n",
    "\n",
    "\n",
    "def get_fifteen_puzzle_dataset(path=None, fraction=None):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    if path is None:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/gdrive')\n",
    "        path = 'gdrive/MyDrive/15-costs-v3.csv'\n",
    "    costs = pd.read_csv(path)\n",
    "\n",
    "    X_raw = costs.iloc[:,:-1].values\n",
    "    y = costs['cost'].values\n",
    "    X = np.apply_along_axis(lambda x: np.eye(16)[x].ravel(), 1, X_raw)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    del X, X_raw, y\n",
    "\n",
    "    shape = (-1, 256)\n",
    "    shape_flattened = (-1, 256)  # Scaling all features together\n",
    "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened, vision=False, fraction=fraction)\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# REGULARIZERS\n",
    "################################################################################\n",
    "\n",
    "\n",
    "class Regularizer(tf.keras.regularizers.Regularizer):\n",
    "    def __init__(self):\n",
    "        self.n_new_neurons = 0\n",
    "        self.scaling_tensor = None\n",
    "        self.set_regularization_penalty(0.)\n",
    "        self.set_regularization_method(None)\n",
    "    \n",
    "    def copy(self):\n",
    "        regularizer_copy = Regularizer.__new__(Regularizer)\n",
    "        regularizer_copy.n_new_neurons = self.n_new_neurons\n",
    "        regularizer_copy.scaling_tensor = self.scaling_tensor\n",
    "        regularizer_copy.set_regularization_penalty(self.regularization_penalty)\n",
    "        regularizer_copy.set_regularization_method(self.regularization_method)\n",
    "        return regularizer_copy\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if self.regularization_method is None or self.regularization_penalty == 0:\n",
    "            return 0\n",
    "        elif self.regularization_method == 'weighted_l1':\n",
    "            return self.weighted_l1(x)\n",
    "        elif self.regularization_method == 'weighted_l1_reordered':\n",
    "            return self.weighted_l1_reordered(x)\n",
    "        elif self.regularization_method == 'group_sparsity':\n",
    "            return self.group_sparsity(x)\n",
    "        elif self.regularization_method == 'l1':\n",
    "            return self.l1(x)\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Unknown regularization method {self.regularization_method}\")\n",
    "    \n",
    "    def weighted_l1(self, x):\n",
    "        # I.e. for a parameter matrix of 4 input and 10 output neurons:\n",
    "        #\n",
    "        # [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]\n",
    "        #\n",
    "        # the scaling tensor, as well as the resulting weighted values, could be:\n",
    "        #\n",
    "        # [[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
    "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
    "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
    "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]\n",
    "        #\n",
    "        # Therefore every additional output neuron is regularized more.\n",
    "\n",
    "        scaling_tensor = tf.cumsum(tf.constant(self.regularization_penalty, shape=x.shape, dtype=dtype), axis=-1)\n",
    "        weighted_values = scaling_tensor * tf.abs(x)\n",
    "        return tf.reduce_sum(weighted_values)\n",
    "    \n",
    "    def weighted_l1_reordered(self, x):\n",
    "        # I.e. for a parameter matrix of 4 input and 10 output neurons:\n",
    "        #\n",
    "        # [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]\n",
    "        #\n",
    "        # the scaling tensor, as well as the resulting weighted values, could be:\n",
    "        #\n",
    "        # [[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
    "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
    "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
    "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]\n",
    "        #\n",
    "        # Therefore every additional output neuron is regularized more.\n",
    "\n",
    "        if self.update_scaling_tensor:\n",
    "            scaling_tensor_raw = tf.cumsum(tf.constant(self.regularization_penalty, shape=x.shape, dtype=dtype), axis=-1)\n",
    "\n",
    "            scaling_tensor_old_neurons = scaling_tensor_raw[:, :-self.n_new_neurons]\n",
    "            scaling_tensor_new_neurons = scaling_tensor_raw[:, -self.n_new_neurons:]\n",
    "            scaling_tensor_old_neurons_shuffled = tf.transpose(tf.random.shuffle(tf.transpose(scaling_tensor_old_neurons)))\n",
    "            self.scaling_tensor = tf.concat([scaling_tensor_old_neurons_shuffled, scaling_tensor_new_neurons], axis=-1)\n",
    "            self.update_scaling_tensor = False\n",
    "\n",
    "        weighted_values = self.scaling_tensor * tf.abs(x)\n",
    "        return tf.reduce_sum(weighted_values)\n",
    "    \n",
    "    def group_sparsity(self, x):\n",
    "        # I.e. for a parameter matrix of 3 input and 5 output neurons:\n",
    "        #\n",
    "        # [[1., 1., 1., 1., 1.],\n",
    "        #  [1., 2., 2., 1., 2.],\n",
    "        #  [2., 2., 3., 1., 3.]]\n",
    "        #\n",
    "        # The resulting vector of group norms is [2., 2., 3., 1., 3.], therefore for\n",
    "        # every output neuron, its incoming connections form a group.\n",
    "\n",
    "        group_norms = tf.norm(x, ord=2, axis=0)\n",
    "        # assert group_norms.shape[0] == x.shape[1]\n",
    "        return self.regularization_penalty * tf.reduce_sum(group_norms)\n",
    "    \n",
    "    def l1(self, x):\n",
    "        weighted_values = self.regularization_penalty * tf.abs(x)\n",
    "        return tf.reduce_sum(weighted_values)\n",
    "    \n",
    "    def prune(self):\n",
    "        self.n_new_neurons = 0\n",
    "        if self.regularization_method == 'weighted_l1_reordered':\n",
    "            self.update_scaling_tensor = True\n",
    "    \n",
    "    def grow(self, n_new_neurons):\n",
    "        self.n_new_neurons = n_new_neurons\n",
    "        if self.regularization_method == 'weighted_l1_reordered':\n",
    "            self.update_scaling_tensor = True\n",
    "    \n",
    "    def set_regularization_penalty(self, regularization_penalty):\n",
    "        self.regularization_penalty = regularization_penalty\n",
    "    \n",
    "    def set_regularization_method(self, regularization_method):\n",
    "        self.regularization_method = regularization_method\n",
    "        if self.regularization_method == 'weighted_l1_reordered':\n",
    "            self.update_scaling_tensor = True\n",
    "        else:\n",
    "            self.update_scaling_tensor = None\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'regularization_penalty': float(self.regularization_penalty)}\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# LAYERS\n",
    "################################################################################\n",
    "\n",
    "\n",
    "class DASLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_shape):\n",
    "        super().__init__()\n",
    "\n",
    "        self._input_shape = input_shape\n",
    "        self._built = False\n",
    "\n",
    "\n",
    "class Dense(DASLayer):\n",
    "    def __init__(self, units, activation, kernel_initializer='glorot_uniform', \n",
    "                 bias_initializer='zeros', input_shape=None, fixed_size=False,\n",
    "                 regularizer=None):\n",
    "        super().__init__(input_shape)\n",
    "\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.bias_initializer = bias_initializer\n",
    "        self.fixed_size = fixed_size\n",
    "        \n",
    "        self.A = tf.keras.activations.get(activation)\n",
    "        self.W_init = tf.keras.initializers.get(kernel_initializer)\n",
    "        self.b_init = tf.keras.initializers.get(bias_initializer)\n",
    "        if regularizer is not None:\n",
    "            self.regularizer = regularizer\n",
    "        else:\n",
    "            self.regularizer = Regularizer()\n",
    "    \n",
    "    def copy(self):\n",
    "        layer_copy = Dense.__new__(Dense)\n",
    "        super(Dense, layer_copy).__init__(self._input_shape)\n",
    "        \n",
    "        layer_copy.units = self.units\n",
    "        layer_copy.activation = self.activation\n",
    "        layer_copy.kernel_initializer = self.kernel_initializer\n",
    "        layer_copy.bias_initializer = self.bias_initializer\n",
    "        layer_copy.fixed_size = self.fixed_size\n",
    "        \n",
    "        layer_copy.A = self.A\n",
    "        layer_copy.W_init = self.W_init\n",
    "        layer_copy.b_init = self.b_init\n",
    "        layer_copy.regularizer = self.regularizer.copy()\n",
    "        \n",
    "        layer_copy.W = tf.Variable(\n",
    "            name='W',\n",
    "            initial_value=self.W,\n",
    "            trainable=True)\n",
    "        \n",
    "        layer_copy.b = tf.Variable(\n",
    "            name='b',\n",
    "            initial_value=self.b,\n",
    "            trainable=True)\n",
    "        \n",
    "        layer_copy.add_regularizer_loss()\n",
    "        \n",
    "        layer_copy._built = True\n",
    "        return layer_copy\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        if self._built:\n",
    "            return\n",
    "            \n",
    "        input_units = input_shape[-1]\n",
    "\n",
    "        self.W = tf.Variable(\n",
    "            name='W',\n",
    "            initial_value=self.W_init(shape=(input_units, self.units), dtype=dtype),\n",
    "            trainable=True)\n",
    "        \n",
    "        self.b = tf.Variable(\n",
    "            name='b',\n",
    "            initial_value=self.b_init(shape=(self.units,), dtype=dtype),\n",
    "            trainable=True)\n",
    "        \n",
    "        self.add_regularizer_loss()\n",
    "        \n",
    "        self._built = True\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        return self.A(tf.matmul(inputs, self.W) + self.b)\n",
    "    \n",
    "    def add_regularizer_loss(self):\n",
    "        self.add_loss(lambda: self.regularizer(tf.concat([self.W, tf.reshape(self.b, (1, -1))], axis=0)))\n",
    "\n",
    "    def get_size(self):\n",
    "        return self.W.shape[0], self.W.shape[1]\n",
    "    \n",
    "    def prune(self, threshold, active_input_units_indices):\n",
    "        # Remove connections from pruned units in previous layer\n",
    "        new_W = tf.gather(self.W.value(), active_input_units_indices, axis=0)\n",
    "\n",
    "        if self.fixed_size:\n",
    "            active_output_neurons_indices = list(range(new_W.shape[1]))\n",
    "        else:\n",
    "            # Prune units in this layer\n",
    "            weights_with_biases = tf.concat([new_W, tf.reshape(self.b.value(), (1, -1))], axis=0)\n",
    "            neurons_are_active = tf.math.reduce_max(tf.abs(weights_with_biases), axis=0) >= threshold\n",
    "            active_output_neurons_indices = tf.reshape(tf.where(neurons_are_active), (-1,))\n",
    "            \n",
    "            new_W = tf.gather(new_W, active_output_neurons_indices, axis=1)\n",
    "            new_b = tf.gather(self.b.value(), active_output_neurons_indices, axis=0)\n",
    "\n",
    "            self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
    "\n",
    "        self.W = tf.Variable(name='W', initial_value=new_W, trainable=True)\n",
    "\n",
    "        self.regularizer.prune()\n",
    "        return active_output_neurons_indices\n",
    "    \n",
    "    def grow(self, n_new_input_units, percentage, min_new_units, scaling_factor):\n",
    "        if n_new_input_units > 0:\n",
    "            # Add connections to grown units in previous layer\n",
    "            W_growth = self.W_init(shape=(self.W.shape[0] + n_new_input_units, self.W.shape[1]), dtype=dtype)[-n_new_input_units:, :] * scaling_factor  # TODO is it better to be multiplying here by scaling_factor? It does help with not increasing the max weights of existing neurons when new neurons are added.\n",
    "            new_W = tf.concat([self.W.value(), W_growth], axis=0)\n",
    "        else:\n",
    "            new_W = self.W.value()\n",
    "\n",
    "        if self.fixed_size:\n",
    "            n_new_output_units = 0\n",
    "        else:\n",
    "            # Grow new units in this layer\n",
    "            n_new_output_units = max(min_new_units, int(new_W.shape[1] * percentage))\n",
    "            if n_new_output_units > 0:\n",
    "                W_growth = self.W_init(shape=(new_W.shape[0], new_W.shape[1] + n_new_output_units), dtype=dtype)[:, -n_new_output_units:] * scaling_factor\n",
    "                b_growth = self.b_init(shape=(n_new_output_units,), dtype=dtype)  # TODO for all possible bias initializers to work properly, the whole bias vector should be initialized at once\n",
    "                new_W = tf.concat([new_W, W_growth], axis=1)\n",
    "                new_b = tf.concat([self.b.value(), b_growth], axis=0)\n",
    "\n",
    "                self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
    "\n",
    "        self.W = tf.Variable(name='W', initial_value=new_W, trainable=True)\n",
    "\n",
    "        self.regularizer.grow(n_new_output_units)\n",
    "        return n_new_output_units\n",
    "    \n",
    "    def mutate(self, mutation_strength):\n",
    "        self.W.assign_add(tf.random.normal(self.W.shape, mean=0.0, stddev=mutation_strength))\n",
    "        self.b.assign_add(tf.random.normal(self.b.shape, mean=0.0, stddev=mutation_strength))\n",
    "    \n",
    "    def set_regularization_penalty(self, regularization_penalty):\n",
    "        if not self.fixed_size:\n",
    "            self.regularizer.set_regularization_penalty(regularization_penalty)\n",
    "    \n",
    "    def set_regularization_method(self, regularization_method):\n",
    "        if not self.fixed_size:\n",
    "            self.regularizer.set_regularization_method(regularization_method)\n",
    "    \n",
    "    def get_param_string():\n",
    "        param_string = \"\"\n",
    "        weights_with_bias = tf.concat([self.W, tf.reshape(self.b, (1, -1))], axis=0)\n",
    "        max_parameters = tf.math.reduce_max(tf.abs(weights_with_bias), axis=0).numpy()\n",
    "        magnitudes = np.floor(np.log10(max_parameters))\n",
    "        for m in magnitudes:\n",
    "            if m > 0:\n",
    "                m = 0\n",
    "            param_string += str(int(-m))\n",
    "        return param_string\n",
    "\n",
    "\n",
    "class Conv2D(DASLayer):\n",
    "    def __init__(self, filters, filter_size, activation, strides=(1, 1), \n",
    "                 padding='SAME', kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros', input_shape=None, fixed_size=False,\n",
    "                 regularizer=None):\n",
    "        super().__init__(input_shape)\n",
    "    \n",
    "        self.filters = filters\n",
    "        self.filter_size = filter_size\n",
    "        self.activation = activation\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.bias_initializer = bias_initializer\n",
    "        self.fixed_size = fixed_size\n",
    "        \n",
    "        self.A = tf.keras.activations.get(activation)\n",
    "        self.F_init = tf.keras.initializers.get(kernel_initializer)\n",
    "        self.b_init = tf.keras.initializers.get(bias_initializer)\n",
    "        if regularizer is not None:\n",
    "            self.regularizer = regularizer\n",
    "        else:\n",
    "            self.regularizer = Regularizer()\n",
    "    \n",
    "    def copy(self):\n",
    "        layer_copy = Conv2D.__new__(Conv2D)\n",
    "        super(Conv2D, layer_copy).__init__(self._input_shape)\n",
    "        \n",
    "        layer_copy.filters = self.filters\n",
    "        layer_copy.filter_size = self.filter_size\n",
    "        layer_copy.activation = self.activation\n",
    "        layer_copy.strides = self.strides\n",
    "        layer_copy.padding = self.padding\n",
    "        layer_copy.kernel_initializer = self.kernel_initializer\n",
    "        layer_copy.bias_initializer = self.bias_initializer\n",
    "        layer_copy.fixed_size = self.fixed_size\n",
    "        \n",
    "        layer_copy.A = self.A\n",
    "        layer_copy.F_init = self.F_init\n",
    "        layer_copy.b_init = self.b_init\n",
    "        layer_copy.regularizer = self.regularizer.copy()\n",
    "        \n",
    "        layer_copy.F = tf.Variable(\n",
    "            name='F',\n",
    "            initial_value=self.F,\n",
    "            trainable=True)\n",
    "        \n",
    "        layer_copy.b = tf.Variable(\n",
    "            name='b',\n",
    "            initial_value=self.b,\n",
    "            trainable=True)\n",
    "        \n",
    "        layer_copy.add_regularizer_loss()\n",
    "        \n",
    "        layer_copy._built = True\n",
    "        return layer_copy\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        if self._built:\n",
    "            return\n",
    "\n",
    "        input_filters = input_shape[-1]\n",
    "\n",
    "        self.F = tf.Variable(\n",
    "            name='F',\n",
    "            initial_value=self.F_init(\n",
    "                shape=(self.filter_size[0], self.filter_size[1], input_filters, self.filters), dtype=dtype\n",
    "            ),\n",
    "            trainable=True)\n",
    "        \n",
    "        self.b = tf.Variable(\n",
    "            name='b',\n",
    "            initial_value=self.b_init(shape=(self.filters,), dtype=dtype),\n",
    "            trainable=True)\n",
    "\n",
    "        self.add_regularizer_loss()\n",
    "        \n",
    "        self._built = True\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        y = tf.nn.conv2d(inputs, self.F, strides=self.strides, padding=self.padding)\n",
    "        y = tf.nn.bias_add(y, self.b)\n",
    "        y = self.A(y)\n",
    "        return y\n",
    "    \n",
    "    def add_regularizer_loss(self):\n",
    "        self.add_loss(lambda: self.regularizer(tf.concat([tf.reshape(self.F, (-1, self.F.shape[-1])), tf.reshape(self.b, (1, -1))], axis=0)))\n",
    "    \n",
    "    def get_size(self):\n",
    "        return self.F.shape[-2], self.F.shape[-1]\n",
    "    \n",
    "    def prune(self, threshold, active_input_units_indices):\n",
    "        # Remove connections from pruned units in previous layer\n",
    "        new_F = tf.gather(self.F.value(), active_input_units_indices, axis=-2)\n",
    "\n",
    "        if self.fixed_size:\n",
    "            active_output_filters_indices = list(range(new_F.shape[-1]))\n",
    "        else:\n",
    "            # Prune units in this layer\n",
    "            F_reduced_max = tf.reshape(tf.math.reduce_max(tf.abs(new_F), axis=(0, 1, 2)), (1, -1))\n",
    "            F_reduced_max_with_biases = tf.concat([F_reduced_max, tf.reshape(self.b.value(), (1, -1))], axis=0)\n",
    "            filters_are_active = tf.math.reduce_max(tf.abs(F_reduced_max_with_biases), axis=0) >= threshold\n",
    "            active_output_filters_indices = tf.reshape(tf.where(filters_are_active), (-1,))\n",
    "            \n",
    "            new_F = tf.gather(new_F, active_output_filters_indices, axis=-1)\n",
    "            new_b = tf.gather(self.b.value(), active_output_filters_indices, axis=0)\n",
    "\n",
    "            self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
    "\n",
    "        self.F = tf.Variable(name='F', initial_value=new_F, trainable=True)\n",
    "\n",
    "        self.regularizer.prune()\n",
    "        return active_output_filters_indices\n",
    "\n",
    "    def grow(self, n_new_input_units, percentage, min_new_units, scaling_factor):\n",
    "        if n_new_input_units > 0:\n",
    "            # Add connections to grown units in previous layer\n",
    "            F_growth = self.F_init(shape=(self.F.shape[0], self.F.shape[1], self.F.shape[2] + n_new_input_units, self.F.shape[3]), dtype=dtype)[:, :, -n_new_input_units:, :] * scaling_factor  # TODO is it better to be multiplying here by scaling_factor? It does help with not increasing the max weights of existing neurons when new neurons are added.\n",
    "            new_F = tf.concat([self.F.value(), F_growth], axis=-2)\n",
    "        else:\n",
    "            new_F = self.F.value()\n",
    "\n",
    "        if self.fixed_size:\n",
    "            n_new_output_units = 0\n",
    "        else:\n",
    "            # Grow new units in this layer\n",
    "            n_new_output_units = max(min_new_units, int(new_F.shape[-1] * percentage))\n",
    "            if n_new_output_units > 0:\n",
    "                F_growth = self.F_init(shape=(new_F.shape[0], new_F.shape[1], new_F.shape[2], new_F.shape[3] + n_new_output_units), dtype=dtype)[:, :, :, -n_new_output_units:] * scaling_factor\n",
    "                b_growth = self.b_init(shape=(n_new_output_units,), dtype=dtype)  # TODO for all possible bias initializers to work properly, the whole bias vector should be initialized at once\n",
    "                new_F = tf.concat([new_F, F_growth], axis=-1)\n",
    "                new_b = tf.concat([self.b.value(), b_growth], axis=0)\n",
    "\n",
    "                self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
    "\n",
    "        self.F = tf.Variable(name='F', initial_value=new_F, trainable=True)\n",
    "\n",
    "        self.regularizer.grow(n_new_output_units)\n",
    "        return n_new_output_units\n",
    "    \n",
    "    def mutate(self, mutation_strength):\n",
    "        self.F.assign_add(tf.random.normal(self.F.shape, mean=0.0, stddev=mutation_strength))\n",
    "        self.b.assign_add(tf.random.normal(self.b.shape, mean=0.0, stddev=mutation_strength))\n",
    "    \n",
    "    def set_regularization_penalty(self, regularization_penalty):\n",
    "        if not self.fixed_size:\n",
    "            self.regularizer.set_regularization_penalty(regularization_penalty)\n",
    "    \n",
    "    def set_regularization_method(self, regularization_method):\n",
    "        if not self.fixed_size:\n",
    "            self.regularizer.set_regularization_method(regularization_method)\n",
    "\n",
    "    def get_param_string():\n",
    "        param_string = \"\"\n",
    "        # TODO\n",
    "        return param_string\n",
    "\n",
    "\n",
    "class Flatten(tf.keras.layers.Layer):\n",
    "    def call(self, inputs, training=None):\n",
    "        return tf.reshape(tf.transpose(inputs, perm=[0, 3, 1, 2]), (inputs.shape[0], -1))\n",
    "    \n",
    "    # def copy(self):\n",
    "    #     return Flatten()\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# MODELS\n",
    "################################################################################\n",
    "\n",
    "\n",
    "class Epoch:\n",
    "    def __init__(self, grow, prune, regularization_penalty, regularization_method):\n",
    "        self.grow = grow\n",
    "        self.prune = prune\n",
    "        self.regularization_penalty = regularization_penalty\n",
    "        self.regularization_method = regularization_method\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{int(self.grow)}{int(self.prune)}{self.regularization_penalty}{self.regularization_method}'\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "\n",
    "class DynamicEpoch(Epoch):\n",
    "    def __init__(self, regularization_penalty, regularization_method):\n",
    "        super().__init__(True, True, regularization_penalty, regularization_method)\n",
    "\n",
    "\n",
    "class StaticEpoch(Epoch):\n",
    "    def __init__(self, regularization_penalty, regularization_method):\n",
    "        super().__init__(False, False, regularization_penalty, regularization_method)\n",
    "\n",
    "\n",
    "class StaticEpochNoRegularization(StaticEpoch):\n",
    "    def __init__(self):\n",
    "        super().__init__(0., None)\n",
    "\n",
    "\n",
    "class Schedule:\n",
    "    def __init__(self, epochs):\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.epochs.__iter__()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.epochs)\n",
    "    \n",
    "    def __str__(self):\n",
    "        text = ''.join([str(epoch) for epoch in self.epochs])\n",
    "        _hash = hashlib.sha1(text.encode('utf-8')).hexdigest()[:10]\n",
    "        return f'{_hash}({self.epochs[0].regularization_penalty})'\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "\n",
    "class Sequential(tf.keras.Model):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lrs = layers\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        x = inputs\n",
    "        for layer in self.lrs:\n",
    "            x = layer(x, training=training)\n",
    "        return x\n",
    "    \n",
    "    def copy(self):\n",
    "        copied_layers = list()\n",
    "        for layer in self.lrs:\n",
    "            if isinstance(layer, DASLayer):\n",
    "                layer_copy = layer.copy()\n",
    "#                 layer_copy = copy.deepcopy(layer)\n",
    "#                 layer_copy.add_regularizer_loss()\n",
    "            else:\n",
    "                layer_copy = copy.deepcopy(layer)\n",
    "            copied_layers.append(layer_copy)\n",
    "        \n",
    "        model_copy = Sequential(copied_layers)\n",
    "        return model_copy\n",
    "    \n",
    "    def get_layer_input_shape(self, target_layer):\n",
    "        if target_layer._input_shape is not None:\n",
    "            return target_layer._input_shape\n",
    "\n",
    "        input = np.random.normal(size=(1,) + self.lrs[0]._input_shape)\n",
    "        for layer in self.lrs:\n",
    "            if layer is target_layer:\n",
    "                return tuple(input.shape[1:])\n",
    "            input = layer(input)\n",
    "        raise Exception(\"Layer not found in the model.\")\n",
    "\n",
    "    def get_layer_output_shape(self, target_layer):\n",
    "        input = np.random.normal(size=(1,) + self.lrs[0]._input_shape)\n",
    "        for layer in self.lrs:\n",
    "            output = layer(input)\n",
    "            if layer is target_layer:\n",
    "                return tuple(output.shape[1:])\n",
    "            input = output\n",
    "        raise Exception(\"Layer not found in the model.\")\n",
    "    \n",
    "    def get_layer_sizes(self):\n",
    "        \"\"\"\n",
    "        Returns the sizes of all layers in the model, including the input and output layer.\n",
    "        \"\"\"\n",
    "        layer_sizes = list()\n",
    "        first_layer = True\n",
    "        for l in range(len(self.lrs)):\n",
    "            layer = self.lrs[l]\n",
    "            if isinstance(layer, DASLayer):\n",
    "                layer_size = layer.get_size()\n",
    "                if first_layer:\n",
    "                    layer_sizes.append(layer_size[0])\n",
    "                    first_layer = False\n",
    "                layer_sizes.append(layer_size[1])\n",
    "        return layer_sizes\n",
    "    \n",
    "    def get_hidden_layer_sizes(self):\n",
    "        return self.get_layer_sizes()[1:-1]\n",
    "    \n",
    "    def get_regularization_penalty(self):\n",
    "        #TODO improve\n",
    "        return self.lrs[-2].regularizer.regularization_penalty\n",
    "    \n",
    "    def set_regularization_penalty(self, regularization_penalty):\n",
    "        for layer in self.lrs:\n",
    "            if isinstance(layer, DASLayer) and not layer.fixed_size:\n",
    "                layer.set_regularization_penalty(regularization_penalty)\n",
    "    \n",
    "    def set_regularization_method(self, regularization_method):\n",
    "        for layer in self.lrs:\n",
    "            if isinstance(layer, DASLayer) and not layer.fixed_size:\n",
    "                layer.set_regularization_method(regularization_method)\n",
    "\n",
    "    def prune(self, params):\n",
    "        input_shape = self.get_layer_input_shape(self.lrs[0])\n",
    "        n_input_units = input_shape[-1]\n",
    "        active_units_indices = list(range(n_input_units))\n",
    "\n",
    "        last_custom_layer = None\n",
    "        for layer in self.lrs:\n",
    "            if isinstance(layer, DASLayer):\n",
    "                if last_custom_layer is not None and type(last_custom_layer) != type(layer):\n",
    "                    if type(last_custom_layer) == Conv2D and type(layer) == Dense:\n",
    "                        convolutional_shape = self.get_layer_output_shape(last_custom_layer)\n",
    "                        active_units_indices = self.convert_channel_indices_to_flattened_indices(active_units_indices, convolutional_shape)\n",
    "                    else:\n",
    "                        raise Exception(\"Incorrect order of custom layer types.\")\n",
    "                active_units_indices = layer.prune(params.pruning_threshold, active_units_indices)\n",
    "                last_custom_layer = layer\n",
    "    \n",
    "    def grow(self, params):   \n",
    "        n_new_units = 0\n",
    "\n",
    "        last_custom_layer = None\n",
    "        for layer in self.lrs:\n",
    "            if isinstance(layer, DASLayer):\n",
    "                if last_custom_layer is not None and type(last_custom_layer) != type(layer):\n",
    "                    if type(last_custom_layer) == Conv2D and type(layer) == Dense:\n",
    "                        convolutional_shape = self.get_layer_output_shape(last_custom_layer)\n",
    "                        n_new_units = n_new_units * convolutional_shape[0] * convolutional_shape[1]\n",
    "                    else:\n",
    "                        raise Exception(\"Incorrect order of custom layer types.\")\n",
    "                n_new_units = layer.grow(n_new_units, params.growth_percentage, min_new_units=params.min_new_neurons, scaling_factor=params.pruning_threshold)\n",
    "                last_custom_layer = layer\n",
    "    \n",
    "    def mutate(self, mutation_strength):\n",
    "        for layer in self.lrs:\n",
    "            if isinstance(layer, DASLayer):\n",
    "                layer.mutate(mutation_strength)\n",
    "    \n",
    "    @staticmethod\n",
    "    def convert_channel_indices_to_flattened_indices(channel_indices, convolutional_shape):\n",
    "        dense_indices = list()\n",
    "        units_per_channel = convolutional_shape[0] * convolutional_shape[1]\n",
    "        for channel_index in channel_indices:\n",
    "            for iter in range(units_per_channel):\n",
    "                dense_indices.append(channel_index * units_per_channel + iter)\n",
    "        return dense_indices\n",
    "    \n",
    "    def print_neurons(self):\n",
    "        for layer in self.lrs[:-1]:\n",
    "            print(layer.get_param_string())\n",
    "    \n",
    "    def evaluate(self, params, summed_training_loss, summed_training_metric):\n",
    "        # Calculate training loss and metric\n",
    "        if summed_training_loss is not None:\n",
    "            loss = summed_training_loss / params.x.shape[0]\n",
    "        else:\n",
    "            loss = None\n",
    "        \n",
    "        if summed_training_metric is not None:\n",
    "            metric = summed_training_metric / params.x.shape[0]\n",
    "        else:\n",
    "            metric = None\n",
    "        \n",
    "        # Calculate val loss and metric\n",
    "        summed_val_loss = 0\n",
    "        summed_val_metric = 0\n",
    "        n_val_instances = 0\n",
    "        \n",
    "        for step, (x_batch, y_batch) in enumerate(params.val_dataset):\n",
    "            # y_pred = tf.reshape(self(x_batch, training=False), y_batch.shape)\n",
    "            y_pred = self(x_batch, training=False)\n",
    "            summed_val_loss += tf.reduce_sum(params.loss_fn(y_batch, y_pred))\n",
    "            summed_val_metric += float(tf.reduce_sum(params.metric_fn(y_batch, y_pred)))\n",
    "            n_val_instances += x_batch.shape[0]\n",
    "        \n",
    "        val_loss = summed_val_loss / n_val_instances\n",
    "        val_metric = summed_val_metric / n_val_instances\n",
    "\n",
    "        return loss, metric, val_loss, val_metric\n",
    "\n",
    "    def list_params(self):\n",
    "        trainable_count = np.sum([K.count_params(w) for w in self.trainable_weights])\n",
    "        non_trainable_count = np.sum([K.count_params(w) for w in self.non_trainable_weights])\n",
    "        total_count = trainable_count + non_trainable_count\n",
    "\n",
    "        print('Total params: {:,}'.format(total_count))\n",
    "        print('Trainable params: {:,}'.format(trainable_count))\n",
    "        print('Non-trainable params: {:,}'.format(non_trainable_count))\n",
    "\n",
    "        return total_count, trainable_count, non_trainable_count\n",
    "    \n",
    "    def print_epoch_statistics(self, params, summed_training_loss, summed_training_metric, message=None, require_result=False):\n",
    "        if not params.verbose:\n",
    "            if require_result:\n",
    "                return self.evaluate(params, summed_training_loss, summed_training_metric)\n",
    "            else:\n",
    "                return\n",
    "        \n",
    "        loss, metric, val_loss, val_metric = self.evaluate(params, summed_training_loss, summed_training_metric)  \n",
    "\n",
    "        if message is not None:\n",
    "            print(message)\n",
    "        \n",
    "        print(f\"loss: {loss} - metric: {metric} - val_loss: {val_loss} - val_metric: {val_metric} - penalty: {self.get_regularization_penalty()}\")\n",
    "        hidden_layer_sizes = self.get_hidden_layer_sizes()\n",
    "        print(f\"hidden layer sizes: {hidden_layer_sizes}, total units: {sum(hidden_layer_sizes)}\")\n",
    "        if params.print_neurons:\n",
    "            self.print_neurons()\n",
    "        \n",
    "        if require_result:\n",
    "            return loss, metric, val_loss, val_metric\n",
    "    \n",
    "    def update_history(self, params, loss, metric, val_loss, val_metric):\n",
    "        params.history['loss'].append(float(loss))\n",
    "        params.history['metric'].append(float(metric))\n",
    "        params.history['val_loss'].append(float(val_loss))\n",
    "        params.history['val_metric'].append(float(val_metric))\n",
    "        params.history['hidden_layer_sizes'].append(self.get_hidden_layer_sizes())\n",
    "    \n",
    "    @staticmethod\n",
    "    def prepare_datasets(x, y, batch_size, validation_data):\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "        train_dataset = train_dataset.shuffle(buffer_size=20000).batch(batch_size)\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices(validation_data).batch(batch_size)\n",
    "        return train_dataset.prefetch(tf.data.AUTOTUNE), val_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    def manage_dynamic_regularization(self, params, val_loss):\n",
    "        if val_loss >= params.best_conditional_val_loss * params.stall_coefficient:\n",
    "            # Training is currently in stall\n",
    "            if not params.training_stalled:\n",
    "                penalty = self.get_regularization_penalty() * params.regularization_penalty_multiplier\n",
    "                print(\"Changing penalty...\")\n",
    "                # TODO this must be modified, penalty can differ for each layer\n",
    "                self.set_regularization_penalty(penalty)\n",
    "                params.training_stalled = True\n",
    "        else:\n",
    "            params.best_conditional_val_loss = val_loss\n",
    "            params.training_stalled = False\n",
    "    \n",
    "    def grow_wrapper(self, params):\n",
    "        dynamic_reqularization_active = params.regularization_penalty_multiplier != 1.\n",
    "        if dynamic_reqularization_active:\n",
    "            loss, metric, val_loss, val_metric = self.print_epoch_statistics(params, None, None, \"Before growing:\", require_result=True)\n",
    "            self.manage_dynamic_regularization(params, val_loss)\n",
    "        else:\n",
    "            self.print_epoch_statistics(params, None, None, \"Before growing:\")\n",
    "\n",
    "        self.grow(params)\n",
    "        self.print_epoch_statistics(params, None, None, \"After growing:\")\n",
    "    \n",
    "    def prune_wrapper(self, params, summed_loss, summed_metric):\n",
    "        loss, metric, _, _ = self.print_epoch_statistics(params, summed_loss, summed_metric, \"Before pruning:\", require_result=True)\n",
    "        self.prune(params)\n",
    "        _, _, val_loss, val_metric = self.print_epoch_statistics(params, None, None, \"After pruning:\", require_result=True)\n",
    "        self.update_history(params, loss, metric, val_loss, val_metric)\n",
    "    \n",
    "    class ParameterContainer:\n",
    "        def __init__(self, x, y, optimizer, batch_size, min_new_neurons, validation_data, pruning_threshold, regularization_penalty_multiplier, \n",
    "                     stall_coefficient, growth_percentage, mini_epochs_per_epoch, verbose, print_neurons, use_static_graph, loss_fn, metric_fn):\n",
    "            self.x = x\n",
    "            self.y = y\n",
    "            self.optimizer = optimizer\n",
    "            self.batch_size = batch_size\n",
    "            self.min_new_neurons = min_new_neurons\n",
    "            self.validation_data = validation_data\n",
    "            self.pruning_threshold = pruning_threshold\n",
    "            self.regularization_penalty_multiplier = regularization_penalty_multiplier\n",
    "            self.stall_coefficient = stall_coefficient\n",
    "            self.growth_percentage = growth_percentage\n",
    "            self.mini_epochs_per_epoch = mini_epochs_per_epoch\n",
    "            self.verbose = verbose\n",
    "            self.print_neurons = print_neurons\n",
    "            self.use_static_graph = use_static_graph\n",
    "            self.loss_fn = loss_fn\n",
    "            self.metric_fn = metric_fn\n",
    "\n",
    "            self.train_dataset, self.val_dataset = Sequential.prepare_datasets(x, y, batch_size, validation_data)\n",
    "            self.history = self.prepare_history()\n",
    "\n",
    "            self.best_conditional_val_loss = np.inf\n",
    "            self.training_stalled = False\n",
    "        \n",
    "        @staticmethod\n",
    "        def prepare_history():\n",
    "            history = {\n",
    "                'loss': list(),\n",
    "                'metric': list(),\n",
    "                'val_loss': list(),\n",
    "                'val_metric': list(),\n",
    "                'hidden_layer_sizes': list(),\n",
    "            }\n",
    "            return history\n",
    "    \n",
    "    def fit_single_step(self, x_batch, y_batch, optimizer, loss_fn, metric_fn):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # y_pred = tf.reshape(self(x_batch, training=True), y_batch.shape)\n",
    "            y_pred = self(x_batch, training=True)\n",
    "            raw_loss = loss_fn(y_batch, y_pred)\n",
    "            loss_value = tf.reduce_mean(raw_loss)\n",
    "            loss_value += sum(self.losses)  # Add losses registered by model.add_loss\n",
    "\n",
    "            loss = tf.reduce_sum(raw_loss)\n",
    "            metric = float(tf.reduce_sum(metric_fn(y_batch, y_pred)))\n",
    "\n",
    "        grads = tape.gradient(loss_value, self.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "\n",
    "        return loss, metric\n",
    "    \n",
    "    def fit_single_epoch(self, params):\n",
    "        summed_loss = 0\n",
    "        summed_metric = 0\n",
    "        \n",
    "        for mini_epoch in range(params.mini_epochs_per_epoch):\n",
    "            summed_loss = 0\n",
    "            summed_metric = 0\n",
    "\n",
    "            if params.use_static_graph:\n",
    "                fit_single_step_function = tf.function(self.fit_single_step)\n",
    "            else:\n",
    "                fit_single_step_function = self.fit_single_step\n",
    "            for step, (x_batch, y_batch) in enumerate(params.train_dataset):\n",
    "                loss, metric = fit_single_step_function(x_batch, y_batch, params.optimizer, params.loss_fn, params.metric_fn)\n",
    "                summed_loss += loss\n",
    "                summed_metric += metric\n",
    "        \n",
    "        return summed_loss, summed_metric\n",
    "\n",
    "    def fit(self, x, y, optimizer, schedule, batch_size, min_new_neurons, validation_data, pruning_threshold=0.001, regularization_penalty_multiplier=1., \n",
    "            stall_coefficient=1, growth_percentage=0.2, mini_epochs_per_epoch=1, verbose=True, print_neurons=False, use_static_graph=True, \n",
    "            loss_fn=tf.keras.losses.sparse_categorical_crossentropy, metric_fn=tf.keras.metrics.sparse_categorical_accuracy):\n",
    "        params = self.ParameterContainer(x=x, y=y, optimizer=optimizer, batch_size=batch_size, min_new_neurons=min_new_neurons, validation_data=validation_data, \n",
    "                                         pruning_threshold=pruning_threshold, regularization_penalty_multiplier=regularization_penalty_multiplier, stall_coefficient=stall_coefficient, \n",
    "                                         growth_percentage=growth_percentage, mini_epochs_per_epoch=mini_epochs_per_epoch, verbose=verbose, print_neurons=print_neurons, \n",
    "                                         use_static_graph=use_static_graph, loss_fn=loss_fn, metric_fn=metric_fn)\n",
    "        self.build(x.shape)  # Necessary when verbose == False\n",
    "\n",
    "        for epoch_no, epoch in enumerate(schedule):\n",
    "            if verbose:\n",
    "                print(\"##########################################################\")\n",
    "                print(f\"Epoch {epoch_no + 1}/{len(schedule)}\")\n",
    "            \n",
    "            self.set_regularization_penalty(epoch.regularization_penalty)\n",
    "            self.set_regularization_method(epoch.regularization_method)\n",
    "\n",
    "            if epoch.grow:\n",
    "                self.grow_wrapper(params)\n",
    "\n",
    "            summed_loss, summed_metric = self.fit_single_epoch(params)\n",
    "            \n",
    "            if epoch.prune:\n",
    "                self.prune_wrapper(params, summed_loss, summed_metric)\n",
    "            else:\n",
    "                loss, metric, val_loss, val_metric = self.print_epoch_statistics(params, summed_loss, summed_metric, require_result=True)\n",
    "                self.update_history(params, loss, metric, val_loss, val_metric)\n",
    "        \n",
    "        return params.history\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# HELPER FUNCTIONS\n",
    "################################################################################\n",
    "\n",
    "\n",
    "def get_statistics_from_history(history):\n",
    "    best_epoch_number = np.argmax(history['val_metric'])\n",
    "    best_loss = history['loss'][best_epoch_number]\n",
    "    best_metric = history['metric'][best_epoch_number]\n",
    "    best_val_loss = history['val_loss'][best_epoch_number]\n",
    "    best_val_metric = history['val_metric'][best_epoch_number]\n",
    "    best_hidden_layer_sizes = history['hidden_layer_sizes'][best_epoch_number]\n",
    "    return best_loss, best_metric, best_val_loss, best_val_metric, best_hidden_layer_sizes\n",
    "\n",
    "\n",
    "def get_statistics_from_histories(histories):\n",
    "    best_val_losses = list()\n",
    "    best_val_metrics = list()\n",
    "    all_best_hidden_layer_sizes = list()\n",
    "\n",
    "    for history in histories:\n",
    "        _, _, best_val_loss, best_val_metric, best_hidden_layer_sizes = get_statistics_from_history(history)\n",
    "        best_val_losses.append(best_val_loss)\n",
    "        best_val_metrics.append(best_val_metric)\n",
    "        all_best_hidden_layer_sizes.append(best_hidden_layer_sizes)\n",
    "    \n",
    "    mean_best_val_loss = np.mean(best_val_losses)\n",
    "    mean_best_val_metric = np.mean(best_val_metrics)\n",
    "    mean_best_hidden_layer_sizes = [np.mean(layer) for layer in list(zip(*all_best_hidden_layer_sizes))]\n",
    "    \n",
    "    return mean_best_val_loss, mean_best_val_metric, mean_best_hidden_layer_sizes\n",
    "\n",
    "\n",
    "def cross_validate(train_fn, x, y, n_splits, random_state=42, *args, **kwargs):\n",
    "    from sklearn.model_selection import KFold\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    histories = list()\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "        xtrain, xtest = x[train_index], x[test_index]\n",
    "        ytrain, ytest = y[train_index], y[test_index]\n",
    "\n",
    "        history = train_fn(xtrain, ytrain, validation_data=(xtest, ytest), *args, **kwargs)\n",
    "        histories.append(history)\n",
    "\n",
    "        _, _, best_val_loss, best_val_metric, best_hidden_layer_sizes = get_statistics_from_history(history)\n",
    "        print(f\"Run {i} completed, best_val_loss: {best_val_loss}, best_val_metric: {best_val_metric}, best_hidden_layer_sizes: {best_hidden_layer_sizes}\")\n",
    "\n",
    "    mean_best_val_loss, mean_best_val_metric, mean_best_hidden_layer_sizes = get_statistics_from_histories(histories)\n",
    "    print(f'mean_best_val_loss: {mean_best_val_loss}')\n",
    "    print(f'mean_best_val_metric: {mean_best_val_metric}')\n",
    "    print(f'mean_best_hidden_layer_sizes: {mean_best_hidden_layer_sizes}')\n",
    "\n",
    "    return histories, mean_best_hidden_layer_sizes\n",
    "\n",
    "\n",
    "def hyperparameter_search(train_fn, x, y, validation_data, *args, **kwargs):\n",
    "    from itertools import product\n",
    "\n",
    "    all_params = [*args] + list(kwargs.values())\n",
    "    histories = list()\n",
    "\n",
    "    best_overall_val_loss = np.inf\n",
    "    best_overall_val_metric = None\n",
    "    best_overall_combination = None\n",
    "\n",
    "    for combination in product(*all_params):\n",
    "        combination_args = combination[:len(args)]\n",
    "\n",
    "        combination_kwargs_values = combination[len(args):]\n",
    "        combination_kwargs = dict(zip(kwargs.keys(), combination_kwargs_values))\n",
    "\n",
    "        history = train_fn(x, y, validation_data, *combination_args, **combination_kwargs)\n",
    "        history['parameters'] = combination\n",
    "        histories.append(history)\n",
    "\n",
    "        _, _, best_val_loss, best_val_metric, best_hidden_layer_sizes = get_statistics_from_history(history)\n",
    "        print(f\"Run with parameters {combination} completed, best_val_loss: {best_val_loss}, best_val_metric: {best_val_metric}, best_hidden_layer_sizes: {best_hidden_layer_sizes}\")\n",
    "\n",
    "        if best_val_loss < best_overall_val_loss:\n",
    "            best_overall_val_loss = best_val_loss\n",
    "            best_overall_val_metric = best_val_metric\n",
    "            best_overall_combination = combination\n",
    "    \n",
    "    print(f'Best overall combination: {best_overall_combination}, val_metric: {best_overall_val_metric}')\n",
    "\n",
    "    return histories, best_overall_combination\n",
    "\n",
    "\n",
    "def interruptible(f):\n",
    "    def function(*args, **kwargs):\n",
    "        try:\n",
    "            return f(*args, **kwargs)\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Interrupted by user.\")\n",
    "    return function\n",
    "\n",
    "\n",
    "class Range:\n",
    "    def __init__(self, min_value, max_value, transformation=None, integer=False):\n",
    "        self.min_value = min_value\n",
    "        self.max_value = max_value\n",
    "        self.transformation = transformation\n",
    "        self.integer = integer\n",
    "    \n",
    "    def sample(self, x=None):\n",
    "        y = self._raw_sample(x)\n",
    "        if self.integer:\n",
    "            y = np.rint(y).astype(int)\n",
    "        if self.transformation is not None:\n",
    "            result = self.transformation(y)\n",
    "#             print(f\"Transformed value {y} to {result}.\")\n",
    "            return result\n",
    "        return y\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def _raw_sample(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class UniformRange(Range):\n",
    "    def _raw_sample(self, x):\n",
    "        if x is None:\n",
    "            return np.random.uniform(self.min_value, self.max_value)\n",
    "        else:\n",
    "            return self.min_value + x * (self.max_value - self.min_value)\n",
    "\n",
    "\n",
    "class PowerRange(Range):\n",
    "    def _raw_sample(self, x):\n",
    "        if x is None:\n",
    "            y = np.random.uniform(self.min_value, self.max_value)\n",
    "        else:\n",
    "            y = self.min_value + x * (self.max_value - self.min_value)\n",
    "        return 10. ** y\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# ANYTIME ALGORITHMS\n",
    "################################################################################\n",
    "\n",
    "\n",
    "class AnytimeAlgorithmResult:\n",
    "    def __init__(self, loss, metric, val_loss, val_metric, hidden_layer_sizes, duration, args, kwargs, level=None):\n",
    "        self.loss = loss\n",
    "        self.metric = metric\n",
    "        self.val_loss = val_loss\n",
    "        self.val_metric = val_metric\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.duration = duration\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "        self.level = level\n",
    "        self.time = None\n",
    "        self.best_val_metric = None\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'loss': self.loss,\n",
    "            'metric': self.metric,\n",
    "            'val_loss': self.val_loss,\n",
    "            'val_metric': self.val_metric,\n",
    "            'hidden_layer_sizes': self.hidden_layer_sizes,\n",
    "            'duration': self.duration,\n",
    "            'args': self.args,\n",
    "            'kwargs': self.kwargs,\n",
    "            'level': self.level,\n",
    "            'time': self.time,\n",
    "            'best_val_metric': self.best_val_metric,\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_dict(_dict):\n",
    "        result = AnytimeAlgorithmResult.__new__(AnytimeAlgorithmResult)\n",
    "        result.loss = _dict['loss']\n",
    "        result.metric = _dict['metric']\n",
    "        result.val_loss = _dict['val_loss']\n",
    "        result.val_metric = _dict['val_metric']\n",
    "        result.hidden_layer_sizes = _dict['hidden_layer_sizes']\n",
    "        result.duration = _dict['duration']\n",
    "        result.args = _dict['args']\n",
    "        result.kwargs = _dict['kwargs']\n",
    "        result.level = _dict['level']\n",
    "        result.time = _dict['time']\n",
    "        result.best_val_metric = _dict['best_val_metric']\n",
    "        return result\n",
    "\n",
    "\n",
    "class AnytimeAlgorithm:\n",
    "    def __init__(self):\n",
    "        self.results = list()\n",
    "        self.best_val_metric = -np.inf\n",
    "        self.start_time = None\n",
    "    \n",
    "    def log_result(self, result):\n",
    "        if result.val_metric > self.best_val_metric:\n",
    "            self.best_val_metric = result.val_metric\n",
    "        result.time = time.time() - self.start_time\n",
    "        result.best_val_metric = self.best_val_metric\n",
    "        self.results.append(result)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_total_duration_from_results(results):\n",
    "        return sum([result.duration for result in results])\n",
    "    \n",
    "    def get_total_duration(self):\n",
    "        return self.get_total_duration_from_results(self.results)\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_mean_duration_from_results(results):\n",
    "        return np.mean([result.duration for result in results])\n",
    "        \n",
    "    def get_mean_duration(self):\n",
    "        return self.get_mean_duration_from_results(self.results)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_mean_val_metric_from_results(results):\n",
    "        return np.mean([result.val_metric for result in results])\n",
    "        \n",
    "    def get_mean_val_metric(self):\n",
    "        return self.get_mean_val_metric_from_results(self.results)\n",
    "    \n",
    "    def run(self):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "\n",
    "def identity_postprocess(args, kwargs):\n",
    "    return args, kwargs\n",
    "\n",
    "\n",
    "def get_data_for_run(x, y, validation_data, fraction, test_size):\n",
    "    assert (fraction is None) != (validation_data is None)\n",
    "    assert not ((validation_data is not None) and (test_size is not None))\n",
    "    \n",
    "    if fraction is not None:\n",
    "        x_iter, y_iter = get_dataset_sample(x, y, fraction, seed=None)\n",
    "    else:\n",
    "        x_iter, y_iter = x, y\n",
    "\n",
    "    if validation_data is None:\n",
    "        x_iter, x_val_iter, y_iter, y_val_iter = model_selection.train_test_split(x_iter, y_iter, test_size=test_size)\n",
    "        validation_data_iter = (x_val_iter, y_val_iter)\n",
    "    else:\n",
    "        validation_data_iter = validation_data\n",
    "    \n",
    "#     print(len(y_iter), len(validation_data_iter[1]))\n",
    "    return x_iter, y_iter, validation_data_iter\n",
    "\n",
    "\n",
    "class RandomSearch(AnytimeAlgorithm):\n",
    "    @staticmethod\n",
    "    def sample_combination(values):\n",
    "        combination = list()\n",
    "        for value in values:\n",
    "            if isinstance(value, Range):\n",
    "                combination.append(value.sample())\n",
    "            else:\n",
    "                combination.append(value)\n",
    "        return tuple(combination)\n",
    "    \n",
    "    @interruptible\n",
    "    def run(self, train_fn, x, y, validation_data=None, postprocess_fn=identity_postprocess, fraction=None, test_size=None, *args, **kwargs):\n",
    "        super().run()\n",
    "\n",
    "        start_time = time.time()\n",
    "        histories = list()\n",
    "\n",
    "        best_overall_val_metric = -np.inf\n",
    "        best_overall_combination = None\n",
    "\n",
    "        while True:\n",
    "            start_time = time.time()\n",
    "            combination_args = self.sample_combination([*args])\n",
    "            combination_kwargs = dict(zip(kwargs.keys(), self.sample_combination(list(kwargs.values()))))\n",
    "            combination_args, combination_kwargs = postprocess_fn(combination_args, combination_kwargs)\n",
    "            \n",
    "            combination = combination_args + tuple(combination_kwargs.values())\n",
    "            print(f\"Run with parameters {combination} started...\")\n",
    "            \n",
    "            x_iter, y_iter, validation_data_iter = get_data_for_run(x, y, validation_data, fraction, test_size)\n",
    "\n",
    "            history = train_fn(x_iter, y_iter, validation_data_iter, *combination_args, **combination_kwargs)\n",
    "            history['parameters'] = combination\n",
    "            histories.append(history)\n",
    "\n",
    "            duration = time.time() - start_time\n",
    "            best_loss, best_metric, best_val_loss, best_val_metric, best_hidden_layer_sizes = get_statistics_from_history(history)\n",
    "            print(f\"Run with parameters {combination} completed, duration {round(duration, 1)}, best_val_loss: {best_val_loss}, best_val_metric: {best_val_metric}, best_hidden_layer_sizes: {best_hidden_layer_sizes}\")\n",
    "\n",
    "            if best_val_metric > best_overall_val_metric:\n",
    "                best_overall_val_metric = best_val_metric\n",
    "                best_overall_combination = combination\n",
    "            \n",
    "            \n",
    "            result = AnytimeAlgorithmResult(loss=best_loss, metric=best_metric, val_loss=best_val_loss, val_metric=best_val_metric,\n",
    "                                            hidden_layer_sizes=best_hidden_layer_sizes, duration=duration, args=combination_args, kwargs=combination_kwargs)\n",
    "            self.log_result(result)\n",
    "            print(f'Total duration {round(self.get_total_duration(), 1)}, mean val metric {self.get_mean_val_metric()}, mean duration {round(self.get_mean_duration(), 1)}, best overall combination: {best_overall_combination}, val_metric: {best_overall_val_metric}')\n",
    "\n",
    "\n",
    "class AnytimeGridSearch(AnytimeAlgorithm):\n",
    "    @staticmethod\n",
    "    def get_range_arguments(arguments):\n",
    "        return [argument for argument in arguments if isinstance(argument, Range)]\n",
    "    \n",
    "    @staticmethod\n",
    "    def _raw_relative_combinations_for_level(level, n_range_arguments):\n",
    "        l = level + 1\n",
    "        single_argument_values = tuple(i / (2 ** l) for i in range(1, 2 ** l))\n",
    "        all_argument_values = [single_argument_values for _ in range(n_range_arguments)]\n",
    "        return list(itertools.product(*all_argument_values))\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_relative_combinations_for_level(level, n_range_arguments, randomize):\n",
    "        relative_combinations = set(AnytimeGridSearch._raw_relative_combinations_for_level(level, n_range_arguments))\n",
    "        previous_combinations = set()\n",
    "        for i in range(0, level):\n",
    "            previous_combinations = previous_combinations.union(set(AnytimeGridSearch._raw_relative_combinations_for_level(i, n_range_arguments)))\n",
    "        relative_combinations = list(relative_combinations.difference(previous_combinations))\n",
    "        if randomize:\n",
    "            random.shuffle(relative_combinations)\n",
    "        return relative_combinations\n",
    "    \n",
    "    @staticmethod\n",
    "    def relative_combination_to_range_argument_combination(relative_combination, range_arguments):\n",
    "        return [range_argument.sample(x=relative_value) for range_argument, relative_value in zip(range_arguments, relative_combination)]\n",
    "    \n",
    "    @staticmethod\n",
    "    def range_argument_combination_to_combination(range_argument_combination, arguments):\n",
    "        combination = list()\n",
    "        range_argument_combination = collections.deque(range_argument_combination)\n",
    "        for argument in arguments:\n",
    "            if isinstance(argument, Range):\n",
    "                # Range argument, take its value from the generated relative argument combination\n",
    "                value = range_argument_combination.popleft()\n",
    "            else:\n",
    "                # Normal argument, use it directly\n",
    "                value = argument\n",
    "            combination.append(value)\n",
    "        return tuple(combination)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_combinations_for_level(level, arguments, randomize):\n",
    "        range_arguments = AnytimeGridSearch.get_range_arguments(arguments)\n",
    "        relative_combinations = AnytimeGridSearch.get_relative_combinations_for_level(level, len(range_arguments), randomize)\n",
    "        range_argument_combinations = [AnytimeGridSearch.relative_combination_to_range_argument_combination(relative_combination, range_arguments) \n",
    "                                       for relative_combination in relative_combinations]\n",
    "        combinations = [AnytimeGridSearch.range_argument_combination_to_combination(range_argument_combination, arguments) \n",
    "                        for range_argument_combination in range_argument_combinations]\n",
    "        return combinations\n",
    "    \n",
    "    @interruptible\n",
    "    def run(self, train_fn, x, y, validation_data=None, postprocess_fn=identity_postprocess, fraction=None, test_size=None, randomize=True, *args, **kwargs):\n",
    "        super().run()\n",
    "\n",
    "        start_time = time.time()\n",
    "        histories = list()\n",
    "\n",
    "        best_overall_val_metric = -np.inf\n",
    "        best_overall_combination = None\n",
    "\n",
    "        level = 0\n",
    "        arguments = [*args] + list(kwargs.values())\n",
    "        while True:\n",
    "            for combination in AnytimeGridSearch.get_combinations_for_level(level, arguments, randomize):\n",
    "                start_time = time.time()\n",
    "                combination_args = combination[:len(args)]\n",
    "                combination_kwargs = dict(zip(kwargs.keys(), combination[len(args):]))\n",
    "                combination_args, combination_kwargs = postprocess_fn(combination_args, combination_kwargs)\n",
    "                \n",
    "                combination = combination_args + tuple(combination_kwargs.values())\n",
    "                print(f\"Run with parameters {combination} started...\")\n",
    "                \n",
    "                x_iter, y_iter, validation_data_iter = get_data_for_run(x, y, validation_data, fraction, test_size)\n",
    "\n",
    "                history = train_fn(x_iter, y_iter, validation_data_iter, *combination_args, **combination_kwargs)\n",
    "                history['parameters'] = combination\n",
    "                histories.append(history)\n",
    "\n",
    "                duration = time.time() - start_time\n",
    "                best_loss, best_metric, best_val_loss, best_val_metric, best_hidden_layer_sizes = get_statistics_from_history(history)\n",
    "                print(f\"Run with parameters {combination} completed, duration {round(duration, 1)}, best_val_loss: {best_val_loss}, best_val_metric: {best_val_metric}, best_hidden_layer_sizes: {best_hidden_layer_sizes}\")\n",
    "\n",
    "                if best_val_metric > best_overall_val_metric:\n",
    "                    best_overall_val_metric = best_val_metric\n",
    "                    best_overall_combination = combination\n",
    "                \n",
    "                result = AnytimeAlgorithmResult(loss=best_loss, metric=best_metric, val_loss=best_val_loss, val_metric=best_val_metric,\n",
    "                                                hidden_layer_sizes=best_hidden_layer_sizes, duration=duration, args=combination_args, kwargs=combination_kwargs,\n",
    "                                                level=level)\n",
    "                self.log_result(result)\n",
    "                print(f'Total duration {round(self.get_total_duration(), 1)}, mean val metric {self.get_mean_val_metric()}, mean duration {round(self.get_mean_duration(), 1)}, best overall combination: {best_overall_combination}, val_metric: {best_overall_val_metric}')\n",
    "            level += 1\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# HELPER FUNCTIONS\n",
    "################################################################################\n",
    "\n",
    "\n",
    "def merge_histories(history1, history2):\n",
    "    merged_history = dict()\n",
    "    for key in history1.keys():\n",
    "        merged_history[key] = history1[key] + history2[key]\n",
    "    return merged_history\n",
    "\n",
    "\n",
    "def get_convolutional_model(x, layer_sizes, output_neurons=10):\n",
    "    model = Sequential([\n",
    "        Conv2D(layer_sizes[0], filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', kernel_initializer='lecun_normal', input_shape=x[0,:,:,:].shape),\n",
    "        Conv2D(layer_sizes[1], filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', kernel_initializer='lecun_normal'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        Conv2D(layer_sizes[2], filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', kernel_initializer='lecun_normal'),\n",
    "        Conv2D(layer_sizes[3], filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', kernel_initializer='lecun_normal'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        Flatten(),\n",
    "        Dense(layer_sizes[4], activation='selu', kernel_initializer='lecun_normal'),\n",
    "        Dense(output_neurons, activation='softmax', fixed_size=True),\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_dense_model(x, layer_sizes):\n",
    "    layers = list()\n",
    "    \n",
    "    layers.append(Dense(layer_sizes[0], activation='selu', kernel_initializer='lecun_normal', input_shape=x[0, :].shape))\n",
    "    for layer_size in layer_sizes[1:]:\n",
    "        layers.append(Dense(layer_size, activation='selu', kernel_initializer='lecun_normal'))\n",
    "    layers.append(Dense(1, activation=None, kernel_initializer='lecun_normal', fixed_size=True))\n",
    "    \n",
    "    model = Sequential(layers)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_fn_conv(x, y, validation_data, learning_rate, schedule, layer_sizes, output_neurons=10, min_new_neurons=20, \n",
    "             growth_percentage=0.2, verbose=False, use_static_graph=True, batch_size=128):\n",
    "    model = get_convolutional_model(x, layer_sizes, output_neurons)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    history = model.fit(x=x, y=y, optimizer=optimizer, schedule=schedule, batch_size=batch_size, min_new_neurons=min_new_neurons, \n",
    "                        validation_data=validation_data, growth_percentage=growth_percentage, verbose=verbose, use_static_graph=use_static_graph)\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "def early_stopping_conv(x, y, validation_data, learning_rate, schedule, layer_sizes, output_neurons=10, min_new_neurons=20, \n",
    "                        growth_percentage=0.2, verbose=False, use_static_graph=True, batch_size=128, max_setbacks=2):\n",
    "    assert len(schedule) == 1\n",
    "    \n",
    "    model = get_convolutional_model(x, layer_sizes, output_neurons)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    history = Sequential.ParameterContainer.prepare_history()\n",
    "    \n",
    "    best_val_loss = np.inf\n",
    "    n_setbacks = 0\n",
    "    while True:\n",
    "        epoch_history = model.fit(x=x, y=y, optimizer=optimizer, schedule=schedule, batch_size=batch_size, min_new_neurons=min_new_neurons, \n",
    "                                  validation_data=validation_data, growth_percentage=growth_percentage, verbose=verbose, use_static_graph=use_static_graph)\n",
    "        history = merge_histories(history, epoch_history)\n",
    "        val_loss = epoch_history['val_loss'][-1]\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            n_setbacks = 0\n",
    "        else:\n",
    "            n_setbacks += 1\n",
    "            if n_setbacks > max_setbacks:\n",
    "                break\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "def squared_error(y_true, y_pred):\n",
    "    return (y_true - y_pred) ** 2\n",
    "\n",
    "\n",
    "def train_fn_dense(x, y, validation_data, learning_rate, schedule, layer_sizes, min_new_neurons=20, \n",
    "             growth_percentage=0.2, verbose=False, use_static_graph=True, batch_size=128):\n",
    "    model = get_dense_model(x, layer_sizes)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    history = model.fit(x=x, y=y, optimizer=optimizer, schedule=schedule, batch_size=batch_size, min_new_neurons=min_new_neurons, \n",
    "                        validation_data=validation_data, growth_percentage=growth_percentage, verbose=verbose, use_static_graph=use_static_graph,\n",
    "                        loss_fn=squared_error, metric_fn=squared_error)\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "def layer_sizes_join_postprocess(args, kwargs):\n",
    "    kwargs['layer_sizes'] = kwargs['layer_1_size'], kwargs['layer_2_size'], kwargs['layer_3_size'], kwargs['layer_4_size'], kwargs['layer_5_size']\n",
    "    del kwargs['layer_1_size'], kwargs['layer_2_size'], kwargs['layer_3_size'], kwargs['layer_4_size'], kwargs['layer_5_size']\n",
    "    return args, kwargs\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# EVOLUTION\n",
    "################################################################################\n",
    "\n",
    "\n",
    "class Hyperparameter:\n",
    "    def __init__(self, initial_value, min_value, max_value, strategy):\n",
    "        self.initial_value = initial_value\n",
    "        self.min_value = min_value\n",
    "        self.max_value = max_value\n",
    "        self.strategy = strategy\n",
    "\n",
    "class Individual:\n",
    "    def __init__(self, x, layer_sizes, output_neurons, hyperparameters):\n",
    "        self.genome = np.array([\n",
    "            hyperparameters['regularization_penalty'].initial_value, \n",
    "            hyperparameters['learning_rate'].initial_value, \n",
    "            hyperparameters['batch_size'].initial_value, \n",
    "        ])\n",
    "        self.model = get_convolutional_model(x, layer_sizes, output_neurons=output_neurons)\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.get_learning_rate())\n",
    "        self.history = Sequential.ParameterContainer.prepare_history()\n",
    "        self.age = 0\n",
    "        \n",
    "        self.model.build(x.shape)\n",
    "    \n",
    "    def copy(self):\n",
    "        individual_copy = Individual.__new__(Individual)\n",
    "        individual_copy.genome = self.genome.copy()\n",
    "        individual_copy.model = self.model.copy()\n",
    "        individual_copy.optimizer = copy.deepcopy(self.optimizer)\n",
    "        individual_copy.history = copy.deepcopy(self.history)\n",
    "        individual_copy.age = self.age\n",
    "        return individual_copy\n",
    "    \n",
    "    def mutate(self, mutation_strength):\n",
    "        if mutation_strength > 0:\n",
    "            self.model.mutate(mutation_strength)\n",
    "    \n",
    "    def correct(self, hyperparameters):\n",
    "        self.genome[0] = np.clip(self.genome[0], hyperparameters['regularization_penalty'].min_value, hyperparameters['regularization_penalty'].max_value)\n",
    "        self.genome[1] = np.clip(self.genome[1], hyperparameters['learning_rate'].min_value, hyperparameters['learning_rate'].max_value)\n",
    "        self.genome[2] = np.clip(self.genome[2], hyperparameters['batch_size'].min_value, hyperparameters['batch_size'].max_value)\n",
    "    \n",
    "    def get_loss(self):\n",
    "        return self.history['loss'][-1]\n",
    "    \n",
    "    def get_metric(self):\n",
    "        return self.history['metric'][-1]\n",
    "    \n",
    "    def get_val_loss(self):\n",
    "        return self.history['val_loss'][-1]\n",
    "    \n",
    "    def get_val_metric(self):\n",
    "        return self.history['val_metric'][-1]\n",
    "    \n",
    "    def get_hidden_layer_sizes(self):\n",
    "        return self.history['hidden_layer_sizes'][-1]\n",
    "    \n",
    "    def get_age(self):\n",
    "#         return len(self.history['val_metric'])\n",
    "        return self.age\n",
    "    \n",
    "    def get_age_penalty_coefficient(self, age_penalty_period):\n",
    "        age = self.get_age()\n",
    "#         return 1 / (2 ** max(0, (age - age_penalty_period) / age_penalty_period))\n",
    "        if age <= age_penalty_period:\n",
    "            return 1\n",
    "        return 1 / (1 + 0.005 * 1.8 ** (age - age_penalty_period))\n",
    "    \n",
    "    def get_fitness(self, age_penalty_period):\n",
    "        if age_penalty_period is None:\n",
    "            return self.get_val_metric()\n",
    "        return self.get_val_metric() * self.get_age_penalty_coefficient(age_penalty_period)\n",
    "    \n",
    "    def get_regularization_penalty(self):\n",
    "        return 10. ** -self.genome[0]\n",
    "    \n",
    "    def get_learning_rate(self):\n",
    "        return self.genome[1]\n",
    "    \n",
    "    def get_batch_size(self):\n",
    "        return int(self.genome[2])\n",
    "\n",
    "\n",
    "class Evolution(AnytimeAlgorithm):\n",
    "    @staticmethod\n",
    "    def initialize_population(population_size, x, layer_sizes, output_neurons, hyperparameters):\n",
    "        population = [Individual(x, layer_sizes, output_neurons, hyperparameters) for _ in range(population_size)]\n",
    "        return population\n",
    "\n",
    "    @staticmethod\n",
    "    def introduce_new_individuals(population, n_introduced, x, layer_sizes, output_neurons, hyperparameters):\n",
    "        introduced_individuals = [Individual(x, layer_sizes, output_neurons, hyperparameters) for _ in range(n_introduced)]\n",
    "        return population + introduced_individuals\n",
    "\n",
    "    @staticmethod\n",
    "    def get_best_individual_by_fitness(population, age_penalty_period):\n",
    "        return max(population, key=lambda x: x.get_fitness(age_penalty_period))\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_best_individual_by_val_metric(population):\n",
    "        return max(population, key=lambda x: x.get_val_metric())\n",
    "\n",
    "    @staticmethod\n",
    "    def get_strategy(hyperparameters):\n",
    "        return [\n",
    "            hyperparameters['regularization_penalty'].strategy, \n",
    "            hyperparameters['learning_rate'].strategy, \n",
    "            hyperparameters['batch_size'].strategy\n",
    "        ]\n",
    "    \n",
    "    @staticmethod\n",
    "    def crossover(population, n_parents, mutation_strength, hyperparameters):\n",
    "        novel_population = list()\n",
    "        for individual in population:\n",
    "            parents_selection = np.random.choice(list(range(len(population))), size=n_parents, replace=False)\n",
    "            parent_genomes = [population[index].genome for index in parents_selection]\n",
    "            offspring_genome = np.mean(np.vstack(parent_genomes), axis=0)\n",
    "            offspring = individual.copy()\n",
    "            offspring.genome = offspring_genome\n",
    "            offspring.genome += np.random.normal(0, 1, offspring.genome.shape) * Evolution.get_strategy(hyperparameters)\n",
    "            offspring.correct(hyperparameters)\n",
    "            offspring.optimizer.learning_rate.assign(offspring.get_learning_rate())\n",
    "            offspring.mutate(mutation_strength)\n",
    "            novel_population.append(offspring)\n",
    "        return population + novel_population\n",
    "\n",
    "    # @staticmethod\n",
    "    # def mutation(population, mutation_strength):\n",
    "    #     new_population = list()\n",
    "    #     for individual in population:\n",
    "    #         individual_copy = individual.copy()\n",
    "    #         individual_copy.mutate(mutation_strength)\n",
    "    #         new_population.extend([individual, individual_copy])\n",
    "    #     return new_population\n",
    "\n",
    "    @staticmethod\n",
    "    def extend_history(old_history, new_history):\n",
    "        for key in old_history.keys():\n",
    "            old_history[key].extend(new_history[key])\n",
    "\n",
    "    @staticmethod\n",
    "    def training(population, x, y, validation_data, min_new_neurons, growth_percentage, verbose, use_static_graph, age_penalty_period, fine_tuning):\n",
    "        for individual in population:\n",
    "            model = individual.model\n",
    "            optimizer = individual.optimizer\n",
    "            # schedule = Schedule([StaticEpochNoRegularization()])\n",
    "            if fine_tuning and individual.get_age() >= age_penalty_period:\n",
    "                schedule = Schedule([StaticEpochNoRegularization()])\n",
    "            else:\n",
    "                schedule = Schedule([DynamicEpoch(individual.get_regularization_penalty(), 'weighted_l1')])\n",
    "            x_train_sample, y_train_sample = x, y\n",
    "            x_test_sample, y_test_sample = validation_data[0], validation_data[1]\n",
    "            history = model.fit(x=x_train_sample, y=y_train_sample, optimizer=optimizer, schedule=schedule, batch_size=individual.get_batch_size(), \n",
    "                                min_new_neurons=min_new_neurons, validation_data=(x_test_sample, y_test_sample), growth_percentage=growth_percentage, \n",
    "                                verbose=verbose, use_static_graph=use_static_graph)\n",
    "            Evolution.extend_history(individual.history, history)\n",
    "        return population\n",
    "\n",
    "    @staticmethod\n",
    "    def tournament_selection(population, population_size, tournament_size, age_penalty_period):\n",
    "        new_population = list()\n",
    "\n",
    "        while len(new_population) < population_size:\n",
    "            selection = np.random.choice(list(range(len(population))), size=tournament_size, replace=False)\n",
    "            best_individual = None\n",
    "            best_fitness = - np.inf\n",
    "            for individual_index in selection:\n",
    "                individual = population[individual_index]\n",
    "                fitness = individual.get_fitness(age_penalty_period)\n",
    "                if fitness > best_fitness:\n",
    "                    best_individual = individual\n",
    "                    best_fitness = fitness\n",
    "            new_population.append(best_individual.copy())\n",
    "\n",
    "        return new_population\n",
    "    \n",
    "    @staticmethod\n",
    "    def age_population(population):\n",
    "        for individual in population:\n",
    "            individual.age += 1\n",
    "        return population\n",
    "\n",
    "    @staticmethod\n",
    "    def measure_fitnesses(population, age_penalty_period):\n",
    "        fitnesses = list()\n",
    "        for individual in population:\n",
    "            fitnesses.append(individual.get_fitness(age_penalty_period))\n",
    "        return fitnesses\n",
    "\n",
    "    def print_generation_statistics(self, generation, population, duration, age_penalty_period):\n",
    "        population_sorted_by_fitness = sorted(population, key=lambda x: x.get_fitness(age_penalty_period), reverse=True)\n",
    "        individuals = [\n",
    "            (\n",
    "                individual.get_age(), \n",
    "                round(individual.get_val_metric(), 4), \n",
    "                round(individual.get_fitness(age_penalty_period), 4), \n",
    "                individual.get_regularization_penalty(),\n",
    "                individual.get_learning_rate(),\n",
    "                individual.get_batch_size(),\n",
    "                individual.get_hidden_layer_sizes(),\n",
    "            ) \n",
    "            for individual in population_sorted_by_fitness\n",
    "        ]\n",
    "        population_sorted_by_val_metric = sorted(population, key=lambda x: x.get_val_metric(), reverse=True)\n",
    "        best_individual = population_sorted_by_val_metric[0]\n",
    "        result = AnytimeAlgorithmResult(\n",
    "            loss=best_individual.get_loss(), \n",
    "            metric=best_individual.get_metric(), \n",
    "            val_loss=best_individual.get_val_loss(), \n",
    "            val_metric=best_individual.get_val_metric(),\n",
    "            hidden_layer_sizes=best_individual.get_hidden_layer_sizes(), \n",
    "            duration=duration,\n",
    "            args=list(), \n",
    "            kwargs={'regularization_penalty': best_individual.get_regularization_penalty(), \n",
    "                    'learning_rate': best_individual.get_learning_rate(), 'batch_size': best_individual.get_batch_size()},\n",
    "        )\n",
    "        self.log_result(result)\n",
    "        print(f\"Generation {generation}: {round(duration, 1)} s, best val metric {round(best_individual.get_val_metric(), 4)}, {individuals}\")\n",
    "        print(f\"#### Total duration {round(self.get_total_duration(), 1)}, overall best val metric {self.best_val_metric} ####\")\n",
    "\n",
    "    @interruptible\n",
    "    def run(self, x, y, validation_data, layer_sizes, output_neurons, hyperparameters, n_parents, population_size=10, n_generations=10, \n",
    "            tournament_size=3, elitism=True, n_introduced=0, age_penalty_period=None, min_new_neurons=20, growth_percentage=0.2, use_static_graph=False, \n",
    "            mutation_strength=0., fine_tuning=False, fraction=None, test_size=None):\n",
    "        super().run()\n",
    "        \n",
    "        x, y, validation_data = get_data_for_run(x, y, validation_data, fraction, test_size)\n",
    "        population = self.initialize_population(population_size, x, layer_sizes, output_neurons, hyperparameters)\n",
    "        best_individual = None\n",
    "        fitnesses_history = list()\n",
    "        generation = 0\n",
    "        while True:\n",
    "            if generation >= n_generations:\n",
    "                break\n",
    "            start_time = time.time()\n",
    "            population = self.crossover(population, n_parents, mutation_strength, hyperparameters)\n",
    "            # population = mutation(population, mutation_strength)\n",
    "            population = self.introduce_new_individuals(population, n_introduced, x, layer_sizes, output_neurons, hyperparameters)\n",
    "            population = self.training(population, x, y, validation_data, min_new_neurons, growth_percentage, verbose=False, \n",
    "                                       use_static_graph=use_static_graph, age_penalty_period=age_penalty_period, fine_tuning=fine_tuning)\n",
    "            population = self.tournament_selection(population, population_size, tournament_size, age_penalty_period)\n",
    "            if elitism:\n",
    "                if best_individual is not None:\n",
    "                    population.append(best_individual)\n",
    "            population = self.age_population(population)\n",
    "            if elitism:\n",
    "                best_individual = self.get_best_individual_by_fitness(population, age_penalty_period).copy()\n",
    "            fitnesses = self.measure_fitnesses(population, age_penalty_period)\n",
    "            duration = time.time() - start_time\n",
    "            self.print_generation_statistics(generation, population, duration, age_penalty_period)\n",
    "            generation += 1\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# HELPER FUNCTIONS\n",
    "################################################################################\n",
    "\n",
    "\n",
    "def save_results(obj, name):\n",
    "    filename = f\"results/{name}{datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(obj, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(f\"Saved results to file {filename}\")\n",
    "\n",
    "\n",
    "def anytime_multirun(anytime_cls, n_runs, save, *args, **kwargs):\n",
    "    all_results = list()\n",
    "    all_dict_results = list()\n",
    "    for run in range(n_runs):\n",
    "        print()\n",
    "        print(f\"###########################################\")\n",
    "        print(f\"Started run {run}...\")\n",
    "        algorithm = anytime_cls()\n",
    "        algorithm.run(*args, **kwargs)\n",
    "        print(f\"Total run duration {algorithm.get_total_duration()}, mean duration {algorithm.get_mean_duration()}, mean val metric {algorithm.get_mean_val_metric()}\")\n",
    "        all_results.append(algorithm.results)\n",
    "        all_dict_results.append([result.to_dict() for result in algorithm.results])\n",
    "    \n",
    "    if save:\n",
    "        save_results(all_dict_results, name=str(anytime_cls.__name__))\n",
    "    \n",
    "    print(\"Completed.\")\n",
    "    return all_results\n",
    "\n",
    "\n",
    "def sample_random_search(results, min_duration):\n",
    "    shuffled_results = results.copy()\n",
    "    random.shuffle(shuffled_results)\n",
    "    sampled_results = list()\n",
    "    for result in shuffled_results:\n",
    "        if AnytimeAlgorithm.get_total_duration_from_results(sampled_results) >= min_duration:\n",
    "            return sampled_results\n",
    "        sampled_results.append(result)\n",
    "    raise Exception(\"Not enough results to reach specified duration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo sampling from hyperparameter searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashnion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = get_fashion_mnist_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Static models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with parameters (0e6b7762ad(6.468213629871641e-05), 0.00036839161659472166, 44, 10, 20, 0.2, False, 2, (17, 50, 19, 88, 63)) started...\n",
      "Run with parameters (0e6b7762ad(6.468213629871641e-05), 0.00036839161659472166, 44, 10, 20, 0.2, False, 2, (17, 50, 19, 88, 63)) completed, best_val_loss: 0.5622777342796326, best_val_metric: 0.8390804597701149, best_hidden_layer_sizes: [17, 50, 19, 88, 63]\n",
      "Duration 18.6, best overall combination: (0e6b7762ad(6.468213629871641e-05), 0.00036839161659472166, 44, 10, 20, 0.2, False, 2, (17, 50, 19, 88, 63)), val_metric: 0.8390804597701149\n",
      "Run with parameters (2e122239cb(0.0005530237564695318), 0.0005950746846707398, 64, 10, 20, 0.2, False, 2, (97, 26, 10, 50, 49)) started...\n",
      "Run with parameters (2e122239cb(0.0005530237564695318), 0.0005950746846707398, 64, 10, 20, 0.2, False, 2, (97, 26, 10, 50, 49)) completed, best_val_loss: 0.5839619040489197, best_val_metric: 0.813953488372093, best_hidden_layer_sizes: [97, 26, 10, 50, 49]\n",
      "Duration 11.7, best overall combination: (0e6b7762ad(6.468213629871641e-05), 0.00036839161659472166, 44, 10, 20, 0.2, False, 2, (17, 50, 19, 88, 63)), val_metric: 0.8390804597701149\n",
      "Run with parameters (3a10949da7(0.00019291648110813665), 0.00043158884094476847, 61, 10, 20, 0.2, False, 2, (95, 50, 85, 21, 37)) started...\n",
      "Run with parameters (3a10949da7(0.00019291648110813665), 0.00043158884094476847, 61, 10, 20, 0.2, False, 2, (95, 50, 85, 21, 37)) completed, best_val_loss: 0.6317846775054932, best_val_metric: 0.7902298850574713, best_hidden_layer_sizes: [95, 50, 85, 21, 37]\n",
      "Duration 31.0, best overall combination: (0e6b7762ad(6.468213629871641e-05), 0.00036839161659472166, 44, 10, 20, 0.2, False, 2, (17, 50, 19, 88, 63)), val_metric: 0.8390804597701149\n",
      "Run with parameters (6379997dcd(0.002462588686559862), 0.00038833777906125826, 17, 10, 20, 0.2, False, 2, (39, 75, 80, 41, 23)) started...\n",
      "Run with parameters (6379997dcd(0.002462588686559862), 0.00038833777906125826, 17, 10, 20, 0.2, False, 2, (39, 75, 80, 41, 23)) completed, best_val_loss: 0.6242477893829346, best_val_metric: 0.7906976744186046, best_hidden_layer_sizes: [39, 75, 80, 41, 23]\n",
      "Duration 39.0, best overall combination: (0e6b7762ad(6.468213629871641e-05), 0.00036839161659472166, 44, 10, 20, 0.2, False, 2, (17, 50, 19, 88, 63)), val_metric: 0.8390804597701149\n",
      "Run with parameters (3f285a865a(3.524005611432898e-05), 0.0002224280673393589, 32, 10, 20, 0.2, False, 2, (15, 37, 67, 48, 24)) started...\n",
      "Run with parameters (3f285a865a(3.524005611432898e-05), 0.0002224280673393589, 32, 10, 20, 0.2, False, 2, (15, 37, 67, 48, 24)) completed, best_val_loss: 0.48365968465805054, best_val_metric: 0.8704225352112676, best_hidden_layer_sizes: [15, 37, 67, 48, 24]\n",
      "Duration 34.9, best overall combination: (3f285a865a(3.524005611432898e-05), 0.0002224280673393589, 32, 10, 20, 0.2, False, 2, (15, 37, 67, 48, 24)), val_metric: 0.8704225352112676\n",
      "Run with parameters (317146bef3(0.0012084440712761334), 0.0002954432655536341, 34, 10, 20, 0.2, False, 2, (42, 85, 12, 65, 45)) started...\n",
      "Run with parameters (317146bef3(0.0012084440712761334), 0.0002954432655536341, 34, 10, 20, 0.2, False, 2, (42, 85, 12, 65, 45)) completed, best_val_loss: 0.6607853770256042, best_val_metric: 0.7873563218390804, best_hidden_layer_sizes: [42, 85, 12, 65, 45]\n",
      "Duration 29.0, best overall combination: (3f285a865a(3.524005611432898e-05), 0.0002224280673393589, 32, 10, 20, 0.2, False, 2, (15, 37, 67, 48, 24)), val_metric: 0.8704225352112676\n",
      "Run with parameters (aa252b78e5(0.00012723456121488372), 0.0004524244157409927, 58, 10, 20, 0.2, False, 2, (36, 21, 87, 71, 50)) started...\n",
      "Run with parameters (aa252b78e5(0.00012723456121488372), 0.0004524244157409927, 58, 10, 20, 0.2, False, 2, (36, 21, 87, 71, 50)) completed, best_val_loss: 0.777006208896637, best_val_metric: 0.7854984894259819, best_hidden_layer_sizes: [36, 21, 87, 71, 50]\n",
      "Duration 11.0, best overall combination: (3f285a865a(3.524005611432898e-05), 0.0002224280673393589, 32, 10, 20, 0.2, False, 2, (15, 37, 67, 48, 24)), val_metric: 0.8704225352112676\n",
      "Run with parameters (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)) started...\n",
      "Run with parameters (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)) completed, best_val_loss: 0.4544597268104553, best_val_metric: 0.8715083798882681, best_hidden_layer_sizes: [73, 77, 52, 26, 55]\n",
      "Duration 50.4, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (fe20f54de1(5.986605871581991e-05), 0.0005600360332079101, 55, 10, 20, 0.2, False, 2, (58, 23, 16, 85, 97)) started...\n",
      "Run with parameters (fe20f54de1(5.986605871581991e-05), 0.0005600360332079101, 55, 10, 20, 0.2, False, 2, (58, 23, 16, 85, 97)) completed, best_val_loss: 0.6707861423492432, best_val_metric: 0.8168604651162791, best_hidden_layer_sizes: [58, 23, 16, 85, 97]\n",
      "Duration 11.1, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (5c6f9a9bf1(9.184575044233657e-05), 0.00044098655729015633, 49, 10, 20, 0.2, False, 2, (41, 52, 14, 23, 62)) started...\n",
      "Run with parameters (5c6f9a9bf1(9.184575044233657e-05), 0.00044098655729015633, 49, 10, 20, 0.2, False, 2, (41, 52, 14, 23, 62)) completed, best_val_loss: 0.4867821931838989, best_val_metric: 0.8674033149171271, best_hidden_layer_sizes: [41, 52, 14, 23, 62]\n",
      "Duration 20.9, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (968822cabb(0.00020852715695207112), 0.0003617124027229607, 58, 10, 20, 0.2, False, 2, (96, 89, 30, 26, 32)) started...\n",
      "Run with parameters (968822cabb(0.00020852715695207112), 0.0003617124027229607, 58, 10, 20, 0.2, False, 2, (96, 89, 30, 26, 32)) completed, best_val_loss: 0.4264620840549469, best_val_metric: 0.8575418994413407, best_hidden_layer_sizes: [96, 89, 30, 26, 32]\n",
      "Duration 47.5, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (00c2aaf948(0.0011422148519437253), 0.00040669283771917463, 43, 10, 20, 0.2, False, 2, (23, 83, 88, 56, 23)) started...\n",
      "Run with parameters (00c2aaf948(0.0011422148519437253), 0.00040669283771917463, 43, 10, 20, 0.2, False, 2, (23, 83, 88, 56, 23)) completed, best_val_loss: 0.5831394791603088, best_val_metric: 0.8166189111747851, best_hidden_layer_sizes: [23, 83, 88, 56, 23]\n",
      "Duration 20.9, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (0fb20cf871(0.0004353379949417272), 0.00046519050576728866, 25, 10, 20, 0.2, False, 2, (42, 76, 42, 68, 99)) started...\n",
      "Run with parameters (0fb20cf871(0.0004353379949417272), 0.00046519050576728866, 25, 10, 20, 0.2, False, 2, (42, 76, 42, 68, 99)) completed, best_val_loss: 0.5780739188194275, best_val_metric: 0.8240223463687151, best_hidden_layer_sizes: [42, 76, 42, 68, 99]\n",
      "Duration 28.4, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (23980e8cf5(7.005881092548179e-05), 0.0003590769092389251, 53, 10, 20, 0.2, False, 2, (84, 60, 11, 59, 73)) started...\n",
      "Run with parameters (23980e8cf5(7.005881092548179e-05), 0.0003590769092389251, 53, 10, 20, 0.2, False, 2, (84, 60, 11, 59, 73)) completed, best_val_loss: 0.4757038950920105, best_val_metric: 0.8410404624277457, best_hidden_layer_sizes: [84, 60, 11, 59, 73]\n",
      "Duration 28.7, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (5165fec908(0.00042831844130333303), 0.000544413100219022, 23, 10, 20, 0.2, False, 2, (55, 51, 81, 33, 66)) started...\n",
      "Run with parameters (5165fec908(0.00042831844130333303), 0.000544413100219022, 23, 10, 20, 0.2, False, 2, (55, 51, 81, 33, 66)) completed, best_val_loss: 0.45650961995124817, best_val_metric: 0.8579881656804734, best_hidden_layer_sizes: [55, 51, 81, 33, 66]\n",
      "Duration 34.8, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (0e08865e6f(7.004091703348924e-05), 0.00048446498131063484, 31, 10, 20, 0.2, False, 2, (51, 37, 89, 87, 84)) started...\n",
      "Run with parameters (0e08865e6f(7.004091703348924e-05), 0.00048446498131063484, 31, 10, 20, 0.2, False, 2, (51, 37, 89, 87, 84)) completed, best_val_loss: 0.6723602414131165, best_val_metric: 0.8066298342541437, best_hidden_layer_sizes: [51, 37, 89, 87, 84]\n",
      "Duration 21.2, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (9ef8788899(0.0004914669064959427), 0.00039439510400364816, 31, 10, 20, 0.2, False, 2, (90, 82, 20, 97, 54)) started...\n",
      "Run with parameters (9ef8788899(0.0004914669064959427), 0.00039439510400364816, 31, 10, 20, 0.2, False, 2, (90, 82, 20, 97, 54)) completed, best_val_loss: 0.45692646503448486, best_val_metric: 0.8604651162790697, best_hidden_layer_sizes: [90, 82, 20, 97, 54]\n",
      "Duration 44.6, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (a6324f693c(5.9065848252084646e-05), 0.0005828913017571874, 21, 10, 20, 0.2, False, 2, (39, 72, 42, 99, 40)) started...\n",
      "Run with parameters (a6324f693c(5.9065848252084646e-05), 0.0005828913017571874, 21, 10, 20, 0.2, False, 2, (39, 72, 42, 99, 40)) completed, best_val_loss: 0.6764566898345947, best_val_metric: 0.7809798270893372, best_hidden_layer_sizes: [39, 72, 42, 99, 40]\n",
      "Duration 22.1, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (375f2de7cf(0.0021283979837725944), 0.00012904364738744903, 53, 10, 20, 0.2, False, 2, (81, 80, 98, 22, 76)) started...\n",
      "Run with parameters (375f2de7cf(0.0021283979837725944), 0.00012904364738744903, 53, 10, 20, 0.2, False, 2, (81, 80, 98, 22, 76)) completed, best_val_loss: 0.5578073263168335, best_val_metric: 0.8207282913165266, best_hidden_layer_sizes: [81, 80, 98, 22, 76]\n",
      "Duration 38.3, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (6c5bd50a03(7.791716673077633e-05), 0.00045461446263080947, 54, 10, 20, 0.2, False, 2, (68, 45, 88, 58, 86)) started...\n",
      "Run with parameters (6c5bd50a03(7.791716673077633e-05), 0.00045461446263080947, 54, 10, 20, 0.2, False, 2, (68, 45, 88, 58, 86)) completed, best_val_loss: 0.5484061241149902, best_val_metric: 0.8080229226361032, best_hidden_layer_sizes: [68, 45, 88, 58, 86]\n",
      "Duration 17.0, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (aa30b1e378(6.613604741619363e-05), 0.00010662287172480859, 33, 10, 20, 0.2, False, 2, (82, 26, 50, 24, 51)) started...\n",
      "Run with parameters (aa30b1e378(6.613604741619363e-05), 0.00010662287172480859, 33, 10, 20, 0.2, False, 2, (82, 26, 50, 24, 51)) completed, best_val_loss: 0.5629008412361145, best_val_metric: 0.8153409090909091, best_hidden_layer_sizes: [82, 26, 50, 24, 51]\n",
      "Duration 51.1, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (e8b06360dc(0.001640437191003505), 0.0002006896659662616, 64, 10, 20, 0.2, False, 2, (48, 46, 92, 93, 15)) started...\n",
      "Run with parameters (e8b06360dc(0.001640437191003505), 0.0002006896659662616, 64, 10, 20, 0.2, False, 2, (48, 46, 92, 93, 15)) completed, best_val_loss: 0.5544938445091248, best_val_metric: 0.8068181818181818, best_hidden_layer_sizes: [48, 46, 92, 93, 15]\n",
      "Duration 33.7, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (dd14014012(0.0013553251213559566), 0.00023516235236850544, 36, 10, 20, 0.2, False, 2, (37, 14, 64, 34, 94)) started...\n",
      "Run with parameters (dd14014012(0.0013553251213559566), 0.00023516235236850544, 36, 10, 20, 0.2, False, 2, (37, 14, 64, 34, 94)) completed, best_val_loss: 0.49984776973724365, best_val_metric: 0.8409090909090909, best_hidden_layer_sizes: [37, 14, 64, 34, 94]\n",
      "Duration 32.3, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (661817ebad(7.502639615505995e-05), 0.000521744685882929, 25, 10, 20, 0.2, False, 2, (38, 42, 95, 26, 65)) started...\n",
      "Run with parameters (661817ebad(7.502639615505995e-05), 0.000521744685882929, 25, 10, 20, 0.2, False, 2, (38, 42, 95, 26, 65)) completed, best_val_loss: 0.5442907810211182, best_val_metric: 0.8550295857988166, best_hidden_layer_sizes: [38, 42, 95, 26, 65]\n",
      "Duration 23.3, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (c000593797(6.587707337300806e-05), 0.0003401094508653971, 20, 10, 20, 0.2, False, 2, (92, 42, 81, 88, 79)) started...\n",
      "Run with parameters (c000593797(6.587707337300806e-05), 0.0003401094508653971, 20, 10, 20, 0.2, False, 2, (92, 42, 81, 88, 79)) completed, best_val_loss: 0.7839722633361816, best_val_metric: 0.8238805970149253, best_hidden_layer_sizes: [92, 42, 81, 88, 79]\n",
      "Duration 29.5, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (5c85e271ff(5.6964719857016015e-05), 0.00011383212930069721, 20, 10, 20, 0.2, False, 2, (73, 51, 70, 20, 44)) started...\n",
      "Run with parameters (5c85e271ff(5.6964719857016015e-05), 0.00011383212930069721, 20, 10, 20, 0.2, False, 2, (73, 51, 70, 20, 44)) completed, best_val_loss: 0.48255711793899536, best_val_metric: 0.8228571428571428, best_hidden_layer_sizes: [73, 51, 70, 20, 44]\n",
      "Duration 84.4, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (6ee85fb071(0.0004959823328356515), 0.00011020329395516695, 43, 10, 20, 0.2, False, 2, (33, 39, 25, 23, 66)) started...\n",
      "Run with parameters (6ee85fb071(0.0004959823328356515), 0.00011020329395516695, 43, 10, 20, 0.2, False, 2, (33, 39, 25, 23, 66)) completed, best_val_loss: 0.6102386713027954, best_val_metric: 0.8130311614730878, best_hidden_layer_sizes: [33, 39, 25, 23, 66]\n",
      "Duration 37.6, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (8550f6beb7(0.0010150175470755736), 0.00048529342339114834, 21, 10, 20, 0.2, False, 2, (78, 24, 31, 68, 69)) started...\n",
      "Run with parameters (8550f6beb7(0.0010150175470755736), 0.00048529342339114834, 21, 10, 20, 0.2, False, 2, (78, 24, 31, 68, 69)) completed, best_val_loss: 0.6083407402038574, best_val_metric: 0.8065476190476191, best_hidden_layer_sizes: [78, 24, 31, 68, 69]\n",
      "Duration 20.9, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (2c22b0c641(0.001645331137162991), 0.00026779018699804005, 61, 10, 20, 0.2, False, 2, (12, 47, 50, 90, 49)) started...\n",
      "Run with parameters (2c22b0c641(0.001645331137162991), 0.00026779018699804005, 61, 10, 20, 0.2, False, 2, (12, 47, 50, 90, 49)) completed, best_val_loss: 0.45668983459472656, best_val_metric: 0.8431372549019608, best_hidden_layer_sizes: [12, 47, 50, 90, 49]\n",
      "Duration 10.9, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (c892108b44(0.00016441418730391596), 0.0002301820311681091, 55, 10, 20, 0.2, False, 2, (43, 47, 86, 95, 43)) started...\n",
      "Run with parameters (c892108b44(0.00016441418730391596), 0.0002301820311681091, 55, 10, 20, 0.2, False, 2, (43, 47, 86, 95, 43)) completed, best_val_loss: 0.603632926940918, best_val_metric: 0.788135593220339, best_hidden_layer_sizes: [43, 47, 86, 95, 43]\n",
      "Duration 18.2, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (0cdad38a53(0.0030537444902944554), 0.0005818902253502521, 55, 10, 20, 0.2, False, 2, (69, 76, 65, 36, 51)) started...\n",
      "Run with parameters (0cdad38a53(0.0030537444902944554), 0.0005818902253502521, 55, 10, 20, 0.2, False, 2, (69, 76, 65, 36, 51)) completed, best_val_loss: 0.6824724078178406, best_val_metric: 0.775, best_hidden_layer_sizes: [69, 76, 65, 36, 51]\n",
      "Duration 33.7, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (c5ca6267c5(0.0008750207032593152), 0.0002719800559451692, 32, 10, 20, 0.2, False, 2, (29, 68, 49, 39, 65)) started...\n",
      "Run with parameters (c5ca6267c5(0.0008750207032593152), 0.0002719800559451692, 32, 10, 20, 0.2, False, 2, (29, 68, 49, 39, 65)) completed, best_val_loss: 0.4705738127231598, best_val_metric: 0.8575581395348837, best_hidden_layer_sizes: [29, 68, 49, 39, 65]\n",
      "Duration 38.6, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (82f59d3dde(0.00029995813327200955), 0.0005296081811501321, 50, 10, 20, 0.2, False, 2, (35, 68, 60, 71, 15)) started...\n",
      "Run with parameters (82f59d3dde(0.00029995813327200955), 0.0005296081811501321, 50, 10, 20, 0.2, False, 2, (35, 68, 60, 71, 15)) completed, best_val_loss: 0.6256659030914307, best_val_metric: 0.8011695906432749, best_hidden_layer_sizes: [35, 68, 60, 71, 15]\n",
      "Duration 20.5, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (9f5cbffda3(0.00223891491516641), 0.0005985360525953585, 27, 10, 20, 0.2, False, 2, (62, 45, 92, 51, 49)) started...\n",
      "Run with parameters (9f5cbffda3(0.00223891491516641), 0.0005985360525953585, 27, 10, 20, 0.2, False, 2, (62, 45, 92, 51, 49)) completed, best_val_loss: 0.6386071443557739, best_val_metric: 0.7965616045845272, best_hidden_layer_sizes: [62, 45, 92, 51, 49]\n",
      "Duration 40.0, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (96f77dccef(0.0009948584172665064), 0.0004805708278009051, 51, 10, 20, 0.2, False, 2, (29, 55, 95, 42, 93)) started...\n",
      "Run with parameters (96f77dccef(0.0009948584172665064), 0.0004805708278009051, 51, 10, 20, 0.2, False, 2, (29, 55, 95, 42, 93)) completed, best_val_loss: 0.6141446232795715, best_val_metric: 0.8035190615835777, best_hidden_layer_sizes: [29, 55, 95, 42, 93]\n",
      "Duration 22.0, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (c9939a0b38(0.0009347176151402905), 0.00040482277804842234, 33, 10, 20, 0.2, False, 2, (64, 63, 61, 29, 51)) started...\n",
      "Run with parameters (c9939a0b38(0.0009347176151402905), 0.00040482277804842234, 33, 10, 20, 0.2, False, 2, (64, 63, 61, 29, 51)) completed, best_val_loss: 0.5176527500152588, best_val_metric: 0.8367952522255193, best_hidden_layer_sizes: [64, 63, 61, 29, 51]\n",
      "Duration 26.3, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (c0939be520(0.0001336719971286285), 0.00017782157611803164, 58, 10, 20, 0.2, False, 2, (21, 60, 70, 73, 81)) started...\n",
      "Run with parameters (c0939be520(0.0001336719971286285), 0.00017782157611803164, 58, 10, 20, 0.2, False, 2, (21, 60, 70, 73, 81)) completed, best_val_loss: 0.4428728222846985, best_val_metric: 0.8575498575498576, best_hidden_layer_sizes: [21, 60, 70, 73, 81]\n",
      "Duration 18.8, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (3882dda732(3.9717383112901415e-05), 0.00015519235715530703, 32, 10, 20, 0.2, False, 2, (14, 51, 55, 39, 80)) started...\n",
      "Run with parameters (3882dda732(3.9717383112901415e-05), 0.00015519235715530703, 32, 10, 20, 0.2, False, 2, (14, 51, 55, 39, 80)) completed, best_val_loss: 0.5109801888465881, best_val_metric: 0.8455056179775281, best_hidden_layer_sizes: [14, 51, 55, 39, 80]\n",
      "Duration 35.0, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (d75d1b65c4(0.002041483003554862), 0.0003646152395096268, 25, 10, 20, 0.2, False, 2, (71, 68, 13, 47, 45)) started...\n",
      "Run with parameters (d75d1b65c4(0.002041483003554862), 0.0003646152395096268, 25, 10, 20, 0.2, False, 2, (71, 68, 13, 47, 45)) completed, best_val_loss: 0.49370333552360535, best_val_metric: 0.8092307692307692, best_hidden_layer_sizes: [71, 68, 13, 47, 45]\n",
      "Duration 44.2, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (c76730bede(0.00017044604594399266), 0.00032232006403697523, 54, 10, 20, 0.2, False, 2, (11, 51, 41, 78, 74)) started...\n",
      "Run with parameters (c76730bede(0.00017044604594399266), 0.00032232006403697523, 54, 10, 20, 0.2, False, 2, (11, 51, 41, 78, 74)) completed, best_val_loss: 0.6111934781074524, best_val_metric: 0.793002915451895, best_hidden_layer_sizes: [11, 51, 41, 78, 74]\n",
      "Duration 22.5, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (d476165000(0.00023513363799760643), 0.0003503126886953026, 20, 10, 20, 0.2, False, 2, (68, 87, 23, 65, 77)) started...\n",
      "Run with parameters (d476165000(0.00023513363799760643), 0.0003503126886953026, 20, 10, 20, 0.2, False, 2, (68, 87, 23, 65, 77)) completed, best_val_loss: 0.6271982789039612, best_val_metric: 0.8306451612903226, best_hidden_layer_sizes: [68, 87, 23, 65, 77]\n",
      "Duration 40.4, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (34d5aa3044(0.0024662219815960555), 0.0003817092194516443, 46, 10, 20, 0.2, False, 2, (70, 36, 79, 81, 81)) started...\n",
      "Run with parameters (34d5aa3044(0.0024662219815960555), 0.0003817092194516443, 46, 10, 20, 0.2, False, 2, (70, 36, 79, 81, 81)) completed, best_val_loss: 0.5823706984519958, best_val_metric: 0.7982954545454546, best_hidden_layer_sizes: [70, 36, 79, 81, 81]\n",
      "Duration 18.2, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (dd7af4be4d(0.0003308194881154381), 0.0003943946367244194, 33, 10, 20, 0.2, False, 2, (32, 67, 21, 78, 18)) started...\n",
      "Run with parameters (dd7af4be4d(0.0003308194881154381), 0.0003943946367244194, 33, 10, 20, 0.2, False, 2, (32, 67, 21, 78, 18)) completed, best_val_loss: 0.6344426870346069, best_val_metric: 0.7883008356545961, best_hidden_layer_sizes: [32, 67, 21, 78, 18]\n",
      "Duration 18.8, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (329ae81293(3.439342676543562e-05), 0.00018574503924324848, 22, 10, 20, 0.2, False, 2, (15, 23, 30, 49, 28)) started...\n",
      "Run with parameters (329ae81293(3.439342676543562e-05), 0.00018574503924324848, 22, 10, 20, 0.2, False, 2, (15, 23, 30, 49, 28)) completed, best_val_loss: 0.5033847689628601, best_val_metric: 0.8413173652694611, best_hidden_layer_sizes: [15, 23, 30, 49, 28]\n",
      "Duration 23.2, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (d686f08971(0.00014101802525861475), 0.00045150695951389966, 44, 10, 20, 0.2, False, 2, (16, 47, 16, 21, 99)) started...\n",
      "Run with parameters (d686f08971(0.00014101802525861475), 0.00045150695951389966, 44, 10, 20, 0.2, False, 2, (16, 47, 16, 21, 99)) completed, best_val_loss: 0.5361259579658508, best_val_metric: 0.8272980501392758, best_hidden_layer_sizes: [16, 47, 16, 21, 99]\n",
      "Duration 18.4, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (0d2c60d2b2(3.705863575736643e-05), 0.0002271465163785493, 37, 10, 20, 0.2, False, 2, (42, 85, 96, 90, 59)) started...\n",
      "Run with parameters (0d2c60d2b2(3.705863575736643e-05), 0.0002271465163785493, 37, 10, 20, 0.2, False, 2, (42, 85, 96, 90, 59)) completed, best_val_loss: 0.579254150390625, best_val_metric: 0.8125, best_hidden_layer_sizes: [42, 85, 96, 90, 59]\n",
      "Duration 20.2, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (d3b4b71926(0.0006258210305383072), 0.00024247379012647688, 62, 10, 20, 0.2, False, 2, (36, 25, 95, 100, 15)) started...\n",
      "Run with parameters (d3b4b71926(0.0006258210305383072), 0.00024247379012647688, 62, 10, 20, 0.2, False, 2, (36, 25, 95, 100, 15)) completed, best_val_loss: 0.522257924079895, best_val_metric: 0.8208092485549133, best_hidden_layer_sizes: [36, 25, 95, 100, 15]\n",
      "Duration 22.7, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (8746d69335(3.8450438567741564e-05), 0.00027132745239315335, 60, 10, 20, 0.2, False, 2, (86, 39, 21, 24, 87)) started...\n",
      "Run with parameters (8746d69335(3.8450438567741564e-05), 0.00027132745239315335, 60, 10, 20, 0.2, False, 2, (86, 39, 21, 24, 87)) completed, best_val_loss: 0.6615747809410095, best_val_metric: 0.798219584569733, best_hidden_layer_sizes: [86, 39, 21, 24, 87]\n",
      "Duration 27.8, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (d53129521d(7.710846562732934e-05), 0.00015479281079932574, 33, 10, 20, 0.2, False, 2, (17, 72, 99, 35, 18)) started...\n",
      "Run with parameters (d53129521d(7.710846562732934e-05), 0.00015479281079932574, 33, 10, 20, 0.2, False, 2, (17, 72, 99, 35, 18)) completed, best_val_loss: 0.5608389973640442, best_val_metric: 0.8088235294117647, best_hidden_layer_sizes: [17, 72, 99, 35, 18]\n",
      "Duration 50.8, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (18796b9319(0.0014537960321207692), 0.0005557341896744231, 61, 10, 20, 0.2, False, 2, (55, 61, 74, 34, 46)) started...\n",
      "Run with parameters (18796b9319(0.0014537960321207692), 0.0005557341896744231, 61, 10, 20, 0.2, False, 2, (55, 61, 74, 34, 46)) completed, best_val_loss: 0.5154284238815308, best_val_metric: 0.8422535211267606, best_hidden_layer_sizes: [55, 61, 74, 34, 46]\n",
      "Duration 20.5, best overall combination: (2f55e26343(6.680729265514559e-05), 0.00028290000028864323, 23, 10, 20, 0.2, False, 2, (73, 77, 52, 26, 55)), val_metric: 0.8715083798882681\n",
      "Run with parameters (5a1fddc512(0.00025380674151762397), 0.0005007492002259492, 34, 10, 20, 0.2, False, 2, (75, 28, 59, 37, 84)) started...\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomSearch()\n",
    "random_search.run(\n",
    "    early_stopping_conv, x=fashion_mnist.X_norm, y=fashion_mnist.y, validation_data=None, fraction=0.025, test_size=0.2,\n",
    "    schedule=PowerRange(-4.5, -2.5, lambda x: Schedule([StaticEpoch(x, 'l1')])), \n",
    "    layer_1_size=UniformRange(10, 100, integer=True),\n",
    "    layer_2_size=UniformRange(10, 100, integer=True),\n",
    "    layer_3_size=UniformRange(10, 100, integer=True),\n",
    "    layer_4_size=UniformRange(10, 100, integer=True),\n",
    "    layer_5_size=UniformRange(10, 100, integer=True),\n",
    "    learning_rate=UniformRange(0.0001, 0.0006),\n",
    "    batch_size=UniformRange(16, 64, integer=True),\n",
    "    output_neurons=10, min_new_neurons=20, growth_percentage=0.2, use_static_graph=False, postprocess_fn=layer_sizes_join_postprocess, max_setbacks=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8213418297232145"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([result.val_metric for result in random_search.results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with parameters (05f31057af(0.00011151171128197354), [75, 75, 75, 75, 75], 0.0003179992206569219, 53, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (05f31057af(0.00011151171128197354), [75, 75, 75, 75, 75], 0.0003179992206569219, 53, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.5854276418685913, best_val_metric: 0.8168168168168168, best_hidden_layer_sizes: [75, 75, 75, 75, 75]\n",
      "Duration 24.9, best overall combination: (05f31057af(0.00011151171128197354), [75, 75, 75, 75, 75], 0.0003179992206569219, 53, 10, 20, 0.2, False, 2), val_metric: 0.8168168168168168\n",
      "Run with parameters (169fc12288(0.00012404581605019577), [30, 30, 30, 30, 30], 0.00036362942002440883, 35, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (169fc12288(0.00012404581605019577), [30, 30, 30, 30, 30], 0.00036362942002440883, 35, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.5325362682342529, best_val_metric: 0.8052325581395349, best_hidden_layer_sizes: [30, 30, 30, 30, 30]\n",
      "Duration 24.7, best overall combination: (05f31057af(0.00011151171128197354), [75, 75, 75, 75, 75], 0.0003179992206569219, 53, 10, 20, 0.2, False, 2), val_metric: 0.8168168168168168\n",
      "Run with parameters (ad91a06311(4.510831438791322e-05), [13, 13, 13, 13, 13], 0.0001926231621055954, 64, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (ad91a06311(4.510831438791322e-05), [13, 13, 13, 13, 13], 0.0001926231621055954, 64, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.5254354476928711, best_val_metric: 0.8259668508287292, best_hidden_layer_sizes: [13, 13, 13, 13, 13]\n",
      "Duration 70.5, best overall combination: (ad91a06311(4.510831438791322e-05), [13, 13, 13, 13, 13], 0.0001926231621055954, 64, 10, 20, 0.2, False, 2), val_metric: 0.8259668508287292\n",
      "Run with parameters (9739bf6289(0.0023702589522115397), [93, 93, 93, 93, 93], 0.0004332896871982237, 22, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (9739bf6289(0.0023702589522115397), [93, 93, 93, 93, 93], 0.0004332896871982237, 22, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.5610597729682922, best_val_metric: 0.7988826815642458, best_hidden_layer_sizes: [93, 93, 93, 93, 93]\n",
      "Duration 27.1, best overall combination: (ad91a06311(4.510831438791322e-05), [13, 13, 13, 13, 13], 0.0001926231621055954, 64, 10, 20, 0.2, False, 2), val_metric: 0.8259668508287292\n",
      "Run with parameters (28b075b4b3(0.00012749649605251019), [64, 64, 64, 64, 64], 0.00034008312728830205, 60, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (28b075b4b3(0.00012749649605251019), [64, 64, 64, 64, 64], 0.00034008312728830205, 60, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.7443187236785889, best_val_metric: 0.7861111111111111, best_hidden_layer_sizes: [64, 64, 64, 64, 64]\n",
      "Duration 14.8, best overall combination: (ad91a06311(4.510831438791322e-05), [13, 13, 13, 13, 13], 0.0001926231621055954, 64, 10, 20, 0.2, False, 2), val_metric: 0.8259668508287292\n",
      "Run with parameters (644e7c91a0(0.0005898404900273794), [42, 42, 42, 42, 42], 0.0001475323213399731, 29, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (644e7c91a0(0.0005898404900273794), [42, 42, 42, 42, 42], 0.0001475323213399731, 29, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.47586965560913086, best_val_metric: 0.8431952662721893, best_hidden_layer_sizes: [42, 42, 42, 42, 42]\n",
      "Duration 36.9, best overall combination: (644e7c91a0(0.0005898404900273794), [42, 42, 42, 42, 42], 0.0001475323213399731, 29, 10, 20, 0.2, False, 2), val_metric: 0.8431952662721893\n",
      "Run with parameters (39339c3341(9.45329792370219e-05), [18, 18, 18, 18, 18], 0.0001354137788166484, 61, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (39339c3341(9.45329792370219e-05), [18, 18, 18, 18, 18], 0.0001354137788166484, 61, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.603649377822876, best_val_metric: 0.8080229226361032, best_hidden_layer_sizes: [18, 18, 18, 18, 18]\n",
      "Duration 58.6, best overall combination: (644e7c91a0(0.0005898404900273794), [42, 42, 42, 42, 42], 0.0001475323213399731, 29, 10, 20, 0.2, False, 2), val_metric: 0.8431952662721893\n",
      "Run with parameters (6f0e88b594(0.000433773608666072), [43, 43, 43, 43, 43], 0.0005196354092805192, 22, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (6f0e88b594(0.000433773608666072), [43, 43, 43, 43, 43], 0.0005196354092805192, 22, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.5860834121704102, best_val_metric: 0.8, best_hidden_layer_sizes: [43, 43, 43, 43, 43]\n",
      "Duration 18.3, best overall combination: (644e7c91a0(0.0005898404900273794), [42, 42, 42, 42, 42], 0.0001475323213399731, 29, 10, 20, 0.2, False, 2), val_metric: 0.8431952662721893\n",
      "Run with parameters (a5f3f11110(0.00013209641671018885), [27, 27, 27, 27, 27], 0.0004066904077645838, 26, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (a5f3f11110(0.00013209641671018885), [27, 27, 27, 27, 27], 0.0004066904077645838, 26, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.5661448240280151, best_val_metric: 0.8108882521489972, best_hidden_layer_sizes: [27, 27, 27, 27, 27]\n",
      "Duration 31.4, best overall combination: (644e7c91a0(0.0005898404900273794), [42, 42, 42, 42, 42], 0.0001475323213399731, 29, 10, 20, 0.2, False, 2), val_metric: 0.8431952662721893\n",
      "Run with parameters (e9403cf29a(0.0020370267994443384), [45, 45, 45, 45, 45], 0.0005897160278580744, 57, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (e9403cf29a(0.0020370267994443384), [45, 45, 45, 45, 45], 0.0005897160278580744, 57, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.6534693837165833, best_val_metric: 0.7842565597667639, best_hidden_layer_sizes: [45, 45, 45, 45, 45]\n",
      "Duration 11.8, best overall combination: (644e7c91a0(0.0005898404900273794), [42, 42, 42, 42, 42], 0.0001475323213399731, 29, 10, 20, 0.2, False, 2), val_metric: 0.8431952662721893\n",
      "Run with parameters (9b3836882a(0.00025437944963551914), [55, 55, 55, 55, 55], 0.00044936265064652957, 61, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (9b3836882a(0.00025437944963551914), [55, 55, 55, 55, 55], 0.00044936265064652957, 61, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.5129731297492981, best_val_metric: 0.8305084745762712, best_hidden_layer_sizes: [55, 55, 55, 55, 55]\n",
      "Duration 17.7, best overall combination: (644e7c91a0(0.0005898404900273794), [42, 42, 42, 42, 42], 0.0001475323213399731, 29, 10, 20, 0.2, False, 2), val_metric: 0.8431952662721893\n",
      "Run with parameters (81b521c899(8.830626099228837e-05), [52, 52, 52, 52, 52], 0.00029559689975817966, 39, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (81b521c899(8.830626099228837e-05), [52, 52, 52, 52, 52], 0.00029559689975817966, 39, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.5358405113220215, best_val_metric: 0.828080229226361, best_hidden_layer_sizes: [52, 52, 52, 52, 52]\n",
      "Duration 16.2, best overall combination: (644e7c91a0(0.0005898404900273794), [42, 42, 42, 42, 42], 0.0001475323213399731, 29, 10, 20, 0.2, False, 2), val_metric: 0.8431952662721893\n",
      "Run with parameters (9788171e5d(0.0006065598892776541), [66, 66, 66, 66, 66], 0.00026462848084339206, 43, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (9788171e5d(0.0006065598892776541), [66, 66, 66, 66, 66], 0.00026462848084339206, 43, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.5156805515289307, best_val_metric: 0.8153409090909091, best_hidden_layer_sizes: [66, 66, 66, 66, 66]\n",
      "Duration 12.6, best overall combination: (644e7c91a0(0.0005898404900273794), [42, 42, 42, 42, 42], 0.0001475323213399731, 29, 10, 20, 0.2, False, 2), val_metric: 0.8431952662721893\n",
      "Run with parameters (1606b6a212(6.341218820105046e-05), [51, 51, 51, 51, 51], 0.00012028700763871255, 30, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (1606b6a212(6.341218820105046e-05), [51, 51, 51, 51, 51], 0.00012028700763871255, 30, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.6177394390106201, best_val_metric: 0.8176470588235294, best_hidden_layer_sizes: [51, 51, 51, 51, 51]\n",
      "Duration 40.5, best overall combination: (644e7c91a0(0.0005898404900273794), [42, 42, 42, 42, 42], 0.0001475323213399731, 29, 10, 20, 0.2, False, 2), val_metric: 0.8431952662721893\n",
      "Run with parameters (2240e54a4e(0.0005656816356790318), [40, 40, 40, 40, 40], 0.00028881728739297083, 29, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (2240e54a4e(0.0005656816356790318), [40, 40, 40, 40, 40], 0.00028881728739297083, 29, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.5376940369606018, best_val_metric: 0.8235294117647058, best_hidden_layer_sizes: [40, 40, 40, 40, 40]\n",
      "Duration 23.4, best overall combination: (644e7c91a0(0.0005898404900273794), [42, 42, 42, 42, 42], 0.0001475323213399731, 29, 10, 20, 0.2, False, 2), val_metric: 0.8431952662721893\n",
      "Run with parameters (bd6e37b521(0.0007220906171223163), [10, 10, 10, 10, 10], 0.0003809934137218782, 22, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (bd6e37b521(0.0007220906171223163), [10, 10, 10, 10, 10], 0.0003809934137218782, 22, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.49855750799179077, best_val_metric: 0.8301369863013699, best_hidden_layer_sizes: [10, 10, 10, 10, 10]\n",
      "Duration 43.5, best overall combination: (644e7c91a0(0.0005898404900273794), [42, 42, 42, 42, 42], 0.0001475323213399731, 29, 10, 20, 0.2, False, 2), val_metric: 0.8431952662721893\n",
      "Run with parameters (e1c8738914(0.0013861749374491175), [52, 52, 52, 52, 52], 0.0002676958751224252, 40, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (e1c8738914(0.0013861749374491175), [52, 52, 52, 52, 52], 0.0002676958751224252, 40, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.48872119188308716, best_val_metric: 0.8413597733711048, best_hidden_layer_sizes: [52, 52, 52, 52, 52]\n",
      "Duration 41.6, best overall combination: (644e7c91a0(0.0005898404900273794), [42, 42, 42, 42, 42], 0.0001475323213399731, 29, 10, 20, 0.2, False, 2), val_metric: 0.8431952662721893\n",
      "Run with parameters (b1c4c28095(0.0010951247620970452), [51, 51, 51, 51, 51], 0.00012856641104247714, 51, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (b1c4c28095(0.0010951247620970452), [51, 51, 51, 51, 51], 0.00012856641104247714, 51, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.5809341073036194, best_val_metric: 0.7954545454545454, best_hidden_layer_sizes: [51, 51, 51, 51, 51]\n",
      "Duration 32.1, best overall combination: (644e7c91a0(0.0005898404900273794), [42, 42, 42, 42, 42], 0.0001475323213399731, 29, 10, 20, 0.2, False, 2), val_metric: 0.8431952662721893\n",
      "Run with parameters (471a433071(0.0004637615766015612), [45, 45, 45, 45, 45], 0.00036840600043812637, 30, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (471a433071(0.0004637615766015612), [45, 45, 45, 45, 45], 0.00036840600043812637, 30, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.5376976132392883, best_val_metric: 0.807909604519774, best_hidden_layer_sizes: [45, 45, 45, 45, 45]\n",
      "Duration 18.0, best overall combination: (644e7c91a0(0.0005898404900273794), [42, 42, 42, 42, 42], 0.0001475323213399731, 29, 10, 20, 0.2, False, 2), val_metric: 0.8431952662721893\n",
      "Run with parameters (17d9d42e20(0.0005455714479927254), [77, 77, 77, 77, 77], 0.00038500009987914356, 37, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (17d9d42e20(0.0005455714479927254), [77, 77, 77, 77, 77], 0.00038500009987914356, 37, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.5320519208908081, best_val_metric: 0.8236994219653179, best_hidden_layer_sizes: [77, 77, 77, 77, 77]\n",
      "Duration 20.3, best overall combination: (644e7c91a0(0.0005898404900273794), [42, 42, 42, 42, 42], 0.0001475323213399731, 29, 10, 20, 0.2, False, 2), val_metric: 0.8431952662721893\n",
      "Run with parameters (cba676c317(0.000151395716177938), [50, 50, 50, 50, 50], 0.00042711411318820987, 48, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (cba676c317(0.000151395716177938), [50, 50, 50, 50, 50], 0.00042711411318820987, 48, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.4592183530330658, best_val_metric: 0.8314285714285714, best_hidden_layer_sizes: [50, 50, 50, 50, 50]\n",
      "Duration 16.2, best overall combination: (644e7c91a0(0.0005898404900273794), [42, 42, 42, 42, 42], 0.0001475323213399731, 29, 10, 20, 0.2, False, 2), val_metric: 0.8431952662721893\n",
      "Run with parameters (3d1979d9d4(7.402548197600252e-05), [41, 41, 41, 41, 41], 0.0003420649107195314, 31, 10, 20, 0.2, False, 2) started...\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomSearch()\n",
    "random_search.run(\n",
    "    early_stopping_conv, x=fashion_mnist.X_norm, y=fashion_mnist.y, validation_data=None, fraction=0.025, test_size=0.2,\n",
    "    schedule=PowerRange(-4.5, -2.5, lambda x: Schedule([StaticEpoch(x, 'l1')])), \n",
    "    layer_sizes=UniformRange(10, 100, lambda x: [x] * 5, integer=True),\n",
    "    learning_rate=UniformRange(0.0001, 0.0006),\n",
    "    batch_size=UniformRange(16, 64, integer=True),\n",
    "    output_neurons=10, min_new_neurons=20, growth_percentage=0.2, use_static_graph=False, max_setbacks=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8154508574193786"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([result.val_metric for result in random_search.results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with parameters (dc5a940e0e(0.003101686150188936), [19, 19, 19, 19, 19], 0.00012916165651511398, 34, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (dc5a940e0e(0.003101686150188936), [19, 19, 19, 19, 19], 0.00012916165651511398, 34, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.5111762881278992, best_val_metric: 0.8162162162162162, best_hidden_layer_sizes: [19, 19, 19, 19, 19]\n",
      "Duration 70.5, best overall combination: (dc5a940e0e(0.003101686150188936), [19, 19, 19, 19, 19], 0.00012916165651511398, 34, 10, 20, 0.2, False, 8), val_metric: 0.8162162162162162\n",
      "Run with parameters (430ef05d70(0.0006713042122459809), [96, 96, 96, 96, 96], 0.0003194193665359994, 35, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (430ef05d70(0.0006713042122459809), [96, 96, 96, 96, 96], 0.0003194193665359994, 35, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.5851006507873535, best_val_metric: 0.8323863636363636, best_hidden_layer_sizes: [96, 96, 96, 96, 96]\n",
      "Duration 126.0, best overall combination: (430ef05d70(0.0006713042122459809), [96, 96, 96, 96, 96], 0.0003194193665359994, 35, 10, 20, 0.2, False, 8), val_metric: 0.8323863636363636\n",
      "Run with parameters (9b0ec22980(4.657649365172835e-05), [67, 67, 67, 67, 67], 0.0003386085971740183, 61, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (9b0ec22980(4.657649365172835e-05), [67, 67, 67, 67, 67], 0.0003386085971740183, 61, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.684613823890686, best_val_metric: 0.7900874635568513, best_hidden_layer_sizes: [67, 67, 67, 67, 67]\n",
      "Duration 41.1, best overall combination: (430ef05d70(0.0006713042122459809), [96, 96, 96, 96, 96], 0.0003194193665359994, 35, 10, 20, 0.2, False, 8), val_metric: 0.8323863636363636\n",
      "Run with parameters (525275b185(0.0016698518333998272), [69, 69, 69, 69, 69], 0.00017731830755673663, 63, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (525275b185(0.0016698518333998272), [69, 69, 69, 69, 69], 0.00017731830755673663, 63, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.6257196068763733, best_val_metric: 0.7982708933717579, best_hidden_layer_sizes: [69, 69, 69, 69, 69]\n",
      "Duration 76.7, best overall combination: (430ef05d70(0.0006713042122459809), [96, 96, 96, 96, 96], 0.0003194193665359994, 35, 10, 20, 0.2, False, 8), val_metric: 0.8323863636363636\n",
      "Run with parameters (13663e417b(6.620718673609248e-05), [65, 65, 65, 65, 65], 0.0005721853598157868, 25, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (13663e417b(6.620718673609248e-05), [65, 65, 65, 65, 65], 0.0005721853598157868, 25, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.5339328050613403, best_val_metric: 0.835195530726257, best_hidden_layer_sizes: [65, 65, 65, 65, 65]\n",
      "Duration 53.5, best overall combination: (13663e417b(6.620718673609248e-05), [65, 65, 65, 65, 65], 0.0005721853598157868, 25, 10, 20, 0.2, False, 8), val_metric: 0.835195530726257\n",
      "Run with parameters (59af43fb88(0.0008616182735466129), [29, 29, 29, 29, 29], 0.00024212379821435422, 56, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (59af43fb88(0.0008616182735466129), [29, 29, 29, 29, 29], 0.00024212379821435422, 56, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.41331255435943604, best_val_metric: 0.8591549295774648, best_hidden_layer_sizes: [29, 29, 29, 29, 29]\n",
      "Duration 48.9, best overall combination: (59af43fb88(0.0008616182735466129), [29, 29, 29, 29, 29], 0.00024212379821435422, 56, 10, 20, 0.2, False, 8), val_metric: 0.8591549295774648\n",
      "Run with parameters (2972cfb883(0.0004974124740900586), [20, 20, 20, 20, 20], 0.0005378239667460169, 35, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (2972cfb883(0.0004974124740900586), [20, 20, 20, 20, 20], 0.0005378239667460169, 35, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.5053175091743469, best_val_metric: 0.8545994065281899, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Duration 36.1, best overall combination: (59af43fb88(0.0008616182735466129), [29, 29, 29, 29, 29], 0.00024212379821435422, 56, 10, 20, 0.2, False, 8), val_metric: 0.8591549295774648\n",
      "Run with parameters (c2d1da1247(0.00039062770358410103), [14, 14, 14, 14, 14], 0.00031395465224912463, 60, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (c2d1da1247(0.00039062770358410103), [14, 14, 14, 14, 14], 0.00031395465224912463, 60, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.4623291492462158, best_val_metric: 0.8247126436781609, best_hidden_layer_sizes: [14, 14, 14, 14, 14]\n",
      "Duration 60.4, best overall combination: (59af43fb88(0.0008616182735466129), [29, 29, 29, 29, 29], 0.00024212379821435422, 56, 10, 20, 0.2, False, 8), val_metric: 0.8591549295774648\n",
      "Run with parameters (c337ffa45f(0.00030344336640971667), [44, 44, 44, 44, 44], 0.00010881584088198173, 26, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (c337ffa45f(0.00030344336640971667), [44, 44, 44, 44, 44], 0.00010881584088198173, 26, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.49119436740875244, best_val_metric: 0.8457142857142858, best_hidden_layer_sizes: [44, 44, 44, 44, 44]\n",
      "Duration 90.4, best overall combination: (59af43fb88(0.0008616182735466129), [29, 29, 29, 29, 29], 0.00024212379821435422, 56, 10, 20, 0.2, False, 8), val_metric: 0.8591549295774648\n",
      "Run with parameters (27dba09857(3.8623775779256216e-05), [96, 96, 96, 96, 96], 0.0002717234417711245, 54, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (27dba09857(3.8623775779256216e-05), [96, 96, 96, 96, 96], 0.0002717234417711245, 54, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.7863790988922119, best_val_metric: 0.7936046511627907, best_hidden_layer_sizes: [96, 96, 96, 96, 96]\n",
      "Duration 51.9, best overall combination: (59af43fb88(0.0008616182735466129), [29, 29, 29, 29, 29], 0.00024212379821435422, 56, 10, 20, 0.2, False, 8), val_metric: 0.8591549295774648\n",
      "Run with parameters (ba7bd7e132(0.0003502556359123027), [43, 43, 43, 43, 43], 0.00018074654188445462, 30, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (ba7bd7e132(0.0003502556359123027), [43, 43, 43, 43, 43], 0.00018074654188445462, 30, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.7060364484786987, best_val_metric: 0.7851002865329513, best_hidden_layer_sizes: [43, 43, 43, 43, 43]\n",
      "Duration 44.3, best overall combination: (59af43fb88(0.0008616182735466129), [29, 29, 29, 29, 29], 0.00024212379821435422, 56, 10, 20, 0.2, False, 8), val_metric: 0.8591549295774648\n",
      "Run with parameters (29dc20d0f4(0.0005884861606791225), [46, 46, 46, 46, 46], 0.00012033977692226124, 57, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (29dc20d0f4(0.0005884861606791225), [46, 46, 46, 46, 46], 0.00012033977692226124, 57, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.5942224860191345, best_val_metric: 0.8117647058823529, best_hidden_layer_sizes: [46, 46, 46, 46, 46]\n",
      "Duration 60.0, best overall combination: (59af43fb88(0.0008616182735466129), [29, 29, 29, 29, 29], 0.00024212379821435422, 56, 10, 20, 0.2, False, 8), val_metric: 0.8591549295774648\n",
      "Run with parameters (a03ccd03d2(0.00041651773969104196), [96, 96, 96, 96, 96], 0.0003650874829505685, 19, 10, 20, 0.2, False, 8) started...\n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "<built-in function len> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.miniconda3/envs/self-scaling-nets/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_aggregate_grads\u001b[0;34m(gradients)\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/self-scaling-nets/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd_n\u001b[0;34m(inputs, name)\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    395\u001b[0m         _ctx, \"AddN\", name, inputs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/.miniconda3/envs/self-scaling-nets/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_aggregate_grads\u001b[0;34m(gradients)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function len> returned a result with an error set",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/.miniconda3/envs/self-scaling-nets/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_aggregate_grads\u001b[0;34m(gradients)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function len> returned a result with an error set",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-e3561ccf4171>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrandom_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m random_search.run(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mearly_stopping_conv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfashion_mnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfashion_mnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfraction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mschedule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPowerRange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSchedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mStaticEpoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'l1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlayer_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mUniformRange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-03aa6960e272>\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-03aa6960e272>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, train_fn, x, y, validation_data, postprocess_fn, fraction, test_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1259\u001b[0m             \u001b[0mx_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_for_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfraction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1261\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mcombination_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcombination_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1262\u001b[0m             \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parameters'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-03aa6960e272>\u001b[0m in \u001b[0;36mearly_stopping_conv\u001b[0;34m(x, y, validation_data, learning_rate, schedule, layer_sizes, output_neurons, min_new_neurons, growth_percentage, verbose, use_static_graph, batch_size, max_setbacks)\u001b[0m\n\u001b[1;32m   1429\u001b[0m     \u001b[0mn_setbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m         epoch_history = model.fit(x=x, y=y, optimizer=optimizer, schedule=schedule, batch_size=batch_size, min_new_neurons=min_new_neurons, \n\u001b[0m\u001b[1;32m   1432\u001b[0m                                   validation_data=validation_data, growth_percentage=growth_percentage, verbose=verbose, use_static_graph=use_static_graph)\n\u001b[1;32m   1433\u001b[0m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_histories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-03aa6960e272>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, optimizer, schedule, batch_size, min_new_neurons, validation_data, pruning_threshold, regularization_penalty_multiplier, stall_coefficient, growth_percentage, mini_epochs_per_epoch, verbose, print_neurons, use_static_graph, loss_fn, metric_fn)\u001b[0m\n\u001b[1;32m   1024\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrow_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m             \u001b[0msummed_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummed_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_single_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprune\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-03aa6960e272>\u001b[0m in \u001b[0;36mfit_single_epoch\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    998\u001b[0m                 \u001b[0mfit_single_step_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_single_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_single_step_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1001\u001b[0m                 \u001b[0msummed_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m                 \u001b[0msummed_metric\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-03aa6960e272>\u001b[0m in \u001b[0;36mfit_single_step\u001b[0;34m(self, x_batch, y_batch, optimizer, loss_fn, metric_fn)\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/self-scaling-nets/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1079\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1082\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/self-scaling-nets/lib/python3.8/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/self-scaling-nets/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_aggregate_grads\u001b[0;34m(gradients)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No gradients to aggregate\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function len> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "random_search = RandomSearch()\n",
    "random_search.run(\n",
    "    early_stopping_conv, x=fashion_mnist.X_norm, y=fashion_mnist.y, validation_data=None, fraction=0.025, test_size=0.2,\n",
    "    schedule=PowerRange(-4.5, -2.5, lambda x: Schedule([StaticEpoch(x, 'l1')])), \n",
    "    layer_sizes=UniformRange(10, 100, lambda x: [x] * 5, integer=True),\n",
    "    learning_rate=UniformRange(0.0001, 0.0006),\n",
    "    batch_size=UniformRange(16, 64, integer=True),\n",
    "    output_neurons=10, min_new_neurons=20, growth_percentage=0.2, use_static_graph=False, max_setbacks=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8205672813819703"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([result.val_metric for result in random_search.results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.32619188229243"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([result.duration for result in random_search.results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with parameters (6c51009342(6.64454742238569e-05), [20, 20, 20, 20, 20], 0.0005270695556026855, 51, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (6c51009342(6.64454742238569e-05), [20, 20, 20, 20, 20], 0.0005270695556026855, 51, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.675999641418457, best_val_metric: 0.771117166212534, best_hidden_layer_sizes: [20, 73, 42, 67, 65]\n",
      "Duration 24.3, best overall combination: (6c51009342(6.64454742238569e-05), [20, 20, 20, 20, 20], 0.0005270695556026855, 51, 10, 20, 0.2, False, 2), val_metric: 0.771117166212534\n",
      "Run with parameters (757886b014(0.0011168778272064447), [20, 20, 20, 20, 20], 0.00042529012136676006, 34, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (757886b014(0.0011168778272064447), [20, 20, 20, 20, 20], 0.00042529012136676006, 34, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.6109392046928406, best_val_metric: 0.7994350282485876, best_hidden_layer_sizes: [10, 5, 7, 8, 31]\n",
      "Duration 34.6, best overall combination: (757886b014(0.0011168778272064447), [20, 20, 20, 20, 20], 0.00042529012136676006, 34, 10, 20, 0.2, False, 2), val_metric: 0.7994350282485876\n",
      "Run with parameters (b2fd7c7954(0.00029595379834915296), [20, 20, 20, 20, 20], 0.0003354144161817492, 62, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (b2fd7c7954(0.00029595379834915296), [20, 20, 20, 20, 20], 0.0003354144161817492, 62, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.513579249382019, best_val_metric: 0.82, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Duration 20.9, best overall combination: (b2fd7c7954(0.00029595379834915296), [20, 20, 20, 20, 20], 0.0003354144161817492, 62, 10, 20, 0.2, False, 2), val_metric: 0.82\n",
      "Run with parameters (a249aa1c37(0.00044740374244906645), [20, 20, 20, 20, 20], 0.0005577741951717412, 37, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (a249aa1c37(0.00044740374244906645), [20, 20, 20, 20, 20], 0.0005577741951717412, 37, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.6143147945404053, best_val_metric: 0.7888888888888889, best_hidden_layer_sizes: [20, 20, 20, 20, 25]\n",
      "Duration 13.3, best overall combination: (b2fd7c7954(0.00029595379834915296), [20, 20, 20, 20, 20], 0.0003354144161817492, 62, 10, 20, 0.2, False, 2), val_metric: 0.82\n",
      "Run with parameters (8fff12379f(0.0002551681504242417), [20, 20, 20, 20, 20], 0.00025399431538648663, 36, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (8fff12379f(0.0002551681504242417), [20, 20, 20, 20, 20], 0.00025399431538648663, 36, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.6268637180328369, best_val_metric: 0.7888888888888889, best_hidden_layer_sizes: [20, 20, 20, 20, 21]\n",
      "Duration 39.9, best overall combination: (b2fd7c7954(0.00029595379834915296), [20, 20, 20, 20, 20], 0.0003354144161817492, 62, 10, 20, 0.2, False, 2), val_metric: 0.82\n",
      "Run with parameters (4c249f9eb8(0.00030068529507388544), [20, 20, 20, 20, 20], 0.0003183145583412095, 48, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (4c249f9eb8(0.00030068529507388544), [20, 20, 20, 20, 20], 0.0003183145583412095, 48, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.5416438579559326, best_val_metric: 0.8314606741573034, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Duration 26.2, best overall combination: (4c249f9eb8(0.00030068529507388544), [20, 20, 20, 20, 20], 0.0003183145583412095, 48, 10, 20, 0.2, False, 2), val_metric: 0.8314606741573034\n",
      "Run with parameters (1dcd46a51a(7.161194644331999e-05), [20, 20, 20, 20, 20], 0.00012938585732854082, 26, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (1dcd46a51a(7.161194644331999e-05), [20, 20, 20, 20, 20], 0.00012938585732854082, 26, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.5755124688148499, best_val_metric: 0.8184438040345822, best_hidden_layer_sizes: [20, 20, 20, 39, 29]\n",
      "Duration 60.9, best overall combination: (4c249f9eb8(0.00030068529507388544), [20, 20, 20, 20, 20], 0.0003183145583412095, 48, 10, 20, 0.2, False, 2), val_metric: 0.8314606741573034\n",
      "Run with parameters (eed24e8145(0.0017510140845319933), [20, 20, 20, 20, 20], 0.000527596334052618, 19, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (eed24e8145(0.0017510140845319933), [20, 20, 20, 20, 20], 0.000527596334052618, 19, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.6811370849609375, best_val_metric: 0.7690140845070422, best_hidden_layer_sizes: [12, 3, 5, 6, 33]\n",
      "Duration 50.2, best overall combination: (4c249f9eb8(0.00030068529507388544), [20, 20, 20, 20, 20], 0.0003183145583412095, 48, 10, 20, 0.2, False, 2), val_metric: 0.8314606741573034\n",
      "Run with parameters (1d1c461f28(0.00028436861669092013), [20, 20, 20, 20, 20], 0.0003551147235711508, 38, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (1d1c461f28(0.00028436861669092013), [20, 20, 20, 20, 20], 0.0003551147235711508, 38, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.5610842108726501, best_val_metric: 0.8107344632768362, best_hidden_layer_sizes: [20, 20, 20, 20, 46]\n",
      "Duration 36.5, best overall combination: (4c249f9eb8(0.00030068529507388544), [20, 20, 20, 20, 20], 0.0003183145583412095, 48, 10, 20, 0.2, False, 2), val_metric: 0.8314606741573034\n",
      "Run with parameters (2b45b1b43e(5.815613816590827e-05), [20, 20, 20, 20, 20], 0.00011940242164326667, 29, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (2b45b1b43e(5.815613816590827e-05), [20, 20, 20, 20, 20], 0.00011940242164326667, 29, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.6034135222434998, best_val_metric: 0.7959183673469388, best_hidden_layer_sizes: [20, 22, 21, 35, 30]\n",
      "Duration 31.4, best overall combination: (4c249f9eb8(0.00030068529507388544), [20, 20, 20, 20, 20], 0.0003183145583412095, 48, 10, 20, 0.2, False, 2), val_metric: 0.8314606741573034\n",
      "Run with parameters (65beb25fd8(5.67002917070245e-05), [20, 20, 20, 20, 20], 0.00040444316944798856, 60, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (65beb25fd8(5.67002917070245e-05), [20, 20, 20, 20, 20], 0.00040444316944798856, 60, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.5767274498939514, best_val_metric: 0.8034188034188035, best_hidden_layer_sizes: [20, 71, 30, 81, 55]\n",
      "Duration 30.1, best overall combination: (4c249f9eb8(0.00030068529507388544), [20, 20, 20, 20, 20], 0.0003183145583412095, 48, 10, 20, 0.2, False, 2), val_metric: 0.8314606741573034\n",
      "Run with parameters (1b83cee277(0.000984524637047809), [20, 20, 20, 20, 20], 0.0003981119865269912, 37, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (1b83cee277(0.000984524637047809), [20, 20, 20, 20, 20], 0.0003981119865269912, 37, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.6376249194145203, best_val_metric: 0.7853107344632768, best_hidden_layer_sizes: [20, 19, 20, 19, 20]\n",
      "Duration 28.1, best overall combination: (4c249f9eb8(0.00030068529507388544), [20, 20, 20, 20, 20], 0.0003183145583412095, 48, 10, 20, 0.2, False, 2), val_metric: 0.8314606741573034\n",
      "Run with parameters (b42372d67d(0.0023145888813881866), [20, 20, 20, 20, 20], 0.00033023595024980274, 20, 10, 20, 0.2, False, 2) started...\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomSearch()\n",
    "random_search.run(\n",
    "    early_stopping_conv, x=fashion_mnist.X_norm, y=fashion_mnist.y, validation_data=None, fraction=0.025, test_size=0.2,\n",
    "    schedule=PowerRange(-4.5, -2.5, lambda x: Schedule([DynamicEpoch(x, 'weighted_l1')])), \n",
    "    layer_sizes=[20, 20, 20, 20, 20],\n",
    "    learning_rate=UniformRange(0.0001, 0.0006),\n",
    "    batch_size=UniformRange(16, 64, integer=True),\n",
    "    output_neurons=10, min_new_neurons=20, growth_percentage=0.2, use_static_graph=False, max_setbacks=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7985525752869735"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([result.val_metric for result in random_search.results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.04273682832718"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([result.duration for result in random_search.results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with parameters (470df8c5ec(0.0024571853763312376), [20, 20, 20, 20, 20], 0.00043141821261181686, 26, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (470df8c5ec(0.0024571853763312376), [20, 20, 20, 20, 20], 0.00043141821261181686, 26, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.8513667583465576, best_val_metric: 0.7577464788732394, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Duration 25.7, best overall combination: (470df8c5ec(0.0024571853763312376), [20, 20, 20, 20, 20], 0.00043141821261181686, 26, 10, 20, 0.2, False, 2), val_metric: 0.7577464788732394\n",
      "Run with parameters (7d25d495e8(0.00043589252435480573), [20, 20, 20, 20, 20], 0.0005774270813372936, 51, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (7d25d495e8(0.00043589252435480573), [20, 20, 20, 20, 20], 0.0005774270813372936, 51, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.6590991020202637, best_val_metric: 0.775623268698061, best_hidden_layer_sizes: [20, 20, 24, 27, 59]\n",
      "Duration 27.7, best overall combination: (7d25d495e8(0.00043589252435480573), [20, 20, 20, 20, 20], 0.0005774270813372936, 51, 10, 20, 0.2, False, 2), val_metric: 0.775623268698061\n",
      "Run with parameters (d7e8bf344d(0.0029843525268337286), [20, 20, 20, 20, 20], 0.0005982827879807027, 33, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (d7e8bf344d(0.0029843525268337286), [20, 20, 20, 20, 20], 0.0005982827879807027, 33, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.7005712985992432, best_val_metric: 0.7638483965014577, best_hidden_layer_sizes: [4, 2, 4, 18, 103]\n",
      "Duration 54.9, best overall combination: (7d25d495e8(0.00043589252435480573), [20, 20, 20, 20, 20], 0.0005774270813372936, 51, 10, 20, 0.2, False, 2), val_metric: 0.775623268698061\n",
      "Run with parameters (5f8eb4e06c(9.76411119005569e-05), [20, 20, 20, 20, 20], 0.0002447174247622081, 42, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (5f8eb4e06c(9.76411119005569e-05), [20, 20, 20, 20, 20], 0.0002447174247622081, 42, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.6176071166992188, best_val_metric: 0.8097982708933718, best_hidden_layer_sizes: [20, 21, 20, 36, 36]\n",
      "Duration 31.4, best overall combination: (5f8eb4e06c(9.76411119005569e-05), [20, 20, 20, 20, 20], 0.0002447174247622081, 42, 10, 20, 0.2, False, 2), val_metric: 0.8097982708933718\n",
      "Run with parameters (997ca58394(0.0021577401712681446), [20, 20, 20, 20, 20], 0.0003332429570679455, 28, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (997ca58394(0.0021577401712681446), [20, 20, 20, 20, 20], 0.0003332429570679455, 28, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.6725038886070251, best_val_metric: 0.770949720670391, best_hidden_layer_sizes: [3, 5, 5, 7, 20]\n",
      "Duration 58.5, best overall combination: (5f8eb4e06c(9.76411119005569e-05), [20, 20, 20, 20, 20], 0.0002447174247622081, 42, 10, 20, 0.2, False, 2), val_metric: 0.8097982708933718\n",
      "Run with parameters (0159286e69(0.000525451710605544), [20, 20, 20, 20, 20], 0.00033805732876427113, 21, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (0159286e69(0.000525451710605544), [20, 20, 20, 20, 20], 0.00033805732876427113, 21, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.5166469812393188, best_val_metric: 0.8242074927953891, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Duration 23.7, best overall combination: (0159286e69(0.000525451710605544), [20, 20, 20, 20, 20], 0.00033805732876427113, 21, 10, 20, 0.2, False, 2), val_metric: 0.8242074927953891\n",
      "Run with parameters (545b6edb07(0.0010993806925923845), [20, 20, 20, 20, 20], 0.0005360161801541628, 26, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (545b6edb07(0.0010993806925923845), [20, 20, 20, 20, 20], 0.0005360161801541628, 26, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.7563118934631348, best_val_metric: 0.749271137026239, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Duration 12.9, best overall combination: (0159286e69(0.000525451710605544), [20, 20, 20, 20, 20], 0.00033805732876427113, 21, 10, 20, 0.2, False, 2), val_metric: 0.8242074927953891\n",
      "Run with parameters (8b05856efa(0.00041706161579618925), [20, 20, 20, 20, 20], 0.0001526650333706906, 60, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (8b05856efa(0.00041706161579618925), [20, 20, 20, 20, 20], 0.0001526650333706906, 60, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.5981507301330566, best_val_metric: 0.8223495702005731, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Duration 29.8, best overall combination: (0159286e69(0.000525451710605544), [20, 20, 20, 20, 20], 0.00033805732876427113, 21, 10, 20, 0.2, False, 2), val_metric: 0.8242074927953891\n",
      "Run with parameters (a78740b3d5(0.0008471137386391872), [20, 20, 20, 20, 20], 0.00017557201560230632, 43, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (a78740b3d5(0.0008471137386391872), [20, 20, 20, 20, 20], 0.00017557201560230632, 43, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.5094677209854126, best_val_metric: 0.830028328611898, best_hidden_layer_sizes: [15, 7, 9, 9, 20]\n",
      "Duration 72.0, best overall combination: (a78740b3d5(0.0008471137386391872), [20, 20, 20, 20, 20], 0.00017557201560230632, 43, 10, 20, 0.2, False, 2), val_metric: 0.830028328611898\n",
      "Run with parameters (53f7052eb4(0.0003819383515221074), [20, 20, 20, 20, 20], 0.0005738693288682305, 27, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (53f7052eb4(0.0003819383515221074), [20, 20, 20, 20, 20], 0.0005738693288682305, 27, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.5933428406715393, best_val_metric: 0.8104956268221575, best_hidden_layer_sizes: [20, 20, 20, 20, 35]\n",
      "Duration 23.6, best overall combination: (a78740b3d5(0.0008471137386391872), [20, 20, 20, 20, 20], 0.00017557201560230632, 43, 10, 20, 0.2, False, 2), val_metric: 0.830028328611898\n",
      "Run with parameters (5eb5975a61(5.269798250674092e-05), [20, 20, 20, 20, 20], 0.0004902069023074016, 56, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (5eb5975a61(5.269798250674092e-05), [20, 20, 20, 20, 20], 0.0004902069023074016, 56, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.5614081621170044, best_val_metric: 0.8342857142857143, best_hidden_layer_sizes: [31, 126, 90, 209, 137]\n",
      "Duration 41.9, best overall combination: (5eb5975a61(5.269798250674092e-05), [20, 20, 20, 20, 20], 0.0004902069023074016, 56, 10, 20, 0.2, False, 2), val_metric: 0.8342857142857143\n",
      "Run with parameters (2c709854b2(0.00019508177183562026), [20, 20, 20, 20, 20], 0.0004791456339800211, 17, 10, 20, 0.2, False, 2) started...\n",
      "Run with parameters (2c709854b2(0.00019508177183562026), [20, 20, 20, 20, 20], 0.0004791456339800211, 17, 10, 20, 0.2, False, 2) completed, best_val_loss: 0.6062829494476318, best_val_metric: 0.7728531855955678, best_hidden_layer_sizes: [20, 21, 20, 22, 111]\n",
      "Duration 42.7, best overall combination: (5eb5975a61(5.269798250674092e-05), [20, 20, 20, 20, 20], 0.0004902069023074016, 56, 10, 20, 0.2, False, 2), val_metric: 0.8342857142857143\n",
      "Run with parameters (644a68eb61(0.0008753119601974915), [20, 20, 20, 20, 20], 0.0005532494366495022, 51, 10, 20, 0.2, False, 2) started...\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomSearch()\n",
    "random_search.run(\n",
    "    early_stopping_conv, x=fashion_mnist.X_norm, y=fashion_mnist.y, validation_data=None, fraction=0.025, test_size=0.2,\n",
    "    schedule=PowerRange(-4.5, -2.5, lambda x: Schedule([DynamicEpoch(x, 'weighted_l1')])), \n",
    "    layer_sizes=[20, 20, 20, 20, 20],\n",
    "    learning_rate=UniformRange(0.0001, 0.0006),\n",
    "    batch_size=UniformRange(16, 64, integer=True),\n",
    "    output_neurons=10, min_new_neurons=20, growth_percentage=0.2, use_static_graph=False, max_setbacks=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7934547659145048"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([result.val_metric for result in random_search.results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with parameters (60158b0e0e(0.00027223295877836694), [20, 20, 20, 20, 20], 0.0004667041191646742, 43, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (60158b0e0e(0.00027223295877836694), [20, 20, 20, 20, 20], 0.0004667041191646742, 43, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.5247147083282471, best_val_metric: 0.833810888252149, best_hidden_layer_sizes: [20, 20, 20, 20, 22]\n",
      "Duration 48.0, best overall combination: (60158b0e0e(0.00027223295877836694), [20, 20, 20, 20, 20], 0.0004667041191646742, 43, 10, 20, 0.2, False, 8), val_metric: 0.833810888252149\n",
      "Run with parameters (2a2bb42f9c(0.002127069523543648), [20, 20, 20, 20, 20], 0.0003384749833128299, 60, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (2a2bb42f9c(0.002127069523543648), [20, 20, 20, 20, 20], 0.0003384749833128299, 60, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.5111258029937744, best_val_metric: 0.8342857142857143, best_hidden_layer_sizes: [3, 4, 2, 11, 38]\n",
      "Duration 132.1, best overall combination: (2a2bb42f9c(0.002127069523543648), [20, 20, 20, 20, 20], 0.0003384749833128299, 60, 10, 20, 0.2, False, 8), val_metric: 0.8342857142857143\n",
      "Run with parameters (b9eda133cf(0.0008501812697359913), [20, 20, 20, 20, 20], 0.00035450530121129405, 45, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (b9eda133cf(0.0008501812697359913), [20, 20, 20, 20, 20], 0.00035450530121129405, 45, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.6790879964828491, best_val_metric: 0.7947976878612717, best_hidden_layer_sizes: [10, 6, 7, 11, 26]\n",
      "Duration 67.8, best overall combination: (2a2bb42f9c(0.002127069523543648), [20, 20, 20, 20, 20], 0.0003384749833128299, 60, 10, 20, 0.2, False, 8), val_metric: 0.8342857142857143\n",
      "Run with parameters (61b8e9a2f8(4.353645361786884e-05), [20, 20, 20, 20, 20], 0.0003996045150922346, 42, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (61b8e9a2f8(4.353645361786884e-05), [20, 20, 20, 20, 20], 0.0003996045150922346, 42, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.5312130451202393, best_val_metric: 0.8151260504201681, best_hidden_layer_sizes: [29, 87, 56, 150, 123]\n",
      "Duration 57.3, best overall combination: (2a2bb42f9c(0.002127069523543648), [20, 20, 20, 20, 20], 0.0003384749833128299, 60, 10, 20, 0.2, False, 8), val_metric: 0.8342857142857143\n",
      "Run with parameters (a5a559d64d(0.00015067215265112126), [20, 20, 20, 20, 20], 0.00018860828719069608, 44, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (a5a559d64d(0.00015067215265112126), [20, 20, 20, 20, 20], 0.00018860828719069608, 44, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.46487340331077576, best_val_metric: 0.847457627118644, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Duration 59.8, best overall combination: (a5a559d64d(0.00015067215265112126), [20, 20, 20, 20, 20], 0.00018860828719069608, 44, 10, 20, 0.2, False, 8), val_metric: 0.847457627118644\n",
      "Run with parameters (04080b8304(0.00034687322536919595), [20, 20, 20, 20, 20], 0.0005253698152058486, 52, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (04080b8304(0.00034687322536919595), [20, 20, 20, 20, 20], 0.0005253698152058486, 52, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.5166772603988647, best_val_metric: 0.8254847645429363, best_hidden_layer_sizes: [20, 25, 33, 69, 182]\n",
      "Duration 72.9, best overall combination: (a5a559d64d(0.00015067215265112126), [20, 20, 20, 20, 20], 0.00018860828719069608, 44, 10, 20, 0.2, False, 8), val_metric: 0.847457627118644\n",
      "Run with parameters (cbb62e33e6(0.0031175942931080656), [20, 20, 20, 20, 20], 0.0005726813962028144, 38, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (cbb62e33e6(0.0031175942931080656), [20, 20, 20, 20, 20], 0.0005726813962028144, 38, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.6503075361251831, best_val_metric: 0.7758620689655172, best_hidden_layer_sizes: [2, 4, 5, 26, 137]\n",
      "Duration 141.9, best overall combination: (a5a559d64d(0.00015067215265112126), [20, 20, 20, 20, 20], 0.00018860828719069608, 44, 10, 20, 0.2, False, 8), val_metric: 0.847457627118644\n",
      "Run with parameters (ebcfcbec95(0.0003975101640452534), [20, 20, 20, 20, 20], 0.0005107702256883139, 53, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (ebcfcbec95(0.0003975101640452534), [20, 20, 20, 20, 20], 0.0005107702256883139, 53, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.5813980102539062, best_val_metric: 0.8173913043478261, best_hidden_layer_sizes: [17, 33, 38, 123, 282]\n",
      "Duration 82.8, best overall combination: (a5a559d64d(0.00015067215265112126), [20, 20, 20, 20, 20], 0.00018860828719069608, 44, 10, 20, 0.2, False, 8), val_metric: 0.847457627118644\n",
      "Run with parameters (5dc9fbce31(0.000929453197336784), [20, 20, 20, 20, 20], 0.0005043024484954349, 27, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (5dc9fbce31(0.000929453197336784), [20, 20, 20, 20, 20], 0.0005043024484954349, 27, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.5357173681259155, best_val_metric: 0.847887323943662, best_hidden_layer_sizes: [8, 7, 7, 15, 154]\n",
      "Duration 105.0, best overall combination: (5dc9fbce31(0.000929453197336784), [20, 20, 20, 20, 20], 0.0005043024484954349, 27, 10, 20, 0.2, False, 8), val_metric: 0.847887323943662\n",
      "Run with parameters (d56287a2fe(7.625146452752558e-05), [20, 20, 20, 20, 20], 0.0004630385369258793, 45, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (d56287a2fe(7.625146452752558e-05), [20, 20, 20, 20, 20], 0.0004630385369258793, 45, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.5599308609962463, best_val_metric: 0.8361581920903954, best_hidden_layer_sizes: [21, 55, 40, 113, 200]\n",
      "Duration 61.9, best overall combination: (5dc9fbce31(0.000929453197336784), [20, 20, 20, 20, 20], 0.0005043024484954349, 27, 10, 20, 0.2, False, 8), val_metric: 0.847887323943662\n",
      "Run with parameters (828ba0955f(0.00027916628157397173), [20, 20, 20, 20, 20], 0.0002087329420914726, 29, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (828ba0955f(0.00027916628157397173), [20, 20, 20, 20, 20], 0.0002087329420914726, 29, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.5426239967346191, best_val_metric: 0.8296089385474861, best_hidden_layer_sizes: [19, 13, 12, 18, 25]\n",
      "Duration 134.9, best overall combination: (5dc9fbce31(0.000929453197336784), [20, 20, 20, 20, 20], 0.0005043024484954349, 27, 10, 20, 0.2, False, 8), val_metric: 0.847887323943662\n",
      "Run with parameters (1aa9718b2f(5.405998985299654e-05), [20, 20, 20, 20, 20], 0.0005628228030579641, 30, 10, 20, 0.2, False, 8) started...\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomSearch()\n",
    "random_search.run(\n",
    "    early_stopping_conv, x=fashion_mnist.X_norm, y=fashion_mnist.y, validation_data=None, fraction=0.025, test_size=0.2,\n",
    "    schedule=PowerRange(-4.5, -2.5, lambda x: Schedule([DynamicEpoch(x, 'weighted_l1')])), \n",
    "    layer_sizes=[20, 20, 20, 20, 20],\n",
    "    learning_rate=UniformRange(0.0001, 0.0006),\n",
    "    batch_size=UniformRange(16, 64, integer=True),\n",
    "    output_neurons=10, min_new_neurons=20, growth_percentage=0.2, use_static_graph=False, max_setbacks=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8234427782159791"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([result.val_metric for result in random_search.results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.67465912212025"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([result.duration for result in random_search.results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with parameters (63d037a9eb(0.00011360268441832483), [20, 20, 20, 20, 20], 0.00024664030028448457, 30, 10, 20, 0.2, False, 10) started...\n",
      "Run with parameters (63d037a9eb(0.00011360268441832483), [20, 20, 20, 20, 20], 0.00024664030028448457, 30, 10, 20, 0.2, False, 10) completed, duration 98.7, best_val_loss: 0.5806478261947632, best_val_metric: 0.8245614035087719, best_hidden_layer_sizes: [20, 19, 20, 28, 80]\n",
      "Total duration 98.7, mean val metric 0.8245614035087719, mean duration 98.7, best overall combination: (63d037a9eb(0.00011360268441832483), [20, 20, 20, 20, 20], 0.00024664030028448457, 30, 10, 20, 0.2, False, 10), val_metric: 0.8245614035087719\n",
      "Run with parameters (3f556d14be(4.7752285741481555e-05), [20, 20, 20, 20, 20], 0.00037077517843889875, 37, 10, 20, 0.2, False, 10) started...\n",
      "Run with parameters (3f556d14be(4.7752285741481555e-05), [20, 20, 20, 20, 20], 0.00037077517843889875, 37, 10, 20, 0.2, False, 10) completed, duration 83.3, best_val_loss: 0.6611487865447998, best_val_metric: 0.811965811965812, best_hidden_layer_sizes: [27, 94, 69, 122, 207]\n",
      "Total duration 182.0, mean val metric 0.818263607737292, mean duration 91.0, best overall combination: (63d037a9eb(0.00011360268441832483), [20, 20, 20, 20, 20], 0.00024664030028448457, 30, 10, 20, 0.2, False, 10), val_metric: 0.8245614035087719\n",
      "Run with parameters (85bbec58f3(0.00011615163141286432), [20, 20, 20, 20, 20], 0.00019631927731523537, 25, 10, 20, 0.2, False, 10) started...\n",
      "Run with parameters (85bbec58f3(0.00011615163141286432), [20, 20, 20, 20, 20], 0.00019631927731523537, 25, 10, 20, 0.2, False, 10) completed, duration 56.6, best_val_loss: 0.5018948316574097, best_val_metric: 0.8444444444444444, best_hidden_layer_sizes: [20, 23, 20, 29, 27]\n",
      "Total duration 238.6, mean val metric 0.8269905533063429, mean duration 79.5, best overall combination: (85bbec58f3(0.00011615163141286432), [20, 20, 20, 20, 20], 0.00019631927731523537, 25, 10, 20, 0.2, False, 10), val_metric: 0.8444444444444444\n",
      "Run with parameters (3a35167c50(0.0001956478665200939), [20, 20, 20, 20, 20], 0.000279370938370801, 30, 10, 20, 0.2, False, 10) started...\n",
      "Run with parameters (3a35167c50(0.0001956478665200939), [20, 20, 20, 20, 20], 0.000279370938370801, 30, 10, 20, 0.2, False, 10) completed, duration 153.5, best_val_loss: 0.5079999566078186, best_val_metric: 0.8289855072463768, best_hidden_layer_sizes: [15, 14, 13, 22, 68]\n",
      "Total duration 392.1, mean val metric 0.8274892917913513, mean duration 98.0, best overall combination: (85bbec58f3(0.00011615163141286432), [20, 20, 20, 20, 20], 0.00019631927731523537, 25, 10, 20, 0.2, False, 10), val_metric: 0.8444444444444444\n",
      "Run with parameters (6ef83e87ca(0.0006857592519425884), [20, 20, 20, 20, 20], 0.00026119879076455207, 16, 10, 20, 0.2, False, 10) started...\n",
      "Run with parameters (6ef83e87ca(0.0006857592519425884), [20, 20, 20, 20, 20], 0.00026119879076455207, 16, 10, 20, 0.2, False, 10) completed, duration 203.0, best_val_loss: 0.5362657308578491, best_val_metric: 0.8284883720930233, best_hidden_layer_sizes: [7, 4, 4, 10, 32]\n",
      "Total duration 595.1, mean val metric 0.8276891078516858, mean duration 119.0, best overall combination: (85bbec58f3(0.00011615163141286432), [20, 20, 20, 20, 20], 0.00019631927731523537, 25, 10, 20, 0.2, False, 10), val_metric: 0.8444444444444444\n",
      "Run with parameters (9011c251f0(0.001035154169953062), [20, 20, 20, 20, 20], 0.00036936966927240804, 50, 10, 20, 0.2, False, 10) started...\n",
      "Run with parameters (9011c251f0(0.001035154169953062), [20, 20, 20, 20, 20], 0.00036936966927240804, 50, 10, 20, 0.2, False, 10) completed, duration 59.2, best_val_loss: 0.6017037630081177, best_val_metric: 0.7894736842105263, best_hidden_layer_sizes: [19, 8, 10, 13, 24]\n",
      "Total duration 654.4, mean val metric 0.8213198705781593, mean duration 109.1, best overall combination: (85bbec58f3(0.00011615163141286432), [20, 20, 20, 20, 20], 0.00019631927731523537, 25, 10, 20, 0.2, False, 10), val_metric: 0.8444444444444444\n",
      "Run with parameters (9ec7edbc86(4.3204608030527865e-05), [20, 20, 20, 20, 20], 0.0001655167396015528, 41, 10, 20, 0.2, False, 10) started...\n",
      "Run with parameters (9ec7edbc86(4.3204608030527865e-05), [20, 20, 20, 20, 20], 0.0001655167396015528, 41, 10, 20, 0.2, False, 10) completed, duration 56.3, best_val_loss: 0.655110776424408, best_val_metric: 0.8091168091168092, best_hidden_layer_sizes: [20, 35, 20, 62, 48]\n",
      "Total duration 710.7, mean val metric 0.8195765760836807, mean duration 101.5, best overall combination: (85bbec58f3(0.00011615163141286432), [20, 20, 20, 20, 20], 0.00019631927731523537, 25, 10, 20, 0.2, False, 10), val_metric: 0.8444444444444444\n",
      "Run with parameters (5efded3683(0.0005906733387346247), [20, 20, 20, 20, 20], 0.00024016994945849212, 47, 10, 20, 0.2, False, 10) started...\n",
      "Run with parameters (5efded3683(0.0005906733387346247), [20, 20, 20, 20, 20], 0.00024016994945849212, 47, 10, 20, 0.2, False, 10) completed, duration 109.7, best_val_loss: 0.5500794053077698, best_val_metric: 0.8287292817679558, best_hidden_layer_sizes: [9, 6, 7, 11, 23]\n",
      "Total duration 820.4, mean val metric 0.8207206642942151, mean duration 102.6, best overall combination: (85bbec58f3(0.00011615163141286432), [20, 20, 20, 20, 20], 0.00019631927731523537, 25, 10, 20, 0.2, False, 10), val_metric: 0.8444444444444444\n",
      "Run with parameters (b4c9645c2e(0.00225918086942455), [20, 20, 20, 20, 20], 0.0005074927921996801, 43, 10, 20, 0.2, False, 10) started...\n",
      "Run with parameters (b4c9645c2e(0.00225918086942455), [20, 20, 20, 20, 20], 0.0005074927921996801, 43, 10, 20, 0.2, False, 10) completed, duration 124.5, best_val_loss: 0.6807491779327393, best_val_metric: 0.7427745664739884, best_hidden_layer_sizes: [3, 2, 4, 30, 144]\n",
      "Total duration 944.9, mean val metric 0.8120599867586343, mean duration 105.0, best overall combination: (85bbec58f3(0.00011615163141286432), [20, 20, 20, 20, 20], 0.00019631927731523537, 25, 10, 20, 0.2, False, 10), val_metric: 0.8444444444444444\n",
      "Run with parameters (546bd4028b(0.00017135894876311815), [20, 20, 20, 20, 20], 0.0005096797872868115, 59, 10, 20, 0.2, False, 10) started...\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomSearch()\n",
    "random_search.run(\n",
    "    early_stopping_conv, x=fashion_mnist.X_norm, y=fashion_mnist.y, validation_data=None, fraction=0.025, test_size=0.2,\n",
    "    schedule=PowerRange(-4.5, -2.5, lambda x: Schedule([DynamicEpoch(x, 'weighted_l1')])), \n",
    "    layer_sizes=[20, 20, 20, 20, 20],\n",
    "    learning_rate=UniformRange(0.0001, 0.0006),\n",
    "    batch_size=UniformRange(16, 64, integer=True),\n",
    "    output_neurons=10, min_new_neurons=20, growth_percentage=0.2, use_static_graph=False, max_setbacks=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with parameters (f0541bbe2d(0.0002275631770030383), [20, 20, 20, 20, 20], 0.0005525149068718821, 18, 10, 20, 0.2, False, 6) started...\n",
      "Run with parameters (f0541bbe2d(0.0002275631770030383), [20, 20, 20, 20, 20], 0.0005525149068718821, 18, 10, 20, 0.2, False, 6) completed, duration 83.4, best_val_loss: 0.5830672979354858, best_val_metric: 0.8050139275766016, best_hidden_layer_sizes: [20, 20, 20, 25, 86]\n",
      "Total duration 83.4, mean val metric 0.8050139275766016, mean duration 83.4, best overall combination: (f0541bbe2d(0.0002275631770030383), [20, 20, 20, 20, 20], 0.0005525149068718821, 18, 10, 20, 0.2, False, 6), val_metric: 0.8050139275766016\n",
      "Run with parameters (7ad06e4e19(0.000866824797496868), [20, 20, 20, 20, 20], 0.0003511112648415954, 20, 10, 20, 0.2, False, 6) started...\n",
      "Run with parameters (7ad06e4e19(0.000866824797496868), [20, 20, 20, 20, 20], 0.0003511112648415954, 20, 10, 20, 0.2, False, 6) completed, duration 120.3, best_val_loss: 0.6533282995223999, best_val_metric: 0.7822349570200573, best_hidden_layer_sizes: [6, 5, 3, 9, 38]\n",
      "Total duration 203.7, mean val metric 0.7936244422983294, mean duration 101.8, best overall combination: (f0541bbe2d(0.0002275631770030383), [20, 20, 20, 20, 20], 0.0005525149068718821, 18, 10, 20, 0.2, False, 6), val_metric: 0.8050139275766016\n",
      "Run with parameters (02246a240c(0.0005266589438930651), [20, 20, 20, 20, 20], 0.00041039100150685207, 62, 10, 20, 0.2, False, 6) started...\n",
      "Run with parameters (02246a240c(0.0005266589438930651), [20, 20, 20, 20, 20], 0.00041039100150685207, 62, 10, 20, 0.2, False, 6) completed, duration 42.4, best_val_loss: 0.46753597259521484, best_val_metric: 0.8367346938775511, best_hidden_layer_sizes: [20, 17, 16, 21, 28]\n",
      "Total duration 246.1, mean val metric 0.8079945261580699, mean duration 82.0, best overall combination: (02246a240c(0.0005266589438930651), [20, 20, 20, 20, 20], 0.00041039100150685207, 62, 10, 20, 0.2, False, 6), val_metric: 0.8367346938775511\n",
      "Run with parameters (25f7617d6d(0.00024824504505339257), [20, 20, 20, 20, 20], 0.0004024119301887034, 44, 10, 20, 0.2, False, 6) started...\n",
      "Run with parameters (25f7617d6d(0.00024824504505339257), [20, 20, 20, 20, 20], 0.0004024119301887034, 44, 10, 20, 0.2, False, 6) completed, duration 61.8, best_val_loss: 0.6272312998771667, best_val_metric: 0.8130311614730878, best_hidden_layer_sizes: [20, 20, 18, 28, 106]\n",
      "Total duration 307.9, mean val metric 0.8092536849868244, mean duration 77.0, best overall combination: (02246a240c(0.0005266589438930651), [20, 20, 20, 20, 20], 0.00041039100150685207, 62, 10, 20, 0.2, False, 6), val_metric: 0.8367346938775511\n",
      "Run with parameters (cb697ff3b1(0.0007825328785794726), [20, 20, 20, 20, 20], 0.0005240875630689853, 30, 10, 20, 0.2, False, 6) started...\n",
      "Run with parameters (cb697ff3b1(0.0007825328785794726), [20, 20, 20, 20, 20], 0.0005240875630689853, 30, 10, 20, 0.2, False, 6) completed, duration 61.8, best_val_loss: 0.6125507950782776, best_val_metric: 0.8016997167138811, best_hidden_layer_sizes: [14, 8, 9, 13, 75]\n",
      "Total duration 369.7, mean val metric 0.8077428913322358, mean duration 73.9, best overall combination: (02246a240c(0.0005266589438930651), [20, 20, 20, 20, 20], 0.00041039100150685207, 62, 10, 20, 0.2, False, 6), val_metric: 0.8367346938775511\n",
      "Run with parameters (fb704e8561(0.0015051736245438403), [20, 20, 20, 20, 20], 0.00020147571175877416, 61, 10, 20, 0.2, False, 6) started...\n",
      "Run with parameters (fb704e8561(0.0015051736245438403), [20, 20, 20, 20, 20], 0.00020147571175877416, 61, 10, 20, 0.2, False, 6) completed, duration 84.4, best_val_loss: 0.5733690857887268, best_val_metric: 0.8099415204678363, best_hidden_layer_sizes: [9, 3, 6, 8, 20]\n",
      "Total duration 454.2, mean val metric 0.8081093295215025, mean duration 75.7, best overall combination: (02246a240c(0.0005266589438930651), [20, 20, 20, 20, 20], 0.00041039100150685207, 62, 10, 20, 0.2, False, 6), val_metric: 0.8367346938775511\n",
      "Run with parameters (b27a15d7d7(5.803964889913124e-05), [20, 20, 20, 20, 20], 0.00022565373401930186, 21, 10, 20, 0.2, False, 6) started...\n",
      "Run with parameters (b27a15d7d7(5.803964889913124e-05), [20, 20, 20, 20, 20], 0.00022565373401930186, 21, 10, 20, 0.2, False, 6) completed, duration 84.4, best_val_loss: 0.6445563435554504, best_val_metric: 0.8064516129032258, best_hidden_layer_sizes: [21, 44, 25, 74, 44]\n",
      "Total duration 538.6, mean val metric 0.8078725128617487, mean duration 76.9, best overall combination: (02246a240c(0.0005266589438930651), [20, 20, 20, 20, 20], 0.00041039100150685207, 62, 10, 20, 0.2, False, 6), val_metric: 0.8367346938775511\n",
      "Run with parameters (0f295a8ad0(0.0004937736225092737), [20, 20, 20, 20, 20], 0.00024175257038771734, 57, 10, 20, 0.2, False, 6) started...\n",
      "Run with parameters (0f295a8ad0(0.0004937736225092737), [20, 20, 20, 20, 20], 0.00024175257038771734, 57, 10, 20, 0.2, False, 6) completed, duration 115.3, best_val_loss: 0.4835585951805115, best_val_metric: 0.8356940509915014, best_hidden_layer_sizes: [11, 7, 8, 12, 28]\n",
      "Total duration 653.9, mean val metric 0.8113502051279677, mean duration 81.7, best overall combination: (02246a240c(0.0005266589438930651), [20, 20, 20, 20, 20], 0.00041039100150685207, 62, 10, 20, 0.2, False, 6), val_metric: 0.8367346938775511\n",
      "Run with parameters (f24a90849a(0.0001633857022512683), [20, 20, 20, 20, 20], 0.0001578754146004184, 63, 10, 20, 0.2, False, 6) started...\n",
      "Run with parameters (f24a90849a(0.0001633857022512683), [20, 20, 20, 20, 20], 0.0001578754146004184, 63, 10, 20, 0.2, False, 6) completed, duration 52.7, best_val_loss: 0.537899374961853, best_val_metric: 0.8287292817679558, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Total duration 706.6, mean val metric 0.8132812136435219, mean duration 78.5, best overall combination: (02246a240c(0.0005266589438930651), [20, 20, 20, 20, 20], 0.00041039100150685207, 62, 10, 20, 0.2, False, 6), val_metric: 0.8367346938775511\n",
      "Run with parameters (8664c23f79(0.00019837152864803843), [20, 20, 20, 20, 20], 0.0005006476517816118, 34, 10, 20, 0.2, False, 6) started...\n",
      "Run with parameters (8664c23f79(0.00019837152864803843), [20, 20, 20, 20, 20], 0.0005006476517816118, 34, 10, 20, 0.2, False, 6) completed, duration 53.9, best_val_loss: 0.6022278666496277, best_val_metric: 0.8126801152737753, best_hidden_layer_sizes: [21, 39, 35, 45, 188]\n",
      "Total duration 760.5, mean val metric 0.8132211038065472, mean duration 76.1, best overall combination: (02246a240c(0.0005266589438930651), [20, 20, 20, 20, 20], 0.00041039100150685207, 62, 10, 20, 0.2, False, 6), val_metric: 0.8367346938775511\n",
      "Run with parameters (cab543c5ac(0.00025365962842928186), [20, 20, 20, 20, 20], 0.0003488561809367753, 20, 10, 20, 0.2, False, 6) started...\n",
      "Run with parameters (cab543c5ac(0.00025365962842928186), [20, 20, 20, 20, 20], 0.0003488561809367753, 20, 10, 20, 0.2, False, 6) completed, duration 112.6, best_val_loss: 0.5618656873703003, best_val_metric: 0.8230337078651685, best_hidden_layer_sizes: [11, 10, 10, 19, 77]\n",
      "Total duration 873.1, mean val metric 0.8141131587209673, mean duration 79.4, best overall combination: (02246a240c(0.0005266589438930651), [20, 20, 20, 20, 20], 0.00041039100150685207, 62, 10, 20, 0.2, False, 6), val_metric: 0.8367346938775511\n",
      "Run with parameters (a227aec5aa(0.00017267856211728534), [20, 20, 20, 20, 20], 0.0003190178643174164, 21, 10, 20, 0.2, False, 6) started...\n",
      "Run with parameters (a227aec5aa(0.00017267856211728534), [20, 20, 20, 20, 20], 0.0003190178643174164, 21, 10, 20, 0.2, False, 6) completed, duration 68.3, best_val_loss: 0.6566996574401855, best_val_metric: 0.7674418604651163, best_hidden_layer_sizes: [20, 20, 20, 24, 91]\n",
      "Total duration 941.4, mean val metric 0.810223883866313, mean duration 78.4, best overall combination: (02246a240c(0.0005266589438930651), [20, 20, 20, 20, 20], 0.00041039100150685207, 62, 10, 20, 0.2, False, 6), val_metric: 0.8367346938775511\n",
      "Run with parameters (5573ed0ae1(5.129107882552052e-05), [20, 20, 20, 20, 20], 0.0003016214773398251, 37, 10, 20, 0.2, False, 6) started...\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomSearch()\n",
    "random_search.run(\n",
    "    early_stopping_conv, x=fashion_mnist.X_norm, y=fashion_mnist.y, validation_data=None, fraction=0.025, test_size=0.2,\n",
    "    schedule=PowerRange(-4.5, -2.5, lambda x: Schedule([DynamicEpoch(x, 'weighted_l1')])), \n",
    "    layer_sizes=[20, 20, 20, 20, 20],\n",
    "    learning_rate=UniformRange(0.0001, 0.0006),\n",
    "    batch_size=UniformRange(16, 64, integer=True),\n",
    "    output_neurons=10, min_new_neurons=20, growth_percentage=0.2, use_static_graph=False, max_setbacks=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with parameters (463e4d3c19(0.00026211059410829736), [50, 50, 50, 50, 50], 0.0003690287789228201, 16, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (463e4d3c19(0.00026211059410829736), [50, 50, 50, 50, 50], 0.0003690287789228201, 16, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.5107776522636414, best_val_metric: 0.8476454293628809, best_hidden_layer_sizes: [20, 8, 11, 16, 98]\n",
      "Duration 93.6, best overall combination: (463e4d3c19(0.00026211059410829736), [50, 50, 50, 50, 50], 0.0003690287789228201, 16, 10, 20, 0.2, False, 8), val_metric: 0.8476454293628809\n",
      "Run with parameters (6ee41e6e4f(6.3074541435798e-05), [50, 50, 50, 50, 50], 0.00046130857577600766, 50, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (6ee41e6e4f(6.3074541435798e-05), [50, 50, 50, 50, 50], 0.00046130857577600766, 50, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.522895097732544, best_val_metric: 0.8259587020648967, best_hidden_layer_sizes: [50, 56, 71, 110, 224]\n",
      "Duration 159.9, best overall combination: (463e4d3c19(0.00026211059410829736), [50, 50, 50, 50, 50], 0.0003690287789228201, 16, 10, 20, 0.2, False, 8), val_metric: 0.8476454293628809\n",
      "Run with parameters (ea2ae4ff9e(0.0011365553720094112), [50, 50, 50, 50, 50], 0.00034671886937982717, 39, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (ea2ae4ff9e(0.0011365553720094112), [50, 50, 50, 50, 50], 0.00034671886937982717, 39, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.5669693946838379, best_val_metric: 0.8099173553719008, best_hidden_layer_sizes: [7, 3, 4, 8, 49]\n",
      "Duration 97.7, best overall combination: (463e4d3c19(0.00026211059410829736), [50, 50, 50, 50, 50], 0.0003690287789228201, 16, 10, 20, 0.2, False, 8), val_metric: 0.8476454293628809\n",
      "Run with parameters (48cb58f187(0.00021753399836860863), [50, 50, 50, 50, 50], 0.00010144571137322125, 33, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (48cb58f187(0.00021753399836860863), [50, 50, 50, 50, 50], 0.00010144571137322125, 33, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.5034694671630859, best_val_metric: 0.8694362017804155, best_hidden_layer_sizes: [50, 25, 36, 36, 50]\n",
      "Duration 140.8, best overall combination: (48cb58f187(0.00021753399836860863), [50, 50, 50, 50, 50], 0.00010144571137322125, 33, 10, 20, 0.2, False, 8), val_metric: 0.8694362017804155\n",
      "Run with parameters (b9938fa799(0.00027435721426186284), [50, 50, 50, 50, 50], 0.00025558305463140144, 57, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (b9938fa799(0.00027435721426186284), [50, 50, 50, 50, 50], 0.00025558305463140144, 57, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.540863037109375, best_val_metric: 0.8304093567251462, best_hidden_layer_sizes: [31, 9, 17, 16, 50]\n",
      "Duration 94.7, best overall combination: (48cb58f187(0.00021753399836860863), [50, 50, 50, 50, 50], 0.00010144571137322125, 33, 10, 20, 0.2, False, 8), val_metric: 0.8694362017804155\n",
      "Run with parameters (e3a5c8a217(0.0016716013169481526), [50, 50, 50, 50, 50], 0.0002435572561822391, 32, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (e3a5c8a217(0.0016716013169481526), [50, 50, 50, 50, 50], 0.0002435572561822391, 32, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.619108259677887, best_val_metric: 0.7865168539325843, best_hidden_layer_sizes: [2, 2, 5, 5, 34]\n",
      "Duration 121.3, best overall combination: (48cb58f187(0.00021753399836860863), [50, 50, 50, 50, 50], 0.00010144571137322125, 33, 10, 20, 0.2, False, 8), val_metric: 0.8694362017804155\n",
      "Run with parameters (2ffead5a51(0.00035664647543057703), [50, 50, 50, 50, 50], 0.000507773853482657, 21, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (2ffead5a51(0.00035664647543057703), [50, 50, 50, 50, 50], 0.000507773853482657, 21, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.6483399868011475, best_val_metric: 0.7953216374269005, best_hidden_layer_sizes: [7, 10, 12, 25, 277]\n",
      "Duration 113.9, best overall combination: (48cb58f187(0.00021753399836860863), [50, 50, 50, 50, 50], 0.00010144571137322125, 33, 10, 20, 0.2, False, 8), val_metric: 0.8694362017804155\n",
      "Run with parameters (7a28eb0ff7(0.0002523376809909988), [50, 50, 50, 50, 50], 0.0003222141123099835, 46, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (7a28eb0ff7(0.0002523376809909988), [50, 50, 50, 50, 50], 0.0003222141123099835, 46, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.5571436285972595, best_val_metric: 0.828169014084507, best_hidden_layer_sizes: [50, 15, 23, 24, 50]\n",
      "Duration 93.1, best overall combination: (48cb58f187(0.00021753399836860863), [50, 50, 50, 50, 50], 0.00010144571137322125, 33, 10, 20, 0.2, False, 8), val_metric: 0.8694362017804155\n",
      "Run with parameters (3351342aa6(0.00019999564929251842), [50, 50, 50, 50, 50], 0.0005661353342319749, 27, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (3351342aa6(0.00019999564929251842), [50, 50, 50, 50, 50], 0.0005661353342319749, 27, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.5588454604148865, best_val_metric: 0.8155619596541787, best_hidden_layer_sizes: [23, 23, 38, 62, 462]\n",
      "Duration 156.1, best overall combination: (48cb58f187(0.00021753399836860863), [50, 50, 50, 50, 50], 0.00010144571137322125, 33, 10, 20, 0.2, False, 8), val_metric: 0.8694362017804155\n",
      "Run with parameters (3d32b3d0d4(9.79897821479283e-05), [50, 50, 50, 50, 50], 0.0003740760973231357, 16, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (3d32b3d0d4(9.79897821479283e-05), [50, 50, 50, 50, 50], 0.0003740760973231357, 16, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.5583347678184509, best_val_metric: 0.8405797101449275, best_hidden_layer_sizes: [37, 22, 38, 46, 217]\n",
      "Duration 148.2, best overall combination: (48cb58f187(0.00021753399836860863), [50, 50, 50, 50, 50], 0.00010144571137322125, 33, 10, 20, 0.2, False, 8), val_metric: 0.8694362017804155\n",
      "Run with parameters (bc0396b4b2(0.001207675570240366), [50, 50, 50, 50, 50], 0.0005716329136988635, 51, 10, 20, 0.2, False, 8) started...\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomSearch()\n",
    "random_search.run(\n",
    "    early_stopping_conv, x=fashion_mnist.X_norm, y=fashion_mnist.y, validation_data=None, fraction=0.025, test_size=0.2,\n",
    "    schedule=PowerRange(-4.5, -2.5, lambda x: Schedule([DynamicEpoch(x, 'weighted_l1')])), \n",
    "    layer_sizes=[50, 50, 50, 50, 50],\n",
    "    learning_rate=UniformRange(0.0001, 0.0006),\n",
    "    batch_size=UniformRange(16, 64, integer=True),\n",
    "    output_neurons=10, min_new_neurons=20, growth_percentage=0.2, use_static_graph=False, max_setbacks=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8249516220548339"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([result.val_metric for result in random_search.results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121.92176241874695"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([result.duration for result in random_search.results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with parameters (92da5ff824(0.001327145179613897), 0.0003014684191618844, 31, 10, 20, 0.2, False, 2, (49, 47, 29, 96, 95)) started...\n",
      "Run with parameters (92da5ff824(0.001327145179613897), 0.0003014684191618844, 31, 10, 20, 0.2, False, 2, (49, 47, 29, 96, 95)) completed, best_val_loss: 0.8706918358802795, best_val_metric: 0.692090395480226, best_hidden_layer_sizes: [49, 47, 29, 96, 95]\n",
      "Duration 15.6, best overall combination: (92da5ff824(0.001327145179613897), 0.0003014684191618844, 31, 10, 20, 0.2, False, 2, (49, 47, 29, 96, 95)), val_metric: 0.692090395480226\n",
      "Run with parameters (722de840ea(3.180801097665005e-05), 0.00016195544083580154, 46, 10, 20, 0.2, False, 2, (37, 47, 74, 100, 22)) started...\n",
      "Run with parameters (722de840ea(3.180801097665005e-05), 0.00016195544083580154, 46, 10, 20, 0.2, False, 2, (37, 47, 74, 100, 22)) completed, best_val_loss: 0.5480306148529053, best_val_metric: 0.8342696629213483, best_hidden_layer_sizes: [37, 47, 74, 100, 24]\n",
      "Duration 25.5, best overall combination: (722de840ea(3.180801097665005e-05), 0.00016195544083580154, 46, 10, 20, 0.2, False, 2, (37, 47, 74, 100, 22)), val_metric: 0.8342696629213483\n",
      "Run with parameters (dac47eaab2(0.0011235260597752073), 0.00022308504909775395, 18, 10, 20, 0.2, False, 2, (92, 76, 77, 30, 91)) started...\n",
      "Run with parameters (dac47eaab2(0.0011235260597752073), 0.00022308504909775395, 18, 10, 20, 0.2, False, 2, (92, 76, 77, 30, 91)) completed, best_val_loss: 0.6368179321289062, best_val_metric: 0.7703488372093024, best_hidden_layer_sizes: [16, 3, 7, 6, 51]\n",
      "Duration 96.9, best overall combination: (722de840ea(3.180801097665005e-05), 0.00016195544083580154, 46, 10, 20, 0.2, False, 2, (37, 47, 74, 100, 22)), val_metric: 0.8342696629213483\n",
      "Run with parameters (8dba05224b(0.00021072396434981475), 0.0002932838176918663, 54, 10, 20, 0.2, False, 2, (77, 49, 28, 50, 89)) started...\n",
      "Run with parameters (8dba05224b(0.00021072396434981475), 0.0002932838176918663, 54, 10, 20, 0.2, False, 2, (77, 49, 28, 50, 89)) completed, best_val_loss: 0.7210728526115417, best_val_metric: 0.7527472527472527, best_hidden_layer_sizes: [77, 49, 28, 50, 89]\n",
      "Duration 21.2, best overall combination: (722de840ea(3.180801097665005e-05), 0.00016195544083580154, 46, 10, 20, 0.2, False, 2, (37, 47, 74, 100, 22)), val_metric: 0.8342696629213483\n",
      "Run with parameters (a43dc131a8(0.0006241115208602315), 0.0004989963219628005, 39, 10, 20, 0.2, False, 2, (77, 15, 80, 58, 64)) started...\n",
      "Run with parameters (a43dc131a8(0.0006241115208602315), 0.0004989963219628005, 39, 10, 20, 0.2, False, 2, (77, 15, 80, 58, 64)) completed, best_val_loss: 0.6262671947479248, best_val_metric: 0.7556818181818182, best_hidden_layer_sizes: [77, 15, 26, 20, 64]\n",
      "Duration 30.4, best overall combination: (722de840ea(3.180801097665005e-05), 0.00016195544083580154, 46, 10, 20, 0.2, False, 2, (37, 47, 74, 100, 22)), val_metric: 0.8342696629213483\n",
      "Run with parameters (d62bd782ff(0.0001021133810374144), 0.0004969995175149294, 56, 10, 20, 0.2, False, 2, (50, 37, 31, 56, 31)) started...\n",
      "Run with parameters (d62bd782ff(0.0001021133810374144), 0.0004969995175149294, 56, 10, 20, 0.2, False, 2, (50, 37, 31, 56, 31)) completed, best_val_loss: 0.4668729603290558, best_val_metric: 0.8498583569405099, best_hidden_layer_sizes: [50, 38, 31, 58, 33]\n",
      "Duration 20.3, best overall combination: (d62bd782ff(0.0001021133810374144), 0.0004969995175149294, 56, 10, 20, 0.2, False, 2, (50, 37, 31, 56, 31)), val_metric: 0.8498583569405099\n",
      "Run with parameters (904cce7c4d(0.0002642403081708951), 0.0005334863989454249, 51, 10, 20, 0.2, False, 2, (94, 18, 24, 77, 45)) started...\n",
      "Run with parameters (904cce7c4d(0.0002642403081708951), 0.0005334863989454249, 51, 10, 20, 0.2, False, 2, (94, 18, 24, 77, 45)) completed, best_val_loss: 0.5438368320465088, best_val_metric: 0.8169014084507042, best_hidden_layer_sizes: [90, 19, 24, 36, 72]\n",
      "Duration 50.4, best overall combination: (d62bd782ff(0.0001021133810374144), 0.0004969995175149294, 56, 10, 20, 0.2, False, 2, (50, 37, 31, 56, 31)), val_metric: 0.8498583569405099\n",
      "Run with parameters (b8ee5328d5(0.0026096721823892738), 0.000322521952774443, 41, 10, 20, 0.2, False, 2, (51, 73, 83, 80, 24)) started...\n",
      "Run with parameters (b8ee5328d5(0.0026096721823892738), 0.000322521952774443, 41, 10, 20, 0.2, False, 2, (51, 73, 83, 80, 24)) completed, best_val_loss: 1.1994773149490356, best_val_metric: 0.6564245810055865, best_hidden_layer_sizes: [51, 73, 83, 80, 24]\n",
      "Duration 15.6, best overall combination: (d62bd782ff(0.0001021133810374144), 0.0004969995175149294, 56, 10, 20, 0.2, False, 2, (50, 37, 31, 56, 31)), val_metric: 0.8498583569405099\n",
      "Run with parameters (7331ef247c(0.0014540021479407734), 0.0003926878296830616, 24, 10, 20, 0.2, False, 2, (55, 28, 43, 55, 61)) started...\n",
      "Run with parameters (7331ef247c(0.0014540021479407734), 0.0003926878296830616, 24, 10, 20, 0.2, False, 2, (55, 28, 43, 55, 61)) completed, best_val_loss: 0.599659264087677, best_val_metric: 0.8130311614730878, best_hidden_layer_sizes: [5, 5, 4, 5, 54]\n",
      "Duration 49.6, best overall combination: (d62bd782ff(0.0001021133810374144), 0.0004969995175149294, 56, 10, 20, 0.2, False, 2, (50, 37, 31, 56, 31)), val_metric: 0.8498583569405099\n",
      "Run with parameters (af2653f517(0.0003239309391385059), 0.00047678784431874247, 42, 10, 20, 0.2, False, 2, (23, 74, 39, 41, 60)) started...\n",
      "Run with parameters (af2653f517(0.0003239309391385059), 0.00047678784431874247, 42, 10, 20, 0.2, False, 2, (23, 74, 39, 41, 60)) completed, best_val_loss: 0.6457809805870056, best_val_metric: 0.7749287749287749, best_hidden_layer_sizes: [23, 74, 39, 41, 60]\n",
      "Duration 12.2, best overall combination: (d62bd782ff(0.0001021133810374144), 0.0004969995175149294, 56, 10, 20, 0.2, False, 2, (50, 37, 31, 56, 31)), val_metric: 0.8498583569405099\n",
      "Run with parameters (d318a0bfa8(0.0012036628587194604), 0.00037596374532263243, 55, 10, 20, 0.2, False, 2, (41, 40, 67, 100, 22)) started...\n",
      "Run with parameters (d318a0bfa8(0.0012036628587194604), 0.00037596374532263243, 55, 10, 20, 0.2, False, 2, (41, 40, 67, 100, 22)) completed, best_val_loss: 0.7657655477523804, best_val_metric: 0.7570621468926554, best_hidden_layer_sizes: [41, 40, 67, 100, 22]\n",
      "Duration 14.8, best overall combination: (d62bd782ff(0.0001021133810374144), 0.0004969995175149294, 56, 10, 20, 0.2, False, 2, (50, 37, 31, 56, 31)), val_metric: 0.8498583569405099\n",
      "Run with parameters (e15f932700(0.00040568902684371696), 0.0005178595697949658, 44, 10, 20, 0.2, False, 2, (19, 48, 29, 74, 83)) started...\n",
      "Run with parameters (e15f932700(0.00040568902684371696), 0.0005178595697949658, 44, 10, 20, 0.2, False, 2, (19, 48, 29, 74, 83)) completed, best_val_loss: 0.6010717749595642, best_val_metric: 0.7987987987987988, best_hidden_layer_sizes: [19, 48, 29, 74, 83]\n",
      "Duration 10.6, best overall combination: (d62bd782ff(0.0001021133810374144), 0.0004969995175149294, 56, 10, 20, 0.2, False, 2, (50, 37, 31, 56, 31)), val_metric: 0.8498583569405099\n",
      "Run with parameters (97dec0019c(0.00023310188448116904), 0.0005976667823843929, 48, 10, 20, 0.2, False, 2, (69, 72, 60, 26, 32)) started...\n",
      "Run with parameters (97dec0019c(0.00023310188448116904), 0.0005976667823843929, 48, 10, 20, 0.2, False, 2, (69, 72, 60, 26, 32)) completed, best_val_loss: 0.5495500564575195, best_val_metric: 0.8039772727272727, best_hidden_layer_sizes: [47, 51, 68, 116, 299]\n",
      "Duration 62.1, best overall combination: (d62bd782ff(0.0001021133810374144), 0.0004969995175149294, 56, 10, 20, 0.2, False, 2, (50, 37, 31, 56, 31)), val_metric: 0.8498583569405099\n",
      "Run with parameters (1827852088(0.0001109085537027648), 0.00021300513335947884, 52, 10, 20, 0.2, False, 2, (19, 44, 26, 25, 54)) started...\n",
      "Run with parameters (1827852088(0.0001109085537027648), 0.00021300513335947884, 52, 10, 20, 0.2, False, 2, (19, 44, 26, 25, 54)) completed, best_val_loss: 0.5314173102378845, best_val_metric: 0.8375350140056023, best_hidden_layer_sizes: [19, 44, 26, 25, 54]\n",
      "Duration 26.5, best overall combination: (d62bd782ff(0.0001021133810374144), 0.0004969995175149294, 56, 10, 20, 0.2, False, 2, (50, 37, 31, 56, 31)), val_metric: 0.8498583569405099\n",
      "Run with parameters (a608902242(0.00020075929549690617), 0.0003690001979258244, 43, 10, 20, 0.2, False, 2, (93, 93, 61, 98, 99)) started...\n",
      "Run with parameters (a608902242(0.00020075929549690617), 0.0003690001979258244, 43, 10, 20, 0.2, False, 2, (93, 93, 61, 98, 99)) completed, best_val_loss: 0.7308432459831238, best_val_metric: 0.7118155619596542, best_hidden_layer_sizes: [93, 93, 61, 98, 99]\n",
      "Duration 19.0, best overall combination: (d62bd782ff(0.0001021133810374144), 0.0004969995175149294, 56, 10, 20, 0.2, False, 2, (50, 37, 31, 56, 31)), val_metric: 0.8498583569405099\n",
      "Run with parameters (727d23fa92(0.00010762530837160302), 0.0002228439030162331, 54, 10, 20, 0.2, False, 2, (31, 75, 53, 87, 14)) started...\n",
      "Run with parameters (727d23fa92(0.00010762530837160302), 0.0002228439030162331, 54, 10, 20, 0.2, False, 2, (31, 75, 53, 87, 14)) completed, best_val_loss: 0.587053656578064, best_val_metric: 0.8089887640449438, best_hidden_layer_sizes: [31, 30, 30, 51, 28]\n",
      "Duration 72.6, best overall combination: (d62bd782ff(0.0001021133810374144), 0.0004969995175149294, 56, 10, 20, 0.2, False, 2, (50, 37, 31, 56, 31)), val_metric: 0.8498583569405099\n",
      "Run with parameters (e77395e23f(6.953656035412979e-05), 0.0003435249694001554, 58, 10, 20, 0.2, False, 2, (60, 93, 80, 52, 26)) started...\n",
      "Run with parameters (e77395e23f(6.953656035412979e-05), 0.0003435249694001554, 58, 10, 20, 0.2, False, 2, (60, 93, 80, 52, 26)) completed, best_val_loss: 0.6087561845779419, best_val_metric: 0.8202247191011236, best_hidden_layer_sizes: [60, 93, 80, 85, 32]\n",
      "Duration 50.9, best overall combination: (d62bd782ff(0.0001021133810374144), 0.0004969995175149294, 56, 10, 20, 0.2, False, 2, (50, 37, 31, 56, 31)), val_metric: 0.8498583569405099\n",
      "Run with parameters (b8f643f965(0.00042168954436590613), 0.0003583528708792458, 35, 10, 20, 0.2, False, 2, (71, 68, 84, 40, 37)) started...\n",
      "Run with parameters (b8f643f965(0.00042168954436590613), 0.0003583528708792458, 35, 10, 20, 0.2, False, 2, (71, 68, 84, 40, 37)) completed, best_val_loss: 0.5433481931686401, best_val_metric: 0.8149171270718232, best_hidden_layer_sizes: [10, 7, 8, 16, 52]\n",
      "Duration 68.8, best overall combination: (d62bd782ff(0.0001021133810374144), 0.0004969995175149294, 56, 10, 20, 0.2, False, 2, (50, 37, 31, 56, 31)), val_metric: 0.8498583569405099\n",
      "Run with parameters (125ef5b333(0.0001970734317733352), 0.000388054178689386, 60, 10, 20, 0.2, False, 2, (63, 31, 34, 70, 83)) started...\n",
      "Run with parameters (125ef5b333(0.0001970734317733352), 0.000388054178689386, 60, 10, 20, 0.2, False, 2, (63, 31, 34, 70, 83)) completed, best_val_loss: 0.5719460844993591, best_val_metric: 0.8089887640449438, best_hidden_layer_sizes: [63, 31, 34, 70, 83]\n",
      "Duration 13.8, best overall combination: (d62bd782ff(0.0001021133810374144), 0.0004969995175149294, 56, 10, 20, 0.2, False, 2, (50, 37, 31, 56, 31)), val_metric: 0.8498583569405099\n",
      "Run with parameters (1c8d03e9ff(0.000560106593488175), 0.0005205803102534404, 43, 10, 20, 0.2, False, 2, (21, 23, 61, 91, 17)) started...\n",
      "Run with parameters (1c8d03e9ff(0.000560106593488175), 0.0005205803102534404, 43, 10, 20, 0.2, False, 2, (21, 23, 61, 91, 17)) completed, best_val_loss: 0.587602436542511, best_val_metric: 0.7916666666666666, best_hidden_layer_sizes: [21, 15, 16, 20, 36]\n",
      "Duration 29.9, best overall combination: (d62bd782ff(0.0001021133810374144), 0.0004969995175149294, 56, 10, 20, 0.2, False, 2, (50, 37, 31, 56, 31)), val_metric: 0.8498583569405099\n",
      "Run with parameters (c18df742a4(0.0007527133361927392), 0.00016047230704292873, 51, 10, 20, 0.2, False, 2, (56, 60, 55, 59, 73)) started...\n",
      "Run with parameters (c18df742a4(0.0007527133361927392), 0.00016047230704292873, 51, 10, 20, 0.2, False, 2, (56, 60, 55, 59, 73)) completed, best_val_loss: 0.7751816511154175, best_val_metric: 0.7415730337078652, best_hidden_layer_sizes: [56, 60, 55, 59, 73]\n",
      "Duration 15.5, best overall combination: (d62bd782ff(0.0001021133810374144), 0.0004969995175149294, 56, 10, 20, 0.2, False, 2, (50, 37, 31, 56, 31)), val_metric: 0.8498583569405099\n",
      "Run with parameters (a453ccc0a8(0.000180431307321972), 0.00034676166927691867, 16, 10, 20, 0.2, False, 2, (63, 63, 84, 68, 59)) started...\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomSearch()\n",
    "random_search.run(\n",
    "    early_stopping_conv, x=fashion_mnist.X_norm, y=fashion_mnist.y, validation_data=None, fraction=0.025, test_size=0.2,\n",
    "    schedule=PowerRange(-4.5, -2.5, lambda x: Schedule([DynamicEpoch(x, 'weighted_l1')])), \n",
    "    layer_1_size=UniformRange(10, 100, integer=True),\n",
    "    layer_2_size=UniformRange(10, 100, integer=True),\n",
    "    layer_3_size=UniformRange(10, 100, integer=True),\n",
    "    layer_4_size=UniformRange(10, 100, integer=True),\n",
    "    layer_5_size=UniformRange(10, 100, integer=True),\n",
    "    learning_rate=UniformRange(0.0001, 0.0006),\n",
    "    batch_size=UniformRange(16, 64, integer=True),\n",
    "    output_neurons=10, min_new_neurons=20, growth_percentage=0.2, use_static_graph=False, postprocess_fn=layer_sizes_join_postprocess, max_setbacks=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7815157199219028"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([result.val_metric for result in random_search.results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with parameters (5aee8427d6(0.00031622776601683794), 0.00034999999999999994, 40, 10, 20, 0.2, False, 2, (55, 55, 55, 55, 55)) started...\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), 0.00034999999999999994, 40, 10, 20, 0.2, False, 2, (55, 55, 55, 55, 55)) completed, best_val_loss: 0.6776053309440613, best_val_metric: 0.8048128342245989, best_hidden_layer_sizes: [55, 55, 55, 55, 55]\n",
      "Duration 23.7, best overall combination: (5aee8427d6(0.00031622776601683794), 0.00034999999999999994, 40, 10, 20, 0.2, False, 2, (55, 55, 55, 55, 55)), val_metric: 0.8048128342245989\n",
      "Run with parameters (928f3d7753(0.001), 0.00034999999999999994, 40, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 55)) started...\n",
      "Run with parameters (928f3d7753(0.001), 0.00034999999999999994, 40, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 55)) completed, best_val_loss: 0.5780321359634399, best_val_metric: 0.8153409090909091, best_hidden_layer_sizes: [78, 55, 32, 78, 55]\n",
      "Duration 17.6, best overall combination: (928f3d7753(0.001), 0.00034999999999999994, 40, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 55)), val_metric: 0.8153409090909091\n",
      "Run with parameters (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)) started...\n",
      "Run with parameters (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)) completed, best_val_loss: 0.44566279649734497, best_val_metric: 0.8596491228070176, best_hidden_layer_sizes: [78, 55, 32, 78, 32]\n",
      "Duration 19.6, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (928f3d7753(0.001), 0.000225, 40, 10, 20, 0.2, False, 2, (78, 78, 32, 78, 32)) started...\n",
      "Run with parameters (928f3d7753(0.001), 0.000225, 40, 10, 20, 0.2, False, 2, (78, 78, 32, 78, 32)) completed, best_val_loss: 0.4252968728542328, best_val_metric: 0.8444444444444444, best_hidden_layer_sizes: [78, 78, 32, 78, 32]\n",
      "Duration 48.7, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (928f3d7753(0.001), 0.000225, 28, 10, 20, 0.2, False, 2, (32, 78, 78, 32, 55)) started...\n",
      "Run with parameters (928f3d7753(0.001), 0.000225, 28, 10, 20, 0.2, False, 2, (32, 78, 78, 32, 55)) completed, best_val_loss: 0.6410727500915527, best_val_metric: 0.8130311614730878, best_hidden_layer_sizes: [32, 78, 78, 32, 55]\n",
      "Duration 31.8, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (928f3d7753(0.001), 0.0004749999999999999, 40, 10, 20, 0.2, False, 2, (55, 32, 32, 78, 32)) started...\n",
      "Run with parameters (928f3d7753(0.001), 0.0004749999999999999, 40, 10, 20, 0.2, False, 2, (55, 32, 32, 78, 32)) completed, best_val_loss: 0.612732470035553, best_val_metric: 0.815028901734104, best_hidden_layer_sizes: [55, 32, 32, 78, 32]\n",
      "Duration 21.7, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (3219c4823d(0.0001), 0.000225, 28, 10, 20, 0.2, False, 2, (78, 78, 55, 32, 32)) started...\n",
      "Run with parameters (3219c4823d(0.0001), 0.000225, 28, 10, 20, 0.2, False, 2, (78, 78, 55, 32, 32)) completed, best_val_loss: 0.4620809853076935, best_val_metric: 0.8563218390804598, best_hidden_layer_sizes: [78, 78, 55, 32, 32]\n",
      "Duration 37.5, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (928f3d7753(0.001), 0.0004749999999999999, 40, 10, 20, 0.2, False, 2, (55, 32, 78, 32, 55)) started...\n",
      "Run with parameters (928f3d7753(0.001), 0.0004749999999999999, 40, 10, 20, 0.2, False, 2, (55, 32, 78, 32, 55)) completed, best_val_loss: 0.630723237991333, best_val_metric: 0.8, best_hidden_layer_sizes: [55, 32, 78, 32, 55]\n",
      "Duration 18.7, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), 0.000225, 52, 10, 20, 0.2, False, 2, (55, 78, 32, 32, 78)) started...\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), 0.000225, 52, 10, 20, 0.2, False, 2, (55, 78, 32, 32, 78)) completed, best_val_loss: 0.49086815118789673, best_val_metric: 0.8579387186629527, best_hidden_layer_sizes: [55, 78, 32, 32, 78]\n",
      "Duration 30.4, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (928f3d7753(0.001), 0.000225, 40, 10, 20, 0.2, False, 2, (55, 78, 32, 78, 55)) started...\n",
      "Run with parameters (928f3d7753(0.001), 0.000225, 40, 10, 20, 0.2, False, 2, (55, 78, 32, 78, 55)) completed, best_val_loss: 0.5738522410392761, best_val_metric: 0.8181818181818182, best_hidden_layer_sizes: [55, 78, 32, 78, 55]\n",
      "Duration 26.5, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), 0.000225, 52, 10, 20, 0.2, False, 2, (55, 32, 55, 55, 32)) started...\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), 0.000225, 52, 10, 20, 0.2, False, 2, (55, 32, 55, 55, 32)) completed, best_val_loss: 0.5667111873626709, best_val_metric: 0.811965811965812, best_hidden_layer_sizes: [55, 32, 55, 55, 32]\n",
      "Duration 30.9, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (3219c4823d(0.0001), 0.00034999999999999994, 40, 10, 20, 0.2, False, 2, (55, 78, 32, 32, 55)) started...\n",
      "Run with parameters (3219c4823d(0.0001), 0.00034999999999999994, 40, 10, 20, 0.2, False, 2, (55, 78, 32, 32, 55)) completed, best_val_loss: 0.6290911436080933, best_val_metric: 0.8, best_hidden_layer_sizes: [55, 78, 32, 32, 55]\n",
      "Duration 23.4, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (928f3d7753(0.001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 32, 32, 55, 32)) started...\n",
      "Run with parameters (928f3d7753(0.001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 32, 32, 55, 32)) completed, best_val_loss: 0.5532920360565186, best_val_metric: 0.8088642659279779, best_hidden_layer_sizes: [78, 32, 32, 55, 32]\n",
      "Duration 19.6, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), 0.000225, 52, 10, 20, 0.2, False, 2, (78, 32, 55, 55, 32)) started...\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), 0.000225, 52, 10, 20, 0.2, False, 2, (78, 32, 55, 55, 32)) completed, best_val_loss: 0.6072491407394409, best_val_metric: 0.8047337278106509, best_hidden_layer_sizes: [78, 32, 55, 55, 32]\n",
      "Duration 19.6, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (928f3d7753(0.001), 0.0004749999999999999, 52, 10, 20, 0.2, False, 2, (78, 78, 32, 32, 78)) started...\n",
      "Run with parameters (928f3d7753(0.001), 0.0004749999999999999, 52, 10, 20, 0.2, False, 2, (78, 78, 32, 32, 78)) completed, best_val_loss: 0.7074972987174988, best_val_metric: 0.788235294117647, best_hidden_layer_sizes: [78, 78, 32, 32, 78]\n",
      "Duration 18.0, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), 0.00034999999999999994, 40, 10, 20, 0.2, False, 2, (78, 55, 55, 55, 78)) started...\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), 0.00034999999999999994, 40, 10, 20, 0.2, False, 2, (78, 55, 55, 55, 78)) completed, best_val_loss: 0.6470315456390381, best_val_metric: 0.815028901734104, best_hidden_layer_sizes: [78, 55, 55, 55, 78]\n",
      "Duration 23.5, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (928f3d7753(0.001), 0.000225, 28, 10, 20, 0.2, False, 2, (32, 78, 55, 78, 55)) started...\n",
      "Run with parameters (928f3d7753(0.001), 0.000225, 28, 10, 20, 0.2, False, 2, (32, 78, 55, 78, 55)) completed, best_val_loss: 0.5872088074684143, best_val_metric: 0.8046647230320699, best_hidden_layer_sizes: [32, 78, 55, 78, 55]\n",
      "Duration 37.6, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (928f3d7753(0.001), 0.0004749999999999999, 52, 10, 20, 0.2, False, 2, (32, 78, 55, 55, 32)) started...\n",
      "Run with parameters (928f3d7753(0.001), 0.0004749999999999999, 52, 10, 20, 0.2, False, 2, (32, 78, 55, 55, 32)) completed, best_val_loss: 0.5816760063171387, best_val_metric: 0.8068181818181818, best_hidden_layer_sizes: [32, 78, 55, 55, 32]\n",
      "Duration 18.7, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), 0.000225, 40, 10, 20, 0.2, False, 2, (32, 32, 32, 55, 78)) started...\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), 0.000225, 40, 10, 20, 0.2, False, 2, (32, 32, 32, 55, 78)) completed, best_val_loss: 0.479550302028656, best_val_metric: 0.8424068767908309, best_hidden_layer_sizes: [32, 32, 32, 55, 78]\n",
      "Duration 12.6, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (3219c4823d(0.0001), 0.0004749999999999999, 28, 10, 20, 0.2, False, 2, (55, 32, 78, 32, 55)) started...\n",
      "Run with parameters (3219c4823d(0.0001), 0.0004749999999999999, 28, 10, 20, 0.2, False, 2, (55, 32, 78, 32, 55)) completed, best_val_loss: 0.6476293802261353, best_val_metric: 0.7891566265060241, best_hidden_layer_sizes: [55, 32, 78, 32, 55]\n",
      "Duration 15.8, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (3219c4823d(0.0001), 0.00034999999999999994, 40, 10, 20, 0.2, False, 2, (78, 78, 32, 55, 55)) started...\n",
      "Run with parameters (3219c4823d(0.0001), 0.00034999999999999994, 40, 10, 20, 0.2, False, 2, (78, 78, 32, 55, 55)) completed, best_val_loss: 0.6109314560890198, best_val_metric: 0.8338028169014085, best_hidden_layer_sizes: [78, 78, 32, 55, 55]\n",
      "Duration 24.9, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (928f3d7753(0.001), 0.00034999999999999994, 40, 10, 20, 0.2, False, 2, (55, 55, 32, 78, 78)) started...\n",
      "Run with parameters (928f3d7753(0.001), 0.00034999999999999994, 40, 10, 20, 0.2, False, 2, (55, 55, 32, 78, 78)) completed, best_val_loss: 0.4905775487422943, best_val_metric: 0.8476454293628809, best_hidden_layer_sizes: [55, 55, 32, 78, 78]\n",
      "Duration 28.4, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (928f3d7753(0.001), 0.000225, 40, 10, 20, 0.2, False, 2, (78, 32, 55, 78, 55)) started...\n",
      "Run with parameters (928f3d7753(0.001), 0.000225, 40, 10, 20, 0.2, False, 2, (78, 32, 55, 78, 55)) completed, best_val_loss: 0.5975072979927063, best_val_metric: 0.7982708933717579, best_hidden_layer_sizes: [78, 32, 55, 78, 55]\n",
      "Duration 21.0, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (928f3d7753(0.001), 0.000225, 28, 10, 20, 0.2, False, 2, (78, 78, 55, 55, 32)) started...\n",
      "Run with parameters (928f3d7753(0.001), 0.000225, 28, 10, 20, 0.2, False, 2, (78, 78, 55, 55, 32)) completed, best_val_loss: 0.4962027370929718, best_val_metric: 0.8221574344023324, best_hidden_layer_sizes: [78, 78, 55, 55, 32]\n",
      "Duration 31.3, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (3219c4823d(0.0001), 0.00034999999999999994, 28, 10, 20, 0.2, False, 2, (55, 55, 55, 55, 78)) started...\n",
      "Run with parameters (3219c4823d(0.0001), 0.00034999999999999994, 28, 10, 20, 0.2, False, 2, (55, 55, 55, 55, 78)) completed, best_val_loss: 0.7119351625442505, best_val_metric: 0.7749287749287749, best_hidden_layer_sizes: [55, 55, 55, 55, 78]\n",
      "Duration 25.8, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (3219c4823d(0.0001), 0.000225, 40, 10, 20, 0.2, False, 2, (55, 55, 78, 55, 78)) started...\n",
      "Run with parameters (3219c4823d(0.0001), 0.000225, 40, 10, 20, 0.2, False, 2, (55, 55, 78, 55, 78)) completed, best_val_loss: 0.4848856031894684, best_val_metric: 0.8426966292134831, best_hidden_layer_sizes: [55, 55, 78, 55, 78]\n",
      "Duration 28.9, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), 0.000225, 52, 10, 20, 0.2, False, 2, (55, 78, 78, 78, 55)) started...\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), 0.000225, 52, 10, 20, 0.2, False, 2, (55, 78, 78, 78, 55)) completed, best_val_loss: 0.5731907486915588, best_val_metric: 0.8361581920903954, best_hidden_layer_sizes: [55, 78, 78, 78, 55]\n",
      "Duration 36.0, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (32, 32, 78, 55, 32)) started...\n",
      "Run with parameters (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (32, 32, 78, 55, 32)) completed, best_val_loss: 0.5068926811218262, best_val_metric: 0.8502824858757062, best_hidden_layer_sizes: [32, 32, 78, 55, 32]\n",
      "Duration 21.1, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (3219c4823d(0.0001), 0.0004749999999999999, 52, 10, 20, 0.2, False, 2, (32, 32, 55, 55, 55)) started...\n",
      "Run with parameters (3219c4823d(0.0001), 0.0004749999999999999, 52, 10, 20, 0.2, False, 2, (32, 32, 55, 55, 55)) completed, best_val_loss: 0.5167398452758789, best_val_metric: 0.8313953488372093, best_hidden_layer_sizes: [32, 32, 55, 55, 55]\n",
      "Duration 18.5, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (928f3d7753(0.001), 0.000225, 28, 10, 20, 0.2, False, 2, (32, 55, 78, 78, 78)) started...\n",
      "Run with parameters (928f3d7753(0.001), 0.000225, 28, 10, 20, 0.2, False, 2, (32, 55, 78, 78, 78)) completed, best_val_loss: 0.5192923545837402, best_val_metric: 0.8501440922190202, best_hidden_layer_sizes: [32, 55, 78, 78, 78]\n",
      "Duration 35.1, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (3219c4823d(0.0001), 0.0004749999999999999, 28, 10, 20, 0.2, False, 2, (55, 32, 55, 78, 32)) started...\n",
      "Run with parameters (3219c4823d(0.0001), 0.0004749999999999999, 28, 10, 20, 0.2, False, 2, (55, 32, 55, 78, 32)) completed, best_val_loss: 0.6638617515563965, best_val_metric: 0.786144578313253, best_hidden_layer_sizes: [55, 32, 55, 78, 32]\n",
      "Duration 18.6, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 55, 55)) started...\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 55, 55)) completed, best_val_loss: 0.5498997569084167, best_val_metric: 0.8057971014492754, best_hidden_layer_sizes: [78, 55, 32, 55, 55]\n",
      "Duration 22.6, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (3219c4823d(0.0001), 0.0004749999999999999, 28, 10, 20, 0.2, False, 2, (55, 32, 32, 32, 32)) started...\n",
      "Run with parameters (3219c4823d(0.0001), 0.0004749999999999999, 28, 10, 20, 0.2, False, 2, (55, 32, 32, 32, 32)) completed, best_val_loss: 0.48894011974334717, best_val_metric: 0.8407079646017699, best_hidden_layer_sizes: [55, 32, 32, 32, 32]\n",
      "Duration 32.3, best overall combination: (3219c4823d(0.0001), 0.00034999999999999994, 52, 10, 20, 0.2, False, 2, (78, 55, 32, 78, 32)), val_metric: 0.8596491228070176\n",
      "Run with parameters (928f3d7753(0.001), 0.00034999999999999994, 28, 10, 20, 0.2, False, 2, (55, 55, 55, 55, 32)) started...\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "grid_search = AnytimeGridSearch()\n",
    "grid_search.run(\n",
    "    early_stopping_conv, x=fashion_mnist.X_norm, y=fashion_mnist.y, validation_data=None, fraction=0.025, test_size=0.2,\n",
    "    schedule=PowerRange(-4.5, -2.5, lambda x: Schedule([StaticEpoch(x, 'l1')])), \n",
    "    layer_1_size=UniformRange(10, 100, integer=True),\n",
    "    layer_2_size=UniformRange(10, 100, integer=True),\n",
    "    layer_3_size=UniformRange(10, 100, integer=True),\n",
    "    layer_4_size=UniformRange(10, 100, integer=True),\n",
    "    layer_5_size=UniformRange(10, 100, integer=True),\n",
    "    learning_rate=UniformRange(0.0001, 0.0006),\n",
    "    batch_size=UniformRange(16, 64, integer=True),\n",
    "    output_neurons=10, min_new_neurons=20, growth_percentage=0.2, use_static_graph=False, postprocess_fn=layer_sizes_join_postprocess, max_setbacks=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8205077545748471"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([result.val_metric for result in grid_search.results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with parameters (5aee8427d6(0.00031622776601683794), [55, 55, 55, 55, 55], 0.00034999999999999994, 40, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), [55, 55, 55, 55, 55], 0.00034999999999999994, 40, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.5153456330299377, best_val_metric: 0.835195530726257, best_hidden_layer_sizes: [55, 55, 55, 55, 55]\n",
      "Duration 38.0, best overall combination: (5aee8427d6(0.00031622776601683794), [55, 55, 55, 55, 55], 0.00034999999999999994, 40, 10, 20, 0.2, False, 8), val_metric: 0.835195530726257\n",
      "Run with parameters (928f3d7753(0.001), [55, 55, 55, 55, 55], 0.00034999999999999994, 28, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (928f3d7753(0.001), [55, 55, 55, 55, 55], 0.00034999999999999994, 28, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.47439122200012207, best_val_metric: 0.8342696629213483, best_hidden_layer_sizes: [55, 55, 55, 55, 55]\n",
      "Duration 48.9, best overall combination: (5aee8427d6(0.00031622776601683794), [55, 55, 55, 55, 55], 0.00034999999999999994, 40, 10, 20, 0.2, False, 8), val_metric: 0.835195530726257\n",
      "Run with parameters (3219c4823d(0.0001), [55, 55, 55, 55, 55], 0.0004749999999999999, 52, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (3219c4823d(0.0001), [55, 55, 55, 55, 55], 0.0004749999999999999, 52, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.5530596971511841, best_val_metric: 0.8348082595870207, best_hidden_layer_sizes: [55, 55, 55, 55, 55]\n",
      "Duration 34.1, best overall combination: (5aee8427d6(0.00031622776601683794), [55, 55, 55, 55, 55], 0.00034999999999999994, 40, 10, 20, 0.2, False, 8), val_metric: 0.835195530726257\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), [78, 78, 78, 78, 78], 0.0004749999999999999, 52, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), [78, 78, 78, 78, 78], 0.0004749999999999999, 52, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.6738657355308533, best_val_metric: 0.8376811594202899, best_hidden_layer_sizes: [78, 78, 78, 78, 78]\n",
      "Duration 40.9, best overall combination: (5aee8427d6(0.00031622776601683794), [78, 78, 78, 78, 78], 0.0004749999999999999, 52, 10, 20, 0.2, False, 8), val_metric: 0.8376811594202899\n",
      "Run with parameters (928f3d7753(0.001), [78, 78, 78, 78, 78], 0.0004749999999999999, 40, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (928f3d7753(0.001), [78, 78, 78, 78, 78], 0.0004749999999999999, 40, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.527868390083313, best_val_metric: 0.8299120234604106, best_hidden_layer_sizes: [78, 78, 78, 78, 78]\n",
      "Duration 75.4, best overall combination: (5aee8427d6(0.00031622776601683794), [78, 78, 78, 78, 78], 0.0004749999999999999, 52, 10, 20, 0.2, False, 8), val_metric: 0.8376811594202899\n",
      "Run with parameters (928f3d7753(0.001), [78, 78, 78, 78, 78], 0.0004749999999999999, 28, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (928f3d7753(0.001), [78, 78, 78, 78, 78], 0.0004749999999999999, 28, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.6520633697509766, best_val_metric: 0.8045977011494253, best_hidden_layer_sizes: [78, 78, 78, 78, 78]\n",
      "Duration 65.6, best overall combination: (5aee8427d6(0.00031622776601683794), [78, 78, 78, 78, 78], 0.0004749999999999999, 52, 10, 20, 0.2, False, 8), val_metric: 0.8376811594202899\n",
      "Run with parameters (3219c4823d(0.0001), [55, 55, 55, 55, 55], 0.000225, 40, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (3219c4823d(0.0001), [55, 55, 55, 55, 55], 0.000225, 40, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.6283782720565796, best_val_metric: 0.8218390804597702, best_hidden_layer_sizes: [55, 55, 55, 55, 55]\n",
      "Duration 68.4, best overall combination: (5aee8427d6(0.00031622776601683794), [78, 78, 78, 78, 78], 0.0004749999999999999, 52, 10, 20, 0.2, False, 8), val_metric: 0.8376811594202899\n",
      "Run with parameters (928f3d7753(0.001), [78, 78, 78, 78, 78], 0.00034999999999999994, 28, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (928f3d7753(0.001), [78, 78, 78, 78, 78], 0.00034999999999999994, 28, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.4952996075153351, best_val_metric: 0.851123595505618, best_hidden_layer_sizes: [78, 78, 78, 78, 78]\n",
      "Duration 71.3, best overall combination: (928f3d7753(0.001), [78, 78, 78, 78, 78], 0.00034999999999999994, 28, 10, 20, 0.2, False, 8), val_metric: 0.851123595505618\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), [55, 55, 55, 55, 55], 0.0004749999999999999, 52, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), [55, 55, 55, 55, 55], 0.0004749999999999999, 52, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.655376136302948, best_val_metric: 0.8149171270718232, best_hidden_layer_sizes: [55, 55, 55, 55, 55]\n",
      "Duration 28.9, best overall combination: (928f3d7753(0.001), [78, 78, 78, 78, 78], 0.00034999999999999994, 28, 10, 20, 0.2, False, 8), val_metric: 0.851123595505618\n",
      "Run with parameters (3219c4823d(0.0001), [78, 78, 78, 78, 78], 0.000225, 52, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (3219c4823d(0.0001), [78, 78, 78, 78, 78], 0.000225, 52, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.6184266805648804, best_val_metric: 0.8225352112676056, best_hidden_layer_sizes: [78, 78, 78, 78, 78]\n",
      "Duration 48.1, best overall combination: (928f3d7753(0.001), [78, 78, 78, 78, 78], 0.00034999999999999994, 28, 10, 20, 0.2, False, 8), val_metric: 0.851123595505618\n",
      "Run with parameters (3219c4823d(0.0001), [32, 32, 32, 32, 32], 0.000225, 52, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (3219c4823d(0.0001), [32, 32, 32, 32, 32], 0.000225, 52, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.5200031995773315, best_val_metric: 0.8314285714285714, best_hidden_layer_sizes: [32, 32, 32, 32, 32]\n",
      "Duration 40.3, best overall combination: (928f3d7753(0.001), [78, 78, 78, 78, 78], 0.00034999999999999994, 28, 10, 20, 0.2, False, 8), val_metric: 0.851123595505618\n",
      "Run with parameters (928f3d7753(0.001), [78, 78, 78, 78, 78], 0.000225, 28, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (928f3d7753(0.001), [78, 78, 78, 78, 78], 0.000225, 28, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.5870131254196167, best_val_metric: 0.8092485549132948, best_hidden_layer_sizes: [78, 78, 78, 78, 78]\n",
      "Duration 52.9, best overall combination: (928f3d7753(0.001), [78, 78, 78, 78, 78], 0.00034999999999999994, 28, 10, 20, 0.2, False, 8), val_metric: 0.851123595505618\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), [32, 32, 32, 32, 32], 0.000225, 28, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), [32, 32, 32, 32, 32], 0.000225, 28, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.5819296836853027, best_val_metric: 0.8097982708933718, best_hidden_layer_sizes: [32, 32, 32, 32, 32]\n",
      "Duration 55.5, best overall combination: (928f3d7753(0.001), [78, 78, 78, 78, 78], 0.00034999999999999994, 28, 10, 20, 0.2, False, 8), val_metric: 0.851123595505618\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), [78, 78, 78, 78, 78], 0.00034999999999999994, 40, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), [78, 78, 78, 78, 78], 0.00034999999999999994, 40, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.6702806949615479, best_val_metric: 0.8194444444444444, best_hidden_layer_sizes: [78, 78, 78, 78, 78]\n",
      "Duration 54.2, best overall combination: (928f3d7753(0.001), [78, 78, 78, 78, 78], 0.00034999999999999994, 28, 10, 20, 0.2, False, 8), val_metric: 0.851123595505618\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), [55, 55, 55, 55, 55], 0.00034999999999999994, 52, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), [55, 55, 55, 55, 55], 0.00034999999999999994, 52, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.6496330499649048, best_val_metric: 0.8132183908045977, best_hidden_layer_sizes: [55, 55, 55, 55, 55]\n",
      "Duration 29.2, best overall combination: (928f3d7753(0.001), [78, 78, 78, 78, 78], 0.00034999999999999994, 28, 10, 20, 0.2, False, 8), val_metric: 0.851123595505618\n",
      "Run with parameters (3219c4823d(0.0001), [78, 78, 78, 78, 78], 0.0004749999999999999, 40, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (3219c4823d(0.0001), [78, 78, 78, 78, 78], 0.0004749999999999999, 40, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.6719756722450256, best_val_metric: 0.8361111111111111, best_hidden_layer_sizes: [78, 78, 78, 78, 78]\n",
      "Duration 38.7, best overall combination: (928f3d7753(0.001), [78, 78, 78, 78, 78], 0.00034999999999999994, 28, 10, 20, 0.2, False, 8), val_metric: 0.851123595505618\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), [32, 32, 32, 32, 32], 0.00034999999999999994, 28, 10, 20, 0.2, False, 8) started...\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "grid_search = AnytimeGridSearch()\n",
    "grid_search.run(\n",
    "    early_stopping_conv, x=fashion_mnist.X_norm, y=fashion_mnist.y, validation_data=None, fraction=0.025, test_size=0.2,\n",
    "    schedule=PowerRange(-4.5, -2.5, lambda x: Schedule([StaticEpoch(x, 'l1')])), \n",
    "    layer_sizes=UniformRange(10, 100, lambda x: [x] * 5, integer=True),\n",
    "    learning_rate=UniformRange(0.0001, 0.0006),\n",
    "    batch_size=UniformRange(16, 64, integer=True),\n",
    "    output_neurons=10, min_new_neurons=20, growth_percentage=0.2, use_static_graph=False, max_setbacks=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82538304344781"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([result.val_metric for result in grid_search.results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with parameters (5aee8427d6(0.00031622776601683794), [55, 55, 55, 55, 55], 0.00034999999999999994, 40, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), [55, 55, 55, 55, 55], 0.00034999999999999994, 40, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.5916856527328491, best_val_metric: 0.8181818181818182, best_hidden_layer_sizes: [55, 55, 55, 55, 55]\n",
      "Duration 40.6, best overall combination: (5aee8427d6(0.00031622776601683794), [55, 55, 55, 55, 55], 0.00034999999999999994, 40, 10, 20, 0.2, False, 8), val_metric: 0.8181818181818182\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), [78, 78, 78, 78, 78], 0.00034999999999999994, 28, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), [78, 78, 78, 78, 78], 0.00034999999999999994, 28, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.6058548092842102, best_val_metric: 0.8410404624277457, best_hidden_layer_sizes: [78, 78, 78, 78, 78]\n",
      "Duration 62.0, best overall combination: (5aee8427d6(0.00031622776601683794), [78, 78, 78, 78, 78], 0.00034999999999999994, 28, 10, 20, 0.2, False, 8), val_metric: 0.8410404624277457\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), [78, 78, 78, 78, 78], 0.00034999999999999994, 40, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), [78, 78, 78, 78, 78], 0.00034999999999999994, 40, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.5739880204200745, best_val_metric: 0.8401162790697675, best_hidden_layer_sizes: [78, 78, 78, 78, 78]\n",
      "Duration 57.3, best overall combination: (5aee8427d6(0.00031622776601683794), [78, 78, 78, 78, 78], 0.00034999999999999994, 28, 10, 20, 0.2, False, 8), val_metric: 0.8410404624277457\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), [78, 78, 78, 78, 78], 0.00034999999999999994, 52, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), [78, 78, 78, 78, 78], 0.00034999999999999994, 52, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.5426760315895081, best_val_metric: 0.8171091445427728, best_hidden_layer_sizes: [78, 78, 78, 78, 78]\n",
      "Duration 45.6, best overall combination: (5aee8427d6(0.00031622776601683794), [78, 78, 78, 78, 78], 0.00034999999999999994, 28, 10, 20, 0.2, False, 8), val_metric: 0.8410404624277457\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), [32, 32, 32, 32, 32], 0.0004749999999999999, 28, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), [32, 32, 32, 32, 32], 0.0004749999999999999, 28, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.44519293308258057, best_val_metric: 0.8388888888888889, best_hidden_layer_sizes: [32, 32, 32, 32, 32]\n",
      "Duration 40.0, best overall combination: (5aee8427d6(0.00031622776601683794), [78, 78, 78, 78, 78], 0.00034999999999999994, 28, 10, 20, 0.2, False, 8), val_metric: 0.8410404624277457\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), [32, 32, 32, 32, 32], 0.0004749999999999999, 40, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), [32, 32, 32, 32, 32], 0.0004749999999999999, 40, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.6045172810554504, best_val_metric: 0.8186813186813187, best_hidden_layer_sizes: [32, 32, 32, 32, 32]\n",
      "Duration 29.2, best overall combination: (5aee8427d6(0.00031622776601683794), [78, 78, 78, 78, 78], 0.00034999999999999994, 28, 10, 20, 0.2, False, 8), val_metric: 0.8410404624277457\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), [32, 32, 32, 32, 32], 0.0004749999999999999, 52, 10, 20, 0.2, False, 8) started...\n",
      "Run with parameters (5aee8427d6(0.00031622776601683794), [32, 32, 32, 32, 32], 0.0004749999999999999, 52, 10, 20, 0.2, False, 8) completed, best_val_loss: 0.5726032853126526, best_val_metric: 0.8502824858757062, best_hidden_layer_sizes: [32, 32, 32, 32, 32]\n",
      "Duration 28.0, best overall combination: (5aee8427d6(0.00031622776601683794), [32, 32, 32, 32, 32], 0.0004749999999999999, 52, 10, 20, 0.2, False, 8), val_metric: 0.8502824858757062\n",
      "Run with parameters (928f3d7753(0.001), [55, 55, 55, 55, 55], 0.00034999999999999994, 28, 10, 20, 0.2, False, 8) started...\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "grid_search = AnytimeGridSearch()\n",
    "grid_search.run(\n",
    "    early_stopping_conv, x=fashion_mnist.X_norm, y=fashion_mnist.y, validation_data=None, fraction=0.025, test_size=0.2, randomize=False,\n",
    "    schedule=PowerRange(-4.5, -2.5, lambda x: Schedule([StaticEpoch(x, 'l1')])), \n",
    "    layer_sizes=UniformRange(10, 100, lambda x: [x] * 5, integer=True),\n",
    "    learning_rate=UniformRange(0.0001, 0.0006),\n",
    "    batch_size=UniformRange(16, 64, integer=True),\n",
    "    output_neurons=10, min_new_neurons=20, growth_percentage=0.2, use_static_graph=False, max_setbacks=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8320429139525738"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([result.val_metric for result in grid_search.results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###########################################\n",
      "Started run 0...\n",
      "Generation 0: 51.7 s, best val metric 0.7243, [(1, 0.7243, 0.7243, 0.001, 0.00045047822868158314, 26, [20, 20, 20, 20, 20]), (1, 0.6804, 0.6804, 0.00036921351158514465, 0.00042328904879388937, 33, [20, 20, 20, 20, 20]), (1, 0.6804, 0.6804, 0.00036921351158514465, 0.00042328904879388937, 33, [20, 20, 20, 20, 20]), (1, 0.6774, 0.6774, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6716, 0.6716, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6716, 0.6716, 0.0002318534912545094, 0.0004299492304831737, 23, [20, 20, 20, 31, 20]), (1, 0.6686, 0.6686, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6686, 0.6686, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6569, 0.6569, 0.001, 0.00039688787629910707, 35, [20, 20, 20, 20, 20]), (1, 0.651, 0.651, 0.0006242303735264302, 0.0004086689425332929, 30, [20, 20, 20, 20, 20])]\n",
      "#### Total duration 51.7, overall best val metric 0.7243401759530792 ####\n",
      "Total run duration 51.67835474014282, mean duration 51.67835474014282, mean val metric 0.7243401759530792\n",
      "Saved results to file results/Evolution2022-04-12-15-34-48\n",
      "Completed.\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    'regularization_penalty': Hyperparameter(3., 3., 4.5, 0.5),\n",
    "    'learning_rate': Hyperparameter(0.0004, 0.0001, 0.0006, 0.000025),\n",
    "    'batch_size': Hyperparameter(32, 16, 64, 4),\n",
    "}\n",
    "results = anytime_multirun(Evolution, n_runs=1, save=True, x=fashion_mnist.X_norm, y=fashion_mnist.y, validation_data=None, fraction=0.025, test_size=0.2,\n",
    "              layer_sizes=[20, 20, 20, 20, 20], output_neurons=10, hyperparameters=hyperparameters, n_parents=5, population_size=10, \n",
    "              n_generations=1, tournament_size=3, n_introduced=2, age_penalty_period=10, use_static_graph=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cifar 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = get_cifar_10_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Static models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashnion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = get_fashion_mnist_dataset(fraction=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: 80.7 s, best val metric 0.7056, [(1, 0.7056, 0.7056, 9.456344654366426e-05, 0.00038364190812786164, 32, [20, 20, 20, 38, 24]), (1, 0.7056, 0.7056, 9.456344654366426e-05, 0.00038364190812786164, 32, [20, 20, 20, 38, 24]), (1, 0.6954, 0.6954, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6853, 0.6853, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6853, 0.6853, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6853, 0.6853, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6802, 0.6802, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6802, 0.6802, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6701, 0.6701, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6548, 0.6548, 0.0003884943543836332, 0.0003561937315055006, 24, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.7055837563451777 ####\n",
      "Generation 1: 79.6 s, best val metric 0.7716, [(2, 0.7716, 0.7716, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7614, 0.7614, 9.78069324887646e-05, 0.00041136667909830616, 37, [20, 23, 20, 20, 21]), (2, 0.7614, 0.7614, 9.78069324887646e-05, 0.00041136667909830616, 37, [20, 23, 20, 20, 21]), (2, 0.7513, 0.7513, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7462, 0.7462, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7462, 0.7462, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7411, 0.7411, 0.0031622776601683794, 0.00043295390717766694, 26, [20, 20, 20, 20, 20]), (2, 0.7411, 0.7411, 0.0006747573813520718, 0.000379494749040991, 24, [20, 20, 20, 20, 20]), (2, 0.7411, 0.7411, 0.0001844704128074617, 0.0004230221948642858, 33, [20, 20, 20, 38, 22]), (2, 0.736, 0.736, 9.456344654366426e-05, 0.00038364190812786164, 32, [20, 20, 20, 38, 26]), (2, 0.7056, 0.7056, 9.456344654366426e-05, 0.00038364190812786164, 32, [20, 20, 20, 38, 24])]\n",
      "#### Overall best val metric 0.7715736040609137 ####\n",
      "Generation 2: 87.7 s, best val metric 0.797, [(3, 0.797, 0.797, 0.00047536370052946394, 0.00041495101985608346, 33, [20, 20, 20, 20, 20]), (3, 0.7868, 0.7868, 9.456344654366426e-05, 0.00038364190812786164, 32, [20, 20, 20, 46, 35]), (3, 0.7868, 0.7868, 9.456344654366426e-05, 0.00038364190812786164, 32, [20, 20, 20, 46, 35]), (3, 0.7868, 0.7868, 9.456344654366426e-05, 0.00038364190812786164, 32, [20, 20, 20, 46, 35]), (3, 0.7817, 0.7817, 8.580495136484046e-05, 0.0004397142229599078, 29, [20, 35, 23, 40, 38]), (3, 0.7817, 0.7817, 8.580495136484046e-05, 0.0004397142229599078, 29, [20, 35, 23, 40, 38]), (3, 0.7817, 0.7817, 8.580495136484046e-05, 0.0004397142229599078, 29, [20, 35, 23, 40, 38]), (3, 0.7766, 0.7766, 0.0008824249519631757, 0.00041691399609305817, 33, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 9.78069324887646e-05, 0.00041136667909830616, 37, [20, 21, 20, 25, 22]), (3, 0.7716, 0.7716, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (3, 0.7665, 0.7665, 9.456344654366426e-05, 0.00038364190812786164, 32, [20, 20, 20, 42, 27])]\n",
      "#### Overall best val metric 0.7969543147208121 ####\n",
      "Generation 3: 107.3 s, best val metric 0.8122, [(4, 0.8122, 0.8122, 9.456344654366426e-05, 0.00038364190812786164, 32, [20, 21, 20, 50, 38]), (4, 0.802, 0.802, 0.0001066146040742186, 0.0004070404949072553, 24, [20, 32, 20, 32, 39]), (4, 0.802, 0.802, 0.0001066146040742186, 0.0004070404949072553, 24, [20, 32, 20, 32, 39]), (4, 0.802, 0.802, 0.0002622965534202609, 0.0004169760500104441, 37, [20, 20, 20, 37, 23]), (4, 0.797, 0.797, 0.00047536370052946394, 0.00041495101985608346, 33, [20, 20, 20, 20, 20]), (4, 0.7919, 0.7919, 8.580495136484046e-05, 0.0004397142229599078, 29, [20, 52, 23, 58, 47]), (4, 0.7919, 0.7919, 0.0001670280906095747, 0.000371002053161714, 29, [20, 23, 20, 40, 31]), (4, 0.7919, 0.7919, 0.0001670280906095747, 0.000371002053161714, 29, [20, 23, 20, 40, 31]), (4, 0.7868, 0.7868, 0.0006650835773601007, 0.000440411667467704, 32, [20, 20, 20, 21, 20]), (4, 0.7868, 0.7868, 0.00018994875614640399, 0.00040341092494415045, 33, [20, 20, 20, 39, 27]), (4, 0.7868, 0.7868, 0.00018994875614640399, 0.00040341092494415045, 33, [20, 20, 20, 39, 27])]\n",
      "#### Overall best val metric 0.8121827411167513 ####\n",
      "Generation 4: 107.4 s, best val metric 0.8122, [(5, 0.8122, 0.8122, 0.00025948673375992144, 0.00043916377908313965, 24, [20, 20, 20, 37, 27]), (5, 0.8122, 0.8122, 9.456344654366426e-05, 0.00038364190812786164, 32, [20, 25, 20, 52, 40]), (5, 0.8122, 0.8122, 9.456344654366426e-05, 0.00038364190812786164, 32, [20, 21, 20, 50, 38]), (5, 0.8071, 0.8071, 0.00018994875614640399, 0.00040341092494415045, 33, [20, 22, 20, 39, 28]), (5, 0.802, 0.802, 0.0001670280906095747, 0.000371002053161714, 29, [20, 21, 20, 39, 31]), (5, 0.7919, 0.7919, 0.00018141838511850054, 0.0004357972142079593, 31, [20, 24, 20, 21, 27]), (5, 0.7919, 0.7919, 0.00018994875614640399, 0.00040341092494415045, 33, [20, 20, 20, 37, 28]), (5, 0.7919, 0.7919, 0.00018141838511850054, 0.0004357972142079593, 31, [20, 24, 20, 21, 27]), (5, 0.7868, 0.7868, 0.0006650835773601007, 0.000440411667467704, 32, [20, 20, 20, 20, 20]), (5, 0.7868, 0.7868, 0.0001670280906095747, 0.000371002053161714, 29, [20, 23, 20, 40, 34]), (5, 0.7868, 0.7868, 0.0006650835773601007, 0.000440411667467704, 32, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8121827411167513 ####\n",
      "Generation 5: 91.6 s, best val metric 0.8274, [(6, 0.8274, 0.8274, 0.0002158943453314709, 0.00039920505525983634, 25, [20, 20, 20, 37, 39]), (6, 0.8274, 0.8274, 0.0002158943453314709, 0.00039920505525983634, 25, [20, 20, 20, 37, 39]), (6, 0.8173, 0.8173, 0.00015290746691273442, 0.0004068675441256286, 38, [20, 20, 20, 27, 25]), (6, 0.8173, 0.8173, 0.00018141838511850054, 0.0004357972142079593, 31, [20, 25, 20, 21, 36]), (6, 0.8122, 0.8122, 0.00027308013817120574, 0.0004267158423915852, 31, [20, 20, 20, 27, 22]), (6, 0.8122, 0.8122, 0.00027308013817120574, 0.0004267158423915852, 31, [20, 20, 20, 27, 22]), (6, 0.8122, 0.8122, 0.00025948673375992144, 0.00043916377908313965, 24, [20, 20, 20, 37, 27]), (6, 0.8071, 0.8071, 0.0006650835773601007, 0.000440411667467704, 32, [20, 20, 20, 20, 22]), (6, 0.802, 0.802, 0.00018994875614640399, 0.00040341092494415045, 33, [20, 20, 20, 45, 30]), (6, 0.7868, 0.7868, 0.0031622776601683794, 0.00042291700866668627, 37, [20, 20, 20, 34, 20]), (6, 0.7817, 0.7817, 0.00018141838511850054, 0.0004357972142079593, 31, [20, 25, 20, 21, 33])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 6: 90.7 s, best val metric 0.8274, [(7, 0.8274, 0.8274, 0.0002158943453314709, 0.00039920505525983634, 25, [20, 20, 20, 37, 39]), (7, 0.8173, 0.8173, 0.0002158943453314709, 0.00039920505525983634, 25, [20, 20, 20, 34, 43]), (7, 0.8071, 0.8071, 0.00038518353090006706, 0.0003947580164864487, 30, [20, 20, 20, 31, 26]), (7, 0.8071, 0.8071, 0.00018994875614640399, 0.00040341092494415045, 33, [20, 20, 20, 38, 36]), (7, 0.8071, 0.8071, 4.036434688048434e-05, 0.00036444659615118765, 33, [28, 40, 39, 57, 59]), (7, 0.8071, 0.8071, 0.00038518353090006706, 0.0003947580164864487, 30, [20, 20, 20, 31, 26]), (7, 0.8071, 0.8071, 0.00038518353090006706, 0.0003947580164864487, 30, [20, 20, 20, 31, 26]), (7, 0.802, 0.802, 0.00036898235793336184, 0.00034797985902864623, 31, [20, 20, 20, 21, 28]), (7, 0.802, 0.802, 0.00025948673375992144, 0.00043916377908313965, 24, [20, 20, 20, 34, 30]), (7, 0.802, 0.802, 0.00036826567401617734, 0.0004318957584525375, 36, [20, 20, 20, 20, 28]), (7, 0.7868, 0.7868, 0.00018141838511850054, 0.0004357972142079593, 31, [20, 31, 20, 26, 40])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 7: 98.9 s, best val metric 0.8274, [(8, 0.8274, 0.8274, 0.0002158943453314709, 0.00039920505525983634, 25, [20, 20, 20, 37, 39]), (8, 0.8223, 0.8223, 3.1622776601683795e-05, 0.0003947200663904853, 30, [20, 40, 40, 51, 46]), (8, 0.8223, 0.8223, 0.00036898235793336184, 0.00034797985902864623, 31, [20, 20, 20, 20, 26]), (8, 0.8223, 0.8223, 0.00036898235793336184, 0.00034797985902864623, 31, [20, 20, 20, 20, 26]), (8, 0.8223, 0.8223, 0.00036898235793336184, 0.00034797985902864623, 31, [20, 20, 20, 20, 26]), (8, 0.8173, 0.8173, 0.0002158943453314709, 0.00039920505525983634, 25, [20, 20, 20, 35, 35]), (8, 0.8122, 0.8122, 0.00025948673375992144, 0.00043916377908313965, 24, [20, 20, 20, 33, 37]), (8, 0.8122, 0.8122, 0.00038518353090006706, 0.0003947580164864487, 30, [20, 20, 20, 21, 31]), (8, 0.8122, 0.8122, 0.0001566278234804365, 0.0003778021046932116, 25, [20, 20, 20, 34, 49]), (8, 0.802, 0.802, 0.00036826567401617734, 0.0004318957584525375, 36, [20, 20, 20, 20, 27]), (8, 0.7868, 0.7868, 4.036434688048434e-05, 0.00036444659615118765, 33, [37, 59, 49, 77, 79])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 8: 100.7 s, best val metric 0.8274, [(9, 0.8274, 0.8274, 0.0002158943453314709, 0.00039920505525983634, 25, [20, 20, 20, 37, 39]), (9, 0.8223, 0.8223, 0.00036826567401617734, 0.0004318957584525375, 36, [20, 20, 20, 20, 29]), (9, 0.8122, 0.8122, 8.67499513145641e-05, 0.00036074864381921244, 30, [20, 21, 20, 54, 56]), (9, 0.8071, 0.8071, 8.163308305688062e-05, 0.000387327770576567, 29, [20, 32, 22, 55, 55]), (9, 0.797, 0.797, 0.0006101167520247794, 0.00037268329447293904, 24, [20, 20, 20, 22, 29]), (9, 0.7919, 0.7919, 0.00010901957006727402, 0.00042006567103996894, 30, [20, 37, 24, 40, 46]), (9, 0.7919, 0.7919, 0.00011900530101883338, 0.0003743282945002785, 28, [20, 20, 20, 37, 41]), (9, 0.7919, 0.7919, 0.00011900530101883338, 0.0003743282945002785, 28, [20, 20, 20, 37, 41]), (9, 0.7919, 0.7919, 6.0083702013072396e-05, 0.00042080634218379743, 24, [21, 40, 40, 40, 47]), (9, 0.7919, 0.7919, 6.0083702013072396e-05, 0.00042080634218379743, 24, [21, 40, 40, 40, 47]), (9, 0.7868, 0.7868, 0.00025948673375992144, 0.00043916377908313965, 24, [20, 22, 20, 37, 55])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 9: 111.5 s, best val metric 0.8325, [(10, 0.8325, 0.8325, 0.0013487660210729387, 0.0003777289675186337, 38, [20, 20, 21, 36, 21]), (10, 0.8325, 0.8325, 0.0013487660210729387, 0.0003777289675186337, 38, [20, 20, 21, 36, 21]), (10, 0.8274, 0.8274, 0.0002158943453314709, 0.00039920505525983634, 25, [20, 20, 20, 37, 39]), (10, 0.8122, 0.8122, 0.000717969622931903, 0.0004028729468376282, 28, [20, 20, 20, 20, 24]), (10, 0.8071, 0.8071, 0.00025948673375992144, 0.00043916377908313965, 24, [20, 21, 20, 34, 53]), (10, 0.8071, 0.8071, 3.1622776601683795e-05, 0.0004107659395596811, 30, [38, 40, 40, 57, 59]), (10, 0.8071, 0.8071, 8.163308305688062e-05, 0.000387327770576567, 29, [20, 42, 22, 75, 66]), (10, 0.8071, 0.8071, 0.00025948673375992144, 0.00043916377908313965, 24, [20, 21, 20, 34, 53]), (10, 0.8071, 0.8071, 0.00010901957006727402, 0.00042006567103996894, 30, [20, 53, 23, 60, 65]), (10, 0.802, 0.802, 0.0001688905908980135, 0.0004370089351661884, 24, [20, 20, 20, 41, 48]), (10, 0.797, 0.797, 3.844810819259737e-05, 0.00037601563269274644, 26, [36, 40, 40, 57, 61])]\n",
      "#### Overall best val metric 0.8324873096446701 ####\n",
      "Generation 10: 115.3 s, best val metric 0.8325, [(11, 0.8325, 0.8251, 0.0013487660210729387, 0.0003777289675186337, 38, [20, 20, 21, 36, 21]), (11, 0.8071, 0.7999, 0.00020232867809252797, 0.0004000764109599745, 32, [20, 60, 21, 51, 65]), (11, 0.8071, 0.7999, 0.00020232867809252797, 0.0004000764109599745, 32, [20, 60, 21, 51, 65]), (11, 0.802, 0.7949, 0.0013487660210729387, 0.0003777289675186337, 38, [20, 20, 20, 20, 20]), (11, 0.802, 0.7949, 0.00010901957006727402, 0.00042006567103996894, 30, [20, 69, 40, 75, 70]), (11, 0.802, 0.7949, 5.482803714400627e-05, 0.000417282978447841, 27, [29, 56, 43, 77, 79]), (11, 0.802, 0.7949, 0.00010901957006727402, 0.00042006567103996894, 30, [20, 69, 40, 75, 70]), (11, 0.802, 0.7949, 0.0013487660210729387, 0.0003777289675186337, 38, [20, 20, 20, 20, 20]), (11, 0.797, 0.7898, 0.0001380470703900086, 0.00040135080507792064, 24, [20, 28, 21, 71, 67]), (11, 0.797, 0.7898, 0.0001380470703900086, 0.00040135080507792064, 24, [20, 28, 21, 71, 67]), (11, 0.797, 0.7898, 0.0013487660210729387, 0.0003777289675186337, 38, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8324873096446701 ####\n",
      "Generation 11: 119.8 s, best val metric 0.8325, [(12, 0.8325, 0.8192, 0.000830095400302582, 0.0003642806091006724, 25, [20, 20, 20, 23, 21]), (12, 0.8325, 0.8192, 0.0013487660210729387, 0.0003777289675186337, 38, [20, 20, 21, 36, 21]), (12, 0.8122, 0.7992, 0.00047721740827719373, 0.0004229875225205085, 32, [20, 20, 20, 21, 21]), (12, 0.802, 0.7892, 0.0013487660210729387, 0.0003777289675186337, 38, [20, 20, 20, 20, 20]), (12, 0.797, 0.7842, 0.0013487660210729387, 0.0003777289675186337, 38, [20, 20, 19, 20, 20]), (12, 0.797, 0.7842, 0.00012065719951395537, 0.0003644848040918605, 28, [20, 47, 20, 50, 69]), (12, 0.797, 0.7842, 0.0013487660210729387, 0.0003777289675186337, 38, [20, 20, 19, 20, 20]), (12, 0.797, 0.7842, 0.0013487660210729387, 0.0003777289675186337, 38, [20, 20, 19, 20, 20]), (12, 0.797, 0.7842, 0.00012065719951395537, 0.0003644848040918605, 28, [20, 47, 20, 50, 69]), (12, 0.797, 0.7842, 0.0013487660210729387, 0.0003777289675186337, 38, [20, 20, 19, 20, 20]), (12, 0.797, 0.7842, 0.00032893654453796886, 0.00034902937411829347, 28, [20, 22, 20, 28, 34])]\n",
      "#### Overall best val metric 0.8324873096446701 ####\n",
      "Generation 12: 103.2 s, best val metric 0.8325, [(13, 0.8325, 0.8089, 0.000830095400302582, 0.0003642806091006724, 25, [20, 20, 20, 23, 21]), (13, 0.8274, 0.804, 0.0013487660210729387, 0.0003777289675186337, 38, [20, 19, 16, 19, 20]), (13, 0.8274, 0.804, 0.0013487660210729387, 0.0003777289675186337, 38, [20, 20, 20, 20, 21]), (13, 0.8274, 0.804, 0.0013487660210729387, 0.0003777289675186337, 38, [20, 20, 20, 20, 21]), (13, 0.8274, 0.804, 0.0013487660210729387, 0.0003777289675186337, 38, [20, 19, 16, 19, 20]), (13, 0.8274, 0.804, 0.0013487660210729387, 0.0003777289675186337, 38, [20, 20, 20, 20, 21]), (13, 0.8274, 0.804, 0.0013487660210729387, 0.0003777289675186337, 38, [20, 20, 20, 20, 21]), (13, 0.8274, 0.804, 0.0013487660210729387, 0.0003777289675186337, 38, [20, 20, 20, 20, 21]), (13, 0.8071, 0.7842, 0.0006652089523784036, 0.0004321815815642918, 29, [20, 23, 20, 22, 25]), (13, 0.8071, 0.7842, 0.00014743696549677585, 0.0003938753863913403, 41, [20, 26, 19, 40, 40]), (13, 0.797, 0.7744, 0.000830095400302582, 0.0003642806091006724, 25, [20, 20, 20, 21, 21])]\n",
      "#### Overall best val metric 0.8324873096446701 ####\n",
      "Generation 13: 125.4 s, best val metric 0.8325, [(14, 0.8325, 0.791, 0.000830095400302582, 0.0003642806091006724, 25, [20, 20, 20, 23, 21]), (14, 0.8274, 0.7861, 0.00014743696549677585, 0.0003938753863913403, 41, [20, 27, 18, 54, 56]), (14, 0.8274, 0.7861, 0.00014743696549677585, 0.0003938753863913403, 41, [20, 27, 18, 54, 56]), (14, 0.8274, 0.7861, 0.00014743696549677585, 0.0003938753863913403, 41, [20, 27, 18, 54, 56]), (14, 0.8223, 0.7813, 0.0005917626487576497, 0.00035691869848932927, 38, [20, 20, 20, 20, 25]), (14, 0.8223, 0.7813, 0.0005917626487576497, 0.00035691869848932927, 38, [20, 20, 20, 20, 25]), (14, 0.8071, 0.7669, 0.0003620592528509373, 0.0003535616924997687, 35, [20, 20, 20, 20, 25]), (14, 0.8071, 0.7669, 0.0005097011925891965, 0.00038241129112964376, 37, [20, 20, 17, 32, 39]), (14, 0.7919, 0.7524, 0.000468708932510933, 0.00040629833740997456, 30, [20, 20, 20, 20, 23]), (14, 0.7868, 0.7476, 0.0013487660210729387, 0.0003777289675186337, 38, [20, 20, 19, 20, 20]), (14, 0.7868, 0.7476, 0.0013487660210729387, 0.0003777289675186337, 38, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8324873096446701 ####\n",
      "Generation 14: 123.1 s, best val metric 0.8325, [(15, 0.8325, 0.7606, 0.000830095400302582, 0.0003642806091006724, 25, [20, 20, 20, 23, 21]), (15, 0.8274, 0.756, 0.00014743696549677585, 0.0003938753863913403, 41, [20, 39, 20, 61, 69]), (15, 0.8274, 0.756, 0.00014743696549677585, 0.0003938753863913403, 41, [20, 39, 20, 61, 69]), (15, 0.8274, 0.756, 0.00014743696549677585, 0.0003938753863913403, 41, [20, 39, 20, 61, 69]), (15, 0.8223, 0.7513, 0.00047545504509589756, 0.0003614665692639179, 32, [20, 18, 15, 19, 38]), (15, 0.8223, 0.7513, 0.00014743696549677585, 0.0003938753863913403, 41, [20, 33, 18, 51, 65]), (15, 0.8173, 0.7467, 0.00014743696549677585, 0.0003938753863913403, 41, [20, 36, 18, 62, 65]), (15, 0.8173, 0.7467, 0.0002214352356277084, 0.0003496377229987791, 34, [20, 22, 20, 22, 35]), (15, 0.8122, 0.7421, 0.00015765055696390122, 0.0004005968422056705, 38, [20, 22, 21, 39, 42]), (15, 0.8122, 0.7421, 0.00015765055696390122, 0.0004005968422056705, 38, [20, 22, 21, 39, 42]), (15, 0.802, 0.7328, 0.000468708932510933, 0.00040629833740997456, 30, [20, 20, 18, 20, 25])]\n",
      "#### Overall best val metric 0.8324873096446701 ####\n",
      "Generation 15: 105.1 s, best val metric 0.8325, [(16, 0.8325, 0.7115, 0.000830095400302582, 0.0003642806091006724, 25, [20, 20, 20, 23, 21]), (16, 0.8223, 0.7028, 0.0001781494638764352, 0.0004252318884678662, 31, [20, 42, 19, 55, 72]), (16, 0.8223, 0.7028, 0.0001781494638764352, 0.0004252318884678662, 31, [20, 42, 19, 55, 72]), (16, 0.8173, 0.6985, 0.00015765055696390122, 0.0004005968422056705, 38, [21, 30, 22, 58, 55]), (16, 0.8173, 0.6985, 0.00015765055696390122, 0.0004005968422056705, 38, [21, 30, 22, 58, 55]), (16, 0.8122, 0.6941, 0.00014743696549677585, 0.0003938753863913403, 41, [20, 47, 26, 71, 76]), (16, 0.8122, 0.6941, 0.00014743696549677585, 0.0003938753863913403, 41, [20, 47, 26, 71, 76]), (16, 0.8122, 0.6941, 0.00014743696549677585, 0.0003938753863913403, 41, [20, 47, 26, 71, 76]), (16, 0.8122, 0.6941, 0.00014743696549677585, 0.0003938753863913403, 41, [20, 45, 21, 59, 83]), (16, 0.8071, 0.6898, 0.0002214352356277084, 0.0003496377229987791, 34, [20, 27, 20, 20, 40]), (16, 0.7919, 0.6768, 0.0017867390739248455, 0.00038717866969810883, 31, [20, 17, 14, 19, 20])]\n",
      "#### Overall best val metric 0.8324873096446701 ####\n",
      "Generation 16: 130.8 s, best val metric 0.8325, [(1, 0.7005, 0.7005, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.7005, 0.7005, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.7005, 0.7005, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (17, 0.8325, 0.6374, 4.584788021793706e-05, 0.00037809762986462566, 38, [20, 50, 42, 78, 75]), (17, 0.8325, 0.6374, 0.000830095400302582, 0.0003642806091006724, 25, [20, 20, 20, 23, 21]), (17, 0.8173, 0.6257, 0.00014743696549677585, 0.0003938753863913403, 41, [20, 43, 25, 60, 83]), (17, 0.8173, 0.6257, 0.00014743696549677585, 0.0003938753863913403, 41, [20, 52, 26, 72, 89]), (17, 0.8173, 0.6257, 0.00014743696549677585, 0.0003938753863913403, 41, [20, 52, 26, 72, 89]), (17, 0.8173, 0.6257, 0.00014743696549677585, 0.0003938753863913403, 41, [20, 52, 26, 72, 89]), (17, 0.8071, 0.6179, 3.1622776601683795e-05, 0.00040835408711652194, 40, [36, 62, 39, 75, 92]), (17, 0.802, 0.6141, 0.0007723616366709623, 0.000397114845854364, 36, [20, 23, 16, 27, 39])]\n",
      "#### Overall best val metric 0.8324873096446701 ####\n",
      "Generation 17: 111.7 s, best val metric 0.8173, [(2, 0.7563, 0.7563, 0.0025773704709051676, 0.0003931990805671457, 30, [20, 20, 20, 20, 20]), (2, 0.7563, 0.7563, 0.0025773704709051676, 0.0003931990805671457, 30, [20, 20, 20, 20, 20]), (2, 0.7513, 0.7513, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7513, 0.7513, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7462, 0.7462, 8.864979968261956e-05, 0.0003935974300191432, 35, [20, 20, 20, 23, 32]), (2, 0.7462, 0.7462, 8.864979968261956e-05, 0.0003935974300191432, 35, [20, 20, 20, 23, 32]), (2, 0.7462, 0.7462, 8.864979968261956e-05, 0.0003935974300191432, 35, [20, 20, 20, 23, 32]), (2, 0.7259, 0.7259, 9.214875834008407e-05, 0.0003838799487466173, 39, [20, 20, 20, 20, 25]), (2, 0.7005, 0.7005, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (18, 0.8173, 0.5269, 0.00028408404687923925, 0.0003681377685752186, 38, [20, 25, 17, 35, 58]), (18, 0.8122, 0.5237, 0.0004322779245871807, 0.00039324356947353846, 38, [20, 27, 20, 60, 39])]\n",
      "#### Overall best val metric 0.8324873096446701 ####\n",
      "Generation 18: 95.3 s, best val metric 0.7817, [(3, 0.7817, 0.7817, 0.00026992936563797706, 0.00040650241762341615, 33, [20, 20, 20, 20, 20]), (3, 0.7817, 0.7817, 0.0002871725348095922, 0.0004050260570814902, 30, [20, 20, 20, 20, 20]), (3, 0.7817, 0.7817, 0.0002871725348095922, 0.0004050260570814902, 30, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 4.128674540158153e-05, 0.0004080113393447036, 34, [20, 39, 26, 43, 51]), (3, 0.7716, 0.7716, 4.128674540158153e-05, 0.0004080113393447036, 34, [20, 39, 26, 43, 51]), (3, 0.7665, 0.7665, 8.864979968261956e-05, 0.0003935974300191432, 35, [20, 21, 20, 27, 50]), (3, 0.7614, 0.7614, 4.688975553269153e-05, 0.0004017773677155216, 36, [20, 38, 27, 40, 45]), (3, 0.7614, 0.7614, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (3, 0.7563, 0.7563, 0.0002621695415003147, 0.0003905175084911424, 39, [20, 20, 20, 21, 23]), (3, 0.7563, 0.7563, 0.0002621695415003147, 0.0003905175084911424, 39, [20, 20, 20, 21, 23]), (3, 0.7563, 0.7563, 0.0025773704709051676, 0.0003931990805671457, 30, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8324873096446701 ####\n",
      "Generation 19: 94.9 s, best val metric 0.8122, [(4, 0.8122, 0.8122, 0.0002871725348095922, 0.0004050260570814902, 30, [20, 20, 20, 20, 22]), (4, 0.8122, 0.8122, 0.0002871725348095922, 0.0004050260570814902, 30, [20, 20, 20, 20, 22]), (4, 0.797, 0.797, 3.1622776601683795e-05, 0.00039905210921612285, 26, [21, 40, 39, 40, 40]), (4, 0.7868, 0.7868, 0.0006393489630156378, 0.00042274468452476507, 33, [20, 20, 20, 20, 20]), (4, 0.7868, 0.7868, 0.0006393489630156378, 0.00042274468452476507, 33, [20, 20, 20, 20, 20]), (4, 0.7868, 0.7868, 0.0006393489630156378, 0.00042274468452476507, 33, [20, 20, 20, 20, 20]), (4, 0.7817, 0.7817, 0.0002713807471447471, 0.00043217104707161046, 31, [20, 20, 20, 24, 31]), (4, 0.7817, 0.7817, 0.00026992936563797706, 0.00040650241762341615, 33, [20, 20, 20, 20, 20]), (4, 0.7665, 0.7665, 0.00044867712836423284, 0.00037417740356624613, 44, [20, 20, 20, 20, 20]), (4, 0.7563, 0.7563, 4.061975284855681e-05, 0.0003713076800791542, 29, [20, 36, 33, 40, 40]), (4, 0.7462, 0.7462, 6.910862085332432e-05, 0.00040434823620395766, 35, [20, 32, 20, 40, 40])]\n",
      "#### Overall best val metric 0.8324873096446701 ####\n",
      "Generation 20: 77.1 s, best val metric 0.8122, [(5, 0.8122, 0.8122, 0.0002871725348095922, 0.0004050260570814902, 30, [20, 20, 20, 20, 22]), (5, 0.7919, 0.7919, 0.0002871725348095922, 0.0004050260570814902, 30, [20, 20, 20, 20, 20]), (5, 0.7919, 0.7919, 0.0002871725348095922, 0.0004050260570814902, 30, [20, 20, 20, 20, 20]), (5, 0.7817, 0.7817, 0.0006393489630156378, 0.00042274468452476507, 33, [20, 20, 20, 20, 20]), (5, 0.7817, 0.7817, 0.0002742601502367667, 0.0004289211042735855, 28, [20, 20, 20, 20, 25]), (5, 0.7817, 0.7817, 0.00014465494834986232, 0.0004591182758854381, 33, [20, 20, 20, 22, 36]), (5, 0.7817, 0.7817, 0.00012095951026573271, 0.0004145313631959519, 31, [20, 28, 21, 41, 44]), (5, 0.7817, 0.7817, 6.910862085332432e-05, 0.00040434823620395766, 35, [20, 35, 21, 51, 46]), (5, 0.7766, 0.7766, 0.0001706915325105404, 0.0003571254122423446, 28, [20, 20, 20, 20, 24]), (5, 0.7665, 0.7665, 6.777487967344969e-05, 0.0004110044413139622, 32, [20, 36, 20, 43, 44]), (5, 0.7563, 0.7563, 0.0002713807471447471, 0.00043217104707161046, 31, [20, 20, 20, 21, 32])]\n",
      "#### Overall best val metric 0.8324873096446701 ####\n",
      "Generation 21: 77.7 s, best val metric 0.8122, [(6, 0.8122, 0.8122, 0.0002871725348095922, 0.0004050260570814902, 30, [20, 20, 20, 20, 22]), (6, 0.802, 0.802, 0.0001135915617401715, 0.00042177097497689324, 30, [20, 27, 20, 36, 48]), (6, 0.802, 0.802, 0.0002871725348095922, 0.0004050260570814902, 30, [20, 20, 20, 20, 23]), (6, 0.7919, 0.7919, 0.00037149884534571655, 0.00039688622599515195, 26, [20, 20, 20, 20, 20]), (6, 0.7919, 0.7919, 0.00012147492968245486, 0.0003966142135182498, 34, [20, 22, 20, 31, 38]), (6, 0.7919, 0.7919, 0.00012147492968245486, 0.0003966142135182498, 34, [20, 22, 20, 31, 38]), (6, 0.7919, 0.7919, 0.00012147492968245486, 0.0003966142135182498, 34, [20, 22, 20, 31, 38]), (6, 0.7919, 0.7919, 0.00037149884534571655, 0.00039688622599515195, 26, [20, 20, 20, 20, 20]), (6, 0.7868, 0.7868, 0.0002196602867912846, 0.0004179116523658072, 30, [20, 20, 20, 20, 25]), (6, 0.7868, 0.7868, 0.0002196602867912846, 0.0004179116523658072, 30, [20, 20, 20, 20, 25]), (6, 0.7766, 0.7766, 0.0001596624076666676, 0.0003854089978625328, 29, [20, 20, 20, 20, 34])]\n",
      "#### Overall best val metric 0.8324873096446701 ####\n",
      "Generation 22: 75.2 s, best val metric 0.8122, [(7, 0.8122, 0.8122, 0.0002871725348095922, 0.0004050260570814902, 30, [20, 20, 20, 20, 22]), (7, 0.8071, 0.8071, 0.0002871725348095922, 0.0004050260570814902, 30, [20, 20, 20, 20, 24]), (7, 0.8071, 0.8071, 0.0002196602867912846, 0.0004179116523658072, 30, [20, 20, 20, 20, 27]), (7, 0.797, 0.797, 0.0001135915617401715, 0.00042177097497689324, 30, [20, 28, 20, 38, 55]), (7, 0.7919, 0.7919, 0.0002223410428416839, 0.00037949071803821234, 33, [20, 20, 20, 20, 36]), (7, 0.7919, 0.7919, 0.0001596624076666676, 0.0003854089978625328, 29, [20, 20, 20, 20, 37]), (7, 0.7919, 0.7919, 7.409824777865898e-05, 0.00042076553936771176, 27, [20, 36, 20, 50, 51]), (7, 0.7868, 0.7868, 0.00022185471015513796, 0.0004005818902744811, 34, [20, 20, 20, 20, 23]), (7, 0.7868, 0.7868, 0.0002196602867912846, 0.0004179116523658072, 30, [20, 20, 20, 20, 34]), (7, 0.7868, 0.7868, 0.00022185471015513796, 0.0004005818902744811, 34, [20, 20, 20, 20, 23]), (7, 0.7868, 0.7868, 0.00022185471015513796, 0.0004005818902744811, 34, [20, 20, 20, 20, 23])]\n",
      "#### Overall best val metric 0.8324873096446701 ####\n",
      "Generation 23: 83.5 s, best val metric 0.8173, [(8, 0.8173, 0.8173, 0.0002196602867912846, 0.0004179116523658072, 30, [20, 20, 20, 20, 39]), (8, 0.8122, 0.8122, 0.0002871725348095922, 0.0004050260570814902, 30, [20, 20, 20, 20, 22]), (8, 0.8071, 0.8071, 0.0003436278559033422, 0.00039858830601397025, 31, [20, 20, 20, 20, 27]), (8, 0.8071, 0.8071, 0.0003436278559033422, 0.00039858830601397025, 31, [20, 20, 20, 20, 27]), (8, 0.8071, 0.8071, 0.0003436278559033422, 0.00039858830601397025, 31, [20, 20, 20, 20, 27]), (8, 0.802, 0.802, 0.0001596624076666676, 0.0003854089978625328, 29, [20, 20, 20, 25, 37]), (8, 0.802, 0.802, 0.00022185471015513796, 0.0004005818902744811, 34, [20, 20, 20, 20, 32]), (8, 0.797, 0.797, 0.0002223410428416839, 0.00037949071803821234, 33, [20, 20, 20, 20, 42]), (8, 0.797, 0.797, 0.0002223410428416839, 0.00037949071803821234, 33, [20, 20, 20, 20, 42]), (8, 0.7817, 0.7817, 0.0003290924722297736, 0.00041776256074020597, 30, [20, 20, 20, 20, 32]), (8, 0.7817, 0.7817, 0.00037612195180335514, 0.00039576769997678746, 34, [20, 20, 20, 23, 39])]\n",
      "#### Overall best val metric 0.8324873096446701 ####\n",
      "Generation 24: 117.8 s, best val metric 0.8173, [(9, 0.8173, 0.8173, 0.00010907956654119754, 0.0003656112117067137, 25, [20, 20, 20, 28, 48]), (9, 0.8173, 0.8173, 0.00010907956654119754, 0.0003656112117067137, 25, [20, 20, 20, 28, 48]), (9, 0.8173, 0.8173, 0.0002196602867912846, 0.0004179116523658072, 30, [20, 20, 20, 20, 39]), (9, 0.8122, 0.8122, 0.0003436278559033422, 0.00039858830601397025, 31, [20, 20, 20, 20, 23]), (9, 0.8071, 0.8071, 4.7505098046337596e-05, 0.0004172015938219185, 31, [21, 40, 40, 40, 47]), (9, 0.8071, 0.8071, 4.7505098046337596e-05, 0.0004172015938219185, 31, [21, 40, 40, 40, 47]), (9, 0.802, 0.802, 0.0002196602867912846, 0.0004179116523658072, 30, [20, 20, 20, 20, 46]), (9, 0.797, 0.797, 0.0001441412597404274, 0.00039619049373247075, 26, [20, 20, 20, 26, 51]), (9, 0.797, 0.797, 0.0001596624076666676, 0.0003854089978625328, 29, [20, 20, 20, 24, 42]), (9, 0.797, 0.797, 0.0001441412597404274, 0.00039619049373247075, 26, [20, 20, 20, 26, 51]), (9, 0.7766, 0.7766, 0.0003436278559033422, 0.00039858830601397025, 31, [20, 20, 20, 20, 26])]\n",
      "#### Overall best val metric 0.8324873096446701 ####\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "evolution = Evolution()\n",
    "hyperparameters = {\n",
    "    'regularization_penalty': Hyperparameter(3., 2.5, 4.5, 0.5),\n",
    "    'learning_rate': Hyperparameter(0.0004, 0.0001, 0.0006, 0.000025),\n",
    "    'batch_size': Hyperparameter(32, 16, 64, 4),\n",
    "}\n",
    "evolution.run(x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test),\n",
    "              layer_sizes=[20, 20, 20, 20, 20], output_neurons=10, hyperparameters=hyperparameters, n_parents=5, population_size=10, \n",
    "              n_generations=50, tournament_size=3, n_introduced=2, age_penalty_period=10, use_static_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1f58eb1400>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 244,
       "width": 366
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [0] + [result.time for result in evolution.results]\n",
    "x += [x[-1] + (x[-1] - x[-2]) / 10]\n",
    "y = [0, 0] + [result.best_val_metric for result in evolution.results]\n",
    "plt.step(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: 98.1 s, best val metric 0.7056, [(1, 0.7056, 0.7056, 0.0003386718979544792, 0.0004069589784912005, 33, [20, 20, 20, 20, 20]), (1, 0.7056, 0.7056, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.7056, 0.7056, 0.0003386718979544792, 0.0004069589784912005, 33, [20, 20, 20, 20, 20]), (1, 0.6954, 0.6954, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6853, 0.6853, 0.002155935950363182, 0.0003569042308518582, 28, [20, 20, 20, 20, 20]), (1, 0.6802, 0.6802, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6751, 0.6751, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6751, 0.6751, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6701, 0.6701, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6701, 0.6701, 0.001, 0.0004, 32, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.7055837563451777 ####\n",
      "Generation 1: 85.4 s, best val metric 0.7716, [(2, 0.7716, 0.7716, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7716, 0.7716, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7716, 0.7716, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7614, 0.7614, 0.00010394596491511754, 0.00039330390572459007, 27, [20, 20, 20, 23, 26]), (2, 0.7513, 0.7513, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7513, 0.7513, 0.0003687261130788958, 0.00037196666986931713, 34, [20, 20, 20, 20, 20]), (2, 0.7513, 0.7513, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7462, 0.7462, 0.0003386718979544792, 0.0004069589784912005, 33, [20, 20, 20, 20, 20]), (2, 0.7462, 0.7462, 0.0003386718979544792, 0.0004069589784912005, 33, [20, 20, 20, 20, 20]), (2, 0.7411, 0.7411, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7056, 0.7056, 0.0003386718979544792, 0.0004069589784912005, 33, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.7715736040609137 ####\n",
      "Generation 2: 107.9 s, best val metric 0.802, [(3, 0.802, 0.802, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (3, 0.797, 0.797, 0.0003386718979544792, 0.0004069589784912005, 33, [20, 20, 20, 20, 20]), (3, 0.797, 0.797, 0.0003386718979544792, 0.0004069589784912005, 33, [20, 20, 20, 20, 20]), (3, 0.7868, 0.7868, 0.00013981031191582157, 0.00043755591514781404, 30, [20, 20, 20, 21, 28]), (3, 0.7868, 0.7868, 0.00010394596491511754, 0.00039330390572459007, 27, [20, 20, 20, 23, 35]), (3, 0.7817, 0.7817, 4.312282105872232e-05, 0.00045535827030393744, 35, [20, 40, 35, 40, 40]), (3, 0.7817, 0.7817, 0.0003674684010482604, 0.00038072038966624597, 31, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (3, 0.7665, 0.7665, 0.0006675197410126248, 0.00037460060848011314, 30, [20, 20, 20, 20, 20]), (3, 0.7665, 0.7665, 0.0006675197410126248, 0.00037460060848011314, 30, [20, 20, 20, 20, 20]), (3, 0.7462, 0.7462, 0.0031622776601683794, 0.00038604095304192536, 31, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8020304568527918 ####\n",
      "Generation 3: 95.5 s, best val metric 0.8071, [(4, 0.8071, 0.8071, 0.0006675197410126248, 0.00037460060848011314, 30, [20, 20, 20, 20, 20]), (4, 0.8071, 0.8071, 0.0006675197410126248, 0.00037460060848011314, 30, [20, 20, 20, 20, 20]), (4, 0.802, 0.802, 0.00013981031191582157, 0.00043755591514781404, 30, [20, 20, 20, 20, 29]), (4, 0.802, 0.802, 0.00013981031191582157, 0.00043755591514781404, 30, [20, 20, 20, 20, 29]), (4, 0.802, 0.802, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (4, 0.797, 0.797, 0.0005622775466845562, 0.00043183794992341013, 34, [20, 20, 20, 20, 20]), (4, 0.797, 0.797, 0.001375263811406781, 0.00041781470364536585, 34, [20, 20, 20, 20, 20]), (4, 0.7919, 0.7919, 9.944693438847843e-05, 0.0004226742964080081, 33, [20, 20, 20, 36, 39]), (4, 0.7919, 0.7919, 4.312282105872232e-05, 0.00045535827030393744, 35, [32, 60, 48, 60, 58]), (4, 0.7919, 0.7919, 0.00014785725911315378, 0.00037515772797960616, 35, [20, 20, 20, 20, 20]), (4, 0.7919, 0.7919, 4.312282105872232e-05, 0.00045535827030393744, 35, [32, 60, 48, 60, 58])]\n",
      "#### Overall best val metric 0.8071065989847716 ####\n",
      "Generation 4: 117.0 s, best val metric 0.8376, [(5, 0.8376, 0.8376, 0.0006675197410126248, 0.00037460060848011314, 30, [20, 20, 20, 20, 20]), (5, 0.8325, 0.8325, 7.104633485132242e-05, 0.0003886732644372665, 31, [20, 39, 21, 40, 39]), (5, 0.8274, 0.8274, 0.000138309018925668, 0.00041549329359241206, 34, [20, 20, 20, 28, 33]), (5, 0.8223, 0.8223, 7.22893384080714e-05, 0.0004243757707082078, 35, [20, 38, 21, 51, 51]), (5, 0.8223, 0.8223, 7.22893384080714e-05, 0.0004243757707082078, 35, [20, 38, 21, 51, 51]), (5, 0.8223, 0.8223, 7.22893384080714e-05, 0.0004243757707082078, 35, [20, 38, 21, 51, 51]), (5, 0.8173, 0.8173, 4.312282105872232e-05, 0.00045535827030393744, 35, [32, 78, 58, 80, 77]), (5, 0.8173, 0.8173, 4.312282105872232e-05, 0.00045535827030393744, 35, [32, 78, 58, 80, 77]), (5, 0.8173, 0.8173, 4.312282105872232e-05, 0.00045535827030393744, 35, [32, 78, 58, 80, 77]), (5, 0.8071, 0.8071, 0.0006675197410126248, 0.00037460060848011314, 30, [20, 20, 20, 20, 20]), (5, 0.7817, 0.7817, 0.001, 0.0004, 32, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8375634517766497 ####\n",
      "Generation 5: 137.0 s, best val metric 0.8376, [(6, 0.8376, 0.8376, 0.0006675197410126248, 0.00037460060848011314, 30, [20, 20, 20, 20, 20]), (6, 0.8122, 0.8122, 0.0006675197410126248, 0.00037460060848011314, 30, [20, 20, 20, 20, 20]), (6, 0.8122, 0.8122, 4.312282105872232e-05, 0.00045535827030393744, 35, [31, 93, 60, 100, 94]), (6, 0.8122, 0.8122, 4.312282105872232e-05, 0.00045535827030393744, 35, [31, 93, 60, 100, 94]), (6, 0.8122, 0.8122, 4.312282105872232e-05, 0.00045535827030393744, 35, [31, 93, 60, 100, 94]), (6, 0.802, 0.802, 7.22893384080714e-05, 0.0004243757707082078, 35, [20, 46, 22, 68, 63]), (6, 0.802, 0.802, 0.00023370978835923732, 0.0004389533705374429, 34, [20, 30, 23, 69, 43]), (6, 0.797, 0.797, 0.00040444641588102746, 0.00042509510314329247, 30, [20, 20, 20, 36, 48]), (6, 0.7919, 0.7919, 0.0002842264317923083, 0.0004625090841654614, 32, [20, 20, 20, 23, 26]), (6, 0.7919, 0.7919, 0.0006675197410126248, 0.00037460060848011314, 30, [20, 20, 20, 20, 20]), (6, 0.7919, 0.7919, 0.0002842264317923083, 0.0004625090841654614, 32, [20, 20, 20, 23, 26])]\n",
      "#### Overall best val metric 0.8375634517766497 ####\n",
      "Generation 6: 151.9 s, best val metric 0.8376, [(7, 0.8376, 0.8376, 0.0006675197410126248, 0.00037460060848011314, 30, [20, 20, 20, 20, 20]), (7, 0.8325, 0.8325, 0.0003043047830523966, 0.0003961299680630675, 39, [20, 23, 20, 40, 32]), (7, 0.8325, 0.8325, 0.0003043047830523966, 0.0003961299680630675, 39, [20, 23, 20, 40, 32]), (7, 0.8325, 0.8325, 0.0003043047830523966, 0.0003961299680630675, 39, [20, 23, 20, 40, 32]), (7, 0.8325, 0.8325, 0.0003043047830523966, 0.0003961299680630675, 39, [20, 23, 20, 40, 32]), (7, 0.8274, 0.8274, 7.22893384080714e-05, 0.0004243757707082078, 35, [20, 53, 30, 85, 65]), (7, 0.8223, 0.8223, 0.0006675197410126248, 0.00037460060848011314, 30, [20, 20, 20, 20, 20]), (7, 0.8173, 0.8173, 4.312282105872232e-05, 0.00045535827030393744, 35, [33, 112, 70, 120, 108]), (7, 0.8071, 0.8071, 5.19505025819731e-05, 0.00046622510102114817, 35, [20, 39, 39, 43, 46]), (7, 0.8071, 0.8071, 9.475180274171945e-05, 0.0003945843644713639, 38, [20, 24, 20, 39, 40]), (7, 0.797, 0.797, 0.00019096114620261958, 0.00040222831134812515, 34, [20, 20, 20, 34, 26])]\n",
      "#### Overall best val metric 0.8375634517766497 ####\n",
      "Generation 7: 86.8 s, best val metric 0.8376, [(8, 0.8376, 0.8376, 0.0006675197410126248, 0.00037460060848011314, 30, [20, 20, 20, 20, 20]), (8, 0.8274, 0.8274, 5.19505025819731e-05, 0.00046622510102114817, 35, [33, 59, 59, 63, 65]), (8, 0.8274, 0.8274, 5.19505025819731e-05, 0.00046622510102114817, 35, [33, 59, 59, 63, 65]), (8, 0.8274, 0.8274, 5.19505025819731e-05, 0.00046622510102114817, 35, [33, 59, 59, 63, 65]), (8, 0.8223, 0.8223, 0.00020419976700915775, 0.0004724179427726749, 38, [21, 48, 25, 78, 60]), (8, 0.8223, 0.8223, 0.00052620121335892, 0.0004121234973647935, 30, [20, 20, 20, 21, 21]), (8, 0.8173, 0.8173, 0.00014389044228216592, 0.000347053993852, 32, [20, 31, 22, 45, 44]), (8, 0.8173, 0.8173, 0.00014389044228216592, 0.000347053993852, 32, [20, 31, 22, 45, 44]), (8, 0.8122, 0.8122, 9.475180274171945e-05, 0.0003945843644713639, 38, [20, 28, 20, 57, 54]), (8, 0.8071, 0.8071, 9.659903086790269e-05, 0.00038455000387628324, 30, [20, 30, 21, 58, 48]), (8, 0.797, 0.797, 0.00019096114620261958, 0.00040222831134812515, 34, [20, 20, 20, 36, 30])]\n",
      "#### Overall best val metric 0.8375634517766497 ####\n",
      "Generation 8: 92.6 s, best val metric 0.8426, [(9, 0.8426, 0.8426, 9.475180274171945e-05, 0.0003945843644713639, 38, [20, 28, 20, 65, 54]), (9, 0.8426, 0.8426, 9.475180274171945e-05, 0.0003945843644713639, 38, [20, 28, 20, 65, 54]), (9, 0.8426, 0.8426, 9.475180274171945e-05, 0.0003945843644713639, 38, [20, 28, 20, 65, 54]), (9, 0.8426, 0.8426, 9.475180274171945e-05, 0.0003945843644713639, 38, [20, 28, 20, 65, 54]), (9, 0.8376, 0.8376, 0.0006675197410126248, 0.00037460060848011314, 30, [20, 20, 20, 20, 20]), (9, 0.8274, 0.8274, 5.19505025819731e-05, 0.00046622510102114817, 35, [28, 77, 74, 83, 85]), (9, 0.8274, 0.8274, 5.19505025819731e-05, 0.00046622510102114817, 35, [28, 77, 74, 83, 85]), (9, 0.8223, 0.8223, 0.0001339753312794209, 0.00042957391904128604, 36, [21, 34, 31, 64, 61]), (9, 0.8122, 0.8122, 0.00019939923847872348, 0.00037297992719485167, 33, [20, 20, 20, 35, 26]), (9, 0.8071, 0.8071, 0.0006675197410126248, 0.00037460060848011314, 30, [20, 20, 20, 20, 20]), (9, 0.797, 0.797, 3.2145103254730366e-05, 0.0003773221239343942, 35, [30, 48, 40, 77, 74])]\n",
      "#### Overall best val metric 0.8426395939086294 ####\n",
      "Generation 9: 95.0 s, best val metric 0.8426, [(10, 0.8426, 0.8426, 9.475180274171945e-05, 0.0003945843644713639, 38, [20, 28, 20, 65, 54]), (10, 0.8325, 0.8325, 0.00023750060102930857, 0.0003835709463089187, 32, [20, 21, 20, 40, 41]), (10, 0.8325, 0.8325, 0.00023750060102930857, 0.0003835709463089187, 32, [20, 21, 20, 40, 41]), (10, 0.8325, 0.8325, 8.951094004621359e-05, 0.00041817408373786766, 41, [20, 20, 20, 40, 40]), (10, 0.8325, 0.8325, 8.951094004621359e-05, 0.00041817408373786766, 41, [20, 20, 20, 40, 40]), (10, 0.8223, 0.8223, 9.475180274171945e-05, 0.0003945843644713639, 38, [20, 33, 21, 80, 65]), (10, 0.8223, 0.8223, 9.475180274171945e-05, 0.0003945843644713639, 38, [20, 33, 21, 80, 65]), (10, 0.8223, 0.8223, 9.475180274171945e-05, 0.0003945843644713639, 38, [20, 33, 21, 80, 65]), (10, 0.8173, 0.8173, 3.1622776601683795e-05, 0.00038709342213525067, 29, [27, 40, 40, 55, 46]), (10, 0.802, 0.802, 7.495260694427889e-05, 0.00045959272947949237, 32, [20, 40, 40, 40, 40]), (10, 0.802, 0.802, 9.475180274171945e-05, 0.0003945843644713639, 38, [20, 43, 21, 73, 58])]\n",
      "#### Overall best val metric 0.8426395939086294 ####\n",
      "Generation 10: 85.9 s, best val metric 0.8426, [(11, 0.8426, 0.8351, 9.475180274171945e-05, 0.0003945843644713639, 38, [20, 28, 20, 65, 54]), (11, 0.8325, 0.8251, 8.627125268547663e-05, 0.0004005969561047893, 33, [20, 52, 30, 98, 76]), (11, 0.8325, 0.8251, 8.951094004621359e-05, 0.00041817408373786766, 41, [20, 25, 23, 57, 54]), (11, 0.8274, 0.82, 0.0001944805616425323, 0.0003642960753859931, 35, [20, 20, 20, 34, 42]), (11, 0.8223, 0.815, 0.00023750060102930857, 0.0003835709463089187, 32, [20, 20, 20, 29, 40]), (11, 0.8223, 0.815, 0.00023750060102930857, 0.0003835709463089187, 32, [20, 20, 20, 29, 40]), (11, 0.8223, 0.815, 0.00023750060102930857, 0.0003835709463089187, 32, [20, 20, 20, 29, 40]), (11, 0.8223, 0.815, 0.00023750060102930857, 0.0003835709463089187, 32, [20, 20, 20, 29, 40]), (11, 0.8223, 0.815, 0.00023750060102930857, 0.0003835709463089187, 32, [20, 20, 20, 29, 40]), (11, 0.8173, 0.81, 6.819660906146932e-05, 0.0003849267174374958, 36, [22, 44, 41, 69, 63]), (11, 0.7919, 0.7848, 0.00022393326641448704, 0.00040433451476014413, 26, [20, 25, 20, 40, 51])]\n",
      "#### Overall best val metric 0.8426395939086294 ####\n",
      "Generation 11: 81.7 s, best val metric 0.8426, [(12, 0.8426, 0.8292, 9.475180274171945e-05, 0.0003945843644713639, 38, [20, 28, 20, 65, 54]), (12, 0.8325, 0.8192, 0.0002513393979068487, 0.00040460527290767133, 37, [20, 21, 20, 30, 42]), (12, 0.8325, 0.8192, 0.0002513393979068487, 0.00040460527290767133, 37, [20, 21, 20, 30, 42]), (12, 0.8325, 0.8192, 0.0002513393979068487, 0.00040460527290767133, 37, [20, 21, 20, 30, 42]), (12, 0.8223, 0.8092, 0.00023750060102930857, 0.0003835709463089187, 32, [20, 20, 20, 42, 51]), (12, 0.8223, 0.8092, 5.584569219278893e-05, 0.00043286127383496977, 33, [22, 40, 40, 49, 60]), (12, 0.8223, 0.8092, 5.584569219278893e-05, 0.00043286127383496977, 33, [22, 40, 40, 49, 60]), (12, 0.8173, 0.8042, 0.00022393326641448704, 0.00040433451476014413, 26, [20, 20, 20, 38, 51]), (12, 0.8173, 0.8042, 0.0007137159576996877, 0.0004079883704570502, 28, [20, 20, 20, 20, 21]), (12, 0.802, 0.7892, 0.0006477940417559817, 0.0004555913325260387, 34, [20, 20, 20, 21, 37]), (12, 0.7817, 0.7693, 0.000474873532025556, 0.0003924759901080246, 35, [20, 20, 20, 26, 27])]\n",
      "#### Overall best val metric 0.8426395939086294 ####\n",
      "Generation 12: 81.6 s, best val metric 0.8426, [(13, 0.8426, 0.8188, 9.475180274171945e-05, 0.0003945843644713639, 38, [20, 28, 20, 65, 54]), (13, 0.8122, 0.7892, 0.0002513393979068487, 0.00040460527290767133, 37, [20, 21, 20, 26, 48]), (13, 0.8122, 0.7892, 0.0002513393979068487, 0.00040460527290767133, 37, [20, 21, 20, 26, 48]), (13, 0.8071, 0.7842, 0.0008354070532265518, 0.00039160076915319326, 43, [20, 31, 22, 44, 28]), (13, 0.8071, 0.7842, 0.0005531838444932856, 0.00041683742942357697, 31, [20, 20, 20, 20, 27]), (13, 0.8071, 0.7842, 0.0008354070532265518, 0.00039160076915319326, 43, [20, 31, 22, 44, 28]), (13, 0.802, 0.7793, 0.00014016105793922013, 0.00042309081701819, 37, [20, 26, 20, 60, 68]), (13, 0.802, 0.7793, 0.000474873532025556, 0.0003924759901080246, 35, [20, 20, 20, 20, 27]), (13, 0.802, 0.7793, 0.0006477940417559817, 0.0004555913325260387, 34, [20, 20, 20, 20, 37]), (13, 0.802, 0.7793, 0.00022393326641448704, 0.00040433451476014413, 26, [20, 24, 20, 35, 52]), (13, 0.7919, 0.7694, 5.584569219278893e-05, 0.00043286127383496977, 33, [25, 60, 54, 69, 80])]\n",
      "#### Overall best val metric 0.8426395939086294 ####\n",
      "Generation 13: 80.8 s, best val metric 0.8426, [(14, 0.8426, 0.8006, 9.475180274171945e-05, 0.0003945843644713639, 38, [20, 28, 20, 65, 54]), (14, 0.8376, 0.7958, 0.00021374417219948352, 0.0004426160785789155, 34, [20, 33, 21, 56, 45]), (14, 0.8376, 0.7958, 0.00021374417219948352, 0.0004426160785789155, 34, [20, 33, 21, 56, 45]), (14, 0.8274, 0.7861, 0.00010067986133095368, 0.0004229608953744892, 39, [21, 38, 20, 74, 59]), (14, 0.8274, 0.7861, 4.752592075639174e-05, 0.0004113075347571205, 38, [28, 44, 40, 55, 72]), (14, 0.8274, 0.7861, 4.752592075639174e-05, 0.0004113075347571205, 38, [28, 44, 40, 55, 72]), (14, 0.8122, 0.7717, 0.0002513393979068487, 0.00040460527290767133, 37, [20, 21, 20, 22, 45]), (14, 0.8122, 0.7717, 0.0002513393979068487, 0.00040460527290767133, 37, [20, 21, 20, 22, 45]), (14, 0.802, 0.762, 3.395509647138045e-05, 0.0004069179080772743, 37, [38, 41, 40, 46, 68]), (14, 0.802, 0.762, 3.395509647138045e-05, 0.0004069179080772743, 37, [38, 41, 40, 46, 68]), (14, 0.802, 0.762, 0.000864498891765548, 0.000413544379853476, 30, [20, 20, 20, 20, 27])]\n",
      "#### Overall best val metric 0.8426395939086294 ####\n",
      "Generation 14: 89.7 s, best val metric 0.8426, [(15, 0.8426, 0.7699, 9.475180274171945e-05, 0.0003945843644713639, 38, [20, 28, 20, 65, 54]), (15, 0.8376, 0.7653, 0.00019151357401516047, 0.0004145273685669718, 31, [20, 26, 20, 55, 53]), (15, 0.8173, 0.7467, 4.752592075639174e-05, 0.0004113075347571205, 38, [26, 63, 60, 75, 91]), (15, 0.8173, 0.7467, 8.57558574779122e-05, 0.0003874309620368547, 38, [20, 54, 24, 66, 71]), (15, 0.8122, 0.7421, 9.475180274171945e-05, 0.0003945843644713639, 38, [20, 31, 23, 73, 57]), (15, 0.8122, 0.7421, 9.475180274171945e-05, 0.0003945843644713639, 38, [20, 31, 23, 73, 57]), (15, 0.8071, 0.7374, 0.00010067986133095368, 0.0004229608953744892, 39, [20, 30, 21, 77, 69]), (15, 0.8071, 0.7374, 0.00015517450466239824, 0.00043982978294055205, 41, [20, 25, 25, 57, 63]), (15, 0.7919, 0.7235, 8.414892357196831e-05, 0.0004494270048728886, 30, [20, 45, 54, 74, 92]), (15, 0.7868, 0.7189, 0.00017152709629898776, 0.00041869680607002364, 27, [20, 24, 20, 38, 54]), (15, 0.7868, 0.7189, 0.0008107981988081906, 0.0004309717712652146, 37, [20, 20, 20, 23, 38])]\n",
      "#### Overall best val metric 0.8426395939086294 ####\n",
      "Generation 15: 115.6 s, best val metric 0.8426, [(16, 0.8426, 0.7202, 9.475180274171945e-05, 0.0003945843644713639, 38, [20, 28, 20, 65, 54]), (16, 0.8274, 0.7072, 0.00010067986133095368, 0.0004229608953744892, 39, [20, 30, 21, 92, 76]), (16, 0.8274, 0.7072, 8.45241561952134e-05, 0.00041316685563346693, 37, [20, 44, 27, 81, 83]), (16, 0.8274, 0.7072, 8.45241561952134e-05, 0.00041316685563346693, 37, [20, 44, 27, 81, 83]), (16, 0.8274, 0.7072, 0.00010067986133095368, 0.0004229608953744892, 39, [20, 30, 21, 92, 76]), (16, 0.8274, 0.7072, 8.45241561952134e-05, 0.00041316685563346693, 37, [20, 44, 27, 81, 83]), (16, 0.8223, 0.7028, 9.475180274171945e-05, 0.0003945843644713639, 38, [20, 39, 20, 83, 60]), (16, 0.8223, 0.7028, 9.475180274171945e-05, 0.0003945843644713639, 38, [20, 39, 20, 83, 60]), (16, 0.802, 0.6855, 0.0001418007988113445, 0.0004160930941214258, 40, [20, 36, 22, 42, 58]), (16, 0.802, 0.6855, 0.0001418007988113445, 0.0004160930941214258, 40, [20, 36, 22, 42, 58]), (16, 0.802, 0.6855, 3.1622776601683795e-05, 0.0004068549328142305, 38, [39, 44, 40, 58, 74])]\n",
      "#### Overall best val metric 0.8426395939086294 ####\n",
      "Generation 16: 142.8 s, best val metric 0.8426, [(17, 0.8426, 0.6452, 9.475180274171945e-05, 0.0003945843644713639, 38, [20, 28, 20, 65, 54]), (17, 0.8274, 0.6335, 8.45241561952134e-05, 0.00041316685563346693, 37, [20, 46, 29, 90, 92]), (17, 0.8274, 0.6335, 8.45241561952134e-05, 0.00041316685563346693, 37, [20, 46, 29, 90, 92]), (17, 0.8274, 0.6335, 9.475180274171945e-05, 0.0003945843644713639, 38, [20, 36, 26, 90, 69]), (17, 0.8274, 0.6335, 8.45241561952134e-05, 0.00041316685563346693, 37, [20, 46, 29, 90, 92]), (17, 0.8274, 0.6335, 8.45241561952134e-05, 0.00041316685563346693, 37, [20, 46, 29, 90, 92]), (17, 0.8223, 0.6296, 0.0002837574314546646, 0.0004429365552775545, 34, [20, 33, 20, 36, 65]), (17, 0.8173, 0.6257, 9.475180274171945e-05, 0.0003945843644713639, 38, [20, 37, 20, 73, 59]), (17, 0.8173, 0.6257, 3.1622776601683795e-05, 0.0004346863168164583, 37, [35, 64, 47, 101, 103]), (17, 0.8173, 0.6257, 9.475180274171945e-05, 0.0003945843644713639, 38, [20, 37, 20, 73, 59]), (17, 0.8173, 0.6257, 9.475180274171945e-05, 0.0003945843644713639, 38, [20, 37, 20, 73, 59])]\n",
      "#### Overall best val metric 0.8426395939086294 ####\n",
      "Generation 17: 158.8 s, best val metric 0.8426, [(1, 0.7056, 0.7056, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6599, 0.6599, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6599, 0.6599, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6599, 0.6599, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (18, 0.8426, 0.5433, 9.475180274171945e-05, 0.0003945843644713639, 38, [20, 28, 20, 65, 54]), (18, 0.8223, 0.5302, 6.251148966287023e-05, 0.00047531209802406427, 37, [22, 65, 48, 110, 111]), (18, 0.8173, 0.5269, 9.475180274171945e-05, 0.0003945843644713639, 38, [20, 29, 20, 82, 67]), (18, 0.8122, 0.5237, 0.0005626450768441499, 0.0003758441029578247, 36, [20, 21, 20, 28, 31]), (18, 0.8122, 0.5237, 0.0005626450768441499, 0.0003758441029578247, 36, [20, 21, 20, 28, 31]), (18, 0.8071, 0.5204, 0.00027820793351054744, 0.00041250197451492927, 32, [20, 31, 20, 51, 81]), (18, 0.802, 0.5171, 9.475180274171945e-05, 0.0003945843644713639, 38, [20, 39, 20, 85, 76])]\n",
      "#### Overall best val metric 0.8426395939086294 ####\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "evolution = Evolution()\n",
    "hyperparameters = {\n",
    "    'regularization_penalty': Hyperparameter(3., 2.5, 4.5, 0.5),\n",
    "    'learning_rate': Hyperparameter(0.0004, 0.0001, 0.0006, 0.000025),\n",
    "    'batch_size': Hyperparameter(32, 16, 64, 4),\n",
    "}\n",
    "evolution.run(x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test),\n",
    "              layer_sizes=[20, 20, 20, 20, 20], output_neurons=10, hyperparameters=hyperparameters, n_parents=5, population_size=10, \n",
    "              n_generations=50, tournament_size=3, n_introduced=2, age_penalty_period=10, use_static_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1f59a655e0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 244,
       "width": 375
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [0] + [result.time for result in evolution.results]\n",
    "x += [x[-1] + (x[-1] - x[-2]) / 10]\n",
    "y = [0, 0] + [result.best_val_metric for result in evolution.results]\n",
    "plt.step(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: 65.6 s, best val metric 0.7462, [(1, 0.7462, 0.7462, 0.00042487534303538104, 0.00037724766991369726, 28, [20, 20, 20, 20, 20]), (1, 0.7157, 0.7157, 0.000997615388300815, 0.0004156491630537969, 25, [20, 20, 20, 20, 20]), (1, 0.7157, 0.7157, 0.000997615388300815, 0.0004156491630537969, 25, [20, 20, 20, 20, 20]), (1, 0.6954, 0.6954, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6954, 0.6954, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.665, 0.665, 0.0023069608990303235, 0.0004235222797918026, 34, [20, 20, 20, 20, 20]), (1, 0.665, 0.665, 0.0023069608990303235, 0.0004235222797918026, 34, [20, 20, 20, 20, 20]), (1, 0.6599, 0.6599, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6599, 0.6599, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6497, 0.6497, 0.001, 0.0004, 32, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.7461928934010152 ####\n",
      "Generation 1: 66.6 s, best val metric 0.7868, [(2, 0.7868, 0.7868, 0.00042487534303538104, 0.00037724766991369726, 28, [20, 20, 20, 20, 20]), (2, 0.7817, 0.7817, 0.0006596228975551668, 0.0004001499495359794, 30, [20, 20, 20, 20, 20]), (2, 0.7817, 0.7817, 0.0006596228975551668, 0.0004001499495359794, 30, [20, 20, 20, 20, 20]), (2, 0.7817, 0.7817, 0.0006596228975551668, 0.0004001499495359794, 30, [20, 20, 20, 20, 20]), (2, 0.7716, 0.7716, 0.00032148761317603183, 0.00042710038976266385, 34, [20, 20, 20, 20, 20]), (2, 0.7716, 0.7716, 0.00032148761317603183, 0.00042710038976266385, 34, [20, 20, 20, 20, 20]), (2, 0.7665, 0.7665, 0.00030710841659973046, 0.00036624650231015585, 27, [20, 20, 20, 20, 20]), (2, 0.7665, 0.7665, 0.0010822580064505786, 0.00038627866491985, 34, [20, 20, 20, 20, 20]), (2, 0.7513, 0.7513, 0.0009035037713077247, 0.00042612507637551026, 33, [20, 20, 20, 20, 20]), (2, 0.7513, 0.7513, 0.0009035037713077247, 0.00042612507637551026, 33, [20, 20, 20, 20, 20]), (2, 0.7462, 0.7462, 0.00042487534303538104, 0.00037724766991369726, 28, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.7868020304568528 ####\n",
      "Generation 2: 72.5 s, best val metric 0.802, [(3, 0.802, 0.802, 0.0006940824251957409, 0.00038074820377438564, 24, [20, 20, 20, 20, 20]), (3, 0.802, 0.802, 0.0009035037713077247, 0.00042612507637551026, 33, [20, 20, 20, 20, 20]), (3, 0.802, 0.802, 0.0006940824251957409, 0.00038074820377438564, 24, [20, 20, 20, 20, 20]), (3, 0.7868, 0.7868, 0.00042487534303538104, 0.00037724766991369726, 28, [20, 20, 20, 20, 20]), (3, 0.7868, 0.7868, 0.0006064234665023273, 0.0004216239164943759, 30, [20, 20, 20, 20, 20]), (3, 0.7868, 0.7868, 0.00042487534303538104, 0.00037724766991369726, 28, [20, 20, 20, 20, 20]), (3, 0.7868, 0.7868, 0.00045768226714013727, 0.00040235583450618444, 37, [20, 20, 20, 20, 20]), (3, 0.7868, 0.7868, 0.00042487534303538104, 0.00037724766991369726, 28, [20, 20, 20, 20, 20]), (3, 0.7817, 0.7817, 0.00042487534303538104, 0.00037724766991369726, 28, [20, 20, 20, 20, 20]), (3, 0.7766, 0.7766, 0.0009035037713077247, 0.00042612507637551026, 33, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 0.0003335607352929826, 0.00041066903707483285, 31, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8020304568527918 ####\n",
      "Generation 3: 89.4 s, best val metric 0.8122, [(4, 0.8122, 0.8122, 0.00036316169802133434, 0.0004011751339484933, 29, [20, 20, 20, 20, 20]), (4, 0.8071, 0.8071, 0.00042487534303538104, 0.00037724766991369726, 28, [20, 20, 20, 20, 20]), (4, 0.8071, 0.8071, 0.00042487534303538104, 0.00037724766991369726, 28, [20, 20, 20, 20, 20]), (4, 0.802, 0.802, 0.0006940824251957409, 0.00038074820377438564, 24, [20, 20, 20, 20, 20]), (4, 0.7919, 0.7919, 0.0009035037713077247, 0.00042612507637551026, 33, [20, 20, 20, 20, 20]), (4, 0.7919, 0.7919, 0.0003335607352929826, 0.00041066903707483285, 31, [20, 20, 20, 20, 20]), (4, 0.7919, 0.7919, 0.0003335607352929826, 0.00041066903707483285, 31, [20, 20, 20, 20, 20]), (4, 0.7919, 0.7919, 0.0009035037713077247, 0.00042612507637551026, 33, [20, 20, 20, 20, 20]), (4, 0.7868, 0.7868, 0.0009035037713077247, 0.00042612507637551026, 33, [20, 20, 20, 20, 20]), (4, 0.7817, 0.7817, 0.0008421484223251596, 0.00040218134398113675, 29, [20, 20, 20, 20, 20]), (4, 0.7766, 0.7766, 0.001371594895372441, 0.00044081179093728034, 28, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8121827411167513 ####\n",
      "Generation 4: 126.2 s, best val metric 0.8122, [(5, 0.8122, 0.8122, 0.0005320850884312935, 0.00039780520351026814, 20, [20, 20, 20, 20, 20]), (5, 0.8122, 0.8122, 0.00036316169802133434, 0.0004011751339484933, 29, [20, 20, 20, 20, 20]), (5, 0.8071, 0.8071, 0.00042035429436712156, 0.0003807510778609042, 30, [20, 20, 20, 20, 20]), (5, 0.8071, 0.8071, 0.00042035429436712156, 0.0003807510778609042, 30, [20, 20, 20, 20, 20]), (5, 0.802, 0.802, 0.0006871565627487587, 0.0004212083280248869, 32, [20, 20, 20, 20, 20]), (5, 0.797, 0.797, 0.000163120271707407, 0.00036689894033368933, 24, [20, 20, 20, 20, 22]), (5, 0.797, 0.797, 0.000163120271707407, 0.00036689894033368933, 24, [20, 20, 20, 20, 22]), (5, 0.797, 0.797, 0.0011326075571595872, 0.0003929654443432237, 29, [20, 20, 20, 20, 20]), (5, 0.7919, 0.7919, 0.0009822003950410477, 0.0004137435755192002, 26, [20, 20, 20, 20, 20]), (5, 0.7868, 0.7868, 0.0003335607352929826, 0.00041066903707483285, 31, [20, 20, 20, 20, 21]), (5, 0.7716, 0.7716, 0.0031622776601683794, 0.00040157690323114245, 30, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8121827411167513 ####\n",
      "Generation 5: 126.0 s, best val metric 0.8122, [(6, 0.8122, 0.8122, 0.0005320850884312935, 0.00039780520351026814, 20, [20, 20, 20, 20, 20]), (6, 0.8071, 0.8071, 0.000163120271707407, 0.00036689894033368933, 24, [20, 20, 20, 20, 25]), (6, 0.8071, 0.8071, 0.000163120271707407, 0.00036689894033368933, 24, [20, 20, 20, 20, 25]), (6, 0.802, 0.802, 3.1622776601683795e-05, 0.00041486438228606, 35, [27, 40, 40, 40, 40]), (6, 0.802, 0.802, 0.0006871565627487587, 0.0004212083280248869, 32, [20, 20, 20, 20, 20]), (6, 0.797, 0.797, 0.0011326075571595872, 0.0003929654443432237, 29, [20, 20, 20, 20, 20]), (6, 0.7919, 0.7919, 0.0003543659099714868, 0.0003367574437515136, 28, [20, 20, 20, 20, 20]), (6, 0.7919, 0.7919, 0.0003543659099714868, 0.0003367574437515136, 28, [20, 20, 20, 20, 20]), (6, 0.7868, 0.7868, 0.00024263566776213733, 0.0003993408263236212, 28, [20, 20, 20, 20, 22]), (6, 0.7766, 0.7766, 0.0018539562466001389, 0.0004134471606862763, 30, [20, 20, 20, 20, 20]), (6, 0.7716, 0.7716, 0.00017005062888817975, 0.0003635257524188609, 31, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8121827411167513 ####\n",
      "Generation 6: 129.4 s, best val metric 0.8173, [(7, 0.8173, 0.8173, 0.0002411003280251307, 0.0003550245716541641, 31, [20, 20, 20, 20, 25]), (7, 0.8122, 0.8122, 0.001089768058325818, 0.00040876040357601173, 31, [20, 20, 20, 20, 20]), (7, 0.8122, 0.8122, 0.001089768058325818, 0.00040876040357601173, 31, [20, 20, 20, 20, 20]), (7, 0.8122, 0.8122, 0.0005320850884312935, 0.00039780520351026814, 20, [20, 20, 20, 20, 20]), (7, 0.802, 0.802, 0.0003543659099714868, 0.0003367574437515136, 28, [20, 20, 20, 20, 20]), (7, 0.802, 0.802, 0.0011326075571595872, 0.0003929654443432237, 29, [20, 20, 20, 20, 20]), (7, 0.797, 0.797, 0.0018539562466001389, 0.0004134471606862763, 30, [20, 20, 20, 20, 20]), (7, 0.797, 0.797, 0.000163120271707407, 0.00036689894033368933, 24, [20, 20, 20, 20, 39]), (7, 0.797, 0.797, 0.0006343280290981116, 0.0003764319903738808, 41, [20, 20, 20, 20, 20]), (7, 0.797, 0.797, 0.0006209012588270557, 0.00036852723342132464, 26, [20, 20, 20, 20, 20]), (7, 0.7919, 0.7919, 0.0017851574097352961, 0.0003917367434192631, 35, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.817258883248731 ####\n",
      "Generation 7: 121.4 s, best val metric 0.8173, [(8, 0.8173, 0.8173, 0.0002411003280251307, 0.0003550245716541641, 31, [20, 20, 20, 20, 25]), (8, 0.797, 0.797, 0.0011326075571595872, 0.0003929654443432237, 29, [20, 18, 19, 20, 20]), (8, 0.797, 0.797, 0.001089768058325818, 0.00040876040357601173, 31, [20, 20, 20, 20, 20]), (8, 0.797, 0.797, 0.0011326075571595872, 0.0003929654443432237, 29, [20, 18, 19, 20, 20]), (8, 0.797, 0.797, 0.0011326075571595872, 0.0003929654443432237, 29, [20, 18, 19, 20, 20]), (8, 0.7919, 0.7919, 0.000163120271707407, 0.00036689894033368933, 24, [20, 20, 20, 22, 45]), (8, 0.7919, 0.7919, 0.00054462433648645, 0.0003595275029640171, 33, [20, 20, 20, 20, 20]), (8, 0.7919, 0.7919, 0.00054462433648645, 0.0003595275029640171, 33, [20, 20, 20, 20, 20]), (8, 0.7868, 0.7868, 0.0003543659099714868, 0.0003367574437515136, 28, [20, 20, 20, 20, 20]), (8, 0.7868, 0.7868, 0.0003543659099714868, 0.0003367574437515136, 28, [20, 20, 20, 20, 20]), (8, 0.7766, 0.7766, 0.0009495544957059181, 0.00037117436540222247, 30, [20, 18, 19, 20, 20])]\n",
      "#### Overall best val metric 0.817258883248731 ####\n",
      "Generation 8: 75.2 s, best val metric 0.8173, [(9, 0.8173, 0.8173, 0.00012195704435590949, 0.00038870962191948097, 29, [20, 21, 20, 28, 36]), (9, 0.8173, 0.8173, 0.0002411003280251307, 0.0003550245716541641, 31, [20, 20, 20, 20, 25]), (9, 0.8122, 0.8122, 0.0002555746153175901, 0.0003574747229157953, 31, [20, 20, 20, 20, 20]), (9, 0.8122, 0.8122, 0.0002555746153175901, 0.0003574747229157953, 31, [20, 20, 20, 20, 20]), (9, 0.8122, 0.8122, 0.0002555746153175901, 0.0003574747229157953, 31, [20, 20, 20, 20, 20]), (9, 0.802, 0.802, 0.0003543659099714868, 0.0003367574437515136, 28, [20, 20, 20, 20, 22]), (9, 0.802, 0.802, 0.0003543659099714868, 0.0003367574437515136, 28, [20, 20, 20, 20, 22]), (9, 0.797, 0.797, 0.00054462433648645, 0.0003595275029640171, 33, [20, 20, 20, 20, 20]), (9, 0.797, 0.797, 0.00026749391297997336, 0.0004004994713947364, 25, [20, 20, 20, 25, 34]), (9, 0.7817, 0.7817, 0.000163120271707407, 0.00036689894033368933, 24, [20, 20, 20, 21, 44]), (9, 0.7766, 0.7766, 0.0018251675995031229, 0.0003991809244325281, 28, [20, 14, 18, 18, 20])]\n",
      "#### Overall best val metric 0.817258883248731 ####\n",
      "Generation 9: 78.6 s, best val metric 0.8173, [(10, 0.8173, 0.8173, 0.00012195704435590949, 0.00038870962191948097, 29, [20, 21, 20, 28, 36]), (10, 0.8122, 0.8122, 0.0002128244711781887, 0.00035295222982810736, 28, [20, 20, 20, 20, 26]), (10, 0.8122, 0.8122, 0.0002128244711781887, 0.00035295222982810736, 28, [20, 20, 20, 20, 26]), (10, 0.8122, 0.8122, 0.0002128244711781887, 0.00035295222982810736, 28, [20, 20, 20, 20, 26]), (10, 0.8071, 0.8071, 0.0002882747486673429, 0.0003981622998976324, 30, [20, 20, 20, 20, 36]), (10, 0.802, 0.802, 0.00026749391297997336, 0.0004004994713947364, 25, [20, 19, 20, 23, 41]), (10, 0.802, 0.802, 0.0002555746153175901, 0.0003574747229157953, 31, [20, 20, 20, 20, 24]), (10, 0.802, 0.802, 0.0003543659099714868, 0.0003367574437515136, 28, [20, 20, 20, 20, 20]), (10, 0.802, 0.802, 0.0003543659099714868, 0.0003367574437515136, 28, [20, 20, 20, 20, 20]), (10, 0.802, 0.802, 0.00026749391297997336, 0.0004004994713947364, 25, [20, 19, 20, 23, 41]), (10, 0.7919, 0.7919, 0.00032251485881533974, 0.00032961910648733253, 24, [20, 20, 20, 20, 21])]\n",
      "#### Overall best val metric 0.817258883248731 ####\n",
      "Generation 10: 47.2 s, best val metric 0.8223, [(11, 0.8223, 0.815, 0.00026749391297997336, 0.0004004994713947364, 25, [20, 19, 20, 23, 41]), (11, 0.8173, 0.81, 0.0003543659099714868, 0.0003367574437515136, 28, [20, 20, 20, 20, 20]), (11, 0.8173, 0.81, 0.00040353886137467856, 0.0003941130257769117, 33, [20, 19, 20, 23, 41]), (11, 0.8173, 0.81, 0.0003543659099714868, 0.0003367574437515136, 28, [20, 20, 20, 20, 20]), (11, 0.8173, 0.81, 0.0003543659099714868, 0.0003367574437515136, 28, [20, 20, 20, 20, 20]), (11, 0.8173, 0.81, 0.0003543659099714868, 0.0003367574437515136, 28, [20, 20, 20, 20, 20]), (11, 0.8173, 0.81, 0.00012195704435590949, 0.00038870962191948097, 29, [20, 21, 20, 28, 36]), (11, 0.8122, 0.8049, 0.0005063880793058732, 0.00036906410131211967, 28, [20, 20, 20, 20, 26]), (11, 0.797, 0.7898, 0.0012103386263830175, 0.00030025239626230843, 20, [20, 20, 20, 20, 26]), (11, 0.797, 0.7898, 0.00015587985715645895, 0.0003356414151724785, 26, [20, 21, 20, 28, 36]), (11, 0.797, 0.7898, 0.0012103386263830175, 0.00030025239626230843, 20, [20, 20, 20, 20, 26])]\n",
      "#### Overall best val metric 0.8223350253807107 ####\n",
      "Generation 11: 49.6 s, best val metric 0.8223, [(12, 0.8223, 0.8092, 0.00026749391297997336, 0.0004004994713947364, 25, [20, 19, 20, 23, 41]), (12, 0.8173, 0.8042, 0.0012103386263830175, 0.00030025239626230843, 20, [20, 20, 20, 20, 26]), (12, 0.8173, 0.8042, 0.0012103386263830175, 0.00030025239626230843, 20, [20, 20, 20, 20, 26]), (12, 0.8173, 0.8042, 0.0012103386263830175, 0.00030025239626230843, 20, [20, 20, 20, 20, 26]), (12, 0.8122, 0.7992, 0.0002855331574417921, 0.0003737624807405427, 19, [20, 21, 20, 28, 36]), (12, 0.8122, 0.7992, 0.0002855331574417921, 0.0003737624807405427, 19, [20, 21, 20, 28, 36]), (12, 0.8122, 0.7992, 0.0003448505540652059, 0.00036548002899129873, 26, [20, 21, 20, 28, 36]), (12, 0.8122, 0.7992, 0.0003448505540652059, 0.00036548002899129873, 26, [20, 21, 20, 28, 36]), (12, 0.802, 0.7892, 0.0003543659099714868, 0.0003367574437515136, 28, [20, 20, 20, 20, 20]), (12, 0.802, 0.7892, 0.00015587985715645895, 0.0003356414151724785, 26, [20, 21, 20, 28, 36]), (12, 0.797, 0.7842, 0.0002377770166494118, 0.00035680848457788733, 19, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8223350253807107 ####\n",
      "Generation 12: 58.0 s, best val metric 0.8223, [(13, 0.8223, 0.799, 0.0012103386263830175, 0.00030025239626230843, 20, [20, 20, 20, 20, 26]), (13, 0.8223, 0.799, 0.0012103386263830175, 0.00030025239626230843, 20, [20, 20, 20, 20, 26]), (13, 0.8223, 0.799, 0.00026749391297997336, 0.0004004994713947364, 25, [20, 19, 20, 23, 41]), (13, 0.8173, 0.7941, 0.0008706755994490488, 0.00034644864343161833, 17, [20, 21, 20, 28, 36]), (13, 0.8173, 0.7941, 0.0008706755994490488, 0.00034644864343161833, 17, [20, 21, 20, 28, 36]), (13, 0.8122, 0.7892, 0.00022926960032693103, 0.000314323494378015, 25, [20, 20, 20, 20, 20]), (13, 0.8122, 0.7892, 0.0004320856298799477, 0.0002991247659619634, 20, [20, 21, 20, 28, 36]), (13, 0.8071, 0.7842, 0.0009388967345742565, 0.0003689106070165832, 25, [20, 20, 20, 20, 26]), (13, 0.802, 0.7793, 0.0003448505540652059, 0.00036548002899129873, 26, [20, 21, 20, 28, 36]), (13, 0.802, 0.7793, 0.0031622776601683794, 0.00034849696199318076, 20, [20, 19, 20, 23, 41]), (13, 0.797, 0.7744, 0.0002377770166494118, 0.00035680848457788733, 19, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8223350253807107 ####\n",
      "Generation 13: 74.0 s, best val metric 0.8274, [(14, 0.8274, 0.7861, 0.0012103386263830175, 0.00030025239626230843, 20, [20, 20, 20, 20, 26]), (14, 0.8274, 0.7861, 0.0012103386263830175, 0.00030025239626230843, 20, [20, 20, 20, 20, 26]), (14, 0.8223, 0.7813, 0.0012103386263830175, 0.00030025239626230843, 20, [20, 20, 20, 20, 26]), (14, 0.8122, 0.7717, 0.0005023226002934405, 0.00035965495210255993, 24, [20, 20, 20, 20, 26]), (14, 0.8122, 0.7717, 0.00013985553620763738, 0.0003586981663971926, 17, [20, 21, 20, 28, 36]), (14, 0.8122, 0.7717, 0.0005023226002934405, 0.00035965495210255993, 24, [20, 20, 20, 20, 26]), (14, 0.8071, 0.7669, 0.0004778304882763009, 0.00031308477917457673, 31, [20, 21, 20, 28, 36]), (14, 0.8071, 0.7669, 0.0004778304882763009, 0.00031308477917457673, 31, [20, 21, 20, 28, 36]), (14, 0.797, 0.7572, 0.0012103386263830175, 0.00030025239626230843, 20, [20, 20, 20, 20, 26]), (14, 0.7919, 0.7524, 0.0009273846175975947, 0.00034341952427768526, 26, [20, 19, 20, 23, 41]), (14, 0.7868, 0.7476, 0.0009388967345742565, 0.0003689106070165832, 25, [20, 20, 20, 20, 26])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 14: 68.0 s, best val metric 0.8274, [(15, 0.8274, 0.756, 0.0012103386263830175, 0.00030025239626230843, 20, [20, 20, 20, 20, 26]), (15, 0.8122, 0.7421, 0.0005023226002934405, 0.00035965495210255993, 24, [20, 20, 20, 20, 26]), (15, 0.8071, 0.7374, 0.0005168320999686909, 0.00036154418710905616, 25, [20, 20, 20, 20, 26]), (15, 0.8071, 0.7374, 0.0005168320999686909, 0.00036154418710905616, 25, [20, 20, 20, 20, 26]), (15, 0.797, 0.7282, 0.0008584466027808446, 0.0003141724876378021, 20, [20, 20, 20, 20, 26]), (15, 0.797, 0.7282, 0.0008584466027808446, 0.0003141724876378021, 20, [20, 20, 20, 20, 26]), (15, 0.797, 0.7282, 0.0020201781133993473, 0.0002934067232406134, 27, [20, 20, 20, 20, 26]), (15, 0.7919, 0.7235, 0.0004778304882763009, 0.00031308477917457673, 31, [20, 21, 20, 28, 36]), (15, 0.7919, 0.7235, 0.0012103386263830175, 0.00030025239626230843, 20, [20, 20, 20, 20, 26]), (15, 0.7919, 0.7235, 0.0019503884429054662, 0.0003354649630188016, 28, [20, 20, 20, 20, 26]), (15, 0.7817, 0.7142, 0.0012103386263830175, 0.00030025239626230843, 20, [20, 20, 20, 20, 26])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 15: 76.6 s, best val metric 0.8274, [(16, 0.8274, 0.7072, 0.0012103386263830175, 0.00030025239626230843, 20, [20, 20, 20, 20, 26]), (16, 0.8223, 0.7028, 0.0005023226002934405, 0.00035965495210255993, 24, [20, 20, 20, 20, 26]), (16, 0.8223, 0.7028, 0.0005023226002934405, 0.00035965495210255993, 24, [20, 20, 20, 20, 26]), (16, 0.8223, 0.7028, 0.0005023226002934405, 0.00035965495210255993, 24, [20, 20, 20, 20, 26]), (16, 0.8223, 0.7028, 0.0005023226002934405, 0.00035965495210255993, 24, [20, 20, 20, 20, 26]), (16, 0.8173, 0.6985, 0.0005168320999686909, 0.00036154418710905616, 25, [20, 20, 20, 20, 26]), (16, 0.8173, 0.6985, 0.0005168320999686909, 0.00036154418710905616, 25, [20, 20, 20, 20, 26]), (16, 0.8173, 0.6985, 0.0005168320999686909, 0.00036154418710905616, 25, [20, 20, 20, 20, 26]), (16, 0.8122, 0.6941, 0.0005069090768505098, 0.00035289089358625313, 28, [20, 21, 20, 28, 36]), (16, 0.8071, 0.6898, 0.0012103386263830175, 0.00030025239626230843, 20, [20, 20, 20, 20, 26]), (16, 0.8071, 0.6898, 0.0006804100404206002, 0.0003272208431513238, 21, [20, 20, 20, 20, 26])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 16: 75.7 s, best val metric 0.8426, [(17, 0.8426, 0.6452, 0.0012659266395163933, 0.00035508438666062407, 21, [20, 20, 20, 20, 26]), (17, 0.8426, 0.6452, 0.0012659266395163933, 0.00035508438666062407, 21, [20, 20, 20, 20, 26]), (17, 0.8274, 0.6335, 0.0012103386263830175, 0.00030025239626230843, 20, [20, 20, 20, 20, 26]), (17, 0.8071, 0.6179, 0.0031622776601683794, 0.00036944720954917875, 17, [20, 20, 20, 20, 26]), (17, 0.8071, 0.6179, 0.0031622776601683794, 0.00036944720954917875, 17, [20, 20, 20, 20, 26]), (17, 0.8071, 0.6179, 0.0005023226002934405, 0.00035965495210255993, 24, [20, 20, 20, 20, 26]), (17, 0.8071, 0.6179, 0.0031622776601683794, 0.00036944720954917875, 17, [20, 20, 20, 20, 26]), (17, 0.802, 0.6141, 0.0010489087966540878, 0.0003441555419546926, 22, [20, 20, 20, 20, 26]), (17, 0.802, 0.6141, 0.0010489087966540878, 0.0003441555419546926, 22, [20, 20, 20, 20, 26]), (17, 0.7919, 0.6063, 0.0003496187690895405, 0.00035728188046323, 24, [20, 20, 20, 20, 26]), (17, 0.7919, 0.6063, 0.0002485247472149835, 0.0003369065867509357, 27, [20, 20, 20, 20, 26])]\n",
      "#### Overall best val metric 0.8426395939086294 ####\n",
      "Generation 17: 67.9 s, best val metric 0.8426, [(1, 0.665, 0.665, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.665, 0.665, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (18, 0.8426, 0.5433, 0.0012659266395163933, 0.00035508438666062407, 21, [20, 20, 20, 20, 26]), (18, 0.8325, 0.5367, 0.0031622776601683794, 0.00036944720954917875, 17, [20, 20, 20, 20, 26]), (18, 0.8122, 0.5237, 0.0019199415300799735, 0.00034686471022366607, 17, [20, 20, 20, 20, 26]), (18, 0.8122, 0.5237, 0.0019199415300799735, 0.00034686471022366607, 17, [20, 20, 20, 20, 26]), (18, 0.8122, 0.5237, 0.0019199415300799735, 0.00034686471022366607, 17, [20, 20, 20, 20, 26]), (18, 0.8071, 0.5204, 0.00027324082224418084, 0.0003526986105692932, 21, [20, 20, 20, 20, 26]), (18, 0.8071, 0.5204, 0.00015440502943641938, 0.0003234441521470555, 17, [20, 20, 20, 20, 26]), (18, 0.802, 0.5171, 0.0010489087966540878, 0.0003441555419546926, 22, [20, 20, 20, 20, 26]), (18, 0.802, 0.5171, 0.0010489087966540878, 0.0003441555419546926, 22, [20, 20, 20, 20, 26])]\n",
      "#### Overall best val metric 0.8426395939086294 ####\n",
      "Generation 18: 91.4 s, best val metric 0.8122, [(2, 0.7665, 0.7665, 0.0001876804681825757, 0.00040985131172500413, 23, [20, 20, 20, 20, 20]), (2, 0.7665, 0.7665, 0.0001876804681825757, 0.00040985131172500413, 23, [20, 20, 20, 20, 20]), (2, 0.7665, 0.7665, 0.0001876804681825757, 0.00040985131172500413, 23, [20, 20, 20, 20, 20]), (2, 0.7259, 0.7259, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7259, 0.7259, 0.0013058287629131346, 0.00040992884379345714, 16, [20, 20, 20, 20, 20]), (2, 0.665, 0.665, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6345, 0.6345, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6345, 0.6345, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (19, 0.8122, 0.4078, 0.0019199415300799735, 0.00034686471022366607, 17, [20, 20, 20, 20, 26]), (19, 0.797, 0.4001, 0.0010489087966540878, 0.0003441555419546926, 22, [20, 20, 20, 20, 26]), (19, 0.7919, 0.3976, 0.0031622776601683794, 0.0003136957756581233, 20, [20, 20, 20, 20, 26])]\n",
      "#### Overall best val metric 0.8426395939086294 ####\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "evolution = Evolution()\n",
    "hyperparameters = {\n",
    "    'regularization_penalty': Hyperparameter(3., 2.5, 4.5, 0.5),\n",
    "    'learning_rate': Hyperparameter(0.0004, 0.0001, 0.0006, 0.000025),\n",
    "    'batch_size': Hyperparameter(32, 16, 64, 4),\n",
    "}\n",
    "evolution.run(x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test),\n",
    "              layer_sizes=[20, 20, 20, 20, 20], output_neurons=10, hyperparameters=hyperparameters, n_parents=5, population_size=10, \n",
    "              n_generations=50, tournament_size=3, n_introduced=2, age_penalty_period=10, use_static_graph=False, fine_tuning=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1f586ab070>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuEAAAHpCAYAAAAs++JiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAABYlAAAWJQFJUiTwAAAxsUlEQVR4nO3de3TU9Z3/8dcABnIBIWkw3EXtkFkTwkWxqG2Qiwr1QiIskQC6qKByi3R3g4uKuqKYc6xyEclWCBJJwKYVNqxGtrSWnpZUSY22GmIczB6IIJfIJVdCmN8f/GZ0yAQy+SafTMLzcY5H+Hw+3+985s13klc++cx3bC6XyyUAAAAAxnRq6wkAAAAAlxtCOAAAAGAYIRwAAAAwjBAOAAAAGEYIBwAAAAwjhAMAAACGEcIBAAAAwwjhAAAAgGGEcAAAAMAwQjgAAABgGCEcAAAAMIwQDgAAABjWpa0nYFVBQUFbTwEAAACXkZEjR1o+ByvhAAAAgGHtfiXcrSV+IvFXUVGRJMnhcBh/7PaKmjUPdfMfNWse6tY81M1/1Kx5qJv/WrJmLbkDg5VwAAAAwDBCOAAAAGAYIRwAAAAwjBAOAAAAGEYIBwAAAAwjhAMAAACGEcIBAAAAwwjhAAAAgGGEcAAAAMAwQjgAAABgGCEcAAAAMIwQDgAAABhGCAcAAAAMI4QDAAAAhhHCAQAAAMMI4QAAAIBhXdp6AgAAAGia33x+QpsLv1P12f1tPZU2FRrUWSnj7XrkZ9e09VSajZVwAACAduJ8AHe19TTaXOWZev3qT+37BxFCOAAAQDtBAD8vNKizHvlp+10Fl9iOAgAA0C6Vrvh5W08BFrASDgAAABhGCAcAAAAMI4QDAAAAhhHCAQAAAMN4YyYAAGgVv9q9X6/97ktVnqm/yKj2fZs5oLlYCQcAAK3i0gEczRUa1LmtpwCLWAkHAMCCX+3er1/u/Pr/37+ZVV20vuAuNqWMt7f1NGARIRwAAAte+92XfIDKJYQGddbnz9/p1VZUVCRJcjgcbTGlduv7urXvD6oBIRwAWlTT9sC2B6zoomWEBnVm1RbwgRAOAC2oYwRwNEdwF5uKXpjU1tMA0E7wxkwAaEEE8MtTcBebkof1autpAGhHWAnHZa99bR9gi4D/2q5mpSt+3maP3Vzs020ed90AoKlaJISfOnVKq1ev1q5du3TkyBH17NlT8fHxSklJUWRk5CWP37VrlzZu3Cin06nq6mr169dP48aN0+zZs3XllVe2xBSBRrWfAI72hNuHAQAuxnIIr6qq0owZM+R0OpWcnKyYmBiVlpZqw4YNys/PV05Ojnr1avxXdK+++qrWrVun2NhYzZs3T8HBwSosLNSbb76p9957T++++67CwsKsThNoFAEcLY03ogEALsVyCM/MzFRxcbGWLVum6dOne9odDofmz5+v9PR0LVmyxOex3333nd58803169dPmzdvVteuXSVJiYmJ6tmzp9LT05WTk6MHH3zQ6jSBJgnU7QNsEfAfNQMABDLLb8zMzc1VSEiIpkyZ4tU+fvx4RUVFKTc3Vy6X7/unHj58WGfPnlVsbKwngLuNHDlSkvTNN99YnSIAAAAQUCythFdUVKikpEQjR45UUFCQV5/NZlNcXJw++OADHTx4UAMGDGhw/IABAxQUFKTS0tIGfQcPHpQkXXvttU2aS1u8Kaa6urrNHru9ctfshZw92lz4XcB9wEWg/ltyrfmPmjUPdWse6uY/atY81M1/gVozSyvh7qDcp08fn/1RUVGSpAMHDvjsDwsL06OPPqp9+/bpueeek9Pp1LfffqudO3dq7dq1stvtuvfee61MEQEqEAN4cBdbW08BAABcJiythFdWVkqSgoODffa72ysqKho9x7x58xQeHq4XX3xRWVlZnvbbbrtNK1asULdu3Zo0l7bY98meU/+5axZoAdz9RrpA/RhgrjX/UbPmoW7NQ938R82ah7r5ryVrVlBQYPkcbpZCuM12fuWwsT3fF47z5e2339aLL76on/3sZ7r77rsVHBysTz/9VJs2bdKcOXP0q1/9itsUdnCB+mZIAACA1mIphLtvHVhVVeWz371S3tgtBp1Op1588UXdcsstWrdunad97NixcjgcWrRokd54441G764CAAAAtEeW9oT3799fNptNhw4d8tlfVlYmSRo0aJDP/j179qi+vl7jxo1r0HfbbbfJZrPpo48+sjJFAAAAIOBYCuEhISFyOBwqKipSTU2NV199fb0KCwvVr18/9e3b1+fx7mNqa2sb9NXW1srlcqmurs7KFAEAAICAY/nDehISErR8+XJt2bLF60N1tm/frvLyci1YsMDT5nQ6FRQU5Lld4bBhwyRJ77//vmbNmuW1d/x///d/vcagdf1q934+vh0AAMAQyyE8KSlJO3bsUFpamsrKyhQbG6uSkhJlZGQoOjpas2fP9oydNGmSBg8erLy8PEnSDTfcoNtvv107d+7U/fffr5///OcKCwvT559/rnfeeUcRERF67LHHrE4RTdBWATw0qLPxxwQAAGhrlkN4UFCQMjIytGbNGuXl5Sk7O1sRERFKSkrSwoULFRISctHjX331VWVlZWnbtm165ZVXdPbsWfXu3VuTJ0/W448/7rnXOFpXWwXwlPF2448LAADQ1iyHcEkKDQ1VamqqUlNTLzquuLi44QS6dNGsWbM0a9aslpgKWkBr3jKQ+5sCAABYfGMmAAAAAP8RwgEAAADDCOEAAACAYYRwAAAAwDBCOAAAAGAYIRwAAAAwjBAOAAAAGEYIBwAAAAwjhAMAAACGEcIBAAAAwwjhAAAAgGGEcAAAAMAwQjgAAABgGCEcAAAAMIwQDgAAABjWpa0ngIv71e79eu13X6ryTH1bTwUAAAAthJXwAGc6gIcGdTb2WAAAAJcrQniAMx3AU8bbjT0eAADA5YrtKO1I6Yqft/UUAAAA0AJYCQcAAAAMI4QDAAAAhhHCAQAAAMMI4QAAAIBhhHAAAADAMEI4AAAAYBghHAAAADCMEA4AAAAYRggHAAAADCOEAwAAAIYRwgEAAADDCOEAAACAYYRwAAAAwDBCOAAAAGAYIRwAAAAwjBAOAAAAGEYIBwAAAAwjhAMAAACGEcIBAAAAwwjhAAAAgGGEcAAAAMAwQjgAAABgGCEcAAAAMIwQDgAAABhGCAcAAAAMI4QDAAAAhhHCAQAAAMMI4QAAAIBhhHAAAADAMEI4AAAAYBghHAAAADCMEA4AAAAYRggHAAAADCOEAwAAAIYRwgEAAADDCOEAAACAYYRwAAAAwDBCOAAAAGAYIRwAAAAwjBAOAAAAGEYIBwAAAAwjhAMAAACGEcIBAAAAwwjhAAAAgGGEcAAAAMAwQjgAAABgGCEcAAAAMIwQDgAAABhGCAcAAAAMI4QDAAAAhhHCAQAAAMMI4QAAAIBhhHAAAADAMEI4AAAAYBghHAAAADCMEA4AAAAYRggHAAAADCOEAwAAAIYRwgEAAADDCOEAAACAYV1a4iSnTp3S6tWrtWvXLh05ckQ9e/ZUfHy8UlJSFBkZecnjz5w5o3Xr1ik3N1eHDx9WRESE4uPjtXDhQkVERLTEFAEAAICAYTmEV1VVacaMGXI6nUpOTlZMTIxKS0u1YcMG5efnKycnR7169Wr0+LNnz2rOnDnau3evZs6cqejoaH3xxRfKzMxUQUGBfvvb3yooKMjqNAEAAICAYTmEZ2Zmqri4WMuWLdP06dM97Q6HQ/Pnz1d6erqWLFnS6PFbt27Vnj179Nprr2nixImSpHvvvVc9evTQb3/7W3366ae68cYbrU4TAAAACBiW94Tn5uYqJCREU6ZM8WofP368oqKilJubK5fL1ejxmzdvlsPh8ARwt3nz5mnXrl0EcAAAAHQ4llbCKyoqVFJSopEjRzbYMmKz2RQXF6cPPvhABw8e1IABAxoc/+2338rpdOqRRx7xtNXW1uqKK65Qp07+/XxQVFTUvCdhQXV1tdHHbovn2NJM16yjoG7+o2bNQ92ah7r5j5o1D3XzX6DWzNJK+MGDByVJffr08dkfFRUlSTpw4IDPfqfTKUkaOHCg1q9frzFjxmjo0KEaOnSo5s6dq6+//trK9AAAAICAZGklvLKyUpIUHBzss9/dXlFR4bP/xIkTks5vSZGkhQsX6sorr1R+fr42b96sTz/9VNu3b9dVV111ybk4HA5/p2+Z+yeq1n3s/Z4/tcVzbGlmatbxUDf/UbPmoW7NQ938R82ah7r5ryVrVlBQYPkcbpZCuM1mk6SL7vn+4bgL1dXVSZJOnz6tHTt2KCQkRJI0btw4RUZG6pVXXtGGDRv05JNPWpkmAAAAEFAsbUcJCwuTdP42hb64V8rd4y7kDt1jxozx/NktISFBkvTxxx9bmSIAAAAQcCyF8P79+8tms+nQoUM++8vKyiRJgwYNavR4ST7fhBkeHi6bzeYJ8gAAAEBHYSmEh4SEyOFwqKioSDU1NV599fX1KiwsVL9+/dS3b1+fx1933XXq3r27iouLG/QdOnRILpdLvXv3tjJFAAAAIOBYvk94QkKCampqtGXLFq/27du3q7y8XImJiZ42p9PpdaeUK664Qvfcc48++ugj7d271+v4t99+W5IUHx9vdYoAAABAQLH8iZlJSUnasWOH0tLSVFZWptjYWJWUlCgjI0PR0dGaPXu2Z+ykSZM0ePBg5eXledrmz5+v3bt369FHH9Xs2bMVFRWlv/zlL8rNzdWQIUOUnJxsdYoAAABAQLEcwoOCgpSRkaE1a9YoLy9P2dnZioiIUFJSkhYuXNjgDZcXCg8P19atW7Vy5UplZWXpxIkTioyM1KxZs7RgwYJGb38IAAAAtFeWQ7gkhYaGKjU1VampqRcd52vvtyRFRETo+eef1/PPP98S0wEAAAACmuU94QAAAAD8QwgHAAAADCOEAwAAAIYRwgEAAADDCOEAAACAYYRwAAAAwDBCOAAAAGAYIRwAAAAwjBAOAAAAGEYIBwAAAAwjhAMAAACGEcIBAAAAwwjhAAAAgGGEcAAAAMAwQjgAAABgGCEcAAAAMIwQDgAAABhGCAcAAAAMI4QDAAAAhhHCAQAAAMMI4QAAAIBhhHAAAADAMEI4AAAAYBghHAAAADCMEA4AAAAYRggHAAAADCOEAwAAAIYRwgEAAADDCOEAAACAYYRwAAAAwDBCOAAAAGAYIRwAAAAwjBAOAAAAGEYIBwAAAAwjhAMAAACGEcIBAAAAwwjhAAAAgGGEcAAAAMAwQjgAAABgGCEcAAAAMIwQDgAAABhGCAcAAAAMI4QDAAAAhhHCAQAAAMMI4QAAAIBhhHAAAADAMEI4AAAAYBghHAAAADCMEA4AAAAYRggHAAAADCOEAwAAAIYRwgEAAADDCOEAAACAYYRwAAAAwDBCOAAAAGAYIRwAAAAwjBAOAAAAGEYIBwAAAAwjhAMAAACGEcIBAAAAwwjhAAAAgGGEcAAAAMAwQjgAAABgGCEcAAAAMIwQDgAAABhGCAcAAAAMI4QDAAAAhhHCAQAAAMMI4QAAAIBhhHAAAADAMEI4AAAAYBghHAAAADCMEA4AAAAYRggHAAAADCOEAwAAAIYRwgEAAADDCOEAAACAYYRwAAAAwLAWCeGnTp3S8uXLNXbsWMXExOjWW2/V0qVLdfToUb/PVVtbqzvuuENDhgzRX//615aYHgAAABBQulg9QVVVlWbMmCGn06nk5GTFxMSotLRUGzZsUH5+vnJyctSrV68mn2/t2rUqLS21Oi0AAAAgYFkO4ZmZmSouLtayZcs0ffp0T7vD4dD8+fOVnp6uJUuWNOlcxcXFWr9+vRwOh4qKiqxODQAAAAhIlrej5ObmKiQkRFOmTPFqHz9+vKKiopSbmyuXy3XJ85w7d05PP/20+vXrp6SkJKvTAgAAAAKWpRBeUVGhkpISORwOBQUFefXZbDbFxcXp2LFjOnjw4CXP9fbbb+uzzz7TCy+80OBcAAAAQEdiaTuKO1z36dPHZ39UVJQk6cCBAxowYECj5zl06JBeffVVTZ06VTfeeKMOHDjg91zaYvtKdXW10cfuCFt0TNeso6Bu/qNmzUPdmoe6+Y+aNQ9181+g1szSSnhlZaUkKTg42Ge/u72iouKi53n22WcVGhqqf/u3f7MyHQAAAKBdsLQSbrPZJOmSe77d43z5n//5H3344YdauXKlevTo0ey5OByOZh/bXO6fqFr3sfd7/tQWz7GlmalZx0Pd/EfNmoe6NQ918x81ax7q5r+WrFlBQYHlc7hZWgkPCwuTdP42hb64V8rd4y504sQJz/3F77zzTitTAQAAANoNSyvh/fv3l81m06FDh3z2l5WVSZIGDRrksz8tLU3V1dV67LHHdPjwYU/7qVOnJEnl5eU6fPiwwsPDebMmAAAAOgxLITwkJMRzT++amhp169bN01dfX6/CwkL169dPffv29Xl8fn6+qqqqNHXqVJ/9KSkpkqRNmzbppptusjJVAAAAIGBY/rCehIQELV++XFu2bNGDDz7oad++fbvKy8u1YMECT5vT6VRQUJDnTinLly9XTU1Ng3Pu2bNHb731lhYvXiy73S673W51mgAAAEDAsBzCk5KStGPHDqWlpamsrEyxsbEqKSlRRkaGoqOjNXv2bM/YSZMmafDgwcrLy5MkjR492uc5v/vuO0nSsGHDWAEHAABAh2M5hAcFBSkjI0Nr1qxRXl6esrOzFRERoaSkJC1cuFAhISEtMU8AAACgw7AcwiUpNDRUqampSk1Nvei44uLiJp0vMTFRiYmJLTE1AAAAIOBYukUhAAAAAP8RwgEAAADDCOEAAACAYYRwAAAAwDBCOAAAAGAYIRwAAAAwjBAOAAAAGEYIBwAAAAwjhAMAAACGEcIBAAAAwwjhAAAAgGGEcAAAAMAwQjgAAABgGCEcAAAAMIwQDgAAABhGCAcAAAAMI4QDAAAAhhHCAQAAAMMI4QAAAIBhhHAAAADAMEI4AAAAYBghHAAAADCMEA4AAAAYRggHAAAADCOEAwAAAIYRwgEAAADDCOEAAACAYYRwAAAAwDBCOAAAAGAYIRwAAAAwjBAOAAAAGEYIBwAAAAwjhAMAAACGEcIBAAAAwwjhAAAAgGGEcAAAAMAwQjgAAABgGCEcAAAAMIwQDgAAABhGCAcAAAAMI4QDAAAAhhHCAQAAAMMI4QAAAIBhhHAAAADAMEI4AAAAYBghHAAAADCMEA4AAAAYRggHAAAADCOEAwAAAIYRwgEAAADDCOEAAACAYYRwAAAAwDBCOAAAAGAYIRwAAAAwjBAOAAAAGEYIBwAAAAwjhAMAAACGEcIBAAAAwwjhAAAAgGGEcAAAAMAwQjgAAABgGCEcAAAAMIwQDgAAABhGCAcAAAAMI4QDAAAAhhHCAQAAAMMI4QAAAIBhhHAAAADAMEI4AAAAYBghHAAAADCMEA4AAAAYRggHAAAADCOEAwAAAIYRwgEAAADDCOEAAACAYYRwAAAAwDBCOAAAAGAYIRwAAAAwjBAOAAAAGNalJU5y6tQprV69Wrt27dKRI0fUs2dPxcfHKyUlRZGRkZc8fu/evUpPT1dRUZEqKys1YMAA3XnnnZo9e7a6devWElMEAAAAAoblEF5VVaUZM2bI6XQqOTlZMTExKi0t1YYNG5Sfn6+cnBz16tWr0ePfe+89LV68WFdffbUefvhhhYWFaffu3Vq5cqV2796trKwsderEgj0AAAA6DsshPDMzU8XFxVq2bJmmT5/uaXc4HJo/f77S09O1ZMkSn8eeOXNGTz/9tPr06aNf//rX6t69uyRpypQpWrBggXbu3Kndu3drzJgxVqcJAAAABAzLS8y5ubkKCQnRlClTvNrHjx+vqKgo5ebmyuVy+Tz22LFjmjBhgubMmeMJ4G4//elPJUlffvml1SkCAAAAAcVSCK+oqFBJSYkcDoeCgoK8+mw2m+Li4nTs2DEdPHjQ5/F9+/bVihUrdP/99zfoO336tCQ1COcAAABAe2dpO4o7XPfp08dnf1RUlCTpwIEDGjBgQJPPe+bMGf3mN79RUFCQxo4d26RjioqKmnz+llJdXW30sdviObY00zXrKKib/6hZ81C35qFu/qNmzUPd/BeoNbO0El5ZWSlJCg4O9tnvbq+oqGjyOc+dO6enn35aTqdT8+fP11VXXWVligAAAEDAsbQSbrPZJKnRPd8XjruUmpoa/eIXv9Dvfvc7TZ06VXPmzGnyXBwOR5PHthT3T1St+9j7PX9qi+fY0szUrOOhbv6jZs1D3ZqHuvmPmjUPdfNfS9asoKDA8jncLIXwsLAwSedvU+iLe6XcPe5iysvL9dhjj6mwsFCPPvqoUlJSmhzeAQAAgPbEUgjv37+/bDabDh065LO/rKxMkjRo0KCLnufYsWNKTk5WWVmZXn75ZU2ePNnKtAAAAICAZimEh4SEyOFwqKioSDU1NV6fbllfX6/CwkL169dPffv2bfQcFRUVevjhh3X48GH913/9l26++WYrUwIAAAACnuX7hCckJKimpkZbtmzxat++fbvKy8uVmJjoaXM6nTpw4IDXuOXLl2vfvn365S9/SQAHAADAZcHyJ2YmJSVpx44dSktLU1lZmWJjY1VSUqKMjAxFR0dr9uzZnrGTJk3S4MGDlZeXJ0nat2+f3n33XdntdtXV1Xnafyg8PFyjRo2yOk0AAAAgYFgO4UFBQcrIyNCaNWuUl5en7OxsRUREKCkpSQsXLlRISEijx37xxRdyuVwqLi7WokWLfI4ZNWqUMjMzrU4TAAAACBiWQ7gkhYaGKjU1VampqRcdV1xc7PX3xMREr+0qAAAAwOXA8p5wAAAAAP4hhAMAAACGEcIBAAAAwwjhAAAAgGGEcAAAAMAwQjgAAABgGCEcAAAAMIwQDgAAABhGCAcAAAAMI4QDAAAAhhHCAQAAAMMI4QAAAIBhhHAAAADAMEI4AAAAYBghHAAAADCMEA4AAAAYRggHAAAADCOEAwAAAIYRwgEAAADDCOEAAACAYYRwAAAAwDBCOAAAAGAYIRwAAAAwjBAOAAAAGEYIBwAAAAwjhAMAAACGEcIBAAAAwwjhAAAAgGGEcAAAAMAwQjgAAABgGCEcAAAAMIwQDgAAABhGCAcAAAAMI4QDAAAAhhHCAQAAAMMI4QAAAIBhhHAAAADAMEI4AAAAYBghHAAAADCMEA4AAAAYRggHAAAADCOEAwAAAIYRwgEAAADDCOEAAACAYYRwAAAAwDBCOAAAAGAYIRwAAAAwjBAOAAAAGEYIBwAAAAwjhAMAAACGEcIBAAAAwwjhAAAAgGGEcAAAAMAwQjgAAABgGCEcAAAAMIwQDgAAABhGCAcAAAAMI4QDAAAAhhHCAQAAAMMI4QAAAIBhhHAAAADAMEI4AAAAYBghHAAAADCMEA4AAAAYRggHAAAADCOEAwAAAIYRwgEAAADDCOEAAACAYYRwAAAAwDBCOAAAAGAYIRwAAAAwjBAOAAAAGEYIBwAAAAwjhAMAAACGEcIBAAAAwwjhAAAAgGGEcAAAAMAwQjgAAABgGCEcAAAAMKxLS5zk1KlTWr16tXbt2qUjR46oZ8+eio+PV0pKiiIjIy95fGFhoV5//XUVFhaqtrZWgwYN0rRp0zR9+nR16sTPCQAAAOhYLIfwqqoqzZgxQ06nU8nJyYqJiVFpaak2bNig/Px85eTkqFevXo0ev2fPHj3yyCOKiorSvHnz1LNnT+3cuVP/+Z//qdLSUj311FNWpwgAAAAEFMshPDMzU8XFxVq2bJmmT5/uaXc4HJo/f77S09O1ZMkSn8e6XC4999xz6tatm7KystS7d29J0uTJk/XYY4/p7bff1pQpUxQdHW11mgAAAEDAsLzXIzc3VyEhIZoyZYpX+/jx4xUVFaXc3Fy5XC6fx/7jH//Q119/rYkTJ3oCuNvMmTPlcrn03//931anCAAAAAQUSyG8oqJCJSUlcjgcCgoK8uqz2WyKi4vTsWPHdPDgQZ/Hf/rpp5KkoUOHNuiLi4vzGgMAAAB0FJa2o7jDdZ8+fXz2R0VFSZIOHDigAQMGNOg/cOBAo8eHhoaqR48enjGXUlRU1KRxLWlL4VFt/bxCNWf3G3m8tniOLa26ulpSx3guJlE3/1Gz5qFuzUPd/EfNmoe6+S9Qa2ZpJbyyslKSFBwc7LPf3V5RUdHs4xs7NhD8d3Glas763mrT0oK72Iw8DgAAAFqfpZVwm+18MGxsz/eF45pzfGPHXsjhcDRpXEu6L+aENhd+p+pWDuKhQZ2VMt4uh+OaVn0cE9w/hbbFv1d7Rt38R82ah7o1D3XzHzVrHurmv5asWUFBgeVzuFkK4WFhYZLO36bQF/dKt3tcc47v3r27lSm2qvuu76n7ru/JCwEAAAB+sbQdpX///rLZbDp06JDP/rKyMknSoEGDfPa794n7Ov7kyZOqqKjQwIEDrUwRAAAACDiWQnhISIgcDoeKiopUU1Pj1VdfX6/CwkL169dPffv29Xn8iBEjJJ3/xMwL7d27V5J0ww03WJkiAAAAEHAs3yc8ISFBNTU12rJli1f79u3bVV5ersTERE+b0+n0uttJdHS0/umf/kl5eXleq+Eul0sbN25Uly5dNHnyZKtTBAAAAAKK5U/MTEpK0o4dO5SWlqaysjLFxsaqpKREGRkZio6O1uzZsz1jJ02apMGDBysvL8/TtmzZMs2aNUvJycl64IEH1KNHD+3YsUMfffSRFi1axHYUAAAAdDiWQ3hQUJAyMjK0Zs0a5eXlKTs7WxEREUpKStLChQsVEhJy0eOHDRum7OxsrVq1SqtXr1ZdXZ2uvfZavfzyy6yCAwAAoEOyHMKl8x+sk5qaqtTU1IuOKy4u9tl+/fXXKz09vSWmAgAAAAQ8y3vCAQAAAPiHEA4AAAAYRggHAAAADCOEAwAAAIYRwgEAAADDCOEAAACAYYRwAAAAwDBCOAAAAGAYIRwAAAAwjBAOAAAAGGZzuVyutp6EFQUFBW09BQAAAFxGRo4cafkcrIQDAAAAhrX7lXAAAACgvWElHAAAADCMEA4AAAAYRggHAAAADCOEAwAAAIYRwgEAAADDCOEAAACAYYTwZjh16pSWL1+usWPHKiYmRrfeequWLl2qo0ePtvXUjDp+/LiWL1+uO+64Q3FxcRo3bpyeeOIJ7d+/v8HY2tparV69WnfccYdiY2M1evRoLVq0SKWlpQ3G1tfXa+PGjbr77rs1dOhQjRo1SnPmzNHf//53A8/KvJUrV2rIkCFasmSJV7u/ddi2bZumTJmi4cOHa+TIkZo5c6b+9Kc/mXgKRvzxj3/U9OnTNXz4cI0aNUoPPPCA8vPzG4zjWvvegQMH9OSTT2rChAkaOnSoxo4dqwULFjR4fpdzzc6cOaO0tDRFR0dr5syZPse0Zn3a6+u2KXWrqKjQ6tWrddddd2nYsGGKj4/X3Llz9dlnnzUYeznUrSk1u1BOTo6GDBnS6Hh/6vDhhx9qxowZGjFihIYPH66pU6cqNze32c/HlKbWrbCwUA899JBuuOEGjRgxQtOmTdMHH3zQYFwgXWvcJ9xPVVVVSkpKktPpVHJysmJiYlRaWqoNGzYoIiJCOTk56tWrV1tPs9UdP35cU6dO1fHjx3X//fcrOjpapaWl2rRpk86ePavs7Gxdf/31kqRz587poYce0l/+8hclJibqpptu0pEjR5SRkaFz587pnXfe0aBBgzzn/o//+A/95je/0bhx4zRhwgSdOnVKmzZt0pEjR7Rp0yYNHz68rZ52iyspKVFCQoLq6uqUkJCgFStWePr8qcPrr7+uVatWadSoUbrnnntUX1+v7OxsFRcX67XXXtOdd97ZFk+vxeTk5Gjp0qUaPXq07r77blVUVOitt97SkSNHtH79et10002SuNZ+6IsvvlBycrKuuOIKJScn6+qrr9a3336rrKwsHTlyRGvWrNHYsWMv65rt379f//qv/6qvv/5aVVVVGjVqlDIzM73GtGZ92uvrtil1q66uVnJysvbt26f77rtPI0aM8NSgvLxcb7zxhsaMGeMZ39Hr1pSaXejYsWOaNGmSTp486XO8P3XYtm2bUlNTFR0drWnTpikoKEjbtm3Txx9/rCVLluhf/uVfWuV5W9XUuv35z3/WnDlzNGTIEE2bNk0ul0tZWVkqLi5WWlqa7r33Xs/YgLrWXPDLunXrXHa73bV582av9p07d7rsdrvrpZdeaqOZmfXMM8+47Ha7a+fOnV7tu3btctntdteCBQs8bbm5uS673e5KS0vzGvv3v//dNWTIENf8+fM9bX/7299cdrvdtWjRIq+x33zzjWvYsGGuhISEln8ybaS+vt41bdo017333uuy2+2u1NRUT58/dSgrK3Ndf/31rmnTprnq6+s97adPn3b99Kc/dd1yyy2u2traVn8+reXo0aOuYcOGuebOnes6d+6cp/3//u//XD/5yU9cK1as8LRxrX3v8ccfd9ntdtfu3bu92p1Op8tut7vuuecel8t1+dbsxIkTrri4ONc999zjqcmMGTMajGut+rTX121T65aenu6y2+2ujIwMr/aioiKX3W53JSYmeto6et2aWrMLpaSkuG655RbXzTff3GC8P3WoqKhwjRo1yjV27FhXZWWlZ2xdXZ0rISHBNXToUNfRo0db6Nm2nKbWraamxhUfH++aPHmy17/9yZMnXWPGjHE98cQTnrZAu9bYjuKn3NxchYSEaMqUKV7t48ePV1RUlHJzc+W6DH65EBkZqbvuukvjx4/3ar/11ltls9n05Zdfetrcv+6aNWuW19iYmBgNHz5cf/jDH3T69OmLju3Tp4/GjRunzz//XF999VWLP5+2kJ2drU8++aTBNhTJvzq8//77qqurU3Jysjp1+v4lHRYWpoSEBB09elR79uxpxWfSut59911VVVUpJSVFNpvN0z5w4EDt2bNHqampnjaute8dPHhQknTDDTd4tV9zzTUKDw/XN998I+nyrVldXZ3uvfdevfPOO7rmmmsaHdda9Wmvr9um1i00NFR33HGH7rvvPq/26Oho9e7du0nfIzpK3Zpasx/68MMP9d5772nx4sXq2rVrg35/6vCnP/1JJ06c0NSpUxUSEuIZ26VLF91///2qqanxuW2jrTW1brt27dKhQ4c0b948BQUFedp79OihP/zhD/rlL3/paQu0a40Q7oeKigqVlJTI4XB4/UNLks1mU1xcnI4dO+b55teRzZ8/X6+88opXKJLO18jlcqlHjx6etsLCQkVFRemqq65qcJ5hw4aprq5O//jHPzxjO3XqpJiYGJ9j3WPau8OHD+uVV17Rfffdp5/85CcN+v2pw6effipJiouLu+TY9mjPnj2KjIxUdHS0pPP7+c6cOeNzLNfa96677jpJarBvuaKiQidPntS1114r6fKt2Y9+9CM999xzPgPOD7VWfdrr67apdUtOTtaqVavUvXt3r/b6+npVV1c3+B7RkevW1Jq5VVZW6rnnntPo0aOVmJjoc4w/dbjYWHebe0wgaWrd9uzZo06dOumWW26RJLlcLtXW1vocG2jXGiHcD+5w3adPH5/9UVFRks6/GepytWXLFkny7JOqqKjQiRMnLlkzd20PHjyoiIiIBj/k/HBsR6jvc889p+DgYK9V3B/ypw7u/7vbf8hd9/Zcs6+++koDBw5UYWGhpk+frtjYWMXGxmrixInavn27ZxzXmre5c+eqe/fuSk1NVX5+vo4eParPP/9cixcvVqdOnbRo0SJqdgmtWZ+O/rptzI4dO3T69GmvvbTUzdurr76q8vJyPf/8842O8acOHb1mX331lXr37q1Dhw7p4YcfVmxsrIYOHarbbrtNGzdu9NqdEGjXGiHcD5WVlZKk4OBgn/3u9oqKCmNzCiR//OMftXbtWg0ZMkTJycmSLl0z96/G3DWrrKz0+nWZr7Huc7ZXeXl5+v3vf6+lS5fqyiuv9DnGnzpUVlaqS5cuPr+odIRr8sSJEzp+/Lgef/xx3XzzzVq7dq2eeeYZVVVV6d///d+1detWSVxrF7Lb7crOztbZs2f1wAMP6NZbb1ViYqKKioq0fv16jR49mppdQmvWp6O/bn35/PPP9fzzz+uqq67SvHnzPO3U7XufffaZNm/erHnz5mngwIGNjvOnDu7a+apxR6jZiRMnVF9fr9mzZ+vHP/6xVq1apeXLlyskJEQvvfSSXn31Vc/YQLvWulg6+jLj3npxqT3fF27RuBxs27ZNTz31lKKiorRu3boGvz5qas1sNluH3lN/6tQpvfDCCxozZowmTZrU6Dh/6tCUse35mjx79qxKS0uVnp7udTeF+Ph4TZw4Ua+99prXezS41s5zOp2aO3euXC6XnnrqKQ0cOFDffvutMjMz9eijj2rVqlWy2+2SqNmltEZ9Ovrr9kJ//vOftWDBAl1xxRVKT09XeHi4p4+6nVdXV6elS5fKbrdr9uzZFx3rTx2akl3aa82k898jjh49qmeeecazACid/438hAkTtGHDBj344IMKDw8PuGuNlXA/hIWFSTp/m0Jf3D89ucddLl5//XWlpqbKbrcrKytLffv29fT5W7PQ0NBLjr1wj2F7kpaWpsrKSi1btuyi4/ypQ2hoqOrr633ugesINQsODlZISIhXAJek/v37a9SoUSovL5fT6eRau8DSpUt1/PhxZWZmaubMmYqPj9c///M/KysrS2FhYXryyScVGhoqiZo1pjWvqY7+uv2hnJwczZkzR+Hh4crKypLD4fDqp27nvfnmm3I6nXrhhRfUpcvF10j9qYP7+vT1W6r2XjPp+1XpiRMnerWHhYVpwoQJqqur8+zvDrRrjRDuh/79+8tms+nQoUM++8vKyiTJ656xHd3y5cu1atUq3X777dq8ebN69+7t1R8aGqqIiAjPnRgu5N5L6a7ZwIEDVV5e7vOib+/1/fjjj5WTk6OHHnpInTp10uHDhz3/Sefvq3v48GGdPHnSrzq4f2Xpq8busRf7tWag69+/vzp37uyz70c/+pGk878S5Fr7XkVFhT755BNFR0erf//+Xn3du3fXjTfeqKNHj6qsrIyaXURrXlMd/XXrtnHjRi1dulRxcXF65513PG8I/iHqdv4N1G+88YYSEhIUGRnp9f3B/Wb0w4cPq7y8XJJ/dRgwYIAk+cwu7blmbu6vcb6+T/zwe4QUeNcaIdwPISEhcjgcKioqUk1NjVdffX29CgsL1a9fP6+V4I7s9ddf16ZNm5SUlKSVK1c2um9yxIgRnm/4FyooKFC3bt0871QeMWKEzp075/Od2nv37pUkjRw5sgWfhTn5+flyuVxavXq14uPjvf6Tzu8Vj4+P10svveRXHUaMGCHJ97u03WMvvE1dezJ8+HCdPn3a512H3F8c3T/8ca2d5757TGN3CHB//aqrq6Nml9Ba9enor1vp/DbFFStW6LbbblNGRobXFpQfom7S3/72N9XW1ionJ6fB94fDhw+rsLBQ8fHxWrRokST/6tBRa+bm/nCdffv2Nejz9T0ikK41QrifEhISVFNT47kLiNv27dtVXl7e6O2EOpr8/HzPxzg/++yzXvfQvFBCQoIkKSMjw6v9r3/9q7744gtNmjTJE+AnT54sm82mjRs3eo3dv3+/PvzwQ910002en+rbm7vuukvr1q3z+Z8kjR49WuvWrdODDz7oVx0mTpyobt26KTMzU2fPnvWMLS8v17Zt23T11VfrxhtvNPY8W5r7NbV27Vqv9n379mnv3r267rrrPCshXGvnhYeHa8CAASopKfG6H7MkfffddyooKFBoaKh+/OMfU7NLaK36dPTXrdPp1DPPPKNhw4Zp1apVF73NHHWTbr755ka/P0RERMhut2vdunVavHixJP/qcOuttyoyMlK//vWvvd5IWFtbq6ysLF155ZW6/fbbzT7hFnTXXXcpKChI69at89rDfeTIEX3wwQfq2bOn5zaDgXat8cZMPyUlJWnHjh1KS0tTWVmZYmNjVVJSooyMDEVHR1/yzRQdRVpamqTzXzgau8l/fHy8goODNW7cOI0fP16ZmZmqqKjQ6NGjVVZWpg0bNigqKsrzRUWSHA6HZs2apbfeekuPPvqo7rzzTn333XfasGGDunbtqqefftrI82sNgwcP1uDBgxvtj4qK0m233eb5e1PrEBkZqcWLF+vFF1/UrFmzlJiYqNraWmVmZqqyslIrV65sdDtHezB06FDNmjVLmzZtUnV1teLj41VWVqa33npLnTt31lNPPeUZy7X2vSVLlmjBggWaOXOmkpOTNXDgQB0/flxbt27ViRMn9Oyzz6pr166Xbc2++uqrBh8sVF5erry8PM/f4+PjW60+7fV129S6vfbaa6qtrVV8fLx+//vf+zzXqFGjFB4e3uHr1tSa/fDr/w9169ZNPXv29Or3pw5du3bVsmXLtGDBAt1///2aPn26unTpoq1bt+rrr7/Wyy+/HJB7wptatz59+ugXv/iFXnrpJT388MO66667PO+Hqa6u1rJly9StWzdJgfcatbkux7e6W1RZWak1a9YoLy9PR48eVUREhCZMmKCFCxd6fQBBRzZkyJBLjtm1a5dnhfLMmTNav369tm3bprKyMvXo0UM/+9nP9MQTTzT4EAyXy6Xs7GxlZ2ertLRUISEhGjVqlFJSUnzuJ+wIhgwZooSEBK1YscLT5m8d3nvvPWVkZKikpESdO3fWsGHDtGDBAs+HCrRnLpdLW7ZsUXZ2tr7++mt17dpVw4cP1/z58xt8kALX2vcKCgq0fv16ffLJJzp58qTCwsIUExOjBx54wLMNSro8a7Z69WqtWbPmomPcX8Nasz7t7XXb1LrNmjXL5xaeH9q0aZNuuukmSR27bv5ca76MHTtW/fr1U2ZmZoM+f+qwZ88erV271vPhUg6HQ3PnzvX6WhBI/K3b+++/r4yMDH355Zey2Wy6/vrr9cgjjzR4foF0rRHCAQAAAMPYEw4AAAAYRggHAAAADCOEAwAAAIYRwgEAAADDCOEAAACAYYRwAAAAwDBCOAAAAGAYIRwAAAAwjBAOAAAAGEYIBwAAAAwjhAMAAACGEcIBAAAAwwjhAAAAgGGEcAAAAMAwQjgAAABgGCEcAAAAMIwQDgAAABj2/wARDYcUno0AAgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 244,
       "width": 368
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [0] + [result.time for result in evolution.results]\n",
    "x += [x[-1] + (x[-1] - x[-2]) / 10]\n",
    "y = [0, 0] + [result.best_val_metric for result in evolution.results]\n",
    "plt.step(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: 90.7 s, best val metric 0.7005, [(1, 0.7005, 0.7005, 0.0016639530398982313, 0.00038824380766863036, 37, [20, 20, 20, 20, 20]), (1, 0.7005, 0.7005, 0.0016639530398982313, 0.00038824380766863036, 37, [20, 20, 20, 20, 20]), (1, 0.6802, 0.6802, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6802, 0.6802, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6751, 0.6751, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6751, 0.6751, 0.0006047455983630011, 0.00041815167120119213, 29, [20, 20, 20, 20, 20]), (1, 0.6751, 0.6751, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6701, 0.6701, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6599, 0.6599, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6396, 0.6396, 0.0004848743834409068, 0.0003991010436554287, 28, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.700507614213198 ####\n",
      "Generation 1: 110.9 s, best val metric 0.802, [(2, 0.802, 0.802, 0.00040782169110330674, 0.000365915418284352, 30, [20, 20, 20, 20, 20]), (2, 0.7766, 0.7766, 6.572851301726554e-05, 0.0003793718468947482, 34, [20, 20, 20, 36, 31]), (2, 0.7766, 0.7766, 6.572851301726554e-05, 0.0003793718468947482, 34, [20, 20, 20, 36, 31]), (2, 0.7716, 0.7716, 0.001615510211667519, 0.0004133923172568234, 21, [20, 20, 20, 20, 20]), (2, 0.7716, 0.7716, 0.001615510211667519, 0.0004133923172568234, 21, [20, 20, 20, 20, 20]), (2, 0.7716, 0.7716, 0.001615510211667519, 0.0004133923172568234, 21, [20, 20, 20, 20, 20]), (2, 0.7513, 0.7513, 0.0004848743834409068, 0.0003991010436554287, 28, [20, 20, 20, 20, 20]), (2, 0.7462, 0.7462, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7462, 0.7462, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7462, 0.7462, 0.00019319892271967403, 0.0003934459406665044, 28, [20, 20, 20, 20, 20]), (2, 0.7005, 0.7005, 0.0016639530398982313, 0.00038824380766863036, 37, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8020304568527918 ####\n",
      "Generation 2: 108.9 s, best val metric 0.802, [(3, 0.802, 0.802, 0.00040782169110330674, 0.000365915418284352, 30, [20, 20, 20, 20, 20]), (3, 0.797, 0.797, 0.00019319892271967403, 0.0003934459406665044, 28, [20, 20, 20, 20, 21]), (3, 0.797, 0.797, 0.00019319892271967403, 0.0003934459406665044, 28, [20, 20, 20, 20, 21]), (3, 0.797, 0.797, 7.529303252274798e-05, 0.00035763653500819155, 25, [20, 36, 20, 56, 45]), (3, 0.7868, 0.7868, 0.0025496532120557348, 0.00038333036438999174, 26, [20, 20, 20, 20, 20]), (3, 0.7817, 0.7817, 0.0004848743834409068, 0.0003991010436554287, 28, [20, 20, 20, 20, 20]), (3, 0.7766, 0.7766, 0.00022129070968056466, 0.00038489077581615913, 29, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 0.000211365367896776, 0.00038463727589108484, 32, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 0.0016639530398982313, 0.00038824380766863036, 37, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 0.000211365367896776, 0.00038463727589108484, 32, [20, 20, 20, 20, 20]), (3, 0.7614, 0.7614, 0.00020859614932052106, 0.00038717525356121864, 26, [20, 20, 20, 20, 21])]\n",
      "#### Overall best val metric 0.8020304568527918 ####\n",
      "Generation 3: 82.2 s, best val metric 0.8122, [(4, 0.8122, 0.8122, 0.00042093004094800933, 0.0003987390452666319, 33, [20, 20, 20, 20, 20]), (4, 0.8122, 0.8122, 0.00042093004094800933, 0.0003987390452666319, 33, [20, 20, 20, 20, 20]), (4, 0.8122, 0.8122, 0.00042093004094800933, 0.0003987390452666319, 33, [20, 20, 20, 20, 20]), (4, 0.8122, 0.8122, 0.00042093004094800933, 0.0003987390452666319, 33, [20, 20, 20, 20, 20]), (4, 0.8122, 0.8122, 0.00045697160744101196, 0.00039181284152126257, 33, [20, 20, 20, 20, 20]), (4, 0.802, 0.802, 0.00040782169110330674, 0.000365915418284352, 30, [20, 20, 20, 20, 20]), (4, 0.7919, 0.7919, 0.000211365367896776, 0.00038463727589108484, 32, [20, 20, 20, 22, 33]), (4, 0.7817, 0.7817, 7.529303252274798e-05, 0.00035763653500819155, 25, [20, 33, 22, 59, 44]), (4, 0.7817, 0.7817, 0.0007855939819701075, 0.00036891617315653246, 34, [20, 20, 20, 20, 20]), (4, 0.7817, 0.7817, 0.0007855939819701075, 0.00036891617315653246, 34, [20, 20, 20, 20, 20]), (4, 0.7563, 0.7563, 0.00019319892271967403, 0.0003934459406665044, 28, [20, 20, 20, 20, 21])]\n",
      "#### Overall best val metric 0.8121827411167513 ####\n",
      "Generation 4: 123.4 s, best val metric 0.8173, [(5, 0.8173, 0.8173, 0.0007855939819701075, 0.00036891617315653246, 34, [20, 20, 20, 20, 20]), (5, 0.8173, 0.8173, 0.0007855939819701075, 0.00036891617315653246, 34, [20, 20, 20, 20, 20]), (5, 0.8122, 0.8122, 0.000211365367896776, 0.00038463727589108484, 32, [20, 20, 20, 20, 39]), (5, 0.8122, 0.8122, 0.00042093004094800933, 0.0003987390452666319, 33, [20, 20, 20, 20, 20]), (5, 0.802, 0.802, 0.0002132315251538191, 0.00040597841698055255, 32, [20, 20, 20, 20, 24]), (5, 0.802, 0.802, 0.0007855939819701075, 0.00036891617315653246, 34, [20, 20, 20, 20, 20]), (5, 0.802, 0.802, 0.0002132315251538191, 0.00040597841698055255, 32, [20, 20, 20, 20, 24]), (5, 0.797, 0.797, 0.00045697160744101196, 0.00039181284152126257, 33, [20, 20, 20, 20, 20]), (5, 0.797, 0.797, 0.00023309523791017377, 0.0003831788886746897, 27, [20, 20, 20, 20, 33]), (5, 0.7817, 0.7817, 0.0018747393992109658, 0.0003719103908044418, 35, [20, 20, 20, 20, 20]), (5, 0.7817, 0.7817, 5.8744891119045245e-05, 0.00036617656620051303, 33, [20, 34, 26, 40, 37])]\n",
      "#### Overall best val metric 0.817258883248731 ####\n",
      "Generation 5: 134.0 s, best val metric 0.8173, [(6, 0.8173, 0.8173, 0.0007855939819701075, 0.00036891617315653246, 34, [20, 20, 20, 20, 20]), (6, 0.8071, 0.8071, 0.0004522431178262824, 0.0003828417688370498, 36, [20, 20, 20, 20, 20]), (6, 0.8071, 0.8071, 0.0010167653890729572, 0.00043289401123012053, 29, [20, 20, 20, 20, 20]), (6, 0.8071, 0.8071, 0.0004522431178262824, 0.0003828417688370498, 36, [20, 20, 20, 20, 20]), (6, 0.8071, 0.8071, 0.0002132315251538191, 0.00040597841698055255, 32, [20, 20, 20, 27, 27]), (6, 0.8071, 0.8071, 0.0002132315251538191, 0.00040597841698055255, 32, [20, 20, 20, 27, 27]), (6, 0.797, 0.797, 0.00040321210731636734, 0.0004206570973494692, 33, [20, 20, 20, 20, 20]), (6, 0.797, 0.797, 0.0007855939819701075, 0.00036891617315653246, 34, [20, 20, 20, 20, 20]), (6, 0.797, 0.797, 0.0007855939819701075, 0.00036891617315653246, 34, [20, 20, 20, 20, 20]), (6, 0.7868, 0.7868, 0.00019722989136283507, 0.0004020986995694231, 32, [20, 20, 20, 21, 33]), (6, 0.7868, 0.7868, 0.00031063586311961785, 0.00033730032971523977, 35, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.817258883248731 ####\n",
      "Generation 6: 101.0 s, best val metric 0.8223, [(7, 0.8223, 0.8223, 9.705121418257995e-05, 0.0003570094597970618, 29, [20, 20, 20, 40, 38]), (7, 0.8173, 0.8173, 3.1622776601683795e-05, 0.0004077522749444553, 38, [21, 40, 40, 40, 40]), (7, 0.8173, 0.8173, 3.1622776601683795e-05, 0.0004077522749444553, 38, [21, 40, 40, 40, 40]), (7, 0.8173, 0.8173, 0.0007855939819701075, 0.00036891617315653246, 34, [20, 20, 20, 20, 20]), (7, 0.8122, 0.8122, 0.0008602168390057145, 0.00037581852769219635, 34, [20, 20, 20, 20, 20]), (7, 0.8122, 0.8122, 0.00036102982325601324, 0.0003786610835061082, 29, [20, 20, 20, 20, 21]), (7, 0.8071, 0.8071, 0.0007855939819701075, 0.00036891617315653246, 34, [20, 20, 20, 20, 20]), (7, 0.8071, 0.8071, 0.0007855939819701075, 0.00036891617315653246, 34, [20, 20, 20, 20, 20]), (7, 0.802, 0.802, 0.0004522431178262824, 0.0003828417688370498, 36, [20, 20, 20, 20, 20]), (7, 0.7919, 0.7919, 0.0002132315251538191, 0.00040597841698055255, 32, [20, 20, 20, 26, 29]), (7, 0.7868, 0.7868, 0.0010167653890729572, 0.00043289401123012053, 29, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8223350253807107 ####\n",
      "Generation 7: 74.1 s, best val metric 0.8223, [(8, 0.8223, 0.8223, 0.00012219093271490636, 0.00041927414822769116, 34, [20, 34, 37, 44, 41]), (8, 0.8223, 0.8223, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 39, 29, 40, 40]), (8, 0.8223, 0.8223, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 39, 29, 40, 40]), (8, 0.8223, 0.8223, 9.705121418257995e-05, 0.0003570094597970618, 29, [20, 20, 20, 40, 38]), (8, 0.8173, 0.8173, 3.1622776601683795e-05, 0.0004077522749444553, 38, [29, 60, 60, 60, 60]), (8, 0.8173, 0.8173, 3.1622776601683795e-05, 0.0004077522749444553, 38, [29, 60, 60, 60, 60]), (8, 0.8122, 0.8122, 0.0007855939819701075, 0.00036891617315653246, 34, [20, 20, 20, 20, 20]), (8, 0.8071, 0.8071, 0.00017519454709553553, 0.00036963480355753413, 36, [20, 20, 20, 24, 35]), (8, 0.8071, 0.8071, 9.705121418257995e-05, 0.0003570094597970618, 29, [20, 22, 20, 58, 54]), (8, 0.8071, 0.8071, 8.553272741017027e-05, 0.0003612103115653958, 37, [20, 23, 21, 40, 40]), (8, 0.7868, 0.7868, 0.0007855939819701075, 0.00036891617315653246, 34, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8223350253807107 ####\n",
      "Generation 8: 83.8 s, best val metric 0.8223, [(9, 0.8223, 0.8223, 0.00033421783827213697, 0.0004136713642706353, 41, [20, 20, 20, 39, 38]), (9, 0.8223, 0.8223, 0.00012219093271490636, 0.00041927414822769116, 34, [20, 34, 37, 44, 41]), (9, 0.8122, 0.8122, 8.553272741017027e-05, 0.0003612103115653958, 37, [20, 26, 21, 59, 56]), (9, 0.8122, 0.8122, 0.00021416035457666604, 0.00039314107465711286, 35, [20, 21, 20, 40, 42]), (9, 0.8122, 0.8122, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 59, 43, 60, 60]), (9, 0.8122, 0.8122, 0.00021416035457666604, 0.00039314107465711286, 35, [20, 21, 20, 40, 42]), (9, 0.802, 0.802, 3.1622776601683795e-05, 0.0004077522749444553, 38, [36, 80, 80, 80, 80]), (9, 0.802, 0.802, 3.1622776601683795e-05, 0.0004077522749444553, 38, [36, 80, 80, 80, 80]), (9, 0.802, 0.802, 0.00023836210287654674, 0.00035393241736468735, 35, [20, 34, 26, 50, 23]), (9, 0.802, 0.802, 9.705121418257995e-05, 0.0003570094597970618, 29, [20, 25, 20, 57, 53]), (9, 0.7868, 0.7868, 0.00017519454709553553, 0.00036963480355753413, 36, [20, 22, 20, 22, 36])]\n",
      "#### Overall best val metric 0.8223350253807107 ####\n",
      "Generation 9: 95.4 s, best val metric 0.8223, [(10, 0.8223, 0.8223, 0.00033421783827213697, 0.0004136713642706353, 41, [20, 20, 20, 39, 38]), (10, 0.8173, 0.8173, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (10, 0.8173, 0.8173, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (10, 0.8173, 0.8173, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (10, 0.8173, 0.8173, 0.00012132508469386062, 0.00039685991418437214, 40, [25, 64, 54, 80, 58]), (10, 0.8173, 0.8173, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (10, 0.8173, 0.8173, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (10, 0.8173, 0.8173, 3.1622776601683795e-05, 0.0004077522749444553, 38, [48, 100, 100, 100, 100]), (10, 0.8122, 0.8122, 0.0003152595499704371, 0.0003762736599578165, 37, [20, 20, 20, 25, 24]), (10, 0.8122, 0.8122, 3.310925845057965e-05, 0.00037210628957368424, 27, [37, 41, 40, 60, 62]), (10, 0.7817, 0.7817, 0.00021416035457666604, 0.00039314107465711286, 35, [20, 20, 20, 40, 52])]\n",
      "#### Overall best val metric 0.8223350253807107 ####\n",
      "Generation 10: 66.6 s, best val metric 0.8274, [(11, 0.8274, 0.82, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (11, 0.8274, 0.82, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (11, 0.8274, 0.82, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (11, 0.8274, 0.82, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (11, 0.8223, 0.815, 0.0003638825773846755, 0.0004044825824230376, 35, [20, 20, 20, 39, 38]), (11, 0.8223, 0.815, 0.00033421783827213697, 0.0004136713642706353, 41, [20, 20, 20, 39, 38]), (11, 0.8122, 0.8049, 0.00028446044528995356, 0.0003742889196091425, 38, [25, 64, 54, 80, 58]), (11, 0.8071, 0.7999, 0.0006047476424517655, 0.0004047519777955345, 38, [20, 69, 54, 80, 80]), (11, 0.8071, 0.7999, 0.0006047476424517655, 0.0004047519777955345, 38, [20, 69, 54, 80, 80]), (11, 0.802, 0.7949, 3.310925845057965e-05, 0.00037210628957368424, 27, [37, 41, 40, 60, 62]), (11, 0.802, 0.7949, 0.00033421783827213697, 0.0004136713642706353, 41, [20, 20, 20, 39, 38])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 11: 63.8 s, best val metric 0.8274, [(12, 0.8274, 0.8142, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (12, 0.8223, 0.8092, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (12, 0.8223, 0.8092, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (12, 0.8223, 0.8092, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (12, 0.8223, 0.8092, 0.00015384022421289058, 0.00038453441722855055, 37, [20, 69, 54, 80, 80]), (12, 0.8173, 0.8042, 0.0001216209546943416, 0.00042894916719769604, 39, [20, 69, 54, 80, 80]), (12, 0.8173, 0.8042, 0.0001216209546943416, 0.00042894916719769604, 39, [20, 69, 54, 80, 80]), (12, 0.8173, 0.8042, 0.0001216209546943416, 0.00042894916719769604, 39, [20, 69, 54, 80, 80]), (12, 0.8173, 0.8042, 0.0006047476424517655, 0.0004047519777955345, 38, [20, 69, 54, 80, 80]), (12, 0.8173, 0.8042, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (12, 0.7919, 0.7793, 0.0005985498727694027, 0.00038247845662326937, 40, [25, 64, 54, 80, 58])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 12: 71.2 s, best val metric 0.8274, [(13, 0.8274, 0.804, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (13, 0.8223, 0.799, 0.00015384022421289058, 0.00038453441722855055, 37, [20, 69, 54, 80, 80]), (13, 0.8223, 0.799, 0.00015384022421289058, 0.00038453441722855055, 37, [20, 69, 54, 80, 80]), (13, 0.8173, 0.7941, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (13, 0.8173, 0.7941, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (13, 0.8173, 0.7941, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (13, 0.802, 0.7793, 0.0001216209546943416, 0.00042894916719769604, 39, [20, 69, 54, 80, 80]), (13, 0.802, 0.7793, 0.0005985498727694027, 0.00038247845662326937, 40, [25, 64, 54, 80, 58]), (13, 0.797, 0.7744, 0.00017777746929870125, 0.0004461059130740915, 36, [20, 69, 54, 80, 80]), (13, 0.7868, 0.7645, 0.0006084094212059441, 0.0004024962890283192, 34, [20, 69, 54, 80, 80]), (13, 0.7868, 0.7645, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 13: 71.8 s, best val metric 0.8274, [(14, 0.8274, 0.7861, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (14, 0.8122, 0.7717, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (14, 0.8122, 0.7717, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (14, 0.8122, 0.7717, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (14, 0.8122, 0.7717, 0.0001403407677599507, 0.00038989938996160405, 34, [20, 69, 54, 80, 80]), (14, 0.8071, 0.7669, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (14, 0.802, 0.762, 0.0006084094212059441, 0.0004024962890283192, 34, [20, 69, 54, 80, 80]), (14, 0.802, 0.762, 0.0006084094212059441, 0.0004024962890283192, 34, [20, 69, 54, 80, 80]), (14, 0.797, 0.7572, 0.00015384022421289058, 0.00038453441722855055, 37, [20, 69, 54, 80, 80]), (14, 0.797, 0.7572, 0.00015384022421289058, 0.00038453441722855055, 37, [20, 69, 54, 80, 80]), (14, 0.7919, 0.7524, 0.0001216209546943416, 0.00042894916719769604, 39, [20, 69, 54, 80, 80])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 14: 72.6 s, best val metric 0.8274, [(15, 0.8274, 0.756, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (15, 0.8173, 0.7467, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (15, 0.8173, 0.7467, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (15, 0.8173, 0.7467, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (15, 0.8173, 0.7467, 0.0002094691015277486, 0.00039563970009951426, 32, [20, 69, 54, 80, 80]), (15, 0.797, 0.7282, 0.0001818044352746214, 0.00037774882260287624, 39, [20, 69, 54, 80, 80]), (15, 0.797, 0.7282, 0.00019807654684019202, 0.0003564532974832783, 39, [20, 69, 54, 80, 80]), (15, 0.797, 0.7282, 0.00026224489209967426, 0.0003820729729590281, 34, [20, 69, 54, 80, 80]), (15, 0.797, 0.7282, 0.00026224489209967426, 0.0003820729729590281, 34, [20, 69, 54, 80, 80]), (15, 0.7919, 0.7235, 0.0001403407677599507, 0.00038989938996160405, 34, [20, 69, 54, 80, 80]), (15, 0.7868, 0.7189, 0.0002370713811227538, 0.0004502000128120818, 29, [20, 69, 54, 80, 80])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 15: 72.1 s, best val metric 0.8274, [(16, 0.8274, 0.7072, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (16, 0.8223, 0.7028, 0.00026224489209967426, 0.0003820729729590281, 34, [20, 69, 54, 80, 80]), (16, 0.8223, 0.7028, 0.00026224489209967426, 0.0003820729729590281, 34, [20, 69, 54, 80, 80]), (16, 0.8173, 0.6985, 0.0001818044352746214, 0.00037774882260287624, 39, [20, 69, 54, 80, 80]), (16, 0.8173, 0.6985, 0.0001818044352746214, 0.00037774882260287624, 39, [20, 69, 54, 80, 80]), (16, 0.8122, 0.6941, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (16, 0.8122, 0.6941, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (16, 0.802, 0.6855, 5.8635614408743667e-05, 0.00036832807103542246, 42, [20, 69, 54, 80, 80]), (16, 0.7919, 0.6768, 0.00012449132320365808, 0.000355578689929842, 31, [20, 69, 54, 80, 80]), (16, 0.7868, 0.6724, 0.0002094691015277486, 0.00039563970009951426, 32, [20, 69, 54, 80, 80]), (16, 0.7868, 0.6724, 0.0002094691015277486, 0.00039563970009951426, 32, [20, 69, 54, 80, 80])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 16: 72.7 s, best val metric 0.8376, [(1, 0.6853, 0.6853, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (17, 0.8376, 0.6413, 0.00012449132320365808, 0.000355578689929842, 31, [20, 69, 54, 80, 80]), (17, 0.8274, 0.6335, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80]), (17, 0.8173, 0.6257, 5.1722430067903535e-05, 0.0003595271646537169, 35, [20, 69, 54, 80, 80]), (17, 0.797, 0.6102, 0.0005569654334444889, 0.000377767955900731, 38, [20, 69, 54, 80, 80]), (17, 0.797, 0.6102, 0.0001818044352746214, 0.00037774882260287624, 39, [20, 69, 54, 80, 80]), (17, 0.797, 0.6102, 0.0005569654334444889, 0.000377767955900731, 38, [20, 69, 54, 80, 80]), (17, 0.7919, 0.6063, 0.0001818044352746214, 0.00037774882260287624, 39, [20, 69, 54, 80, 80]), (17, 0.7919, 0.6063, 0.00017865257341035046, 0.0003576305659485566, 33, [20, 69, 54, 80, 80]), (17, 0.7868, 0.6024, 0.0002094691015277486, 0.00039563970009951426, 32, [20, 69, 54, 80, 80]), (17, 0.7817, 0.5985, 5.4157384150197536e-05, 0.00038683958162221956, 36, [20, 69, 54, 80, 80])]\n",
      "#### Overall best val metric 0.8375634517766497 ####\n",
      "Generation 17: 72.6 s, best val metric 0.8122, [(2, 0.7259, 0.7259, 0.00032141569421332764, 0.0003669429270653397, 40, [20, 20, 20, 20, 20]), (2, 0.6853, 0.6853, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6041, 0.6041, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (18, 0.8122, 0.5237, 0.00017865257341035046, 0.0003576305659485566, 33, [20, 69, 54, 80, 80]), (18, 0.8122, 0.5237, 0.0011243730406132286, 0.0003454324249939298, 30, [20, 69, 54, 80, 80]), (18, 0.8122, 0.5237, 0.00017865257341035046, 0.0003576305659485566, 33, [20, 69, 54, 80, 80]), (18, 0.8122, 0.5237, 0.00017865257341035046, 0.0003576305659485566, 33, [20, 69, 54, 80, 80]), (18, 0.8122, 0.5237, 0.00017865257341035046, 0.0003576305659485566, 33, [20, 69, 54, 80, 80]), (18, 0.8122, 0.5237, 0.00017865257341035046, 0.0003576305659485566, 33, [20, 69, 54, 80, 80]), (18, 0.8122, 0.5237, 0.0011243730406132286, 0.0003454324249939298, 30, [20, 69, 54, 80, 80]), (18, 0.7868, 0.5073, 0.0001818044352746214, 0.00037774882260287624, 39, [20, 69, 54, 80, 80])]\n",
      "#### Overall best val metric 0.8375634517766497 ####\n",
      "Generation 18: 72.4 s, best val metric 0.802, [(3, 0.7665, 0.7665, 0.00032141569421332764, 0.0003669429270653397, 40, [20, 20, 20, 20, 20]), (3, 0.7614, 0.7614, 0.0003525189946826696, 0.00032143599011428533, 30, [20, 20, 20, 20, 20]), (3, 0.7614, 0.7614, 0.0003525189946826696, 0.00032143599011428533, 30, [20, 20, 20, 20, 20]), (3, 0.7462, 0.7462, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7411, 0.7411, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (3, 0.7259, 0.7259, 0.00032141569421332764, 0.0003669429270653397, 40, [20, 20, 20, 20, 20]), (1, 0.6396, 0.6396, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (19, 0.802, 0.4027, 0.0001818044352746214, 0.00037774882260287624, 39, [20, 69, 54, 80, 80]), (19, 0.802, 0.4027, 0.0001818044352746214, 0.00037774882260287624, 39, [20, 69, 54, 80, 80]), (19, 0.7919, 0.3976, 0.0011243730406132286, 0.0003454324249939298, 30, [20, 69, 54, 80, 80]), (19, 0.7919, 0.3976, 0.0011243730406132286, 0.0003454324249939298, 30, [20, 69, 54, 80, 80])]\n",
      "#### Overall best val metric 0.8375634517766497 ####\n",
      "Generation 19: 72.6 s, best val metric 0.7817, [(4, 0.7817, 0.7817, 0.0003525189946826696, 0.00032143599011428533, 30, [20, 20, 20, 20, 20]), (4, 0.7817, 0.7817, 0.00041637807889651494, 0.00033643243374088013, 36, [20, 20, 20, 20, 20]), (3, 0.7766, 0.7766, 0.0005169665325639621, 0.0003505312874018946, 31, [20, 20, 20, 20, 20]), (4, 0.7665, 0.7665, 0.0003525189946826696, 0.00032143599011428533, 30, [20, 20, 20, 20, 20]), (4, 0.7665, 0.7665, 0.00032141569421332764, 0.0003669429270653397, 40, [20, 20, 20, 20, 20]), (4, 0.7411, 0.7411, 0.00032141569421332764, 0.0003669429270653397, 40, [20, 20, 20, 20, 20]), (2, 0.7411, 0.7411, 0.00047811802856368227, 0.000378175316194395, 27, [20, 20, 20, 20, 20]), (2, 0.7411, 0.7411, 0.00047811802856368227, 0.000378175316194395, 27, [20, 20, 20, 20, 20]), (4, 0.7411, 0.7411, 0.00032141569421332764, 0.0003669429270653397, 40, [20, 20, 20, 20, 20]), (3, 0.736, 0.736, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6294, 0.6294, 0.001, 0.0004, 32, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8375634517766497 ####\n",
      "Generation 20: 71.9 s, best val metric 0.7919, [(5, 0.7919, 0.7919, 0.0003525189946826696, 0.00032143599011428533, 30, [20, 20, 20, 20, 20]), (5, 0.7868, 0.7868, 0.00032141569421332764, 0.0003669429270653397, 40, [20, 20, 20, 20, 20]), (5, 0.7868, 0.7868, 0.00032141569421332764, 0.0003669429270653397, 40, [20, 20, 20, 20, 20]), (5, 0.7817, 0.7817, 0.0003525189946826696, 0.00032143599011428533, 30, [20, 20, 20, 20, 20]), (5, 0.7766, 0.7766, 0.0009889703719604137, 0.0003679839061833263, 36, [20, 20, 20, 20, 20]), (5, 0.7766, 0.7766, 0.00014162937539087325, 0.0003858308785754296, 37, [20, 20, 20, 21, 20]), (5, 0.7766, 0.7766, 0.00041779037556834977, 0.00034794273357503075, 29, [20, 20, 20, 20, 20]), (5, 0.7766, 0.7766, 0.0009889703719604137, 0.0003679839061833263, 36, [20, 20, 20, 20, 20]), (4, 0.7766, 0.7766, 0.0031622776601683794, 0.0003556991073732585, 27, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 0.00032956035853469874, 0.00042419276702294786, 29, [20, 20, 20, 20, 22]), (5, 0.7614, 0.7614, 0.0007900518349168742, 0.0003858781342536137, 33, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8375634517766497 ####\n",
      "Generation 21: 70.3 s, best val metric 0.797, [(6, 0.797, 0.797, 0.0001312523143835712, 0.00041870080093711685, 37, [20, 28, 20, 36, 34]), (6, 0.797, 0.797, 3.1622776601683795e-05, 0.0004076623032469741, 36, [21, 40, 40, 40, 40]), (6, 0.7919, 0.7919, 0.00041779037556834977, 0.00034794273357503075, 29, [20, 20, 20, 20, 20]), (6, 0.7919, 0.7919, 0.0003525189946826696, 0.00032143599011428533, 30, [20, 20, 20, 20, 20]), (4, 0.7919, 0.7919, 0.0002076030444545275, 0.0003556656259552989, 38, [20, 20, 20, 20, 22]), (4, 0.7919, 0.7919, 0.0002076030444545275, 0.0003556656259552989, 38, [20, 20, 20, 20, 22]), (6, 0.7919, 0.7919, 0.0003525189946826696, 0.00032143599011428533, 30, [20, 20, 20, 20, 20]), (6, 0.7868, 0.7868, 0.0003525189946826696, 0.00032143599011428533, 30, [20, 20, 20, 20, 20]), (6, 0.7817, 0.7817, 0.00032141569421332764, 0.0003669429270653397, 40, [20, 20, 20, 20, 20]), (6, 0.7817, 0.7817, 0.00014162937539087325, 0.0003858308785754296, 37, [20, 29, 20, 32, 28]), (6, 0.7766, 0.7766, 0.001009819848110608, 0.0003913689004402648, 40, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8375634517766497 ####\n",
      "Generation 22: 74.4 s, best val metric 0.8071, [(7, 0.8071, 0.8071, 0.00022473908313620276, 0.0003323027428232239, 30, [20, 20, 20, 20, 27]), (7, 0.802, 0.802, 0.00012618800732861854, 0.0003610225440936119, 33, [20, 21, 20, 26, 34]), (7, 0.802, 0.802, 0.00022502010275651357, 0.00032845984647040014, 41, [20, 20, 20, 20, 20]), (7, 0.802, 0.802, 0.00012618800732861854, 0.0003610225440936119, 33, [20, 21, 20, 26, 34]), (7, 0.797, 0.797, 0.0003525189946826696, 0.00032143599011428533, 30, [20, 20, 20, 20, 20]), (5, 0.797, 0.797, 0.0002076030444545275, 0.0003556656259552989, 38, [20, 20, 20, 20, 23]), (7, 0.797, 0.797, 0.0003525189946826696, 0.00032143599011428533, 30, [20, 20, 20, 20, 20]), (7, 0.797, 0.797, 0.0001312523143835712, 0.00041870080093711685, 37, [20, 28, 20, 36, 34]), (7, 0.7817, 0.7817, 0.001009819848110608, 0.0003913689004402648, 40, [20, 20, 20, 20, 20]), (7, 0.7817, 0.7817, 0.001009819848110608, 0.0003913689004402648, 40, [20, 20, 20, 20, 20]), (7, 0.7766, 0.7766, 0.0005297970245225805, 0.00035011566039267313, 27, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8375634517766497 ####\n",
      "Generation 23: 71.7 s, best val metric 0.8173, [(8, 0.8173, 0.8173, 0.00022502010275651357, 0.00032845984647040014, 41, [20, 20, 20, 20, 24]), (8, 0.8071, 0.8071, 0.00011548329813161662, 0.00030721682169661577, 32, [20, 20, 20, 37, 26]), (8, 0.8071, 0.8071, 0.00016017344643034094, 0.00038245602466103443, 30, [20, 21, 20, 26, 33]), (8, 0.8071, 0.8071, 0.00011548329813161662, 0.00030721682169661577, 32, [20, 20, 20, 37, 26]), (8, 0.8071, 0.8071, 0.00022473908313620276, 0.0003323027428232239, 30, [20, 20, 20, 20, 27]), (8, 0.802, 0.802, 0.00012618800732861854, 0.0003610225440936119, 33, [20, 26, 20, 29, 42]), (8, 0.797, 0.797, 0.00022473908313620276, 0.0003323027428232239, 30, [20, 20, 20, 20, 28]), (6, 0.797, 0.797, 0.0002076030444545275, 0.0003556656259552989, 38, [20, 20, 20, 20, 23]), (8, 0.797, 0.797, 0.0003525189946826696, 0.00032143599011428533, 30, [20, 20, 20, 20, 20]), (8, 0.797, 0.797, 0.00022473908313620276, 0.0003323027428232239, 30, [20, 20, 20, 20, 28]), (8, 0.797, 0.797, 0.0003525189946826696, 0.00032143599011428533, 30, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8375634517766497 ####\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "evolution = Evolution()\n",
    "hyperparameters = {\n",
    "    'regularization_penalty': Hyperparameter(3., 2.5, 4.5, 0.5),\n",
    "    'learning_rate': Hyperparameter(0.0004, 0.0001, 0.0006, 0.000025),\n",
    "    'batch_size': Hyperparameter(32, 16, 64, 4),\n",
    "}\n",
    "evolution.run(x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test),\n",
    "              layer_sizes=[20, 20, 20, 20, 20], output_neurons=10, hyperparameters=hyperparameters, n_parents=5, population_size=10, \n",
    "              n_generations=50, tournament_size=3, n_introduced=2, age_penalty_period=10, use_static_graph=False, fine_tuning=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1f58b7f190>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 244,
       "width": 366
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [0] + [result.time for result in evolution.results]\n",
    "x += [x[-1] + (x[-1] - x[-2]) / 10]\n",
    "y = [0, 0] + [result.best_val_metric for result in evolution.results]\n",
    "plt.step(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: 68.4 s, best val metric 0.7259, [(1, 0.7259, 0.7259, 4.5260504121845285e-05, 0.00041156713469941124, 23, [20, 39, 40, 40, 40]), (1, 0.7259, 0.7259, 4.5260504121845285e-05, 0.00041156713469941124, 23, [20, 39, 40, 40, 40]), (1, 0.7259, 0.7259, 4.5260504121845285e-05, 0.00041156713469941124, 23, [20, 39, 40, 40, 40]), (1, 0.7259, 0.7259, 4.5260504121845285e-05, 0.00041156713469941124, 23, [20, 39, 40, 40, 40]), (1, 0.7107, 0.7107, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6954, 0.6954, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6904, 0.6904, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6904, 0.6904, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6853, 0.6853, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6701, 0.6701, 0.0029484168277212463, 0.0003986067362190583, 36, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.7258883248730964 ####\n",
      "Generation 1: 76.5 s, best val metric 0.7868, [(2, 0.7868, 0.7868, 4.5260504121845285e-05, 0.00041156713469941124, 23, [20, 57, 56, 60, 57]), (2, 0.7716, 0.7716, 5.481878883723334e-05, 0.00040101728744509684, 29, [20, 35, 26, 40, 37]), (2, 0.7716, 0.7716, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7716, 0.7716, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7716, 0.7716, 5.481878883723334e-05, 0.00040101728744509684, 29, [20, 35, 26, 40, 37]), (2, 0.7513, 0.7513, 4.5260504121845285e-05, 0.00041156713469941124, 23, [21, 54, 58, 60, 57]), (2, 0.7513, 0.7513, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7513, 0.7513, 4.5260504121845285e-05, 0.00041156713469941124, 23, [21, 54, 58, 60, 57]), (2, 0.7513, 0.7513, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7259, 0.7259, 0.0029484168277212463, 0.0003986067362190583, 36, [20, 20, 20, 20, 20]), (2, 0.7259, 0.7259, 4.5260504121845285e-05, 0.00041156713469941124, 23, [20, 39, 40, 40, 40])]\n",
      "#### Overall best val metric 0.7868020304568528 ####\n",
      "Generation 2: 91.7 s, best val metric 0.7919, [(3, 0.7919, 0.7919, 0.00013092606103652207, 0.0004178619564161466, 27, [20, 20, 20, 35, 31]), (3, 0.7919, 0.7919, 0.00013092606103652207, 0.0004178619564161466, 27, [20, 20, 20, 35, 31]), (3, 0.7868, 0.7868, 5.481878883723334e-05, 0.00040101728744509684, 29, [20, 41, 26, 60, 43]), (3, 0.7868, 0.7868, 5.481878883723334e-05, 0.00040101728744509684, 29, [20, 41, 26, 60, 43]), (3, 0.7868, 0.7868, 4.5260504121845285e-05, 0.00041156713469941124, 23, [20, 57, 56, 60, 57]), (3, 0.7766, 0.7766, 0.0002708869740789451, 0.0004214801114652561, 28, [20, 20, 20, 20, 20]), (3, 0.7766, 0.7766, 0.0002708869740789451, 0.0004214801114652561, 28, [20, 20, 20, 20, 20]), (3, 0.7766, 0.7766, 0.0002708869740789451, 0.0004214801114652561, 28, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (3, 0.7665, 0.7665, 5.481878883723334e-05, 0.00040101728744509684, 29, [20, 55, 43, 60, 52]), (3, 0.7665, 0.7665, 0.00010291111811534508, 0.0003792506218127764, 37, [20, 28, 21, 40, 35])]\n",
      "#### Overall best val metric 0.7918781725888325 ####\n",
      "Generation 3: 87.9 s, best val metric 0.8071, [(4, 0.8071, 0.8071, 0.0002708869740789451, 0.0004214801114652561, 28, [20, 20, 20, 20, 20]), (4, 0.797, 0.797, 0.0002708869740789451, 0.0004214801114652561, 28, [20, 20, 20, 20, 22]), (4, 0.7919, 0.7919, 8.487740263295236e-05, 0.00044537269707155307, 24, [20, 36, 20, 40, 39]), (4, 0.7919, 0.7919, 8.487740263295236e-05, 0.00044537269707155307, 24, [20, 36, 20, 40, 39]), (4, 0.7919, 0.7919, 8.487740263295236e-05, 0.00044537269707155307, 24, [20, 36, 20, 40, 39]), (4, 0.7919, 0.7919, 0.00013092606103652207, 0.0004178619564161466, 27, [20, 20, 20, 35, 31]), (4, 0.7868, 0.7868, 0.0002473298938763231, 0.00043141192870308593, 33, [20, 25, 21, 43, 24]), (4, 0.7868, 0.7868, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (4, 0.7868, 0.7868, 0.0002473298938763231, 0.00043141192870308593, 33, [20, 25, 21, 43, 24]), (4, 0.7868, 0.7868, 0.0002473298938763231, 0.00043141192870308593, 33, [20, 25, 21, 43, 24]), (4, 0.7766, 0.7766, 5.740851770745673e-05, 0.00040787102086812664, 36, [20, 64, 59, 79, 58])]\n",
      "#### Overall best val metric 0.8071065989847716 ####\n",
      "Generation 4: 86.9 s, best val metric 0.8071, [(5, 0.8071, 0.8071, 0.0002708869740789451, 0.0004214801114652561, 28, [20, 20, 20, 20, 23]), (5, 0.8071, 0.8071, 0.0002473298938763231, 0.00043141192870308593, 33, [20, 20, 20, 38, 25]), (5, 0.8071, 0.8071, 0.0002708869740789451, 0.0004214801114652561, 28, [20, 20, 20, 20, 23]), (5, 0.8071, 0.8071, 0.0002708869740789451, 0.0004214801114652561, 28, [20, 20, 20, 20, 20]), (5, 0.797, 0.797, 0.00011652735091955304, 0.00043930122681951734, 32, [20, 56, 23, 48, 48]), (5, 0.797, 0.797, 0.0002473298938763231, 0.00043141192870308593, 33, [20, 20, 20, 23, 24]), (5, 0.7919, 0.7919, 8.487740263295236e-05, 0.00044537269707155307, 24, [20, 55, 37, 60, 57]), (5, 0.7919, 0.7919, 0.00013925708215290533, 0.00044803695083720765, 29, [20, 24, 20, 25, 36]), (5, 0.7919, 0.7919, 8.487740263295236e-05, 0.00044537269707155307, 24, [20, 55, 37, 60, 57]), (5, 0.7868, 0.7868, 5.740851770745673e-05, 0.00040787102086812664, 36, [20, 78, 51, 90, 58]), (5, 0.7665, 0.7665, 0.00013092606103652207, 0.0004178619564161466, 27, [20, 20, 20, 33, 35])]\n",
      "#### Overall best val metric 0.8071065989847716 ####\n",
      "Generation 5: 88.5 s, best val metric 0.8173, [(6, 0.8173, 0.8173, 0.0002708869740789451, 0.0004214801114652561, 28, [20, 20, 20, 20, 30]), (6, 0.8173, 0.8173, 0.0002708869740789451, 0.0004214801114652561, 28, [20, 20, 20, 20, 30]), (6, 0.8173, 0.8173, 3.1622776601683795e-05, 0.0004038775761123569, 30, [22, 40, 40, 40, 43]), (6, 0.8173, 0.8173, 0.0002708869740789451, 0.0004214801114652561, 28, [20, 20, 20, 20, 30]), (6, 0.8173, 0.8173, 0.0002708869740789451, 0.0004214801114652561, 28, [20, 20, 20, 20, 30]), (6, 0.8173, 0.8173, 0.0002708869740789451, 0.0004214801114652561, 28, [20, 20, 20, 20, 30]), (6, 0.8122, 0.8122, 0.00027059570112853066, 0.0004252319910635616, 26, [20, 28, 20, 31, 40]), (6, 0.8122, 0.8122, 8.487740263295236e-05, 0.00044537269707155307, 24, [20, 72, 34, 74, 68]), (6, 0.8071, 0.8071, 0.00013925708215290533, 0.00044803695083720765, 29, [20, 39, 20, 31, 39]), (6, 0.8071, 0.8071, 0.00013925708215290533, 0.00044803695083720765, 29, [20, 39, 20, 31, 39]), (6, 0.8071, 0.8071, 0.0002708869740789451, 0.0004214801114652561, 28, [20, 20, 20, 20, 23])]\n",
      "#### Overall best val metric 0.817258883248731 ####\n",
      "Generation 6: 86.1 s, best val metric 0.8223, [(7, 0.8223, 0.8223, 0.0001765209349950247, 0.0004237472901544169, 31, [20, 20, 20, 23, 32]), (7, 0.8173, 0.8173, 0.0007832047829046643, 0.00043871601290731315, 31, [20, 20, 20, 20, 23]), (7, 0.8173, 0.8173, 0.00013925708215290533, 0.00044803695083720765, 29, [20, 40, 21, 41, 41]), (7, 0.8173, 0.8173, 0.00027059570112853066, 0.0004252319910635616, 26, [20, 24, 20, 20, 39]), (7, 0.8173, 0.8173, 0.0007832047829046643, 0.00043871601290731315, 31, [20, 20, 20, 20, 23]), (7, 0.8173, 0.8173, 0.00027059570112853066, 0.0004252319910635616, 26, [20, 24, 20, 20, 39]), (7, 0.8173, 0.8173, 0.0002708869740789451, 0.0004214801114652561, 28, [20, 20, 20, 20, 30]), (7, 0.8122, 0.8122, 6.294840233157154e-05, 0.00039643613160923725, 20, [20, 48, 39, 51, 58]), (7, 0.8122, 0.8122, 0.00011050841750352828, 0.0004183638553306435, 31, [20, 69, 25, 67, 64]), (7, 0.8122, 0.8122, 6.294840233157154e-05, 0.00039643613160923725, 20, [20, 48, 39, 51, 58]), (7, 0.8071, 0.8071, 0.0002708869740789451, 0.0004214801114652561, 28, [20, 20, 20, 20, 30])]\n",
      "#### Overall best val metric 0.8223350253807107 ####\n",
      "Generation 7: 90.2 s, best val metric 0.8376, [(8, 0.8376, 0.8376, 0.0001765209349950247, 0.0004237472901544169, 31, [20, 29, 20, 20, 39]), (8, 0.8223, 0.8223, 7.415097163150424e-05, 0.00041605875976427815, 27, [20, 39, 37, 40, 50]), (8, 0.8223, 0.8223, 0.0001765209349950247, 0.0004237472901544169, 31, [20, 20, 20, 23, 32]), (8, 0.8122, 0.8122, 0.00020311808374733273, 0.00045751506802506174, 30, [20, 20, 20, 21, 42]), (8, 0.8122, 0.8122, 0.00020311808374733273, 0.00045751506802506174, 30, [20, 20, 20, 21, 42]), (8, 0.8122, 0.8122, 0.00020311808374733273, 0.00045751506802506174, 30, [20, 20, 20, 21, 42]), (8, 0.8122, 0.8122, 0.00013925708215290533, 0.00044803695083720765, 29, [20, 47, 21, 42, 60]), (8, 0.8122, 0.8122, 0.00020311808374733273, 0.00045751506802506174, 30, [20, 20, 20, 21, 42]), (8, 0.8071, 0.8071, 0.00027059570112853066, 0.0004252319910635616, 26, [20, 20, 20, 20, 39]), (8, 0.802, 0.802, 0.000542079891843105, 0.00043928809166464286, 29, [20, 20, 20, 20, 24]), (8, 0.7766, 0.7766, 0.0009394097290157683, 0.0004642646707057157, 34, [20, 21, 21, 27, 23])]\n",
      "#### Overall best val metric 0.8375634517766497 ####\n",
      "Generation 8: 78.7 s, best val metric 0.8376, [(9, 0.8376, 0.8376, 0.0001765209349950247, 0.0004237472901544169, 31, [20, 29, 20, 20, 39]), (9, 0.8325, 0.8325, 0.00020311808374733273, 0.00045751506802506174, 30, [20, 20, 20, 20, 43]), (9, 0.8325, 0.8325, 0.00017146296741111825, 0.00042114870377183013, 32, [20, 21, 20, 20, 50]), (9, 0.8325, 0.8325, 0.00020311808374733273, 0.00045751506802506174, 30, [20, 20, 20, 20, 43]), (9, 0.8325, 0.8325, 0.00020311808374733273, 0.00045751506802506174, 30, [20, 20, 20, 20, 43]), (9, 0.8223, 0.8223, 9.612614435386523e-05, 0.0004698360028892021, 33, [20, 39, 27, 43, 50]), (9, 0.8223, 0.8223, 9.612614435386523e-05, 0.0004698360028892021, 33, [20, 39, 27, 43, 50]), (9, 0.8173, 0.8173, 0.00020311808374733273, 0.00045751506802506174, 30, [20, 28, 20, 22, 47]), (9, 0.8173, 0.8173, 0.00020311808374733273, 0.00045751506802506174, 30, [20, 28, 20, 22, 47]), (9, 0.802, 0.802, 0.00032535827456598435, 0.0004283705267583641, 29, [20, 20, 20, 20, 36]), (9, 0.7919, 0.7919, 0.0004542892185945822, 0.00043607335540236475, 28, [20, 20, 20, 20, 27])]\n",
      "#### Overall best val metric 0.8375634517766497 ####\n",
      "Generation 9: 79.8 s, best val metric 0.8376, [(10, 0.8376, 0.8376, 0.0001765209349950247, 0.0004237472901544169, 31, [20, 29, 20, 20, 39]), (10, 0.8274, 0.8274, 0.0007770696652026159, 0.0004355750888176479, 32, [20, 20, 20, 20, 21]), (10, 0.8223, 0.8223, 0.00020311808374733273, 0.00045751506802506174, 30, [20, 20, 20, 24, 50]), (10, 0.8173, 0.8173, 0.0004542892185945822, 0.00043607335540236475, 28, [20, 20, 20, 20, 26]), (10, 0.8122, 0.8122, 0.0001765209349950247, 0.0004237472901544169, 31, [20, 31, 20, 21, 51]), (10, 0.8122, 0.8122, 5.109235969610608e-05, 0.0004795214414003829, 32, [20, 48, 40, 42, 67]), (10, 0.8071, 0.8071, 0.00020311808374733273, 0.00045751506802506174, 30, [20, 21, 20, 24, 57]), (10, 0.797, 0.797, 9.612614435386523e-05, 0.0004698360028892021, 33, [20, 54, 41, 63, 64]), (10, 0.797, 0.797, 9.612614435386523e-05, 0.0004698360028892021, 33, [20, 54, 41, 63, 64]), (10, 0.797, 0.797, 0.00017146296741111825, 0.00042114870377183013, 32, [20, 23, 20, 29, 64]), (10, 0.7919, 0.7919, 0.0002424607877279436, 0.00045572593674365723, 31, [20, 21, 20, 20, 42])]\n",
      "#### Overall best val metric 0.8375634517766497 ####\n",
      "Generation 10: 49.7 s, best val metric 0.8376, [(11, 0.8376, 0.8301, 0.0001765209349950247, 0.0004237472901544169, 31, [20, 29, 20, 20, 39]), (11, 0.8223, 0.815, 5.109235969610608e-05, 0.0004795214414003829, 32, [20, 48, 40, 42, 67]), (11, 0.8122, 0.8049, 0.0002424607877279436, 0.00045572593674365723, 31, [20, 21, 20, 20, 42]), (11, 0.8122, 0.8049, 0.0002424607877279436, 0.00045572593674365723, 31, [20, 21, 20, 20, 42]), (11, 0.8122, 0.8049, 0.0002424607877279436, 0.00045572593674365723, 31, [20, 21, 20, 20, 42]), (11, 0.8071, 0.7999, 0.00030455534577405026, 0.0004150884628890312, 33, [20, 21, 20, 20, 42]), (11, 0.8071, 0.7999, 0.00048762384383192026, 0.00047205728390945477, 40, [20, 48, 40, 42, 67]), (11, 0.8071, 0.7999, 0.00020311808374733273, 0.00045751506802506174, 30, [20, 20, 20, 24, 50]), (11, 0.8071, 0.7999, 0.00048762384383192026, 0.00047205728390945477, 40, [20, 48, 40, 42, 67]), (11, 0.797, 0.7898, 0.0001765209349950247, 0.0004237472901544169, 31, [20, 31, 20, 21, 51]), (11, 0.7868, 0.7798, 0.0001765209349950247, 0.0004237472901544169, 31, [20, 29, 20, 20, 39])]\n",
      "#### Overall best val metric 0.8375634517766497 ####\n",
      "Generation 11: 49.2 s, best val metric 0.8426, [(12, 0.8426, 0.8292, 0.0001765209349950247, 0.0004237472901544169, 31, [20, 29, 20, 20, 39]), (12, 0.8376, 0.8242, 0.0001765209349950247, 0.0004237472901544169, 31, [20, 29, 20, 20, 39]), (12, 0.8274, 0.8142, 0.00048762384383192026, 0.00047205728390945477, 40, [20, 48, 40, 42, 67]), (12, 0.8274, 0.8142, 0.00048762384383192026, 0.00047205728390945477, 40, [20, 48, 40, 42, 67]), (12, 0.8173, 0.8042, 9.175308100181277e-05, 0.0004976368042203168, 29, [20, 21, 20, 20, 42]), (12, 0.8173, 0.8042, 0.0002670701534847487, 0.0004232998615059765, 32, [20, 21, 20, 20, 42]), (12, 0.8173, 0.8042, 9.175308100181277e-05, 0.0004976368042203168, 29, [20, 21, 20, 20, 42]), (12, 0.8122, 0.7992, 0.00027475390796774616, 0.0004647669871432816, 33, [20, 31, 20, 21, 51]), (12, 0.8071, 0.7942, 5.109235969610608e-05, 0.0004795214414003829, 32, [20, 48, 40, 42, 67]), (12, 0.8071, 0.7942, 5.109235969610608e-05, 0.0004795214414003829, 32, [20, 48, 40, 42, 67]), (12, 0.8071, 0.7942, 0.00048762384383192026, 0.00047205728390945477, 40, [20, 48, 40, 42, 67])]\n",
      "#### Overall best val metric 0.8426395939086294 ####\n",
      "Generation 12: 51.1 s, best val metric 0.8426, [(13, 0.8426, 0.8188, 0.0001765209349950247, 0.0004237472901544169, 31, [20, 29, 20, 20, 39]), (13, 0.8223, 0.799, 0.0010159666476771477, 0.0004326043090233313, 33, [20, 29, 20, 20, 39]), (13, 0.8122, 0.7892, 9.175308100181277e-05, 0.0004976368042203168, 29, [20, 21, 20, 20, 42]), (13, 0.8122, 0.7892, 9.175308100181277e-05, 0.0004976368042203168, 29, [20, 21, 20, 20, 42]), (13, 0.8122, 0.7892, 0.00027475390796774616, 0.0004647669871432816, 33, [20, 31, 20, 21, 51]), (13, 0.8122, 0.7892, 0.00027475390796774616, 0.0004647669871432816, 33, [20, 31, 20, 21, 51]), (13, 0.8071, 0.7842, 0.0001765209349950247, 0.0004237472901544169, 31, [20, 29, 20, 20, 39]), (13, 0.8071, 0.7842, 0.00044326255781512757, 0.0004856931257879527, 38, [20, 31, 20, 21, 51]), (13, 0.802, 0.7793, 0.0010351701367278623, 0.0004356866595918231, 31, [20, 48, 40, 42, 67]), (13, 0.797, 0.7744, 0.0014422451491165752, 0.0004489824285975689, 31, [20, 21, 20, 20, 42]), (13, 0.797, 0.7744, 9.175308100181277e-05, 0.0004976368042203168, 29, [20, 21, 20, 20, 42])]\n",
      "#### Overall best val metric 0.8426395939086294 ####\n",
      "Generation 13: 48.3 s, best val metric 0.8426, [(14, 0.8426, 0.8006, 0.0001765209349950247, 0.0004237472901544169, 31, [20, 29, 20, 20, 39]), (14, 0.8223, 0.7813, 0.0001765209349950247, 0.0004237472901544169, 31, [20, 29, 20, 20, 39]), (14, 0.8223, 0.7813, 0.0001765209349950247, 0.0004237472901544169, 31, [20, 29, 20, 20, 39]), (14, 0.8223, 0.7813, 0.0009885106905987498, 0.00046969887746057593, 32, [20, 29, 20, 20, 39]), (14, 0.8173, 0.7765, 0.00022515198884558364, 0.00043817001379952726, 33, [20, 21, 20, 20, 42]), (14, 0.8173, 0.7765, 0.00022515198884558364, 0.00043817001379952726, 33, [20, 21, 20, 20, 42]), (14, 0.8173, 0.7765, 0.00014863087407274026, 0.0004970265881993151, 24, [20, 31, 20, 21, 51]), (14, 0.8122, 0.7717, 9.175308100181277e-05, 0.0004976368042203168, 29, [20, 21, 20, 20, 42]), (14, 0.8122, 0.7717, 9.175308100181277e-05, 0.0004976368042203168, 29, [20, 21, 20, 20, 42]), (14, 0.8122, 0.7717, 9.175308100181277e-05, 0.0004976368042203168, 29, [20, 21, 20, 20, 42]), (14, 0.802, 0.762, 0.0014422451491165752, 0.0004489824285975689, 31, [20, 21, 20, 20, 42])]\n",
      "#### Overall best val metric 0.8426395939086294 ####\n",
      "Generation 14: 47.5 s, best val metric 0.8426, [(15, 0.8426, 0.7699, 0.0001765209349950247, 0.0004237472901544169, 31, [20, 29, 20, 20, 39]), (15, 0.8223, 0.7513, 0.0001765209349950247, 0.0004237472901544169, 31, [20, 29, 20, 20, 39]), (15, 0.8173, 0.7467, 9.189261631082255e-05, 0.00045212637307930466, 33, [20, 29, 20, 20, 39]), (15, 0.8173, 0.7467, 9.189261631082255e-05, 0.00045212637307930466, 33, [20, 29, 20, 20, 39]), (15, 0.8173, 0.7467, 9.536571236277937e-05, 0.00043612947325598155, 29, [20, 29, 20, 20, 39]), (15, 0.8173, 0.7467, 9.189261631082255e-05, 0.00045212637307930466, 33, [20, 29, 20, 20, 39]), (15, 0.8173, 0.7467, 9.536571236277937e-05, 0.00043612947325598155, 29, [20, 29, 20, 20, 39]), (15, 0.8122, 0.7421, 7.735349577768371e-05, 0.0004965126546797695, 28, [20, 29, 20, 20, 39]), (15, 0.8122, 0.7421, 0.0001765209349950247, 0.0004237472901544169, 31, [20, 29, 20, 20, 39]), (15, 0.8122, 0.7421, 0.0001765209349950247, 0.0004237472901544169, 31, [20, 29, 20, 20, 39]), (15, 0.802, 0.7328, 9.175308100181277e-05, 0.0004976368042203168, 29, [20, 21, 20, 20, 42])]\n",
      "#### Overall best val metric 0.8426395939086294 ####\n",
      "Generation 15: 48.2 s, best val metric 0.8426, [(16, 0.8426, 0.7202, 0.0001765209349950247, 0.0004237472901544169, 31, [20, 29, 20, 20, 39]), (16, 0.8325, 0.7115, 9.189261631082255e-05, 0.00045212637307930466, 33, [20, 29, 20, 20, 39]), (16, 0.8274, 0.7072, 9.189261631082255e-05, 0.00045212637307930466, 33, [20, 29, 20, 20, 39]), (16, 0.8223, 0.7028, 0.0001765209349950247, 0.0004237472901544169, 31, [20, 29, 20, 20, 39]), (16, 0.8223, 0.7028, 0.0001765209349950247, 0.0004237472901544169, 31, [20, 29, 20, 20, 39]), (16, 0.8173, 0.6985, 9.189261631082255e-05, 0.00045212637307930466, 33, [20, 29, 20, 20, 39]), (16, 0.8173, 0.6985, 8.395383089024888e-05, 0.0004345752472165222, 33, [20, 29, 20, 20, 39]), (16, 0.8173, 0.6985, 8.395383089024888e-05, 0.0004345752472165222, 33, [20, 29, 20, 20, 39]), (16, 0.8122, 0.6941, 0.00027943273103297334, 0.00042686028711768275, 28, [20, 29, 20, 20, 39]), (16, 0.8122, 0.6941, 0.0001765209349950247, 0.0004237472901544169, 31, [20, 29, 20, 20, 39]), (16, 0.8122, 0.6941, 0.00027943273103297334, 0.00042686028711768275, 28, [20, 29, 20, 20, 39])]\n",
      "#### Overall best val metric 0.8426395939086294 ####\n",
      "Generation 16: 51.2 s, best val metric 0.8426, [(17, 0.8426, 0.6452, 0.0001765209349950247, 0.0004237472901544169, 31, [20, 29, 20, 20, 39]), (17, 0.8173, 0.6257, 0.00033268022757235974, 0.00043362547771636666, 32, [20, 29, 20, 20, 39]), (17, 0.8173, 0.6257, 9.189261631082255e-05, 0.00045212637307930466, 33, [20, 29, 20, 20, 39]), (17, 0.8173, 0.6257, 9.189261631082255e-05, 0.00045212637307930466, 33, [20, 29, 20, 20, 39]), (17, 0.8173, 0.6257, 3.1622776601683795e-05, 0.00040032860985843646, 33, [20, 29, 20, 20, 39]), (17, 0.8173, 0.6257, 9.189261631082255e-05, 0.00045212637307930466, 33, [20, 29, 20, 20, 39]), (17, 0.8173, 0.6257, 0.00027943273103297334, 0.00042686028711768275, 28, [20, 29, 20, 20, 39]), (17, 0.8122, 0.6218, 0.00027943273103297334, 0.00042686028711768275, 28, [20, 29, 20, 20, 39]), (17, 0.8071, 0.6179, 0.0001765209349950247, 0.0004237472901544169, 31, [20, 29, 20, 20, 39]), (17, 0.797, 0.6102, 0.000303404750741783, 0.0004659731939812239, 32, [20, 29, 20, 20, 39]), (17, 0.7919, 0.6063, 0.0001765209349950247, 0.0004237472901544169, 31, [20, 29, 20, 20, 39])]\n",
      "#### Overall best val metric 0.8426395939086294 ####\n",
      "Generation 17: 50.8 s, best val metric 0.8426, [(1, 0.6904, 0.6904, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6751, 0.6751, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6751, 0.6751, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (18, 0.8426, 0.5433, 0.0001765209349950247, 0.0004237472901544169, 31, [20, 29, 20, 20, 39]), (18, 0.8325, 0.5367, 0.0002129346325174635, 0.0004526113002192489, 24, [20, 29, 20, 20, 39]), (18, 0.8223, 0.5302, 0.00015664420080895434, 0.00043093823849643946, 34, [20, 29, 20, 20, 39]), (18, 0.8223, 0.5302, 0.00015664420080895434, 0.00043093823849643946, 34, [20, 29, 20, 20, 39]), (18, 0.8223, 0.5302, 0.00015664420080895434, 0.00043093823849643946, 34, [20, 29, 20, 20, 39]), (18, 0.8223, 0.5302, 0.00015664420080895434, 0.00043093823849643946, 34, [20, 29, 20, 20, 39]), (18, 0.8122, 0.5237, 3.1622776601683795e-05, 0.00044585546064808266, 32, [20, 29, 20, 20, 39]), (18, 0.802, 0.5171, 0.0001765209349950247, 0.0004237472901544169, 31, [20, 29, 20, 20, 39])]\n",
      "#### Overall best val metric 0.8426395939086294 ####\n",
      "Generation 18: 55.9 s, best val metric 0.797, [(2, 0.7614, 0.7614, 0.000744631927272459, 0.0004576498340096488, 31, [20, 20, 20, 20, 20]), (2, 0.7513, 0.7513, 5.4512108835143415e-05, 0.00048080061253814117, 35, [20, 40, 27, 40, 40]), (2, 0.7513, 0.7513, 5.4512108835143415e-05, 0.00048080061253814117, 35, [20, 40, 27, 40, 40]), (2, 0.7462, 0.7462, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7462, 0.7462, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.731, 0.731, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.731, 0.731, 0.0031622776601683794, 0.0004148593741758563, 30, [20, 20, 20, 20, 20]), (2, 0.6904, 0.6904, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6497, 0.6497, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (19, 0.797, 0.4001, 0.0002129346325174635, 0.0004526113002192489, 24, [20, 29, 20, 20, 39]), (19, 0.797, 0.4001, 0.0002129346325174635, 0.0004526113002192489, 24, [20, 29, 20, 20, 39])]\n",
      "#### Overall best val metric 0.8426395939086294 ####\n",
      "Generation 19: 70.3 s, best val metric 0.7868, [(3, 0.7868, 0.7868, 5.4512108835143415e-05, 0.00048080061253814117, 35, [20, 45, 37, 59, 54]), (3, 0.7868, 0.7868, 5.4512108835143415e-05, 0.00048080061253814117, 35, [20, 45, 37, 59, 54]), (3, 0.7766, 0.7766, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (3, 0.7766, 0.7766, 0.0003859574744222636, 0.0004246638580862351, 33, [20, 20, 20, 20, 20]), (3, 0.7766, 0.7766, 0.0003098089502610085, 0.00042086123249555457, 29, [20, 20, 20, 20, 20]), (3, 0.7665, 0.7665, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (3, 0.7665, 0.7665, 5.4512108835143415e-05, 0.00048080061253814117, 35, [20, 42, 28, 56, 53]), (3, 0.7614, 0.7614, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (3, 0.7614, 0.7614, 0.000744631927272459, 0.0004576498340096488, 31, [20, 20, 20, 20, 20]), (3, 0.7563, 0.7563, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (3, 0.736, 0.736, 0.00043811977517344084, 0.00037207182995907496, 26, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8426395939086294 ####\n",
      "Generation 20: 78.7 s, best val metric 0.8071, [(4, 0.8071, 0.8071, 5.4512108835143415e-05, 0.00048080061253814117, 35, [23, 57, 35, 68, 66]), (4, 0.802, 0.802, 5.4512108835143415e-05, 0.00048080061253814117, 35, [25, 65, 45, 75, 69]), (4, 0.802, 0.802, 5.4512108835143415e-05, 0.00048080061253814117, 35, [25, 65, 45, 75, 69]), (4, 0.7919, 0.7919, 7.905479569821811e-05, 0.00039789199809124874, 31, [20, 37, 23, 53, 49]), (4, 0.7919, 0.7919, 7.905479569821811e-05, 0.00039789199809124874, 31, [20, 37, 23, 53, 49]), (4, 0.7868, 0.7868, 0.0010699661306584067, 0.0004371523226803313, 34, [20, 20, 20, 20, 20]), (4, 0.7868, 0.7868, 5.4512108835143415e-05, 0.00048080061253814117, 35, [20, 45, 37, 59, 54]), (4, 0.7817, 0.7817, 0.0002920310426751365, 0.00039619820872866646, 32, [20, 23, 20, 23, 32]), (4, 0.7817, 0.7817, 0.00011365992158520538, 0.00043152862538000655, 34, [20, 20, 20, 20, 33]), (4, 0.7716, 0.7716, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (4, 0.7665, 0.7665, 0.0010705754678471, 0.00044794080371559643, 31, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8426395939086294 ####\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "evolution = Evolution()\n",
    "hyperparameters = {\n",
    "    'regularization_penalty': Hyperparameter(3., 2.5, 4.5, 0.5),\n",
    "    'learning_rate': Hyperparameter(0.0004, 0.0001, 0.0006, 0.000025),\n",
    "    'batch_size': Hyperparameter(32, 16, 64, 4),\n",
    "}\n",
    "evolution.run(x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test),\n",
    "              layer_sizes=[20, 20, 20, 20, 20], output_neurons=10, hyperparameters=hyperparameters, n_parents=5, population_size=10, \n",
    "              n_generations=50, tournament_size=3, n_introduced=2, age_penalty_period=10, use_static_graph=False, fine_tuning=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age penalty period 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: 43.8 s, best val metric 0.7513, [(1, 0.7513, 0.7513, 0.00013670032839482597, 0.00041953229643229697, 28, [20, 20, 20, 37, 20]), (1, 0.7107, 0.7107, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.7107, 0.7107, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.7005, 0.7005, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6904, 0.6904, 0.0010130241134930083, 0.00038832298952206186, 27, [20, 20, 20, 20, 20]), (1, 0.665, 0.665, 0.0031622776601683794, 0.0003491816579090291, 35, [20, 20, 20, 20, 20]), (1, 0.665, 0.665, 0.0031622776601683794, 0.0003491816579090291, 35, [20, 20, 20, 20, 20]), (1, 0.6497, 0.6497, 0.0031622776601683794, 0.000364733146480906, 36, [20, 20, 20, 20, 20]), (1, 0.6497, 0.6497, 0.0031622776601683794, 0.000364733146480906, 36, [20, 20, 20, 20, 20]), (1, 0.6345, 0.6345, 0.001, 0.0004, 32, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.751269035532995 ####\n",
      "Generation 1: 43.7 s, best val metric 0.7766, [(2, 0.7766, 0.7766, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7766, 0.7766, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7716, 0.7716, 0.0016001191171973734, 0.0004152705433755988, 38, [20, 20, 20, 20, 20]), (2, 0.7716, 0.7716, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7716, 0.7716, 0.0031622776601683794, 0.0003816619928565228, 43, [20, 20, 20, 20, 20]), (2, 0.7716, 0.7716, 0.0016001191171973734, 0.0004152705433755988, 38, [20, 20, 20, 20, 20]), (2, 0.7716, 0.7716, 0.0031622776601683794, 0.0003816619928565228, 43, [20, 20, 20, 20, 20]), (2, 0.7716, 0.7716, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7716, 0.7716, 0.0031622776601683794, 0.0003816619928565228, 43, [20, 20, 20, 20, 20]), (2, 0.7716, 0.7716, 0.0031622776601683794, 0.0003816619928565228, 43, [20, 20, 20, 20, 20]), (2, 0.7513, 0.7513, 0.00013670032839482597, 0.00041953229643229697, 28, [20, 20, 20, 37, 20])]\n",
      "#### Overall best val metric 0.7766497461928934 ####\n",
      "Generation 2: 46.6 s, best val metric 0.7817, [(3, 0.7817, 0.7817, 0.0008216513091697675, 0.0004398168141614046, 35, [20, 20, 20, 20, 20]), (3, 0.7817, 0.7817, 0.0008216513091697675, 0.0004398168141614046, 35, [20, 20, 20, 20, 20]), (3, 0.7766, 0.7766, 0.0008717945193285192, 0.00040718740319593393, 36, [20, 20, 20, 20, 20]), (3, 0.7766, 0.7766, 0.0008717945193285192, 0.00040718740319593393, 36, [20, 20, 20, 20, 20]), (3, 0.7766, 0.7766, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 0.0008285583494346411, 0.0003838267550332496, 23, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 0.0008285583494346411, 0.0003838267550332496, 23, [20, 20, 20, 20, 20]), (3, 0.7462, 0.7462, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (3, 0.7462, 0.7462, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (3, 0.7462, 0.7462, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (3, 0.7462, 0.7462, 0.001, 0.0004, 32, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.7817258883248731 ####\n",
      "Generation 3: 50.4 s, best val metric 0.797, [(4, 0.797, 0.797, 0.0008717945193285192, 0.00040718740319593393, 36, [20, 20, 20, 20, 20]), (4, 0.797, 0.797, 0.0008717945193285192, 0.00040718740319593393, 36, [20, 20, 20, 20, 20]), (4, 0.7868, 0.7868, 0.0014313918887427352, 0.0004196927436412437, 28, [20, 20, 20, 20, 20]), (4, 0.7868, 0.7868, 0.0008179745434285954, 0.0003795587328682191, 24, [20, 20, 20, 20, 20]), (4, 0.7817, 0.7817, 0.00032199761474751854, 0.0004115150624545968, 32, [20, 20, 20, 20, 20]), (4, 0.7817, 0.7817, 0.00032199761474751854, 0.0004115150624545968, 32, [20, 20, 20, 20, 20]), (4, 0.7817, 0.7817, 0.0008216513091697675, 0.0004398168141614046, 35, [20, 20, 20, 20, 20]), (4, 0.7716, 0.7716, 0.0008216513091697675, 0.0004398168141614046, 35, [20, 20, 20, 20, 20]), (4, 0.7716, 0.7716, 0.0008216513091697675, 0.0004398168141614046, 35, [20, 20, 20, 20, 20]), (4, 0.7665, 0.7665, 0.0005997273204146978, 0.00043861546242956545, 30, [20, 20, 20, 20, 20]), (4, 0.7411, 0.7411, 0.001084370011067652, 0.00045219462519474857, 30, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.7969543147208121 ####\n",
      "Generation 4: 49.8 s, best val metric 0.797, [(5, 0.797, 0.797, 0.0007098897851456408, 0.0003652638307689622, 34, [20, 20, 20, 20, 20]), (5, 0.797, 0.797, 0.0007098897851456408, 0.0003652638307689622, 34, [20, 20, 20, 20, 20]), (5, 0.797, 0.797, 0.0008717945193285192, 0.00040718740319593393, 36, [20, 20, 20, 20, 20]), (5, 0.7919, 0.7919, 0.0031622776601683794, 0.00044972079102142433, 39, [20, 20, 20, 20, 20]), (5, 0.7919, 0.7919, 0.0031622776601683794, 0.00044972079102142433, 39, [20, 20, 20, 20, 20]), (5, 0.7868, 0.7868, 0.0006554161956397548, 0.0004435999356983537, 32, [20, 20, 20, 20, 20]), (5, 0.7766, 0.7766, 0.001961419955230228, 0.000368121249178293, 21, [20, 20, 20, 20, 20]), (5, 0.7766, 0.7766, 0.0008179745434285954, 0.0003795587328682191, 24, [20, 20, 20, 20, 20]), (5, 0.7766, 0.7766, 0.0031622776601683794, 0.0004299643358498629, 35, [20, 20, 20, 20, 20]), (5, 0.7766, 0.7766, 0.0008216513091697675, 0.0004398168141614046, 35, [20, 20, 20, 20, 20]), (5, 0.7766, 0.7766, 0.00032199761474751854, 0.0004115150624545968, 32, [20, 20, 20, 20, 22])]\n",
      "#### Overall best val metric 0.7969543147208121 ####\n",
      "Generation 5: 49.3 s, best val metric 0.8173, [(6, 0.8173, 0.8173, 0.0008179745434285954, 0.0003795587328682191, 24, [20, 20, 20, 20, 20]), (6, 0.797, 0.797, 9.325670494920048e-05, 0.00037607285101976835, 34, [20, 22, 20, 40, 37]), (6, 0.797, 0.797, 0.0007098897851456408, 0.0003652638307689622, 34, [20, 20, 20, 20, 20]), (6, 0.7919, 0.7919, 0.00032199761474751854, 0.0004115150624545968, 32, [20, 20, 20, 20, 29]), (6, 0.7919, 0.7919, 0.000342668745195912, 0.00042887696913476833, 28, [20, 20, 20, 25, 22]), (6, 0.7868, 0.7868, 0.0007098897851456408, 0.0003652638307689622, 34, [20, 20, 20, 20, 20]), (6, 0.7868, 0.7868, 0.0006554161956397548, 0.0004435999356983537, 32, [20, 20, 20, 20, 20]), (6, 0.7868, 0.7868, 0.0008216513091697675, 0.0004398168141614046, 35, [20, 20, 20, 20, 20]), (6, 0.7868, 0.7868, 0.0008216513091697675, 0.0004398168141614046, 35, [20, 20, 20, 20, 20]), (6, 0.7817, 0.7817, 0.0014804490568104413, 0.00039758787797702564, 39, [20, 20, 20, 20, 20]), (6, 0.731, 0.731, 0.0007098897851456408, 0.0003652638307689622, 34, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.817258883248731 ####\n",
      "Generation 6: 49.3 s, best val metric 0.8173, [(7, 0.8173, 0.8173, 9.325670494920048e-05, 0.00037607285101976835, 34, [20, 31, 26, 60, 51]), (7, 0.8173, 0.8173, 9.325670494920048e-05, 0.00037607285101976835, 34, [20, 31, 26, 60, 51]), (7, 0.8173, 0.8173, 0.00048543197884312367, 0.0004261372469473506, 40, [20, 20, 20, 20, 20]), (7, 0.8173, 0.8173, 0.0008179745434285954, 0.0003795587328682191, 24, [20, 20, 20, 20, 20]), (7, 0.8071, 0.8071, 0.0007098897851456408, 0.0003652638307689622, 34, [20, 20, 20, 20, 20]), (7, 0.7919, 0.7919, 0.0007098897851456408, 0.0003652638307689622, 34, [20, 20, 20, 20, 20]), (7, 0.7919, 0.7919, 0.00015625423313409434, 0.0004256062266310276, 34, [20, 20, 20, 40, 40]), (7, 0.7919, 0.7919, 0.0007098897851456408, 0.0003652638307689622, 34, [20, 20, 20, 20, 20]), (7, 0.7868, 0.7868, 0.0001168720473697595, 0.0004032067422464818, 34, [20, 25, 22, 36, 38]), (7, 0.7868, 0.7868, 0.0009407271056653846, 0.0003777161961129197, 28, [20, 20, 20, 20, 20]), (7, 0.7665, 0.7665, 0.00040249768277009, 0.00044990915427883273, 28, [20, 20, 20, 20, 23])]\n",
      "#### Overall best val metric 0.817258883248731 ####\n",
      "Generation 7: 52.8 s, best val metric 0.8274, [(8, 0.8274, 0.8274, 0.0007098897851456408, 0.0003652638307689622, 34, [20, 20, 20, 20, 20]), (8, 0.8274, 0.8274, 0.0007098897851456408, 0.0003652638307689622, 34, [20, 20, 20, 20, 20]), (8, 0.8274, 0.8274, 0.0008179745434285954, 0.0003795587328682191, 24, [20, 20, 20, 20, 20]), (8, 0.8274, 0.8274, 0.0008179745434285954, 0.0003795587328682191, 24, [20, 20, 20, 20, 20]), (8, 0.8223, 0.8223, 0.00028085014969317406, 0.0004092744787212405, 34, [20, 20, 20, 20, 21]), (8, 0.8173, 0.8173, 0.0007098897851456408, 0.0003652638307689622, 34, [20, 20, 20, 20, 20]), (8, 0.8173, 0.8173, 0.0007098897851456408, 0.0003652638307689622, 34, [20, 20, 20, 20, 20]), (8, 0.8173, 0.8173, 9.325670494920048e-05, 0.00037607285101976835, 34, [20, 31, 26, 60, 51]), (8, 0.802, 0.802, 0.0001964594586404916, 0.00044419178258795893, 30, [20, 27, 20, 51, 42]), (8, 0.797, 0.797, 3.317981236224932e-05, 0.0003703484413996727, 24, [29, 45, 42, 56, 58]), (8, 0.7919, 0.7919, 9.325670494920048e-05, 0.00037607285101976835, 34, [20, 26, 23, 70, 48])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 8: 55.6 s, best val metric 0.8274, [(9, 0.8274, 0.8274, 0.0008179745434285954, 0.0003795587328682191, 24, [20, 19, 20, 20, 20]), (9, 0.8274, 0.8274, 0.0008179745434285954, 0.0003795587328682191, 24, [20, 19, 20, 20, 20]), (9, 0.8274, 0.8274, 0.0008179745434285954, 0.0003795587328682191, 24, [20, 19, 20, 20, 20]), (9, 0.8274, 0.8274, 0.0008179745434285954, 0.0003795587328682191, 24, [20, 19, 20, 20, 20]), (9, 0.8274, 0.8274, 0.0007098897851456408, 0.0003652638307689622, 34, [20, 20, 20, 20, 20]), (9, 0.8223, 0.8223, 0.0001964594586404916, 0.00044419178258795893, 30, [20, 20, 20, 40, 51]), (9, 0.8173, 0.8173, 9.325670494920048e-05, 0.00037607285101976835, 34, [20, 38, 25, 82, 55]), (9, 0.8122, 0.8122, 3.2008856504095996e-05, 0.0003308169683827025, 30, [31, 65, 62, 76, 78]), (9, 0.8071, 0.8071, 9.325670494920048e-05, 0.00037607285101976835, 34, [20, 40, 21, 66, 57]), (9, 0.7919, 0.7919, 0.00037638238264058017, 0.00032682051743830717, 25, [20, 20, 20, 20, 22]), (9, 0.7919, 0.7919, 0.0005885542788785311, 0.00037118642675858937, 27, [20, 20, 20, 21, 23])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 9: 59.6 s, best val metric 0.8376, [(10, 0.8376, 0.8376, 9.900672372091258e-05, 0.00035130145059763694, 23, [20, 22, 23, 40, 42]), (10, 0.8274, 0.8274, 0.0008179745434285954, 0.0003795587328682191, 24, [20, 19, 20, 20, 20]), (10, 0.8173, 0.8173, 9.726548826698333e-05, 0.00039631932850866646, 28, [20, 40, 20, 81, 70]), (10, 0.8173, 0.8173, 0.0008179745434285954, 0.0003795587328682191, 24, [20, 15, 19, 20, 22]), (10, 0.8071, 0.8071, 0.0008179745434285954, 0.0003795587328682191, 24, [20, 15, 19, 20, 20]), (10, 0.8071, 0.8071, 0.0008179745434285954, 0.0003795587328682191, 24, [20, 15, 19, 20, 20]), (10, 0.8071, 0.8071, 9.325670494920048e-05, 0.00037607285101976835, 34, [20, 38, 21, 75, 68]), (10, 0.802, 0.802, 9.352171100722892e-05, 0.0004107686349951452, 28, [20, 21, 29, 40, 40]), (10, 0.797, 0.797, 0.0005885542788785311, 0.00037118642675858937, 27, [20, 20, 20, 20, 23]), (10, 0.797, 0.797, 0.0005885542788785311, 0.00037118642675858937, 27, [20, 20, 20, 20, 23]), (10, 0.7919, 0.7919, 0.0001964594586404916, 0.00044419178258795893, 30, [20, 20, 20, 39, 62])]\n",
      "#### Overall best val metric 0.8375634517766497 ####\n",
      "Generation 10: 60.5 s, best val metric 0.8376, [(11, 0.8376, 0.8376, 9.900672372091258e-05, 0.00035130145059763694, 23, [20, 22, 23, 40, 42]), (11, 0.8274, 0.8274, 9.900672372091258e-05, 0.00035130145059763694, 23, [20, 31, 20, 53, 58]), (11, 0.8223, 0.8223, 0.00041730176614393635, 0.00034810660151083695, 30, [20, 15, 19, 20, 25]), (11, 0.8223, 0.8223, 0.00041730176614393635, 0.00034810660151083695, 30, [20, 15, 19, 20, 25]), (11, 0.8173, 0.8173, 0.0008179745434285954, 0.0003795587328682191, 24, [20, 16, 20, 20, 23]), (11, 0.8173, 0.8173, 0.00014558132223388518, 0.00038425350675589634, 34, [20, 17, 19, 39, 38]), (11, 0.8122, 0.8122, 9.726548826698333e-05, 0.00039631932850866646, 28, [20, 46, 33, 84, 90]), (11, 0.8122, 0.8122, 0.00039559031923961356, 0.00040104044978614856, 21, [20, 16, 20, 20, 31]), (11, 0.8122, 0.8122, 0.0008179745434285954, 0.0003795587328682191, 24, [20, 10, 18, 18, 23]), (11, 0.8122, 0.8122, 9.352171100722892e-05, 0.0004107686349951452, 28, [20, 30, 35, 60, 60]), (11, 0.797, 0.797, 0.00035014954301567345, 0.0003878493404067595, 30, [20, 21, 20, 31, 46])]\n",
      "#### Overall best val metric 0.8375634517766497 ####\n",
      "Generation 11: 63.1 s, best val metric 0.8376, [(12, 0.8376, 0.8376, 9.900672372091258e-05, 0.00035130145059763694, 23, [20, 22, 23, 40, 42]), (12, 0.8223, 0.8223, 0.00027105571771201555, 0.00037020975947438055, 28, [20, 19, 20, 37, 42]), (12, 0.8223, 0.8223, 0.00027105571771201555, 0.00037020975947438055, 28, [20, 19, 20, 37, 42]), (12, 0.8223, 0.8223, 0.00041730176614393635, 0.00034810660151083695, 30, [20, 13, 18, 20, 30]), (12, 0.8223, 0.8223, 0.00041730176614393635, 0.00034810660151083695, 30, [20, 13, 18, 20, 30]), (12, 0.8223, 0.8223, 0.00041730176614393635, 0.00034810660151083695, 30, [20, 13, 18, 20, 30]), (12, 0.8173, 0.8173, 6.0067851120256155e-05, 0.0003830020571825382, 27, [21, 49, 55, 80, 80]), (12, 0.8173, 0.8173, 6.0067851120256155e-05, 0.0003830020571825382, 27, [21, 49, 55, 80, 80]), (12, 0.8122, 0.8122, 0.00041730176614393635, 0.00034810660151083695, 30, [20, 15, 18, 20, 26]), (12, 0.8122, 0.8122, 0.0006595753309325786, 0.0003862568816700103, 24, [20, 18, 20, 20, 23]), (12, 0.802, 0.802, 4.5617417920248254e-05, 0.00042740875436447074, 22, [28, 36, 40, 40, 51])]\n",
      "#### Overall best val metric 0.8375634517766497 ####\n",
      "Generation 12: 65.4 s, best val metric 0.8376, [(13, 0.8376, 0.8376, 9.900672372091258e-05, 0.00035130145059763694, 23, [20, 22, 23, 40, 42]), (13, 0.8274, 0.8274, 0.00041730176614393635, 0.00034810660151083695, 30, [20, 12, 17, 18, 35]), (13, 0.8274, 0.8274, 6.0067851120256155e-05, 0.0003830020571825382, 27, [22, 62, 74, 100, 97]), (13, 0.8274, 0.8274, 6.0067851120256155e-05, 0.0003830020571825382, 27, [22, 62, 74, 100, 97]), (13, 0.8274, 0.8274, 6.0067851120256155e-05, 0.0003830020571825382, 27, [22, 62, 74, 100, 97]), (13, 0.8223, 0.8223, 0.00038043580739444415, 0.00039877167846268216, 26, [20, 12, 17, 19, 47]), (13, 0.8223, 0.8223, 3.1622776601683795e-05, 0.0003805017482408535, 26, [41, 69, 75, 100, 100]), (13, 0.8173, 0.8173, 0.00041730176614393635, 0.00034810660151083695, 30, [20, 11, 17, 18, 32]), (13, 0.8173, 0.8173, 0.00041730176614393635, 0.00034810660151083695, 30, [20, 11, 17, 18, 32]), (13, 0.8071, 0.8071, 0.0002661155647639801, 0.00034897315512269174, 31, [20, 19, 20, 25, 44]), (13, 0.736, 0.736, 0.00027105571771201555, 0.00037020975947438055, 28, [20, 19, 20, 25, 46])]\n",
      "#### Overall best val metric 0.8375634517766497 ####\n",
      "Generation 13: 68.5 s, best val metric 0.8376, [(14, 0.8376, 0.8376, 9.900672372091258e-05, 0.00035130145059763694, 23, [20, 22, 23, 40, 42]), (14, 0.8274, 0.8274, 0.0003368579788414852, 0.00031729344435786584, 34, [20, 21, 29, 51, 30]), (14, 0.8274, 0.8274, 0.0003368579788414852, 0.00031729344435786584, 34, [20, 21, 29, 51, 30]), (14, 0.8274, 0.8274, 0.0003368579788414852, 0.00031729344435786584, 34, [20, 21, 29, 51, 30]), (14, 0.8173, 0.8173, 0.0002661155647639801, 0.00034897315512269174, 31, [20, 19, 20, 22, 47]), (14, 0.8173, 0.8173, 0.00028158486315426647, 0.0003618066037405765, 25, [20, 21, 21, 56, 35]), (14, 0.8122, 0.8122, 4.982440820017041e-05, 0.00042601616109677994, 36, [26, 32, 37, 38, 55]), (14, 0.802, 0.802, 6.0067851120256155e-05, 0.0003830020571825382, 27, [31, 75, 73, 120, 111]), (14, 0.802, 0.802, 6.0067851120256155e-05, 0.0003830020571825382, 27, [22, 68, 79, 120, 108]), (14, 0.797, 0.797, 0.00041730176614393635, 0.00034810660151083695, 30, [20, 11, 16, 17, 28]), (14, 0.797, 0.797, 9.900672372091258e-05, 0.00035130145059763694, 23, [20, 23, 21, 56, 61])]\n",
      "#### Overall best val metric 0.8375634517766497 ####\n",
      "Generation 14: 67.2 s, best val metric 0.8477, [(15, 0.8477, 0.8477, 0.0002661155647639801, 0.00034897315512269174, 31, [20, 18, 20, 23, 50]), (15, 0.8376, 0.8376, 9.900672372091258e-05, 0.00035130145059763694, 23, [20, 22, 23, 40, 42]), (15, 0.8223, 0.8223, 0.00041730176614393635, 0.00034810660151083695, 30, [20, 10, 15, 17, 32]), (15, 0.8223, 0.8223, 0.00041730176614393635, 0.00034810660151083695, 30, [20, 10, 15, 17, 32]), (15, 0.8173, 0.8173, 9.900672372091258e-05, 0.00035130145059763694, 23, [20, 26, 20, 66, 73]), (15, 0.8173, 0.8173, 9.900672372091258e-05, 0.00035130145059763694, 23, [20, 25, 20, 57, 60]), (15, 0.8173, 0.8173, 9.900672372091258e-05, 0.00035130145059763694, 23, [20, 25, 20, 57, 60]), (15, 0.8122, 0.8122, 0.00044243486246683424, 0.0003104329525616803, 31, [20, 16, 20, 20, 27]), (15, 0.8071, 0.8071, 4.982440820017041e-05, 0.00042601616109677994, 36, [36, 52, 57, 58, 75]), (15, 0.797, 0.797, 0.0002018720517870536, 0.0003490536654781163, 31, [20, 20, 25, 38, 47]), (15, 0.7919, 0.7919, 6.0067851120256155e-05, 0.0003830020571825382, 27, [34, 70, 74, 142, 122])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 15: 38.1 s, best val metric 0.8477, [(16, 0.8477, 0.8402, 0.0002661155647639801, 0.00034897315512269174, 31, [20, 18, 20, 23, 50]), (16, 0.8223, 0.815, 9.900672372091258e-05, 0.00035130145059763694, 23, [20, 25, 20, 57, 60]), (16, 0.8122, 0.8049, 4.456789735437799e-05, 0.00039094596653505096, 31, [20, 25, 20, 57, 60]), (16, 0.8122, 0.8049, 4.456789735437799e-05, 0.00039094596653505096, 31, [20, 25, 20, 57, 60]), (16, 0.8071, 0.7999, 0.00044243486246683424, 0.0003104329525616803, 31, [20, 16, 20, 20, 27]), (16, 0.8071, 0.7999, 0.00044243486246683424, 0.0003104329525616803, 31, [20, 16, 20, 20, 27]), (16, 0.8071, 0.7999, 0.00044243486246683424, 0.0003104329525616803, 31, [20, 16, 20, 20, 27]), (16, 0.802, 0.7949, 0.00011801078950458164, 0.0003591249041518661, 31, [20, 10, 15, 17, 32]), (16, 0.797, 0.7898, 0.0002018720517870536, 0.0003490536654781163, 31, [20, 20, 25, 38, 47]), (16, 0.7919, 0.7848, 5.297796398700548e-05, 0.0003953889796723903, 33, [20, 16, 20, 20, 27]), (16, 0.7919, 0.7848, 5.297796398700548e-05, 0.0003953889796723903, 33, [20, 16, 20, 20, 27])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 16: 33.9 s, best val metric 0.8477, [(17, 0.8477, 0.8342, 0.0002661155647639801, 0.00034897315512269174, 31, [20, 18, 20, 23, 50]), (17, 0.8426, 0.8292, 0.0002106436117413248, 0.0003674293397930307, 30, [20, 10, 15, 17, 32]), (17, 0.8325, 0.8192, 0.0002661155647639801, 0.00034897315512269174, 31, [20, 18, 20, 23, 50]), (17, 0.8325, 0.8192, 0.00048325625437697, 0.00034198529491144764, 32, [20, 25, 20, 57, 60]), (17, 0.8325, 0.8192, 0.00048325625437697, 0.00034198529491144764, 32, [20, 25, 20, 57, 60]), (17, 0.8122, 0.7992, 0.00016238891375464627, 0.0003859006488972998, 23, [20, 16, 20, 20, 27]), (17, 0.8071, 0.7942, 4.456789735437799e-05, 0.00039094596653505096, 31, [20, 25, 20, 57, 60]), (17, 0.802, 0.7892, 0.0002018720517870536, 0.0003490536654781163, 31, [20, 20, 25, 38, 47]), (17, 0.797, 0.7842, 0.00044243486246683424, 0.0003104329525616803, 31, [20, 16, 20, 20, 27]), (17, 0.797, 0.7842, 0.00044243486246683424, 0.0003104329525616803, 31, [20, 16, 20, 20, 27]), (17, 0.7817, 0.7693, 0.0002849545686765873, 0.00037696643870800933, 27, [20, 18, 20, 23, 50])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 17: 34.4 s, best val metric 0.8477, [(18, 0.8477, 0.8237, 0.0002661155647639801, 0.00034897315512269174, 31, [20, 18, 20, 23, 50]), (18, 0.8274, 0.804, 0.0002661155647639801, 0.00034897315512269174, 31, [20, 18, 20, 23, 50]), (18, 0.8274, 0.804, 0.0002661155647639801, 0.00034897315512269174, 31, [20, 18, 20, 23, 50]), (18, 0.8223, 0.799, 0.00028927472257471193, 0.00033643987023507254, 29, [20, 18, 20, 23, 50]), (18, 0.8173, 0.7941, 3.1622776601683795e-05, 0.0003580464660020834, 22, [20, 16, 20, 20, 27]), (18, 0.8122, 0.7892, 0.00012487544149959953, 0.0003491308123787454, 27, [20, 25, 20, 57, 60]), (18, 0.8071, 0.7842, 0.0002106436117413248, 0.0003674293397930307, 30, [20, 10, 15, 17, 32]), (18, 0.8071, 0.7842, 0.0001735793637674032, 0.00036836967049894744, 33, [20, 25, 20, 57, 60]), (18, 0.8071, 0.7842, 0.0003031895533158098, 0.0003650908581438976, 31, [20, 16, 20, 20, 27]), (18, 0.802, 0.7793, 0.0005863047200264662, 0.00033196815640818705, 26, [20, 18, 20, 23, 50]), (18, 0.797, 0.7744, 0.0002535774297226722, 0.00038600927442917213, 28, [20, 25, 20, 57, 60])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 18: 34.3 s, best val metric 0.8477, [(19, 0.8477, 0.8054, 0.0002661155647639801, 0.00034897315512269174, 31, [20, 18, 20, 23, 50]), (19, 0.8325, 0.791, 0.00012487544149959953, 0.0003491308123787454, 27, [20, 25, 20, 57, 60]), (19, 0.8325, 0.791, 0.00012487544149959953, 0.0003491308123787454, 27, [20, 25, 20, 57, 60]), (19, 0.8274, 0.7861, 0.0002661155647639801, 0.00034897315512269174, 31, [20, 18, 20, 23, 50]), (19, 0.8274, 0.7861, 0.0002661155647639801, 0.00034897315512269174, 31, [20, 18, 20, 23, 50]), (19, 0.8274, 0.7861, 0.0002661155647639801, 0.00034897315512269174, 31, [20, 18, 20, 23, 50]), (19, 0.8223, 0.7813, 0.00028927472257471193, 0.00033643987023507254, 29, [20, 18, 20, 23, 50]), (19, 0.8223, 0.7813, 0.00028927472257471193, 0.00033643987023507254, 29, [20, 18, 20, 23, 50]), (19, 0.8122, 0.7717, 0.0005863047200264662, 0.00033196815640818705, 26, [20, 18, 20, 23, 50]), (19, 0.8122, 0.7717, 0.0002749195898494236, 0.0003145037052519678, 27, [20, 18, 20, 23, 50]), (19, 0.8122, 0.7717, 0.0005863047200264662, 0.00033196815640818705, 26, [20, 18, 20, 23, 50])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 19: 36.5 s, best val metric 0.8477, [(20, 0.8477, 0.7745, 0.0002661155647639801, 0.00034897315512269174, 31, [20, 18, 20, 23, 50]), (20, 0.8376, 0.7653, 0.00028927472257471193, 0.00033643987023507254, 29, [20, 18, 20, 23, 50]), (20, 0.8376, 0.7653, 0.00028927472257471193, 0.00033643987023507254, 29, [20, 18, 20, 23, 50]), (20, 0.8325, 0.7606, 0.0003418693642209025, 0.0003306277202428676, 30, [20, 18, 20, 23, 50]), (20, 0.8325, 0.7606, 0.0003418693642209025, 0.0003306277202428676, 30, [20, 18, 20, 23, 50]), (20, 0.8274, 0.756, 0.0002661155647639801, 0.00034897315512269174, 31, [20, 18, 20, 23, 50]), (20, 0.8223, 0.7513, 0.00019396983308594382, 0.000387728022327529, 19, [20, 18, 20, 23, 50]), (20, 0.8223, 0.7513, 0.0003628191265358001, 0.0003395645006218677, 26, [20, 18, 20, 23, 50]), (20, 0.8223, 0.7513, 0.00019396983308594382, 0.000387728022327529, 19, [20, 18, 20, 23, 50]), (20, 0.8173, 0.7467, 0.00036430583729294254, 0.00036121050120442984, 32, [20, 18, 20, 23, 50]), (20, 0.802, 0.7328, 7.277493435716018e-05, 0.0003873143309698341, 27, [20, 18, 20, 23, 50])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 20: 35.6 s, best val metric 0.8477, [(21, 0.8477, 0.7245, 0.0002661155647639801, 0.00034897315512269174, 31, [20, 18, 20, 23, 50]), (21, 0.8426, 0.7202, 0.00024373034562608138, 0.0003624860482087385, 27, [20, 18, 20, 23, 50]), (21, 0.8426, 0.7202, 0.00024373034562608138, 0.0003624860482087385, 27, [20, 18, 20, 23, 50]), (21, 0.8325, 0.7115, 0.0011865829515385687, 0.0003453699028285549, 29, [20, 18, 20, 23, 50]), (21, 0.8274, 0.7072, 0.00026318605685072324, 0.00034304292370377227, 28, [20, 18, 20, 23, 50]), (21, 0.8274, 0.7072, 0.00026318605685072324, 0.00034304292370377227, 28, [20, 18, 20, 23, 50]), (21, 0.8274, 0.7072, 0.00026318605685072324, 0.00034304292370377227, 28, [20, 18, 20, 23, 50]), (21, 0.8223, 0.7028, 0.00019396983308594382, 0.000387728022327529, 19, [20, 18, 20, 23, 50]), (21, 0.8223, 0.7028, 0.00028927472257471193, 0.00033643987023507254, 29, [20, 18, 20, 23, 50]), (21, 0.8173, 0.6985, 0.0003418693642209025, 0.0003306277202428676, 30, [20, 18, 20, 23, 50]), (21, 0.8173, 0.6985, 0.00041408972649548657, 0.0003982538620948478, 21, [20, 18, 20, 23, 50])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 21: 36.2 s, best val metric 0.8477, [(22, 0.8477, 0.649, 0.0002661155647639801, 0.00034897315512269174, 31, [20, 18, 20, 23, 50]), (22, 0.8274, 0.6335, 0.00043697317896589387, 0.0003863619662455791, 31, [20, 18, 20, 23, 50]), (22, 0.8274, 0.6335, 0.00043697317896589387, 0.0003863619662455791, 31, [20, 18, 20, 23, 50]), (22, 0.8223, 0.6296, 0.00028927472257471193, 0.00033643987023507254, 29, [20, 18, 20, 23, 50]), (22, 0.8173, 0.6257, 0.00026318605685072324, 0.00034304292370377227, 28, [20, 18, 20, 23, 50]), (22, 0.8173, 0.6257, 0.00011124549856855312, 0.00038236642727916813, 28, [20, 18, 20, 23, 50]), (22, 0.8122, 0.6218, 0.00013032262083332766, 0.0003661237403662951, 19, [20, 18, 20, 23, 50]), (22, 0.8122, 0.6218, 0.00013032262083332766, 0.0003661237403662951, 19, [20, 18, 20, 23, 50]), (22, 0.8071, 0.6179, 0.0002661155647639801, 0.00034897315512269174, 31, [20, 18, 20, 23, 50]), (22, 0.8071, 0.6179, 0.00024373034562608138, 0.0003624860482087385, 27, [20, 18, 20, 23, 50]), (22, 0.802, 0.6141, 0.00026318605685072324, 0.00034304292370377227, 28, [20, 18, 20, 23, 50])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 22: 34.8 s, best val metric 0.8477, [(1, 0.6244, 0.6244, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (23, 0.8477, 0.5466, 0.0002661155647639801, 0.00034897315512269174, 31, [20, 18, 20, 23, 50]), (23, 0.8223, 0.5302, 0.00024373034562608138, 0.0003624860482087385, 27, [20, 18, 20, 23, 50]), (23, 0.8223, 0.5302, 0.00024373034562608138, 0.0003624860482087385, 27, [20, 18, 20, 23, 50]), (23, 0.8223, 0.5302, 0.00012182405062212234, 0.00041016829515879794, 27, [20, 18, 20, 23, 50]), (23, 0.8173, 0.5269, 0.003105533548237327, 0.0003125217744817362, 22, [20, 18, 20, 23, 50]), (23, 0.8173, 0.5269, 0.001078263284047967, 0.000380584289818337, 30, [20, 18, 20, 23, 50]), (23, 0.8173, 0.5269, 0.003105533548237327, 0.0003125217744817362, 22, [20, 18, 20, 23, 50]), (23, 0.8122, 0.5237, 0.0001192397299427909, 0.00034842004985291444, 35, [20, 18, 20, 23, 50]), (23, 0.8071, 0.5204, 0.00014054229733421705, 0.00033013333133583163, 25, [20, 18, 20, 23, 50]), (23, 0.8071, 0.5204, 0.00014054229733421705, 0.00033013333133583163, 25, [20, 18, 20, 23, 50])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 23: 36.5 s, best val metric 0.8325, [(2, 0.7157, 0.7157, 0.0020018566798570333, 0.0003739933638272302, 29, [20, 20, 20, 20, 20]), (1, 0.6294, 0.6294, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.6244, 0.6244, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (24, 0.8325, 0.418, 0.003105533548237327, 0.0003125217744817362, 22, [20, 18, 20, 23, 50]), (24, 0.8274, 0.4154, 0.0002661155647639801, 0.00034897315512269174, 31, [20, 18, 20, 23, 50]), (24, 0.8274, 0.4154, 0.0002661155647639801, 0.00034897315512269174, 31, [20, 18, 20, 23, 50]), (24, 0.8122, 0.4078, 0.00014054229733421705, 0.00033013333133583163, 25, [20, 18, 20, 23, 50]), (24, 0.8122, 0.4078, 0.00014054229733421705, 0.00033013333133583163, 25, [20, 18, 20, 23, 50]), (24, 0.8071, 0.4052, 0.0007616129303734395, 0.0003217592220351004, 32, [20, 18, 20, 23, 50]), (24, 0.802, 0.4027, 0.00014054229733421705, 0.00033013333133583163, 25, [20, 18, 20, 23, 50]), (24, 0.797, 0.4001, 8.65844611572408e-05, 0.0003924583801300914, 29, [20, 18, 20, 23, 50])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 24: 38.8 s, best val metric 0.8173, [(3, 0.7513, 0.7513, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (3, 0.7513, 0.7513, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7411, 0.7411, 0.0002996778931581777, 0.00034185229089168804, 26, [20, 20, 20, 20, 20]), (3, 0.731, 0.731, 0.0011249577931901201, 0.00038388349228634397, 29, [20, 20, 20, 20, 20]), (3, 0.7157, 0.7157, 0.0020018566798570333, 0.0003739933638272302, 29, [20, 20, 20, 20, 20]), (1, 0.6954, 0.6954, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6954, 0.6954, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (25, 0.8173, 0.2934, 0.0002661155647639801, 0.00034897315512269174, 31, [20, 18, 20, 23, 50]), (25, 0.8173, 0.2934, 0.0002661155647639801, 0.00034897315512269174, 31, [20, 18, 20, 23, 50]), (25, 0.8122, 0.2916, 0.0006826100276512871, 0.0003829725906541422, 28, [20, 18, 20, 23, 50]), (25, 0.8071, 0.2898, 8.65844611572408e-05, 0.0003924583801300914, 29, [20, 18, 20, 23, 50])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 25: 43.9 s, best val metric 0.7716, [(4, 0.7716, 0.7716, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 0.0002996778931581777, 0.00034185229089168804, 26, [20, 20, 20, 20, 20]), (4, 0.7665, 0.7665, 0.0011249577931901201, 0.00038388349228634397, 29, [20, 20, 20, 20, 20]), (4, 0.7665, 0.7665, 0.0011249577931901201, 0.00038388349228634397, 29, [20, 20, 20, 20, 20]), (2, 0.7665, 0.7665, 0.0005838406144179964, 0.0003687248231362277, 30, [20, 20, 20, 20, 20]), (4, 0.7665, 0.7665, 0.0011249577931901201, 0.00038388349228634397, 29, [20, 20, 20, 20, 20]), (4, 0.7614, 0.7614, 0.0020018566798570333, 0.0003739933638272302, 29, [20, 20, 20, 20, 20]), (4, 0.7513, 0.7513, 0.002707413261683097, 0.0003692560394085173, 25, [20, 20, 20, 20, 20]), (4, 0.7513, 0.7513, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6802, 0.6802, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6294, 0.6294, 0.001, 0.0004, 32, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 26: 51.0 s, best val metric 0.797, [(5, 0.797, 0.797, 0.000494459227402001, 0.00040710779445315894, 30, [20, 20, 20, 20, 20]), (5, 0.797, 0.797, 0.000494459227402001, 0.00040710779445315894, 30, [20, 20, 20, 20, 20]), (5, 0.797, 0.797, 0.000494459227402001, 0.00040710779445315894, 30, [20, 20, 20, 20, 20]), (5, 0.797, 0.797, 0.0006938758450875705, 0.00036905434221196537, 27, [20, 20, 20, 20, 20]), (3, 0.7868, 0.7868, 0.0005838406144179964, 0.0003687248231362277, 30, [20, 20, 20, 20, 20]), (5, 0.7766, 0.7766, 0.0011249577931901201, 0.00038388349228634397, 29, [20, 20, 20, 20, 20]), (5, 0.7716, 0.7716, 0.0020018566798570333, 0.0003739933638272302, 29, [20, 20, 20, 20, 20]), (5, 0.7716, 0.7716, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (5, 0.7665, 0.7665, 0.0011249577931901201, 0.00038388349228634397, 29, [20, 20, 20, 20, 20]), (5, 0.7665, 0.7665, 0.0011249577931901201, 0.00038388349228634397, 29, [20, 20, 20, 20, 20]), (2, 0.7614, 0.7614, 0.0005329129849881364, 0.0004090292920627381, 25, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 27: 51.7 s, best val metric 0.8223, [(6, 0.8223, 0.8223, 4.787632821458888e-05, 0.0003988940303819411, 30, [20, 40, 39, 40, 40]), (4, 0.802, 0.802, 9.578900910546954e-05, 0.000405777210424461, 23, [20, 29, 20, 40, 39]), (6, 0.797, 0.797, 0.000494459227402001, 0.00040710779445315894, 30, [20, 20, 20, 20, 20]), (6, 0.7868, 0.7868, 0.0008825907385113885, 0.0003459100697100465, 26, [20, 20, 20, 20, 20]), (6, 0.7868, 0.7868, 0.0008825907385113885, 0.0003459100697100465, 26, [20, 20, 20, 20, 20]), (6, 0.7817, 0.7817, 0.00025345641615530254, 0.00038567328806801893, 29, [20, 20, 20, 20, 20]), (3, 0.7817, 0.7817, 0.0005329129849881364, 0.0004090292920627381, 25, [20, 20, 20, 20, 20]), (3, 0.7817, 0.7817, 0.0005329129849881364, 0.0004090292920627381, 25, [20, 20, 20, 20, 20]), (6, 0.7817, 0.7817, 0.000494459227402001, 0.00040710779445315894, 30, [20, 20, 20, 20, 20]), (3, 0.7766, 0.7766, 0.0003078632334597556, 0.0003936355244956084, 35, [20, 20, 20, 20, 20]), (6, 0.7716, 0.7716, 0.0007071426156940073, 0.0003615062566517475, 22, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 28: 56.9 s, best val metric 0.8223, [(7, 0.8223, 0.8223, 4.787632821458888e-05, 0.0003988940303819411, 30, [20, 40, 39, 40, 40]), (5, 0.8173, 0.8173, 9.578900910546954e-05, 0.000405777210424461, 23, [20, 41, 20, 53, 54]), (7, 0.8071, 0.8071, 0.0007848818548364747, 0.00033761726602135676, 27, [20, 20, 20, 20, 20]), (5, 0.802, 0.802, 3.296752239099503e-05, 0.00039164796356603747, 22, [34, 49, 40, 60, 59]), (5, 0.802, 0.802, 3.296752239099503e-05, 0.00039164796356603747, 22, [34, 49, 40, 60, 59]), (7, 0.797, 0.797, 0.00025184421505024853, 0.0003722527293779204, 28, [20, 20, 20, 20, 25]), (4, 0.7919, 0.7919, 0.0005329129849881364, 0.0004090292920627381, 25, [20, 20, 20, 20, 20]), (7, 0.7868, 0.7868, 0.000494459227402001, 0.00040710779445315894, 30, [20, 20, 20, 20, 20]), (7, 0.7817, 0.7817, 0.000494459227402001, 0.00040710779445315894, 30, [20, 20, 20, 20, 20]), (4, 0.7817, 0.7817, 0.0031622776601683794, 0.0004264232127658083, 31, [20, 20, 20, 20, 20]), (4, 0.7766, 0.7766, 0.0007150076774411127, 0.00039585369561699683, 24, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 29: 62.0 s, best val metric 0.8223, [(8, 0.8223, 0.8223, 4.787632821458888e-05, 0.0003988940303819411, 30, [20, 40, 39, 40, 40]), (8, 0.802, 0.802, 0.0007848818548364747, 0.00033761726602135676, 27, [20, 20, 20, 20, 20]), (8, 0.802, 0.802, 0.0003066104551303414, 0.0004439660469322691, 28, [20, 21, 20, 20, 29]), (6, 0.802, 0.802, 3.296752239099503e-05, 0.00039164796356603747, 22, [49, 69, 60, 80, 79]), (6, 0.802, 0.802, 9.578900910546954e-05, 0.000405777210424461, 23, [23, 41, 22, 61, 58]), (6, 0.802, 0.802, 3.296752239099503e-05, 0.00039164796356603747, 22, [49, 69, 60, 80, 79]), (6, 0.802, 0.802, 0.001600335321754011, 0.00038382172500356533, 29, [20, 20, 20, 20, 20]), (8, 0.802, 0.802, 4.787632821458888e-05, 0.0003988940303819411, 30, [20, 59, 43, 60, 60]), (8, 0.797, 0.797, 0.000494459227402001, 0.00040710779445315894, 30, [20, 20, 20, 20, 20]), (5, 0.7919, 0.7919, 8.25015562166934e-05, 0.00039544983937817035, 27, [20, 21, 20, 40, 40]), (6, 0.7868, 0.7868, 0.0005931788982719748, 0.0003526181809693744, 23, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 30: 70.3 s, best val metric 0.8223, [(6, 0.8223, 0.8223, 0.00012018323524716196, 0.0004288320462805366, 26, [20, 26, 23, 57, 52]), (9, 0.8223, 0.8223, 4.787632821458888e-05, 0.0003988940303819411, 30, [20, 40, 39, 40, 40]), (7, 0.8122, 0.8122, 3.296752239099503e-05, 0.00039164796356603747, 22, [65, 89, 79, 100, 93]), (7, 0.8122, 0.8122, 3.296752239099503e-05, 0.00039164796356603747, 22, [65, 89, 79, 100, 93]), (7, 0.8071, 0.8071, 3.1622776601683795e-05, 0.00040995075545541385, 27, [32, 40, 40, 40, 40]), (7, 0.8071, 0.8071, 3.1622776601683795e-05, 0.00040995075545541385, 27, [32, 40, 40, 40, 40]), (7, 0.802, 0.802, 0.0003212757551953265, 0.0003684717572847767, 20, [20, 20, 20, 26, 26]), (7, 0.802, 0.802, 0.0003212757551953265, 0.0003684717572847767, 20, [20, 20, 20, 26, 26]), (9, 0.7919, 0.7919, 0.0006120555218282335, 0.00040625317308432164, 25, [20, 20, 20, 20, 20]), (7, 0.7919, 0.7919, 5.7303749637591195e-05, 0.00037631375235539915, 22, [20, 40, 36, 40, 40]), (9, 0.7817, 0.7817, 0.0007848818548364747, 0.00033761726602135676, 27, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 31: 78.5 s, best val metric 0.8223, [(7, 0.8223, 0.8223, 0.00012018323524716196, 0.0004288320462805366, 26, [20, 26, 23, 57, 52]), (8, 0.8122, 0.8122, 3.1622776601683795e-05, 0.00040995075545541385, 27, [48, 60, 60, 60, 60]), (8, 0.8122, 0.8122, 3.1622776601683795e-05, 0.00040995075545541385, 27, [48, 60, 60, 60, 60]), (8, 0.8071, 0.8071, 3.218155009880938e-05, 0.00038838245466932486, 31, [46, 60, 60, 60, 60]), (8, 0.8071, 0.8071, 3.218155009880938e-05, 0.00038838245466932486, 31, [46, 60, 60, 60, 60]), (8, 0.8071, 0.8071, 3.218155009880938e-05, 0.00038838245466932486, 31, [46, 60, 60, 60, 60]), (8, 0.8071, 0.8071, 3.218155009880938e-05, 0.00038838245466932486, 31, [46, 60, 60, 60, 60]), (8, 0.797, 0.797, 3.296752239099503e-05, 0.00039164796356603747, 22, [79, 109, 96, 120, 109]), (8, 0.797, 0.797, 0.0003212757551953265, 0.0003684717572847767, 20, [20, 20, 20, 21, 27]), (8, 0.7817, 0.7817, 3.1622776601683795e-05, 0.00040995075545541385, 27, [51, 60, 60, 60, 60]), (7, 0.7716, 0.7716, 0.00012018323524716196, 0.0004288320462805366, 26, [20, 25, 27, 51, 67])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 32: 82.3 s, best val metric 0.8223, [(9, 0.8223, 0.8223, 6.27389400936318e-05, 0.0003871764898982017, 28, [33, 64, 56, 79, 79]), (8, 0.8223, 0.8223, 0.00012018323524716196, 0.0004288320462805366, 26, [20, 26, 23, 57, 52]), (9, 0.8173, 0.8173, 3.1622776601683795e-05, 0.00039942017449474753, 39, [54, 80, 76, 80, 80]), (8, 0.8122, 0.8122, 0.00012018323524716196, 0.0004288320462805366, 26, [20, 27, 30, 49, 63]), (9, 0.8122, 0.8122, 3.1622776601683795e-05, 0.00040995075545541385, 27, [52, 79, 80, 80, 80]), (8, 0.8122, 0.8122, 0.00012018323524716196, 0.0004288320462805366, 26, [20, 27, 30, 49, 63]), (9, 0.8122, 0.8122, 3.1622776601683795e-05, 0.00040995075545541385, 27, [52, 79, 80, 80, 80]), (9, 0.8071, 0.8071, 0.0009521496501750649, 0.00041960118996176043, 28, [20, 20, 20, 30, 21]), (9, 0.802, 0.802, 3.218155009880938e-05, 0.00038838245466932486, 31, [62, 80, 80, 80, 80]), (9, 0.802, 0.802, 3.218155009880938e-05, 0.00038838245466932486, 31, [62, 80, 80, 80, 80]), (9, 0.797, 0.797, 0.00011581158624047418, 0.00041498438291703887, 27, [29, 56, 39, 63, 66])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 33: 82.3 s, best val metric 0.8274, [(10, 0.8274, 0.8274, 7.235262337062246e-05, 0.0003870801820634515, 37, [27, 53, 35, 75, 77]), (10, 0.8274, 0.8274, 7.235262337062246e-05, 0.0003870801820634515, 37, [27, 53, 35, 75, 77]), (10, 0.8274, 0.8274, 7.235262337062246e-05, 0.0003870801820634515, 37, [27, 53, 35, 75, 77]), (10, 0.8223, 0.8223, 6.27389400936318e-05, 0.0003871764898982017, 28, [25, 73, 48, 94, 94]), (10, 0.8223, 0.8223, 6.27389400936318e-05, 0.0003871764898982017, 28, [25, 73, 48, 94, 94]), (10, 0.8223, 0.8223, 6.27389400936318e-05, 0.0003871764898982017, 28, [33, 64, 56, 79, 79]), (10, 0.8173, 0.8173, 3.218155009880938e-05, 0.00038838245466932486, 31, [56, 100, 98, 100, 100]), (9, 0.8122, 0.8122, 0.00012018323524716196, 0.0004288320462805366, 26, [20, 34, 22, 64, 66]), (10, 0.797, 0.797, 0.0009521496501750649, 0.00041960118996176043, 28, [20, 20, 20, 20, 21]), (10, 0.797, 0.797, 3.1622776601683795e-05, 0.00039942017449474753, 39, [48, 98, 90, 100, 100]), (9, 0.797, 0.797, 0.00012018323524716196, 0.0004288320462805366, 26, [20, 35, 28, 45, 72])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 34: 77.3 s, best val metric 0.8274, [(11, 0.8274, 0.8274, 7.235262337062246e-05, 0.0003870801820634515, 37, [27, 53, 35, 75, 77]), (11, 0.8122, 0.8122, 6.27389400936318e-05, 0.0003871764898982017, 28, [23, 75, 47, 95, 107]), (11, 0.8122, 0.8122, 6.27389400936318e-05, 0.0003871764898982017, 28, [23, 75, 47, 95, 107]), (11, 0.8122, 0.8122, 6.27389400936318e-05, 0.0003871764898982017, 28, [23, 75, 47, 95, 107]), (11, 0.8071, 0.8071, 0.0003571654951650947, 0.00040172080846538643, 34, [20, 22, 20, 29, 37]), (11, 0.802, 0.802, 0.00029859903519917136, 0.00039968135022805146, 26, [20, 24, 20, 36, 40]), (11, 0.802, 0.802, 0.0003253196992234489, 0.00039523961019066755, 31, [20, 20, 20, 40, 33]), (11, 0.802, 0.802, 8.869489959641295e-05, 0.00035995612035854294, 33, [22, 76, 51, 101, 95]), (11, 0.797, 0.797, 7.235262337062246e-05, 0.0003870801820634515, 37, [25, 60, 40, 91, 88]), (11, 0.7919, 0.7919, 8.216326353070872e-05, 0.00041393340131636665, 28, [24, 73, 46, 77, 93]), (11, 0.7766, 0.7766, 0.0009521496501750649, 0.00041960118996176043, 28, [20, 20, 19, 20, 23])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 35: 72.4 s, best val metric 0.8325, [(12, 0.8325, 0.8325, 0.0003571654951650947, 0.00040172080846538643, 34, [20, 20, 20, 20, 38]), (12, 0.8274, 0.8274, 7.235262337062246e-05, 0.0003870801820634515, 37, [27, 53, 35, 75, 77]), (12, 0.8223, 0.8223, 0.0005654892657767361, 0.00039419205031955643, 31, [20, 20, 20, 34, 30]), (12, 0.8071, 0.8071, 0.0003717337504947419, 0.00041189305828701316, 35, [20, 26, 20, 44, 51]), (12, 0.8071, 0.8071, 0.0003717337504947419, 0.00041189305828701316, 35, [20, 26, 20, 44, 51]), (12, 0.8071, 0.8071, 0.0003253196992234489, 0.00039523961019066755, 31, [20, 20, 20, 21, 32]), (12, 0.8071, 0.8071, 0.00029859903519917136, 0.00039968135022805146, 26, [20, 22, 20, 21, 43]), (12, 0.8071, 0.8071, 0.0003253196992234489, 0.00039523961019066755, 31, [20, 20, 20, 21, 32]), (12, 0.797, 0.797, 8.216326353070872e-05, 0.00041393340131636665, 28, [23, 66, 41, 91, 96]), (12, 0.7919, 0.7919, 0.0005243472904626063, 0.00039124480400833995, 30, [20, 20, 20, 20, 35]), (12, 0.7817, 0.7817, 0.00014947990034945788, 0.00039529021515491793, 35, [20, 23, 20, 46, 57])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 36: 57.2 s, best val metric 0.8325, [(13, 0.8325, 0.8325, 0.0003571654951650947, 0.00040172080846538643, 34, [20, 20, 20, 20, 38]), (13, 0.8173, 0.8173, 0.0002475593285065038, 0.000363775369384168, 30, [20, 20, 20, 21, 41]), (13, 0.8173, 0.8173, 0.00010495017271641821, 0.00039045942954726186, 35, [20, 33, 27, 41, 51]), (13, 0.8173, 0.8173, 0.0002475593285065038, 0.000363775369384168, 30, [20, 20, 20, 21, 41]), (13, 0.8173, 0.8173, 0.00010495017271641821, 0.00039045942954726186, 35, [20, 33, 27, 41, 51]), (13, 0.8122, 0.8122, 0.00029859903519917136, 0.00039968135022805146, 26, [20, 21, 20, 20, 49]), (13, 0.8122, 0.8122, 0.00029859903519917136, 0.00039968135022805146, 26, [20, 21, 20, 20, 49]), (13, 0.8071, 0.8071, 0.0003717337504947419, 0.00041189305828701316, 35, [20, 20, 20, 22, 51]), (13, 0.802, 0.802, 0.0003253196992234489, 0.00039523961019066755, 31, [20, 20, 20, 20, 39]), (13, 0.7919, 0.7919, 0.0011530571499845895, 0.0003998896100668151, 40, [20, 20, 20, 20, 26]), (13, 0.7868, 0.7868, 0.0008862019036095203, 0.00036285037211067545, 33, [20, 20, 20, 26, 20])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 37: 53.6 s, best val metric 0.8325, [(14, 0.8325, 0.8325, 0.0003571654951650947, 0.00040172080846538643, 34, [20, 20, 20, 20, 38]), (14, 0.8223, 0.8223, 0.00010495017271641821, 0.00039045942954726186, 35, [20, 31, 25, 58, 67]), (14, 0.8122, 0.8122, 0.00023658926542619163, 0.0004020842493771212, 37, [20, 20, 20, 22, 62]), (14, 0.8122, 0.8122, 0.00023658926542619163, 0.0004020842493771212, 37, [20, 20, 20, 22, 62]), (14, 0.8071, 0.8071, 0.00011562521074520843, 0.000393985607297637, 34, [20, 20, 21, 41, 60]), (14, 0.802, 0.802, 0.0003571654951650947, 0.00040172080846538643, 34, [20, 20, 20, 20, 37]), (14, 0.797, 0.797, 0.0008862019036095203, 0.00036285037211067545, 33, [20, 20, 20, 20, 21]), (14, 0.797, 0.797, 0.0003717337504947419, 0.00041189305828701316, 35, [20, 20, 20, 21, 50]), (14, 0.797, 0.797, 0.00011951794729158296, 0.0003693149079307532, 29, [20, 21, 22, 39, 55]), (14, 0.797, 0.797, 0.00011951794729158296, 0.0003693149079307532, 29, [20, 21, 22, 39, 55]), (14, 0.797, 0.797, 0.001429963538711156, 0.00039578269264529205, 34, [20, 20, 20, 20, 24])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 38: 54.7 s, best val metric 0.8325, [(15, 0.8325, 0.8325, 0.0003571654951650947, 0.00040172080846538643, 34, [20, 20, 20, 20, 38]), (15, 0.8274, 0.8274, 0.0003017239095670012, 0.00038964361040251484, 37, [20, 21, 20, 20, 56]), (15, 0.8274, 0.8274, 0.0003017239095670012, 0.00038964361040251484, 37, [20, 21, 20, 20, 56]), (15, 0.8274, 0.8274, 0.0003017239095670012, 0.00038964361040251484, 37, [20, 21, 20, 20, 56]), (15, 0.8173, 0.8173, 0.00010495017271641821, 0.00039045942954726186, 35, [20, 31, 28, 59, 85]), (15, 0.8173, 0.8173, 0.00010495017271641821, 0.00039045942954726186, 35, [20, 31, 28, 59, 85]), (15, 0.8071, 0.8071, 4.504280971099451e-05, 0.00042221502857250274, 27, [31, 51, 45, 78, 87]), (15, 0.8071, 0.8071, 4.504280971099451e-05, 0.00042221502857250274, 27, [31, 51, 45, 78, 87]), (15, 0.8071, 0.8071, 0.00011562521074520843, 0.000393985607297637, 34, [20, 37, 25, 57, 76]), (15, 0.8071, 0.8071, 0.00039193751457077984, 0.0003562729070470429, 32, [20, 20, 20, 20, 33]), (15, 0.8071, 0.8071, 4.504280971099451e-05, 0.00042221502857250274, 27, [31, 51, 45, 78, 87])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 39: 38.6 s, best val metric 0.8325, [(16, 0.8325, 0.8251, 0.0003017239095670012, 0.00038964361040251484, 37, [20, 21, 20, 20, 56]), (16, 0.8325, 0.8251, 0.0003017239095670012, 0.00038964361040251484, 37, [20, 21, 20, 20, 56]), (16, 0.8325, 0.8251, 0.0003571654951650947, 0.00040172080846538643, 34, [20, 20, 20, 20, 38]), (16, 0.8274, 0.82, 0.00041106667189337966, 0.00041461894430711184, 34, [20, 20, 20, 20, 38]), (16, 0.8173, 0.81, 4.504280971099451e-05, 0.00042221502857250274, 27, [31, 51, 45, 78, 87]), (16, 0.8122, 0.8049, 4.8234396409293384e-05, 0.0003999125675077866, 39, [20, 20, 20, 20, 33]), (16, 0.8122, 0.8049, 4.8234396409293384e-05, 0.0003999125675077866, 39, [20, 20, 20, 20, 33]), (16, 0.8071, 0.7999, 0.00014546658566012765, 0.0004006032871981588, 28, [20, 37, 25, 57, 76]), (16, 0.8071, 0.7999, 0.0009304432038647431, 0.0004434060121728042, 35, [20, 21, 20, 20, 56]), (16, 0.797, 0.7898, 0.00010495017271641821, 0.00039045942954726186, 35, [20, 31, 28, 59, 85]), (16, 0.7868, 0.7798, 6.015357884125588e-05, 0.00039979435744796617, 36, [31, 51, 45, 78, 87])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 40: 35.7 s, best val metric 0.8325, [(17, 0.8325, 0.8192, 0.0003017239095670012, 0.00038964361040251484, 37, [20, 21, 20, 20, 56]), (17, 0.8223, 0.8092, 0.00041106667189337966, 0.00041461894430711184, 34, [20, 20, 20, 20, 38]), (17, 0.8223, 0.8092, 0.00041106667189337966, 0.00041461894430711184, 34, [20, 20, 20, 20, 38]), (17, 0.8071, 0.7942, 3.1622776601683795e-05, 0.0004197091773757819, 33, [20, 21, 20, 20, 56]), (17, 0.8071, 0.7942, 0.0003017239095670012, 0.00038964361040251484, 37, [20, 21, 20, 20, 56]), (17, 0.8071, 0.7942, 3.934136036248002e-05, 0.00041030717529307113, 36, [20, 21, 20, 20, 56]), (17, 0.8071, 0.7942, 5.2485626782126936e-05, 0.00036141703828648195, 33, [20, 21, 20, 20, 56]), (17, 0.802, 0.7892, 0.0009304432038647431, 0.0004434060121728042, 35, [20, 21, 20, 20, 56]), (17, 0.802, 0.7892, 4.8234396409293384e-05, 0.0003999125675077866, 39, [20, 20, 20, 20, 33]), (17, 0.7919, 0.7793, 3.1622776601683795e-05, 0.0004011410511642796, 33, [20, 37, 25, 57, 76]), (17, 0.7716, 0.7593, 7.06017085591079e-05, 0.000394724842572911, 33, [31, 51, 45, 78, 87])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 41: 34.0 s, best val metric 0.8325, [(18, 0.8325, 0.8089, 0.0003017239095670012, 0.00038964361040251484, 37, [20, 21, 20, 20, 56]), (18, 0.8173, 0.7941, 7.126466016693615e-05, 0.0003567913924762159, 35, [20, 20, 20, 20, 33]), (18, 0.8122, 0.7892, 6.197487603065232e-05, 0.00044384884808159063, 32, [20, 21, 20, 20, 56]), (18, 0.8122, 0.7892, 6.197487603065232e-05, 0.00044384884808159063, 32, [20, 21, 20, 20, 56]), (18, 0.802, 0.7793, 9.925441231645962e-05, 0.00041117066458574666, 41, [20, 37, 25, 57, 76]), (18, 0.802, 0.7793, 7.099172691940295e-05, 0.0004332977087913965, 37, [20, 21, 20, 20, 56]), (18, 0.802, 0.7793, 0.0003017239095670012, 0.00038964361040251484, 37, [20, 21, 20, 20, 56]), (18, 0.802, 0.7793, 3.1622776601683795e-05, 0.0004017428878978811, 35, [20, 21, 20, 20, 56]), (18, 0.802, 0.7793, 7.099172691940295e-05, 0.0004332977087913965, 37, [20, 21, 20, 20, 56]), (18, 0.802, 0.7793, 3.1622776601683795e-05, 0.0004017428878978811, 35, [20, 21, 20, 20, 56]), (18, 0.797, 0.7744, 3.1622776601683795e-05, 0.0004197091773757819, 33, [20, 21, 20, 20, 56])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 42: 32.6 s, best val metric 0.8325, [(19, 0.8325, 0.791, 0.0003017239095670012, 0.00038964361040251484, 37, [20, 21, 20, 20, 56]), (19, 0.8122, 0.7717, 9.925441231645962e-05, 0.00041117066458574666, 41, [20, 37, 25, 57, 76]), (19, 0.8071, 0.7669, 3.1622776601683795e-05, 0.0004197091773757819, 33, [20, 21, 20, 20, 56]), (19, 0.802, 0.762, 8.223193781152496e-05, 0.000378624365438417, 34, [20, 21, 20, 20, 56]), (19, 0.802, 0.762, 5.6685458869628727e-05, 0.0004274851607929438, 39, [20, 21, 20, 20, 56]), (19, 0.802, 0.762, 5.6685458869628727e-05, 0.0004274851607929438, 39, [20, 21, 20, 20, 56]), (19, 0.797, 0.7572, 7.126466016693615e-05, 0.0003567913924762159, 35, [20, 20, 20, 20, 33]), (19, 0.797, 0.7572, 0.0002812712218671943, 0.00045518617400164507, 32, [20, 21, 20, 20, 56]), (19, 0.797, 0.7572, 0.0002812712218671943, 0.00045518617400164507, 32, [20, 21, 20, 20, 56]), (19, 0.797, 0.7572, 0.0003144246411606089, 0.00045765043524545343, 28, [20, 21, 20, 20, 56]), (19, 0.797, 0.7572, 7.126466016693615e-05, 0.0003567913924762159, 35, [20, 20, 20, 20, 33])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 43: 32.9 s, best val metric 0.8325, [(20, 0.8325, 0.7606, 0.0003017239095670012, 0.00038964361040251484, 37, [20, 21, 20, 20, 56]), (20, 0.8071, 0.7374, 8.223193781152496e-05, 0.000378624365438417, 34, [20, 21, 20, 20, 56]), (20, 0.8071, 0.7374, 4.0299900280613034e-05, 0.00042412152991860966, 31, [20, 21, 20, 20, 56]), (20, 0.8071, 0.7374, 7.126466016693615e-05, 0.0003567913924762159, 35, [20, 20, 20, 20, 33]), (20, 0.802, 0.7328, 8.092054279001956e-05, 0.00041770329141605444, 38, [20, 21, 20, 20, 56]), (20, 0.797, 0.7282, 0.00015937411337192615, 0.0004555561628278226, 28, [20, 20, 20, 20, 33]), (20, 0.797, 0.7282, 0.00015937411337192615, 0.0004555561628278226, 28, [20, 20, 20, 20, 33]), (20, 0.7919, 0.7235, 5.6685458869628727e-05, 0.0004274851607929438, 39, [20, 21, 20, 20, 56]), (20, 0.7868, 0.7189, 7.126466016693615e-05, 0.0003567913924762159, 35, [20, 20, 20, 20, 33]), (20, 0.7817, 0.7142, 9.089722324057847e-05, 0.00039419048695784963, 38, [20, 21, 20, 20, 56]), (20, 0.7817, 0.7142, 5.6685458869628727e-05, 0.0004274851607929438, 39, [20, 21, 20, 20, 56])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 44: 32.0 s, best val metric 0.8325, [(21, 0.8325, 0.7115, 0.0003017239095670012, 0.00038964361040251484, 37, [20, 21, 20, 20, 56]), (21, 0.8274, 0.7072, 5.6685458869628727e-05, 0.0004274851607929438, 39, [20, 21, 20, 20, 56]), (21, 0.8274, 0.7072, 3.1622776601683795e-05, 0.0003661470957182246, 37, [20, 21, 20, 20, 56]), (21, 0.8173, 0.6985, 7.948507144253462e-05, 0.00041283503198493376, 35, [20, 21, 20, 20, 56]), (21, 0.8173, 0.6985, 7.948507144253462e-05, 0.00041283503198493376, 35, [20, 21, 20, 20, 56]), (21, 0.8071, 0.6898, 0.00011778658827524312, 0.0004159496538010916, 39, [20, 21, 20, 20, 56]), (21, 0.797, 0.6811, 7.89001100009046e-05, 0.0004096574892709833, 35, [20, 21, 20, 20, 56]), (21, 0.797, 0.6811, 7.89001100009046e-05, 0.0004096574892709833, 35, [20, 21, 20, 20, 56]), (21, 0.797, 0.6811, 7.89001100009046e-05, 0.0004096574892709833, 35, [20, 21, 20, 20, 56]), (21, 0.7919, 0.6768, 7.126466016693615e-05, 0.0003567913924762159, 35, [20, 20, 20, 20, 33]), (21, 0.7919, 0.6768, 7.126466016693615e-05, 0.0003567913924762159, 35, [20, 20, 20, 20, 33])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 45: 31.7 s, best val metric 0.8325, [(1, 0.6802, 0.6802, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (22, 0.8325, 0.6374, 0.0003017239095670012, 0.00038964361040251484, 37, [20, 21, 20, 20, 56]), (22, 0.8274, 0.6335, 0.00013648252581612507, 0.00037240257952028113, 41, [20, 21, 20, 20, 56]), (22, 0.8071, 0.6179, 7.948507144253462e-05, 0.00041283503198493376, 35, [20, 21, 20, 20, 56]), (22, 0.802, 0.6141, 7.061446995903452e-05, 0.00037604544826730466, 34, [20, 21, 20, 20, 56]), (22, 0.802, 0.6141, 0.00017582264002456783, 0.00033529423534887204, 32, [20, 21, 20, 20, 56]), (22, 0.802, 0.6141, 0.00017582264002456783, 0.00033529423534887204, 32, [20, 21, 20, 20, 56]), (22, 0.802, 0.6141, 7.061446995903452e-05, 0.00037604544826730466, 34, [20, 21, 20, 20, 56]), (22, 0.802, 0.6141, 0.00017582264002456783, 0.00033529423534887204, 32, [20, 21, 20, 20, 56]), (22, 0.797, 0.6102, 0.00046338233691799787, 0.00041781287956791437, 29, [20, 21, 20, 20, 56]), (22, 0.797, 0.6102, 0.00046338233691799787, 0.00041781287956791437, 29, [20, 21, 20, 20, 56])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 46: 34.2 s, best val metric 0.8325, [(2, 0.7411, 0.7411, 0.0003652538335108405, 0.0003676275404528943, 32, [20, 20, 20, 20, 20]), (2, 0.7411, 0.7411, 0.0003652538335108405, 0.0003676275404528943, 32, [20, 20, 20, 20, 20]), (2, 0.6802, 0.6802, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (23, 0.8325, 0.5367, 0.00046338233691799787, 0.00041781287956791437, 29, [20, 21, 20, 20, 56]), (23, 0.8173, 0.5269, 0.002176079257691802, 0.00041916703140941334, 36, [20, 21, 20, 20, 56]), (23, 0.8173, 0.5269, 0.0003017239095670012, 0.00038964361040251484, 37, [20, 21, 20, 20, 56]), (23, 0.8122, 0.5237, 0.00033876701828042456, 0.00034711781910963367, 24, [20, 21, 20, 20, 56]), (23, 0.8071, 0.5204, 0.00013648252581612507, 0.00037240257952028113, 41, [20, 21, 20, 20, 56]), (23, 0.8071, 0.5204, 0.00011727195189552232, 0.00039353716700837356, 37, [20, 21, 20, 20, 56]), (23, 0.802, 0.5171, 0.00017582264002456783, 0.00033529423534887204, 32, [20, 21, 20, 20, 56]), (23, 0.802, 0.5171, 7.061446995903452e-05, 0.00037604544826730466, 34, [20, 21, 20, 20, 56])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 47: 37.2 s, best val metric 0.8071, [(3, 0.7766, 0.7766, 0.00012497422354775182, 0.0003880683886358985, 31, [20, 21, 20, 23, 25]), (3, 0.7766, 0.7766, 0.00012497422354775182, 0.0003880683886358985, 31, [20, 21, 20, 23, 25]), (3, 0.7614, 0.7614, 0.0003652538335108405, 0.0003676275404528943, 32, [20, 20, 20, 20, 20]), (3, 0.7614, 0.7614, 0.0003652538335108405, 0.0003676275404528943, 32, [20, 20, 20, 20, 20]), (3, 0.7614, 0.7614, 0.0003652538335108405, 0.0003676275404528943, 32, [20, 20, 20, 20, 20]), (3, 0.7462, 0.7462, 0.0003652538335108405, 0.0003676275404528943, 32, [20, 20, 20, 20, 20]), (3, 0.7462, 0.7462, 0.0003652538335108405, 0.0003676275404528943, 32, [20, 20, 20, 20, 20]), (3, 0.7411, 0.7411, 0.0003652538335108405, 0.0003676275404528943, 32, [20, 20, 20, 20, 20]), (1, 0.6802, 0.6802, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6802, 0.6802, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (24, 0.8071, 0.4052, 0.0017044759013069846, 0.00037680740332873255, 29, [20, 21, 20, 20, 56])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 48: 48.5 s, best val metric 0.7817, [(4, 0.7817, 0.7817, 0.0003652538335108405, 0.0003676275404528943, 32, [20, 20, 20, 20, 20]), (4, 0.7817, 0.7817, 0.0003652538335108405, 0.0003676275404528943, 32, [20, 20, 20, 20, 20]), (4, 0.7817, 0.7817, 0.0003652538335108405, 0.0003676275404528943, 32, [20, 20, 20, 20, 20]), (2, 0.7817, 0.7817, 7.177810871130942e-05, 0.0003921741067168, 37, [20, 20, 25, 29, 28]), (4, 0.7766, 0.7766, 0.00012497422354775182, 0.0003880683886358985, 31, [20, 27, 20, 22, 27]), (4, 0.7766, 0.7766, 0.00012497422354775182, 0.0003880683886358985, 31, [20, 27, 20, 22, 27]), (4, 0.7766, 0.7766, 0.00012497422354775182, 0.0003880683886358985, 31, [20, 21, 20, 23, 25]), (4, 0.7716, 0.7716, 0.0003652538335108405, 0.0003676275404528943, 32, [20, 20, 20, 20, 20]), (4, 0.7614, 0.7614, 0.0003652538335108405, 0.0003676275404528943, 32, [20, 20, 20, 20, 20]), (4, 0.7614, 0.7614, 0.0014362772369838194, 0.0003577597395630903, 34, [20, 20, 20, 20, 20]), (4, 0.7411, 0.7411, 0.0004070996625469285, 0.00035008758912279684, 32, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n",
      "Generation 49: 50.3 s, best val metric 0.8122, [(5, 0.8122, 0.8122, 0.00012497422354775182, 0.0003880683886358985, 31, [20, 27, 20, 28, 28]), (5, 0.8122, 0.8122, 0.00012497422354775182, 0.0003880683886358985, 31, [20, 27, 20, 28, 28]), (5, 0.8122, 0.8122, 0.00012497422354775182, 0.0003880683886358985, 31, [20, 27, 20, 28, 28]), (5, 0.8122, 0.8122, 0.00012497422354775182, 0.0003880683886358985, 31, [20, 27, 20, 28, 28]), (5, 0.797, 0.797, 7.488104582221782e-05, 0.0003737474924630342, 29, [20, 32, 20, 40, 35]), (5, 0.797, 0.797, 7.488104582221782e-05, 0.0003737474924630342, 29, [20, 32, 20, 40, 35]), (5, 0.7919, 0.7919, 0.0007300125080141333, 0.0003603441020203114, 33, [20, 20, 20, 20, 20]), (5, 0.7868, 0.7868, 0.00012497422354775182, 0.0003880683886358985, 31, [20, 32, 20, 38, 33]), (3, 0.7868, 0.7868, 7.177810871130942e-05, 0.0003921741067168, 37, [20, 24, 24, 35, 34]), (5, 0.7817, 0.7817, 0.0003652538335108405, 0.0003676275404528943, 32, [20, 20, 20, 20, 20]), (5, 0.7766, 0.7766, 0.0003652538335108405, 0.0003676275404528943, 32, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8477157360406091 ####\n"
     ]
    }
   ],
   "source": [
    "evolution = Evolution()\n",
    "hyperparameters = {\n",
    "    'regularization_penalty': Hyperparameter(3., 2.5, 4.5, 0.5),\n",
    "    'learning_rate': Hyperparameter(0.0004, 0.0001, 0.0006, 0.000025),\n",
    "    'batch_size': Hyperparameter(32, 16, 64, 4),\n",
    "}\n",
    "evolution.run(x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test),\n",
    "              layer_sizes=[20, 20, 20, 20, 20], output_neurons=10, hyperparameters=hyperparameters, n_parents=5, population_size=10, \n",
    "              n_generations=50, tournament_size=3, n_introduced=2, age_penalty_period=15, use_static_graph=False, fine_tuning=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9f90dd0970>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 244,
       "width": 366
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [0] + [result.time for result in evolution.results]\n",
    "x += [x[-1] + (x[-1] - x[-2]) / 10]\n",
    "y = [0, 0] + [result.best_val_metric for result in evolution.results]\n",
    "plt.step(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: 45.5 s, best val metric 0.731, [(1, 0.731, 0.731, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.7056, 0.7056, 0.00028921492562917746, 0.0003895578758751907, 29, [20, 20, 20, 24, 20]), (1, 0.7056, 0.7056, 0.00028921492562917746, 0.0003895578758751907, 29, [20, 20, 20, 24, 20]), (1, 0.6954, 0.6954, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6954, 0.6954, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6853, 0.6853, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6853, 0.6853, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6751, 0.6751, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6751, 0.6751, 0.001174129041363796, 0.00042329314876229755, 35, [20, 20, 20, 20, 20]), (1, 0.6751, 0.6751, 0.001, 0.0004, 32, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.7309644670050761 ####\n",
      "Generation 1: 47.0 s, best val metric 0.7665, [(2, 0.7665, 0.7665, 0.0004602447233079777, 0.00037407283148479907, 32, [20, 20, 20, 20, 20]), (2, 0.7614, 0.7614, 0.0031622776601683794, 0.0003912613754991017, 26, [20, 20, 20, 20, 20]), (2, 0.7614, 0.7614, 0.0002235373815704861, 0.00037673314847099746, 28, [20, 20, 20, 21, 20]), (2, 0.7614, 0.7614, 0.0002235373815704861, 0.00037673314847099746, 28, [20, 20, 20, 21, 20]), (2, 0.7614, 0.7614, 0.0031622776601683794, 0.0003912613754991017, 26, [20, 20, 20, 20, 20]), (2, 0.7614, 0.7614, 0.0031622776601683794, 0.0003912613754991017, 26, [20, 20, 20, 20, 20]), (2, 0.7462, 0.7462, 0.00028921492562917746, 0.0003895578758751907, 29, [20, 20, 20, 24, 20]), (2, 0.7462, 0.7462, 0.00028921492562917746, 0.0003895578758751907, 29, [20, 20, 20, 24, 20]), (2, 0.7462, 0.7462, 0.00028921492562917746, 0.0003895578758751907, 29, [20, 20, 20, 24, 20]), (2, 0.7411, 0.7411, 0.0017061495881723877, 0.0004158646765886293, 26, [20, 20, 20, 20, 20]), (2, 0.731, 0.731, 0.001, 0.0004, 32, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.766497461928934 ####\n",
      "Generation 2: 53.2 s, best val metric 0.7868, [(3, 0.7868, 0.7868, 0.00025326203458600363, 0.0003643096035711841, 24, [20, 20, 20, 20, 20]), (3, 0.7817, 0.7817, 0.0002235373815704861, 0.00037673314847099746, 28, [20, 20, 20, 23, 20]), (3, 0.7766, 0.7766, 0.0005147008090609643, 0.0003978734988607548, 31, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 0.0005574644869510406, 0.00037392055874456426, 29, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 0.0002235373815704861, 0.00037673314847099746, 28, [20, 20, 20, 21, 20]), (3, 0.7716, 0.7716, 0.0007906387576245329, 0.00045461417396308926, 28, [20, 20, 20, 20, 20]), (3, 0.7665, 0.7665, 0.0031622776601683794, 0.0003912613754991017, 26, [20, 20, 20, 20, 20]), (3, 0.7665, 0.7665, 0.0031622776601683794, 0.0003912613754991017, 26, [20, 20, 20, 20, 20]), (3, 0.7665, 0.7665, 0.0004602447233079777, 0.00037407283148479907, 32, [20, 20, 20, 20, 20]), (3, 0.7614, 0.7614, 0.00028921492562917746, 0.0003895578758751907, 29, [20, 20, 20, 23, 20]), (3, 0.7614, 0.7614, 0.00038570567154001345, 0.0003867089718676922, 30, [20, 20, 20, 23, 20])]\n",
      "#### Overall best val metric 0.7868020304568528 ####\n",
      "Generation 3: 51.1 s, best val metric 0.8122, [(4, 0.8122, 0.8122, 0.00040421166420487667, 0.00035534901859568194, 34, [20, 20, 20, 20, 20]), (4, 0.8122, 0.8122, 0.0002235373815704861, 0.00037673314847099746, 28, [20, 20, 20, 24, 21]), (4, 0.7919, 0.7919, 0.00015815861288082854, 0.0003737748185831982, 30, [20, 20, 20, 20, 23]), (4, 0.7919, 0.7919, 0.00015815861288082854, 0.0003737748185831982, 30, [20, 20, 20, 20, 23]), (4, 0.7868, 0.7868, 0.0006631032435048156, 0.0003342778618052662, 33, [20, 20, 20, 20, 20]), (4, 0.7868, 0.7868, 0.0028879959829921508, 0.00037925996105126207, 34, [20, 20, 20, 20, 20]), (4, 0.7868, 0.7868, 0.00025326203458600363, 0.0003643096035711841, 24, [20, 20, 20, 20, 20]), (4, 0.7766, 0.7766, 0.00025326203458600363, 0.0003643096035711841, 24, [20, 20, 20, 29, 25]), (4, 0.7766, 0.7766, 0.0004602447233079777, 0.00037407283148479907, 32, [20, 20, 20, 20, 20]), (4, 0.7716, 0.7716, 0.0013481537364850777, 0.0003920401247221467, 36, [20, 20, 20, 23, 20]), (4, 0.7665, 0.7665, 0.0005147008090609643, 0.0003978734988607548, 31, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8121827411167513 ####\n",
      "Generation 4: 50.9 s, best val metric 0.8173, [(5, 0.8173, 0.8173, 0.00012652420624108406, 0.0003885685824224899, 29, [20, 21, 20, 40, 39]), (5, 0.8173, 0.8173, 0.00012652420624108406, 0.0003885685824224899, 29, [20, 21, 20, 40, 39]), (5, 0.8122, 0.8122, 0.00040421166420487667, 0.00035534901859568194, 34, [20, 20, 20, 20, 20]), (5, 0.802, 0.802, 8.867762907925142e-05, 0.0003380907656241918, 29, [20, 29, 20, 30, 38]), (5, 0.802, 0.802, 0.0019339688399093008, 0.00035317949692874643, 35, [20, 20, 20, 20, 20]), (5, 0.797, 0.797, 0.0006631032435048156, 0.0003342778618052662, 33, [20, 20, 20, 20, 20]), (5, 0.797, 0.797, 0.0006631032435048156, 0.0003342778618052662, 33, [20, 20, 20, 20, 20]), (5, 0.7919, 0.7919, 0.00040421166420487667, 0.00035534901859568194, 34, [20, 20, 20, 20, 20]), (5, 0.7868, 0.7868, 0.0004602447233079777, 0.00037407283148479907, 32, [20, 20, 20, 20, 20]), (5, 0.7868, 0.7868, 0.001667957395852918, 0.00038023959691878387, 35, [20, 20, 20, 20, 20]), (5, 0.7868, 0.7868, 0.001667957395852918, 0.00038023959691878387, 35, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.817258883248731 ####\n",
      "Generation 5: 50.1 s, best val metric 0.8173, [(6, 0.8173, 0.8173, 0.00012652420624108406, 0.0003885685824224899, 29, [20, 21, 20, 40, 39]), (6, 0.8071, 0.8071, 0.00012652420624108406, 0.0003885685824224899, 29, [20, 29, 20, 56, 44]), (6, 0.8071, 0.8071, 0.00012652420624108406, 0.0003885685824224899, 29, [20, 29, 20, 56, 44]), (6, 0.8071, 0.8071, 0.0006902054957711679, 0.0003301723939084215, 34, [20, 20, 20, 20, 20]), (6, 0.8071, 0.8071, 0.00012652420624108406, 0.0003885685824224899, 29, [20, 29, 20, 56, 44]), (6, 0.8071, 0.8071, 0.00012652420624108406, 0.0003885685824224899, 29, [20, 29, 20, 56, 44]), (6, 0.797, 0.797, 0.00076620322992858, 0.00036766947474213964, 34, [20, 20, 20, 20, 20]), (6, 0.797, 0.797, 6.308965050929871e-05, 0.00033910395610204914, 31, [20, 34, 20, 40, 39]), (6, 0.7868, 0.7868, 0.0003365643907535467, 0.0003338096816069723, 31, [20, 20, 20, 20, 20]), (6, 0.7766, 0.7766, 0.002540491295587667, 0.0003316557827045641, 29, [20, 20, 20, 20, 20]), (6, 0.7766, 0.7766, 0.0005204094470003815, 0.0003209286688375265, 37, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.817258883248731 ####\n",
      "Generation 6: 54.4 s, best val metric 0.8173, [(7, 0.8173, 0.8173, 0.00012652420624108406, 0.0003885685824224899, 29, [20, 21, 20, 40, 39]), (7, 0.8122, 0.8122, 0.0005204094470003815, 0.0003209286688375265, 37, [20, 20, 20, 20, 20]), (7, 0.8122, 0.8122, 0.0005204094470003815, 0.0003209286688375265, 37, [20, 20, 20, 20, 20]), (7, 0.8122, 0.8122, 0.0005204094470003815, 0.0003209286688375265, 37, [20, 20, 20, 20, 20]), (7, 0.8122, 0.8122, 0.0005204094470003815, 0.0003209286688375265, 37, [20, 20, 20, 20, 20]), (7, 0.8071, 0.8071, 0.0006902054957711679, 0.0003301723939084215, 34, [20, 20, 20, 20, 20]), (7, 0.797, 0.797, 0.00012652420624108406, 0.0003885685824224899, 29, [20, 33, 20, 39, 39]), (7, 0.7868, 0.7868, 0.0003483011900095498, 0.0003140568163922695, 35, [20, 20, 20, 20, 20]), (7, 0.7868, 0.7868, 0.00048146110839720986, 0.00034595798610160373, 35, [20, 20, 20, 24, 20]), (7, 0.7868, 0.7868, 0.00048146110839720986, 0.00034595798610160373, 35, [20, 20, 20, 24, 20]), (7, 0.7868, 0.7868, 0.0003483011900095498, 0.0003140568163922695, 35, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.817258883248731 ####\n",
      "Generation 7: 50.2 s, best val metric 0.8173, [(8, 0.8173, 0.8173, 0.00012652420624108406, 0.0003885685824224899, 29, [20, 21, 20, 40, 39]), (8, 0.8122, 0.8122, 0.00048146110839720986, 0.00034595798610160373, 35, [20, 20, 20, 20, 20]), (8, 0.8122, 0.8122, 0.00048146110839720986, 0.00034595798610160373, 35, [20, 20, 20, 20, 20]), (8, 0.8122, 0.8122, 0.00048146110839720986, 0.00034595798610160373, 35, [20, 20, 20, 20, 20]), (8, 0.8071, 0.8071, 0.00011776653012498602, 0.00039236528030668345, 37, [20, 32, 20, 38, 40]), (8, 0.8071, 0.8071, 4.3713923144226886e-05, 0.00039541702516200926, 28, [22, 40, 40, 40, 40]), (8, 0.8071, 0.8071, 4.3713923144226886e-05, 0.00039541702516200926, 28, [22, 40, 40, 40, 40]), (8, 0.7919, 0.7919, 0.0005204094470003815, 0.0003209286688375265, 37, [20, 20, 20, 20, 20]), (8, 0.7817, 0.7817, 0.000174648380636063, 0.000343321803036306, 33, [20, 20, 20, 33, 27]), (8, 0.7817, 0.7817, 0.000174648380636063, 0.000343321803036306, 33, [20, 20, 20, 33, 27]), (8, 0.7766, 0.7766, 0.0003483011900095498, 0.0003140568163922695, 35, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.817258883248731 ####\n",
      "Generation 8: 55.6 s, best val metric 0.8173, [(9, 0.8173, 0.8173, 0.00012652420624108406, 0.0003885685824224899, 29, [20, 21, 20, 40, 39]), (9, 0.8071, 0.8071, 0.00011776653012498602, 0.00039236528030668345, 37, [20, 30, 20, 52, 42]), (9, 0.797, 0.797, 0.00048146110839720986, 0.00034595798610160373, 35, [20, 20, 20, 20, 20]), (9, 0.797, 0.797, 0.00012652420624108406, 0.0003885685824224899, 29, [20, 23, 20, 51, 40]), (9, 0.797, 0.797, 0.00048146110839720986, 0.00034595798610160373, 35, [20, 20, 20, 20, 20]), (9, 0.797, 0.797, 0.00012652420624108406, 0.0003885685824224899, 29, [20, 23, 20, 51, 40]), (9, 0.797, 0.797, 0.00014367384692360447, 0.00036458991543127605, 32, [20, 31, 23, 54, 47]), (9, 0.797, 0.797, 0.00014367384692360447, 0.00036458991543127605, 32, [20, 31, 23, 54, 47]), (9, 0.7919, 0.7919, 0.0005681724544637122, 0.0003346837646383939, 30, [20, 20, 20, 20, 20]), (9, 0.7868, 0.7868, 0.0003483011900095498, 0.0003140568163922695, 35, [20, 20, 20, 20, 20]), (9, 0.7766, 0.7766, 4.3713923144226886e-05, 0.00039541702516200926, 28, [23, 59, 60, 60, 60])]\n",
      "#### Overall best val metric 0.817258883248731 ####\n",
      "Generation 9: 59.4 s, best val metric 0.8173, [(10, 0.8173, 0.8173, 0.00012652420624108406, 0.0003885685824224899, 29, [20, 21, 20, 40, 39]), (10, 0.8071, 0.8071, 0.00011776653012498602, 0.00039236528030668345, 37, [20, 30, 20, 70, 51]), (10, 0.802, 0.802, 0.00012652420624108406, 0.0003885685824224899, 29, [20, 21, 20, 45, 50]), (10, 0.802, 0.802, 0.00048146110839720986, 0.00034595798610160373, 35, [20, 20, 20, 20, 20]), (10, 0.802, 0.802, 0.00048146110839720986, 0.00034595798610160373, 35, [20, 20, 20, 20, 20]), (10, 0.802, 0.802, 0.00012652420624108406, 0.0003885685824224899, 29, [20, 21, 20, 45, 50]), (10, 0.797, 0.797, 0.0001914513691490229, 0.0003965115895883497, 31, [20, 20, 20, 33, 32]), (10, 0.797, 0.797, 0.00012652420624108406, 0.0003885685824224899, 29, [20, 29, 22, 62, 49]), (10, 0.797, 0.797, 0.00048146110839720986, 0.00034595798610160373, 35, [20, 20, 20, 20, 21]), (10, 0.7919, 0.7919, 0.00034975457491376576, 0.00035286197355761077, 28, [20, 20, 20, 25, 22]), (10, 0.7919, 0.7919, 0.0002931328357473973, 0.0003788160544446744, 41, [20, 21, 20, 26, 21])]\n",
      "#### Overall best val metric 0.817258883248731 ####\n",
      "Generation 10: 54.4 s, best val metric 0.8173, [(11, 0.8173, 0.8173, 0.00012652420624108406, 0.0003885685824224899, 29, [20, 21, 20, 42, 45]), (11, 0.8173, 0.8173, 0.00012652420624108406, 0.0003885685824224899, 29, [20, 21, 20, 42, 45]), (11, 0.8173, 0.8173, 0.00012652420624108406, 0.0003885685824224899, 29, [20, 21, 20, 40, 39]), (11, 0.8122, 0.8122, 0.00042513591916339025, 0.0003113767637686857, 32, [20, 20, 20, 33, 25]), (11, 0.802, 0.802, 0.00012652420624108406, 0.0003885685824224899, 29, [20, 23, 20, 72, 56]), (11, 0.802, 0.802, 0.0002931328357473973, 0.0003788160544446744, 41, [20, 20, 20, 20, 22]), (11, 0.802, 0.802, 0.00048146110839720986, 0.00034595798610160373, 35, [20, 20, 20, 20, 20]), (11, 0.802, 0.802, 0.00012652420624108406, 0.0003885685824224899, 29, [20, 23, 20, 72, 56]), (11, 0.802, 0.802, 0.00012652420624108406, 0.0003885685824224899, 29, [20, 23, 20, 72, 56]), (11, 0.797, 0.797, 0.00034975457491376576, 0.00035286197355761077, 28, [20, 20, 20, 28, 27]), (11, 0.7919, 0.7919, 0.00012652420624108406, 0.0003885685824224899, 29, [20, 23, 20, 47, 49])]\n",
      "#### Overall best val metric 0.817258883248731 ####\n",
      "Generation 11: 57.7 s, best val metric 0.8173, [(12, 0.8173, 0.8173, 0.00012652420624108406, 0.0003885685824224899, 29, [20, 21, 20, 42, 45]), (12, 0.8122, 0.8122, 0.00012652420624108406, 0.0003885685824224899, 29, [20, 21, 20, 59, 59]), (12, 0.8071, 0.8071, 0.00042513591916339025, 0.0003113767637686857, 32, [20, 20, 20, 22, 25]), (12, 0.8071, 0.8071, 0.00042513591916339025, 0.0003113767637686857, 32, [20, 20, 20, 22, 25]), (12, 0.802, 0.802, 0.0004400506060944628, 0.0003459902518319791, 36, [20, 20, 20, 26, 22]), (12, 0.797, 0.797, 0.00012652420624108406, 0.0003885685824224899, 29, [20, 26, 20, 58, 51]), (12, 0.797, 0.797, 0.0002931328357473973, 0.0003788160544446744, 41, [20, 20, 20, 21, 22]), (12, 0.797, 0.797, 0.00034639245126227267, 0.00038908853847912457, 36, [20, 20, 20, 20, 26]), (12, 0.7919, 0.7919, 0.00023653826357660526, 0.0003467800719864603, 32, [20, 20, 20, 32, 34]), (12, 0.7919, 0.7919, 0.00020424953105375491, 0.0003627387439700978, 25, [20, 20, 20, 32, 39]), (12, 0.7817, 0.7817, 5.1700976250544336e-05, 0.0004197835433370623, 30, [37, 43, 40, 92, 76])]\n",
      "#### Overall best val metric 0.817258883248731 ####\n",
      "Generation 12: 56.0 s, best val metric 0.8173, [(13, 0.8173, 0.8173, 0.00012652420624108406, 0.0003885685824224899, 29, [20, 21, 20, 42, 45]), (13, 0.8071, 0.8071, 8.090164516829177e-05, 0.000393163773437749, 32, [20, 24, 36, 40, 46]), (13, 0.8071, 0.8071, 8.090164516829177e-05, 0.000393163773437749, 32, [20, 24, 36, 40, 46]), (13, 0.8071, 0.8071, 0.00034639245126227267, 0.00038908853847912457, 36, [20, 20, 20, 20, 34]), (13, 0.802, 0.802, 0.00042513591916339025, 0.0003113767637686857, 32, [20, 20, 20, 20, 26]), (13, 0.802, 0.802, 0.0004400506060944628, 0.0003459902518319791, 36, [20, 20, 20, 20, 21]), (13, 0.797, 0.797, 0.00023653826357660526, 0.0003467800719864603, 32, [20, 20, 20, 32, 33]), (13, 0.797, 0.797, 5.745425585429212e-05, 0.0003710992252040296, 33, [20, 35, 39, 52, 54]), (13, 0.7919, 0.7919, 6.112511007163529e-05, 0.0003634810024222247, 30, [20, 39, 37, 42, 45]), (13, 0.7817, 0.7817, 3.1622776601683795e-05, 0.0003171982634105431, 31, [23, 40, 40, 46, 42]), (13, 0.7716, 0.7716, 0.00018743366231841878, 0.0003855330030780977, 28, [20, 20, 20, 31, 42])]\n",
      "#### Overall best val metric 0.817258883248731 ####\n",
      "Generation 13: 58.6 s, best val metric 0.8223, [(14, 0.8223, 0.8223, 0.0001284235807557094, 0.00038869963725579425, 35, [20, 35, 33, 62, 46]), (14, 0.8173, 0.8173, 8.090164516829177e-05, 0.000393163773437749, 32, [20, 33, 55, 60, 66]), (14, 0.8173, 0.8173, 8.090164516829177e-05, 0.000393163773437749, 32, [20, 33, 55, 60, 66]), (14, 0.8173, 0.8173, 3.1622776601683795e-05, 0.0003158756867726271, 26, [26, 59, 57, 62, 65]), (14, 0.8173, 0.8173, 3.1622776601683795e-05, 0.0003158756867726271, 26, [26, 59, 57, 62, 65]), (14, 0.8173, 0.8173, 0.00012652420624108406, 0.0003885685824224899, 29, [20, 21, 20, 42, 45]), (14, 0.8071, 0.8071, 8.090164516829177e-05, 0.000393163773437749, 32, [20, 25, 42, 60, 65]), (14, 0.802, 0.802, 0.00023653826357660526, 0.0003467800719864603, 32, [20, 20, 20, 34, 36]), (14, 0.802, 0.802, 0.00023653826357660526, 0.0003467800719864603, 32, [20, 20, 20, 34, 36]), (14, 0.802, 0.802, 0.00023653826357660526, 0.0003467800719864603, 32, [20, 20, 20, 34, 36]), (14, 0.802, 0.802, 0.0004400506060944628, 0.0003459902518319791, 36, [20, 20, 20, 20, 21])]\n",
      "#### Overall best val metric 0.8223350253807107 ####\n",
      "Generation 14: 63.7 s, best val metric 0.8274, [(15, 0.8274, 0.8274, 0.00023653826357660526, 0.0003467800719864603, 32, [20, 20, 20, 29, 50]), (15, 0.8223, 0.8223, 0.0001284235807557094, 0.00038869963725579425, 35, [20, 35, 33, 62, 46]), (15, 0.8122, 0.8122, 0.00012799227234116785, 0.0003307418074506906, 29, [20, 23, 35, 60, 67]), (15, 0.8122, 0.8122, 0.00012799227234116785, 0.0003307418074506906, 29, [20, 23, 35, 60, 67]), (15, 0.802, 0.802, 0.0004400506060944628, 0.0003459902518319791, 36, [20, 20, 20, 20, 21]), (15, 0.802, 0.802, 9.538356281230915e-05, 0.00037239761853550976, 32, [20, 30, 25, 54, 56]), (15, 0.797, 0.797, 8.090164516829177e-05, 0.000393163773437749, 32, [20, 47, 53, 80, 78]), (15, 0.797, 0.797, 0.0004838315815344971, 0.0003866583550164815, 30, [20, 21, 20, 37, 26]), (15, 0.797, 0.797, 8.090164516829177e-05, 0.000393163773437749, 32, [20, 47, 53, 80, 78]), (15, 0.7919, 0.7919, 0.0003927416292328508, 0.0003436480008225889, 33, [20, 20, 20, 21, 35]), (15, 0.7868, 0.7868, 5.0595456319775415e-05, 0.000382962748269417, 40, [20, 39, 26, 62, 62])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 15: 38.1 s, best val metric 0.8274, [(16, 0.8274, 0.82, 0.0004370929823745678, 0.0003787799666485656, 36, [20, 20, 20, 29, 50]), (16, 0.8274, 0.82, 0.00023653826357660526, 0.0003467800719864603, 32, [20, 20, 20, 29, 50]), (16, 0.8223, 0.815, 3.1622776601683795e-05, 0.00033364390616370224, 29, [20, 30, 25, 54, 56]), (16, 0.802, 0.7949, 0.00012799227234116785, 0.0003307418074506906, 29, [20, 23, 35, 60, 67]), (16, 0.802, 0.7949, 0.00012799227234116785, 0.0003307418074506906, 29, [20, 23, 35, 60, 67]), (16, 0.802, 0.7949, 0.00012799227234116785, 0.0003307418074506906, 29, [20, 23, 35, 60, 67]), (16, 0.797, 0.7898, 0.0004838315815344971, 0.0003866583550164815, 30, [20, 21, 20, 37, 26]), (16, 0.797, 0.7898, 0.00010628131556558757, 0.00032829190029182035, 40, [20, 35, 33, 62, 46]), (16, 0.797, 0.7898, 0.00010628131556558757, 0.00032829190029182035, 40, [20, 35, 33, 62, 46]), (16, 0.797, 0.7898, 0.00010628131556558757, 0.00032829190029182035, 40, [20, 35, 33, 62, 46]), (16, 0.7919, 0.7848, 0.00023653826357660526, 0.0003467800719864603, 32, [20, 20, 20, 29, 50])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 16: 36.6 s, best val metric 0.8274, [(17, 0.8274, 0.8142, 0.0004370929823745678, 0.0003787799666485656, 36, [20, 20, 20, 29, 50]), (17, 0.8122, 0.7992, 0.00012799227234116785, 0.0003307418074506906, 29, [20, 23, 35, 60, 67]), (17, 0.8122, 0.7992, 0.00012799227234116785, 0.0003307418074506906, 29, [20, 23, 35, 60, 67]), (17, 0.8071, 0.7942, 0.00010628131556558757, 0.00032829190029182035, 40, [20, 35, 33, 62, 46]), (17, 0.8071, 0.7942, 0.00010628131556558757, 0.00032829190029182035, 40, [20, 35, 33, 62, 46]), (17, 0.8071, 0.7942, 0.00010628131556558757, 0.00032829190029182035, 40, [20, 35, 33, 62, 46]), (17, 0.802, 0.7892, 3.1622776601683795e-05, 0.0003543442087824807, 35, [20, 21, 20, 37, 26]), (17, 0.802, 0.7892, 3.1622776601683795e-05, 0.0003543442087824807, 35, [20, 21, 20, 37, 26]), (17, 0.802, 0.7892, 0.00012799227234116785, 0.0003307418074506906, 29, [20, 23, 35, 60, 67]), (17, 0.7919, 0.7793, 0.00017053726365650042, 0.0003403852048448543, 35, [20, 23, 35, 60, 67]), (17, 0.7868, 0.7743, 7.105066199297883e-05, 0.0003428311842042231, 40, [20, 35, 33, 62, 46])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 17: 36.0 s, best val metric 0.8274, [(18, 0.8274, 0.804, 0.0004370929823745678, 0.0003787799666485656, 36, [20, 20, 20, 29, 50]), (18, 0.8122, 0.7892, 3.1622776601683795e-05, 0.00031045350876580393, 23, [20, 21, 20, 37, 26]), (18, 0.8122, 0.7892, 3.1622776601683795e-05, 0.00031045350876580393, 23, [20, 21, 20, 37, 26]), (18, 0.8122, 0.7892, 3.1622776601683795e-05, 0.00031045350876580393, 23, [20, 21, 20, 37, 26]), (18, 0.8122, 0.7892, 3.1622776601683795e-05, 0.00031045350876580393, 23, [20, 21, 20, 37, 26]), (18, 0.802, 0.7793, 0.0010632761275825488, 0.0003775665913460682, 32, [20, 23, 35, 60, 67]), (18, 0.802, 0.7793, 0.00015448408243523668, 0.0003223575060264653, 35, [20, 20, 20, 29, 50]), (18, 0.802, 0.7793, 0.00015448408243523668, 0.0003223575060264653, 35, [20, 20, 20, 29, 50]), (18, 0.7919, 0.7694, 0.00012722139364305647, 0.00034317761925915146, 34, [20, 35, 33, 62, 46]), (18, 0.7868, 0.7645, 0.00012799227234116785, 0.0003307418074506906, 29, [20, 23, 35, 60, 67]), (18, 0.7817, 0.7596, 7.105066199297883e-05, 0.0003428311842042231, 40, [20, 35, 33, 62, 46])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 18: 35.9 s, best val metric 0.8274, [(19, 0.8274, 0.7861, 3.1622776601683795e-05, 0.00031045350876580393, 23, [20, 21, 20, 37, 26]), (19, 0.8274, 0.7861, 0.0004370929823745678, 0.0003787799666485656, 36, [20, 20, 20, 29, 50]), (19, 0.8122, 0.7717, 6.585673415695137e-05, 0.000313021939896241, 29, [20, 20, 20, 29, 50]), (19, 0.8122, 0.7717, 0.00015448408243523668, 0.0003223575060264653, 35, [20, 20, 20, 29, 50]), (19, 0.8122, 0.7717, 6.585673415695137e-05, 0.000313021939896241, 29, [20, 20, 20, 29, 50]), (19, 0.8122, 0.7717, 0.00015448408243523668, 0.0003223575060264653, 35, [20, 20, 20, 29, 50]), (19, 0.8122, 0.7717, 3.1622776601683795e-05, 0.0003198948515500202, 31, [20, 21, 20, 37, 26]), (19, 0.8122, 0.7717, 6.585673415695137e-05, 0.000313021939896241, 29, [20, 20, 20, 29, 50]), (19, 0.797, 0.7572, 0.00011415017029554006, 0.00036504248867043495, 26, [20, 23, 35, 60, 67]), (19, 0.797, 0.7572, 0.0004370929823745678, 0.0003787799666485656, 36, [20, 20, 20, 29, 50]), (19, 0.7868, 0.7476, 6.179536136882298e-05, 0.0002544710323999362, 27, [20, 20, 20, 29, 50])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 19: 35.5 s, best val metric 0.8274, [(20, 0.8274, 0.756, 0.00048004381405997734, 0.0003612807121781675, 33, [20, 20, 20, 29, 50]), (20, 0.8274, 0.756, 3.1622776601683795e-05, 0.00031045350876580393, 23, [20, 21, 20, 37, 26]), (20, 0.8122, 0.7421, 3.1622776601683795e-05, 0.0003628478845146248, 22, [20, 20, 20, 29, 50]), (20, 0.8071, 0.7374, 0.00011415017029554006, 0.00036504248867043495, 26, [20, 23, 35, 60, 67]), (20, 0.802, 0.7328, 3.1622776601683795e-05, 0.0003119405386205873, 27, [20, 20, 20, 29, 50]), (20, 0.797, 0.7282, 6.585673415695137e-05, 0.000313021939896241, 29, [20, 20, 20, 29, 50]), (20, 0.797, 0.7282, 6.585673415695137e-05, 0.000313021939896241, 29, [20, 20, 20, 29, 50]), (20, 0.797, 0.7282, 0.00015448408243523668, 0.0003223575060264653, 35, [20, 20, 20, 29, 50]), (20, 0.797, 0.7282, 6.585673415695137e-05, 0.000313021939896241, 29, [20, 20, 20, 29, 50]), (20, 0.797, 0.7282, 0.00015448408243523668, 0.0003223575060264653, 35, [20, 20, 20, 29, 50]), (20, 0.7919, 0.7235, 0.00021650731210257838, 0.00033272042053824035, 26, [20, 20, 20, 29, 50])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 20: 35.8 s, best val metric 0.8274, [(21, 0.8274, 0.7072, 0.00048004381405997734, 0.0003612807121781675, 33, [20, 20, 20, 29, 50]), (21, 0.8173, 0.6985, 0.00015448408243523668, 0.0003223575060264653, 35, [20, 20, 20, 29, 50]), (21, 0.8122, 0.6941, 6.585673415695137e-05, 0.000313021939896241, 29, [20, 20, 20, 29, 50]), (21, 0.8071, 0.6898, 3.1622776601683795e-05, 0.0003119405386205873, 27, [20, 20, 20, 29, 50]), (21, 0.8071, 0.6898, 6.051822375184578e-05, 0.0003149630448273474, 28, [20, 20, 20, 29, 50]), (21, 0.8071, 0.6898, 3.1622776601683795e-05, 0.0003119405386205873, 27, [20, 20, 20, 29, 50]), (21, 0.802, 0.6855, 6.601300596913788e-05, 0.00036474939964050145, 32, [20, 20, 20, 29, 50]), (21, 0.797, 0.6811, 8.975754114153371e-05, 0.00031499821469799726, 35, [20, 20, 20, 29, 50]), (21, 0.7868, 0.6724, 3.1622776601683795e-05, 0.00039182297635953164, 25, [20, 21, 20, 37, 26]), (21, 0.7868, 0.6724, 4.512277689457668e-05, 0.0003165474804862556, 29, [20, 23, 35, 60, 67]), (21, 0.7614, 0.6508, 9.131261410947072e-05, 0.00037146808010452616, 21, [20, 20, 20, 29, 50])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 21: 34.8 s, best val metric 0.8274, [(22, 0.8274, 0.6335, 0.00048004381405997734, 0.0003612807121781675, 33, [20, 20, 20, 29, 50]), (22, 0.8122, 0.6218, 0.00048004381405997734, 0.0003612807121781675, 33, [20, 20, 20, 29, 50]), (22, 0.8122, 0.6218, 6.051822375184578e-05, 0.0003149630448273474, 28, [20, 20, 20, 29, 50]), (22, 0.8122, 0.6218, 0.00048004381405997734, 0.0003612807121781675, 33, [20, 20, 20, 29, 50]), (22, 0.8122, 0.6218, 6.051822375184578e-05, 0.0003149630448273474, 28, [20, 20, 20, 29, 50]), (22, 0.8071, 0.6179, 3.1622776601683795e-05, 0.0003119405386205873, 27, [20, 20, 20, 29, 50]), (22, 0.802, 0.6141, 6.912786470501699e-05, 0.00036690507645352336, 24, [20, 20, 20, 29, 50]), (22, 0.797, 0.6102, 0.00023717577411885645, 0.00032590285820181694, 29, [20, 20, 20, 29, 50]), (22, 0.797, 0.6102, 8.975754114153371e-05, 0.00031499821469799726, 35, [20, 20, 20, 29, 50]), (22, 0.797, 0.6102, 8.975754114153371e-05, 0.00031499821469799726, 35, [20, 20, 20, 29, 50]), (22, 0.7817, 0.5985, 3.1622776601683795e-05, 0.000410118871671897, 32, [20, 20, 20, 29, 50])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 22: 33.4 s, best val metric 0.8274, [(1, 0.7157, 0.7157, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6853, 0.6853, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6853, 0.6853, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (23, 0.8274, 0.5335, 0.00048004381405997734, 0.0003612807121781675, 33, [20, 20, 20, 29, 50]), (23, 0.8122, 0.5237, 3.1622776601683795e-05, 0.000410118871671897, 32, [20, 20, 20, 29, 50]), (23, 0.8122, 0.5237, 8.975754114153371e-05, 0.00031499821469799726, 35, [20, 20, 20, 29, 50]), (23, 0.8071, 0.5204, 6.051822375184578e-05, 0.0003149630448273474, 28, [20, 20, 20, 29, 50]), (23, 0.8071, 0.5204, 6.051822375184578e-05, 0.0003149630448273474, 28, [20, 20, 20, 29, 50]), (23, 0.797, 0.5138, 0.0006340196582787899, 0.00031961750326563767, 33, [20, 20, 20, 29, 50]), (23, 0.797, 0.5138, 3.1622776601683795e-05, 0.00032019373140778045, 30, [20, 20, 20, 29, 50]), (23, 0.797, 0.5138, 0.00033032868411091984, 0.0003489986445449406, 27, [20, 20, 20, 29, 50])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 23: 37.5 s, best val metric 0.797, [(2, 0.7614, 0.7614, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7614, 0.7614, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.731, 0.731, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7157, 0.7157, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7005, 0.7005, 0.00017954092189108214, 0.00034328411978784687, 32, [20, 20, 20, 20, 20]), (1, 0.665, 0.665, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.665, 0.665, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (1, 0.6142, 0.6142, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (24, 0.797, 0.4001, 0.0004145670354170016, 0.00035210508439579126, 29, [20, 20, 20, 29, 50]), (24, 0.7919, 0.3976, 6.523133774021892e-05, 0.0003769886786787257, 32, [20, 20, 20, 29, 50]), (24, 0.7817, 0.3925, 0.0003701089883896409, 0.0003953256268811633, 30, [20, 20, 20, 29, 50])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 24: 45.0 s, best val metric 0.797, [(3, 0.797, 0.797, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7868, 0.7868, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (2, 0.7665, 0.7665, 0.0010513465938797864, 0.000376171597464011, 24, [20, 20, 20, 20, 20]), (2, 0.7665, 0.7665, 0.0010513465938797864, 0.000376171597464011, 24, [20, 20, 20, 20, 20]), (2, 0.7665, 0.7665, 0.0010513465938797864, 0.000376171597464011, 24, [20, 20, 20, 20, 20]), (3, 0.7614, 0.7614, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (3, 0.7513, 0.7513, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (3, 0.7513, 0.7513, 0.00018704776382006191, 0.0003683420965944222, 27, [20, 20, 20, 20, 20]), (3, 0.7513, 0.7513, 0.00018704776382006191, 0.0003683420965944222, 27, [20, 20, 20, 20, 20]), (3, 0.7462, 0.7462, 0.00017954092189108214, 0.00034328411978784687, 32, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 25: 54.1 s, best val metric 0.797, [(4, 0.797, 0.797, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (4, 0.7919, 0.7919, 0.0008169092610966238, 0.0003733144493102047, 28, [20, 20, 20, 20, 20]), (4, 0.7919, 0.7919, 0.0008169092610966238, 0.0003733144493102047, 28, [20, 20, 20, 20, 20]), (4, 0.7919, 0.7919, 0.0008169092610966238, 0.0003733144493102047, 28, [20, 20, 20, 20, 20]), (4, 0.7868, 0.7868, 0.0003056013509944447, 0.0003656392001085648, 28, [20, 20, 20, 20, 20]), (3, 0.7868, 0.7868, 0.0008540585871676535, 0.00036611636341688056, 27, [20, 20, 20, 20, 20]), (4, 0.7868, 0.7868, 0.00017954092189108214, 0.00034328411978784687, 32, [20, 20, 20, 20, 20]), (3, 0.7817, 0.7817, 0.0010513465938797864, 0.000376171597464011, 24, [20, 20, 20, 20, 20]), (3, 0.7817, 0.7817, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (4, 0.7766, 0.7766, 0.00018704776382006191, 0.0003683420965944222, 27, [20, 20, 20, 20, 20]), (4, 0.7716, 0.7716, 0.00018704776382006191, 0.0003683420965944222, 27, [20, 20, 20, 21, 20])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 26: 54.4 s, best val metric 0.8071, [(5, 0.8071, 0.8071, 0.0005097734262116502, 0.0003307384691036984, 23, [20, 20, 20, 20, 20]), (4, 0.8071, 0.8071, 0.0008540585871676535, 0.00036611636341688056, 27, [20, 20, 20, 20, 20]), (4, 0.8071, 0.8071, 0.0008540585871676535, 0.00036611636341688056, 27, [20, 20, 20, 20, 20]), (4, 0.8071, 0.8071, 0.0008540585871676535, 0.00036611636341688056, 27, [20, 20, 20, 20, 20]), (4, 0.802, 0.802, 6.744177168114923e-05, 0.000373305727228373, 28, [20, 25, 21, 40, 37]), (5, 0.802, 0.802, 0.00018704776382006191, 0.0003683420965944222, 27, [20, 20, 20, 20, 24]), (5, 0.797, 0.797, 0.00015432343392556594, 0.0003951542717645822, 30, [20, 20, 20, 31, 27]), (5, 0.797, 0.797, 0.0008004959474623855, 0.0004276381004196462, 28, [20, 20, 20, 20, 20]), (5, 0.797, 0.797, 0.00015432343392556594, 0.0003951542717645822, 30, [20, 20, 20, 31, 27]), (5, 0.797, 0.797, 0.001, 0.0004, 32, [20, 20, 20, 20, 20]), (5, 0.7614, 0.7614, 0.0008169092610966238, 0.0003733144493102047, 28, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 27: 55.1 s, best val metric 0.8223, [(5, 0.8223, 0.8223, 0.000204703925057141, 0.0003755739189195493, 29, [20, 20, 20, 20, 29]), (6, 0.8122, 0.8122, 0.00015432343392556594, 0.0003951542717645822, 30, [20, 20, 20, 33, 39]), (6, 0.8122, 0.8122, 0.00015432343392556594, 0.0003951542717645822, 30, [20, 20, 20, 33, 39]), (6, 0.8122, 0.8122, 0.00015432343392556594, 0.0003951542717645822, 30, [20, 20, 20, 33, 39]), (6, 0.8122, 0.8122, 0.00015432343392556594, 0.0003951542717645822, 30, [20, 20, 20, 33, 39]), (6, 0.8071, 0.8071, 0.0005097734262116502, 0.0003307384691036984, 23, [20, 20, 20, 20, 20]), (6, 0.8071, 0.8071, 0.0009736066338249792, 0.0003874968509766233, 25, [20, 20, 20, 20, 20]), (6, 0.8071, 0.8071, 0.0005097734262116502, 0.0003307384691036984, 23, [20, 20, 20, 20, 20]), (5, 0.797, 0.797, 6.744177168114923e-05, 0.000373305727228373, 28, [20, 33, 20, 57, 54]), (6, 0.7868, 0.7868, 0.0008004959474623855, 0.0004276381004196462, 28, [20, 20, 20, 20, 20]), (5, 0.7868, 0.7868, 0.0008540585871676535, 0.00036611636341688056, 27, [20, 20, 20, 20, 20])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 28: 56.9 s, best val metric 0.8223, [(6, 0.8223, 0.8223, 0.000204703925057141, 0.0003755739189195493, 29, [20, 20, 20, 20, 29]), (6, 0.8122, 0.8122, 0.000204703925057141, 0.0003755739189195493, 29, [20, 20, 20, 20, 31]), (7, 0.8071, 0.8071, 9.438117965844249e-05, 0.0003812790321241297, 21, [20, 36, 24, 52, 55]), (6, 0.802, 0.802, 6.744177168114923e-05, 0.000373305727228373, 28, [20, 48, 22, 60, 68]), (6, 0.802, 0.802, 6.744177168114923e-05, 0.000373305727228373, 28, [20, 48, 22, 60, 68]), (6, 0.802, 0.802, 6.744177168114923e-05, 0.000373305727228373, 28, [20, 48, 22, 60, 68]), (7, 0.797, 0.797, 0.0005097734262116502, 0.0003307384691036984, 23, [20, 20, 20, 20, 20]), (6, 0.7868, 0.7868, 3.1622776601683795e-05, 0.00037122272104859284, 40, [20, 40, 38, 40, 49]), (7, 0.7817, 0.7817, 0.00015432343392556594, 0.0003951542717645822, 30, [20, 34, 20, 39, 52]), (7, 0.7817, 0.7817, 0.00018884258172313675, 0.0003846896003470653, 36, [20, 20, 20, 25, 25]), (7, 0.7817, 0.7817, 0.00015432343392556594, 0.0003951542717645822, 30, [20, 21, 20, 33, 47])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 29: 61.7 s, best val metric 0.8223, [(7, 0.8223, 0.8223, 0.000204703925057141, 0.0003755739189195493, 29, [20, 20, 20, 20, 29]), (8, 0.8173, 0.8173, 0.00015432343392556594, 0.0003951542717645822, 30, [20, 20, 20, 30, 47]), (7, 0.8071, 0.8071, 8.14010388963412e-05, 0.0003800537843199767, 26, [20, 37, 29, 42, 58]), (7, 0.802, 0.802, 0.000204703925057141, 0.0003755739189195493, 29, [20, 20, 20, 25, 32]), (8, 0.802, 0.802, 0.0004252721053717331, 0.00034351928286616205, 27, [20, 21, 20, 22, 24]), (7, 0.802, 0.802, 0.000204703925057141, 0.0003755739189195493, 29, [20, 20, 20, 20, 30]), (8, 0.802, 0.802, 0.0004252721053717331, 0.00034351928286616205, 27, [20, 21, 20, 22, 24]), (7, 0.797, 0.797, 0.00022372063148113787, 0.000372247393940396, 33, [20, 23, 20, 37, 31]), (7, 0.7919, 0.7919, 0.00042111410770293483, 0.0003792083050791084, 27, [20, 20, 20, 20, 24]), (7, 0.7919, 0.7919, 0.00042111410770293483, 0.0003792083050791084, 27, [20, 20, 20, 20, 24]), (8, 0.7766, 0.7766, 0.00015432343392556594, 0.0003951542717645822, 30, [20, 34, 20, 35, 54])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 30: 57.1 s, best val metric 0.8223, [(8, 0.8223, 0.8223, 0.000204703925057141, 0.0003755739189195493, 29, [20, 20, 20, 20, 29]), (8, 0.8071, 0.8071, 0.00042111410770293483, 0.0003792083050791084, 27, [20, 20, 20, 20, 26]), (8, 0.8071, 0.8071, 0.00022372063148113787, 0.000372247393940396, 33, [20, 20, 20, 20, 35]), (8, 0.8071, 0.8071, 0.00042111410770293483, 0.0003792083050791084, 27, [20, 20, 20, 20, 25]), (8, 0.8071, 0.8071, 0.00022372063148113787, 0.000372247393940396, 33, [20, 20, 20, 20, 35]), (8, 0.8071, 0.8071, 0.00011297244823034657, 0.0003508820068943501, 28, [20, 20, 20, 23, 42]), (9, 0.8071, 0.8071, 0.0004252721053717331, 0.00034351928286616205, 27, [20, 20, 20, 20, 22]), (8, 0.8071, 0.8071, 0.00011297244823034657, 0.0003508820068943501, 28, [20, 20, 20, 23, 42]), (9, 0.8071, 0.8071, 0.0004252721053717331, 0.00034351928286616205, 27, [20, 20, 20, 20, 22]), (8, 0.797, 0.797, 8.14010388963412e-05, 0.0003800537843199767, 26, [20, 44, 25, 54, 66]), (9, 0.797, 0.797, 0.0004252721053717331, 0.00034351928286616205, 27, [20, 20, 20, 20, 23])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 31: 56.6 s, best val metric 0.8223, [(10, 0.8223, 0.8223, 0.00024015892055731001, 0.0003705191022877901, 28, [20, 20, 20, 20, 34]), (10, 0.8223, 0.8223, 0.00024015892055731001, 0.0003705191022877901, 28, [20, 20, 20, 20, 34]), (9, 0.8223, 0.8223, 0.000204703925057141, 0.0003755739189195493, 29, [20, 20, 20, 20, 29]), (9, 0.8122, 0.8122, 0.00012934377218231304, 0.000381018213639923, 32, [20, 22, 20, 22, 45]), (9, 0.8122, 0.8122, 0.00012934377218231304, 0.000381018213639923, 32, [20, 22, 20, 22, 45]), (9, 0.8122, 0.8122, 0.00012934377218231304, 0.000381018213639923, 32, [20, 22, 20, 22, 45]), (9, 0.8071, 0.8071, 0.00011297244823034657, 0.0003508820068943501, 28, [20, 20, 20, 32, 47]), (9, 0.8071, 0.8071, 0.00022372063148113787, 0.000372247393940396, 33, [20, 20, 20, 20, 40]), (9, 0.797, 0.797, 0.0002813710518003337, 0.0003329886460049432, 20, [20, 20, 20, 20, 29]), (9, 0.7919, 0.7919, 0.000204703925057141, 0.0003755739189195493, 29, [20, 20, 20, 20, 29]), (9, 0.7919, 0.7919, 0.00011297244823034657, 0.0003508820068943501, 28, [20, 20, 20, 33, 50])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 32: 55.2 s, best val metric 0.8223, [(11, 0.8223, 0.8223, 0.00024015892055731001, 0.0003705191022877901, 28, [20, 20, 20, 23, 38]), (11, 0.8223, 0.8223, 0.00024015892055731001, 0.0003705191022877901, 28, [20, 20, 20, 23, 38]), (11, 0.8223, 0.8223, 0.00024015892055731001, 0.0003705191022877901, 28, [20, 20, 20, 20, 34]), (10, 0.8122, 0.8122, 3.1622776601683795e-05, 0.00035350346290362436, 23, [31, 40, 40, 53, 70]), (10, 0.8122, 0.8122, 3.1622776601683795e-05, 0.00035350346290362436, 23, [31, 40, 40, 53, 70]), (10, 0.8071, 0.8071, 0.00011297244823034657, 0.0003508820068943501, 28, [20, 22, 20, 39, 62]), (10, 0.8071, 0.8071, 0.000204703925057141, 0.0003755739189195493, 29, [20, 20, 20, 20, 30]), (10, 0.8071, 0.8071, 0.00011297244823034657, 0.0003508820068943501, 28, [20, 22, 20, 39, 62]), (10, 0.7919, 0.7919, 0.00011207098371097049, 0.000380734196259053, 26, [20, 21, 22, 28, 55]), (10, 0.7919, 0.7919, 0.00010373549157230701, 0.0003590742435090067, 30, [20, 22, 20, 35, 53]), (10, 0.7817, 0.7817, 0.00012934377218231304, 0.000381018213639923, 32, [20, 26, 21, 22, 58])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 33: 63.6 s, best val metric 0.8223, [(11, 0.8223, 0.8223, 3.1622776601683795e-05, 0.00035350346290362436, 23, [36, 60, 60, 73, 90]), (11, 0.8223, 0.8223, 3.1622776601683795e-05, 0.00035350346290362436, 23, [36, 60, 60, 73, 90]), (11, 0.8223, 0.8223, 3.1622776601683795e-05, 0.00035350346290362436, 23, [36, 60, 60, 73, 90]), (11, 0.8223, 0.8223, 3.1622776601683795e-05, 0.00035350346290362436, 23, [36, 60, 60, 73, 90]), (12, 0.8223, 0.8223, 0.00024015892055731001, 0.0003705191022877901, 28, [20, 20, 20, 23, 38]), (11, 0.8173, 0.8173, 0.00011297244823034657, 0.0003508820068943501, 28, [20, 24, 21, 38, 68]), (11, 0.8173, 0.8173, 0.00011297244823034657, 0.0003508820068943501, 28, [20, 24, 21, 38, 68]), (11, 0.8122, 0.8122, 0.00012934377218231304, 0.000381018213639923, 32, [20, 25, 20, 25, 74]), (11, 0.8122, 0.8122, 0.0005096244021021849, 0.0003273476152365603, 30, [20, 20, 20, 20, 24]), (11, 0.8071, 0.8071, 0.0012045397991274722, 0.00037780623912459036, 18, [20, 20, 20, 20, 20]), (11, 0.797, 0.797, 0.0001911059329683658, 0.00036871985539111633, 28, [20, 20, 20, 27, 61])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 34: 75.3 s, best val metric 0.8274, [(12, 0.8274, 0.8274, 3.1622776601683795e-05, 0.00035350346290362436, 23, [38, 80, 80, 93, 109]), (12, 0.8223, 0.8223, 0.00011297244823034657, 0.0003508820068943501, 28, [20, 22, 20, 41, 70]), (12, 0.8223, 0.8223, 3.1622776601683795e-05, 0.00035350346290362436, 23, [36, 60, 60, 73, 90]), (12, 0.8173, 0.8173, 0.0001911059329683658, 0.00036871985539111633, 28, [20, 20, 20, 24, 58]), (12, 0.8173, 0.8173, 9.56820090660353e-05, 0.0003731009608360503, 34, [20, 25, 22, 39, 43]), (12, 0.8173, 0.8173, 9.56820090660353e-05, 0.0003731009608360503, 34, [20, 25, 22, 39, 43]), (13, 0.8071, 0.8071, 0.00024015892055731001, 0.0003705191022877901, 28, [20, 20, 20, 20, 47]), (12, 0.8071, 0.8071, 3.1622776601683795e-05, 0.00035350346290362436, 23, [54, 80, 80, 93, 109]), (12, 0.802, 0.802, 3.1622776601683795e-05, 0.00035350346290362436, 23, [50, 80, 80, 93, 110]), (12, 0.802, 0.802, 0.00012853743874242533, 0.0003763534227339363, 21, [26, 58, 43, 72, 87]), (12, 0.797, 0.797, 0.00032019997691164496, 0.00036332973144391034, 25, [20, 20, 20, 20, 37])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 35: 82.7 s, best val metric 0.8274, [(13, 0.8274, 0.8274, 3.1622776601683795e-05, 0.00035350346290362436, 23, [38, 80, 80, 93, 109]), (13, 0.8223, 0.8223, 3.1622776601683795e-05, 0.00035350346290362436, 23, [44, 99, 100, 113, 121]), (13, 0.8173, 0.8173, 0.00012853743874242533, 0.0003763534227339363, 21, [20, 33, 23, 53, 88]), (13, 0.8122, 0.8122, 9.56820090660353e-05, 0.0003731009608360503, 34, [20, 36, 24, 55, 61]), (13, 0.8122, 0.8122, 0.00032019997691164496, 0.00036332973144391034, 25, [20, 20, 20, 20, 35]), (13, 0.8071, 0.8071, 3.1622776601683795e-05, 0.00035350346290362436, 23, [54, 100, 98, 113, 131]), (13, 0.8071, 0.8071, 3.1622776601683795e-05, 0.00035350346290362436, 23, [54, 100, 98, 113, 131]), (13, 0.802, 0.802, 8.38073612596582e-05, 0.0004154091300827737, 33, [22, 80, 67, 96, 125]), (13, 0.797, 0.797, 0.0001911059329683658, 0.00036871985539111633, 28, [20, 20, 20, 24, 60]), (13, 0.797, 0.797, 0.0002163941140742066, 0.00037174956057247916, 19, [20, 32, 25, 47, 49]), (13, 0.7919, 0.7919, 0.00012480065289034302, 0.00033502038286315866, 19, [20, 22, 20, 44, 47])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Generation 36: 90.1 s, best val metric 0.8274, [(14, 0.8274, 0.8274, 3.1622776601683795e-05, 0.00035350346290362436, 23, [38, 80, 80, 93, 109]), (14, 0.8223, 0.8223, 0.0001911059329683658, 0.00036871985539111633, 28, [20, 21, 20, 22, 60]), (14, 0.8223, 0.8223, 0.0001911059329683658, 0.00036871985539111633, 28, [20, 21, 20, 22, 60]), (14, 0.8122, 0.8122, 0.00032019997691164496, 0.00036332973144391034, 25, [20, 20, 20, 20, 39]), (14, 0.8122, 0.8122, 3.1622776601683795e-05, 0.00035350346290362436, 23, [41, 117, 112, 135, 154]), (14, 0.8122, 0.8122, 3.1622776601683795e-05, 0.00035350346290362436, 23, [41, 117, 112, 135, 154]), (14, 0.8122, 0.8122, 0.00032019997691164496, 0.00036332973144391034, 25, [20, 20, 20, 20, 39]), (14, 0.802, 0.802, 0.0002163941140742066, 0.00037174956057247916, 19, [20, 20, 20, 25, 50]), (14, 0.802, 0.802, 0.0002163941140742066, 0.00037174956057247916, 19, [20, 20, 20, 25, 50]), (14, 0.797, 0.797, 0.0005961788508725046, 0.00036198674547467956, 28, [20, 21, 20, 25, 23]), (14, 0.7868, 0.7868, 3.1622776601683795e-05, 0.000385999917351781, 20, [40, 40, 40, 44, 80])]\n",
      "#### Overall best val metric 0.8274111675126904 ####\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "evolution = Evolution()\n",
    "hyperparameters = {\n",
    "    'regularization_penalty': Hyperparameter(3., 2.5, 4.5, 0.5),\n",
    "    'learning_rate': Hyperparameter(0.0004, 0.0001, 0.0006, 0.000025),\n",
    "    'batch_size': Hyperparameter(32, 16, 64, 4),\n",
    "}\n",
    "evolution.run(x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test),\n",
    "              layer_sizes=[20, 20, 20, 20, 20], output_neurons=10, hyperparameters=hyperparameters, n_parents=5, population_size=10, \n",
    "              n_generations=50, tournament_size=3, n_introduced=2, age_penalty_period=15, use_static_graph=False, fine_tuning=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9f8fc67b80>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 244,
       "width": 370
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [0] + [result.time for result in evolution.results]\n",
    "x += [x[-1] + (x[-1] - x[-2]) / 10]\n",
    "y = [0, 0] + [result.best_val_metric for result in evolution.results]\n",
    "plt.step(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Static models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with parameters (cf1ed20d15(0.0011269304841879752), 0.000412698299316758, 53, 10, 20, 0.2, False, (39, 91, 12, 81, 49)) started...\n",
      "Run with parameters (cf1ed20d15(0.0011269304841879752), 0.000412698299316758, 53, 10, 20, 0.2, False, (39, 91, 12, 81, 49)) completed, best_val_loss: 0.6196548342704773, best_val_metric: 0.8223350253807107, best_hidden_layer_sizes: [39, 91, 12, 81, 49]\n",
      "Best overall combination: (cf1ed20d15(0.0011269304841879752), 0.000412698299316758, 53, 10, 20, 0.2, False, (39, 91, 12, 81, 49)), val_metric: 0.8223350253807107\n",
      "Run with parameters (63adeee786(0.00028904177415217626), 0.000276667547628745, 45, 10, 20, 0.2, False, (86, 39, 85, 37, 69)) started...\n",
      "Run with parameters (63adeee786(0.00028904177415217626), 0.000276667547628745, 45, 10, 20, 0.2, False, (86, 39, 85, 37, 69)) completed, best_val_loss: 0.6456269025802612, best_val_metric: 0.8121827411167513, best_hidden_layer_sizes: [86, 39, 85, 37, 69]\n",
      "Best overall combination: (cf1ed20d15(0.0011269304841879752), 0.000412698299316758, 53, 10, 20, 0.2, False, (39, 91, 12, 81, 49)), val_metric: 0.8223350253807107\n",
      "Run with parameters (5589c30403(0.0015140328079894828), 0.00037190458382873763, 30, 10, 20, 0.2, False, (97, 12, 95, 30, 70)) started...\n",
      "Run with parameters (5589c30403(0.0015140328079894828), 0.00037190458382873763, 30, 10, 20, 0.2, False, (97, 12, 95, 30, 70)) completed, best_val_loss: 0.6712232232093811, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [97, 12, 95, 30, 70]\n",
      "Best overall combination: (cf1ed20d15(0.0011269304841879752), 0.000412698299316758, 53, 10, 20, 0.2, False, (39, 91, 12, 81, 49)), val_metric: 0.8223350253807107\n",
      "Run with parameters (cb26b0f254(0.0003596529056855498), 0.0005895775188816352, 48, 10, 20, 0.2, False, (41, 35, 90, 73, 82)) started...\n",
      "Run with parameters (cb26b0f254(0.0003596529056855498), 0.0005895775188816352, 48, 10, 20, 0.2, False, (41, 35, 90, 73, 82)) completed, best_val_loss: 0.8803796768188477, best_val_metric: 0.8020304568527918, best_hidden_layer_sizes: [41, 35, 90, 73, 82]\n",
      "Best overall combination: (cf1ed20d15(0.0011269304841879752), 0.000412698299316758, 53, 10, 20, 0.2, False, (39, 91, 12, 81, 49)), val_metric: 0.8223350253807107\n",
      "Run with parameters (8b22f52cfe(5.50894379402083e-05), 0.00017166913427240477, 43, 10, 20, 0.2, False, (12, 44, 29, 86, 81)) started...\n",
      "Run with parameters (8b22f52cfe(5.50894379402083e-05), 0.00017166913427240477, 43, 10, 20, 0.2, False, (12, 44, 29, 86, 81)) completed, best_val_loss: 0.6071282625198364, best_val_metric: 0.8121827411167513, best_hidden_layer_sizes: [12, 44, 29, 86, 81]\n",
      "Best overall combination: (cf1ed20d15(0.0011269304841879752), 0.000412698299316758, 53, 10, 20, 0.2, False, (39, 91, 12, 81, 49)), val_metric: 0.8223350253807107\n",
      "Run with parameters (018a4e88e1(6.315319883245461e-05), 0.0005657442586270504, 53, 10, 20, 0.2, False, (78, 70, 61, 86, 84)) started...\n",
      "Run with parameters (018a4e88e1(6.315319883245461e-05), 0.0005657442586270504, 53, 10, 20, 0.2, False, (78, 70, 61, 86, 84)) completed, best_val_loss: 0.695099949836731, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [78, 70, 61, 86, 84]\n",
      "Best overall combination: (cf1ed20d15(0.0011269304841879752), 0.000412698299316758, 53, 10, 20, 0.2, False, (39, 91, 12, 81, 49)), val_metric: 0.8223350253807107\n",
      "Run with parameters (0c6f72da51(0.00016218572597881555), 0.00025918400988519106, 23, 10, 20, 0.2, False, (32, 84, 71, 71, 98)) started...\n",
      "Run with parameters (0c6f72da51(0.00016218572597881555), 0.00025918400988519106, 23, 10, 20, 0.2, False, (32, 84, 71, 71, 98)) completed, best_val_loss: 0.7526888847351074, best_val_metric: 0.817258883248731, best_hidden_layer_sizes: [32, 84, 71, 71, 98]\n",
      "Best overall combination: (cf1ed20d15(0.0011269304841879752), 0.000412698299316758, 53, 10, 20, 0.2, False, (39, 91, 12, 81, 49)), val_metric: 0.8223350253807107\n",
      "Run with parameters (9349a2e7bb(0.00040225043171495474), 0.0004804984653779014, 59, 10, 20, 0.2, False, (46, 82, 85, 13, 22)) started...\n",
      "Run with parameters (9349a2e7bb(0.00040225043171495474), 0.0004804984653779014, 59, 10, 20, 0.2, False, (46, 82, 85, 13, 22)) completed, best_val_loss: 0.5892137289047241, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [46, 82, 85, 13, 22]\n",
      "Best overall combination: (cf1ed20d15(0.0011269304841879752), 0.000412698299316758, 53, 10, 20, 0.2, False, (39, 91, 12, 81, 49)), val_metric: 0.8223350253807107\n",
      "Run with parameters (277f35a637(3.2540915784790256e-05), 0.00025929587395354695, 20, 10, 20, 0.2, False, (79, 93, 52, 31, 63)) started...\n",
      "Run with parameters (277f35a637(3.2540915784790256e-05), 0.00025929587395354695, 20, 10, 20, 0.2, False, (79, 93, 52, 31, 63)) completed, best_val_loss: 0.560918927192688, best_val_metric: 0.8121827411167513, best_hidden_layer_sizes: [79, 93, 52, 31, 63]\n",
      "Best overall combination: (cf1ed20d15(0.0011269304841879752), 0.000412698299316758, 53, 10, 20, 0.2, False, (39, 91, 12, 81, 49)), val_metric: 0.8223350253807107\n",
      "Run with parameters (460859fd50(0.0009705419549913782), 0.0004953046365397199, 53, 10, 20, 0.2, False, (44, 92, 17, 48, 37)) started...\n",
      "Run with parameters (460859fd50(0.0009705419549913782), 0.0004953046365397199, 53, 10, 20, 0.2, False, (44, 92, 17, 48, 37)) completed, best_val_loss: 0.6153979897499084, best_val_metric: 0.8274111675126904, best_hidden_layer_sizes: [44, 92, 17, 48, 37]\n",
      "Best overall combination: (460859fd50(0.0009705419549913782), 0.0004953046365397199, 53, 10, 20, 0.2, False, (44, 92, 17, 48, 37)), val_metric: 0.8274111675126904\n",
      "Run with parameters (2a2e7431c2(0.0018584904783139717), 0.0003118540989436522, 33, 10, 20, 0.2, False, (23, 17, 50, 31, 88)) started...\n",
      "Run with parameters (2a2e7431c2(0.0018584904783139717), 0.0003118540989436522, 33, 10, 20, 0.2, False, (23, 17, 50, 31, 88)) completed, best_val_loss: 0.7253485918045044, best_val_metric: 0.8020304568527918, best_hidden_layer_sizes: [23, 17, 50, 31, 88]\n",
      "Best overall combination: (460859fd50(0.0009705419549913782), 0.0004953046365397199, 53, 10, 20, 0.2, False, (44, 92, 17, 48, 37)), val_metric: 0.8274111675126904\n",
      "Run with parameters (83088e54e9(0.00022496295417470324), 0.0004836533258490654, 34, 10, 20, 0.2, False, (12, 24, 26, 32, 22)) started...\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomSearch()\n",
    "random_search.run(\n",
    "    train_fn_conv, x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test), \n",
    "    schedule=PowerRange(-4.5, -2.5, lambda x: Schedule([StaticEpoch(x, 'l1')] * 20)), \n",
    "    layer_1_size=UniformRange(10, 100, integer=True),\n",
    "    layer_2_size=UniformRange(10, 100, integer=True),\n",
    "    layer_3_size=UniformRange(10, 100, integer=True),\n",
    "    layer_4_size=UniformRange(10, 100, integer=True),\n",
    "    layer_5_size=UniformRange(10, 100, integer=True),\n",
    "    learning_rate=UniformRange(0.0001, 0.0006),\n",
    "    batch_size=UniformRange(16, 64, integer=True),\n",
    "    output_neurons=10, min_new_neurons=20, growth_percentage=0.2, use_static_graph=False, postprocess_fn=layer_sizes_join_postprocess\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9f90d9bd30>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 244,
       "width": 366
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [0] + [result.time for result in random_search.results]\n",
    "x += [x[-1] + (x[-1] - x[-2]) / 10]\n",
    "y = [0, 0] + [result.best_val_metric for result in random_search.results]\n",
    "plt.step(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with parameters (fdb5d3f1e9(0.000163189620373698), [20, 20, 20, 20, 20], 0.0002096556470841659, 18, 10, 20, 0.2, False) started...\n",
      "Run with parameters (fdb5d3f1e9(0.000163189620373698), [20, 20, 20, 20, 20], 0.0002096556470841659, 18, 10, 20, 0.2, False) completed, best_val_loss: 0.606458306312561, best_val_metric: 0.8223350253807107, best_hidden_layer_sizes: [20, 20, 20, 28, 44]\n",
      "Best overall combination: (fdb5d3f1e9(0.000163189620373698), [20, 20, 20, 20, 20], 0.0002096556470841659, 18, 10, 20, 0.2, False), val_metric: 0.8223350253807107\n",
      "Run with parameters (daeeb86ac0(9.930253078431562e-05), [20, 20, 20, 20, 20], 0.00017545083469109286, 47, 10, 20, 0.2, False) started...\n",
      "Run with parameters (daeeb86ac0(9.930253078431562e-05), [20, 20, 20, 20, 20], 0.00017545083469109286, 47, 10, 20, 0.2, False) completed, best_val_loss: 0.6177849173545837, best_val_metric: 0.8223350253807107, best_hidden_layer_sizes: [20, 20, 20, 33, 20]\n",
      "Best overall combination: (fdb5d3f1e9(0.000163189620373698), [20, 20, 20, 20, 20], 0.0002096556470841659, 18, 10, 20, 0.2, False), val_metric: 0.8223350253807107\n",
      "Run with parameters (f9de63524a(0.0003479311257553057), [20, 20, 20, 20, 20], 0.00040930669086305054, 63, 10, 20, 0.2, False) started...\n",
      "Run with parameters (f9de63524a(0.0003479311257553057), [20, 20, 20, 20, 20], 0.00040930669086305054, 63, 10, 20, 0.2, False) completed, best_val_loss: 0.5965628027915955, best_val_metric: 0.817258883248731, best_hidden_layer_sizes: [20, 20, 20, 20, 21]\n",
      "Best overall combination: (fdb5d3f1e9(0.000163189620373698), [20, 20, 20, 20, 20], 0.0002096556470841659, 18, 10, 20, 0.2, False), val_metric: 0.8223350253807107\n",
      "Run with parameters (5a228cec09(0.0030135496485728963), [20, 20, 20, 20, 20], 0.00023438642287457677, 60, 10, 20, 0.2, False) started...\n",
      "Run with parameters (5a228cec09(0.0030135496485728963), [20, 20, 20, 20, 20], 0.00023438642287457677, 60, 10, 20, 0.2, False) completed, best_val_loss: 0.7173214554786682, best_val_metric: 0.7817258883248731, best_hidden_layer_sizes: [20, 11, 11, 14, 20]\n",
      "Best overall combination: (fdb5d3f1e9(0.000163189620373698), [20, 20, 20, 20, 20], 0.0002096556470841659, 18, 10, 20, 0.2, False), val_metric: 0.8223350253807107\n",
      "Run with parameters (b8799689cf(0.0001221765686302286), [20, 20, 20, 20, 20], 0.0003405255851470179, 18, 10, 20, 0.2, False) started...\n",
      "Run with parameters (b8799689cf(0.0001221765686302286), [20, 20, 20, 20, 20], 0.0003405255851470179, 18, 10, 20, 0.2, False) completed, best_val_loss: 0.6663068532943726, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [20, 24, 21, 35, 84]\n",
      "Best overall combination: (fdb5d3f1e9(0.000163189620373698), [20, 20, 20, 20, 20], 0.0002096556470841659, 18, 10, 20, 0.2, False), val_metric: 0.8223350253807107\n",
      "Run with parameters (47f1128abd(0.0013560159362023027), [20, 20, 20, 20, 20], 0.0005626223318263013, 57, 10, 20, 0.2, False) started...\n",
      "Run with parameters (47f1128abd(0.0013560159362023027), [20, 20, 20, 20, 20], 0.0005626223318263013, 57, 10, 20, 0.2, False) completed, best_val_loss: 0.6502918004989624, best_val_metric: 0.8020304568527918, best_hidden_layer_sizes: [20, 17, 19, 24, 21]\n",
      "Best overall combination: (fdb5d3f1e9(0.000163189620373698), [20, 20, 20, 20, 20], 0.0002096556470841659, 18, 10, 20, 0.2, False), val_metric: 0.8223350253807107\n",
      "Run with parameters (a2d68c5fe6(6.70426348004911e-05), [20, 20, 20, 20, 20], 0.00016795425617181222, 50, 10, 20, 0.2, False) started...\n",
      "Run with parameters (a2d68c5fe6(6.70426348004911e-05), [20, 20, 20, 20, 20], 0.00016795425617181222, 50, 10, 20, 0.2, False) completed, best_val_loss: 0.6194660663604736, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [20, 20, 20, 35, 22]\n",
      "Best overall combination: (fdb5d3f1e9(0.000163189620373698), [20, 20, 20, 20, 20], 0.0002096556470841659, 18, 10, 20, 0.2, False), val_metric: 0.8223350253807107\n",
      "Run with parameters (f0ad03cede(0.0010693606743122674), [20, 20, 20, 20, 20], 0.00018914720981062663, 56, 10, 20, 0.2, False) started...\n",
      "Run with parameters (f0ad03cede(0.0010693606743122674), [20, 20, 20, 20, 20], 0.00018914720981062663, 56, 10, 20, 0.2, False) completed, best_val_loss: 0.6765465140342712, best_val_metric: 0.7918781725888325, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Best overall combination: (fdb5d3f1e9(0.000163189620373698), [20, 20, 20, 20, 20], 0.0002096556470841659, 18, 10, 20, 0.2, False), val_metric: 0.8223350253807107\n",
      "Run with parameters (e3a11ef56e(0.0005667934414783776), [20, 20, 20, 20, 20], 0.00042032232140656807, 34, 10, 20, 0.2, False) started...\n",
      "Run with parameters (e3a11ef56e(0.0005667934414783776), [20, 20, 20, 20, 20], 0.00042032232140656807, 34, 10, 20, 0.2, False) completed, best_val_loss: 0.5899722576141357, best_val_metric: 0.817258883248731, best_hidden_layer_sizes: [19, 13, 17, 18, 29]\n",
      "Best overall combination: (fdb5d3f1e9(0.000163189620373698), [20, 20, 20, 20, 20], 0.0002096556470841659, 18, 10, 20, 0.2, False), val_metric: 0.8223350253807107\n",
      "Run with parameters (d0337a5692(0.00035350797228370865), [20, 20, 20, 20, 20], 0.00014466959838034806, 58, 10, 20, 0.2, False) started...\n",
      "Run with parameters (d0337a5692(0.00035350797228370865), [20, 20, 20, 20, 20], 0.00014466959838034806, 58, 10, 20, 0.2, False) completed, best_val_loss: 0.5680921077728271, best_val_metric: 0.817258883248731, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Best overall combination: (fdb5d3f1e9(0.000163189620373698), [20, 20, 20, 20, 20], 0.0002096556470841659, 18, 10, 20, 0.2, False), val_metric: 0.8223350253807107\n",
      "Run with parameters (e35ac0186a(0.0029779368914698793), [20, 20, 20, 20, 20], 0.0005086823017809162, 48, 10, 20, 0.2, False) started...\n",
      "Run with parameters (e35ac0186a(0.0029779368914698793), [20, 20, 20, 20, 20], 0.0005086823017809162, 48, 10, 20, 0.2, False) completed, best_val_loss: 0.7293630838394165, best_val_metric: 0.7766497461928934, best_hidden_layer_sizes: [12, 4, 3, 14, 33]\n",
      "Best overall combination: (fdb5d3f1e9(0.000163189620373698), [20, 20, 20, 20, 20], 0.0002096556470841659, 18, 10, 20, 0.2, False), val_metric: 0.8223350253807107\n",
      "Run with parameters (0ed43f7366(0.00012657420997131015), [20, 20, 20, 20, 20], 0.0004160787264453848, 21, 10, 20, 0.2, False) started...\n",
      "Run with parameters (0ed43f7366(0.00012657420997131015), [20, 20, 20, 20, 20], 0.0004160787264453848, 21, 10, 20, 0.2, False) completed, best_val_loss: 0.6197600364685059, best_val_metric: 0.8223350253807107, best_hidden_layer_sizes: [20, 53, 30, 78, 100]\n",
      "Best overall combination: (fdb5d3f1e9(0.000163189620373698), [20, 20, 20, 20, 20], 0.0002096556470841659, 18, 10, 20, 0.2, False), val_metric: 0.8223350253807107\n",
      "Run with parameters (dd17cd10c9(0.0007868852468970968), [20, 20, 20, 20, 20], 0.00034662491701775396, 20, 10, 20, 0.2, False) started...\n",
      "Run with parameters (dd17cd10c9(0.0007868852468970968), [20, 20, 20, 20, 20], 0.00034662491701775396, 20, 10, 20, 0.2, False) completed, best_val_loss: 0.5784850716590881, best_val_metric: 0.8426395939086294, best_hidden_layer_sizes: [13, 7, 7, 13, 32]\n",
      "Best overall combination: (dd17cd10c9(0.0007868852468970968), [20, 20, 20, 20, 20], 0.00034662491701775396, 20, 10, 20, 0.2, False), val_metric: 0.8426395939086294\n",
      "Run with parameters (af0a4fce92(0.00016877651858023738), [20, 20, 20, 20, 20], 0.00023559800954073247, 59, 10, 20, 0.2, False) started...\n",
      "Run with parameters (af0a4fce92(0.00016877651858023738), [20, 20, 20, 20, 20], 0.00023559800954073247, 59, 10, 20, 0.2, False) completed, best_val_loss: 0.6649633646011353, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Best overall combination: (dd17cd10c9(0.0007868852468970968), [20, 20, 20, 20, 20], 0.00034662491701775396, 20, 10, 20, 0.2, False), val_metric: 0.8426395939086294\n",
      "Run with parameters (891feaadd5(0.0010850359720739166), [20, 20, 20, 20, 20], 0.0003573276899587236, 29, 10, 20, 0.2, False) started...\n",
      "Run with parameters (891feaadd5(0.0010850359720739166), [20, 20, 20, 20, 20], 0.0003573276899587236, 29, 10, 20, 0.2, False) completed, best_val_loss: 0.5900232195854187, best_val_metric: 0.8324873096446701, best_hidden_layer_sizes: [14, 7, 7, 10, 22]\n",
      "Best overall combination: (dd17cd10c9(0.0007868852468970968), [20, 20, 20, 20, 20], 0.00034662491701775396, 20, 10, 20, 0.2, False), val_metric: 0.8426395939086294\n",
      "Run with parameters (7db5611385(0.0021566123395474713), [20, 20, 20, 20, 20], 0.0004723310360791838, 19, 10, 20, 0.2, False) started...\n",
      "Run with parameters (7db5611385(0.0021566123395474713), [20, 20, 20, 20, 20], 0.0004723310360791838, 19, 10, 20, 0.2, False) completed, best_val_loss: 0.5971142053604126, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [4, 4, 4, 4, 30]\n",
      "Best overall combination: (dd17cd10c9(0.0007868852468970968), [20, 20, 20, 20, 20], 0.00034662491701775396, 20, 10, 20, 0.2, False), val_metric: 0.8426395939086294\n",
      "Run with parameters (5be5de0c4d(0.00020588609868648491), [20, 20, 20, 20, 20], 0.00031803419826765693, 21, 10, 20, 0.2, False) started...\n",
      "Run with parameters (5be5de0c4d(0.00020588609868648491), [20, 20, 20, 20, 20], 0.00031803419826765693, 21, 10, 20, 0.2, False) completed, best_val_loss: 0.5606003403663635, best_val_metric: 0.8223350253807107, best_hidden_layer_sizes: [20, 20, 20, 28, 43]\n",
      "Best overall combination: (dd17cd10c9(0.0007868852468970968), [20, 20, 20, 20, 20], 0.00034662491701775396, 20, 10, 20, 0.2, False), val_metric: 0.8426395939086294\n",
      "Run with parameters (259d10d81b(0.0003414755568714431), [20, 20, 20, 20, 20], 0.00047211088028817013, 17, 10, 20, 0.2, False) started...\n",
      "Run with parameters (259d10d81b(0.0003414755568714431), [20, 20, 20, 20, 20], 0.00047211088028817013, 17, 10, 20, 0.2, False) completed, best_val_loss: 0.5686542987823486, best_val_metric: 0.8121827411167513, best_hidden_layer_sizes: [20, 20, 20, 20, 70]\n",
      "Best overall combination: (dd17cd10c9(0.0007868852468970968), [20, 20, 20, 20, 20], 0.00034662491701775396, 20, 10, 20, 0.2, False), val_metric: 0.8426395939086294\n",
      "Run with parameters (8e1dee61e6(0.0012186374368358787), [20, 20, 20, 20, 20], 0.0005842855188258006, 30, 10, 20, 0.2, False) started...\n",
      "Run with parameters (8e1dee61e6(0.0012186374368358787), [20, 20, 20, 20, 20], 0.0005842855188258006, 30, 10, 20, 0.2, False) completed, best_val_loss: 0.6303697824478149, best_val_metric: 0.817258883248731, best_hidden_layer_sizes: [14, 5, 7, 12, 60]\n",
      "Best overall combination: (dd17cd10c9(0.0007868852468970968), [20, 20, 20, 20, 20], 0.00034662491701775396, 20, 10, 20, 0.2, False), val_metric: 0.8426395939086294\n",
      "Run with parameters (880c4d0ff1(5.405126192834705e-05), [20, 20, 20, 20, 20], 0.0005599034536784743, 34, 10, 20, 0.2, False) started...\n",
      "Run with parameters (880c4d0ff1(5.405126192834705e-05), [20, 20, 20, 20, 20], 0.0005599034536784743, 34, 10, 20, 0.2, False) completed, best_val_loss: 0.5571756958961487, best_val_metric: 0.8121827411167513, best_hidden_layer_sizes: [38, 129, 82, 148, 115]\n",
      "Best overall combination: (dd17cd10c9(0.0007868852468970968), [20, 20, 20, 20, 20], 0.00034662491701775396, 20, 10, 20, 0.2, False), val_metric: 0.8426395939086294\n",
      "Run with parameters (d1fc854f3e(0.0001767319843954476), [20, 20, 20, 20, 20], 0.0002702042198697255, 25, 10, 20, 0.2, False) started...\n",
      "Run with parameters (d1fc854f3e(0.0001767319843954476), [20, 20, 20, 20, 20], 0.0002702042198697255, 25, 10, 20, 0.2, False) completed, best_val_loss: 0.5295966267585754, best_val_metric: 0.817258883248731, best_hidden_layer_sizes: [20, 20, 20, 20, 48]\n",
      "Best overall combination: (dd17cd10c9(0.0007868852468970968), [20, 20, 20, 20, 20], 0.00034662491701775396, 20, 10, 20, 0.2, False), val_metric: 0.8426395939086294\n",
      "Run with parameters (d182140b28(0.00248431156700018), [20, 20, 20, 20, 20], 0.0004080968084613735, 60, 10, 20, 0.2, False) started...\n",
      "Run with parameters (d182140b28(0.00248431156700018), [20, 20, 20, 20, 20], 0.0004080968084613735, 60, 10, 20, 0.2, False) completed, best_val_loss: 0.7715546488761902, best_val_metric: 0.7868020304568528, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Best overall combination: (dd17cd10c9(0.0007868852468970968), [20, 20, 20, 20, 20], 0.00034662491701775396, 20, 10, 20, 0.2, False), val_metric: 0.8426395939086294\n",
      "Run with parameters (a5bb10c79e(0.0001929108284242817), [20, 20, 20, 20, 20], 0.0002513390334735993, 33, 10, 20, 0.2, False) started...\n",
      "Run with parameters (a5bb10c79e(0.0001929108284242817), [20, 20, 20, 20, 20], 0.0002513390334735993, 33, 10, 20, 0.2, False) completed, best_val_loss: 0.5763823390007019, best_val_metric: 0.8274111675126904, best_hidden_layer_sizes: [20, 20, 20, 20, 30]\n",
      "Best overall combination: (dd17cd10c9(0.0007868852468970968), [20, 20, 20, 20, 20], 0.00034662491701775396, 20, 10, 20, 0.2, False), val_metric: 0.8426395939086294\n",
      "Run with parameters (c1c6196058(0.001106127628027176), [20, 20, 20, 20, 20], 0.00038219909417624233, 18, 10, 20, 0.2, False) started...\n",
      "Run with parameters (c1c6196058(0.001106127628027176), [20, 20, 20, 20, 20], 0.00038219909417624233, 18, 10, 20, 0.2, False) completed, best_val_loss: 0.5827199220657349, best_val_metric: 0.817258883248731, best_hidden_layer_sizes: [8, 5, 7, 8, 34]\n",
      "Best overall combination: (dd17cd10c9(0.0007868852468970968), [20, 20, 20, 20, 20], 0.00034662491701775396, 20, 10, 20, 0.2, False), val_metric: 0.8426395939086294\n",
      "Run with parameters (e764bf4140(0.0006216913035399183), [20, 20, 20, 20, 20], 0.00041461004170694924, 53, 10, 20, 0.2, False) started...\n",
      "Run with parameters (e764bf4140(0.0006216913035399183), [20, 20, 20, 20, 20], 0.00041461004170694924, 53, 10, 20, 0.2, False) completed, best_val_loss: 0.5663204193115234, best_val_metric: 0.8375634517766497, best_hidden_layer_sizes: [20, 11, 17, 17, 26]\n",
      "Best overall combination: (dd17cd10c9(0.0007868852468970968), [20, 20, 20, 20, 20], 0.00034662491701775396, 20, 10, 20, 0.2, False), val_metric: 0.8426395939086294\n",
      "Run with parameters (5dbd15acc1(7.761810847839506e-05), [20, 20, 20, 20, 20], 0.0005975694770809722, 55, 10, 20, 0.2, False) started...\n",
      "Run with parameters (5dbd15acc1(7.761810847839506e-05), [20, 20, 20, 20, 20], 0.0005975694770809722, 55, 10, 20, 0.2, False) completed, best_val_loss: 0.5461944937705994, best_val_metric: 0.8223350253807107, best_hidden_layer_sizes: [24, 79, 55, 118, 124]\n",
      "Best overall combination: (dd17cd10c9(0.0007868852468970968), [20, 20, 20, 20, 20], 0.00034662491701775396, 20, 10, 20, 0.2, False), val_metric: 0.8426395939086294\n",
      "Run with parameters (38d09f6352(0.0006371238414478857), [20, 20, 20, 20, 20], 0.00011423788263092108, 50, 10, 20, 0.2, False) started...\n",
      "Run with parameters (38d09f6352(0.0006371238414478857), [20, 20, 20, 20, 20], 0.00011423788263092108, 50, 10, 20, 0.2, False) completed, best_val_loss: 0.6402671933174133, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Best overall combination: (dd17cd10c9(0.0007868852468970968), [20, 20, 20, 20, 20], 0.00034662491701775396, 20, 10, 20, 0.2, False), val_metric: 0.8426395939086294\n",
      "Run with parameters (4be4a789e3(0.0006826555915504675), [20, 20, 20, 20, 20], 0.0005654467413152713, 17, 10, 20, 0.2, False) started...\n",
      "Run with parameters (4be4a789e3(0.0006826555915504675), [20, 20, 20, 20, 20], 0.0005654467413152713, 17, 10, 20, 0.2, False) completed, best_val_loss: 0.5314803719520569, best_val_metric: 0.8426395939086294, best_hidden_layer_sizes: [9, 6, 8, 11, 109]\n",
      "Best overall combination: (dd17cd10c9(0.0007868852468970968), [20, 20, 20, 20, 20], 0.00034662491701775396, 20, 10, 20, 0.2, False), val_metric: 0.8426395939086294\n",
      "Run with parameters (d79c65c593(0.00023656949930414117), [20, 20, 20, 20, 20], 0.00036800676213265976, 49, 10, 20, 0.2, False) started...\n",
      "Run with parameters (d79c65c593(0.00023656949930414117), [20, 20, 20, 20, 20], 0.00036800676213265976, 49, 10, 20, 0.2, False) completed, best_val_loss: 0.6641347408294678, best_val_metric: 0.817258883248731, best_hidden_layer_sizes: [20, 20, 20, 23, 20]\n",
      "Best overall combination: (dd17cd10c9(0.0007868852468970968), [20, 20, 20, 20, 20], 0.00034662491701775396, 20, 10, 20, 0.2, False), val_metric: 0.8426395939086294\n",
      "Run with parameters (84c3657456(6.721345456393286e-05), [20, 20, 20, 20, 20], 0.0001627295138303972, 52, 10, 20, 0.2, False) started...\n",
      "Run with parameters (84c3657456(6.721345456393286e-05), [20, 20, 20, 20, 20], 0.0001627295138303972, 52, 10, 20, 0.2, False) completed, best_val_loss: 0.5879550576210022, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [20, 20, 20, 39, 20]\n",
      "Best overall combination: (dd17cd10c9(0.0007868852468970968), [20, 20, 20, 20, 20], 0.00034662491701775396, 20, 10, 20, 0.2, False), val_metric: 0.8426395939086294\n",
      "Run with parameters (cf291e31a4(6.961090653610457e-05), [20, 20, 20, 20, 20], 0.0001669248597884848, 20, 10, 20, 0.2, False) started...\n",
      "Run with parameters (cf291e31a4(6.961090653610457e-05), [20, 20, 20, 20, 20], 0.0001669248597884848, 20, 10, 20, 0.2, False) completed, best_val_loss: 0.5643720030784607, best_val_metric: 0.8223350253807107, best_hidden_layer_sizes: [20, 32, 20, 42, 61]\n",
      "Best overall combination: (dd17cd10c9(0.0007868852468970968), [20, 20, 20, 20, 20], 0.00034662491701775396, 20, 10, 20, 0.2, False), val_metric: 0.8426395939086294\n",
      "Run with parameters (a822905400(0.0006916028688393526), [20, 20, 20, 20, 20], 0.00018893683651385917, 59, 10, 20, 0.2, False) started...\n",
      "Run with parameters (a822905400(0.0006916028688393526), [20, 20, 20, 20, 20], 0.00018893683651385917, 59, 10, 20, 0.2, False) completed, best_val_loss: 0.6582721471786499, best_val_metric: 0.8020304568527918, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Best overall combination: (dd17cd10c9(0.0007868852468970968), [20, 20, 20, 20, 20], 0.00034662491701775396, 20, 10, 20, 0.2, False), val_metric: 0.8426395939086294\n",
      "Run with parameters (806bed4911(0.001611863199597079), [20, 20, 20, 20, 20], 0.0005397443030132449, 16, 10, 20, 0.2, False) started...\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomSearch()\n",
    "random_search.run(\n",
    "    train_fn_conv, x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test), \n",
    "    schedule=PowerRange(-4.5, -2.5, lambda x: Schedule([DynamicEpoch(x, 'weighted_l1')] * 20)), \n",
    "    layer_sizes=[20, 20, 20, 20, 20],\n",
    "    learning_rate=UniformRange(0.0001, 0.0006),\n",
    "    batch_size=UniformRange(16, 64, integer=True),\n",
    "    output_neurons=10, min_new_neurons=20, growth_percentage=0.2, use_static_graph=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion MNIST, random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = get_fashion_mnist_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with parameters (8029e9534d(0.0003388919130249544), 0.0003639933752127146, 35, 10, 20, 0.2, False, (77, 76, 22, 25, 98)) started...\n",
      "Run with parameters (8029e9534d(0.0003388919130249544), 0.0003639933752127146, 35, 10, 20, 0.2, False, (77, 76, 22, 25, 98)) completed, best_val_loss: 0.4625168740749359, best_val_metric: 0.8670520231213873, best_hidden_layer_sizes: [77, 76, 22, 25, 98]\n",
      "Duration 49.8, best overall combination: (8029e9534d(0.0003388919130249544), 0.0003639933752127146, 35, 10, 20, 0.2, False, (77, 76, 22, 25, 98)), val_metric: 0.8670520231213873\n",
      "Run with parameters (d6f77c9ec9(7.329398670972555e-05), 0.00016811187229158383, 48, 10, 20, 0.2, False, (86, 61, 20, 47, 92)) started...\n",
      "Run with parameters (d6f77c9ec9(7.329398670972555e-05), 0.00016811187229158383, 48, 10, 20, 0.2, False, (86, 61, 20, 47, 92)) completed, best_val_loss: 0.49034497141838074, best_val_metric: 0.8269230769230769, best_hidden_layer_sizes: [86, 61, 20, 47, 92]\n",
      "Duration 45.3, best overall combination: (8029e9534d(0.0003388919130249544), 0.0003639933752127146, 35, 10, 20, 0.2, False, (77, 76, 22, 25, 98)), val_metric: 0.8670520231213873\n",
      "Run with parameters (ecfa71cc83(0.0002400855951758678), 0.00019574572609668716, 34, 10, 20, 0.2, False, (54, 69, 19, 49, 92)) started...\n",
      "Run with parameters (ecfa71cc83(0.0002400855951758678), 0.00019574572609668716, 34, 10, 20, 0.2, False, (54, 69, 19, 49, 92)) completed, best_val_loss: 0.6331685781478882, best_val_metric: 0.8255813953488372, best_hidden_layer_sizes: [54, 69, 19, 49, 92]\n",
      "Duration 47.6, best overall combination: (8029e9534d(0.0003388919130249544), 0.0003639933752127146, 35, 10, 20, 0.2, False, (77, 76, 22, 25, 98)), val_metric: 0.8670520231213873\n",
      "Run with parameters (df707ce947(5.323462676812539e-05), 0.00016628748260743488, 46, 10, 20, 0.2, False, (99, 43, 76, 15, 88)) started...\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomSearch()\n",
    "random_search.run(\n",
    "    train_fn_conv, x=fashion_mnist.X_norm, y=fashion_mnist.y, validation_data=None, fraction=0.025, test_size=0.2,\n",
    "    schedule=PowerRange(-4.5, -2.5, lambda x: Schedule([StaticEpoch(x, 'l1')] * 20)), \n",
    "    layer_1_size=UniformRange(10, 100, integer=True),\n",
    "    layer_2_size=UniformRange(10, 100, integer=True),\n",
    "    layer_3_size=UniformRange(10, 100, integer=True),\n",
    "    layer_4_size=UniformRange(10, 100, integer=True),\n",
    "    layer_5_size=UniformRange(10, 100, integer=True),\n",
    "    learning_rate=UniformRange(0.0001, 0.0006),\n",
    "    batch_size=UniformRange(16, 64, integer=True),\n",
    "    output_neurons=10, min_new_neurons=20, growth_percentage=0.2, use_static_graph=False, postprocess_fn=layer_sizes_join_postprocess,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = get_fashion_mnist_dataset(fraction=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1185, 197)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fashion_mnist.y_train), len(fashion_mnist.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = early_stopping_conv(x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test), \n",
    "                              learning_rate=0.0004, schedule=Schedule([StaticEpoch(0.0001, 'l1')]), layer_sizes=[20, 20, 20, 20, 20], \n",
    "                              output_neurons=10, min_new_neurons=20, growth_percentage=0.2, verbose=False, use_static_graph=False, batch_size=32, max_setbacks=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.8923521041870117,\n",
       "  1.154221773147583,\n",
       "  0.9501345157623291,\n",
       "  0.7963964939117432,\n",
       "  0.8048096299171448,\n",
       "  0.7233625054359436,\n",
       "  0.6791957020759583,\n",
       "  0.6550287008285522,\n",
       "  0.6060753464698792,\n",
       "  0.5850539803504944,\n",
       "  0.5407936573028564,\n",
       "  0.520182728767395,\n",
       "  0.5132090449333191,\n",
       "  0.47503137588500977,\n",
       "  0.47763749957084656,\n",
       "  0.4562778174877167,\n",
       "  0.4289024770259857,\n",
       "  0.4665936231613159],\n",
       " 'metric': [0.3434599156118143,\n",
       "  0.579746835443038,\n",
       "  0.6556962025316456,\n",
       "  0.7223628691983123,\n",
       "  0.7037974683544304,\n",
       "  0.7350210970464135,\n",
       "  0.7578059071729958,\n",
       "  0.770464135021097,\n",
       "  0.7881856540084389,\n",
       "  0.7822784810126582,\n",
       "  0.7966244725738396,\n",
       "  0.8143459915611815,\n",
       "  0.8143459915611815,\n",
       "  0.830379746835443,\n",
       "  0.8261603375527427,\n",
       "  0.8286919831223629,\n",
       "  0.8413502109704641,\n",
       "  0.8278481012658228],\n",
       " 'val_loss': [1.0502598285675049,\n",
       "  0.8313892483711243,\n",
       "  0.7488256096839905,\n",
       "  0.7100869417190552,\n",
       "  0.6938915252685547,\n",
       "  0.6437969207763672,\n",
       "  0.6173182725906372,\n",
       "  0.6324804425239563,\n",
       "  0.6132561564445496,\n",
       "  0.606491208076477,\n",
       "  0.6062572598457336,\n",
       "  0.6072300672531128,\n",
       "  0.6051803827285767,\n",
       "  0.600619375705719,\n",
       "  0.5814846754074097,\n",
       "  0.5962882041931152,\n",
       "  0.587359607219696,\n",
       "  0.5911709070205688],\n",
       " 'val_metric': [0.6345177664974619,\n",
       "  0.7258883248730964,\n",
       "  0.7309644670050761,\n",
       "  0.7563451776649747,\n",
       "  0.751269035532995,\n",
       "  0.7766497461928934,\n",
       "  0.7715736040609137,\n",
       "  0.7868020304568528,\n",
       "  0.7918781725888325,\n",
       "  0.7868020304568528,\n",
       "  0.7715736040609137,\n",
       "  0.7817258883248731,\n",
       "  0.7969543147208121,\n",
       "  0.8020304568527918,\n",
       "  0.8071065989847716,\n",
       "  0.8020304568527918,\n",
       "  0.7868020304568528,\n",
       "  0.7868020304568528],\n",
       " 'hidden_layer_sizes': [[20, 20, 20, 20, 20],\n",
       "  [20, 20, 20, 20, 20],\n",
       "  [20, 20, 20, 20, 20],\n",
       "  [20, 20, 20, 20, 20],\n",
       "  [20, 20, 20, 20, 20],\n",
       "  [20, 20, 20, 20, 20],\n",
       "  [20, 20, 20, 20, 20],\n",
       "  [20, 20, 20, 20, 20],\n",
       "  [20, 20, 20, 20, 20],\n",
       "  [20, 20, 20, 20, 20],\n",
       "  [20, 20, 20, 20, 20],\n",
       "  [20, 20, 20, 20, 20],\n",
       "  [20, 20, 20, 20, 20],\n",
       "  [20, 20, 20, 20, 20],\n",
       "  [20, 20, 20, 20, 20],\n",
       "  [20, 20, 20, 20, 20],\n",
       "  [20, 20, 20, 20, 20],\n",
       "  [20, 20, 20, 20, 20]]}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = early_stopping_conv(x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test), \n",
    "                              learning_rate=0.0004, schedule=Schedule([DynamicEpoch(0.0001, 'weighted_l1')]), layer_sizes=[20, 20, 20, 20, 20], \n",
    "                              output_neurons=10, min_new_neurons=20, growth_percentage=0.2, verbose=False, use_static_graph=False, batch_size=32, max_setbacks=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.8965582847595215,\n",
       "  1.0091614723205566,\n",
       "  0.8055817484855652,\n",
       "  0.7226932644844055,\n",
       "  0.6321020126342773,\n",
       "  0.5870353579521179,\n",
       "  0.543196976184845,\n",
       "  0.5353223085403442,\n",
       "  0.4810500144958496,\n",
       "  0.4752078652381897],\n",
       " 'metric': [0.36033755274261603,\n",
       "  0.6312236286919831,\n",
       "  0.7071729957805907,\n",
       "  0.7383966244725738,\n",
       "  0.7805907172995781,\n",
       "  0.7856540084388186,\n",
       "  0.7957805907172996,\n",
       "  0.8168776371308016,\n",
       "  0.8227848101265823,\n",
       "  0.8286919831223629],\n",
       " 'val_loss': [0.9335415959358215,\n",
       "  0.7589622735977173,\n",
       "  0.6442540287971497,\n",
       "  0.6977205276489258,\n",
       "  0.5917835831642151,\n",
       "  0.6097767949104309,\n",
       "  0.5299047827720642,\n",
       "  0.6285367608070374,\n",
       "  0.5351715683937073,\n",
       "  0.6649787425994873],\n",
       " 'val_metric': [0.6700507614213198,\n",
       "  0.7309644670050761,\n",
       "  0.7868020304568528,\n",
       "  0.7614213197969543,\n",
       "  0.7766497461928934,\n",
       "  0.8020304568527918,\n",
       "  0.8274111675126904,\n",
       "  0.8020304568527918,\n",
       "  0.8020304568527918,\n",
       "  0.7969543147208121],\n",
       " 'hidden_layer_sizes': [[20, 25, 30, 40, 21],\n",
       "  [20, 26, 28, 41, 25],\n",
       "  [20, 35, 30, 48, 38],\n",
       "  [20, 43, 23, 65, 41],\n",
       "  [20, 38, 22, 62, 49],\n",
       "  [20, 40, 21, 62, 55],\n",
       "  [20, 39, 21, 58, 56],\n",
       "  [20, 40, 20, 58, 67],\n",
       "  [20, 56, 20, 64, 65],\n",
       "  [20, 54, 24, 65, 78]]}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "machine_shape": "hm",
   "name": "tf_multi_layer_ssnet_inverse.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
