{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f_deAUKlniFk",
    "outputId": "434f0bdd-1358-46dc-adc2-aee14230789c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yKwUwV_NneIo"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from enum import Enum\n",
    "import imageio\n",
    "import hashlib\n",
    "import copy\n",
    "import time\n",
    "import abc\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "dtype = 'float32'\n",
    "tf.keras.backend.set_floatx(dtype)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "UTZq4KMpneIv"
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# DATASETS\n",
    "################################################################################\n",
    "\n",
    "\n",
    "def get_dataset_sample(X, y, fraction, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)  # Set random seed\n",
    "    selection = np.random.choice([True, False], len(X), p=[fraction, 1 - fraction])\n",
    "    if seed is not None:\n",
    "        np.random.seed()  # Unset random seed\n",
    "    X_sampled = X[selection]\n",
    "    y_sampled = y[selection]\n",
    "    return X_sampled, y_sampled\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, X_train, y_train, X_test, y_test, shape, shape_flattened, fraction, vision=True, standardize=True):\n",
    "        if fraction is not None:\n",
    "            X_train, y_train = get_dataset_sample(X_train, y_train, fraction, seed=42)\n",
    "            X_test, y_test = get_dataset_sample(X_test, y_test, fraction, seed=42)\n",
    "        \n",
    "        X_train = X_train.astype(dtype)\n",
    "        y_train = y_train.astype(dtype)\n",
    "        X_test = X_test.astype(dtype)\n",
    "        y_test = y_test.astype(dtype)\n",
    "\n",
    "        if vision:\n",
    "            X_train = X_train / 255.0\n",
    "            X_test = X_test / 255.0\n",
    "\n",
    "        X_train = np.reshape(X_train, shape_flattened)\n",
    "        X_test = np.reshape(X_test, shape_flattened)\n",
    "\n",
    "        X = np.concatenate((X_train, X_test), axis=0)\n",
    "        y = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "        if standardize:\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(X_train)  # Scaling each feature independently\n",
    "\n",
    "            X_norm = scaler.transform(X)\n",
    "            X_train_norm = scaler.transform(X_train)\n",
    "            X_test_norm = scaler.transform(X_test)\n",
    "        else:\n",
    "            X_norm = X.copy()\n",
    "            X_train_norm = X_train.copy()\n",
    "            X_test_norm = X_test.copy()\n",
    "\n",
    "        X_norm = np.reshape(X_norm, shape)\n",
    "        X_train_norm = np.reshape(X_train_norm, shape)\n",
    "        X_test_norm = np.reshape(X_test_norm, shape)\n",
    "\n",
    "        del X, X_train, X_test\n",
    "\n",
    "        self.X_norm = X_norm\n",
    "        self.y = y\n",
    "        self.X_train_norm = X_train_norm\n",
    "        self.y_train = y_train\n",
    "        self.X_test_norm = X_test_norm\n",
    "        self.y_test = y_test\n",
    "\n",
    "\n",
    "def get_cifar_10_dataset(fraction=None):\n",
    "    cifar10 = tf.keras.datasets.cifar10\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "    shape = (-1, 32, 32, 3)\n",
    "    shape_flattened = (-1, 3072)  # Scaling each feature independently\n",
    "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened, fraction=fraction)\n",
    "\n",
    "\n",
    "def get_cifar_100_dataset(fraction=None):\n",
    "    cifar100 = tf.keras.datasets.cifar100\n",
    "    (X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
    "    shape = (-1, 32, 32, 3)\n",
    "    shape_flattened = (-1, 3072)  # Scaling each feature independently\n",
    "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened, fraction=fraction)\n",
    "\n",
    "\n",
    "def get_svhn_dataset(fraction=None):\n",
    "    from urllib.request import urlretrieve\n",
    "    from scipy import io\n",
    "\n",
    "    train_filename, _ = urlretrieve('http://ufldl.stanford.edu/housenumbers/train_32x32.mat')\n",
    "    test_filename, _ = urlretrieve('http://ufldl.stanford.edu/housenumbers/test_32x32.mat')\n",
    "\n",
    "    X_train = io.loadmat(train_filename, variable_names='X').get('X')\n",
    "    y_train = io.loadmat(train_filename, variable_names='y').get('y')\n",
    "    X_test = io.loadmat(test_filename, variable_names='X').get('X')\n",
    "    y_test = io.loadmat(test_filename, variable_names='y').get('y')\n",
    "\n",
    "    X_train = np.moveaxis(X_train, -1, 0)\n",
    "    y_train -= 1\n",
    "    X_test = np.moveaxis(X_test, -1, 0)\n",
    "    y_test -= 1\n",
    "\n",
    "    shape = (-1, 32, 32, 3)\n",
    "    shape_flattened = (-1, 3072)  # Scaling each feature independently\n",
    "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened, fraction=fraction)\n",
    "\n",
    "\n",
    "def get_tiny_imagenet_dataset(fraction=None):\n",
    "    \"\"\"\n",
    "    Original source: https://github.com/sonugiri1043/Train_ResNet_On_Tiny_ImageNet/blob/master/Train_ResNet_On_Tiny_ImageNet.ipynb\n",
    "    Original author: sonugiri1043@gmail.com\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.isdir('IMagenet'):\n",
    "        ! git clone https://github.com/seshuad/IMagenet\n",
    "\n",
    "    print(\"Processing the downloaded dataset...\")\n",
    "\n",
    "    path = 'IMagenet/tiny-imagenet-200/'\n",
    "\n",
    "    id_dict = {}\n",
    "    for i, line in enumerate(open(path + 'wnids.txt', 'r')):\n",
    "        id_dict[line.replace('\\n', '')] = i\n",
    "\n",
    "    train_data = list()\n",
    "    test_data = list()\n",
    "    train_labels = list()\n",
    "    test_labels = list()\n",
    "\n",
    "    for key, value in id_dict.items():\n",
    "        train_data += [imageio.imread(path + 'train/{}/images/{}_{}.JPEG'.format(key, key, str(i)), pilmode='RGB') for i in range(500)]\n",
    "        train_labels_ = np.array([[0]*200]*500)\n",
    "        train_labels_[:, value] = 1\n",
    "        train_labels += train_labels_.tolist()\n",
    "\n",
    "    for line in open(path + 'val/val_annotations.txt'):\n",
    "        img_name, class_id = line.split('\\t')[:2]\n",
    "        test_data.append(imageio.imread(path + 'val/images/{}'.format(img_name), pilmode='RGB'))\n",
    "        test_labels_ = np.array([[0]*200])\n",
    "        test_labels_[0, id_dict[class_id]] = 1\n",
    "        test_labels += test_labels_.tolist()\n",
    "\n",
    "    X_train = np.array(train_data)\n",
    "    y_train = np.argmax(np.array(train_labels), axis=1)\n",
    "    X_test = np.array(test_data)\n",
    "    y_test = np.argmax(np.array(test_labels), axis=1)\n",
    "\n",
    "    shape = (-1, 64, 64, 3)\n",
    "    shape_flattened = (-1, 12288)  # Scaling each feature independently\n",
    "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened, fraction=fraction)\n",
    "\n",
    "\n",
    "def get_mnist_dataset(fraction=None):\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    shape = (-1, 28, 28, 1)\n",
    "    shape_flattened = (-1, 1)  # Scaling all features together\n",
    "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened, fraction=fraction)\n",
    "\n",
    "\n",
    "def get_fashion_mnist_dataset(fraction=None):\n",
    "    fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "    (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "    shape = (-1, 28, 28, 1)\n",
    "    shape_flattened = (-1, 1)  # Scaling all features together\n",
    "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened, fraction=fraction)\n",
    "\n",
    "\n",
    "def get_fifteen_puzzle_dataset(path=None, fraction=None):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    if path is None:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/gdrive')\n",
    "        path = 'gdrive/MyDrive/15-costs-v3.csv'\n",
    "    costs = pd.read_csv(path)\n",
    "\n",
    "    X_raw = costs.iloc[:,:-1].values\n",
    "    y = costs['cost'].values\n",
    "    X = np.apply_along_axis(lambda x: np.eye(16)[x].ravel(), 1, X_raw)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    del X, X_raw, y\n",
    "\n",
    "    shape = (-1, 256)\n",
    "    shape_flattened = (-1, 256)  # Scaling all features together\n",
    "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened, vision=False, fraction=fraction)\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# REGULARIZERS\n",
    "################################################################################\n",
    "\n",
    "\n",
    "class Regularizer(tf.keras.regularizers.Regularizer):\n",
    "    def __init__(self):\n",
    "        self.n_new_neurons = 0\n",
    "        self.scaling_tensor = None\n",
    "        self.set_regularization_penalty(0.)\n",
    "        self.set_regularization_method(None)\n",
    "    \n",
    "    def copy(self):\n",
    "        regularizer_copy = Regularizer.__new__(Regularizer)\n",
    "        regularizer_copy.n_new_neurons = self.n_new_neurons\n",
    "        regularizer_copy.scaling_tensor = self.scaling_tensor\n",
    "        regularizer_copy.set_regularization_penalty(self.regularization_penalty)\n",
    "        regularizer_copy.set_regularization_method(self.regularization_method)\n",
    "        return regularizer_copy\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if self.regularization_method is None or self.regularization_penalty == 0:\n",
    "            return 0\n",
    "        elif self.regularization_method == 'weighted_l1':\n",
    "            return self.weighted_l1(x)\n",
    "        elif self.regularization_method == 'weighted_l1_reordered':\n",
    "            return self.weighted_l1_reordered(x)\n",
    "        elif self.regularization_method == 'group_sparsity':\n",
    "            return self.group_sparsity(x)\n",
    "        elif self.regularization_method == 'l1':\n",
    "            return self.l1(x)\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Unknown regularization method {self.regularization_method}\")\n",
    "    \n",
    "    def weighted_l1(self, x):\n",
    "        # I.e. for a parameter matrix of 4 input and 10 output neurons:\n",
    "        #\n",
    "        # [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]\n",
    "        #\n",
    "        # the scaling tensor, as well as the resulting weighted values, could be:\n",
    "        #\n",
    "        # [[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
    "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
    "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
    "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]\n",
    "        #\n",
    "        # Therefore every additional output neuron is regularized more.\n",
    "\n",
    "        scaling_tensor = tf.cumsum(tf.constant(self.regularization_penalty, shape=x.shape, dtype=dtype), axis=-1)\n",
    "        weighted_values = scaling_tensor * tf.abs(x)\n",
    "        return tf.reduce_sum(weighted_values)\n",
    "    \n",
    "    def weighted_l1_reordered(self, x):\n",
    "        # I.e. for a parameter matrix of 4 input and 10 output neurons:\n",
    "        #\n",
    "        # [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]\n",
    "        #\n",
    "        # the scaling tensor, as well as the resulting weighted values, could be:\n",
    "        #\n",
    "        # [[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
    "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
    "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
    "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]\n",
    "        #\n",
    "        # Therefore every additional output neuron is regularized more.\n",
    "\n",
    "        if self.update_scaling_tensor:\n",
    "            scaling_tensor_raw = tf.cumsum(tf.constant(self.regularization_penalty, shape=x.shape, dtype=dtype), axis=-1)\n",
    "\n",
    "            scaling_tensor_old_neurons = scaling_tensor_raw[:, :-self.n_new_neurons]\n",
    "            scaling_tensor_new_neurons = scaling_tensor_raw[:, -self.n_new_neurons:]\n",
    "            scaling_tensor_old_neurons_shuffled = tf.transpose(tf.random.shuffle(tf.transpose(scaling_tensor_old_neurons)))\n",
    "            self.scaling_tensor = tf.concat([scaling_tensor_old_neurons_shuffled, scaling_tensor_new_neurons], axis=-1)\n",
    "            self.update_scaling_tensor = False\n",
    "\n",
    "        weighted_values = self.scaling_tensor * tf.abs(x)\n",
    "        return tf.reduce_sum(weighted_values)\n",
    "    \n",
    "    def group_sparsity(self, x):\n",
    "        # I.e. for a parameter matrix of 3 input and 5 output neurons:\n",
    "        #\n",
    "        # [[1., 1., 1., 1., 1.],\n",
    "        #  [1., 2., 2., 1., 2.],\n",
    "        #  [2., 2., 3., 1., 3.]]\n",
    "        #\n",
    "        # The resulting vector of group norms is [2., 2., 3., 1., 3.], therefore for\n",
    "        # every output neuron, its incoming connections form a group.\n",
    "\n",
    "        group_norms = tf.norm(x, ord=2, axis=0)\n",
    "        # assert group_norms.shape[0] == x.shape[1]\n",
    "        return self.regularization_penalty * tf.reduce_sum(group_norms)\n",
    "    \n",
    "    def l1(self, x):\n",
    "        weighted_values = self.regularization_penalty * tf.abs(x)\n",
    "        return tf.reduce_sum(weighted_values)\n",
    "    \n",
    "    def prune(self):\n",
    "        self.n_new_neurons = 0\n",
    "        if self.regularization_method == 'weighted_l1_reordered':\n",
    "            self.update_scaling_tensor = True\n",
    "    \n",
    "    def grow(self, n_new_neurons):\n",
    "        self.n_new_neurons = n_new_neurons\n",
    "        if self.regularization_method == 'weighted_l1_reordered':\n",
    "            self.update_scaling_tensor = True\n",
    "    \n",
    "    def set_regularization_penalty(self, regularization_penalty):\n",
    "        self.regularization_penalty = regularization_penalty\n",
    "    \n",
    "    def set_regularization_method(self, regularization_method):\n",
    "        self.regularization_method = regularization_method\n",
    "        if self.regularization_method == 'weighted_l1_reordered':\n",
    "            self.update_scaling_tensor = True\n",
    "        else:\n",
    "            self.update_scaling_tensor = None\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'regularization_penalty': float(self.regularization_penalty)}\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# LAYERS\n",
    "################################################################################\n",
    "\n",
    "\n",
    "class DASLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_shape):\n",
    "        super().__init__()\n",
    "\n",
    "        self._input_shape = input_shape\n",
    "        self._built = False\n",
    "\n",
    "\n",
    "class Dense(DASLayer):\n",
    "    def __init__(self, units, activation, kernel_initializer='glorot_uniform', \n",
    "                 bias_initializer='zeros', input_shape=None, fixed_size=False,\n",
    "                 regularizer=None):\n",
    "        super().__init__(input_shape)\n",
    "\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.bias_initializer = bias_initializer\n",
    "        self.fixed_size = fixed_size\n",
    "        \n",
    "        self.A = tf.keras.activations.get(activation)\n",
    "        self.W_init = tf.keras.initializers.get(kernel_initializer)\n",
    "        self.b_init = tf.keras.initializers.get(bias_initializer)\n",
    "        if regularizer is not None:\n",
    "            self.regularizer = regularizer\n",
    "        else:\n",
    "            self.regularizer = Regularizer()\n",
    "    \n",
    "    def copy(self):\n",
    "        layer_copy = Dense.__new__(Dense)\n",
    "        super(Dense, layer_copy).__init__(self._input_shape)\n",
    "        \n",
    "        layer_copy.units = self.units\n",
    "        layer_copy.activation = self.activation\n",
    "        layer_copy.kernel_initializer = self.kernel_initializer\n",
    "        layer_copy.bias_initializer = self.bias_initializer\n",
    "        layer_copy.fixed_size = self.fixed_size\n",
    "        \n",
    "        layer_copy.A = self.A\n",
    "        layer_copy.W_init = self.W_init\n",
    "        layer_copy.b_init = self.b_init\n",
    "        layer_copy.regularizer = self.regularizer.copy()\n",
    "        \n",
    "        layer_copy.W = tf.Variable(\n",
    "            name='W',\n",
    "            initial_value=self.W,\n",
    "            trainable=True)\n",
    "        \n",
    "        layer_copy.b = tf.Variable(\n",
    "            name='b',\n",
    "            initial_value=self.b,\n",
    "            trainable=True)\n",
    "        \n",
    "        layer_copy.add_regularizer_loss()\n",
    "        \n",
    "        layer_copy._built = True\n",
    "        return layer_copy\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        if self._built:\n",
    "            return\n",
    "            \n",
    "        input_units = input_shape[-1]\n",
    "\n",
    "        self.W = tf.Variable(\n",
    "            name='W',\n",
    "            initial_value=self.W_init(shape=(input_units, self.units), dtype=dtype),\n",
    "            trainable=True)\n",
    "        \n",
    "        self.b = tf.Variable(\n",
    "            name='b',\n",
    "            initial_value=self.b_init(shape=(self.units,), dtype=dtype),\n",
    "            trainable=True)\n",
    "        \n",
    "        self.add_regularizer_loss()\n",
    "        \n",
    "        self._built = True\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        return self.A(tf.matmul(inputs, self.W) + self.b)\n",
    "    \n",
    "    def add_regularizer_loss(self):\n",
    "        self.add_loss(lambda: self.regularizer(tf.concat([self.W, tf.reshape(self.b, (1, -1))], axis=0)))\n",
    "\n",
    "    def get_size(self):\n",
    "        return self.W.shape[0], self.W.shape[1]\n",
    "    \n",
    "    def prune(self, threshold, active_input_units_indices):\n",
    "        # Remove connections from pruned units in previous layer\n",
    "        new_W = tf.gather(self.W.value(), active_input_units_indices, axis=0)\n",
    "\n",
    "        if self.fixed_size:\n",
    "            active_output_neurons_indices = list(range(new_W.shape[1]))\n",
    "        else:\n",
    "            # Prune units in this layer\n",
    "            weights_with_biases = tf.concat([new_W, tf.reshape(self.b.value(), (1, -1))], axis=0)\n",
    "            neurons_are_active = tf.math.reduce_max(tf.abs(weights_with_biases), axis=0) >= threshold\n",
    "            active_output_neurons_indices = tf.reshape(tf.where(neurons_are_active), (-1,))\n",
    "            \n",
    "            new_W = tf.gather(new_W, active_output_neurons_indices, axis=1)\n",
    "            new_b = tf.gather(self.b.value(), active_output_neurons_indices, axis=0)\n",
    "\n",
    "            self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
    "\n",
    "        self.W = tf.Variable(name='W', initial_value=new_W, trainable=True)\n",
    "\n",
    "        self.regularizer.prune()\n",
    "        return active_output_neurons_indices\n",
    "    \n",
    "    def grow(self, n_new_input_units, percentage, min_new_units, scaling_factor):\n",
    "        if n_new_input_units > 0:\n",
    "            # Add connections to grown units in previous layer\n",
    "            W_growth = self.W_init(shape=(self.W.shape[0] + n_new_input_units, self.W.shape[1]), dtype=dtype)[-n_new_input_units:, :] * scaling_factor  # TODO is it better to be multiplying here by scaling_factor? It does help with not increasing the max weights of existing neurons when new neurons are added.\n",
    "            new_W = tf.concat([self.W.value(), W_growth], axis=0)\n",
    "        else:\n",
    "            new_W = self.W.value()\n",
    "\n",
    "        if self.fixed_size:\n",
    "            n_new_output_units = 0\n",
    "        else:\n",
    "            # Grow new units in this layer\n",
    "            n_new_output_units = max(min_new_units, int(new_W.shape[1] * percentage))\n",
    "            if n_new_output_units > 0:\n",
    "                W_growth = self.W_init(shape=(new_W.shape[0], new_W.shape[1] + n_new_output_units), dtype=dtype)[:, -n_new_output_units:] * scaling_factor\n",
    "                b_growth = self.b_init(shape=(n_new_output_units,), dtype=dtype)  # TODO for all possible bias initializers to work properly, the whole bias vector should be initialized at once\n",
    "                new_W = tf.concat([new_W, W_growth], axis=1)\n",
    "                new_b = tf.concat([self.b.value(), b_growth], axis=0)\n",
    "\n",
    "                self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
    "\n",
    "        self.W = tf.Variable(name='W', initial_value=new_W, trainable=True)\n",
    "\n",
    "        self.regularizer.grow(n_new_output_units)\n",
    "        return n_new_output_units\n",
    "    \n",
    "    def mutate(self, mutation_strength):\n",
    "        self.W.assign_add(tf.random.normal(self.W.shape, mean=0.0, stddev=mutation_strength))\n",
    "        self.b.assign_add(tf.random.normal(self.b.shape, mean=0.0, stddev=mutation_strength))\n",
    "    \n",
    "    def set_regularization_penalty(self, regularization_penalty):\n",
    "        if not self.fixed_size:\n",
    "            self.regularizer.set_regularization_penalty(regularization_penalty)\n",
    "    \n",
    "    def set_regularization_method(self, regularization_method):\n",
    "        if not self.fixed_size:\n",
    "            self.regularizer.set_regularization_method(regularization_method)\n",
    "    \n",
    "    def get_param_string():\n",
    "        param_string = \"\"\n",
    "        weights_with_bias = tf.concat([self.W, tf.reshape(self.b, (1, -1))], axis=0)\n",
    "        max_parameters = tf.math.reduce_max(tf.abs(weights_with_bias), axis=0).numpy()\n",
    "        magnitudes = np.floor(np.log10(max_parameters))\n",
    "        for m in magnitudes:\n",
    "            if m > 0:\n",
    "                m = 0\n",
    "            param_string += str(int(-m))\n",
    "        return param_string\n",
    "\n",
    "\n",
    "class Conv2D(DASLayer):\n",
    "    def __init__(self, filters, filter_size, activation, strides=(1, 1), \n",
    "                 padding='SAME', kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros', input_shape=None, fixed_size=False,\n",
    "                 regularizer=None):\n",
    "        super().__init__(input_shape)\n",
    "    \n",
    "        self.filters = filters\n",
    "        self.filter_size = filter_size\n",
    "        self.activation = activation\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.bias_initializer = bias_initializer\n",
    "        self.fixed_size = fixed_size\n",
    "        \n",
    "        self.A = tf.keras.activations.get(activation)\n",
    "        self.F_init = tf.keras.initializers.get(kernel_initializer)\n",
    "        self.b_init = tf.keras.initializers.get(bias_initializer)\n",
    "        if regularizer is not None:\n",
    "            self.regularizer = regularizer\n",
    "        else:\n",
    "            self.regularizer = Regularizer()\n",
    "    \n",
    "    def copy(self):\n",
    "        layer_copy = Conv2D.__new__(Conv2D)\n",
    "        super(Conv2D, layer_copy).__init__(self._input_shape)\n",
    "        \n",
    "        layer_copy.filters = self.filters\n",
    "        layer_copy.filter_size = self.filter_size\n",
    "        layer_copy.activation = self.activation\n",
    "        layer_copy.strides = self.strides\n",
    "        layer_copy.padding = self.padding\n",
    "        layer_copy.kernel_initializer = self.kernel_initializer\n",
    "        layer_copy.bias_initializer = self.bias_initializer\n",
    "        layer_copy.fixed_size = self.fixed_size\n",
    "        \n",
    "        layer_copy.A = self.A\n",
    "        layer_copy.F_init = self.F_init\n",
    "        layer_copy.b_init = self.b_init\n",
    "        layer_copy.regularizer = self.regularizer.copy()\n",
    "        \n",
    "        layer_copy.F = tf.Variable(\n",
    "            name='F',\n",
    "            initial_value=self.F,\n",
    "            trainable=True)\n",
    "        \n",
    "        layer_copy.b = tf.Variable(\n",
    "            name='b',\n",
    "            initial_value=self.b,\n",
    "            trainable=True)\n",
    "        \n",
    "        layer_copy.add_regularizer_loss()\n",
    "        \n",
    "        layer_copy._built = True\n",
    "        return layer_copy\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        if self._built:\n",
    "            return\n",
    "\n",
    "        input_filters = input_shape[-1]\n",
    "\n",
    "        self.F = tf.Variable(\n",
    "            name='F',\n",
    "            initial_value=self.F_init(\n",
    "                shape=(self.filter_size[0], self.filter_size[1], input_filters, self.filters), dtype=dtype\n",
    "            ),\n",
    "            trainable=True)\n",
    "        \n",
    "        self.b = tf.Variable(\n",
    "            name='b',\n",
    "            initial_value=self.b_init(shape=(self.filters,), dtype=dtype),\n",
    "            trainable=True)\n",
    "\n",
    "        self.add_regularizer_loss()\n",
    "        \n",
    "        self._built = True\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        y = tf.nn.conv2d(inputs, self.F, strides=self.strides, padding=self.padding)\n",
    "        y = tf.nn.bias_add(y, self.b)\n",
    "        y = self.A(y)\n",
    "        return y\n",
    "    \n",
    "    def add_regularizer_loss(self):\n",
    "        self.add_loss(lambda: self.regularizer(tf.concat([tf.reshape(self.F, (-1, self.F.shape[-1])), tf.reshape(self.b, (1, -1))], axis=0)))\n",
    "    \n",
    "    def get_size(self):\n",
    "        return self.F.shape[-2], self.F.shape[-1]\n",
    "    \n",
    "    def prune(self, threshold, active_input_units_indices):\n",
    "        # Remove connections from pruned units in previous layer\n",
    "        new_F = tf.gather(self.F.value(), active_input_units_indices, axis=-2)\n",
    "\n",
    "        if self.fixed_size:\n",
    "            active_output_filters_indices = list(range(new_F.shape[-1]))\n",
    "        else:\n",
    "            # Prune units in this layer\n",
    "            F_reduced_max = tf.reshape(tf.math.reduce_max(tf.abs(new_F), axis=(0, 1, 2)), (1, -1))\n",
    "            F_reduced_max_with_biases = tf.concat([F_reduced_max, tf.reshape(self.b.value(), (1, -1))], axis=0)\n",
    "            filters_are_active = tf.math.reduce_max(tf.abs(F_reduced_max_with_biases), axis=0) >= threshold\n",
    "            active_output_filters_indices = tf.reshape(tf.where(filters_are_active), (-1,))\n",
    "            \n",
    "            new_F = tf.gather(new_F, active_output_filters_indices, axis=-1)\n",
    "            new_b = tf.gather(self.b.value(), active_output_filters_indices, axis=0)\n",
    "\n",
    "            self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
    "\n",
    "        self.F = tf.Variable(name='F', initial_value=new_F, trainable=True)\n",
    "\n",
    "        self.regularizer.prune()\n",
    "        return active_output_filters_indices\n",
    "\n",
    "    def grow(self, n_new_input_units, percentage, min_new_units, scaling_factor):\n",
    "        if n_new_input_units > 0:\n",
    "            # Add connections to grown units in previous layer\n",
    "            F_growth = self.F_init(shape=(self.F.shape[0], self.F.shape[1], self.F.shape[2] + n_new_input_units, self.F.shape[3]), dtype=dtype)[:, :, -n_new_input_units:, :] * scaling_factor  # TODO is it better to be multiplying here by scaling_factor? It does help with not increasing the max weights of existing neurons when new neurons are added.\n",
    "            new_F = tf.concat([self.F.value(), F_growth], axis=-2)\n",
    "        else:\n",
    "            new_F = self.F.value()\n",
    "\n",
    "        if self.fixed_size:\n",
    "            n_new_output_units = 0\n",
    "        else:\n",
    "            # Grow new units in this layer\n",
    "            n_new_output_units = max(min_new_units, int(new_F.shape[-1] * percentage))\n",
    "            if n_new_output_units > 0:\n",
    "                F_growth = self.F_init(shape=(new_F.shape[0], new_F.shape[1], new_F.shape[2], new_F.shape[3] + n_new_output_units), dtype=dtype)[:, :, :, -n_new_output_units:] * scaling_factor\n",
    "                b_growth = self.b_init(shape=(n_new_output_units,), dtype=dtype)  # TODO for all possible bias initializers to work properly, the whole bias vector should be initialized at once\n",
    "                new_F = tf.concat([new_F, F_growth], axis=-1)\n",
    "                new_b = tf.concat([self.b.value(), b_growth], axis=0)\n",
    "\n",
    "                self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
    "\n",
    "        self.F = tf.Variable(name='F', initial_value=new_F, trainable=True)\n",
    "\n",
    "        self.regularizer.grow(n_new_output_units)\n",
    "        return n_new_output_units\n",
    "    \n",
    "    def mutate(self, mutation_strength):\n",
    "        self.F.assign_add(tf.random.normal(self.F.shape, mean=0.0, stddev=mutation_strength))\n",
    "        self.b.assign_add(tf.random.normal(self.b.shape, mean=0.0, stddev=mutation_strength))\n",
    "    \n",
    "    def set_regularization_penalty(self, regularization_penalty):\n",
    "        if not self.fixed_size:\n",
    "            self.regularizer.set_regularization_penalty(regularization_penalty)\n",
    "    \n",
    "    def set_regularization_method(self, regularization_method):\n",
    "        if not self.fixed_size:\n",
    "            self.regularizer.set_regularization_method(regularization_method)\n",
    "\n",
    "    def get_param_string():\n",
    "        param_string = \"\"\n",
    "        # TODO\n",
    "        return param_string\n",
    "\n",
    "\n",
    "class Flatten(tf.keras.layers.Layer):\n",
    "    def call(self, inputs, training=None):\n",
    "        return tf.reshape(tf.transpose(inputs, perm=[0, 3, 1, 2]), (inputs.shape[0], -1))\n",
    "    \n",
    "    # def copy(self):\n",
    "    #     return Flatten()\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# MODELS\n",
    "################################################################################\n",
    "\n",
    "\n",
    "class Epoch:\n",
    "    def __init__(self, grow, prune, regularization_penalty, regularization_method):\n",
    "        self.grow = grow\n",
    "        self.prune = prune\n",
    "        self.regularization_penalty = regularization_penalty\n",
    "        self.regularization_method = regularization_method\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{int(self.grow)}{int(self.prune)}{self.regularization_penalty}{self.regularization_method}'\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "\n",
    "class DynamicEpoch(Epoch):\n",
    "    def __init__(self, regularization_penalty, regularization_method):\n",
    "        super().__init__(True, True, regularization_penalty, regularization_method)\n",
    "\n",
    "\n",
    "class StaticEpoch(Epoch):\n",
    "    def __init__(self, regularization_penalty, regularization_method):\n",
    "        super().__init__(False, False, regularization_penalty, regularization_method)\n",
    "\n",
    "\n",
    "class StaticEpochNoRegularization(StaticEpoch):\n",
    "    def __init__(self):\n",
    "        super().__init__(0., None)\n",
    "\n",
    "\n",
    "class Schedule:\n",
    "    def __init__(self, epochs):\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.epochs.__iter__()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.epochs)\n",
    "    \n",
    "    def __str__(self):\n",
    "        text = ''.join([str(epoch) for epoch in self.epochs])\n",
    "        return hashlib.sha1(text.encode('utf-8')).hexdigest()[:10]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "\n",
    "class Sequential(tf.keras.Model):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lrs = layers\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        x = inputs\n",
    "        for layer in self.lrs:\n",
    "            x = layer(x, training=training)\n",
    "        return x\n",
    "    \n",
    "    def copy(self):\n",
    "        copied_layers = list()\n",
    "        for layer in self.lrs:\n",
    "            if isinstance(layer, DASLayer):\n",
    "                layer_copy = layer.copy()\n",
    "#                 layer_copy = copy.deepcopy(layer)\n",
    "#                 layer_copy.add_regularizer_loss()\n",
    "            else:\n",
    "                layer_copy = copy.deepcopy(layer)\n",
    "            copied_layers.append(layer_copy)\n",
    "        \n",
    "        model_copy = Sequential(copied_layers)\n",
    "        return model_copy\n",
    "    \n",
    "    def get_layer_input_shape(self, target_layer):\n",
    "        if target_layer._input_shape is not None:\n",
    "            return target_layer._input_shape\n",
    "\n",
    "        input = np.random.normal(size=(1,) + self.lrs[0]._input_shape)\n",
    "        for layer in self.lrs:\n",
    "            if layer is target_layer:\n",
    "                return tuple(input.shape[1:])\n",
    "            input = layer(input)\n",
    "        raise Exception(\"Layer not found in the model.\")\n",
    "\n",
    "    def get_layer_output_shape(self, target_layer):\n",
    "        input = np.random.normal(size=(1,) + self.lrs[0]._input_shape)\n",
    "        for layer in self.lrs:\n",
    "            output = layer(input)\n",
    "            if layer is target_layer:\n",
    "                return tuple(output.shape[1:])\n",
    "            input = output\n",
    "        raise Exception(\"Layer not found in the model.\")\n",
    "    \n",
    "    def get_layer_sizes(self):\n",
    "        \"\"\"\n",
    "        Returns the sizes of all layers in the model, including the input and output layer.\n",
    "        \"\"\"\n",
    "        layer_sizes = list()\n",
    "        first_layer = True\n",
    "        for l in range(len(self.lrs)):\n",
    "            layer = self.lrs[l]\n",
    "            if isinstance(layer, DASLayer):\n",
    "                layer_size = layer.get_size()\n",
    "                if first_layer:\n",
    "                    layer_sizes.append(layer_size[0])\n",
    "                    first_layer = False\n",
    "                layer_sizes.append(layer_size[1])\n",
    "        return layer_sizes\n",
    "    \n",
    "    def get_hidden_layer_sizes(self):\n",
    "        return self.get_layer_sizes()[1:-1]\n",
    "    \n",
    "    def get_regularization_penalty(self):\n",
    "        #TODO improve\n",
    "        return self.lrs[-2].regularizer.regularization_penalty\n",
    "    \n",
    "    def set_regularization_penalty(self, regularization_penalty):\n",
    "        for layer in self.lrs:\n",
    "            if isinstance(layer, DASLayer) and not layer.fixed_size:\n",
    "                layer.set_regularization_penalty(regularization_penalty)\n",
    "    \n",
    "    def set_regularization_method(self, regularization_method):\n",
    "        for layer in self.lrs:\n",
    "            if isinstance(layer, DASLayer) and not layer.fixed_size:\n",
    "                layer.set_regularization_method(regularization_method)\n",
    "\n",
    "    def prune(self, params):\n",
    "        input_shape = self.get_layer_input_shape(self.lrs[0])\n",
    "        n_input_units = input_shape[-1]\n",
    "        active_units_indices = list(range(n_input_units))\n",
    "\n",
    "        last_custom_layer = None\n",
    "        for layer in self.lrs:\n",
    "            if isinstance(layer, DASLayer):\n",
    "                if last_custom_layer is not None and type(last_custom_layer) != type(layer):\n",
    "                    if type(last_custom_layer) == Conv2D and type(layer) == Dense:\n",
    "                        convolutional_shape = self.get_layer_output_shape(last_custom_layer)\n",
    "                        active_units_indices = self.convert_channel_indices_to_flattened_indices(active_units_indices, convolutional_shape)\n",
    "                    else:\n",
    "                        raise Exception(\"Incorrect order of custom layer types.\")\n",
    "                active_units_indices = layer.prune(params.pruning_threshold, active_units_indices)\n",
    "                last_custom_layer = layer\n",
    "    \n",
    "    def grow(self, params):   \n",
    "        n_new_units = 0\n",
    "\n",
    "        last_custom_layer = None\n",
    "        for layer in self.lrs:\n",
    "            if isinstance(layer, DASLayer):\n",
    "                if last_custom_layer is not None and type(last_custom_layer) != type(layer):\n",
    "                    if type(last_custom_layer) == Conv2D and type(layer) == Dense:\n",
    "                        convolutional_shape = self.get_layer_output_shape(last_custom_layer)\n",
    "                        n_new_units = n_new_units * convolutional_shape[0] * convolutional_shape[1]\n",
    "                    else:\n",
    "                        raise Exception(\"Incorrect order of custom layer types.\")\n",
    "                n_new_units = layer.grow(n_new_units, params.growth_percentage, min_new_units=params.min_new_neurons, scaling_factor=params.pruning_threshold)\n",
    "                last_custom_layer = layer\n",
    "    \n",
    "    def mutate(self, mutation_strength):\n",
    "        for layer in self.lrs:\n",
    "            if isinstance(layer, DASLayer):\n",
    "                layer.mutate(mutation_strength)\n",
    "    \n",
    "    @staticmethod\n",
    "    def convert_channel_indices_to_flattened_indices(channel_indices, convolutional_shape):\n",
    "        dense_indices = list()\n",
    "        units_per_channel = convolutional_shape[0] * convolutional_shape[1]\n",
    "        for channel_index in channel_indices:\n",
    "            for iter in range(units_per_channel):\n",
    "                dense_indices.append(channel_index * units_per_channel + iter)\n",
    "        return dense_indices\n",
    "    \n",
    "    def print_neurons(self):\n",
    "        for layer in self.lrs[:-1]:\n",
    "            print(layer.get_param_string())\n",
    "    \n",
    "    def evaluate(self, params, summed_training_loss, summed_training_metric):\n",
    "        # Calculate training loss and metric\n",
    "        if summed_training_loss is not None:\n",
    "            loss = summed_training_loss / params.x.shape[0]\n",
    "        else:\n",
    "            loss = None\n",
    "        \n",
    "        if summed_training_metric is not None:\n",
    "            metric = summed_training_metric / params.x.shape[0]\n",
    "        else:\n",
    "            metric = None\n",
    "        \n",
    "        # Calculate val loss and metric\n",
    "        summed_val_loss = 0\n",
    "        summed_val_metric = 0\n",
    "        n_val_instances = 0\n",
    "        \n",
    "        for step, (x_batch, y_batch) in enumerate(params.val_dataset):\n",
    "            # y_pred = tf.reshape(self(x_batch, training=False), y_batch.shape)\n",
    "            y_pred = self(x_batch, training=False)\n",
    "            summed_val_loss += tf.reduce_sum(params.loss_fn(y_batch, y_pred))\n",
    "            summed_val_metric += float(tf.reduce_sum(params.metric_fn(y_batch, y_pred)))\n",
    "            n_val_instances += x_batch.shape[0]\n",
    "        \n",
    "        val_loss = summed_val_loss / n_val_instances\n",
    "        val_metric = summed_val_metric / n_val_instances\n",
    "\n",
    "        return loss, metric, val_loss, val_metric\n",
    "\n",
    "    def list_params(self):\n",
    "        trainable_count = np.sum([K.count_params(w) for w in self.trainable_weights])\n",
    "        non_trainable_count = np.sum([K.count_params(w) for w in self.non_trainable_weights])\n",
    "        total_count = trainable_count + non_trainable_count\n",
    "\n",
    "        print('Total params: {:,}'.format(total_count))\n",
    "        print('Trainable params: {:,}'.format(trainable_count))\n",
    "        print('Non-trainable params: {:,}'.format(non_trainable_count))\n",
    "\n",
    "        return total_count, trainable_count, non_trainable_count\n",
    "    \n",
    "    def print_epoch_statistics(self, params, summed_training_loss, summed_training_metric, message=None, require_result=False):\n",
    "        if not params.verbose:\n",
    "            if require_result:\n",
    "                return self.evaluate(params, summed_training_loss, summed_training_metric)\n",
    "            else:\n",
    "                return\n",
    "        \n",
    "        loss, metric, val_loss, val_metric = self.evaluate(params, summed_training_loss, summed_training_metric)  \n",
    "\n",
    "        if message is not None:\n",
    "            print(message)\n",
    "        \n",
    "        print(f\"loss: {loss} - metric: {metric} - val_loss: {val_loss} - val_metric: {val_metric} - penalty: {self.get_regularization_penalty()}\")\n",
    "        hidden_layer_sizes = self.get_hidden_layer_sizes()\n",
    "        print(f\"hidden layer sizes: {hidden_layer_sizes}, total units: {sum(hidden_layer_sizes)}\")\n",
    "        if params.print_neurons:\n",
    "            self.print_neurons()\n",
    "        \n",
    "        if require_result:\n",
    "            return loss, metric, val_loss, val_metric\n",
    "    \n",
    "    def update_history(self, params, loss, metric, val_loss, val_metric):\n",
    "        params.history['loss'].append(float(loss))\n",
    "        params.history['metric'].append(float(metric))\n",
    "        params.history['val_loss'].append(float(val_loss))\n",
    "        params.history['val_metric'].append(float(val_metric))\n",
    "        params.history['hidden_layer_sizes'].append(self.get_hidden_layer_sizes())\n",
    "    \n",
    "    @staticmethod\n",
    "    def prepare_datasets(x, y, batch_size, validation_data):\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "        train_dataset = train_dataset.shuffle(buffer_size=20000).batch(batch_size)\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices(validation_data).batch(batch_size)\n",
    "        return train_dataset.prefetch(tf.data.AUTOTUNE), val_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    def manage_dynamic_regularization(self, params, val_loss):\n",
    "        if val_loss >= params.best_conditional_val_loss * params.stall_coefficient:\n",
    "            # Training is currently in stall\n",
    "            if not params.training_stalled:\n",
    "                penalty = self.get_regularization_penalty() * params.regularization_penalty_multiplier\n",
    "                print(\"Changing penalty...\")\n",
    "                # TODO this must be modified, penalty can differ for each layer\n",
    "                self.set_regularization_penalty(penalty)\n",
    "                params.training_stalled = True\n",
    "        else:\n",
    "            params.best_conditional_val_loss = val_loss\n",
    "            params.training_stalled = False\n",
    "    \n",
    "    def grow_wrapper(self, params):\n",
    "        dynamic_reqularization_active = params.regularization_penalty_multiplier != 1.\n",
    "        if dynamic_reqularization_active:\n",
    "            loss, metric, val_loss, val_metric = self.print_epoch_statistics(params, None, None, \"Before growing:\", require_result=True)\n",
    "            self.manage_dynamic_regularization(params, val_loss)\n",
    "        else:\n",
    "            self.print_epoch_statistics(params, None, None, \"Before growing:\")\n",
    "\n",
    "        self.grow(params)\n",
    "        self.print_epoch_statistics(params, None, None, \"After growing:\")\n",
    "    \n",
    "    def prune_wrapper(self, params, summed_loss, summed_metric):\n",
    "        loss, metric, _, _ = self.print_epoch_statistics(params, summed_loss, summed_metric, \"Before pruning:\", require_result=True)\n",
    "        self.prune(params)\n",
    "        _, _, val_loss, val_metric = self.print_epoch_statistics(params, None, None, \"After pruning:\", require_result=True)\n",
    "        self.update_history(params, loss, metric, val_loss, val_metric)\n",
    "    \n",
    "    class ParameterContainer:\n",
    "        def __init__(self, x, y, optimizer, batch_size, min_new_neurons, validation_data, pruning_threshold, regularization_penalty_multiplier, \n",
    "                     stall_coefficient, growth_percentage, mini_epochs_per_epoch, verbose, print_neurons, use_static_graph, loss_fn, metric_fn):\n",
    "            self.x = x\n",
    "            self.y = y\n",
    "            self.optimizer = optimizer\n",
    "            self.batch_size = batch_size\n",
    "            self.min_new_neurons = min_new_neurons\n",
    "            self.validation_data = validation_data\n",
    "            self.pruning_threshold = pruning_threshold\n",
    "            self.regularization_penalty_multiplier = regularization_penalty_multiplier\n",
    "            self.stall_coefficient = stall_coefficient\n",
    "            self.growth_percentage = growth_percentage\n",
    "            self.mini_epochs_per_epoch = mini_epochs_per_epoch\n",
    "            self.verbose = verbose\n",
    "            self.print_neurons = print_neurons\n",
    "            self.use_static_graph = use_static_graph\n",
    "            self.loss_fn = loss_fn\n",
    "            self.metric_fn = metric_fn\n",
    "\n",
    "            self.train_dataset, self.val_dataset = Sequential.prepare_datasets(x, y, batch_size, validation_data)\n",
    "            self.history = self.prepare_history()\n",
    "\n",
    "            self.best_conditional_val_loss = np.inf\n",
    "            self.training_stalled = False\n",
    "        \n",
    "        @staticmethod\n",
    "        def prepare_history():\n",
    "            history = {\n",
    "                'loss': list(),\n",
    "                'metric': list(),\n",
    "                'val_loss': list(),\n",
    "                'val_metric': list(),\n",
    "                'hidden_layer_sizes': list(),\n",
    "            }\n",
    "            return history\n",
    "    \n",
    "    def fit_single_step(self, x_batch, y_batch, optimizer, loss_fn, metric_fn):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # y_pred = tf.reshape(self(x_batch, training=True), y_batch.shape)\n",
    "            y_pred = self(x_batch, training=True)\n",
    "            raw_loss = loss_fn(y_batch, y_pred)\n",
    "            loss_value = tf.reduce_mean(raw_loss)\n",
    "            loss_value += sum(self.losses)  # Add losses registered by model.add_loss\n",
    "\n",
    "            loss = tf.reduce_sum(raw_loss)\n",
    "            metric = float(tf.reduce_sum(metric_fn(y_batch, y_pred)))\n",
    "\n",
    "        grads = tape.gradient(loss_value, self.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "\n",
    "        return loss, metric\n",
    "    \n",
    "    def fit_single_epoch(self, params):\n",
    "        summed_loss = 0\n",
    "        summed_metric = 0\n",
    "        \n",
    "        for mini_epoch in range(params.mini_epochs_per_epoch):\n",
    "            summed_loss = 0\n",
    "            summed_metric = 0\n",
    "\n",
    "            if params.use_static_graph:\n",
    "                fit_single_step_function = tf.function(self.fit_single_step)\n",
    "            else:\n",
    "                fit_single_step_function = self.fit_single_step\n",
    "            for step, (x_batch, y_batch) in enumerate(params.train_dataset):\n",
    "                loss, metric = fit_single_step_function(x_batch, y_batch, params.optimizer, params.loss_fn, params.metric_fn)\n",
    "                summed_loss += loss\n",
    "                summed_metric += metric\n",
    "        \n",
    "        return summed_loss, summed_metric\n",
    "\n",
    "    def fit(self, x, y, optimizer, schedule, batch_size, min_new_neurons, validation_data, pruning_threshold=0.001, regularization_penalty_multiplier=1., \n",
    "            stall_coefficient=1, growth_percentage=0.2, mini_epochs_per_epoch=1, verbose=True, print_neurons=False, use_static_graph=True, \n",
    "            loss_fn=tf.keras.losses.sparse_categorical_crossentropy, metric_fn=tf.keras.metrics.sparse_categorical_accuracy):\n",
    "        params = self.ParameterContainer(x=x, y=y, optimizer=optimizer, batch_size=batch_size, min_new_neurons=min_new_neurons, validation_data=validation_data, \n",
    "                                         pruning_threshold=pruning_threshold, regularization_penalty_multiplier=regularization_penalty_multiplier, stall_coefficient=stall_coefficient, \n",
    "                                         growth_percentage=growth_percentage, mini_epochs_per_epoch=mini_epochs_per_epoch, verbose=verbose, print_neurons=print_neurons, \n",
    "                                         use_static_graph=use_static_graph, loss_fn=loss_fn, metric_fn=metric_fn)\n",
    "        self.build(x.shape)  # Necessary when verbose == False\n",
    "\n",
    "        for epoch_no, epoch in enumerate(schedule):\n",
    "            if verbose:\n",
    "                print(\"##########################################################\")\n",
    "                print(f\"Epoch {epoch_no + 1}/{len(schedule)}\")\n",
    "            \n",
    "            self.set_regularization_penalty(epoch.regularization_penalty)\n",
    "            self.set_regularization_method(epoch.regularization_method)\n",
    "\n",
    "            if epoch.grow:\n",
    "                self.grow_wrapper(params)\n",
    "\n",
    "            summed_loss, summed_metric = self.fit_single_epoch(params)\n",
    "            \n",
    "            if epoch.prune:\n",
    "                self.prune_wrapper(params, summed_loss, summed_metric)\n",
    "            else:\n",
    "                loss, metric, val_loss, val_metric = self.print_epoch_statistics(params, summed_loss, summed_metric, require_result=True)\n",
    "                self.update_history(params, loss, metric, val_loss, val_metric)\n",
    "        \n",
    "        return params.history\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# HELPER FUNCTIONS\n",
    "################################################################################\n",
    "\n",
    "\n",
    "def get_statistics_from_history(history):\n",
    "    best_epoch_number = np.argmax(history['val_metric'])\n",
    "    best_val_loss = history['val_loss'][best_epoch_number]\n",
    "    best_val_metric = history['val_metric'][best_epoch_number]\n",
    "    best_hidden_layer_sizes = history['hidden_layer_sizes'][best_epoch_number]\n",
    "    return best_val_loss, best_val_metric, best_hidden_layer_sizes\n",
    "\n",
    "\n",
    "def get_statistics_from_histories(histories):\n",
    "    best_val_losses = list()\n",
    "    best_val_metrics = list()\n",
    "    all_best_hidden_layer_sizes = list()\n",
    "\n",
    "    for history in histories:\n",
    "        best_val_loss, best_val_metric, best_hidden_layer_sizes = get_statistics_from_history(history)\n",
    "        best_val_losses.append(best_val_loss)\n",
    "        best_val_metrics.append(best_val_metric)\n",
    "        all_best_hidden_layer_sizes.append(best_hidden_layer_sizes)\n",
    "    \n",
    "    mean_best_val_loss = np.mean(best_val_losses)\n",
    "    mean_best_val_metric = np.mean(best_val_metrics)\n",
    "    mean_best_hidden_layer_sizes = [np.mean(layer) for layer in list(zip(*all_best_hidden_layer_sizes))]\n",
    "    \n",
    "    return mean_best_val_loss, mean_best_val_metric, mean_best_hidden_layer_sizes\n",
    "\n",
    "\n",
    "def cross_validate(train_fn, x, y, n_splits, random_state=42, *args, **kwargs):\n",
    "    from sklearn.model_selection import KFold\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    histories = list()\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "        xtrain, xtest = x[train_index], x[test_index]\n",
    "        ytrain, ytest = y[train_index], y[test_index]\n",
    "\n",
    "        history = train_fn(xtrain, ytrain, validation_data=(xtest, ytest), *args, **kwargs)\n",
    "        histories.append(history)\n",
    "\n",
    "        best_val_loss, best_val_metric, best_hidden_layer_sizes = get_statistics_from_history(history)\n",
    "        print(f\"Run {i} completed, best_val_loss: {best_val_loss}, best_val_metric: {best_val_metric}, best_hidden_layer_sizes: {best_hidden_layer_sizes}\")\n",
    "\n",
    "    mean_best_val_loss, mean_best_val_metric, mean_best_hidden_layer_sizes = get_statistics_from_histories(histories)\n",
    "    print(f'mean_best_val_loss: {mean_best_val_loss}')\n",
    "    print(f'mean_best_val_metric: {mean_best_val_metric}')\n",
    "    print(f'mean_best_hidden_layer_sizes: {mean_best_hidden_layer_sizes}')\n",
    "\n",
    "    return histories, mean_best_hidden_layer_sizes\n",
    "\n",
    "\n",
    "def hyperparameter_search(train_fn, x, y, validation_data, *args, **kwargs):\n",
    "    from itertools import product\n",
    "\n",
    "    all_params = [*args] + list(kwargs.values())\n",
    "    histories = list()\n",
    "\n",
    "    best_overall_val_loss = np.inf\n",
    "    best_overall_val_metric = None\n",
    "    best_overall_combination = None\n",
    "\n",
    "    for combination in product(*all_params):\n",
    "        combination_args = combination[:len(args)]\n",
    "\n",
    "        combination_kwargs_values = combination[len(args):]\n",
    "        combination_kwargs = dict(zip(kwargs.keys(), combination_kwargs_values))\n",
    "\n",
    "        history = train_fn(x, y, validation_data, *combination_args, **combination_kwargs)\n",
    "        history['parameters'] = combination\n",
    "        histories.append(history)\n",
    "\n",
    "        best_val_loss, best_val_metric, best_hidden_layer_sizes = get_statistics_from_history(history)\n",
    "        print(f\"Run with parameters {combination} completed, best_val_loss: {best_val_loss}, best_val_metric: {best_val_metric}, best_hidden_layer_sizes: {best_hidden_layer_sizes}\")\n",
    "\n",
    "        if best_val_loss < best_overall_val_loss:\n",
    "            best_overall_val_loss = best_val_loss\n",
    "            best_overall_val_metric = best_val_metric\n",
    "            best_overall_combination = combination\n",
    "    \n",
    "    print(f'Best overall combination: {best_overall_combination}, val_metric: {best_overall_val_metric}')\n",
    "\n",
    "    return histories, best_overall_combination\n",
    "\n",
    "\n",
    "def interruptible(f):\n",
    "    def function(*args, **kwargs):\n",
    "        try:\n",
    "            return f(*args, **kwargs)\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Interrupted by user.\")\n",
    "    return function\n",
    "\n",
    "\n",
    "class AnytimeAlgorithm:\n",
    "    def __init__(self):\n",
    "        self.val_metrics = list()\n",
    "        self.best_val_metric = -np.inf\n",
    "        self.start_time = None\n",
    "    \n",
    "    def log_result(self, val_metric):\n",
    "        if val_metric > self.best_val_metric:\n",
    "            self.best_val_metric = val_metric\n",
    "        _time = time.time() - self.start_time\n",
    "        self.val_metrics.append((_time, self.best_val_metric))\n",
    "    \n",
    "    def run(self):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "\n",
    "class Range:\n",
    "    def __init__(self, min_value, max_value, transformation=None, integer=False):\n",
    "        self.min_value = min_value\n",
    "        self.max_value = max_value\n",
    "        self.transformation = transformation\n",
    "        self.integer = integer\n",
    "    \n",
    "    def sample(self):\n",
    "        x = self._raw_sample()\n",
    "        if self.integer:\n",
    "            x = np.rint(x).astype(int)\n",
    "        if self.transformation is not None:\n",
    "            result = self.transformation(x)\n",
    "            print(f\"Transformed value {x} to {result}.\")\n",
    "            return result\n",
    "        return x\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def _raw_sample(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class UniformRange(Range):\n",
    "    def _raw_sample(self):\n",
    "        return np.random.uniform(self.min_value, self.max_value)\n",
    "\n",
    "\n",
    "class PowerRange(Range):\n",
    "    def _raw_sample(self):\n",
    "        exponent = np.random.uniform(self.min_value, self.max_value)\n",
    "        return 10. ** exponent\n",
    "\n",
    "\n",
    "class RandomSearch(AnytimeAlgorithm):\n",
    "    @staticmethod\n",
    "    def sample_combination(values):\n",
    "        combination = list()\n",
    "        for value in values:\n",
    "            if isinstance(value, Range):\n",
    "                combination.append(value.sample())\n",
    "            else:\n",
    "                combination.append(value)\n",
    "        return tuple(combination)\n",
    "    \n",
    "    @interruptible\n",
    "    def run(self, train_fn, x, y, validation_data, *args, **kwargs):        \n",
    "        super().run()\n",
    "\n",
    "        start_time = time.time()\n",
    "        histories = list()\n",
    "        improvements = list()\n",
    "\n",
    "        best_overall_val_metric = -np.inf\n",
    "        best_overall_combination = None\n",
    "\n",
    "        while True:\n",
    "            combination_args = self.sample_combination([*args])\n",
    "\n",
    "            combination_kwargs_values = self.sample_combination(list(kwargs.values()))\n",
    "            combination_kwargs = dict(zip(kwargs.keys(), combination_kwargs_values))\n",
    "\n",
    "            combination = combination_args + combination_kwargs_values\n",
    "\n",
    "            print(f\"Run with parameters {combination} started...\")\n",
    "\n",
    "            history = train_fn(x, y, validation_data, *combination_args, **combination_kwargs)\n",
    "            history['parameters'] = combination\n",
    "            histories.append(history)\n",
    "\n",
    "            best_val_loss, best_val_metric, best_hidden_layer_sizes = get_statistics_from_history(history)\n",
    "            print(f\"Run with parameters {combination} completed, best_val_loss: {best_val_loss}, best_val_metric: {best_val_metric}, best_hidden_layer_sizes: {best_hidden_layer_sizes}\")\n",
    "\n",
    "            if best_val_metric > best_overall_val_metric:\n",
    "                best_overall_val_metric = best_val_metric\n",
    "                best_overall_combination = combination\n",
    "            \n",
    "            self.log_result(best_overall_val_metric)\n",
    "            print(f'Best overall combination: {best_overall_combination}, val_metric: {best_overall_val_metric}')\n",
    "\n",
    "\n",
    "def get_convolutional_model(x, layer_sizes, output_neurons=10):\n",
    "    model = Sequential([\n",
    "        Conv2D(layer_sizes[0], filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', kernel_initializer='lecun_normal', input_shape=x[0,:,:,:].shape),\n",
    "        Conv2D(layer_sizes[1], filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', kernel_initializer='lecun_normal'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        Conv2D(layer_sizes[2], filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', kernel_initializer='lecun_normal'),\n",
    "        Conv2D(layer_sizes[3], filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', kernel_initializer='lecun_normal'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        Flatten(),\n",
    "        Dense(layer_sizes[4], activation='selu', kernel_initializer='lecun_normal'),\n",
    "        Dense(output_neurons, activation='softmax', fixed_size=True),\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_dense_model(x, layer_sizes):\n",
    "    layers = list()\n",
    "    \n",
    "    layers.append(Dense(layer_sizes[0], activation='selu', kernel_initializer='lecun_normal', input_shape=x[0, :].shape))\n",
    "    for layer_size in layer_sizes[1:]:\n",
    "        layers.append(Dense(layer_size, activation='selu', kernel_initializer='lecun_normal'))\n",
    "    layers.append(Dense(1, activation=None, kernel_initializer='lecun_normal', fixed_size=True))\n",
    "    \n",
    "    model = Sequential(layers)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_fn_conv(x, y, validation_data, learning_rate, schedule, layer_sizes, output_neurons=10, min_new_neurons=20, \n",
    "             growth_percentage=0.2, verbose=False, use_static_graph=True):\n",
    "    batch_size = 128\n",
    "\n",
    "    model = get_convolutional_model(x, layer_sizes, output_neurons)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    history = model.fit(x=x, y=y, optimizer=optimizer, schedule=schedule, batch_size=batch_size, min_new_neurons=min_new_neurons, \n",
    "                        validation_data=validation_data, growth_percentage=growth_percentage, verbose=verbose, use_static_graph=use_static_graph)\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "def squared_error(y_true, y_pred):\n",
    "    return (y_true - y_pred) ** 2\n",
    "\n",
    "\n",
    "def train_fn_dense(x, y, validation_data, learning_rate, schedule, layer_sizes, min_new_neurons=20, \n",
    "             growth_percentage=0.2, verbose=False, use_static_graph=True):\n",
    "    batch_size = 128\n",
    "\n",
    "    model = get_dense_model(x, layer_sizes)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    history = model.fit(x=x, y=y, optimizer=optimizer, schedule=schedule, batch_size=batch_size, min_new_neurons=min_new_neurons, \n",
    "                        validation_data=validation_data, growth_percentage=growth_percentage, verbose=verbose, use_static_graph=use_static_graph,\n",
    "                        loss_fn=squared_error, metric_fn=squared_error)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Individual:\n",
    "    def __init__(self, genome, model, optimizer, history=None):\n",
    "        self.genome = genome\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        if history is not None:\n",
    "            self.history = history\n",
    "        else:\n",
    "            self.history = Sequential.ParameterContainer.prepare_history()\n",
    "        self.age = 0\n",
    "    \n",
    "    def copy(self):\n",
    "        individual_copy = Individual.__new__(Individual)\n",
    "        individual_copy.genome = self.genome.copy()\n",
    "        individual_copy.model = self.model.copy()\n",
    "        individual_copy.optimizer = copy.deepcopy(self.optimizer)\n",
    "        individual_copy.history = copy.deepcopy(self.history)\n",
    "        individual_copy.age = self.age\n",
    "        return individual_copy\n",
    "    \n",
    "    def mutate(self, mutation_strength):\n",
    "        if mutation_strength > 0:\n",
    "            self.model.mutate(mutation_strength)\n",
    "    \n",
    "    def correct(self):\n",
    "        self.genome[0] = max(self.genome[0], 2.5)  # Regularization penalty\n",
    "        self.genome[1] = np.clip(self.genome[1], 0.1, 1)  # Dataset sample size\n",
    "    \n",
    "    def get_val_metric(self):\n",
    "        return self.history['val_metric'][-1]\n",
    "    \n",
    "    def get_age(self):\n",
    "#         return len(self.history['val_metric'])\n",
    "        return self.age\n",
    "    \n",
    "    def get_age_penalty_coefficient(self, age_penalty_period):\n",
    "        age = self.get_age()\n",
    "#         return 1 / (2 ** max(0, (age - age_penalty_period) / age_penalty_period))\n",
    "        if age <= age_penalty_period:\n",
    "            return 1\n",
    "        return 1 / (1 + 0.005 * 1.8 ** (age - age_penalty_period))\n",
    "    \n",
    "    def get_fitness(self, age_penalty_period):\n",
    "        if age_penalty_period is None:\n",
    "            return self.get_val_metric()\n",
    "        return self.get_val_metric() * self.get_age_penalty_coefficient(age_penalty_period)\n",
    "    \n",
    "    def get_regularization_penalty(self):\n",
    "        return 10. ** -self.genome[0]\n",
    "    \n",
    "    def get_dataset_sample_size(self):\n",
    "        return self.genome[1]\n",
    "    \n",
    "    def get_hidden_layer_sizes(self):\n",
    "        return self.history['hidden_layer_sizes'][-1]\n",
    "\n",
    "class Evolution(AnytimeAlgorithm):\n",
    "    @staticmethod\n",
    "    def create_new_individual(x, layer_sizes, output_neurons, learning_rate):\n",
    "        genome = np.array([3, 0.1])\n",
    "        model = get_convolutional_model(x, layer_sizes, output_neurons=output_neurons)\n",
    "        model.build(x.shape)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        individual = Individual(genome, model, optimizer)\n",
    "        return individual\n",
    "    \n",
    "    @staticmethod\n",
    "    def initialize_population(population_size, x, layer_sizes, output_neurons, learning_rate):\n",
    "        population = [Evolution.create_new_individual(x, layer_sizes, output_neurons, learning_rate) for _ in range(population_size)]\n",
    "        return population\n",
    "\n",
    "    @staticmethod\n",
    "    def introduce_new_individuals(population, n_introduced, x, layer_sizes, output_neurons, learning_rate):\n",
    "        introduced_individuals = [Evolution.create_new_individual(x, layer_sizes, output_neurons, learning_rate) for _ in range(n_introduced)]\n",
    "        return population + introduced_individuals\n",
    "\n",
    "    @staticmethod\n",
    "    def get_best_individual_by_fitness(population, age_penalty_period):\n",
    "#         best_individual = None\n",
    "#         best_fitness = - np.inf\n",
    "#         for individual in population:\n",
    "#             fitness = individual.get_fitness(age_penalty_period)\n",
    "#             if fitness > best_fitness:\n",
    "#                 best_individual = individual\n",
    "#                 best_fitness = fitness\n",
    "#         return best_individual\n",
    "        return max(population, key=lambda x: x.get_fitness(age_penalty_period))\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_best_individual_by_val_metric(population):\n",
    "#         best_individual = None\n",
    "#         best_val_metric = - np.inf\n",
    "#         for individual in population, key=population:\n",
    "#             val_metric = individual.get_val_metric()\n",
    "#             if val_metric > best_val_metric:\n",
    "#                 best_individual = individual\n",
    "#                 best_val_metric = val_metric\n",
    "#         return best_individual\n",
    "        return max(population, key=lambda x: x.get_val_metric())\n",
    "\n",
    "    @staticmethod\n",
    "    def crossover(population, n_parents, strategy, mutation_strength):\n",
    "        novel_population = list()\n",
    "        for individual in population:\n",
    "            parents_selection = np.random.choice(list(range(len(population))), size=n_parents, replace=False)\n",
    "            parent_genomes = [population[index].genome for index in parents_selection]\n",
    "            offspring_genome = np.mean(np.vstack(parent_genomes), axis=0)\n",
    "            offspring = individual.copy()\n",
    "            offspring.genome = offspring_genome\n",
    "            offspring.genome += np.random.normal(0, 1, offspring.genome.shape) * strategy\n",
    "            offspring.mutate(mutation_strength)\n",
    "            novel_population.append(offspring)\n",
    "        return population + novel_population\n",
    "\n",
    "    @staticmethod\n",
    "    def correct(population):\n",
    "        for individual in population:\n",
    "            individual.correct()\n",
    "        return population\n",
    "\n",
    "    # @staticmethod\n",
    "    # def mutation(population, mutation_strength):\n",
    "    #     new_population = list()\n",
    "    #     for individual in population:\n",
    "    #         individual_copy = individual.copy()\n",
    "    #         individual_copy.mutate(mutation_strength)\n",
    "    #         new_population.extend([individual, individual_copy])\n",
    "    #     return new_population\n",
    "\n",
    "    @staticmethod\n",
    "    def extend_history(old_history, new_history):\n",
    "        for key in old_history.keys():\n",
    "            old_history[key].extend(new_history[key])\n",
    "\n",
    "    @staticmethod\n",
    "    def training(population, x, y, validation_data, batch_size, min_new_neurons, growth_percentage, verbose, use_static_graph):\n",
    "        for individual in population:\n",
    "            model = individual.model\n",
    "            optimizer = individual.optimizer\n",
    "            # schedule = Schedule([StaticEpochNoRegularization()])\n",
    "            schedule = Schedule([DynamicEpoch(individual.get_regularization_penalty(), 'weighted_l1')])\n",
    "            # x_train_sample, y_train_sample = get_dataset_sample(x, y, individual.get_dataset_sample_size())\n",
    "    #         x_train_sample, y_train_sample = get_dataset_sample(x, y, 0.1)\n",
    "            # x_test_sample, y_test_sample = get_dataset_sample(validation_data[0], validation_data[1], individual.get_dataset_sample_size())\n",
    "    #         x_test_sample, y_test_sample = get_dataset_sample(validation_data[0], validation_data[1], 0.1, seed=42)\n",
    "            x_train_sample, y_train_sample = x, y\n",
    "            x_test_sample, y_test_sample = validation_data[0], validation_data[1]\n",
    "            history = model.fit(x=x_train_sample, y=y_train_sample, optimizer=optimizer, schedule=schedule, batch_size=batch_size, \n",
    "                                min_new_neurons=min_new_neurons, validation_data=(x_test_sample, y_test_sample), growth_percentage=growth_percentage, \n",
    "                                verbose=verbose, use_static_graph=use_static_graph)\n",
    "            Evolution.extend_history(individual.history, history)\n",
    "        return population\n",
    "\n",
    "    @staticmethod\n",
    "    def tournament_selection(population, population_size, tournament_size, age_penalty_period):\n",
    "        new_population = list()\n",
    "\n",
    "        while len(new_population) < population_size:\n",
    "            selection = np.random.choice(list(range(len(population))), size=tournament_size, replace=False)\n",
    "            best_individual = None\n",
    "            best_fitness = - np.inf\n",
    "            for individual_index in selection:\n",
    "                individual = population[individual_index]\n",
    "                fitness = individual.get_fitness(age_penalty_period)\n",
    "                if fitness > best_fitness:\n",
    "                    best_individual = individual\n",
    "                    best_fitness = fitness\n",
    "            new_population.append(best_individual.copy())\n",
    "\n",
    "        return new_population\n",
    "    \n",
    "    @staticmethod\n",
    "    def age_population(population):\n",
    "        for individual in population:\n",
    "            individual.age += 1\n",
    "        return population\n",
    "\n",
    "    @staticmethod\n",
    "    def measure_fitnesses(population, age_penalty_period):\n",
    "        fitnesses = list()\n",
    "        for individual in population:\n",
    "            fitnesses.append(individual.get_fitness(age_penalty_period))\n",
    "        return fitnesses\n",
    "\n",
    "    def print_generation_statistics(self, generation, population, duration, age_penalty_period):\n",
    "        population_sorted_by_fitness = sorted(population, key=lambda x: x.get_fitness(age_penalty_period), reverse=True)\n",
    "        individuals = [(individual.get_age(), round(individual.get_val_metric(), 4), round(individual.get_fitness(age_penalty_period), 4), round(individual.genome[0], 1), round(individual.genome[1], 2), individual.get_hidden_layer_sizes()) for individual in population_sorted_by_fitness]\n",
    "        population_sorted_by_val_metric = sorted(population, key=lambda x: x.get_val_metric(), reverse=True)\n",
    "        best_val_metric = population_sorted_by_val_metric[0].get_val_metric()\n",
    "        self.log_result(best_val_metric)\n",
    "        print(f\"Generation {generation}: {round(duration, 1)} s, best val metric {round(best_val_metric, 4)}, {individuals}\")\n",
    "        print(f\"#### Overall best val metric {self.best_val_metric} ####\")\n",
    "\n",
    "    @interruptible\n",
    "    def run(self, x, y, validation_data, batch_size, layer_sizes, output_neurons, learning_rate, n_parents, strategy, population_size=10, n_generations=10, \n",
    "            tournament_size=3, elitism=True, n_introduced=0, age_penalty_period=None, min_new_neurons=20, growth_percentage=0.2, use_static_graph=True, \n",
    "            mutation_strength=0.):\n",
    "        super().run()\n",
    "        \n",
    "        population = self.initialize_population(population_size, x, layer_sizes, output_neurons, learning_rate)\n",
    "        best_individual = None\n",
    "        fitnesses_history = list()\n",
    "        for generation in range(n_generations):\n",
    "            start_time = time.time()\n",
    "            population = self.crossover(population, n_parents, strategy, mutation_strength)\n",
    "            # population = mutation(population, mutation_strength)\n",
    "            population = self.introduce_new_individuals(population, n_introduced, x, layer_sizes, output_neurons, learning_rate)\n",
    "            population = self.training(population, x, y, validation_data, batch_size, min_new_neurons, \n",
    "                                  growth_percentage, verbose=False, use_static_graph=use_static_graph)\n",
    "            population = self.tournament_selection(population, population_size, tournament_size, age_penalty_period)\n",
    "            if elitism:\n",
    "                if best_individual is not None:\n",
    "                    population.append(best_individual)\n",
    "            population = self.age_population(population)\n",
    "            if elitism:\n",
    "                best_individual = self.get_best_individual_by_fitness(population, age_penalty_period).copy()\n",
    "            fitnesses = self.measure_fitnesses(population, age_penalty_period)\n",
    "            duration = time.time() - start_time\n",
    "            self.print_generation_statistics(generation, population, duration, age_penalty_period)\n",
    "            # fitnesses_history.append(fitnesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashnion MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratio 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = get_fashion_mnist_dataset(fraction=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stats time: 0.04924893379211426\n",
      "pruning time: 0.09215831756591797\n",
      "stats time: 0.028137922286987305\n",
      "update history time: 0.0002963542938232422\n",
      "total pruning time: 0.17015743255615234\n",
      "2.089315176010132\n",
      "[20, 20, 20, 20, 20]\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "evolution(x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test),\n",
    "          batch_size=32, layer_sizes=[20, 20, 20, 20, 20], output_neurons=10, learning_rate=0.0004, n_parents=5, strategy=[0.5, 0.05], \n",
    "          population_size=10, n_generations=50, tournament_size=3, n_introduced=2, age_penalty_period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: 22.9 s, [(1, 0.5263, 0.5263, 3.2, 0.17, [20, 20, 20, 20, 20]), (1, 0.4737, 0.4737, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.4737, 0.4737, 3.4, 0.11, [20, 20, 20, 20, 20]), (1, 0.4737, 0.4737, 3.4, 0.11, [20, 20, 20, 20, 20]), (1, 0.4737, 0.4737, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.4211, 0.4211, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.3947, 0.3947, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.3947, 0.3947, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.3947, 0.3947, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.3684, 0.3684, 2.8, 0.11, [20, 20, 20, 20, 20])]\n",
      "Generation 1: 27.5 s, [(2, 0.6053, 0.6053, 2.9, 0.1, [20, 20, 20, 20, 20]), (2, 0.6053, 0.6053, 2.9, 0.1, [20, 20, 20, 20, 20]), (2, 0.6053, 0.6053, 2.9, 0.1, [20, 20, 20, 20, 20]), (2, 0.5526, 0.5526, 3.6, 0.16, [20, 20, 20, 20, 20]), (2, 0.5526, 0.5526, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.5526, 0.5526, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.5526, 0.5526, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.5526, 0.5526, 3.5, -0.02, [20, 20, 20, 20, 20]), (2, 0.5263, 0.5263, 3.1, 0.04, [20, 20, 20, 20, 20]), (1, 0.5263, 0.5263, 3.2, 0.17, [20, 20, 20, 20, 20]), (2, 0.4737, 0.4737, 3.4, 0.11, [20, 20, 20, 20, 20])]\n",
      "Generation 2: 30.9 s, [(3, 0.7105, 0.7105, 2.9, 0.1, [20, 20, 20, 20, 20]), (3, 0.7105, 0.7105, 2.9, 0.1, [20, 20, 20, 20, 20]), (3, 0.7105, 0.7105, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.6842, 0.6842, 3.0, 0.0, [20, 20, 20, 20, 20]), (3, 0.6579, 0.6579, 2.9, 0.1, [20, 20, 20, 20, 20]), (3, 0.6579, 0.6579, 3.6, 0.06, [20, 20, 20, 20, 20]), (3, 0.6579, 0.6579, 3.6, 0.06, [20, 20, 20, 20, 20]), (3, 0.6579, 0.6579, 3.5, 0.11, [20, 20, 20, 20, 20]), (3, 0.6316, 0.6316, 2.8, 0.11, [20, 20, 20, 20, 20]), (3, 0.6053, 0.6053, 3.4, 0.11, [20, 20, 20, 20, 20]), (2, 0.6053, 0.6053, 2.9, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 3: 33.6 s, [(4, 0.7105, 0.7105, 2.9, 0.1, [20, 20, 20, 20, 20]), (4, 0.7105, 0.7105, 4.0, 0.17, [20, 20, 20, 20, 20]), (3, 0.7105, 0.7105, 2.9, 0.1, [20, 20, 20, 20, 20]), (4, 0.6842, 0.6842, 3.6, 0.06, [20, 20, 20, 20, 20]), (4, 0.6842, 0.6842, 3.4, 0.01, [20, 20, 20, 20, 20]), (4, 0.6842, 0.6842, 3.6, 0.06, [20, 20, 20, 20, 20]), (4, 0.6842, 0.6842, 2.9, 0.1, [20, 20, 20, 20, 20]), (4, 0.6842, 0.6842, 2.8, -0.01, [20, 20, 20, 20, 20]), (4, 0.6842, 0.6842, 3.0, 0.1, [20, 20, 20, 20, 20]), (4, 0.6842, 0.6842, 3.5, 0.11, [20, 20, 20, 20, 20]), (4, 0.6579, 0.6579, 3.4, 0.11, [20, 20, 20, 20, 20])]\n",
      "Generation 4: 36.4 s, [(5, 0.7632, 0.7632, 3.1, 0.12, [20, 20, 20, 20, 20]), (5, 0.7632, 0.7632, 3.1, 0.12, [20, 20, 20, 20, 20]), (5, 0.7632, 0.7632, 3.9, 0.09, [20, 20, 20, 20, 20]), (5, 0.7632, 0.7632, 3.4, 0.11, [20, 20, 20, 20, 20]), (5, 0.7368, 0.7368, 2.9, 0.15, [20, 20, 20, 20, 20]), (5, 0.7105, 0.7105, 2.8, 0.03, [20, 20, 20, 20, 20]), (4, 0.7105, 0.7105, 2.9, 0.1, [20, 20, 20, 20, 20]), (5, 0.6842, 0.6842, 2.8, -0.01, [20, 20, 20, 20, 20]), (4, 0.6842, 0.6842, 2.9, 0.1, [20, 20, 20, 20, 20]), (5, 0.6842, 0.6842, 2.8, -0.01, [20, 20, 20, 20, 20]), (4, 0.6842, 0.6842, 2.9, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 5: 38.1 s, [(5, 0.8158, 0.8158, 2.8, 0.08, [20, 20, 20, 20, 20]), (5, 0.7632, 0.7632, 3.1, 0.12, [20, 20, 20, 20, 20]), (5, 0.7368, 0.7368, 3.3, 0.13, [20, 20, 20, 20, 20]), (6, 0.7368, 0.7368, 2.8, -0.01, [20, 20, 20, 20, 20]), (6, 0.7105, 0.7105, 2.9, 0.15, [20, 20, 20, 20, 20]), (6, 0.7105, 0.7105, 3.1, 0.11, [20, 20, 20, 20, 20]), (6, 0.7105, 0.7105, 3.4, 0.11, [20, 20, 20, 20, 20]), (6, 0.7105, 0.7105, 2.9, 0.15, [20, 20, 20, 20, 20]), (6, 0.7105, 0.7105, 3.4, 0.11, [20, 20, 20, 20, 20]), (6, 0.7105, 0.7105, 3.1, 0.12, [20, 20, 20, 20, 20]), (6, 0.7105, 0.7105, 3.1, 0.11, [20, 20, 20, 20, 20])]\n",
      "Generation 6: 41.5 s, [(7, 0.8158, 0.8158, 2.9, 0.15, [20, 20, 20, 20, 20]), (7, 0.8158, 0.8158, 2.9, 0.15, [20, 20, 20, 20, 20]), (5, 0.8158, 0.8158, 2.8, 0.08, [20, 20, 20, 20, 20]), (7, 0.7632, 0.7632, 2.8, -0.01, [20, 20, 20, 20, 20]), (7, 0.7632, 0.7632, 2.8, -0.01, [20, 20, 20, 20, 20]), (6, 0.7632, 0.7632, 3.1, 0.12, [20, 20, 20, 20, 20]), (7, 0.7632, 0.7632, 2.9, 0.15, [20, 20, 20, 20, 20]), (7, 0.7632, 0.7632, 2.8, -0.01, [20, 20, 20, 20, 20]), (7, 0.7368, 0.7368, 3.1, 0.11, [20, 20, 20, 20, 20]), (7, 0.7368, 0.7368, 3.4, 0.15, [20, 20, 20, 20, 20]), (7, 0.7368, 0.7368, 3.1, 0.14, [20, 20, 20, 20, 20])]\n",
      "Generation 7: 43.7 s, [(7, 0.8158, 0.8158, 2.9, 0.15, [20, 20, 20, 20, 20]), (8, 0.7895, 0.7895, 2.8, -0.01, [20, 20, 20, 20, 20]), (8, 0.7632, 0.7632, 2.9, 0.15, [20, 20, 20, 20, 20]), (8, 0.7632, 0.7632, 3.4, 0.15, [20, 20, 20, 20, 20]), (7, 0.7632, 0.7632, 3.1, 0.12, [20, 20, 20, 20, 20]), (8, 0.7632, 0.7632, 3.1, 0.14, [20, 20, 20, 20, 20]), (8, 0.7632, 0.7632, 2.8, 0.03, [20, 20, 20, 20, 20]), (8, 0.7632, 0.7632, 2.5, 0.18, [20, 20, 20, 20, 20]), (8, 0.7632, 0.7632, 3.1, 0.14, [20, 20, 20, 20, 20]), (7, 0.7632, 0.7632, 3.1, 0.12, [20, 20, 20, 20, 20]), (6, 0.7368, 0.7368, 2.8, 0.08, [20, 20, 20, 20, 20])]\n",
      "Generation 8: 45.7 s, [(8, 0.8158, 0.8158, 3.1, 0.03, [20, 20, 20, 20, 20]), (9, 0.8158, 0.8158, 2.8, -0.01, [20, 20, 20, 20, 20]), (8, 0.8158, 0.8158, 3.1, 0.03, [20, 20, 20, 20, 20]), (9, 0.8158, 0.8158, 2.8, -0.01, [20, 20, 20, 20, 20]), (9, 0.8158, 0.8158, 2.8, 0.07, [20, 20, 20, 20, 20]), (7, 0.8158, 0.8158, 2.9, 0.15, [20, 20, 20, 20, 20]), (9, 0.7895, 0.7895, 2.5, 0.18, [20, 20, 20, 20, 20]), (8, 0.7632, 0.7632, 2.8, 0.1, [20, 20, 20, 20, 20]), (8, 0.7632, 0.7632, 2.8, 0.1, [20, 20, 20, 20, 20]), (7, 0.7632, 0.7632, 2.8, 0.08, [20, 20, 20, 20, 20]), (9, 0.7632, 0.7632, 2.9, 0.13, [20, 20, 20, 20, 20])]\n",
      "Generation 9: 51.4 s, [(10, 0.8421, 0.8421, 2.5, 0.18, [20, 20, 20, 20, 20]), (9, 0.8158, 0.8158, 2.8, 0.1, [20, 20, 20, 20, 20]), (10, 0.8158, 0.8158, 2.9, 0.11, [20, 20, 20, 20, 20]), (10, 0.8158, 0.8158, 2.9, 0.11, [20, 20, 20, 20, 20]), (9, 0.8158, 0.8158, 2.8, 0.1, [20, 20, 20, 20, 20]), (9, 0.8158, 0.8158, 2.8, 0.1, [20, 20, 20, 20, 20]), (10, 0.8158, 0.8158, 2.9, 0.11, [20, 20, 20, 20, 20]), (8, 0.8158, 0.8158, 3.1, 0.03, [20, 20, 20, 20, 20]), (10, 0.7895, 0.7895, 3.5, 0.15, [20, 20, 20, 20, 20]), (10, 0.7895, 0.7895, 3.5, 0.15, [20, 20, 20, 20, 20]), (10, 0.7632, 0.7632, 3.2, 0.06, [20, 20, 20, 20, 20])]\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "evolution(x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test),\n",
    "          batch_size=32, layer_sizes=[20, 20, 20, 20, 20], output_neurons=10, learning_rate=0.0004, n_parents=5, strategy=[0.5, 0.05], \n",
    "          population_size=10, n_generations=50, tournament_size=3, n_introduced=2, age_penalty_period=10, use_static_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: 23.8 s, [(1, 0.4737, 0.4737, 3.1, 0.09, [20, 20, 20, 20, 20]), (1, 0.4474, 0.4474, 2.8, 0.07, [20, 20, 20, 20, 20]), (1, 0.4474, 0.4474, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.4474, 0.4474, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.4474, 0.4474, 2.8, 0.07, [20, 20, 20, 20, 20]), (1, 0.4211, 0.4211, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.3947, 0.3947, 2.6, -0.1, [20, 20, 20, 20, 20]), (1, 0.3947, 0.3947, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.2895, 0.2895, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.2895, 0.2895, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 1: 26.1 s, [(2, 0.5526, 0.5526, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.5526, 0.5526, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.5526, 0.5526, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.5263, 0.5263, 3.1, 0.09, [20, 20, 20, 20, 20]), (2, 0.5, 0.5, 2.8, 0.07, [20, 20, 20, 20, 20]), (2, 0.5, 0.5, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.5, 0.5, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.5, 0.5, 2.8, 0.05, [20, 20, 20, 20, 20]), (2, 0.4737, 0.4737, 3.0, 0.15, [20, 20, 20, 20, 20]), (2, 0.4737, 0.4737, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.4737, 0.4737, 3.1, 0.09, [20, 20, 20, 20, 20])]\n",
      "Generation 2: 29.9 s, [(3, 0.6053, 0.6053, 3.0, 0.17, [20, 20, 20, 20, 20]), (3, 0.6053, 0.6053, 3.0, 0.17, [20, 20, 20, 20, 20]), (3, 0.6053, 0.6053, 2.8, 0.05, [20, 20, 20, 20, 20]), (3, 0.6053, 0.6053, 3.0, 0.17, [20, 20, 20, 20, 20]), (3, 0.5789, 0.5789, 2.9, 0.18, [20, 20, 20, 20, 20]), (3, 0.5789, 0.5789, 2.9, 0.18, [20, 20, 20, 20, 20]), (3, 0.5789, 0.5789, 2.9, 0.18, [20, 20, 20, 20, 20]), (3, 0.5789, 0.5789, 3.3, 0.26, [20, 20, 20, 20, 20]), (3, 0.5789, 0.5789, 3.3, 0.26, [20, 20, 20, 20, 20]), (2, 0.5526, 0.5526, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.5, 0.5, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 3: 37.0 s, [(4, 0.6316, 0.6316, 2.7, 0.11, [20, 20, 20, 20, 20]), (4, 0.6316, 0.6316, 3.6, 0.26, [20, 20, 20, 20, 20]), (4, 0.6316, 0.6316, 2.7, 0.11, [20, 20, 20, 20, 20]), (4, 0.6316, 0.6316, 2.9, 0.18, [20, 20, 20, 20, 20]), (4, 0.6316, 0.6316, 2.9, 0.18, [20, 20, 20, 20, 20]), (4, 0.6316, 0.6316, 3.6, 0.26, [20, 20, 20, 20, 20]), (4, 0.6053, 0.6053, 3.0, 0.17, [20, 20, 20, 20, 20]), (4, 0.6053, 0.6053, 2.9, 0.18, [20, 20, 20, 20, 20]), (4, 0.6053, 0.6053, 3.9, 0.07, [20, 20, 20, 20, 20]), (3, 0.6053, 0.6053, 3.0, 0.17, [20, 20, 20, 20, 20]), (3, 0.5526, 0.5526, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 4: 40.9 s, [(5, 0.6842, 0.6842, 3.0, 0.17, [20, 20, 20, 20, 20]), (5, 0.6842, 0.6842, 2.7, 0.11, [20, 20, 20, 20, 20]), (5, 0.6842, 0.6842, 3.0, 0.17, [20, 20, 20, 20, 20]), (5, 0.6579, 0.6579, 2.9, 0.15, [20, 20, 20, 20, 20]), (5, 0.6579, 0.6579, 2.4, 0.13, [20, 20, 20, 20, 20]), (5, 0.6316, 0.6316, 4.1, 0.09, [20, 20, 20, 20, 20]), (5, 0.6316, 0.6316, 3.4, 0.14, [20, 20, 20, 20, 20]), (5, 0.6316, 0.6316, 2.0, 0.19, [20, 20, 20, 20, 20]), (5, 0.6316, 0.6316, 2.9, 0.18, [20, 20, 20, 20, 20]), (4, 0.6316, 0.6316, 2.7, 0.11, [20, 20, 20, 20, 20]), (5, 0.6053, 0.6053, 2.8, 0.24, [20, 20, 20, 20, 20])]\n",
      "Generation 5: 42.6 s, [(6, 0.7105, 0.7105, 3.4, 0.14, [20, 20, 20, 20, 20]), (6, 0.6842, 0.6842, 2.8, 0.24, [20, 20, 20, 20, 20]), (6, 0.6842, 0.6842, 2.8, 0.24, [20, 20, 20, 20, 20]), (6, 0.6842, 0.6842, 3.1, 0.12, [20, 20, 20, 20, 20]), (6, 0.6842, 0.6842, 3.4, 0.15, [20, 20, 20, 20, 20]), (5, 0.6842, 0.6842, 3.0, 0.17, [20, 20, 20, 20, 20]), (6, 0.6579, 0.6579, 3.2, 0.24, [20, 20, 20, 20, 20]), (6, 0.6579, 0.6579, 2.4, 0.13, [20, 20, 20, 20, 20]), (6, 0.6579, 0.6579, 2.5, 0.15, [20, 20, 20, 20, 20]), (6, 0.6316, 0.6316, 3.0, 0.17, [20, 20, 20, 20, 20]), (6, 0.6316, 0.6316, 2.8, 0.2, [20, 20, 20, 20, 20])]\n",
      "Generation 6: 45.2 s, [(7, 0.7105, 0.7105, 2.8, 0.2, [20, 20, 20, 20, 20]), (7, 0.7105, 0.7105, 3.4, 0.15, [20, 20, 20, 20, 20]), (6, 0.7105, 0.7105, 3.4, 0.14, [20, 20, 20, 20, 20]), (7, 0.6842, 0.6842, 3.5, 0.18, [20, 20, 20, 20, 20]), (6, 0.6842, 0.6842, 3.0, 0.17, [20, 20, 20, 20, 20]), (7, 0.6842, 0.6842, 2.8, 0.24, [20, 20, 20, 20, 20]), (7, 0.6842, 0.6842, 2.5, 0.15, [20, 20, 20, 20, 20]), (7, 0.6842, 0.6842, 3.4, 0.19, [20, 20, 20, 20, 20]), (7, 0.6842, 0.6842, 3.5, 0.18, [20, 20, 20, 20, 20]), (7, 0.6579, 0.6579, 3.4, 0.14, [20, 20, 20, 20, 20]), (7, 0.6579, 0.6579, 3.6, 0.2, [20, 20, 20, 20, 20])]\n",
      "Generation 7: 49.5 s, [(8, 0.7368, 0.7368, 3.0, 0.17, [20, 20, 20, 20, 20]), (8, 0.7368, 0.7368, 3.0, 0.17, [20, 20, 20, 20, 20]), (8, 0.7368, 0.7368, 3.4, 0.19, [20, 20, 20, 20, 20]), (8, 0.7368, 0.7368, 3.8, 0.17, [20, 20, 20, 20, 20]), (8, 0.7368, 0.7368, 3.0, 0.17, [20, 20, 20, 20, 20]), (7, 0.7105, 0.7105, 3.9, 0.18, [20, 20, 20, 20, 20]), (8, 0.7105, 0.7105, 3.4, 0.14, [20, 20, 20, 20, 20]), (8, 0.7105, 0.7105, 3.4, 0.14, [20, 20, 20, 20, 20]), (8, 0.7105, 0.7105, 3.4, 0.15, [20, 20, 20, 20, 20]), (7, 0.7105, 0.7105, 2.8, 0.2, [20, 20, 20, 20, 20]), (8, 0.6842, 0.6842, 3.5, 0.18, [20, 20, 20, 20, 20])]\n",
      "Generation 8: 50.6 s, [(9, 0.7632, 0.7632, 3.2, 0.23, [20, 20, 20, 20, 20]), (9, 0.7632, 0.7632, 3.5, 0.18, [20, 20, 20, 20, 20]), (9, 0.7368, 0.7368, 3.0, 0.17, [20, 20, 20, 20, 20]), (8, 0.7368, 0.7368, 3.0, 0.17, [20, 20, 20, 20, 20]), (9, 0.7105, 0.7105, 3.4, 0.17, [20, 20, 20, 20, 20]), (9, 0.7105, 0.7105, 3.0, 0.17, [20, 20, 20, 20, 20]), (9, 0.7105, 0.7105, 3.4, 0.17, [20, 20, 20, 20, 20]), (8, 0.6842, 0.6842, 3.4, 0.12, [20, 20, 20, 20, 20]), (8, 0.6842, 0.6842, 2.8, 0.2, [20, 20, 20, 20, 20]), (9, 0.6842, 0.6842, 4.2, 0.14, [20, 20, 20, 25, 20]), (8, 0.6579, 0.6579, 3.7, 0.19, [20, 20, 20, 20, 20])]\n",
      "Generation 9: 53.9 s, [(9, 0.7895, 0.7895, 3.4, 0.12, [20, 20, 20, 20, 20]), (10, 0.7632, 0.7632, 3.0, 0.17, [20, 20, 20, 20, 20]), (9, 0.7632, 0.7632, 3.2, 0.23, [20, 20, 20, 20, 20]), (9, 0.7368, 0.7368, 3.6, 0.04, [20, 20, 20, 20, 20]), (9, 0.7368, 0.7368, 3.6, 0.04, [20, 20, 20, 20, 20]), (10, 0.7368, 0.7368, 2.4, 0.22, [20, 20, 20, 20, 20]), (9, 0.7368, 0.7368, 3.0, 0.17, [20, 20, 20, 20, 20]), (9, 0.7368, 0.7368, 3.0, 0.17, [20, 20, 20, 20, 20]), (9, 0.7368, 0.7368, 3.0, 0.17, [20, 20, 20, 20, 20]), (10, 0.7368, 0.7368, 2.4, 0.22, [20, 20, 20, 20, 20]), (10, 0.7105, 0.7105, 3.2, 0.23, [20, 20, 20, 20, 20])]\n",
      "Generation 10: 55.9 s, [(9, 0.7895, 0.7895, 3.4, 0.12, [20, 20, 20, 20, 20]), (10, 0.7632, 0.7632, 3.0, 0.17, [20, 20, 20, 20, 20]), (10, 0.7632, 0.7632, 3.6, 0.04, [20, 20, 20, 20, 20]), (10, 0.7632, 0.7632, 3.0, 0.17, [20, 20, 20, 20, 20]), (10, 0.7632, 0.7632, 3.0, 0.17, [20, 20, 20, 20, 20]), (10, 0.7368, 0.7368, 3.7, 0.24, [20, 20, 20, 20, 20]), (10, 0.7368, 0.7368, 3.7, 0.24, [20, 20, 20, 20, 20]), (11, 0.7632, 0.7121, 3.0, 0.19, [20, 20, 20, 20, 20]), (10, 0.7105, 0.7105, 3.1, 0.22, [20, 20, 20, 20, 20]), (10, 0.7105, 0.7105, 3.3, 0.15, [20, 20, 20, 20, 20]), (10, 0.7105, 0.7105, 3.1, 0.22, [20, 20, 20, 20, 20])]\n",
      "Generation 11: 59.3 s, [(9, 0.7895, 0.7895, 3.4, 0.12, [20, 20, 20, 20, 20]), (10, 0.7368, 0.7368, 2.9, 0.13, [20, 20, 20, 20, 20]), (10, 0.7368, 0.7368, 2.9, 0.13, [20, 20, 20, 20, 20]), (11, 0.7632, 0.7121, 3.2, 0.24, [20, 20, 20, 20, 20]), (11, 0.7632, 0.7121, 3.0, 0.17, [20, 20, 20, 20, 20]), (11, 0.7632, 0.7121, 3.2, 0.24, [20, 20, 20, 20, 20]), (11, 0.7632, 0.7121, 3.2, 0.24, [20, 20, 20, 20, 20]), (11, 0.7632, 0.7121, 3.0, 0.21, [20, 20, 20, 20, 20]), (11, 0.7632, 0.7121, 3.2, 0.24, [20, 20, 20, 20, 20]), (11, 0.7368, 0.6875, 2.6, 0.18, [20, 20, 20, 20, 20]), (11, 0.7105, 0.6629, 3.1, 0.22, [20, 20, 20, 20, 20])]\n",
      "Generation 12: 62.8 s, [(9, 0.7895, 0.7895, 3.4, 0.12, [20, 20, 20, 20, 20]), (10, 0.7632, 0.7632, 3.2, 0.17, [20, 20, 20, 20, 20]), (11, 0.7632, 0.7121, 2.6, 0.22, [20, 20, 20, 20, 20]), (11, 0.7632, 0.7121, 2.6, 0.22, [20, 20, 20, 20, 20]), (11, 0.7632, 0.7121, 2.6, 0.22, [20, 20, 20, 20, 20]), (12, 0.7895, 0.6873, 3.2, 0.24, [20, 20, 20, 20, 20]), (12, 0.7895, 0.6873, 3.7, 0.18, [20, 20, 20, 20, 20]), (12, 0.7895, 0.6873, 3.7, 0.18, [20, 20, 20, 20, 20]), (11, 0.7105, 0.6629, 2.9, 0.13, [20, 20, 20, 20, 20]), (11, 0.7105, 0.6629, 2.9, 0.13, [20, 20, 20, 20, 20]), (11, 0.7105, 0.6629, 2.9, 0.13, [20, 20, 20, 20, 20])]\n",
      "Generation 13: 66.7 s, [(9, 0.7895, 0.7895, 3.4, 0.12, [20, 20, 20, 20, 20]), (10, 0.7368, 0.7368, 2.3, 0.22, [20, 20, 20, 20, 20]), (10, 0.7368, 0.7368, 2.3, 0.22, [20, 20, 20, 20, 20]), (11, 0.7895, 0.7366, 3.2, 0.17, [20, 20, 20, 20, 20]), (11, 0.7895, 0.7366, 3.2, 0.17, [20, 20, 20, 20, 20]), (10, 0.7105, 0.7105, 3.4, 0.12, [20, 20, 20, 20, 20]), (11, 0.7368, 0.6875, 3.6, 0.19, [20, 20, 20, 20, 20]), (12, 0.7368, 0.6415, 3.6, 0.18, [20, 20, 20, 20, 20]), (13, 0.7895, 0.6413, 2.8, 0.07, [20, 20, 20, 20, 20]), (12, 0.7105, 0.6185, 3.7, 0.17, [20, 20, 20, 20, 20]), (13, 0.7368, 0.5985, 3.7, 0.18, [20, 20, 20, 20, 20])]\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "evolution(x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test),\n",
    "          batch_size=32, layer_sizes=[20, 20, 20, 20, 20], output_neurons=10, learning_rate=0.0004, n_parents=5, strategy=[0.5, 0.05], \n",
    "          population_size=10, n_generations=50, tournament_size=3, n_introduced=2, age_penalty_period=10, use_static_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: 12.4 s, [(1, 0.5263, 0.5263, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.5263, 0.5263, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.5263, 0.5263, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.4737, 0.4737, 3.1, 0.07, [20, 20, 20, 20, 20]), (1, 0.4474, 0.4474, 3.8, 0.07, [20, 20, 25, 30, 20]), (1, 0.3947, 0.3947, 2.7, 0.14, [20, 20, 20, 20, 20]), (1, 0.3947, 0.3947, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.3947, 0.3947, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.3684, 0.3684, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.2895, 0.2895, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 1: 14.0 s, [(2, 0.6053, 0.6053, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.6053, 0.6053, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.5789, 0.5789, 3.5, 0.1, [20, 20, 20, 20, 20]), (2, 0.5789, 0.5789, 3.3, 0.05, [20, 20, 20, 20, 20]), (2, 0.5789, 0.5789, 3.5, 0.1, [20, 20, 20, 20, 20]), (2, 0.5526, 0.5526, 2.9, 0.13, [20, 20, 20, 20, 20]), (2, 0.5263, 0.5263, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.5263, 0.5263, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.5263, 0.5263, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.5263, 0.5263, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.3947, 0.3947, 2.7, 0.14, [20, 20, 20, 20, 20])]\n",
      "Generation 2: 16.2 s, [(3, 0.6842, 0.6842, 3.5, 0.1, [20, 20, 20, 20, 20]), (3, 0.6842, 0.6842, 3.5, 0.1, [20, 20, 20, 20, 20]), (3, 0.6842, 0.6842, 3.5, 0.1, [20, 20, 20, 20, 20]), (3, 0.6579, 0.6579, 3.5, 0.1, [20, 20, 20, 20, 20]), (2, 0.6316, 0.6316, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.6316, 0.6316, 3.8, 0.14, [20, 20, 20, 20, 20]), (3, 0.6316, 0.6316, 3.8, 0.14, [20, 20, 20, 20, 20]), (3, 0.6053, 0.6053, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.6053, 0.6053, 3.0, 0.02, [20, 20, 20, 20, 20]), (2, 0.6053, 0.6053, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.5789, 0.5789, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 3: 17.6 s, [(4, 0.6842, 0.6842, 1.9, 0.07, [20, 20, 20, 20, 20]), (4, 0.6842, 0.6842, 3.4, 0.05, [20, 20, 20, 20, 20]), (4, 0.6842, 0.6842, 1.9, 0.07, [20, 20, 20, 20, 20]), (4, 0.6842, 0.6842, 3.4, 0.05, [20, 20, 20, 20, 20]), (3, 0.6842, 0.6842, 3.5, 0.1, [20, 20, 20, 20, 20]), (4, 0.6579, 0.6579, 3.0, 0.14, [20, 20, 20, 20, 20]), (3, 0.6579, 0.6579, 3.0, 0.1, [20, 20, 20, 20, 20]), (4, 0.6316, 0.6316, 3.5, 0.1, [20, 20, 20, 20, 20]), (3, 0.6316, 0.6316, 3.6, 0.15, [20, 20, 20, 20, 20]), (3, 0.6316, 0.6316, 3.6, 0.15, [20, 20, 20, 20, 20]), (3, 0.6316, 0.6316, 4.1, 0.17, [20, 20, 20, 20, 20])]\n",
      "Generation 4: 19.0 s, [(5, 0.7368, 0.7368, 3.5, 0.1, [20, 20, 20, 20, 20]), (5, 0.7368, 0.7368, 3.5, 0.1, [20, 20, 20, 20, 20]), (5, 0.6842, 0.6842, 2.4, 0.12, [20, 20, 20, 20, 20]), (5, 0.6842, 0.6842, 3.6, 0.16, [20, 20, 20, 20, 20]), (5, 0.6842, 0.6842, 3.6, 0.16, [20, 20, 20, 20, 20]), (5, 0.6842, 0.6842, 2.4, 0.12, [20, 20, 20, 20, 20]), (4, 0.6842, 0.6842, 1.9, 0.07, [20, 20, 20, 20, 20]), (5, 0.6579, 0.6579, 1.9, 0.07, [20, 20, 20, 20, 20]), (4, 0.6579, 0.6579, 3.0, 0.1, [20, 20, 20, 20, 20]), (5, 0.6316, 0.6316, 3.0, 0.14, [20, 20, 20, 20, 20]), (5, 0.6316, 0.6316, 3.1, 0.18, [20, 20, 20, 20, 20])]\n",
      "Generation 5: 20.2 s, [(6, 0.7368, 0.7368, 2.7, 0.14, [20, 20, 20, 20, 20]), (6, 0.7368, 0.7368, 3.6, 0.16, [20, 20, 20, 20, 20]), (6, 0.7368, 0.7368, 3.9, 0.33, [20, 20, 20, 20, 20]), (6, 0.7368, 0.7368, 3.5, 0.1, [20, 20, 20, 20, 20]), (6, 0.7368, 0.7368, 3.6, 0.16, [20, 20, 20, 20, 20]), (5, 0.7368, 0.7368, 3.5, 0.1, [20, 20, 20, 20, 20]), (6, 0.7105, 0.7105, 3.0, 0.14, [20, 20, 20, 20, 20]), (6, 0.7105, 0.7105, 3.3, 0.05, [20, 20, 20, 20, 20]), (6, 0.7105, 0.7105, 3.3, 0.05, [20, 20, 20, 20, 20]), (5, 0.6842, 0.6842, 3.0, 0.1, [20, 20, 20, 20, 20]), (5, 0.6842, 0.6842, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 6: 21.7 s, [(6, 0.7632, 0.7632, 3.5, 0.1, [20, 20, 20, 20, 20]), (6, 0.7632, 0.7632, 3.5, 0.1, [20, 20, 20, 20, 20]), (7, 0.7632, 0.7632, 3.5, 0.1, [20, 20, 20, 20, 20]), (6, 0.7368, 0.7368, 2.8, 0.04, [20, 20, 20, 20, 20]), (7, 0.7368, 0.7368, 2.6, 0.15, [20, 20, 20, 20, 20]), (7, 0.7368, 0.7368, 4.2, 0.16, [20, 20, 20, 23, 20]), (7, 0.7368, 0.7368, 4.2, 0.16, [20, 20, 20, 23, 20]), (6, 0.7368, 0.7368, 2.8, 0.04, [20, 20, 20, 20, 20]), (7, 0.7368, 0.7368, 4.2, 0.16, [20, 20, 20, 23, 20]), (7, 0.7368, 0.7368, 3.9, 0.33, [20, 20, 20, 20, 20]), (6, 0.7368, 0.7368, 2.7, 0.14, [20, 20, 20, 20, 20])]\n",
      "Generation 7: 22.8 s, [(8, 0.7895, 0.7895, 3.9, 0.33, [20, 20, 20, 20, 20]), (8, 0.7895, 0.7895, 2.6, 0.15, [20, 20, 20, 20, 20]), (7, 0.7895, 0.7895, 3.5, 0.1, [20, 20, 20, 20, 20]), (8, 0.7895, 0.7895, 3.9, 0.33, [20, 20, 20, 20, 20]), (7, 0.7895, 0.7895, 3.4, 0.19, [20, 20, 20, 20, 20]), (8, 0.7895, 0.7895, 2.6, 0.15, [20, 20, 20, 20, 20]), (8, 0.7895, 0.7895, 2.6, 0.15, [20, 20, 20, 20, 20]), (8, 0.7895, 0.7895, 3.9, 0.33, [20, 20, 20, 20, 20]), (8, 0.7632, 0.7632, 3.6, 0.08, [20, 20, 20, 20, 20]), (6, 0.7632, 0.7632, 3.5, 0.1, [20, 20, 20, 20, 20]), (8, 0.7368, 0.7368, 3.3, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 8: 24.4 s, [(9, 0.8158, 0.8158, 2.6, 0.15, [20, 20, 20, 20, 20]), (9, 0.8158, 0.8158, 3.9, 0.33, [20, 20, 20, 20, 20]), (9, 0.7895, 0.7895, 3.0, 0.11, [20, 20, 20, 20, 20]), (8, 0.7895, 0.7895, 3.4, 0.19, [20, 20, 20, 20, 20]), (8, 0.7895, 0.7895, 2.0, 0.2, [20, 20, 20, 20, 20]), (9, 0.7895, 0.7895, 3.0, 0.11, [20, 20, 20, 20, 20]), (8, 0.7895, 0.7895, 3.4, 0.19, [20, 20, 20, 20, 20]), (9, 0.7895, 0.7895, 2.6, 0.15, [20, 20, 20, 20, 20]), (8, 0.7895, 0.7895, 3.9, 0.33, [20, 20, 20, 20, 20]), (8, 0.7632, 0.7632, 4.1, 0.24, [20, 20, 20, 28, 20]), (9, 0.7368, 0.7368, 3.6, 0.08, [20, 20, 20, 20, 20])]\n",
      "Generation 9: 25.3 s, [(10, 0.8158, 0.8158, 1.8, 0.23, [20, 20, 20, 20, 20]), (10, 0.8158, 0.8158, 3.0, 0.11, [20, 20, 20, 20, 20]), (9, 0.8158, 0.8158, 2.6, 0.15, [20, 20, 20, 20, 20]), (10, 0.7895, 0.7895, 3.0, 0.16, [20, 20, 20, 20, 20]), (10, 0.7895, 0.7895, 3.0, 0.11, [20, 20, 20, 20, 20]), (10, 0.7895, 0.7895, 3.0, 0.11, [20, 20, 20, 20, 20]), (9, 0.7895, 0.7895, 3.8, 0.18, [20, 20, 20, 20, 20]), (9, 0.7895, 0.7895, 3.8, 0.18, [20, 20, 20, 20, 20]), (10, 0.7632, 0.7632, 3.9, 0.33, [20, 20, 20, 20, 20]), (10, 0.7632, 0.7632, 4.1, 0.23, [20, 20, 20, 25, 20]), (9, 0.7632, 0.7632, 3.2, 0.13, [20, 20, 20, 20, 20])]\n",
      "Generation 10: 27.7 s, [(10, 0.8158, 0.8158, 3.2, 0.13, [20, 20, 20, 20, 20]), (10, 0.8158, 0.8158, 1.8, 0.23, [20, 20, 20, 20, 20]), (10, 0.7895, 0.7895, 3.8, 0.18, [20, 20, 20, 20, 20]), (11, 0.8421, 0.7857, 1.8, 0.23, [20, 20, 20, 20, 20]), (11, 0.8421, 0.7857, 1.8, 0.23, [20, 20, 20, 20, 20]), (10, 0.7368, 0.7368, 3.8, 0.18, [20, 20, 20, 20, 20]), (10, 0.7368, 0.7368, 3.7, 0.11, [20, 20, 20, 20, 20]), (10, 0.7368, 0.7368, 3.7, 0.11, [20, 20, 20, 20, 20]), (10, 0.7368, 0.7368, 2.6, 0.15, [20, 20, 20, 20, 20]), (11, 0.7632, 0.7121, 3.0, 0.11, [20, 20, 20, 20, 20]), (11, 0.7632, 0.7121, 2.7, 0.08, [20, 20, 20, 20, 20])]\n",
      "Generation 11: 28.9 s, [(10, 0.8158, 0.8158, 3.2, 0.13, [20, 20, 20, 20, 20]), (11, 0.8421, 0.7857, 1.8, 0.23, [20, 20, 20, 20, 20]), (11, 0.8421, 0.7857, 2.6, 0.12, [20, 20, 20, 20, 20]), (11, 0.8158, 0.7612, 2.6, 0.15, [20, 20, 20, 20, 20]), (11, 0.8158, 0.7612, 2.6, 0.15, [20, 20, 20, 20, 20]), (11, 0.7895, 0.7366, 2.3, 0.18, [20, 20, 20, 20, 20]), (11, 0.7895, 0.7366, 2.3, 0.18, [20, 20, 20, 20, 20]), (11, 0.7895, 0.7366, 3.8, 0.18, [20, 20, 20, 20, 20]), (11, 0.7895, 0.7366, 2.9, 0.2, [20, 20, 20, 20, 20]), (12, 0.8421, 0.7331, 1.8, 0.23, [20, 20, 20, 20, 20]), (11, 0.7368, 0.6875, 3.7, 0.11, [20, 20, 20, 20, 20])]\n",
      "Generation 12: 30.1 s, [(10, 0.8158, 0.8158, 3.2, 0.13, [20, 20, 20, 20, 20]), (11, 0.8158, 0.7612, 3.2, 0.13, [20, 20, 20, 20, 20]), (12, 0.8421, 0.7331, 2.5, 0.19, [20, 20, 20, 20, 20]), (12, 0.8421, 0.7331, 2.5, 0.19, [20, 20, 20, 20, 20]), (12, 0.8421, 0.7331, 2.5, 0.19, [20, 20, 20, 20, 20]), (12, 0.8158, 0.7102, 1.8, 0.23, [20, 20, 20, 20, 20]), (12, 0.8158, 0.7102, 2.6, 0.2, [20, 20, 20, 20, 20]), (12, 0.8158, 0.7102, 2.3, 0.18, [20, 20, 20, 20, 20]), (12, 0.8158, 0.7102, 2.6, 0.2, [20, 20, 20, 20, 20]), (12, 0.8158, 0.7102, 2.6, 0.2, [20, 20, 20, 20, 20]), (12, 0.7895, 0.6873, 3.8, 0.18, [20, 20, 20, 20, 20])]\n",
      "Generation 13: 32.8 s, [(10, 0.8158, 0.8158, 3.2, 0.13, [20, 20, 20, 20, 20]), (11, 0.7895, 0.7366, 2.7, 0.19, [20, 20, 20, 20, 20]), (13, 0.8421, 0.684, 2.5, 0.19, [20, 20, 20, 20, 20]), (13, 0.8421, 0.684, 2.4, 0.16, [20, 20, 20, 20, 20]), (11, 0.7105, 0.6629, 3.2, 0.13, [20, 20, 20, 20, 20]), (13, 0.8158, 0.6626, 2.5, 0.19, [20, 20, 20, 20, 20]), (13, 0.8158, 0.6626, 2.5, 0.19, [20, 20, 20, 20, 20]), (13, 0.8158, 0.6626, 2.0, 0.23, [20, 20, 20, 20, 20]), (13, 0.7632, 0.6199, 2.7, 0.13, [20, 20, 20, 20, 20]), (13, 0.7632, 0.6199, 2.6, 0.2, [20, 20, 20, 20, 20]), (13, 0.7632, 0.6199, 1.8, 0.23, [20, 20, 20, 20, 20])]\n",
      "Generation 14: 32.5 s, [(10, 0.8158, 0.8158, 3.2, 0.13, [20, 20, 20, 20, 20]), (11, 0.7895, 0.7366, 2.5, 0.16, [20, 20, 20, 20, 20]), (11, 0.7632, 0.7121, 3.2, 0.13, [20, 20, 20, 20, 20]), (12, 0.8158, 0.7102, 3.2, 0.13, [20, 20, 20, 20, 20]), (12, 0.8158, 0.7102, 1.9, 0.14, [20, 20, 20, 20, 20]), (12, 0.8158, 0.7102, 1.9, 0.14, [20, 20, 20, 20, 20]), (12, 0.7632, 0.6644, 2.7, 0.19, [20, 20, 20, 20, 20]), (12, 0.7632, 0.6644, 2.7, 0.19, [20, 20, 20, 20, 20]), (12, 0.7632, 0.6644, 2.7, 0.19, [20, 20, 20, 20, 20]), (14, 0.8158, 0.6183, 2.5, 0.14, [20, 20, 20, 20, 20]), (14, 0.7895, 0.5983, 1.1, 0.17, [20, 20, 20, 20, 20])]\n",
      "Generation 15: 34.1 s, [(10, 0.8158, 0.8158, 3.2, 0.13, [20, 20, 20, 20, 20]), (11, 0.8158, 0.7612, 3.2, 0.13, [20, 20, 20, 20, 20]), (11, 0.7632, 0.7121, 2.0, 0.15, [20, 20, 20, 20, 20]), (11, 0.7632, 0.7121, 2.0, 0.15, [20, 20, 20, 20, 20]), (12, 0.7895, 0.6873, 3.2, 0.13, [20, 20, 20, 20, 20]), (13, 0.8421, 0.684, 1.9, 0.21, [20, 20, 20, 20, 20]), (13, 0.8421, 0.684, 1.9, 0.21, [20, 20, 20, 20, 20]), (12, 0.7632, 0.6644, 2.9, 0.15, [20, 20, 20, 20, 20]), (13, 0.7895, 0.6413, 1.9, 0.14, [20, 20, 20, 20, 20]), (13, 0.7895, 0.6413, 2.7, 0.19, [20, 20, 20, 20, 20]), (13, 0.7632, 0.6199, 2.5, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 16: 35.0 s, [(10, 0.8158, 0.8158, 3.2, 0.13, [20, 20, 20, 20, 20]), (11, 0.8421, 0.7857, 3.0, 0.13, [20, 20, 20, 20, 20]), (11, 0.7895, 0.7366, 3.2, 0.13, [20, 20, 20, 20, 20]), (11, 0.7895, 0.7366, 3.2, 0.13, [20, 20, 20, 20, 20]), (12, 0.8421, 0.7331, 2.2, 0.21, [20, 20, 20, 20, 20]), (12, 0.8421, 0.7331, 2.2, 0.21, [20, 20, 20, 20, 20]), (12, 0.8421, 0.7331, 3.2, 0.13, [20, 20, 20, 20, 20]), (12, 0.8421, 0.7331, 2.2, 0.21, [20, 20, 20, 20, 20]), (12, 0.8158, 0.7102, 2.0, 0.15, [20, 20, 20, 20, 20]), (12, 0.8158, 0.7102, 2.5, 0.13, [20, 20, 20, 20, 20]), (13, 0.7632, 0.6199, 2.8, 0.13, [20, 20, 20, 20, 20])]\n",
      "Generation 17: 36.1 s, [(10, 0.8158, 0.8158, 3.2, 0.13, [20, 20, 20, 20, 20]), (11, 0.7895, 0.7366, 2.8, 0.13, [20, 20, 20, 20, 20]), (11, 0.7632, 0.7121, 3.2, 0.13, [20, 20, 20, 20, 20]), (12, 0.7895, 0.6873, 3.0, 0.13, [20, 20, 20, 20, 20]), (12, 0.7895, 0.6873, 2.0, 0.11, [20, 20, 20, 20, 20]), (13, 0.8421, 0.684, 3.7, 0.21, [20, 20, 20, 20, 20]), (12, 0.7632, 0.6644, 3.0, 0.16, [20, 20, 20, 20, 20]), (12, 0.7632, 0.6644, 2.9, 0.18, [20, 20, 20, 20, 20]), (13, 0.8158, 0.6626, 2.1, 0.21, [20, 20, 20, 20, 20]), (13, 0.8158, 0.6626, 2.2, 0.21, [20, 20, 20, 20, 20]), (13, 0.8158, 0.6626, 2.5, 0.13, [20, 20, 20, 20, 20])]\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "evolution(x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test),\n",
    "          batch_size=32, layer_sizes=[20, 20, 20, 20, 20], output_neurons=10, learning_rate=0.0004, n_parents=5, strategy=[0.5, 0.05], \n",
    "          population_size=10, n_generations=50, tournament_size=3, n_introduced=2, age_penalty_period=10, use_static_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: 12.9 s, [(1, 0.4737, 0.4737, 3.8, 0.17, [20, 21, 21, 38, 20]), (1, 0.4737, 0.4737, 3.8, 0.17, [20, 21, 21, 38, 20]), (1, 0.4737, 0.4737, 3.8, 0.17, [20, 21, 21, 38, 20]), (1, 0.4737, 0.4737, 3.8, 0.17, [20, 21, 21, 38, 20]), (1, 0.4211, 0.4211, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.4211, 0.4211, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.4211, 0.4211, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.4211, 0.4211, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.3684, 0.3684, 2.8, 0.08, [20, 20, 20, 20, 20]), (1, 0.3421, 0.3421, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 1: 13.9 s, [(2, 0.5789, 0.5789, 3.8, 0.17, [20, 20, 20, 38, 20]), (2, 0.5789, 0.5789, 3.2, 0.08, [20, 20, 20, 30, 20]), (2, 0.5526, 0.5526, 2.8, 0.08, [20, 20, 20, 20, 20]), (2, 0.5526, 0.5526, 2.8, 0.08, [20, 20, 20, 20, 20]), (2, 0.5526, 0.5526, 2.8, 0.08, [20, 20, 20, 20, 20]), (2, 0.5526, 0.5526, 2.6, 0.11, [20, 20, 20, 20, 20]), (2, 0.5526, 0.5526, 2.6, 0.11, [20, 20, 20, 20, 20]), (2, 0.5263, 0.5263, 3.4, 0.17, [20, 20, 20, 20, 20]), (2, 0.5263, 0.5263, 3.4, 0.17, [20, 20, 20, 20, 20]), (2, 0.4737, 0.4737, 4.1, 0.15, [20, 21, 21, 38, 20]), (1, 0.4737, 0.4737, 3.8, 0.17, [20, 21, 21, 38, 20])]\n",
      "Generation 2: 15.2 s, [(3, 0.6579, 0.6579, 3.4, 0.17, [20, 20, 20, 20, 20]), (3, 0.6579, 0.6579, 3.1, 0.17, [20, 20, 20, 20, 20]), (3, 0.6579, 0.6579, 2.8, 0.08, [20, 20, 20, 20, 20]), (3, 0.6579, 0.6579, 2.6, 0.11, [20, 20, 20, 20, 20]), (3, 0.6579, 0.6579, 2.8, 0.08, [20, 20, 20, 20, 20]), (3, 0.6579, 0.6579, 2.8, 0.08, [20, 20, 20, 20, 20]), (3, 0.6316, 0.6316, 2.6, 0.11, [20, 20, 20, 20, 20]), (2, 0.6316, 0.6316, 3.4, 0.13, [20, 20, 20, 35, 20]), (2, 0.5789, 0.5789, 3.8, 0.17, [20, 20, 20, 38, 20]), (3, 0.5526, 0.5526, 2.8, 0.08, [20, 20, 20, 20, 20]), (3, 0.5526, 0.5526, 3.3, 0.18, [20, 20, 20, 20, 20])]\n",
      "Generation 3: 14.6 s, [(4, 0.7368, 0.7368, 3.0, -0.03, [20, 20, 20, 20, 20]), (4, 0.7368, 0.7368, 3.4, 0.17, [20, 20, 20, 20, 20]), (4, 0.7105, 0.7105, 2.8, 0.08, [20, 20, 20, 20, 20]), (4, 0.6842, 0.6842, 3.8, 0.08, [20, 20, 20, 20, 20]), (4, 0.6579, 0.6579, 3.2, 0.08, [20, 20, 20, 20, 20]), (4, 0.6579, 0.6579, 2.8, 0.08, [20, 20, 20, 20, 20]), (4, 0.6579, 0.6579, 3.1, 0.17, [20, 20, 20, 20, 20]), (4, 0.6579, 0.6579, 3.1, 0.17, [20, 20, 20, 20, 20]), (3, 0.6579, 0.6579, 3.4, 0.17, [20, 20, 20, 20, 20]), (4, 0.6316, 0.6316, 2.9, 0.1, [20, 20, 20, 20, 20]), (3, 0.6316, 0.6316, 3.4, 0.13, [20, 20, 20, 35, 20])]\n",
      "Generation 4: 14.6 s, [(5, 0.7368, 0.7368, 3.0, -0.03, [20, 20, 20, 20, 20]), (5, 0.7368, 0.7368, 3.0, -0.03, [20, 20, 20, 20, 20]), (4, 0.7368, 0.7368, 3.0, -0.03, [20, 20, 20, 20, 20]), (5, 0.7105, 0.7105, 3.8, 0.06, [20, 20, 20, 20, 20]), (5, 0.7105, 0.7105, 2.7, 0.11, [20, 20, 20, 20, 20]), (5, 0.7105, 0.7105, 2.7, 0.11, [20, 20, 20, 20, 20]), (5, 0.6842, 0.6842, 2.9, 0.1, [20, 20, 20, 20, 20]), (5, 0.6842, 0.6842, 4.0, 0.21, [20, 20, 20, 20, 20]), (5, 0.6842, 0.6842, 3.1, 0.17, [20, 20, 20, 20, 20]), (5, 0.6842, 0.6842, 4.0, 0.21, [20, 20, 20, 20, 20]), (5, 0.6579, 0.6579, 3.4, 0.06, [20, 20, 20, 20, 20])]\n",
      "Generation 5: 15.1 s, [(6, 0.7368, 0.7368, 3.4, 0.06, [20, 20, 20, 20, 20]), (6, 0.7368, 0.7368, 2.4, 0.01, [20, 20, 20, 20, 20]), (6, 0.7368, 0.7368, 3.4, 0.06, [20, 20, 20, 20, 20]), (5, 0.7368, 0.7368, 3.0, -0.03, [20, 20, 20, 20, 20]), (6, 0.7105, 0.7105, 2.6, 0.01, [20, 20, 20, 20, 20]), (6, 0.7105, 0.7105, 2.6, 0.01, [20, 20, 20, 20, 20]), (6, 0.7105, 0.7105, 4.0, 0.21, [20, 20, 20, 20, 20]), (6, 0.6842, 0.6842, 2.9, 0.2, [20, 20, 20, 20, 20]), (6, 0.6842, 0.6842, 2.9, 0.1, [20, 20, 20, 20, 20]), (6, 0.6842, 0.6842, 3.0, -0.03, [20, 20, 20, 20, 20]), (5, 0.6842, 0.6842, 3.3, 0.11, [20, 20, 20, 20, 20])]\n",
      "Generation 6: 14.8 s, [(7, 0.7895, 0.7895, 2.9, 0.2, [20, 20, 20, 20, 20]), (7, 0.7895, 0.7895, 2.9, 0.2, [20, 20, 20, 20, 20]), (7, 0.7632, 0.7632, 3.7, 0.04, [20, 20, 20, 20, 20]), (7, 0.7632, 0.7632, 3.5, 0.15, [20, 20, 20, 20, 20]), (7, 0.7632, 0.7632, 3.2, 0.11, [20, 20, 20, 20, 20]), (7, 0.7632, 0.7632, 3.5, 0.15, [20, 20, 20, 20, 20]), (6, 0.7368, 0.7368, 3.4, 0.06, [20, 20, 20, 20, 20]), (6, 0.7105, 0.7105, 3.0, -0.01, [20, 20, 20, 20, 20]), (7, 0.7105, 0.7105, 3.0, 0.07, [20, 20, 20, 20, 20]), (7, 0.7105, 0.7105, 3.0, 0.07, [20, 20, 20, 20, 20]), (7, 0.6842, 0.6842, 2.6, 0.01, [20, 20, 20, 20, 20])]\n",
      "Generation 7: 15.5 s, [(8, 0.7895, 0.7895, 2.4, 0.01, [20, 20, 20, 20, 20]), (8, 0.7895, 0.7895, 2.4, 0.01, [20, 20, 20, 20, 20]), (8, 0.7895, 0.7895, 2.6, 0.07, [20, 20, 20, 20, 20]), (7, 0.7895, 0.7895, 2.9, 0.2, [20, 20, 20, 20, 20]), (8, 0.7632, 0.7632, 3.5, 0.15, [20, 20, 20, 20, 20]), (8, 0.7632, 0.7632, 3.5, 0.15, [20, 20, 20, 20, 20]), (8, 0.7632, 0.7632, 2.9, 0.2, [20, 20, 20, 20, 20]), (8, 0.7368, 0.7368, 3.0, 0.07, [20, 20, 20, 20, 20]), (8, 0.7368, 0.7368, 3.5, 0.15, [20, 20, 20, 20, 20]), (8, 0.7368, 0.7368, 3.0, 0.07, [20, 20, 20, 20, 20]), (7, 0.7105, 0.7105, 3.0, -0.01, [20, 20, 20, 20, 20])]\n",
      "Generation 8: 15.5 s, [(9, 0.8158, 0.8158, 3.0, 0.07, [20, 20, 20, 20, 20]), (9, 0.8158, 0.8158, 3.0, 0.07, [20, 20, 20, 20, 20]), (9, 0.8158, 0.8158, 3.0, 0.07, [20, 20, 20, 20, 20]), (9, 0.8158, 0.8158, 3.0, 0.07, [20, 20, 20, 20, 20]), (9, 0.8158, 0.8158, 3.8, 0.12, [20, 20, 20, 20, 20]), (9, 0.7895, 0.7895, 2.8, 0.15, [20, 20, 20, 20, 20]), (8, 0.7895, 0.7895, 2.4, 0.01, [20, 20, 20, 20, 20]), (9, 0.7632, 0.7632, 2.4, 0.01, [20, 20, 20, 20, 20]), (9, 0.7632, 0.7632, 3.5, 0.15, [20, 20, 20, 20, 20]), (9, 0.7368, 0.7368, 2.4, 0.01, [20, 20, 20, 20, 20]), (9, 0.6842, 0.6842, 2.3, 0.04, [20, 20, 20, 20, 20])]\n",
      "Generation 9: 15.7 s, [(9, 0.8158, 0.8158, 3.0, 0.07, [20, 20, 20, 20, 20]), (10, 0.7895, 0.7895, 2.4, 0.01, [20, 20, 20, 20, 20]), (10, 0.7895, 0.7895, 3.5, -0.03, [20, 20, 20, 20, 20]), (10, 0.7895, 0.7895, 3.5, 0.15, [20, 20, 20, 20, 20]), (10, 0.7895, 0.7895, 3.5, 0.15, [20, 20, 20, 20, 20]), (10, 0.7632, 0.7632, 3.8, 0.12, [20, 20, 20, 20, 20]), (10, 0.7632, 0.7632, 2.8, 0.15, [20, 20, 20, 20, 20]), (10, 0.7632, 0.7632, 2.8, 0.15, [20, 20, 20, 20, 20]), (10, 0.7632, 0.7632, 2.8, 0.15, [20, 20, 20, 20, 20]), (10, 0.7105, 0.7105, 3.4, 0.05, [20, 20, 20, 20, 20]), (10, 0.7105, 0.7105, 3.0, 0.07, [20, 20, 20, 20, 20])]\n",
      "Generation 10: 15.9 s, [(9, 0.8158, 0.8158, 3.0, 0.07, [20, 20, 20, 20, 20]), (10, 0.7895, 0.7895, 3.3, 0.2, [20, 20, 20, 20, 20]), (11, 0.8158, 0.7612, 3.8, 0.12, [20, 20, 20, 22, 20]), (11, 0.8158, 0.7612, 2.5, 0.01, [20, 20, 20, 20, 20]), (11, 0.8158, 0.7612, 3.0, 0.08, [20, 20, 20, 20, 20]), (11, 0.8158, 0.7612, 2.5, 0.01, [20, 20, 20, 20, 20]), (11, 0.8158, 0.7612, 3.0, 0.08, [20, 20, 20, 20, 20]), (11, 0.7895, 0.7366, 3.5, -0.03, [20, 20, 20, 20, 20]), (11, 0.7895, 0.7366, 3.5, -0.03, [20, 20, 20, 20, 20]), (11, 0.7895, 0.7366, 3.5, -0.03, [20, 20, 20, 20, 20]), (11, 0.7368, 0.6875, 2.9, 0.11, [20, 20, 20, 20, 20])]\n",
      "Generation 11: 15.9 s, [(9, 0.8158, 0.8158, 3.0, 0.07, [20, 20, 20, 20, 20]), (10, 0.7632, 0.7632, 2.5, 0.1, [20, 20, 20, 20, 20]), (10, 0.7368, 0.7368, 3.0, 0.07, [20, 20, 20, 20, 20]), (10, 0.7368, 0.7368, 3.0, 0.07, [20, 20, 20, 20, 20]), (10, 0.7368, 0.7368, 3.0, 0.07, [20, 20, 20, 20, 20]), (12, 0.8158, 0.7102, 3.5, -0.03, [20, 20, 20, 20, 20]), (12, 0.7895, 0.6873, 3.0, 0.08, [20, 20, 20, 20, 20]), (12, 0.7895, 0.6873, 2.2, 0.01, [20, 20, 20, 20, 20]), (12, 0.7895, 0.6873, 2.2, 0.01, [20, 20, 20, 20, 20]), (12, 0.7895, 0.6873, 2.2, 0.01, [20, 20, 20, 20, 20]), (12, 0.7632, 0.6644, 3.5, -0.03, [20, 20, 20, 20, 20])]\n",
      "Generation 12: 15.8 s, [(9, 0.8158, 0.8158, 3.0, 0.07, [20, 20, 20, 20, 20]), (10, 0.7632, 0.7632, 2.9, -0.06, [20, 20, 20, 20, 20]), (10, 0.7632, 0.7632, 2.9, -0.06, [20, 20, 20, 20, 20]), (11, 0.7895, 0.7366, 3.0, 0.07, [20, 20, 20, 20, 20]), (11, 0.7895, 0.7366, 3.0, 0.07, [20, 20, 20, 20, 20]), (10, 0.7105, 0.7105, 3.0, 0.07, [20, 20, 20, 20, 20]), (11, 0.7368, 0.6875, 2.9, 0.06, [20, 20, 20, 20, 20]), (11, 0.7368, 0.6875, 2.8, 0.0, [20, 20, 20, 20, 20]), (11, 0.7368, 0.6875, 2.9, 0.06, [20, 20, 20, 20, 20]), (11, 0.7368, 0.6875, 2.9, 0.06, [20, 20, 20, 20, 20]), (13, 0.7895, 0.6413, 2.8, -0.05, [20, 20, 20, 20, 20])]\n",
      "Generation 13: 15.6 s, [(9, 0.8158, 0.8158, 3.0, 0.07, [20, 20, 20, 20, 20]), (10, 0.7895, 0.7895, 3.0, 0.07, [20, 20, 20, 20, 20]), (10, 0.7632, 0.7632, 2.8, 0.09, [20, 20, 20, 20, 20]), (11, 0.7632, 0.7121, 3.0, -0.01, [20, 20, 20, 20, 20]), (12, 0.8158, 0.7102, 2.3, -0.01, [20, 20, 20, 20, 20]), (11, 0.7368, 0.6875, 2.9, -0.06, [20, 20, 20, 20, 20]), (11, 0.7368, 0.6875, 3.0, 0.05, [20, 20, 20, 20, 20]), (11, 0.7368, 0.6875, 2.7, 0.11, [20, 20, 20, 20, 20]), (12, 0.7632, 0.6644, 3.0, 0.07, [20, 20, 20, 20, 20]), (12, 0.7632, 0.6644, 3.3, -0.05, [20, 20, 20, 20, 20]), (14, 0.7895, 0.5983, 2.8, 0.05, [20, 20, 20, 20, 20])]\n",
      "Generation 14: 16.0 s, [(9, 0.8158, 0.8158, 3.0, 0.07, [20, 20, 20, 20, 20]), (10, 0.7632, 0.7632, 2.3, 0.04, [20, 20, 20, 20, 20]), (10, 0.7632, 0.7632, 2.3, 0.04, [20, 20, 20, 20, 20]), (11, 0.7632, 0.7121, 3.1, 0.05, [20, 20, 20, 20, 20]), (11, 0.7632, 0.7121, 3.8, 0.02, [20, 20, 20, 20, 20]), (12, 0.7895, 0.6873, 2.7, 0.11, [20, 20, 20, 20, 20]), (10, 0.6842, 0.6842, 3.0, 0.07, [20, 20, 20, 20, 20]), (12, 0.7632, 0.6644, 3.8, 0.16, [20, 20, 20, 20, 20]), (13, 0.7895, 0.6413, 3.3, -0.05, [20, 20, 20, 20, 20]), (13, 0.7632, 0.6199, 2.5, -0.06, [20, 20, 20, 20, 20]), (13, 0.7368, 0.5985, 2.8, 0.02, [20, 20, 20, 20, 20])]\n",
      "Generation 15: 15.9 s, [(9, 0.8158, 0.8158, 3.0, 0.07, [20, 20, 20, 20, 20]), (11, 0.7632, 0.7121, 3.0, 0.03, [20, 20, 20, 20, 20]), (11, 0.7632, 0.7121, 3.0, 0.03, [20, 20, 20, 20, 20]), (10, 0.7105, 0.7105, 2.1, 0.01, [20, 20, 20, 20, 20]), (11, 0.7368, 0.6875, 4.3, 0.03, [20, 20, 20, 33, 21]), (11, 0.7368, 0.6875, 4.3, 0.03, [20, 20, 20, 33, 21]), (11, 0.7368, 0.6875, 4.3, 0.03, [20, 20, 20, 33, 21]), (11, 0.7368, 0.6875, 3.0, 0.07, [20, 20, 20, 20, 20]), (12, 0.7895, 0.6873, 2.5, 0.1, [20, 20, 20, 20, 20]), (12, 0.7895, 0.6873, 3.8, 0.02, [20, 20, 20, 20, 20]), (11, 0.6842, 0.6384, 2.3, 0.04, [20, 20, 20, 20, 20])]\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "evolution(x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test),\n",
    "          batch_size=32, layer_sizes=[20, 20, 20, 20, 20], output_neurons=10, learning_rate=0.0004, n_parents=5, strategy=[0.5, 0.05], \n",
    "          population_size=10, n_generations=50, tournament_size=3, n_introduced=2, age_penalty_period=10, use_static_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: 12.9 s, best val metric 0.4737, [(1, 0.4737, 0.4737, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.4737, 0.4737, 3.4, 0.16, [20, 20, 20, 20, 20]), (1, 0.4737, 0.4737, 3.4, 0.16, [20, 20, 20, 20, 20]), (1, 0.3947, 0.3947, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.3947, 0.3947, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.3947, 0.3947, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.3684, 0.3684, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.3684, 0.3684, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.3421, 0.3421, 3.3, 0.15, [20, 20, 20, 20, 20]), (1, 0.3421, 0.3421, 3.3, 0.12, [20, 20, 20, 20, 20])]\n",
      "Generation 1: 13.4 s, best val metric 0.5789, [(2, 0.5789, 0.5789, 4.0, 0.05, [20, 20, 20, 20, 20]), (2, 0.5526, 0.5526, 2.9, 0.22, [20, 20, 20, 20, 20]), (2, 0.5526, 0.5526, 3.4, 0.16, [20, 20, 20, 20, 20]), (2, 0.5526, 0.5526, 2.9, 0.22, [20, 20, 20, 20, 20]), (2, 0.5526, 0.5526, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.5526, 0.5526, 2.9, 0.22, [20, 20, 20, 20, 20]), (2, 0.5526, 0.5526, 3.4, 0.16, [20, 20, 20, 20, 20]), (2, 0.5, 0.5, 2.2, 0.1, [20, 20, 20, 20, 20]), (2, 0.4737, 0.4737, 3.3, 0.12, [20, 20, 20, 20, 20]), (1, 0.4737, 0.4737, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.4211, 0.4211, 3.3, 0.15, [20, 20, 20, 20, 20])]\n",
      "Generation 2: 14.1 s, best val metric 0.6053, [(2, 0.6053, 0.6053, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.6053, 0.6053, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.5789, 0.5789, 2.9, 0.22, [20, 20, 20, 20, 20]), (2, 0.5789, 0.5789, 4.0, 0.05, [20, 20, 20, 20, 20]), (3, 0.5526, 0.5526, 3.3, 0.18, [20, 20, 20, 20, 20]), (3, 0.5526, 0.5526, 3.4, 0.13, [20, 20, 20, 20, 20]), (3, 0.5526, 0.5526, 3.8, 0.21, [20, 20, 20, 20, 20]), (3, 0.5526, 0.5526, 3.6, 0.25, [20, 20, 20, 20, 20]), (3, 0.5526, 0.5526, 3.6, 0.25, [20, 20, 20, 20, 20]), (3, 0.5526, 0.5526, 3.6, 0.25, [20, 20, 20, 20, 20]), (3, 0.5263, 0.5263, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 3: 14.4 s, best val metric 0.7105, [(4, 0.7105, 0.7105, 3.8, 0.21, [20, 20, 20, 20, 20]), (4, 0.6842, 0.6842, 4.2, 0.16, [20, 20, 20, 25, 20]), (4, 0.6579, 0.6579, 3.5, 0.18, [20, 20, 20, 20, 20]), (4, 0.6579, 0.6579, 3.5, 0.18, [20, 20, 20, 20, 20]), (4, 0.6579, 0.6579, 3.5, 0.18, [20, 20, 20, 20, 20]), (4, 0.6316, 0.6316, 3.4, 0.2, [20, 20, 20, 20, 20]), (4, 0.6053, 0.6053, 3.1, 0.15, [20, 20, 20, 20, 20]), (3, 0.6053, 0.6053, 3.1, 0.24, [20, 20, 20, 20, 20]), (4, 0.6053, 0.6053, 2.9, 0.22, [20, 20, 20, 20, 20]), (3, 0.6053, 0.6053, 3.0, 0.19, [20, 20, 20, 20, 20]), (2, 0.6053, 0.6053, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 4: 14.8 s, best val metric 0.7368, [(5, 0.7368, 0.7368, 3.6, 0.13, [20, 20, 20, 20, 20]), (5, 0.7368, 0.7368, 3.6, 0.13, [20, 20, 20, 20, 20]), (5, 0.7105, 0.7105, 3.4, 0.26, [20, 20, 20, 20, 20]), (5, 0.7105, 0.7105, 2.9, 0.15, [20, 20, 20, 20, 20]), (5, 0.7105, 0.7105, 3.5, 0.18, [20, 20, 20, 20, 20]), (5, 0.7105, 0.7105, 4.2, 0.16, [20, 20, 20, 26, 20]), (5, 0.7105, 0.7105, 3.5, 0.18, [20, 20, 20, 20, 20]), (4, 0.7105, 0.7105, 3.8, 0.21, [20, 20, 20, 20, 20]), (5, 0.6842, 0.6842, 3.1, 0.23, [20, 20, 20, 20, 20]), (5, 0.6579, 0.6579, 3.1, 0.15, [20, 20, 20, 20, 20]), (5, 0.6316, 0.6316, 2.9, 0.21, [20, 20, 20, 20, 20])]\n",
      "Generation 5: 15.3 s, best val metric 0.7368, [(6, 0.7368, 0.7368, 3.6, 0.13, [20, 20, 20, 20, 20]), (5, 0.7368, 0.7368, 3.6, 0.13, [20, 20, 20, 20, 20]), (6, 0.6842, 0.6842, 2.9, 0.2, [20, 20, 20, 20, 20]), (6, 0.6842, 0.6842, 2.9, 0.13, [20, 20, 20, 20, 20]), (6, 0.6842, 0.6842, 3.5, 0.18, [20, 20, 20, 20, 20]), (6, 0.6842, 0.6842, 4.2, 0.16, [20, 20, 20, 27, 20]), (6, 0.6842, 0.6842, 3.1, 0.23, [20, 20, 20, 20, 20]), (6, 0.6842, 0.6842, 3.0, 0.17, [20, 20, 20, 22, 20]), (6, 0.6842, 0.6842, 3.6, 0.07, [20, 20, 20, 20, 20]), (6, 0.6842, 0.6842, 2.9, 0.13, [20, 20, 20, 20, 20]), (6, 0.6579, 0.6579, 3.9, 0.22, [20, 20, 20, 20, 20])]\n",
      "Generation 6: 15.2 s, best val metric 0.7368, [(7, 0.7368, 0.7368, 3.6, 0.12, [20, 20, 20, 20, 20]), (7, 0.7368, 0.7368, 3.1, 0.23, [20, 20, 20, 20, 20]), (7, 0.7368, 0.7368, 3.1, 0.23, [20, 20, 20, 20, 20]), (7, 0.7368, 0.7368, 4.2, 0.16, [20, 20, 20, 40, 20]), (7, 0.7368, 0.7368, 3.6, 0.12, [20, 20, 20, 20, 20]), (7, 0.7368, 0.7368, 2.7, 0.17, [20, 20, 20, 20, 20]), (7, 0.7368, 0.7368, 3.6, 0.07, [20, 20, 20, 20, 20]), (6, 0.7368, 0.7368, 3.6, 0.13, [20, 20, 20, 20, 20]), (7, 0.7105, 0.7105, 3.1, 0.17, [20, 20, 20, 25, 20]), (7, 0.7105, 0.7105, 3.9, 0.22, [20, 20, 20, 20, 20]), (7, 0.6842, 0.6842, 3.1, 0.17, [20, 20, 20, 20, 20])]\n",
      "Generation 7: 15.1 s, best val metric 0.7895, [(8, 0.7895, 0.7895, 4.0, 0.05, [20, 20, 20, 38, 20]), (8, 0.7895, 0.7895, 4.0, 0.05, [20, 20, 20, 38, 20]), (8, 0.7895, 0.7895, 4.0, 0.05, [20, 20, 20, 38, 20]), (8, 0.7895, 0.7895, 3.3, 0.15, [20, 20, 20, 21, 20]), (8, 0.7895, 0.7895, 3.3, 0.15, [20, 20, 20, 21, 20]), (8, 0.7632, 0.7632, 3.7, 0.16, [20, 20, 20, 20, 20]), (8, 0.7368, 0.7368, 3.9, 0.22, [20, 20, 20, 20, 20]), (8, 0.7368, 0.7368, 3.9, 0.1, [20, 20, 20, 20, 20]), (8, 0.7368, 0.7368, 3.4, 0.18, [20, 20, 20, 20, 20]), (7, 0.7368, 0.7368, 3.6, 0.12, [20, 20, 20, 20, 20]), (8, 0.7105, 0.7105, 3.4, 0.15, [20, 20, 20, 20, 20])]\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "evolution = Evolution()\n",
    "evolution.run(x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test),\n",
    "              batch_size=32, layer_sizes=[20, 20, 20, 20, 20], output_neurons=10, learning_rate=0.0004, n_parents=5, strategy=[0.5, 0.05], \n",
    "              population_size=10, n_generations=50, tournament_size=3, n_introduced=2, age_penalty_period=10, use_static_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc531473430>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 244,
       "width": 371
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [0] + [x[0] for x in evolution.val_metrics]\n",
    "y = [0] + [x[1] for x in evolution.val_metrics]\n",
    "plt.step(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratio 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = get_fashion_mnist_dataset(fraction=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: 41.9 s, best val metric 0.7157, [(1, 0.7157, 0.7157, 3.6, 0.03, [20, 20, 20, 27, 20]), (1, 0.7005, 0.7005, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.7005, 0.7005, 3.4, 0.04, [20, 20, 20, 20, 20]), (1, 0.7005, 0.7005, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6904, 0.6904, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6853, 0.6853, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.665, 0.665, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6599, 0.6599, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6599, 0.6599, 2.6, 0.17, [20, 20, 20, 20, 20]), (1, 0.6497, 0.6497, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 1: 43.7 s, best val metric 0.7817, [(2, 0.7817, 0.7817, 4.2, 0.01, [20, 27, 20, 42, 25]), (2, 0.7817, 0.7817, 4.2, 0.01, [20, 27, 20, 42, 25]), (2, 0.7665, 0.7665, 3.2, 0.02, [20, 20, 20, 20, 20]), (2, 0.7665, 0.7665, 3.2, 0.02, [20, 20, 20, 20, 20]), (2, 0.7665, 0.7665, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7665, 0.7665, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7614, 0.7614, 3.6, 0.03, [20, 20, 20, 27, 20]), (2, 0.7614, 0.7614, 2.8, 0.12, [20, 20, 20, 20, 20]), (2, 0.7563, 0.7563, 3.3, 0.07, [20, 20, 20, 20, 20]), (2, 0.7563, 0.7563, 3.3, 0.07, [20, 20, 20, 20, 20]), (1, 0.7157, 0.7157, 3.6, 0.03, [20, 20, 20, 27, 20])]\n",
      "Generation 2: 48.5 s, best val metric 0.7919, [(3, 0.7919, 0.7919, 3.2, 0.0, [20, 20, 20, 26, 20]), (3, 0.7919, 0.7919, 3.2, 0.0, [20, 20, 20, 26, 20]), (3, 0.7868, 0.7868, 3.6, 0.03, [20, 20, 20, 27, 20]), (3, 0.7817, 0.7817, 4.2, 0.01, [20, 46, 27, 59, 45]), (2, 0.7817, 0.7817, 4.2, 0.01, [20, 27, 20, 42, 25]), (3, 0.7716, 0.7716, 2.8, 0.12, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 3.3, 0.07, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 3.3, 0.07, [20, 20, 20, 20, 20]), (3, 0.7665, 0.7665, 3.9, 0.06, [20, 20, 20, 23, 27]), (3, 0.7665, 0.7665, 3.9, 0.06, [20, 20, 20, 23, 27]), (3, 0.7665, 0.7665, 3.3, 0.07, [20, 20, 20, 20, 20])]\n",
      "Generation 3: 50.9 s, best val metric 0.7919, [(3, 0.7919, 0.7919, 4.2, 0.01, [20, 33, 21, 56, 38]), (4, 0.7919, 0.7919, 3.9, 0.06, [20, 20, 20, 27, 28]), (4, 0.7919, 0.7919, 3.9, 0.06, [20, 20, 20, 27, 28]), (3, 0.7919, 0.7919, 4.2, 0.01, [20, 33, 21, 56, 38]), (3, 0.7919, 0.7919, 3.2, 0.0, [20, 20, 20, 26, 20]), (4, 0.7868, 0.7868, 3.7, 0.03, [20, 20, 20, 21, 26]), (4, 0.7868, 0.7868, 4.2, 0.01, [20, 58, 26, 69, 55]), (4, 0.7868, 0.7868, 3.6, 0.11, [20, 20, 20, 24, 21]), (4, 0.7817, 0.7817, 3.8, 0.12, [20, 36, 20, 42, 33]), (4, 0.7817, 0.7817, 3.8, 0.12, [20, 36, 20, 42, 33]), (4, 0.7716, 0.7716, 2.8, 0.12, [20, 20, 20, 20, 20])]\n",
      "Generation 4: 52.9 s, best val metric 0.8122, [(5, 0.8122, 0.8122, 3.9, 0.06, [20, 21, 20, 36, 38]), (5, 0.8122, 0.8122, 3.9, 0.06, [20, 21, 20, 36, 38]), (5, 0.8122, 0.8122, 3.3, -0.04, [20, 20, 20, 20, 23]), (5, 0.8122, 0.8122, 3.9, 0.06, [20, 21, 20, 36, 38]), (5, 0.8122, 0.8122, 3.3, -0.04, [20, 20, 20, 20, 23]), (5, 0.8122, 0.8122, 3.9, 0.06, [20, 21, 20, 36, 38]), (5, 0.8071, 0.8071, 3.7, 0.03, [20, 20, 20, 22, 26]), (5, 0.8071, 0.8071, 3.8, 0.12, [20, 32, 20, 36, 35]), (5, 0.7919, 0.7919, 4.2, 0.01, [20, 58, 31, 75, 56]), (3, 0.7919, 0.7919, 4.2, 0.01, [20, 33, 21, 56, 38]), (5, 0.7817, 0.7817, 4.3, 0.13, [20, 40, 20, 47, 48])]\n",
      "Generation 5: 54.7 s, best val metric 0.8173, [(6, 0.8173, 0.8173, 3.3, 0.12, [20, 20, 20, 20, 25]), (6, 0.8173, 0.8173, 3.3, 0.12, [20, 20, 20, 20, 25]), (6, 0.8122, 0.8122, 3.9, 0.06, [20, 20, 20, 35, 40]), (5, 0.8122, 0.8122, 3.9, 0.06, [20, 21, 20, 36, 38]), (4, 0.8071, 0.8071, 4.2, 0.01, [20, 37, 23, 68, 54]), (4, 0.8071, 0.8071, 4.2, 0.01, [20, 37, 23, 68, 54]), (6, 0.8071, 0.8071, 3.3, -0.04, [20, 20, 20, 20, 21]), (6, 0.802, 0.802, 3.5, 0.05, [20, 20, 20, 26, 30]), (6, 0.802, 0.802, 3.5, 0.05, [20, 20, 20, 26, 30]), (6, 0.7919, 0.7919, 4.9, -0.07, [40, 41, 40, 56, 58]), (6, 0.7868, 0.7868, 3.0, 0.05, [20, 20, 20, 27, 20])]\n",
      "Generation 6: 53.0 s, best val metric 0.8173, [(6, 0.8173, 0.8173, 3.3, 0.12, [20, 20, 20, 20, 25]), (7, 0.8122, 0.8122, 3.9, -0.0, [20, 22, 20, 37, 37]), (7, 0.8122, 0.8122, 3.9, -0.0, [20, 22, 20, 37, 37]), (7, 0.8122, 0.8122, 3.9, 0.04, [20, 21, 20, 37, 40]), (7, 0.8122, 0.8122, 3.9, -0.0, [20, 22, 20, 37, 37]), (7, 0.8071, 0.8071, 3.4, 0.04, [20, 20, 20, 20, 24]), (7, 0.802, 0.802, 4.9, -0.07, [57, 61, 60, 76, 78]), (7, 0.802, 0.802, 3.3, 0.08, [20, 20, 20, 21, 21]), (7, 0.802, 0.802, 4.9, -0.07, [57, 61, 60, 76, 78]), (5, 0.7919, 0.7919, 3.8, 0.11, [20, 33, 20, 44, 34]), (5, 0.7919, 0.7919, 3.8, 0.11, [20, 33, 20, 44, 34])]\n",
      "Generation 7: 56.4 s, best val metric 0.8274, [(8, 0.8274, 0.8274, 3.6, 0.1, [20, 20, 20, 31, 40]), (8, 0.8173, 0.8173, 3.3, 0.08, [20, 20, 20, 20, 24]), (8, 0.8173, 0.8173, 3.3, 0.08, [20, 20, 20, 20, 24]), (6, 0.8173, 0.8173, 3.3, 0.12, [20, 20, 20, 20, 25]), (8, 0.8071, 0.8071, 4.0, 0.02, [20, 20, 20, 54, 49]), (8, 0.8071, 0.8071, 4.4, 0.02, [52, 81, 69, 96, 91]), (8, 0.8071, 0.8071, 3.9, -0.0, [20, 21, 20, 43, 45]), (8, 0.8071, 0.8071, 3.7, 0.01, [20, 20, 20, 35, 29]), (6, 0.802, 0.802, 2.5, 0.02, [20, 20, 20, 27, 20]), (6, 0.802, 0.802, 2.5, 0.02, [20, 20, 20, 27, 20]), (6, 0.7766, 0.7766, 3.8, 0.11, [20, 26, 20, 29, 35])]\n",
      "Generation 8: 53.6 s, best val metric 0.8274, [(8, 0.8274, 0.8274, 3.6, 0.1, [20, 20, 20, 31, 40]), (9, 0.8173, 0.8173, 3.2, 0.04, [20, 20, 20, 39, 20]), (7, 0.8173, 0.8173, 3.4, -0.01, [20, 20, 20, 20, 25]), (9, 0.8173, 0.8173, 3.2, 0.04, [20, 20, 20, 39, 20]), (9, 0.8173, 0.8173, 4.0, 0.02, [20, 26, 20, 67, 67]), (7, 0.8071, 0.8071, 3.8, 0.11, [20, 25, 20, 28, 37]), (7, 0.8071, 0.8071, 3.6, 0.08, [20, 20, 20, 23, 32]), (9, 0.802, 0.802, 3.6, 0.1, [20, 20, 20, 26, 40]), (9, 0.7716, 0.7716, 2.8, 0.04, [20, 20, 20, 20, 20]), (9, 0.7716, 0.7716, 3.5, -0.04, [20, 20, 20, 20, 32]), (7, 0.7513, 0.7513, 2.5, 0.02, [20, 20, 20, 20, 20])]\n",
      "Generation 9: 49.4 s, best val metric 0.8274, [(8, 0.8274, 0.8274, 3.6, 0.1, [20, 20, 20, 31, 40]), (10, 0.8223, 0.8223, 4.1, 0.11, [20, 39, 22, 46, 60]), (10, 0.8223, 0.8223, 4.1, 0.11, [20, 39, 22, 46, 60]), (10, 0.8173, 0.8173, 3.8, 0.01, [20, 20, 20, 36, 36]), (10, 0.8173, 0.8173, 3.6, 0.1, [20, 20, 20, 23, 43]), (8, 0.8122, 0.8122, 3.4, -0.01, [20, 20, 20, 20, 26]), (10, 0.8071, 0.8071, 4.0, 0.02, [20, 28, 21, 61, 84]), (10, 0.8071, 0.8071, 4.0, 0.02, [20, 28, 21, 61, 84]), (10, 0.8071, 0.8071, 4.0, 0.02, [20, 28, 21, 61, 84]), (10, 0.7868, 0.7868, 3.5, 0.12, [20, 20, 20, 20, 29]), (9, 0.7868, 0.7868, 3.1, 0.01, [20, 20, 20, 20, 26])]\n",
      "Generation 10: 53.4 s, best val metric 0.8325, [(8, 0.8274, 0.8274, 3.6, 0.1, [20, 20, 20, 31, 40]), (9, 0.8223, 0.8223, 3.6, 0.1, [20, 20, 20, 30, 47]), (10, 0.8173, 0.8173, 4.4, 0.05, [20, 40, 40, 40, 46]), (9, 0.8122, 0.8122, 3.0, 0.14, [20, 20, 20, 20, 23]), (9, 0.8122, 0.8122, 3.0, 0.14, [20, 20, 20, 20, 23]), (9, 0.802, 0.802, 3.7, -0.03, [20, 20, 20, 27, 41]), (10, 0.7919, 0.7919, 3.1, 0.01, [20, 20, 20, 20, 25]), (10, 0.7919, 0.7919, 3.1, 0.01, [20, 20, 20, 20, 25]), (11, 0.8325, 0.7767, 3.5, 0.12, [20, 20, 20, 20, 33]), (11, 0.8122, 0.7578, 3.9, 0.02, [20, 21, 20, 38, 61]), (11, 0.8071, 0.7531, 3.6, 0.1, [20, 20, 20, 34, 46])]\n",
      "Generation 11: 53.1 s, best val metric 0.8274, [(8, 0.8274, 0.8274, 3.6, 0.1, [20, 20, 20, 31, 40]), (9, 0.8223, 0.8223, 4.4, 0.13, [28, 40, 40, 51, 60]), (10, 0.8122, 0.8122, 3.1, 0.08, [20, 20, 20, 20, 23]), (10, 0.8122, 0.8122, 3.1, 0.08, [20, 20, 20, 20, 23]), (10, 0.8122, 0.8122, 3.1, 0.08, [20, 20, 20, 20, 23]), (10, 0.8122, 0.8122, 3.1, 0.08, [20, 20, 20, 20, 23]), (10, 0.8122, 0.8122, 3.1, 0.08, [20, 20, 20, 20, 23]), (10, 0.8122, 0.8122, 3.5, 0.06, [20, 20, 20, 29, 33]), (10, 0.8071, 0.8071, 3.9, 0.08, [20, 22, 21, 48, 52]), (10, 0.802, 0.802, 3.7, -0.03, [20, 20, 20, 26, 44]), (10, 0.7919, 0.7919, 3.6, 0.1, [20, 20, 20, 21, 43])]\n",
      "Generation 12: 52.0 s, best val metric 0.8274, [(8, 0.8274, 0.8274, 3.6, 0.1, [20, 20, 20, 31, 40]), (10, 0.802, 0.802, 4.4, 0.13, [37, 60, 60, 71, 80]), (10, 0.802, 0.802, 4.4, 0.13, [37, 60, 60, 71, 80]), (9, 0.797, 0.797, 3.6, 0.1, [20, 20, 20, 24, 47]), (9, 0.7716, 0.7716, 2.9, 0.14, [20, 20, 20, 20, 23]), (9, 0.7716, 0.7716, 2.9, 0.14, [20, 20, 20, 20, 23]), (11, 0.8223, 0.7673, 3.7, -0.03, [20, 20, 20, 22, 44]), (11, 0.8173, 0.7625, 3.6, 0.1, [20, 20, 20, 20, 42]), (11, 0.8122, 0.7578, 3.1, 0.08, [20, 20, 19, 20, 23]), (11, 0.8071, 0.7531, 3.9, 0.08, [20, 34, 20, 54, 70]), (11, 0.7868, 0.7341, 3.1, 0.08, [20, 20, 19, 20, 23])]\n",
      "Generation 13: 54.0 s, best val metric 0.8274, [(8, 0.8274, 0.8274, 3.6, 0.1, [20, 20, 20, 31, 40]), (10, 0.797, 0.797, 4.0, 0.19, [20, 29, 21, 43, 63]), (10, 0.797, 0.797, 4.0, 0.19, [20, 29, 21, 43, 63]), (10, 0.797, 0.797, 4.0, 0.19, [20, 29, 21, 43, 63]), (10, 0.7919, 0.7919, 3.6, 0.1, [20, 20, 20, 23, 49]), (10, 0.7919, 0.7919, 3.6, 0.1, [20, 20, 20, 23, 49]), (9, 0.7817, 0.7817, 3.9, 0.09, [20, 20, 20, 35, 53]), (10, 0.7665, 0.7665, 2.9, 0.14, [20, 20, 19, 20, 21]), (11, 0.797, 0.7436, 3.7, 0.03, [20, 31, 21, 60, 55]), (12, 0.8071, 0.7026, 4.1, 0.08, [20, 35, 27, 42, 63]), (1, 0.6954, 0.6954, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 14: 54.5 s, best val metric 0.8274, [(8, 0.8274, 0.8274, 3.6, 0.1, [20, 20, 20, 31, 40]), (9, 0.8122, 0.8122, 3.6, 0.1, [20, 20, 20, 27, 40]), (10, 0.8122, 0.8122, 3.9, 0.09, [20, 33, 20, 46, 71]), (11, 0.8274, 0.772, 4.0, 0.19, [20, 25, 20, 54, 77]), (2, 0.7716, 0.7716, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7716, 0.7716, 3.0, 0.1, [20, 20, 20, 20, 20]), (11, 0.8223, 0.7673, 4.1, 0.16, [21, 46, 25, 63, 83]), (11, 0.8122, 0.7578, 3.0, 0.01, [20, 20, 20, 20, 21]), (11, 0.8122, 0.7578, 3.0, 0.01, [20, 20, 20, 20, 21]), (11, 0.7919, 0.7388, 3.3, 0.08, [20, 20, 20, 20, 43]), (11, 0.7868, 0.7341, 3.3, 0.17, [20, 20, 20, 22, 30])]\n",
      "Generation 15: 50.3 s, best val metric 0.8274, [(8, 0.8274, 0.8274, 3.6, 0.1, [20, 20, 20, 31, 40]), (10, 0.8071, 0.8071, 3.6, 0.1, [20, 20, 20, 21, 48]), (10, 0.8071, 0.8071, 3.6, 0.1, [20, 20, 20, 21, 48]), (9, 0.802, 0.802, 4.2, 0.19, [20, 36, 25, 51, 60]), (10, 0.7868, 0.7868, 3.0, 0.15, [20, 20, 20, 20, 25]), (3, 0.7766, 0.7766, 4.1, 0.2, [20, 20, 20, 40, 29]), (3, 0.7766, 0.7766, 4.1, 0.2, [20, 20, 20, 40, 29]), (3, 0.7563, 0.7563, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7513, 0.7513, 3.7, 0.1, [20, 20, 20, 20, 23]), (3, 0.7411, 0.7411, 3.0, 0.1, [20, 20, 20, 20, 20]), (12, 0.8223, 0.7159, 3.8, 0.15, [20, 21, 20, 31, 45])]\n",
      "Generation 16: 50.4 s, best val metric 0.8274, [(8, 0.8274, 0.8274, 3.6, 0.1, [20, 20, 20, 31, 40]), (9, 0.8173, 0.8173, 3.7, 0.19, [20, 20, 20, 44, 43]), (4, 0.802, 0.802, 3.0, 0.11, [20, 20, 20, 20, 20]), (10, 0.802, 0.802, 4.2, 0.19, [20, 52, 33, 71, 78]), (10, 0.802, 0.802, 4.2, 0.19, [20, 52, 33, 71, 78]), (4, 0.797, 0.797, 4.2, 0.17, [20, 31, 30, 59, 48]), (4, 0.7817, 0.7817, 4.7, 0.16, [24, 40, 40, 40, 43]), (4, 0.7513, 0.7513, 3.7, 0.12, [20, 20, 20, 20, 33]), (4, 0.7513, 0.7513, 3.7, 0.12, [20, 20, 20, 20, 33]), (4, 0.7462, 0.7462, 3.0, 0.1, [20, 20, 20, 20, 20]), (4, 0.7462, 0.7462, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 17: 53.2 s, best val metric 0.8274, [(8, 0.8274, 0.8274, 3.6, 0.1, [20, 20, 20, 31, 40]), (9, 0.8122, 0.8122, 3.6, 0.1, [20, 20, 20, 26, 43]), (9, 0.8122, 0.8122, 3.6, 0.1, [20, 20, 20, 26, 43]), (10, 0.8071, 0.8071, 3.7, 0.19, [20, 20, 20, 32, 50]), (5, 0.802, 0.802, 3.6, 0.15, [20, 20, 20, 20, 31]), (5, 0.802, 0.802, 3.6, 0.15, [20, 20, 20, 20, 31]), (9, 0.797, 0.797, 4.3, 0.13, [20, 38, 26, 51, 60]), (5, 0.7919, 0.7919, 4.7, 0.16, [34, 60, 60, 60, 63]), (5, 0.7817, 0.7817, 3.0, 0.11, [20, 20, 20, 20, 20]), (5, 0.7766, 0.7766, 3.7, 0.12, [20, 20, 20, 20, 34]), (5, 0.7766, 0.7766, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 18: 54.3 s, best val metric 0.8274, [(8, 0.8274, 0.8274, 3.6, 0.1, [20, 20, 20, 31, 40]), (9, 0.8173, 0.8173, 3.6, 0.1, [20, 20, 20, 24, 40]), (6, 0.8122, 0.8122, 3.6, 0.15, [20, 20, 20, 20, 29]), (9, 0.802, 0.802, 4.1, 0.16, [20, 30, 20, 51, 59]), (6, 0.802, 0.802, 3.5, 0.22, [20, 20, 20, 20, 25]), (10, 0.802, 0.802, 3.6, 0.1, [20, 20, 20, 25, 46]), (10, 0.802, 0.802, 3.6, 0.1, [20, 20, 20, 25, 46]), (10, 0.802, 0.802, 3.7, 0.15, [20, 22, 20, 24, 47]), (6, 0.797, 0.797, 4.7, 0.16, [52, 80, 80, 80, 83]), (10, 0.797, 0.797, 3.6, 0.1, [20, 20, 20, 23, 51]), (10, 0.797, 0.797, 3.6, 0.1, [20, 20, 20, 23, 51])]\n",
      "Generation 19: 56.8 s, best val metric 0.8477, [(8, 0.8274, 0.8274, 3.6, 0.1, [20, 20, 20, 31, 40]), (10, 0.8223, 0.8223, 3.5, 0.15, [20, 21, 20, 34, 46]), (10, 0.8122, 0.8122, 3.6, 0.1, [20, 20, 20, 21, 45]), (7, 0.802, 0.802, 3.6, 0.15, [20, 20, 20, 20, 30]), (7, 0.802, 0.802, 3.6, 0.15, [20, 20, 20, 20, 30]), (7, 0.802, 0.802, 3.6, 0.15, [20, 20, 20, 20, 30]), (11, 0.8477, 0.7909, 3.6, 0.1, [20, 20, 20, 22, 53]), (11, 0.8274, 0.772, 4.6, 0.12, [36, 40, 40, 43, 71]), (11, 0.8274, 0.772, 4.6, 0.12, [36, 40, 40, 43, 71]), (11, 0.8122, 0.7578, 3.7, 0.14, [20, 21, 20, 31, 52]), (11, 0.7766, 0.7246, 3.6, 0.1, [20, 20, 20, 21, 49])]\n",
      "Generation 20: 53.6 s, best val metric 0.8274, [(8, 0.8274, 0.8274, 3.6, 0.1, [20, 20, 20, 31, 40]), (9, 0.8122, 0.8122, 3.5, 0.13, [20, 20, 20, 22, 36]), (9, 0.8122, 0.8122, 3.5, 0.13, [20, 20, 20, 22, 36]), (9, 0.8071, 0.8071, 3.6, 0.1, [20, 20, 20, 25, 42]), (9, 0.8071, 0.8071, 3.6, 0.1, [20, 20, 20, 25, 42]), (8, 0.7817, 0.7817, 3.6, 0.15, [20, 20, 20, 22, 34]), (11, 0.8223, 0.7673, 3.5, 0.15, [20, 20, 20, 20, 50]), (11, 0.8122, 0.7578, 3.7, 0.12, [20, 20, 20, 21, 47]), (11, 0.8122, 0.7578, 3.7, 0.12, [20, 20, 20, 21, 47]), (8, 0.7563, 0.7563, 3.6, 0.15, [20, 20, 20, 20, 32]), (11, 0.7766, 0.7246, 3.6, 0.1, [20, 20, 20, 22, 45])]\n",
      "Generation 21: 48.3 s, best val metric 0.8325, [(10, 0.8325, 0.8325, 3.6, 0.1, [20, 20, 20, 22, 48]), (8, 0.8274, 0.8274, 3.6, 0.1, [20, 20, 20, 31, 40]), (10, 0.802, 0.802, 3.6, 0.06, [20, 20, 20, 28, 42]), (10, 0.802, 0.802, 3.6, 0.06, [20, 20, 20, 28, 42]), (10, 0.797, 0.797, 3.9, 0.12, [20, 22, 20, 45, 60]), (10, 0.797, 0.797, 4.1, 0.05, [20, 38, 23, 42, 56]), (10, 0.797, 0.797, 4.1, 0.05, [20, 38, 23, 42, 56]), (10, 0.7919, 0.7919, 3.6, 0.1, [20, 20, 20, 23, 43]), (9, 0.7817, 0.7817, 3.6, 0.15, [20, 20, 20, 20, 42]), (9, 0.7817, 0.7817, 3.6, 0.15, [20, 20, 20, 20, 42]), (9, 0.7716, 0.7716, 3.7, 0.11, [20, 20, 20, 20, 39])]\n",
      "Generation 22: 53.7 s, best val metric 0.8325, [(10, 0.8325, 0.8325, 3.6, 0.1, [20, 20, 20, 22, 48]), (9, 0.8173, 0.8173, 3.6, 0.1, [20, 20, 20, 27, 39]), (10, 0.802, 0.802, 3.7, 0.11, [20, 20, 20, 25, 49]), (10, 0.797, 0.797, 4.3, 0.08, [20, 40, 40, 40, 59]), (10, 0.797, 0.797, 4.3, 0.08, [20, 40, 40, 40, 59]), (10, 0.7868, 0.7868, 3.6, 0.15, [20, 20, 20, 20, 52]), (10, 0.7868, 0.7868, 3.6, 0.15, [20, 20, 20, 20, 52]), (10, 0.7817, 0.7817, 3.6, 0.15, [20, 20, 20, 20, 40]), (11, 0.8274, 0.772, 4.0, -0.03, [20, 30, 24, 42, 68]), (11, 0.8173, 0.7625, 3.6, 0.12, [20, 20, 20, 22, 41]), (1, 0.7614, 0.7614, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 23: 53.7 s, best val metric 0.8376, [(10, 0.8325, 0.8325, 3.6, 0.1, [20, 20, 20, 22, 48]), (10, 0.8173, 0.8173, 3.6, 0.1, [20, 20, 20, 28, 39]), (10, 0.7919, 0.7919, 3.4, 0.1, [20, 20, 20, 21, 38]), (11, 0.8376, 0.7815, 3.6, 0.15, [20, 20, 20, 20, 51]), (11, 0.8376, 0.7815, 3.6, 0.15, [20, 20, 20, 20, 51]), (11, 0.8173, 0.7625, 3.8, 0.08, [20, 20, 20, 36, 51]), (11, 0.8122, 0.7578, 4.2, 0.1, [21, 58, 49, 60, 79]), (11, 0.8122, 0.7578, 4.2, 0.1, [21, 58, 49, 60, 79]), (11, 0.8071, 0.7531, 3.6, 0.1, [20, 20, 20, 20, 55]), (11, 0.7919, 0.7388, 3.6, 0.14, [20, 20, 20, 20, 45]), (11, 0.7817, 0.7294, 2.6, 0.02, [20, 20, 20, 20, 20])]\n",
      "Generation 24: 53.6 s, best val metric 0.8325, [(10, 0.8325, 0.8325, 3.6, 0.1, [20, 20, 20, 22, 48]), (11, 0.8223, 0.7673, 3.5, 0.04, [20, 20, 20, 21, 43]), (11, 0.8223, 0.7673, 3.5, 0.04, [20, 20, 20, 21, 43]), (11, 0.8071, 0.7531, 2.8, 0.09, [20, 20, 20, 20, 23]), (11, 0.802, 0.7483, 3.6, 0.1, [20, 20, 20, 26, 39]), (11, 0.802, 0.7483, 3.6, 0.1, [20, 20, 20, 26, 39]), (11, 0.802, 0.7483, 3.6, 0.1, [20, 20, 20, 26, 39]), (11, 0.7919, 0.7388, 3.9, 0.13, [20, 27, 20, 41, 54]), (12, 0.8274, 0.7203, 3.9, 0.03, [20, 44, 35, 70, 78]), (12, 0.8173, 0.7115, 3.6, 0.1, [20, 22, 20, 31, 51]), (12, 0.8071, 0.7026, 3.8, 0.08, [20, 21, 20, 45, 68])]\n",
      "Generation 25: 52.3 s, best val metric 0.8325, [(10, 0.8325, 0.8325, 3.6, 0.1, [20, 20, 20, 22, 48]), (11, 0.8071, 0.7531, 3.0, 0.13, [20, 20, 20, 20, 24]), (12, 0.8274, 0.7203, 3.6, 0.06, [20, 20, 20, 26, 43]), (12, 0.8274, 0.7203, 4.0, 0.02, [20, 38, 28, 61, 70]), (12, 0.8274, 0.7203, 4.0, 0.02, [20, 38, 28, 61, 70]), (12, 0.8274, 0.7203, 3.6, 0.06, [20, 20, 20, 26, 43]), (11, 0.7665, 0.7152, 3.6, 0.1, [20, 20, 20, 23, 47]), (12, 0.8122, 0.707, 3.8, 0.07, [20, 20, 20, 27, 51]), (12, 0.8071, 0.7026, 3.8, -0.01, [20, 20, 20, 36, 57]), (13, 0.8274, 0.6721, 3.9, 0.03, [20, 28, 24, 59, 84]), (12, 0.7563, 0.6584, 2.8, 0.09, [20, 20, 17, 20, 21])]\n",
      "Generation 26: 54.0 s, best val metric 0.8376, [(10, 0.8325, 0.8325, 3.6, 0.1, [20, 20, 20, 22, 48]), (11, 0.802, 0.7483, 3.6, 0.1, [20, 20, 20, 23, 43]), (11, 0.802, 0.7483, 3.6, 0.1, [20, 20, 20, 23, 43]), (12, 0.802, 0.6982, 3.4, 0.01, [20, 20, 18, 20, 34]), (12, 0.797, 0.6938, 3.2, -0.01, [20, 20, 18, 20, 21]), (12, 0.7919, 0.6894, 3.6, 0.1, [20, 20, 20, 22, 50]), (13, 0.8376, 0.6803, 3.8, 0.07, [20, 22, 20, 46, 65]), (1, 0.6701, 0.6701, 3.0, 0.1, [20, 20, 20, 20, 20]), (13, 0.8122, 0.6597, 3.7, 0.05, [20, 26, 20, 44, 66]), (12, 0.7462, 0.6496, 3.0, 0.13, [20, 20, 17, 20, 24]), (13, 0.797, 0.6473, 4.0, 0.02, [20, 44, 24, 66, 83])]\n",
      "Generation 27: 50.3 s, best val metric 0.8325, [(10, 0.8325, 0.8325, 3.6, 0.1, [20, 20, 20, 22, 48]), (2, 0.7411, 0.7411, 4.0, 0.03, [20, 20, 20, 22, 23]), (2, 0.7411, 0.7411, 4.0, 0.03, [20, 20, 20, 22, 23]), (2, 0.7411, 0.7411, 4.0, 0.03, [20, 20, 20, 22, 23]), (2, 0.7411, 0.7411, 4.0, 0.03, [20, 20, 20, 22, 23]), (2, 0.7411, 0.7411, 4.0, 0.03, [20, 20, 20, 22, 23]), (12, 0.8223, 0.7159, 3.6, 0.1, [20, 20, 20, 21, 43]), (2, 0.7107, 0.7107, 3.0, 0.1, [20, 20, 20, 20, 20]), (11, 0.7462, 0.6962, 3.6, 0.1, [20, 20, 20, 23, 50]), (1, 0.6904, 0.6904, 3.0, 0.1, [20, 20, 20, 20, 20]), (13, 0.8274, 0.6721, 3.6, 0.1, [20, 20, 20, 22, 56])]\n",
      "Generation 28: 49.1 s, best val metric 0.8325, [(10, 0.8325, 0.8325, 3.6, 0.1, [20, 20, 20, 22, 48]), (3, 0.7716, 0.7716, 3.1, 0.05, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 3.1, 0.05, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 3.7, 0.05, [20, 20, 20, 20, 21]), (3, 0.7665, 0.7665, 4.5, 0.05, [21, 40, 39, 42, 43]), (3, 0.7563, 0.7563, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7411, 0.7411, 4.0, 0.03, [20, 20, 20, 31, 28]), (3, 0.7411, 0.7411, 4.0, 0.03, [20, 20, 20, 31, 28]), (3, 0.736, 0.736, 3.4, -0.01, [20, 20, 20, 20, 20]), (3, 0.736, 0.736, 4.0, 0.03, [20, 20, 20, 22, 32]), (11, 0.7817, 0.7294, 3.6, 0.1, [20, 20, 20, 22, 46])]\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "evolution = Evolution()\n",
    "evolution.run(x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test),\n",
    "              batch_size=32, layer_sizes=[20, 20, 20, 20, 20], output_neurons=10, learning_rate=0.0004, n_parents=5, strategy=[0.5, 0.05], \n",
    "              population_size=10, n_generations=50, tournament_size=3, n_introduced=2, age_penalty_period=10, use_static_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc52ec35af0>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 244,
       "width": 366
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [0] + [x[0] for x in evolution.val_metrics]\n",
    "y = [0] + [x[1] for x in evolution.val_metrics]\n",
    "plt.step(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elitism by val metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: 44.6 s, best val metric 0.736, [(1, 0.736, 0.736, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.736, 0.736, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.736, 0.736, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.7157, 0.7157, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.7157, 0.7157, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6954, 0.6954, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6954, 0.6954, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6701, 0.6701, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.665, 0.665, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6345, 0.6345, 2.9, 0.15, [20, 20, 20, 20, 20])]\n",
      "Generation 1: 44.0 s, best val metric 0.7868, [(2, 0.7868, 0.7868, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7716, 0.7716, 2.9, 0.09, [20, 20, 20, 20, 20]), (2, 0.7716, 0.7716, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7716, 0.7716, 2.9, 0.09, [20, 20, 20, 20, 20]), (2, 0.7716, 0.7716, 2.9, 0.09, [20, 20, 20, 20, 20]), (2, 0.7716, 0.7716, 2.9, 0.09, [20, 20, 20, 20, 20]), (2, 0.7665, 0.7665, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7563, 0.7563, 2.8, 0.09, [20, 20, 20, 20, 20]), (2, 0.7513, 0.7513, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.736, 0.736, 3.1, 0.06, [20, 20, 20, 20, 20]), (1, 0.736, 0.736, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 2: 48.8 s, best val metric 0.8071, [(3, 0.8071, 0.8071, 3.2, 0.05, [20, 20, 20, 20, 20]), (3, 0.8071, 0.8071, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.8071, 0.8071, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.797, 0.797, 3.4, 0.08, [20, 20, 20, 20, 20]), (3, 0.7919, 0.7919, 3.6, 0.13, [20, 20, 20, 20, 20]), (2, 0.7868, 0.7868, 4.1, 0.1, [20, 20, 20, 22, 24]), (2, 0.7868, 0.7868, 4.1, 0.1, [20, 20, 20, 22, 24]), (2, 0.7868, 0.7868, 4.1, 0.1, [20, 20, 20, 22, 24]), (2, 0.7868, 0.7868, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7817, 0.7817, 2.6, 0.21, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 2.9, 0.09, [20, 20, 20, 20, 20])]\n",
      "Generation 3: 49.8 s, best val metric 0.8173, [(3, 0.8173, 0.8173, 4.6, 0.12, [20, 40, 39, 40, 40]), (3, 0.8071, 0.8071, 3.2, 0.05, [20, 20, 20, 20, 20]), (4, 0.802, 0.802, 3.6, 0.08, [20, 20, 20, 20, 20]), (4, 0.802, 0.802, 3.6, 0.08, [20, 20, 20, 20, 20]), (4, 0.802, 0.802, 3.0, 0.1, [20, 20, 20, 20, 20]), (4, 0.802, 0.802, 3.6, 0.08, [20, 20, 20, 20, 20]), (4, 0.797, 0.797, 3.4, 0.12, [20, 20, 20, 20, 20]), (3, 0.7919, 0.7919, 3.6, 0.08, [20, 20, 20, 20, 20]), (3, 0.7868, 0.7868, 4.1, 0.1, [20, 31, 20, 27, 36]), (4, 0.7766, 0.7766, 3.2, 0.05, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 4.1, 0.1, [20, 26, 20, 31, 39])]\n",
      "Generation 4: 51.0 s, best val metric 0.8325, [(4, 0.8325, 0.8325, 4.1, 0.1, [20, 31, 20, 33, 41]), (4, 0.8325, 0.8325, 4.1, 0.1, [20, 31, 20, 33, 41]), (3, 0.8173, 0.8173, 4.6, 0.12, [20, 40, 39, 40, 40]), (5, 0.8122, 0.8122, 3.7, 0.07, [20, 20, 20, 20, 32]), (5, 0.8071, 0.8071, 3.6, 0.08, [20, 20, 20, 20, 21]), (5, 0.802, 0.802, 4.2, 0.12, [20, 39, 33, 40, 40]), (5, 0.802, 0.802, 4.2, 0.12, [20, 39, 33, 40, 40]), (4, 0.802, 0.802, 4.5, 0.07, [21, 59, 53, 60, 58]), (4, 0.802, 0.802, 4.5, 0.07, [21, 59, 53, 60, 58]), (5, 0.7919, 0.7919, 3.0, 0.1, [20, 20, 20, 20, 20]), (5, 0.7817, 0.7817, 3.6, 0.08, [20, 20, 20, 20, 23])]\n",
      "Generation 5: 57.8 s, best val metric 0.8426, [(6, 0.8426, 0.8426, 3.7, 0.07, [20, 20, 20, 20, 34]), (6, 0.8426, 0.8426, 3.7, 0.07, [20, 20, 20, 20, 34]), (6, 0.8426, 0.8426, 3.7, 0.07, [20, 20, 20, 20, 34]), (4, 0.8325, 0.8325, 4.1, 0.1, [20, 31, 20, 33, 41]), (6, 0.8274, 0.8274, 4.2, 0.12, [20, 54, 46, 60, 58]), (6, 0.8173, 0.8173, 4.2, 0.12, [20, 52, 47, 59, 58]), (5, 0.8173, 0.8173, 4.5, 0.09, [22, 79, 63, 80, 77]), (6, 0.8173, 0.8173, 4.2, 0.12, [20, 52, 47, 59, 58]), (6, 0.8173, 0.8173, 4.2, 0.12, [20, 52, 47, 59, 58]), (6, 0.8122, 0.8122, 5.4, 0.01, [40, 40, 40, 40, 52]), (6, 0.8122, 0.8122, 5.4, 0.01, [40, 40, 40, 40, 52])]\n",
      "Generation 6: 65.7 s, best val metric 0.8426, [(6, 0.8426, 0.8426, 3.7, 0.07, [20, 20, 20, 20, 34]), (7, 0.8173, 0.8173, 3.8, 0.12, [20, 31, 21, 46, 41]), (7, 0.8173, 0.8173, 3.8, 0.12, [20, 31, 21, 46, 41]), (7, 0.8173, 0.8173, 3.8, 0.12, [20, 31, 21, 46, 41]), (7, 0.8122, 0.8122, 4.2, 0.12, [20, 69, 59, 80, 75]), (7, 0.8122, 0.8122, 4.2, 0.12, [20, 70, 49, 79, 74]), (7, 0.8122, 0.8122, 4.2, 0.12, [20, 70, 49, 79, 74]), (7, 0.802, 0.802, 3.7, 0.07, [20, 20, 20, 20, 36]), (7, 0.802, 0.802, 5.4, 0.01, [60, 60, 60, 60, 72]), (7, 0.802, 0.802, 3.8, 0.05, [20, 31, 21, 45, 54]), (7, 0.797, 0.797, 3.9, 0.03, [20, 38, 32, 40, 52])]\n",
      "Generation 7: 64.1 s, best val metric 0.8426, [(6, 0.8426, 0.8426, 3.7, 0.07, [20, 20, 20, 20, 34]), (8, 0.8274, 0.8274, 4.2, 0.12, [20, 75, 64, 98, 91]), (8, 0.8274, 0.8274, 3.8, 0.12, [20, 26, 20, 32, 46]), (8, 0.8274, 0.8274, 3.8, 0.12, [20, 26, 20, 32, 46]), (8, 0.8223, 0.8223, 3.8, 0.12, [20, 22, 20, 39, 51]), (8, 0.8173, 0.8173, 4.2, 0.01, [20, 47, 28, 66, 58]), (8, 0.8173, 0.8173, 3.8, 0.05, [20, 26, 20, 35, 65]), (8, 0.8122, 0.8122, 3.7, 0.05, [20, 20, 20, 31, 46]), (8, 0.8122, 0.8122, 3.7, 0.05, [20, 20, 20, 31, 46]), (8, 0.8122, 0.8122, 3.5, 0.07, [20, 21, 20, 33, 30]), (8, 0.8071, 0.8071, 4.3, 0.12, [20, 47, 39, 66, 60])]\n",
      "Generation 8: 58.8 s, best val metric 0.8426, [(6, 0.8426, 0.8426, 3.7, 0.07, [20, 20, 20, 20, 34]), (9, 0.8274, 0.8274, 4.5, 0.13, [24, 42, 40, 59, 71]), (9, 0.8274, 0.8274, 4.5, 0.13, [24, 42, 40, 59, 71]), (9, 0.8223, 0.8223, 4.2, 0.01, [20, 60, 30, 77, 78]), (9, 0.8223, 0.8223, 3.1, 0.06, [20, 20, 20, 20, 27]), (9, 0.8173, 0.8173, 4.0, 0.08, [20, 29, 21, 50, 50]), (9, 0.8173, 0.8173, 4.0, 0.08, [20, 29, 21, 50, 50]), (9, 0.8173, 0.8173, 4.0, 0.08, [20, 29, 21, 50, 50]), (9, 0.8173, 0.8173, 4.0, 0.08, [20, 29, 21, 50, 50]), (9, 0.8071, 0.8071, 4.2, 0.12, [20, 75, 48, 104, 97]), (9, 0.797, 0.797, 3.7, 0.05, [20, 20, 20, 21, 45])]\n",
      "Generation 9: 61.0 s, best val metric 0.8426, [(6, 0.8426, 0.8426, 3.7, 0.07, [20, 20, 20, 20, 34]), (10, 0.8274, 0.8274, 4.0, 0.08, [20, 36, 20, 56, 63]), (7, 0.8223, 0.8223, 4.3, 0.09, [20, 31, 30, 40, 54]), (10, 0.8173, 0.8173, 4.0, 0.08, [20, 43, 21, 68, 69]), (10, 0.8173, 0.8173, 4.0, 0.08, [20, 43, 21, 68, 69]), (10, 0.8122, 0.8122, 4.4, 0.1, [20, 49, 41, 70, 70]), (10, 0.8122, 0.8122, 4.4, 0.1, [20, 49, 41, 70, 70]), (10, 0.8122, 0.8122, 4.4, 0.1, [20, 49, 41, 70, 70]), (10, 0.8071, 0.8071, 3.3, 0.05, [20, 20, 20, 20, 27]), (10, 0.802, 0.802, 4.0, 0.13, [20, 40, 38, 60, 81]), (10, 0.797, 0.797, 4.2, 0.12, [20, 82, 45, 115, 114])]\n",
      "Generation 10: 63.7 s, best val metric 0.8426, [(6, 0.8426, 0.8426, 3.7, 0.07, [20, 20, 20, 20, 34]), (7, 0.8173, 0.8173, 3.6, 0.07, [20, 20, 20, 22, 35]), (8, 0.797, 0.797, 3.8, 0.22, [20, 26, 22, 40, 55]), (8, 0.797, 0.797, 3.8, 0.22, [20, 26, 22, 40, 55]), (8, 0.797, 0.797, 3.8, 0.22, [20, 26, 22, 40, 55]), (8, 0.797, 0.797, 3.8, 0.22, [20, 26, 22, 40, 55]), (7, 0.7868, 0.7868, 3.7, 0.07, [20, 20, 20, 20, 37]), (11, 0.8173, 0.7625, 4.2, 0.13, [20, 61, 39, 85, 88]), (11, 0.8122, 0.7578, 4.4, 0.1, [24, 69, 61, 90, 90]), (11, 0.8071, 0.7531, 4.0, 0.08, [20, 43, 21, 75, 78]), (11, 0.8071, 0.7531, 4.2, 0.12, [20, 95, 46, 113, 115])]\n",
      "Generation 11: 61.8 s, best val metric 0.8426, [(6, 0.8426, 0.8426, 3.7, 0.07, [20, 20, 20, 20, 34]), (8, 0.8274, 0.8274, 3.8, 0.23, [20, 20, 20, 21, 40]), (9, 0.8274, 0.8274, 3.8, 0.22, [20, 21, 22, 38, 58]), (9, 0.8274, 0.8274, 3.8, 0.22, [20, 21, 22, 38, 58]), (8, 0.8223, 0.8223, 3.6, 0.07, [20, 20, 20, 20, 36]), (8, 0.8223, 0.8223, 3.6, 0.07, [20, 20, 20, 20, 36]), (7, 0.8173, 0.8173, 3.7, 0.07, [20, 20, 20, 20, 39]), (9, 0.8122, 0.8122, 4.4, -0.01, [20, 45, 42, 60, 75]), (8, 0.8071, 0.8071, 4.0, 0.17, [20, 21, 20, 32, 51]), (8, 0.7817, 0.7817, 3.7, 0.07, [20, 20, 20, 20, 39]), (12, 0.8223, 0.7159, 4.4, 0.1, [22, 89, 81, 110, 110])]\n",
      "Generation 12: 54.3 s, best val metric 0.8426, [(6, 0.8426, 0.8426, 3.7, 0.07, [20, 20, 20, 20, 34]), (9, 0.8274, 0.8274, 3.8, 0.23, [20, 20, 20, 24, 50]), (9, 0.8274, 0.8274, 3.6, 0.07, [20, 20, 20, 20, 44]), (9, 0.8274, 0.8274, 3.6, 0.07, [20, 20, 20, 20, 44]), (9, 0.8274, 0.8274, 3.6, 0.07, [20, 20, 20, 20, 41]), (9, 0.8274, 0.8274, 3.8, 0.23, [20, 20, 20, 24, 50]), (9, 0.8223, 0.8223, 3.7, 0.07, [20, 20, 20, 20, 42]), (8, 0.8173, 0.8173, 4.3, 0.2, [20, 40, 39, 40, 59]), (8, 0.8173, 0.8173, 4.3, 0.2, [20, 40, 39, 40, 59]), (10, 0.8122, 0.8122, 3.6, 0.09, [20, 20, 20, 26, 55]), (10, 0.8071, 0.8071, 4.0, 0.08, [20, 24, 23, 52, 64])]\n",
      "Generation 13: 53.7 s, best val metric 0.8426, [(6, 0.8426, 0.8426, 3.7, 0.07, [20, 20, 20, 20, 34]), (10, 0.8274, 0.8274, 3.7, 0.06, [20, 20, 20, 20, 47]), (10, 0.8274, 0.8274, 3.7, 0.06, [20, 20, 20, 20, 47]), (9, 0.8274, 0.8274, 4.1, 0.15, [20, 38, 34, 54, 76]), (10, 0.8223, 0.8223, 3.6, 0.07, [20, 20, 20, 20, 46]), (10, 0.8223, 0.8223, 3.6, 0.07, [20, 20, 20, 20, 46]), (10, 0.8173, 0.8173, 4.5, 0.17, [20, 40, 40, 40, 64]), (10, 0.8173, 0.8173, 3.8, 0.23, [20, 20, 20, 26, 62]), (10, 0.8173, 0.8173, 3.8, 0.23, [20, 20, 20, 26, 62]), (9, 0.8122, 0.8122, 4.1, 0.07, [20, 53, 36, 58, 79]), (9, 0.8122, 0.8122, 4.1, 0.07, [20, 53, 36, 58, 79])]\n",
      "Generation 14: 54.9 s, best val metric 0.8426, [(6, 0.8426, 0.8426, 3.7, 0.07, [20, 20, 20, 20, 34]), (10, 0.8325, 0.8325, 4.1, 0.07, [20, 49, 38, 63, 92]), (7, 0.8325, 0.8325, 3.7, 0.07, [20, 20, 20, 20, 47]), (10, 0.8122, 0.8122, 3.9, 0.1, [20, 47, 30, 55, 83]), (10, 0.8071, 0.8071, 4.7, 0.2, [37, 58, 54, 74, 96]), (10, 0.8071, 0.8071, 4.1, 0.07, [20, 51, 34, 72, 84]), (10, 0.802, 0.802, 4.1, 0.15, [20, 37, 30, 62, 81]), (10, 0.802, 0.802, 4.1, 0.15, [20, 37, 30, 62, 81]), (10, 0.802, 0.802, 4.1, 0.15, [20, 37, 30, 62, 81]), (11, 0.8223, 0.7673, 4.3, 0.09, [20, 37, 39, 40, 67]), (11, 0.8122, 0.7578, 3.8, 0.23, [20, 22, 23, 27, 64])]\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "evolution = Evolution()\n",
    "evolution.run(x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test),\n",
    "              batch_size=32, layer_sizes=[20, 20, 20, 20, 20], output_neurons=10, learning_rate=0.0004, n_parents=5, strategy=[0.5, 0.05], \n",
    "              population_size=10, n_generations=50, tournament_size=3, n_introduced=2, age_penalty_period=10, use_static_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc52f915790>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 244,
       "width": 366
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [0] + [x[0] for x in evolution.val_metrics]\n",
    "y = [0] + [x[1] for x in evolution.val_metrics]\n",
    "plt.step(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: 40.2 s, best val metric 0.7208, [(1, 0.7208, 0.7208, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.7208, 0.7208, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.7005, 0.7005, 2.8, -0.02, [20, 20, 20, 20, 20]), (1, 0.7005, 0.7005, 2.8, -0.02, [20, 20, 20, 20, 20]), (1, 0.6954, 0.6954, 3.0, 0.09, [20, 20, 20, 20, 20]), (1, 0.6954, 0.6954, 3.0, 0.09, [20, 20, 20, 20, 20]), (1, 0.6954, 0.6954, 3.0, 0.09, [20, 20, 20, 20, 20]), (1, 0.6497, 0.6497, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6447, 0.6447, 2.9, 0.03, [20, 20, 20, 20, 20]), (1, 0.6294, 0.6294, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 1: 39.8 s, best val metric 0.7868, [(2, 0.7868, 0.7868, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7665, 0.7665, 3.6, 0.08, [20, 20, 20, 20, 20]), (2, 0.7513, 0.7513, 2.8, 0.03, [20, 20, 20, 20, 20]), (2, 0.7411, 0.7411, 3.3, 0.16, [20, 20, 20, 20, 20]), (2, 0.7411, 0.7411, 3.0, 0.02, [20, 20, 20, 20, 20]), (2, 0.7411, 0.7411, 3.0, 0.09, [20, 20, 20, 20, 20]), (2, 0.7411, 0.7411, 2.8, -0.02, [20, 20, 20, 20, 20]), (2, 0.7411, 0.7411, 3.0, 0.06, [20, 20, 20, 20, 20]), (2, 0.736, 0.736, 3.0, 0.09, [20, 20, 20, 20, 20]), (2, 0.7259, 0.7259, 3.3, 0.13, [20, 20, 20, 20, 20]), (1, 0.7208, 0.7208, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 2: 41.5 s, best val metric 0.802, [(3, 0.802, 0.802, 4.1, 0.05, [20, 30, 34, 39, 28]), (2, 0.7868, 0.7868, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7766, 0.7766, 3.1, 0.14, [20, 20, 20, 20, 20]), (3, 0.7766, 0.7766, 3.6, 0.08, [20, 20, 20, 20, 20]), (2, 0.7716, 0.7716, 2.8, 0.1, [20, 20, 20, 20, 20]), (2, 0.7716, 0.7716, 2.8, 0.1, [20, 20, 20, 20, 20]), (3, 0.7665, 0.7665, 3.3, 0.13, [20, 20, 20, 20, 20]), (3, 0.7563, 0.7563, 2.8, -0.02, [20, 20, 20, 20, 20]), (2, 0.7563, 0.7563, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7563, 0.7563, 2.8, -0.02, [20, 20, 20, 20, 20]), (3, 0.7513, 0.7513, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 3: 42.9 s, best val metric 0.802, [(3, 0.802, 0.802, 4.1, 0.05, [20, 30, 34, 39, 28]), (3, 0.7919, 0.7919, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7919, 0.7919, 2.8, 0.1, [20, 20, 20, 20, 20]), (3, 0.7919, 0.7919, 2.8, 0.1, [20, 20, 20, 20, 20]), (3, 0.7919, 0.7919, 3.0, 0.1, [20, 20, 20, 20, 20]), (4, 0.7919, 0.7919, 3.3, 0.13, [20, 20, 20, 20, 20]), (4, 0.7868, 0.7868, 3.3, -0.05, [20, 20, 20, 20, 20]), (4, 0.7868, 0.7868, 4.1, 0.05, [20, 34, 28, 58, 47]), (4, 0.7868, 0.7868, 4.1, 0.05, [20, 34, 28, 58, 47]), (4, 0.7766, 0.7766, 3.0, 0.19, [20, 20, 20, 20, 20]), (4, 0.7766, 0.7766, 3.3, 0.13, [20, 20, 20, 20, 20])]\n",
      "Generation 4: 46.4 s, best val metric 0.8223, [(5, 0.8223, 0.8223, 4.1, 0.05, [20, 38, 34, 72, 45]), (5, 0.8223, 0.8223, 4.1, 0.05, [20, 38, 34, 72, 45]), (5, 0.8223, 0.8223, 4.1, 0.05, [20, 38, 34, 72, 45]), (5, 0.8223, 0.8223, 4.1, 0.05, [20, 38, 34, 72, 45]), (5, 0.8071, 0.8071, 3.3, -0.05, [20, 20, 20, 20, 20]), (5, 0.8071, 0.8071, 3.2, 0.16, [20, 20, 20, 20, 20]), (4, 0.8071, 0.8071, 4.1, 0.05, [20, 39, 37, 56, 40]), (5, 0.8071, 0.8071, 3.2, 0.16, [20, 20, 20, 20, 20]), (4, 0.8071, 0.8071, 4.1, 0.05, [20, 39, 37, 56, 40]), (3, 0.802, 0.802, 4.1, 0.05, [20, 30, 34, 39, 28]), (4, 0.7868, 0.7868, 2.8, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 5: 52.6 s, best val metric 0.8528, [(6, 0.8528, 0.8528, 4.0, 0.04, [20, 43, 31, 77, 52]), (6, 0.8528, 0.8528, 4.0, 0.04, [20, 43, 31, 77, 52]), (6, 0.8376, 0.8376, 4.1, 0.05, [20, 40, 33, 71, 45]), (6, 0.8223, 0.8223, 3.6, -0.01, [20, 22, 21, 33, 28]), (6, 0.8223, 0.8223, 3.6, -0.01, [20, 22, 21, 33, 28]), (4, 0.8223, 0.8223, 4.1, 0.05, [20, 40, 36, 57, 42]), (5, 0.8223, 0.8223, 4.1, 0.05, [20, 38, 34, 72, 45]), (5, 0.8173, 0.8173, 4.4, 0.02, [21, 59, 57, 76, 60]), (6, 0.8071, 0.8071, 4.1, 0.05, [20, 37, 27, 74, 45]), (6, 0.802, 0.802, 4.0, 0.04, [20, 32, 20, 40, 39]), (6, 0.802, 0.802, 4.1, 0.08, [20, 21, 26, 40, 40])]\n",
      "Generation 6: 57.3 s, best val metric 0.8528, [(6, 0.8528, 0.8528, 4.0, 0.04, [20, 43, 31, 77, 52]), (7, 0.8274, 0.8274, 3.4, -0.02, [20, 21, 20, 23, 25]), (7, 0.8274, 0.8274, 3.4, -0.02, [20, 21, 20, 23, 25]), (6, 0.8173, 0.8173, 4.4, 0.02, [23, 79, 76, 96, 76]), (6, 0.8173, 0.8173, 4.4, 0.02, [23, 79, 76, 96, 76]), (6, 0.8173, 0.8173, 4.4, 0.02, [23, 79, 76, 96, 76]), (6, 0.8122, 0.8122, 4.1, 0.05, [20, 44, 27, 72, 56]), (7, 0.8071, 0.8071, 3.6, -0.01, [20, 20, 20, 26, 30]), (5, 0.8071, 0.8071, 3.4, -0.0, [20, 22, 20, 23, 22]), (5, 0.8071, 0.8071, 3.4, -0.0, [20, 22, 20, 23, 22]), (7, 0.797, 0.797, 4.0, 0.04, [20, 41, 30, 77, 63])]\n",
      "Generation 7: 60.4 s, best val metric 0.8528, [(6, 0.8528, 0.8528, 4.0, 0.04, [20, 43, 31, 77, 52]), (8, 0.8376, 0.8376, 3.4, -0.02, [20, 21, 20, 20, 26]), (8, 0.8376, 0.8376, 3.4, -0.02, [20, 21, 20, 20, 26]), (8, 0.8376, 0.8376, 3.4, -0.02, [20, 21, 20, 20, 26]), (8, 0.8376, 0.8376, 3.4, -0.02, [20, 21, 20, 20, 26]), (8, 0.8274, 0.8274, 4.8, 0.0, [40, 40, 40, 46, 50]), (6, 0.8122, 0.8122, 3.4, -0.0, [20, 20, 20, 20, 22]), (8, 0.8071, 0.8071, 3.4, 0.04, [20, 20, 20, 20, 25]), (6, 0.8071, 0.8071, 4.5, 0.03, [21, 42, 40, 43, 42]), (8, 0.8071, 0.8071, 3.4, 0.04, [20, 20, 20, 20, 25]), (8, 0.802, 0.802, 3.6, -0.01, [20, 20, 20, 25, 46])]\n",
      "Generation 8: 50.5 s, best val metric 0.8528, [(6, 0.8528, 0.8528, 4.0, 0.04, [20, 43, 31, 77, 52]), (9, 0.8274, 0.8274, 4.8, 0.0, [59, 60, 60, 66, 70]), (9, 0.8274, 0.8274, 3.0, 0.02, [20, 20, 20, 24, 22]), (9, 0.8223, 0.8223, 3.4, 0.04, [20, 20, 20, 20, 25]), (7, 0.8223, 0.8223, 4.1, -0.03, [20, 39, 26, 40, 42]), (7, 0.8223, 0.8223, 4.1, -0.03, [20, 39, 26, 40, 42]), (9, 0.8122, 0.8122, 4.2, 0.09, [22, 41, 38, 40, 46]), (7, 0.8122, 0.8122, 4.5, 0.03, [24, 62, 60, 63, 62]), (9, 0.797, 0.797, 3.4, 0.04, [20, 20, 20, 20, 25]), (9, 0.7919, 0.7919, 4.1, -0.02, [20, 39, 29, 40, 46]), (9, 0.7716, 0.7716, 4.0, -0.05, [20, 26, 23, 45, 63])]\n",
      "Generation 9: 53.8 s, best val metric 0.8528, [(6, 0.8528, 0.8528, 4.0, 0.04, [20, 43, 31, 77, 52]), (7, 0.8325, 0.8325, 3.8, -0.0, [20, 35, 24, 60, 47]), (7, 0.8223, 0.8223, 4.0, 0.04, [20, 40, 25, 67, 57]), (8, 0.8223, 0.8223, 4.1, -0.03, [20, 44, 25, 60, 61]), (10, 0.8223, 0.8223, 3.4, 0.04, [20, 20, 20, 20, 29]), (10, 0.8122, 0.8122, 3.0, -0.0, [20, 20, 20, 21, 26]), (10, 0.8122, 0.8122, 3.4, -0.0, [20, 20, 20, 20, 25]), (8, 0.8122, 0.8122, 3.4, 0.03, [20, 22, 20, 32, 35]), (10, 0.8122, 0.8122, 3.4, -0.0, [20, 20, 20, 20, 25]), (10, 0.8071, 0.8071, 4.0, 0.09, [20, 38, 33, 40, 45]), (8, 0.7259, 0.7259, 5.0, 0.14, [40, 59, 46, 60, 62])]\n",
      "Generation 10: 51.6 s, best val metric 0.8528, [(6, 0.8528, 0.8528, 4.0, 0.04, [20, 43, 31, 77, 52]), (9, 0.8223, 0.8223, 3.2, -0.02, [20, 20, 20, 20, 29]), (11, 0.8173, 0.8173, 3.4, -0.0, [20, 20, 20, 20, 32]), (11, 0.8173, 0.8173, 3.4, -0.0, [20, 20, 20, 20, 32]), (11, 0.8173, 0.8173, 3.4, -0.0, [20, 20, 20, 20, 32]), (9, 0.8122, 0.8122, 3.4, 0.03, [20, 20, 20, 21, 32]), (9, 0.8071, 0.8071, 3.1, 0.14, [20, 20, 20, 21, 21]), (11, 0.8071, 0.8071, 3.0, -0.0, [20, 20, 20, 20, 26]), (11, 0.802, 0.802, 4.1, 0.04, [20, 40, 37, 41, 46]), (9, 0.797, 0.797, 3.7, 0.09, [21, 42, 37, 60, 45]), (9, 0.797, 0.797, 3.7, 0.09, [21, 42, 37, 60, 45])]\n",
      "Generation 11: 48.4 s, best val metric 0.8528, [(6, 0.8528, 0.8528, 4.0, 0.04, [20, 43, 31, 77, 52]), (12, 0.8325, 0.8325, 4.1, 0.04, [20, 41, 39, 61, 66]), (12, 0.8223, 0.8223, 3.4, -0.0, [20, 20, 20, 20, 32]), (12, 0.8173, 0.8173, 3.4, -0.0, [20, 20, 20, 20, 40]), (12, 0.8122, 0.8122, 3.4, -0.0, [20, 20, 20, 20, 46]), (12, 0.8122, 0.8122, 3.4, -0.0, [20, 20, 20, 20, 46]), (10, 0.8071, 0.8071, 3.2, -0.02, [20, 20, 20, 20, 27]), (12, 0.8071, 0.8071, 3.0, -0.0, [20, 20, 20, 20, 26]), (12, 0.8071, 0.8071, 3.0, -0.0, [20, 20, 20, 20, 26]), (7, 0.802, 0.802, 3.2, 0.11, [20, 21, 20, 21, 24]), (7, 0.7868, 0.7868, 4.0, 0.04, [20, 45, 25, 75, 53])]\n",
      "Generation 12: 48.7 s, best val metric 0.8528, [(6, 0.8528, 0.8528, 4.0, 0.04, [20, 43, 31, 77, 52]), (8, 0.8274, 0.8274, 4.0, 0.04, [20, 43, 27, 90, 70]), (8, 0.8274, 0.8274, 4.0, 0.04, [20, 43, 27, 90, 70]), (7, 0.8223, 0.8223, 4.0, 0.04, [20, 39, 31, 70, 62]), (7, 0.8223, 0.8223, 4.0, 0.04, [20, 39, 31, 70, 62]), (8, 0.8173, 0.8173, 3.0, 0.02, [20, 20, 20, 20, 20]), (13, 0.8122, 0.8122, 3.2, 0.06, [20, 20, 20, 20, 28]), (11, 0.8071, 0.8071, 3.8, 0.01, [20, 20, 21, 40, 46]), (11, 0.8071, 0.8071, 3.8, 0.01, [20, 20, 21, 40, 46]), (7, 0.802, 0.802, 3.7, 0.04, [20, 27, 21, 43, 40]), (13, 0.802, 0.802, 3.4, -0.0, [20, 20, 20, 20, 35])]\n",
      "Generation 13: 52.7 s, best val metric 0.8528, [(6, 0.8528, 0.8528, 4.0, 0.04, [20, 43, 31, 77, 52]), (8, 0.8325, 0.8325, 3.7, 0.04, [20, 21, 20, 33, 40]), (8, 0.8071, 0.8071, 3.9, 0.06, [20, 35, 21, 53, 54]), (14, 0.8071, 0.8071, 3.4, -0.0, [20, 20, 20, 20, 40]), (9, 0.8071, 0.8071, 3.2, 0.01, [20, 20, 20, 22, 24]), (8, 0.8071, 0.8071, 3.9, 0.06, [20, 35, 21, 53, 54]), (8, 0.802, 0.802, 4.0, 0.04, [20, 33, 31, 77, 70]), (12, 0.802, 0.802, 3.8, 0.01, [20, 21, 20, 46, 55]), (9, 0.797, 0.797, 2.9, 0.02, [20, 20, 20, 20, 21]), (8, 0.797, 0.797, 4.0, -0.04, [20, 44, 26, 61, 68]), (9, 0.797, 0.797, 2.9, 0.02, [20, 20, 20, 20, 21])]\n",
      "Generation 14: 51.5 s, best val metric 0.8528, [(6, 0.8528, 0.8528, 4.0, 0.04, [20, 43, 31, 77, 52]), (13, 0.8426, 0.8426, 3.7, -0.02, [20, 21, 20, 37, 67]), (10, 0.8325, 0.8325, 3.4, 0.01, [20, 20, 20, 20, 21]), (9, 0.8122, 0.8122, 3.9, 0.06, [20, 28, 20, 44, 62]), (15, 0.8071, 0.8071, 3.4, -0.0, [20, 20, 20, 20, 41]), (9, 0.802, 0.802, 2.5, 0.07, [20, 20, 20, 20, 20]), (13, 0.802, 0.802, 3.8, 0.01, [20, 21, 20, 55, 63]), (9, 0.802, 0.802, 3.7, 0.08, [20, 30, 22, 47, 57]), (13, 0.802, 0.802, 3.8, 0.01, [20, 21, 20, 55, 63]), (9, 0.802, 0.802, 2.5, 0.07, [20, 20, 20, 20, 20]), (10, 0.797, 0.797, 3.2, 0.01, [20, 20, 20, 20, 23])]\n",
      "Generation 15: 50.0 s, best val metric 0.8528, [(6, 0.8528, 0.8528, 4.0, 0.04, [20, 43, 31, 77, 52]), (10, 0.8122, 0.8122, 3.7, 0.08, [20, 23, 20, 34, 56]), (11, 0.8071, 0.8071, 3.2, 0.03, [20, 20, 20, 20, 23]), (16, 0.802, 0.802, 3.8, 0.05, [20, 21, 26, 40, 59]), (10, 0.797, 0.797, 2.9, 0.06, [20, 20, 20, 20, 21]), (10, 0.797, 0.797, 2.9, 0.06, [20, 20, 20, 20, 21]), (14, 0.797, 0.797, 3.8, 0.01, [20, 20, 20, 44, 72]), (7, 0.7919, 0.7919, 4.0, 0.02, [20, 44, 28, 74, 67]), (10, 0.7919, 0.7919, 3.1, 0.02, [20, 20, 20, 20, 22]), (10, 0.7919, 0.7919, 3.1, 0.02, [20, 20, 20, 20, 22]), (11, 0.7716, 0.7716, 3.4, 0.01, [20, 20, 20, 20, 31])]\n",
      "Generation 16: 47.4 s, best val metric 0.8528, [(6, 0.8528, 0.8528, 4.0, 0.04, [20, 43, 31, 77, 52]), (8, 0.8223, 0.8223, 4.0, 0.02, [20, 48, 28, 87, 68]), (8, 0.8223, 0.8223, 4.0, 0.02, [20, 48, 28, 87, 68]), (15, 0.8223, 0.8223, 3.8, 0.01, [20, 21, 20, 44, 78]), (11, 0.8173, 0.8173, 3.1, 0.02, [20, 20, 20, 20, 22]), (11, 0.8173, 0.8173, 3.1, 0.02, [20, 20, 20, 20, 22]), (11, 0.8122, 0.8122, 3.7, 0.04, [20, 20, 20, 26, 36]), (12, 0.8071, 0.8071, 3.4, 0.01, [20, 20, 20, 20, 32]), (12, 0.8071, 0.8071, 3.4, 0.01, [20, 20, 20, 20, 32]), (12, 0.8071, 0.8071, 3.4, 0.01, [20, 20, 20, 20, 32]), (17, 0.802, 0.802, 2.8, -0.04, [20, 19, 19, 20, 36])]\n",
      "Generation 17: 47.6 s, best val metric 0.8528, [(6, 0.8528, 0.8528, 4.0, 0.04, [20, 43, 31, 77, 52]), (13, 0.8325, 0.8325, 3.9, 0.09, [20, 24, 23, 40, 51]), (13, 0.8325, 0.8325, 3.9, 0.09, [20, 24, 23, 40, 51]), (16, 0.8223, 0.8223, 3.4, 0.06, [20, 20, 20, 28, 55]), (12, 0.8223, 0.8223, 3.0, -0.04, [20, 20, 20, 20, 24]), (9, 0.8223, 0.8223, 4.0, 0.02, [20, 41, 27, 87, 78]), (12, 0.8173, 0.8173, 2.9, -0.03, [20, 20, 20, 20, 21]), (12, 0.8173, 0.8173, 2.9, -0.03, [20, 20, 20, 20, 21]), (13, 0.8173, 0.8173, 3.4, 0.01, [20, 19, 20, 20, 30]), (7, 0.8173, 0.8173, 3.1, 0.08, [20, 20, 20, 20, 20]), (13, 0.8122, 0.8122, 3.4, 0.01, [20, 20, 20, 20, 33])]\n",
      "Generation 18: 48.2 s, best val metric 0.8528, [(6, 0.8528, 0.8528, 4.0, 0.04, [20, 43, 31, 77, 52]), (14, 0.8173, 0.8173, 3.4, 0.01, [20, 19, 20, 20, 32]), (10, 0.8173, 0.8173, 2.9, -0.03, [20, 20, 20, 21, 24]), (10, 0.8173, 0.8173, 2.9, -0.03, [20, 20, 20, 21, 24]), (14, 0.8173, 0.8173, 3.4, 0.01, [20, 19, 20, 20, 32]), (14, 0.8173, 0.8173, 3.4, 0.01, [20, 19, 20, 20, 32]), (14, 0.8173, 0.8173, 3.2, -0.03, [20, 19, 20, 20, 36]), (10, 0.8173, 0.8173, 2.9, -0.03, [20, 20, 20, 21, 24]), (13, 0.797, 0.797, 2.9, -0.03, [20, 20, 20, 20, 21]), (13, 0.797, 0.797, 2.9, -0.03, [20, 20, 20, 20, 21]), (14, 0.7919, 0.7919, 3.9, 0.09, [20, 23, 22, 54, 64])]\n",
      "Generation 19: 45.2 s, best val metric 0.8528, [(6, 0.8528, 0.8528, 4.0, 0.04, [20, 43, 31, 77, 52]), (7, 0.8477, 0.8477, 3.0, -0.05, [20, 20, 20, 20, 20]), (15, 0.8223, 0.8223, 2.7, 0.03, [20, 16, 17, 19, 24]), (15, 0.8173, 0.8173, 3.2, -0.03, [20, 17, 18, 20, 30]), (15, 0.8173, 0.8173, 3.2, -0.03, [20, 17, 18, 20, 30]), (7, 0.8122, 0.8122, 4.0, 0.04, [20, 52, 28, 73, 58]), (11, 0.8122, 0.8122, 2.9, -0.03, [20, 20, 20, 20, 24]), (7, 0.8122, 0.8122, 4.0, 0.04, [20, 52, 28, 73, 58]), (14, 0.802, 0.802, 2.9, -0.03, [20, 18, 17, 20, 21]), (14, 0.802, 0.802, 2.9, -0.03, [20, 18, 17, 20, 21]), (15, 0.7868, 0.7868, 3.4, 0.01, [20, 19, 20, 20, 41])]\n",
      "Generation 20: 49.9 s, best val metric 0.8528, [(6, 0.8528, 0.8528, 4.0, 0.04, [20, 43, 31, 77, 52]), (15, 0.8325, 0.8325, 3.8, 0.01, [20, 21, 17, 40, 38]), (7, 0.8274, 0.8274, 4.0, 0.04, [20, 53, 30, 75, 56]), (7, 0.8274, 0.8274, 4.0, 0.04, [20, 53, 30, 75, 56]), (7, 0.8274, 0.8274, 4.0, 0.04, [20, 53, 30, 75, 56]), (16, 0.8223, 0.8223, 3.2, -0.03, [20, 16, 18, 20, 38]), (16, 0.8223, 0.8223, 3.2, -0.03, [20, 16, 18, 20, 38]), (16, 0.8223, 0.8223, 3.2, -0.03, [20, 16, 18, 20, 38]), (8, 0.8071, 0.8071, 3.5, -0.08, [20, 20, 20, 20, 34]), (8, 0.8071, 0.8071, 3.0, -0.01, [20, 20, 20, 20, 20]), (12, 0.7411, 0.7411, 2.3, -0.09, [20, 20, 20, 20, 20])]\n",
      "Generation 21: 52.5 s, best val metric 0.8528, [(6, 0.8528, 0.8528, 4.0, 0.04, [20, 43, 31, 77, 52]), (17, 0.8223, 0.8223, 3.2, -0.03, [20, 13, 15, 17, 39]), (8, 0.8223, 0.8223, 4.0, 0.04, [20, 45, 31, 70, 63]), (8, 0.8223, 0.8223, 4.0, 0.04, [20, 45, 31, 70, 63]), (17, 0.8223, 0.8223, 3.2, -0.03, [20, 13, 15, 17, 39]), (8, 0.8223, 0.8223, 4.0, 0.04, [20, 45, 31, 70, 63]), (17, 0.8223, 0.8223, 3.2, -0.03, [20, 13, 15, 17, 39]), (7, 0.8071, 0.8071, 4.0, 0.04, [20, 42, 30, 66, 55]), (8, 0.802, 0.802, 3.8, -0.11, [20, 31, 21, 59, 63]), (16, 0.802, 0.802, 4.1, 0.0, [20, 41, 35, 60, 58]), (17, 0.797, 0.797, 3.2, -0.03, [19, 14, 15, 17, 33])]\n",
      "Generation 22: 54.5 s, best val metric 0.8528, [(6, 0.8528, 0.8528, 4.0, 0.04, [20, 43, 31, 77, 52]), (18, 0.8274, 0.8274, 3.2, -0.03, [19, 11, 14, 16, 34]), (18, 0.8274, 0.8274, 3.6, -0.07, [19, 12, 16, 29, 50]), (18, 0.8274, 0.8274, 3.6, -0.07, [19, 12, 16, 29, 50]), (18, 0.8274, 0.8274, 3.6, -0.07, [19, 12, 16, 29, 50]), (18, 0.8274, 0.8274, 3.2, -0.03, [19, 11, 14, 16, 34]), (18, 0.8122, 0.8122, 3.3, -0.07, [19, 13, 14, 16, 40]), (7, 0.8122, 0.8122, 3.9, -0.05, [20, 42, 25, 57, 54]), (18, 0.8122, 0.8122, 3.2, -0.03, [19, 10, 13, 17, 39]), (17, 0.8071, 0.8071, 3.4, 0.06, [20, 32, 18, 43, 49]), (9, 0.802, 0.802, 3.5, -0.02, [20, 22, 20, 35, 47])]\n",
      "Generation 23: 49.5 s, best val metric 0.8528, [(6, 0.8528, 0.8528, 4.0, 0.04, [20, 43, 31, 77, 52]), (19, 0.8173, 0.8173, 3.5, -0.09, [19, 12, 13, 32, 47]), (19, 0.8173, 0.8173, 3.9, -0.07, [19, 20, 22, 36, 54]), (19, 0.8173, 0.8173, 3.5, -0.09, [19, 12, 13, 32, 47]), (19, 0.8122, 0.8122, 3.3, -0.07, [19, 9, 12, 18, 42]), (19, 0.8122, 0.8122, 4.3, -0.04, [33, 32, 36, 49, 70]), (19, 0.8071, 0.8071, 3.3, -0.06, [19, 9, 13, 18, 48]), (18, 0.8071, 0.8071, 3.4, 0.06, [20, 17, 13, 26, 53]), (19, 0.8071, 0.8071, 2.8, -0.08, [19, 9, 11, 14, 30]), (19, 0.8071, 0.8071, 3.3, -0.06, [19, 9, 13, 18, 48]), (19, 0.802, 0.802, 3.3, -0.01, [19, 9, 14, 20, 48])]\n",
      "Generation 24: 49.5 s, best val metric 0.8528, [(6, 0.8528, 0.8528, 4.0, 0.04, [20, 43, 31, 77, 52]), (20, 0.8223, 0.8223, 3.3, -0.06, [18, 9, 11, 14, 57]), (20, 0.8173, 0.8173, 3.5, -0.09, [18, 11, 12, 22, 55]), (20, 0.8173, 0.8173, 4.0, -0.07, [31, 48, 49, 69, 89]), (20, 0.8173, 0.8173, 4.0, -0.07, [31, 48, 49, 69, 89]), (20, 0.8173, 0.8173, 3.5, -0.09, [18, 11, 12, 22, 55]), (20, 0.8173, 0.8173, 3.5, -0.09, [19, 10, 14, 31, 62]), (20, 0.8173, 0.8173, 4.0, -0.07, [31, 48, 49, 69, 89]), (20, 0.8122, 0.8122, 2.8, -0.08, [17, 9, 11, 14, 32]), (20, 0.8122, 0.8122, 3.2, -0.0, [19, 9, 13, 17, 51]), (19, 0.8071, 0.8071, 3.4, 0.06, [19, 12, 13, 20, 52])]\n",
      "Generation 25: 51.7 s, best val metric 0.8528, [(6, 0.8528, 0.8528, 4.0, 0.04, [20, 43, 31, 77, 52]), (20, 0.8122, 0.8122, 3.4, 0.06, [19, 12, 12, 20, 53]), (21, 0.8325, 0.8041, 4.0, -0.07, [26, 45, 49, 88, 103]), (21, 0.8325, 0.8041, 4.0, -0.07, [26, 45, 49, 88, 103]), (21, 0.8325, 0.8041, 4.0, -0.07, [26, 45, 49, 88, 103]), (7, 0.802, 0.802, 3.7, 0.0, [20, 32, 21, 48, 46]), (21, 0.8274, 0.7992, 3.1, -0.05, [16, 9, 12, 19, 55]), (21, 0.8173, 0.7894, 4.0, -0.07, [25, 57, 42, 84, 96]), (21, 0.8122, 0.7845, 4.0, -0.07, [33, 62, 60, 89, 107]), (21, 0.8122, 0.7845, 4.0, -0.07, [33, 62, 60, 89, 107]), (21, 0.797, 0.7698, 3.5, -0.02, [17, 11, 12, 28, 67])]\n",
      "Generation 26: 58.6 s, best val metric 0.8528, [(6, 0.8528, 0.8528, 4.0, 0.04, [20, 43, 31, 77, 52]), (8, 0.8173, 0.8173, 3.7, 0.0, [20, 25, 20, 26, 45]), (8, 0.8173, 0.8173, 3.7, 0.0, [20, 25, 20, 26, 45]), (21, 0.8274, 0.7992, 3.8, -0.05, [19, 21, 12, 37, 69]), (21, 0.8274, 0.7992, 3.8, -0.05, [19, 21, 12, 37, 69]), (7, 0.7817, 0.7817, 4.1, -0.11, [20, 57, 33, 85, 67]), (21, 0.8071, 0.7796, 3.4, 0.06, [19, 10, 11, 21, 54]), (22, 0.8325, 0.7767, 4.4, 0.03, [51, 82, 80, 109, 128]), (22, 0.8274, 0.772, 4.2, 0.02, [17, 29, 32, 39, 75]), (22, 0.8071, 0.7531, 4.0, -0.14, [24, 71, 36, 97, 110]), (22, 0.7868, 0.7341, 2.9, -0.02, [17, 13, 13, 26, 40])]\n",
      "Generation 27: 56.9 s, best val metric 0.8528, [(6, 0.8528, 0.8528, 4.0, 0.04, [20, 43, 31, 77, 52]), (8, 0.8325, 0.8325, 3.2, 0.04, [20, 20, 20, 20, 23]), (8, 0.8325, 0.8325, 3.2, 0.04, [20, 20, 20, 20, 23]), (8, 0.8325, 0.8325, 3.2, 0.04, [20, 20, 20, 20, 23]), (7, 0.8223, 0.8223, 4.0, 0.04, [20, 43, 31, 68, 66]), (7, 0.8223, 0.8223, 4.0, 0.04, [20, 43, 31, 68, 66]), (7, 0.8122, 0.8122, 3.5, 0.03, [20, 23, 20, 25, 25]), (9, 0.8071, 0.8071, 3.7, 0.0, [20, 21, 20, 30, 56]), (9, 0.7868, 0.7868, 3.7, 0.0, [20, 20, 20, 22, 48]), (22, 0.8274, 0.772, 4.5, -0.08, [39, 30, 31, 41, 74]), (22, 0.8071, 0.7531, 3.4, 0.06, [18, 11, 11, 19, 66])]\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "evolution = Evolution()\n",
    "evolution.run(x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test),\n",
    "              batch_size=32, layer_sizes=[20, 20, 20, 20, 20], output_neurons=10, learning_rate=0.0004, n_parents=5, strategy=[0.5, 0.05], \n",
    "              population_size=10, n_generations=50, tournament_size=3, n_introduced=2, age_penalty_period=20, use_static_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0c73dd4430>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 244,
       "width": 366
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [0] + [x[0] for x in evolution.val_metrics]\n",
    "y = [0] + [x[1] for x in evolution.val_metrics]\n",
    "plt.step(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elitism by fitness (immediate selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6447461450184404"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / (1 + 0.005 * 1.8 ** (18 - 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: 41.6 s, best val metric 0.6904, [(1, 0.6904, 0.6904, 2.8, 0.09, [20, 20, 20, 20, 20]), (1, 0.6904, 0.6904, 2.8, 0.09, [20, 20, 20, 20, 20]), (1, 0.6904, 0.6904, 2.8, 0.09, [20, 20, 20, 20, 20]), (1, 0.6853, 0.6853, 2.9, 0.15, [20, 20, 20, 20, 20]), (1, 0.6853, 0.6853, 2.9, 0.15, [20, 20, 20, 20, 20]), (1, 0.6853, 0.6853, 2.9, 0.15, [20, 20, 20, 20, 20]), (1, 0.6853, 0.6853, 2.9, 0.15, [20, 20, 20, 20, 20]), (1, 0.6802, 0.6802, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6751, 0.6751, 3.9, 0.02, [20, 20, 22, 37, 21]), (1, 0.6751, 0.6751, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6751, 0.6751, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 1: 45.8 s, best val metric 0.7919, [(2, 0.7919, 0.7919, 2.7, 0.08, [20, 20, 20, 20, 20]), (2, 0.7919, 0.7919, 2.7, 0.08, [20, 20, 20, 20, 20]), (2, 0.7919, 0.7919, 2.7, 0.08, [20, 20, 20, 20, 20]), (2, 0.7868, 0.7868, 3.6, 0.06, [20, 20, 20, 20, 20]), (2, 0.7868, 0.7868, 2.8, 0.03, [20, 20, 20, 20, 20]), (2, 0.7817, 0.7817, 2.4, 0.09, [20, 20, 20, 20, 20]), (2, 0.7766, 0.7766, 2.9, 0.15, [20, 20, 20, 20, 20]), (2, 0.7665, 0.7665, 2.9, 0.15, [20, 20, 20, 20, 20]), (2, 0.7614, 0.7614, 2.8, 0.09, [20, 20, 20, 20, 20]), (2, 0.7462, 0.7462, 3.4, 0.13, [20, 20, 20, 20, 20]), (2, 0.7462, 0.7462, 3.4, 0.13, [20, 20, 20, 20, 20])]\n",
      "Generation 2: 44.6 s, best val metric 0.797, [(3, 0.797, 0.797, 2.8, 0.16, [20, 20, 20, 20, 20]), (3, 0.797, 0.797, 2.8, 0.16, [20, 20, 20, 20, 20]), (3, 0.7919, 0.7919, 2.9, 0.15, [20, 20, 20, 20, 20]), (3, 0.7919, 0.7919, 2.9, 0.15, [20, 20, 20, 20, 20]), (3, 0.7919, 0.7919, 2.9, 0.15, [20, 20, 20, 20, 20]), (3, 0.7919, 0.7919, 2.8, 0.03, [20, 20, 20, 20, 20]), (3, 0.7919, 0.7919, 2.9, 0.15, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 3.6, 0.06, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 3.4, 0.13, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 2.8, 0.09, [20, 20, 20, 20, 20]), (3, 0.7665, 0.7665, 3.4, 0.13, [20, 20, 20, 20, 20])]\n",
      "Generation 3: 44.1 s, best val metric 0.8071, [(4, 0.8071, 0.8071, 3.5, 0.18, [20, 20, 20, 20, 21]), (4, 0.8071, 0.8071, 3.5, 0.18, [20, 20, 20, 20, 21]), (4, 0.7868, 0.7868, 3.3, 0.2, [20, 20, 20, 20, 20]), (4, 0.7868, 0.7868, 2.9, 0.15, [20, 20, 20, 20, 20]), (4, 0.7868, 0.7868, 3.3, 0.2, [20, 20, 20, 20, 20]), (4, 0.7766, 0.7766, 3.4, -0.05, [20, 20, 20, 20, 20]), (4, 0.7766, 0.7766, 3.4, -0.05, [20, 20, 20, 20, 20]), (4, 0.7563, 0.7563, 2.6, 0.09, [20, 20, 20, 20, 20]), (4, 0.7513, 0.7513, 2.8, 0.16, [20, 20, 20, 20, 20]), (4, 0.7259, 0.7259, 2.8, 0.09, [20, 20, 20, 20, 20]), (4, 0.7157, 0.7157, 2.9, 0.15, [20, 20, 20, 20, 20])]\n",
      "Generation 4: 45.1 s, best val metric 0.8122, [(5, 0.8122, 0.8122, 3.2, 0.27, [20, 20, 20, 20, 20]), (5, 0.8122, 0.8122, 3.3, 0.2, [20, 20, 20, 20, 20]), (5, 0.8122, 0.8122, 3.2, 0.27, [20, 20, 20, 20, 20]), (5, 0.8122, 0.8122, 3.2, 0.27, [20, 20, 20, 20, 20]), (5, 0.8122, 0.8122, 3.2, 0.27, [20, 20, 20, 20, 20]), (5, 0.797, 0.797, 3.8, 0.09, [20, 20, 20, 34, 40]), (5, 0.797, 0.797, 3.8, 0.09, [20, 20, 20, 34, 40]), (5, 0.797, 0.797, 3.0, 0.06, [20, 20, 20, 20, 20]), (5, 0.797, 0.797, 3.0, 0.06, [20, 20, 20, 20, 20]), (5, 0.7868, 0.7868, 2.9, 0.15, [20, 20, 20, 20, 20]), (5, 0.7868, 0.7868, 3.4, 0.15, [20, 20, 20, 20, 22])]\n",
      "Generation 5: 43.9 s, best val metric 0.8122, [(6, 0.8122, 0.8122, 3.8, 0.09, [20, 20, 20, 33, 48]), (6, 0.8122, 0.8122, 3.2, 0.27, [20, 20, 20, 20, 20]), (6, 0.8122, 0.8122, 3.8, 0.09, [20, 20, 20, 33, 48]), (6, 0.8122, 0.8122, 3.8, 0.09, [20, 20, 20, 33, 48]), (6, 0.8071, 0.8071, 4.1, 0.25, [20, 24, 20, 40, 39]), (6, 0.8071, 0.8071, 4.1, 0.25, [20, 24, 20, 40, 39]), (6, 0.802, 0.802, 3.3, 0.2, [20, 20, 20, 20, 20]), (6, 0.7868, 0.7868, 3.4, 0.25, [20, 20, 20, 20, 26]), (6, 0.7868, 0.7868, 3.1, 0.08, [20, 20, 20, 20, 20]), (6, 0.7868, 0.7868, 3.4, 0.25, [20, 20, 20, 20, 26]), (6, 0.7665, 0.7665, 3.2, 0.27, [20, 20, 20, 20, 20])]\n",
      "Generation 6: 46.5 s, best val metric 0.8325, [(7, 0.8325, 0.8325, 3.2, 0.27, [20, 20, 20, 20, 20]), (7, 0.8325, 0.8325, 3.2, 0.27, [20, 20, 20, 20, 20]), (7, 0.8325, 0.8325, 3.2, 0.27, [20, 20, 20, 20, 20]), (7, 0.8274, 0.8274, 4.1, 0.25, [20, 25, 20, 60, 55]), (7, 0.8274, 0.8274, 3.5, 0.26, [20, 20, 20, 22, 24]), (7, 0.8122, 0.8122, 3.4, 0.24, [20, 20, 20, 24, 25]), (7, 0.8122, 0.8122, 3.4, 0.24, [20, 20, 20, 24, 25]), (7, 0.802, 0.802, 3.1, 0.08, [20, 20, 20, 20, 20]), (7, 0.802, 0.802, 3.8, 0.09, [20, 20, 20, 29, 42]), (7, 0.802, 0.802, 3.1, 0.08, [20, 20, 20, 20, 20]), (7, 0.797, 0.797, 3.0, 0.21, [20, 20, 20, 20, 20])]\n",
      "Generation 7: 44.9 s, best val metric 0.8274, [(8, 0.8274, 0.8274, 3.9, 0.24, [20, 20, 20, 69, 58]), (8, 0.8274, 0.8274, 3.9, 0.24, [20, 20, 20, 69, 58]), (8, 0.8274, 0.8274, 3.9, 0.24, [20, 20, 20, 69, 58]), (8, 0.8173, 0.8173, 3.2, 0.27, [20, 19, 20, 20, 20]), (8, 0.8173, 0.8173, 3.4, 0.24, [20, 20, 20, 20, 28]), (8, 0.8173, 0.8173, 3.2, 0.27, [20, 19, 20, 20, 20]), (8, 0.8173, 0.8173, 3.5, 0.23, [20, 20, 20, 22, 34]), (8, 0.8071, 0.8071, 3.8, 0.09, [20, 20, 20, 42, 41]), (8, 0.8071, 0.8071, 3.8, 0.09, [20, 20, 20, 42, 41]), (8, 0.797, 0.797, 3.5, 0.24, [20, 20, 20, 23, 32]), (8, 0.797, 0.797, 3.1, 0.08, [20, 19, 20, 20, 20])]\n",
      "Generation 8: 46.8 s, best val metric 0.8223, [(9, 0.8223, 0.8223, 3.9, 0.24, [20, 23, 20, 77, 68]), (9, 0.8223, 0.8223, 3.9, 0.24, [20, 23, 20, 77, 68]), (9, 0.8122, 0.8122, 3.8, 0.09, [20, 20, 20, 38, 44]), (9, 0.8122, 0.8122, 3.8, 0.09, [20, 20, 20, 38, 44]), (9, 0.8071, 0.8071, 3.1, 0.13, [20, 16, 19, 20, 20]), (9, 0.8071, 0.8071, 3.1, 0.13, [20, 16, 19, 20, 20]), (9, 0.8071, 0.8071, 3.1, 0.13, [20, 16, 19, 20, 20]), (9, 0.8071, 0.8071, 3.1, 0.13, [20, 16, 19, 20, 20]), (9, 0.802, 0.802, 3.4, 0.24, [20, 20, 20, 20, 31]), (9, 0.797, 0.797, 3.5, 0.2, [20, 20, 20, 36, 35]), (9, 0.7919, 0.7919, 4.2, 0.06, [20, 40, 39, 89, 75])]\n",
      "Generation 9: 50.9 s, best val metric 0.8376, [(10, 0.8376, 0.8376, 3.8, 0.09, [20, 20, 20, 50, 54]), (10, 0.8376, 0.8376, 3.8, 0.09, [20, 20, 20, 50, 54]), (10, 0.8376, 0.8376, 3.8, 0.09, [20, 20, 20, 50, 54]), (10, 0.8325, 0.8325, 4.2, 0.06, [20, 58, 58, 109, 95]), (10, 0.8325, 0.8325, 4.2, 0.06, [20, 58, 58, 109, 95]), (10, 0.8223, 0.8223, 3.8, 0.02, [20, 15, 19, 40, 39]), (10, 0.8173, 0.8173, 3.5, 0.16, [20, 20, 20, 23, 50]), (10, 0.8173, 0.8173, 3.5, 0.16, [20, 20, 20, 23, 50]), (10, 0.8122, 0.8122, 3.5, 0.2, [20, 20, 20, 23, 44]), (10, 0.8071, 0.8071, 3.8, 0.09, [20, 20, 20, 35, 53]), (10, 0.797, 0.797, 4.3, 0.07, [20, 59, 55, 109, 93])]\n",
      "Generation 10: 53.6 s, best val metric 0.8325, [(11, 0.8325, 0.7767, 3.5, 0.16, [20, 20, 20, 25, 55]), (11, 0.8325, 0.7767, 3.5, 0.16, [20, 20, 20, 25, 55]), (11, 0.8325, 0.7767, 3.5, 0.16, [20, 20, 20, 25, 55]), (11, 0.8223, 0.7673, 3.5, 0.2, [20, 20, 20, 23, 46]), (11, 0.8173, 0.7625, 3.9, 0.04, [20, 25, 30, 65, 72]), (11, 0.8122, 0.7578, 3.8, 0.09, [20, 20, 20, 31, 60]), (11, 0.8122, 0.7578, 3.8, 0.09, [20, 20, 20, 31, 60]), (11, 0.8122, 0.7578, 3.8, 0.09, [20, 20, 20, 31, 60]), (11, 0.8122, 0.7578, 3.8, 0.09, [20, 20, 20, 55, 58]), (11, 0.8071, 0.7531, 4.3, 0.07, [20, 73, 65, 130, 111]), (11, 0.8071, 0.7531, 5.9, 0.1, [40, 40, 40, 70, 74])]\n",
      "Generation 11: 53.8 s, best val metric 0.8325, [(12, 0.8325, 0.7247, 3.8, 0.09, [20, 20, 20, 39, 63]), (12, 0.8325, 0.7247, 3.8, 0.09, [20, 20, 20, 39, 63]), (12, 0.8325, 0.7247, 3.8, 0.09, [20, 20, 20, 39, 63]), (12, 0.8274, 0.7203, 3.9, 0.04, [20, 24, 26, 79, 71]), (12, 0.8223, 0.7159, 4.0, 0.15, [20, 24, 22, 83, 77]), (12, 0.8173, 0.7115, 3.5, 0.16, [20, 19, 20, 20, 49]), (12, 0.8173, 0.7115, 3.5, 0.16, [20, 19, 20, 20, 54]), (12, 0.8173, 0.7115, 3.5, 0.16, [20, 19, 20, 20, 54]), (12, 0.8122, 0.707, 3.5, 0.2, [20, 20, 20, 21, 47]), (12, 0.8071, 0.7026, 3.9, 0.15, [20, 21, 23, 50, 79]), (12, 0.802, 0.6982, 4.3, 0.07, [20, 85, 63, 153, 128])]\n",
      "Generation 12: 53.9 s, best val metric 0.8274, [(1, 0.6954, 0.6954, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6954, 0.6954, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6954, 0.6954, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6751, 0.6751, 3.0, 0.1, [20, 20, 20, 20, 20]), (13, 0.8274, 0.6721, 3.5, 0.16, [20, 19, 20, 20, 53]), (13, 0.8223, 0.6679, 3.5, 0.2, [20, 20, 20, 32, 47]), (13, 0.8173, 0.6638, 3.1, 0.18, [20, 18, 20, 20, 30]), (13, 0.8071, 0.6556, 3.8, 0.09, [20, 19, 20, 35, 61]), (13, 0.8071, 0.6556, 4.2, 0.14, [20, 40, 40, 59, 82]), (13, 0.8071, 0.6556, 3.8, 0.09, [20, 19, 20, 45, 67]), (13, 0.802, 0.6515, 3.3, 0.24, [20, 18, 20, 22, 58])]\n",
      "Generation 13: 48.3 s, best val metric 0.8122, [(2, 0.7868, 0.7868, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7868, 0.7868, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7868, 0.7868, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7868, 0.7868, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7614, 0.7614, 2.8, 0.18, [20, 20, 20, 20, 20]), (2, 0.731, 0.731, 3.6, 0.17, [20, 20, 20, 20, 20]), (2, 0.731, 0.731, 3.6, 0.17, [20, 20, 20, 20, 20]), (2, 0.7157, 0.7157, 2.3, 0.15, [20, 20, 20, 20, 20]), (14, 0.8122, 0.6155, 3.8, 0.09, [20, 19, 21, 47, 78]), (14, 0.802, 0.6078, 4.2, 0.14, [20, 55, 45, 79, 101]), (14, 0.797, 0.604, 3.1, 0.18, [20, 18, 20, 26, 29])]\n",
      "Generation 14: 46.5 s, best val metric 0.8223, [(3, 0.797, 0.797, 4.2, 0.19, [20, 33, 32, 40, 40]), (3, 0.797, 0.797, 4.2, 0.19, [20, 33, 32, 40, 40]), (3, 0.7766, 0.7766, 2.9, 0.1, [20, 20, 20, 20, 20]), (3, 0.7766, 0.7766, 2.9, 0.1, [20, 20, 20, 20, 20]), (3, 0.7766, 0.7766, 2.9, 0.1, [20, 20, 20, 20, 20]), (3, 0.7766, 0.7766, 2.9, 0.1, [20, 20, 20, 20, 20]), (3, 0.7766, 0.7766, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7614, 0.7614, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7614, 0.7614, 2.7, 0.06, [20, 20, 20, 20, 20]), (3, 0.7563, 0.7563, 3.6, 0.17, [20, 20, 20, 20, 20]), (15, 0.8223, 0.5815, 3.3, 0.07, [20, 16, 20, 20, 34])]\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "evolution = Evolution()\n",
    "evolution.run(x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test),\n",
    "              batch_size=32, layer_sizes=[20, 20, 20, 20, 20], output_neurons=10, learning_rate=0.0004, n_parents=5, strategy=[0.5, 0.05], \n",
    "              population_size=10, n_generations=50, tournament_size=3, n_introduced=2, age_penalty_period=10, use_static_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: 40.7 s, best val metric 0.7005, [(1, 0.7005, 0.7005, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.7005, 0.7005, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.7005, 0.7005, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6701, 0.6701, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6701, 0.6701, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6701, 0.6701, 3.8, 0.11, [20, 20, 20, 21, 20]), (1, 0.6701, 0.6701, 3.8, 0.11, [20, 20, 20, 21, 20]), (1, 0.665, 0.665, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6396, 0.6396, 2.8, 0.04, [20, 20, 20, 20, 20]), (1, 0.6345, 0.6345, 3.0, 0.12, [20, 20, 20, 20, 20]), (1, 0.6345, 0.6345, 3.0, 0.12, [20, 20, 20, 20, 20])]\n",
      "Generation 1: 42.3 s, best val metric 0.7716, [(2, 0.7716, 0.7716, 2.8, 0.06, [20, 20, 20, 20, 20]), (2, 0.7716, 0.7716, 2.8, 0.06, [20, 20, 20, 20, 20]), (2, 0.7716, 0.7716, 2.8, 0.06, [20, 20, 20, 20, 20]), (2, 0.7665, 0.7665, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7614, 0.7614, 3.0, 0.12, [20, 20, 20, 20, 20]), (2, 0.7614, 0.7614, 3.0, 0.12, [20, 20, 20, 20, 20]), (2, 0.7614, 0.7614, 3.0, 0.12, [20, 20, 20, 20, 20]), (2, 0.7563, 0.7563, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7563, 0.7563, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7513, 0.7513, 3.8, 0.11, [20, 20, 20, 21, 20]), (2, 0.7411, 0.7411, 3.6, 0.08, [20, 20, 20, 21, 20])]\n",
      "Generation 2: 43.4 s, best val metric 0.797, [(3, 0.797, 0.797, 2.8, 0.06, [20, 20, 20, 20, 20]), (3, 0.797, 0.797, 2.8, 0.06, [20, 20, 20, 20, 20]), (3, 0.797, 0.797, 2.8, 0.06, [20, 20, 20, 20, 20]), (3, 0.7919, 0.7919, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7919, 0.7919, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7919, 0.7919, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7817, 0.7817, 3.0, 0.12, [20, 20, 20, 20, 20]), (3, 0.7817, 0.7817, 3.0, 0.12, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 2.7, 0.11, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 2.7, 0.11, [20, 20, 20, 20, 20]), (3, 0.7665, 0.7665, 3.0, 0.12, [20, 20, 20, 20, 20])]\n",
      "Generation 3: 46.1 s, best val metric 0.8173, [(4, 0.8173, 0.8173, 3.0, 0.1, [20, 20, 20, 20, 20]), (4, 0.8173, 0.8173, 3.0, 0.1, [20, 20, 20, 20, 20]), (4, 0.8071, 0.8071, 3.4, 0.13, [20, 20, 20, 20, 20]), (4, 0.797, 0.797, 3.0, 0.1, [20, 20, 20, 20, 20]), (4, 0.7868, 0.7868, 2.8, 0.1, [20, 20, 20, 20, 20]), (4, 0.7817, 0.7817, 3.3, 0.09, [20, 20, 20, 20, 20]), (4, 0.7766, 0.7766, 3.0, 0.1, [20, 20, 20, 20, 20]), (4, 0.7766, 0.7766, 3.7, 0.12, [20, 20, 20, 20, 21]), (4, 0.7614, 0.7614, 2.4, 0.16, [20, 20, 20, 20, 20]), (4, 0.7563, 0.7563, 2.7, 0.11, [20, 20, 20, 20, 20]), (4, 0.7513, 0.7513, 3.0, 0.12, [20, 20, 20, 20, 20])]\n",
      "Generation 4: 46.9 s, best val metric 0.8071, [(5, 0.8071, 0.8071, 3.4, 0.15, [20, 20, 20, 20, 21]), (5, 0.8071, 0.8071, 3.4, 0.15, [20, 20, 20, 20, 21]), (5, 0.8071, 0.8071, 3.4, 0.15, [20, 20, 20, 20, 21]), (5, 0.797, 0.797, 3.4, 0.13, [20, 20, 20, 20, 20]), (5, 0.797, 0.797, 3.4, 0.13, [20, 20, 20, 20, 20]), (5, 0.797, 0.797, 2.8, 0.1, [20, 20, 20, 20, 20]), (5, 0.7817, 0.7817, 3.0, 0.1, [20, 20, 20, 20, 20]), (5, 0.7817, 0.7817, 3.0, 0.1, [20, 20, 20, 20, 20]), (5, 0.7817, 0.7817, 3.0, 0.1, [20, 20, 20, 20, 20]), (5, 0.7766, 0.7766, 3.5, 0.11, [20, 20, 20, 20, 22]), (5, 0.7411, 0.7411, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 5: 47.1 s, best val metric 0.8173, [(6, 0.8173, 0.8173, 3.4, 0.13, [20, 20, 20, 20, 20]), (6, 0.8173, 0.8173, 3.4, 0.13, [20, 20, 20, 20, 20]), (6, 0.8173, 0.8173, 3.4, 0.13, [20, 20, 20, 20, 20]), (6, 0.8122, 0.8122, 3.5, 0.11, [20, 20, 20, 20, 22]), (6, 0.8122, 0.8122, 3.5, 0.11, [20, 20, 20, 20, 22]), (6, 0.8122, 0.8122, 3.5, 0.11, [20, 20, 20, 20, 22]), (6, 0.8071, 0.8071, 3.4, 0.15, [20, 20, 20, 20, 22]), (6, 0.802, 0.802, 2.9, -0.01, [20, 20, 20, 20, 20]), (6, 0.7817, 0.7817, 2.8, 0.1, [20, 20, 20, 20, 20]), (6, 0.7817, 0.7817, 3.4, 0.15, [20, 20, 20, 20, 22]), (6, 0.7716, 0.7716, 3.4, 0.26, [20, 20, 20, 20, 25])]\n",
      "Generation 6: 44.7 s, best val metric 0.8173, [(7, 0.8173, 0.8173, 3.5, 0.11, [20, 20, 20, 20, 26]), (7, 0.8173, 0.8173, 3.5, 0.11, [20, 20, 20, 20, 26]), (7, 0.8122, 0.8122, 2.9, 0.11, [20, 20, 20, 20, 20]), (7, 0.8122, 0.8122, 2.9, 0.11, [20, 20, 20, 20, 20]), (7, 0.802, 0.802, 3.5, 0.11, [20, 20, 20, 20, 26]), (7, 0.802, 0.802, 4.0, 0.19, [20, 23, 20, 39, 42]), (7, 0.802, 0.802, 3.4, 0.13, [20, 20, 20, 20, 20]), (7, 0.802, 0.802, 3.5, 0.11, [20, 20, 20, 20, 26]), (7, 0.7919, 0.7919, 3.4, 0.15, [20, 20, 20, 20, 26]), (7, 0.7817, 0.7817, 3.3, 0.06, [20, 20, 20, 20, 20]), (7, 0.7766, 0.7766, 3.2, 0.08, [20, 20, 20, 20, 21])]\n",
      "Generation 7: 46.7 s, best val metric 0.8223, [(8, 0.8223, 0.8223, 4.0, 0.19, [20, 21, 20, 58, 62]), (8, 0.8223, 0.8223, 4.0, 0.19, [20, 21, 20, 58, 62]), (8, 0.8223, 0.8223, 4.0, 0.19, [20, 21, 20, 58, 62]), (8, 0.8173, 0.8173, 3.3, 0.17, [20, 20, 20, 20, 21]), (8, 0.8173, 0.8173, 3.3, 0.17, [20, 20, 20, 20, 21]), (8, 0.8122, 0.8122, 2.9, 0.11, [20, 20, 20, 20, 20]), (8, 0.8071, 0.8071, 3.2, 0.09, [20, 20, 20, 20, 24]), (8, 0.802, 0.802, 4.4, 0.16, [21, 40, 40, 40, 40]), (8, 0.802, 0.802, 4.4, 0.16, [21, 40, 40, 40, 40]), (8, 0.797, 0.797, 3.7, 0.08, [20, 20, 20, 35, 41]), (8, 0.7766, 0.7766, 3.0, 0.07, [20, 20, 20, 20, 21])]\n",
      "Generation 8: 52.3 s, best val metric 0.8274, [(9, 0.8274, 0.8274, 3.3, 0.17, [20, 20, 20, 20, 21]), (9, 0.8274, 0.8274, 3.3, 0.17, [20, 20, 20, 20, 21]), (9, 0.8274, 0.8274, 3.3, 0.17, [20, 20, 20, 20, 21]), (9, 0.8223, 0.8223, 4.0, 0.19, [20, 23, 20, 57, 65]), (9, 0.8223, 0.8223, 4.0, 0.19, [20, 23, 20, 57, 65]), (9, 0.8122, 0.8122, 3.5, 0.12, [20, 22, 28, 36, 41]), (9, 0.8122, 0.8122, 3.3, 0.16, [20, 20, 20, 20, 21]), (9, 0.8122, 0.8122, 3.5, 0.12, [20, 22, 28, 36, 41]), (9, 0.8122, 0.8122, 3.8, 0.18, [20, 20, 20, 49, 61]), (9, 0.8071, 0.8071, 3.3, 0.17, [20, 20, 20, 20, 21]), (9, 0.8071, 0.8071, 3.3, 0.17, [20, 20, 20, 20, 21])]\n",
      "Generation 9: 48.5 s, best val metric 0.8325, [(10, 0.8325, 0.8325, 4.0, 0.19, [20, 24, 20, 56, 63]), (10, 0.8325, 0.8325, 4.0, 0.19, [20, 24, 20, 56, 63]), (10, 0.8325, 0.8325, 4.0, 0.19, [20, 24, 20, 56, 63]), (10, 0.8274, 0.8274, 3.3, 0.14, [20, 20, 20, 20, 23]), (10, 0.8173, 0.8173, 3.3, 0.17, [20, 20, 20, 20, 32]), (10, 0.8173, 0.8173, 3.3, 0.17, [20, 20, 20, 20, 32]), (10, 0.8122, 0.8122, 3.5, 0.12, [20, 20, 20, 20, 36]), (10, 0.8071, 0.8071, 3.3, 0.16, [20, 20, 20, 20, 22]), (10, 0.802, 0.802, 3.3, 0.17, [20, 20, 20, 20, 23]), (10, 0.802, 0.802, 3.4, 0.11, [20, 20, 20, 20, 33]), (10, 0.7868, 0.7868, 3.7, 0.25, [20, 20, 20, 40, 50])]\n",
      "Generation 10: 48.7 s, best val metric 0.8325, [(11, 0.8325, 0.8325, 3.9, 0.21, [20, 20, 21, 39, 51]), (11, 0.8325, 0.8325, 3.9, 0.21, [20, 20, 21, 39, 51]), (11, 0.8274, 0.8274, 3.5, 0.2, [20, 20, 20, 20, 33]), (11, 0.8274, 0.8274, 3.5, 0.2, [20, 20, 20, 20, 33]), (11, 0.8223, 0.8223, 3.8, 0.16, [20, 20, 20, 42, 61]), (11, 0.8223, 0.8223, 3.8, 0.16, [20, 20, 20, 42, 61]), (11, 0.8223, 0.8223, 3.8, 0.16, [20, 20, 20, 42, 61]), (11, 0.8223, 0.8223, 3.8, 0.16, [20, 20, 20, 42, 61]), (11, 0.8173, 0.8173, 3.7, 0.25, [20, 20, 20, 39, 62]), (11, 0.8122, 0.8122, 3.3, 0.17, [20, 19, 20, 20, 33]), (11, 0.8071, 0.8071, 3.3, 0.17, [20, 19, 20, 20, 26])]\n",
      "Generation 11: 48.6 s, best val metric 0.8173, [(12, 0.8173, 0.8173, 4.3, 0.2, [23, 34, 40, 40, 46]), (12, 0.8173, 0.8173, 4.3, 0.2, [23, 34, 40, 40, 46]), (12, 0.8173, 0.8173, 4.3, 0.2, [23, 34, 40, 40, 46]), (12, 0.8122, 0.8122, 3.6, 0.21, [20, 20, 20, 22, 49]), (12, 0.8122, 0.8122, 3.6, 0.21, [20, 20, 20, 22, 49]), (12, 0.8122, 0.8122, 3.8, 0.16, [20, 22, 20, 34, 77]), (12, 0.8122, 0.8122, 3.9, 0.21, [20, 22, 23, 55, 69]), (12, 0.8071, 0.8071, 3.6, 0.21, [20, 19, 20, 31, 58]), (12, 0.8071, 0.8071, 3.2, 0.07, [20, 13, 20, 20, 32]), (12, 0.802, 0.802, 3.1, 0.16, [20, 20, 20, 20, 24]), (12, 0.802, 0.802, 3.3, 0.17, [20, 13, 20, 20, 46])]\n",
      "Generation 12: 51.6 s, best val metric 0.8376, [(13, 0.8376, 0.8376, 3.6, 0.19, [20, 12, 19, 21, 42]), (13, 0.8376, 0.8376, 3.6, 0.19, [20, 12, 19, 21, 42]), (13, 0.8376, 0.8376, 3.6, 0.19, [20, 12, 19, 21, 42]), (13, 0.8325, 0.8325, 3.6, 0.1, [20, 20, 20, 36, 57]), (13, 0.8325, 0.8325, 3.6, 0.1, [20, 20, 20, 36, 57]), (13, 0.8223, 0.8223, 3.2, 0.16, [20, 17, 20, 27, 26]), (13, 0.8223, 0.8223, 3.9, 0.21, [20, 21, 20, 58, 77]), (13, 0.8223, 0.8223, 3.9, 0.21, [20, 21, 20, 58, 77]), (13, 0.8223, 0.8223, 3.9, 0.21, [20, 21, 20, 58, 77]), (13, 0.8223, 0.8223, 3.2, 0.16, [20, 17, 20, 27, 26]), (13, 0.8071, 0.8071, 3.8, 0.16, [20, 20, 20, 32, 74])]\n",
      "Generation 13: 47.6 s, best val metric 0.8274, [(14, 0.8274, 0.8274, 3.6, 0.1, [20, 19, 20, 23, 60]), (14, 0.8274, 0.8274, 3.6, 0.1, [20, 19, 20, 23, 60]), (14, 0.8223, 0.8223, 3.5, 0.25, [20, 18, 20, 35, 65]), (14, 0.8223, 0.8223, 3.5, 0.25, [20, 18, 20, 35, 65]), (14, 0.8223, 0.8223, 3.5, 0.25, [20, 18, 20, 35, 65]), (14, 0.8223, 0.8223, 3.5, 0.25, [20, 18, 20, 35, 65]), (14, 0.8173, 0.8173, 2.7, 0.21, [20, 10, 17, 19, 21]), (14, 0.8173, 0.8173, 2.7, 0.21, [20, 10, 17, 19, 21]), (14, 0.802, 0.802, 3.6, 0.19, [20, 12, 19, 29, 57]), (14, 0.797, 0.797, 3.2, 0.16, [20, 12, 20, 19, 28]), (14, 0.7817, 0.7817, 2.4, 0.14, [20, 10, 18, 18, 20])]\n",
      "Generation 14: 44.9 s, best val metric 0.8122, [(15, 0.8122, 0.8122, 3.5, 0.25, [20, 13, 20, 20, 65]), (15, 0.8122, 0.8122, 3.5, 0.25, [20, 13, 20, 20, 65]), (15, 0.8071, 0.8071, 2.7, 0.21, [20, 8, 14, 15, 21]), (15, 0.8071, 0.8071, 3.7, 0.25, [20, 9, 17, 34, 41]), (15, 0.8071, 0.8071, 3.5, 0.25, [20, 14, 20, 20, 52]), (15, 0.8071, 0.8071, 3.7, 0.25, [20, 9, 17, 34, 41]), (15, 0.8071, 0.8071, 2.7, 0.21, [20, 8, 14, 15, 21]), (15, 0.8071, 0.8071, 3.6, 0.1, [20, 17, 20, 21, 60]), (15, 0.8071, 0.8071, 2.7, 0.21, [20, 8, 14, 15, 21]), (15, 0.802, 0.802, 3.6, 0.19, [20, 12, 19, 25, 71]), (15, 0.802, 0.802, 3.0, 0.17, [20, 8, 15, 18, 24])]\n",
      "Generation 15: 46.5 s, best val metric 0.8325, [(16, 0.8325, 0.8325, 3.1, 0.18, [20, 8, 14, 20, 33]), (16, 0.8325, 0.8325, 3.1, 0.18, [20, 8, 14, 20, 33]), (16, 0.8223, 0.8223, 3.5, 0.25, [20, 12, 20, 20, 50]), (16, 0.8173, 0.8173, 2.7, 0.21, [20, 8, 10, 15, 22]), (16, 0.8173, 0.8173, 2.7, 0.21, [20, 8, 10, 15, 22]), (16, 0.8122, 0.8122, 3.7, 0.25, [20, 10, 16, 42, 60]), (16, 0.8122, 0.8122, 3.7, 0.25, [20, 10, 16, 42, 60]), (16, 0.8071, 0.8071, 3.5, 0.17, [20, 12, 18, 22, 64]), (16, 0.8071, 0.8071, 3.5, 0.25, [20, 12, 20, 20, 65]), (16, 0.802, 0.802, 3.7, 0.29, [20, 15, 20, 26, 67]), (16, 0.797, 0.797, 2.9, 0.13, [20, 10, 16, 19, 40])]\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "evolution = Evolution()\n",
    "evolution.run(x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test),\n",
    "              batch_size=32, layer_sizes=[20, 20, 20, 20, 20], output_neurons=10, learning_rate=0.0004, n_parents=5, strategy=[0.5, 0.05], \n",
    "              population_size=10, n_generations=50, tournament_size=3, n_introduced=2, age_penalty_period=None, use_static_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: 40.9 s, best val metric 0.7157, [(1, 0.7157, 0.7157, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.7157, 0.7157, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6904, 0.6904, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6904, 0.6904, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6904, 0.6904, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6853, 0.6853, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6853, 0.6853, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6853, 0.6853, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6802, 0.6802, 2.9, 0.1, [20, 20, 20, 20, 20]), (1, 0.6751, 0.6751, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6294, 0.6294, 3.2, 0.15, [20, 20, 20, 20, 20])]\n",
      "Generation 1: 46.2 s, best val metric 0.7614, [(2, 0.7614, 0.7614, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7614, 0.7614, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7614, 0.7614, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7614, 0.7614, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7513, 0.7513, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7462, 0.7462, 3.2, 0.15, [20, 20, 20, 20, 20]), (2, 0.7462, 0.7462, 2.7, 0.02, [20, 20, 20, 20, 20]), (2, 0.7411, 0.7411, 3.6, 0.08, [20, 20, 20, 20, 20]), (2, 0.736, 0.736, 2.6, 0.01, [20, 20, 20, 20, 20]), (2, 0.736, 0.736, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7208, 0.7208, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 2: 46.3 s, best val metric 0.7868, [(3, 0.7868, 0.7868, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7868, 0.7868, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7868, 0.7868, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7817, 0.7817, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7766, 0.7766, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7766, 0.7766, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7766, 0.7766, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7766, 0.7766, 3.6, 0.13, [20, 20, 20, 20, 22]), (3, 0.7766, 0.7766, 3.6, 0.13, [20, 20, 20, 20, 22]), (3, 0.7716, 0.7716, 2.4, 0.01, [20, 20, 20, 20, 20]), (3, 0.7563, 0.7563, 3.5, 0.13, [20, 20, 20, 20, 20])]\n",
      "Generation 3: 45.1 s, best val metric 0.8223, [(4, 0.8223, 0.8223, 3.0, 0.11, [20, 20, 20, 20, 20]), (4, 0.8223, 0.8223, 3.0, 0.11, [20, 20, 20, 20, 20]), (4, 0.8223, 0.8223, 3.0, 0.11, [20, 20, 20, 20, 20]), (4, 0.7919, 0.7919, 3.0, 0.1, [20, 20, 20, 20, 20]), (4, 0.7919, 0.7919, 3.4, 0.06, [20, 20, 20, 20, 21]), (4, 0.7919, 0.7919, 3.0, 0.1, [20, 20, 20, 20, 20]), (4, 0.7868, 0.7868, 3.0, 0.1, [20, 20, 20, 20, 20]), (4, 0.7868, 0.7868, 3.0, 0.1, [20, 20, 20, 20, 20]), (4, 0.7817, 0.7817, 2.6, 0.23, [20, 20, 20, 20, 20]), (4, 0.7766, 0.7766, 3.2, 0.15, [20, 20, 20, 20, 20]), (4, 0.7766, 0.7766, 3.6, 0.13, [20, 20, 20, 20, 22])]\n",
      "Generation 4: 46.3 s, best val metric 0.8071, [(5, 0.8071, 0.8071, 3.0, 0.11, [20, 20, 20, 20, 20]), (5, 0.8071, 0.8071, 3.0, 0.11, [20, 20, 20, 20, 20]), (5, 0.802, 0.802, 3.0, 0.11, [20, 20, 20, 20, 20]), (5, 0.802, 0.802, 3.0, 0.11, [20, 20, 20, 20, 20]), (5, 0.802, 0.802, 3.0, 0.1, [20, 20, 20, 20, 20]), (5, 0.802, 0.802, 3.0, 0.1, [20, 20, 20, 20, 20]), (5, 0.797, 0.797, 3.4, 0.06, [20, 20, 20, 21, 21]), (5, 0.797, 0.797, 3.0, 0.11, [20, 20, 20, 20, 20]), (5, 0.7919, 0.7919, 3.0, 0.1, [20, 20, 20, 20, 20]), (5, 0.7817, 0.7817, 3.1, 0.03, [20, 20, 20, 20, 20]), (5, 0.7817, 0.7817, 3.1, 0.03, [20, 20, 20, 20, 20])]\n",
      "Generation 5: 45.3 s, best val metric 0.8122, [(6, 0.8122, 0.8122, 3.0, 0.1, [20, 20, 20, 20, 20]), (6, 0.8122, 0.8122, 3.0, 0.1, [20, 20, 20, 20, 20]), (6, 0.802, 0.802, 3.5, 0.09, [20, 20, 20, 20, 22]), (6, 0.802, 0.802, 2.9, 0.03, [20, 20, 20, 20, 20]), (6, 0.802, 0.802, 2.9, 0.03, [20, 20, 20, 20, 20]), (6, 0.802, 0.802, 2.9, 0.03, [20, 20, 20, 20, 20]), (6, 0.802, 0.802, 2.9, 0.03, [20, 20, 20, 20, 20]), (6, 0.797, 0.797, 3.2, 0.12, [20, 20, 20, 20, 20]), (6, 0.7919, 0.7919, 3.0, 0.11, [20, 20, 20, 20, 20]), (6, 0.7868, 0.7868, 3.0, 0.16, [20, 20, 20, 20, 20]), (6, 0.7868, 0.7868, 3.0, 0.11, [20, 20, 20, 20, 20])]\n",
      "Generation 6: 46.8 s, best val metric 0.797, [(7, 0.797, 0.797, 3.0, 0.1, [20, 20, 20, 20, 20]), (7, 0.797, 0.797, 3.2, 0.12, [20, 20, 20, 20, 20]), (7, 0.797, 0.797, 3.9, 0.07, [20, 22, 21, 38, 38]), (7, 0.797, 0.797, 3.2, 0.12, [20, 20, 20, 20, 20]), (7, 0.797, 0.797, 3.0, 0.1, [20, 20, 20, 20, 20]), (7, 0.7868, 0.7868, 2.9, 0.03, [20, 20, 20, 20, 20]), (7, 0.7868, 0.7868, 2.9, 0.03, [20, 20, 20, 20, 20]), (7, 0.7868, 0.7868, 2.9, 0.03, [20, 20, 20, 20, 20]), (7, 0.7766, 0.7766, 2.9, 0.03, [20, 20, 20, 20, 20]), (7, 0.7665, 0.7665, 3.6, 0.12, [20, 20, 20, 20, 30]), (7, 0.7665, 0.7665, 3.6, 0.12, [20, 20, 20, 20, 30])]\n",
      "Generation 7: 45.7 s, best val metric 0.8071, [(8, 0.8071, 0.8071, 3.4, 0.15, [20, 20, 20, 20, 24]), (8, 0.8071, 0.8071, 3.4, 0.15, [20, 20, 20, 20, 24]), (8, 0.797, 0.797, 2.9, 0.03, [20, 18, 19, 20, 20]), (8, 0.797, 0.797, 2.9, 0.03, [20, 19, 19, 20, 20]), (8, 0.797, 0.797, 2.9, 0.03, [20, 19, 19, 20, 20]), (8, 0.7919, 0.7919, 4.3, 0.02, [20, 38, 38, 40, 50]), (8, 0.7919, 0.7919, 4.3, 0.02, [20, 38, 38, 40, 50]), (8, 0.7919, 0.7919, 4.3, 0.02, [20, 38, 38, 40, 50]), (8, 0.7817, 0.7817, 3.0, 0.1, [20, 20, 20, 20, 20]), (8, 0.7817, 0.7817, 3.6, 0.12, [20, 20, 20, 24, 35]), (8, 0.7817, 0.7817, 3.1, 0.04, [20, 20, 20, 20, 20])]\n",
      "Generation 8: 50.9 s, best val metric 0.8325, [(9, 0.8325, 0.8325, 3.8, 0.08, [20, 21, 20, 36, 43]), (9, 0.8325, 0.8325, 3.8, 0.08, [20, 21, 20, 36, 43]), (9, 0.8325, 0.8325, 3.8, 0.08, [20, 21, 20, 36, 43]), (9, 0.8173, 0.8173, 4.8, -0.0, [38, 58, 58, 60, 70]), (9, 0.8173, 0.8173, 4.8, -0.0, [38, 58, 58, 60, 70]), (9, 0.8122, 0.8122, 3.6, 0.12, [20, 20, 20, 22, 41]), (9, 0.8122, 0.8122, 3.6, 0.12, [20, 20, 20, 22, 41]), (9, 0.8122, 0.8122, 3.6, 0.12, [20, 20, 20, 22, 41]), (9, 0.8071, 0.8071, 4.2, 0.03, [20, 37, 36, 40, 40]), (9, 0.7868, 0.7868, 3.5, 0.04, [20, 19, 19, 19, 34]), (9, 0.7817, 0.7817, 3.4, 0.02, [20, 20, 20, 31, 28])]\n",
      "Generation 9: 53.5 s, best val metric 0.8274, [(10, 0.8274, 0.8274, 3.8, 0.08, [20, 21, 20, 39, 54]), (10, 0.8274, 0.8274, 3.8, 0.08, [20, 21, 20, 39, 54]), (10, 0.8274, 0.8274, 3.8, 0.08, [20, 21, 20, 39, 54]), (10, 0.8173, 0.8173, 3.8, 0.08, [20, 20, 20, 40, 49]), (10, 0.8173, 0.8173, 3.6, 0.01, [20, 19, 19, 21, 44]), (10, 0.8173, 0.8173, 3.6, 0.12, [20, 20, 20, 22, 43]), (10, 0.8122, 0.8122, 4.2, 0.13, [20, 39, 38, 56, 63]), (10, 0.8071, 0.8071, 3.5, 0.04, [20, 19, 18, 19, 37]), (10, 0.8071, 0.8071, 3.5, 0.04, [20, 19, 18, 19, 37]), (10, 0.802, 0.802, 4.2, 0.03, [20, 54, 48, 60, 60]), (10, 0.797, 0.797, 3.9, 0.13, [20, 26, 20, 41, 58])]\n",
      "Generation 10: 51.1 s, best val metric 0.8426, [(11, 0.8426, 0.8351, 3.6, 0.12, [20, 20, 20, 21, 49]), (11, 0.8426, 0.8351, 3.6, 0.12, [20, 20, 20, 21, 49]), (11, 0.8325, 0.8251, 3.9, 0.13, [20, 28, 20, 60, 70]), (11, 0.8325, 0.8251, 3.9, 0.13, [20, 28, 20, 60, 70]), (11, 0.8173, 0.81, 3.8, 0.08, [20, 24, 21, 39, 65]), (11, 0.8173, 0.81, 3.8, 0.08, [20, 24, 21, 39, 65]), (11, 0.8173, 0.81, 3.8, 0.08, [20, 24, 21, 39, 65]), (11, 0.8122, 0.8049, 3.8, 0.08, [20, 21, 20, 38, 59]), (11, 0.8071, 0.7999, 3.5, 0.04, [20, 19, 17, 19, 41]), (11, 0.802, 0.7949, 3.6, 0.01, [20, 19, 17, 19, 46]), (11, 0.802, 0.7949, 4.2, 0.13, [22, 59, 54, 76, 83])]\n",
      "Generation 11: 51.8 s, best val metric 0.8325, [(12, 0.8325, 0.8192, 3.5, 0.04, [20, 18, 16, 19, 44]), (12, 0.8325, 0.8192, 3.5, 0.04, [20, 18, 16, 19, 44]), (12, 0.8325, 0.8192, 3.5, 0.04, [20, 18, 16, 19, 44]), (12, 0.8173, 0.8042, 3.8, 0.08, [20, 20, 20, 36, 75]), (12, 0.8173, 0.8042, 3.8, 0.08, [20, 20, 20, 36, 75]), (12, 0.8173, 0.8042, 3.8, 0.08, [20, 20, 20, 36, 75]), (12, 0.8173, 0.8042, 3.6, 0.12, [20, 20, 19, 20, 51]), (12, 0.8071, 0.7942, 4.2, 0.01, [21, 44, 40, 59, 84]), (12, 0.8071, 0.7942, 4.2, 0.01, [21, 44, 40, 59, 84]), (12, 0.7868, 0.7743, 3.8, 0.08, [20, 21, 20, 36, 70]), (12, 0.7817, 0.7693, 3.8, 0.08, [20, 22, 20, 39, 74])]\n",
      "Generation 12: 49.5 s, best val metric 0.8223, [(13, 0.8223, 0.799, 3.2, -0.03, [20, 20, 18, 19, 36]), (13, 0.8223, 0.799, 3.2, -0.03, [20, 20, 18, 19, 36]), (13, 0.8173, 0.7941, 3.1, 0.12, [20, 16, 15, 18, 29]), (13, 0.8173, 0.7941, 3.4, 0.11, [20, 20, 18, 27, 49]), (13, 0.8173, 0.7941, 3.5, 0.04, [20, 16, 15, 19, 57]), (13, 0.8173, 0.7941, 3.8, 0.08, [20, 28, 20, 42, 85]), (13, 0.8173, 0.7941, 3.1, 0.12, [20, 16, 15, 18, 29]), (13, 0.8173, 0.7941, 3.1, 0.12, [20, 16, 15, 18, 29]), (13, 0.8122, 0.7892, 3.8, 0.03, [20, 17, 16, 39, 60]), (13, 0.8122, 0.7892, 3.5, -0.0, [20, 20, 20, 22, 62]), (13, 0.8071, 0.7842, 3.5, 0.04, [20, 17, 15, 19, 41])]\n",
      "Generation 13: 45.9 s, best val metric 0.8274, [(14, 0.8274, 0.7861, 3.5, -0.0, [20, 20, 19, 21, 64]), (14, 0.8274, 0.7861, 3.5, -0.0, [20, 20, 19, 21, 64]), (14, 0.8173, 0.7765, 3.3, 0.11, [20, 16, 14, 18, 39]), (14, 0.8173, 0.7765, 4.1, 0.05, [20, 48, 38, 62, 105]), (14, 0.8173, 0.7765, 3.2, 0.02, [20, 15, 14, 17, 31]), (14, 0.8173, 0.7765, 4.1, 0.05, [20, 48, 38, 62, 105]), (14, 0.8173, 0.7765, 4.1, 0.05, [20, 48, 38, 62, 105]), (14, 0.8071, 0.7669, 3.9, -0.03, [20, 29, 22, 39, 76]), (14, 0.802, 0.762, 3.1, 0.12, [20, 15, 13, 17, 27]), (14, 0.802, 0.762, 3.8, 0.08, [20, 26, 20, 42, 87]), (14, 0.797, 0.7572, 3.8, 0.03, [20, 30, 17, 51, 79])]\n",
      "Generation 14: 54.5 s, best val metric 0.8325, [(15, 0.8325, 0.7606, 4.1, 0.05, [20, 66, 50, 80, 122]), (15, 0.8325, 0.7606, 4.1, 0.05, [22, 68, 51, 82, 121]), (15, 0.8325, 0.7606, 4.1, 0.05, [20, 66, 50, 80, 122]), (15, 0.8223, 0.7513, 3.8, 0.03, [20, 31, 16, 45, 86]), (15, 0.8223, 0.7513, 3.8, 0.03, [20, 31, 16, 45, 86]), (15, 0.8223, 0.7513, 3.8, 0.03, [20, 31, 16, 45, 86]), (15, 0.8071, 0.7374, 4.6, -0.01, [40, 68, 58, 82, 126]), (15, 0.8071, 0.7374, 3.3, 0.11, [20, 15, 13, 18, 38]), (15, 0.8071, 0.7374, 3.9, 0.05, [20, 38, 24, 49, 94]), (15, 0.8071, 0.7374, 3.2, 0.02, [19, 15, 12, 17, 34]), (15, 0.7817, 0.7142, 3.9, 0.04, [20, 34, 25, 37, 47])]\n",
      "Generation 15: 59.3 s, best val metric 0.8274, [(1, 0.7157, 0.7157, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.7157, 0.7157, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.7157, 0.7157, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.7157, 0.7157, 3.0, 0.1, [20, 20, 20, 20, 20]), (16, 0.8274, 0.7072, 3.2, 0.01, [18, 15, 11, 17, 37]), (16, 0.8223, 0.7028, 4.7, 0.15, [40, 51, 36, 65, 106]), (16, 0.8223, 0.7028, 3.9, 0.05, [24, 76, 57, 82, 106]), (16, 0.8223, 0.7028, 3.9, 0.05, [24, 76, 57, 82, 106]), (16, 0.8223, 0.7028, 4.1, 0.05, [31, 78, 55, 97, 140]), (1, 0.6954, 0.6954, 3.0, 0.1, [20, 20, 20, 20, 20]), (16, 0.802, 0.6855, 4.6, -0.01, [59, 88, 78, 102, 150])]\n",
      "Generation 16: 59.0 s, best val metric 0.7919, [(2, 0.7919, 0.7919, 4.0, 0.12, [20, 20, 20, 28, 21]), (2, 0.7919, 0.7919, 4.0, 0.12, [20, 20, 20, 28, 21]), (2, 0.7919, 0.7919, 4.0, 0.12, [20, 20, 20, 28, 21]), (2, 0.7919, 0.7919, 4.0, 0.12, [20, 20, 20, 28, 21]), (2, 0.7919, 0.7919, 4.0, 0.12, [20, 20, 20, 28, 21]), (2, 0.7817, 0.7817, 3.3, 0.04, [20, 20, 20, 20, 20]), (2, 0.7716, 0.7716, 2.8, 0.12, [20, 20, 20, 20, 20]), (2, 0.7716, 0.7716, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7614, 0.7614, 4.1, 0.15, [20, 20, 20, 24, 22]), (2, 0.7563, 0.7563, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6701, 0.6701, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 17: 44.3 s, best val metric 0.797, [(3, 0.797, 0.797, 4.0, 0.12, [20, 22, 20, 32, 32]), (3, 0.797, 0.797, 4.0, 0.12, [20, 22, 20, 32, 32]), (3, 0.7919, 0.7919, 4.0, 0.12, [20, 20, 20, 36, 25]), (3, 0.7766, 0.7766, 4.5, 0.03, [26, 40, 38, 44, 42]), (3, 0.7766, 0.7766, 4.0, 0.12, [20, 20, 20, 32, 22]), (3, 0.7716, 0.7716, 2.8, 0.12, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 2.6, 0.06, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 3.1, 0.16, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 2.6, 0.06, [20, 20, 20, 20, 20]), (3, 0.7665, 0.7665, 2.9, 0.08, [20, 20, 20, 20, 20]), (3, 0.7614, 0.7614, 3.7, 0.12, [20, 20, 20, 20, 20])]\n",
      "Generation 18: 44.6 s, best val metric 0.8274, [(4, 0.8274, 0.8274, 2.8, 0.12, [20, 20, 20, 20, 20]), (4, 0.8274, 0.8274, 2.8, 0.12, [20, 20, 20, 20, 20]), (4, 0.8274, 0.8274, 2.8, 0.12, [20, 20, 20, 20, 20]), (4, 0.8122, 0.8122, 3.7, 0.12, [20, 21, 20, 20, 27]), (4, 0.8122, 0.8122, 3.7, 0.12, [20, 21, 20, 20, 27]), (4, 0.8122, 0.8122, 3.6, 0.19, [20, 20, 20, 20, 21]), (4, 0.8122, 0.8122, 3.7, 0.12, [20, 21, 20, 20, 27]), (4, 0.8071, 0.8071, 4.0, 0.12, [20, 26, 20, 33, 35]), (4, 0.797, 0.797, 4.0, 0.12, [20, 25, 20, 49, 32]), (4, 0.7919, 0.7919, 4.0, 0.12, [20, 30, 20, 32, 36]), (4, 0.7817, 0.7817, 2.9, 0.08, [20, 20, 20, 20, 20])]\n",
      "Generation 19: 45.6 s, best val metric 0.8122, [(5, 0.8122, 0.8122, 3.2, 0.13, [20, 20, 20, 20, 20]), (5, 0.8122, 0.8122, 3.2, 0.13, [20, 20, 20, 20, 20]), (5, 0.8122, 0.8122, 3.7, 0.12, [20, 20, 20, 25, 27]), (5, 0.8122, 0.8122, 3.7, 0.12, [20, 20, 20, 25, 27]), (5, 0.8122, 0.8122, 3.2, 0.13, [20, 20, 20, 20, 20]), (5, 0.8071, 0.8071, 2.8, 0.12, [20, 20, 20, 20, 20]), (5, 0.802, 0.802, 3.2, 0.14, [20, 20, 20, 20, 20]), (5, 0.802, 0.802, 3.2, 0.14, [20, 20, 20, 20, 20]), (5, 0.802, 0.802, 3.2, 0.14, [20, 20, 20, 20, 20]), (5, 0.802, 0.802, 3.9, 0.14, [20, 33, 20, 27, 40]), (5, 0.7919, 0.7919, 3.6, 0.11, [20, 20, 20, 20, 21])]\n",
      "Generation 20: 46.6 s, best val metric 0.8173, [(6, 0.8173, 0.8173, 3.2, 0.14, [20, 20, 20, 20, 20]), (6, 0.8173, 0.8173, 3.2, 0.13, [20, 20, 20, 20, 20]), (6, 0.8173, 0.8173, 3.1, 0.1, [20, 20, 20, 20, 20]), (6, 0.8173, 0.8173, 3.2, 0.14, [20, 20, 20, 20, 20]), (6, 0.8173, 0.8173, 3.2, 0.13, [20, 20, 20, 20, 20]), (6, 0.8173, 0.8173, 3.2, 0.14, [20, 20, 20, 20, 20]), (6, 0.8071, 0.8071, 3.7, 0.12, [20, 20, 20, 24, 38]), (6, 0.802, 0.802, 3.5, 0.11, [20, 20, 20, 20, 21]), (6, 0.802, 0.802, 3.5, 0.11, [20, 20, 20, 20, 21]), (6, 0.7817, 0.7817, 3.7, 0.12, [20, 20, 20, 23, 40]), (6, 0.7716, 0.7716, 3.2, 0.14, [20, 20, 20, 20, 20])]\n",
      "Generation 21: 45.1 s, best val metric 0.8274, [(7, 0.8274, 0.8274, 3.8, 0.15, [20, 20, 20, 31, 39]), (7, 0.8274, 0.8274, 3.8, 0.15, [20, 20, 20, 31, 39]), (7, 0.8274, 0.8274, 3.8, 0.15, [20, 20, 20, 31, 39]), (7, 0.8173, 0.8173, 3.2, 0.19, [20, 20, 20, 20, 24]), (7, 0.8122, 0.8122, 3.2, 0.13, [20, 20, 20, 20, 20]), (7, 0.8071, 0.8071, 3.5, 0.11, [20, 20, 20, 20, 21]), (7, 0.8071, 0.8071, 3.5, 0.11, [20, 20, 20, 20, 21]), (7, 0.8071, 0.8071, 3.5, 0.11, [20, 20, 20, 20, 24]), (7, 0.802, 0.802, 3.2, 0.12, [20, 20, 20, 20, 21]), (7, 0.802, 0.802, 3.2, 0.14, [20, 20, 20, 20, 20]), (7, 0.7766, 0.7766, 3.1, 0.1, [20, 20, 20, 20, 20])]\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "evolution = Evolution()\n",
    "evolution.run(x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test),\n",
    "              batch_size=32, layer_sizes=[20, 20, 20, 20, 20], output_neurons=10, learning_rate=0.0004, n_parents=5, strategy=[0.5, 0.05], \n",
    "              population_size=10, n_generations=50, tournament_size=3, n_introduced=2, age_penalty_period=10, use_static_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: 40.7 s, best val metric 0.7005, [(1, 0.7005, 0.7005, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.7005, 0.7005, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6904, 0.6904, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6904, 0.6904, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6802, 0.6802, 3.8, 0.09, [20, 20, 20, 34, 20]), (1, 0.6802, 0.6802, 3.8, 0.09, [20, 20, 20, 34, 20]), (1, 0.6701, 0.6701, 3.2, 0.16, [20, 20, 20, 20, 20]), (1, 0.6701, 0.6701, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6701, 0.6701, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6548, 0.6548, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6497, 0.6497, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 1: 44.7 s, best val metric 0.7665, [(2, 0.7665, 0.7665, 4.0, 0.14, [20, 20, 20, 23, 22]), (2, 0.7665, 0.7665, 4.0, 0.14, [20, 20, 20, 23, 22]), (2, 0.7614, 0.7614, 2.8, 0.07, [20, 20, 20, 26, 20]), (2, 0.7614, 0.7614, 2.8, 0.07, [20, 20, 20, 26, 20]), (2, 0.7513, 0.7513, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7513, 0.7513, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7462, 0.7462, 3.8, 0.09, [20, 20, 20, 33, 22]), (2, 0.7462, 0.7462, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7462, 0.7462, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7411, 0.7411, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7411, 0.7411, 2.8, 0.03, [20, 20, 20, 22, 20])]\n",
      "Generation 2: 44.4 s, best val metric 0.802, [(3, 0.802, 0.802, 3.3, 0.05, [20, 20, 20, 20, 20]), (3, 0.802, 0.802, 3.3, 0.05, [20, 20, 20, 20, 20]), (3, 0.7868, 0.7868, 3.5, 0.07, [20, 20, 20, 20, 20]), (3, 0.7868, 0.7868, 2.8, 0.07, [20, 20, 20, 20, 20]), (3, 0.7868, 0.7868, 3.5, 0.07, [20, 20, 20, 20, 20]), (3, 0.7868, 0.7868, 3.5, 0.07, [20, 20, 20, 20, 20]), (3, 0.7766, 0.7766, 3.4, 0.07, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 4.0, 0.14, [20, 20, 20, 25, 33]), (3, 0.7716, 0.7716, 4.0, 0.14, [20, 20, 20, 25, 33]), (3, 0.7716, 0.7716, 4.0, 0.14, [20, 20, 20, 25, 33]), (3, 0.7614, 0.7614, 2.8, 0.07, [20, 20, 20, 20, 20])]\n",
      "Generation 3: 46.2 s, best val metric 0.8122, [(4, 0.8122, 0.8122, 3.7, 0.06, [20, 20, 20, 23, 25]), (4, 0.8122, 0.8122, 3.7, 0.06, [20, 20, 20, 23, 25]), (4, 0.802, 0.802, 3.6, 0.06, [20, 20, 20, 20, 22]), (4, 0.797, 0.797, 3.2, 0.06, [20, 20, 20, 20, 20]), (4, 0.797, 0.797, 3.0, 0.17, [20, 20, 20, 20, 20]), (4, 0.797, 0.797, 3.0, 0.17, [20, 20, 20, 20, 20]), (4, 0.7919, 0.7919, 3.3, 0.13, [20, 20, 20, 20, 20]), (4, 0.7868, 0.7868, 4.3, 0.08, [20, 39, 33, 40, 40]), (4, 0.7868, 0.7868, 3.5, 0.07, [20, 20, 20, 20, 20]), (4, 0.7817, 0.7817, 3.4, 0.07, [20, 20, 20, 20, 20]), (4, 0.7766, 0.7766, 4.0, 0.14, [20, 20, 20, 27, 30])]\n",
      "Generation 4: 46.3 s, best val metric 0.802, [(5, 0.802, 0.802, 4.0, 0.14, [20, 23, 20, 30, 41]), (5, 0.802, 0.802, 4.0, 0.14, [20, 23, 20, 30, 41]), (5, 0.802, 0.802, 3.2, 0.06, [20, 20, 20, 20, 20]), (5, 0.802, 0.802, 3.0, 0.17, [20, 20, 20, 20, 20]), (5, 0.802, 0.802, 3.0, 0.17, [20, 20, 20, 20, 20]), (5, 0.802, 0.802, 4.0, 0.14, [20, 23, 20, 30, 41]), (5, 0.797, 0.797, 3.7, 0.14, [20, 20, 20, 21, 29]), (5, 0.7919, 0.7919, 3.3, 0.09, [20, 20, 20, 20, 20]), (5, 0.7919, 0.7919, 4.1, 0.12, [20, 33, 30, 40, 35]), (5, 0.7919, 0.7919, 3.3, 0.09, [20, 20, 20, 20, 20]), (5, 0.7665, 0.7665, 4.0, -0.02, [20, 21, 20, 26, 31])]\n",
      "Generation 5: 47.3 s, best val metric 0.8223, [(6, 0.8223, 0.8223, 4.7, 0.06, [23, 40, 40, 40, 40]), (6, 0.8223, 0.8223, 4.7, 0.06, [23, 40, 40, 40, 40]), (6, 0.8071, 0.8071, 2.8, 0.09, [20, 20, 20, 20, 20]), (6, 0.8071, 0.8071, 2.8, 0.09, [20, 20, 20, 20, 20]), (6, 0.8071, 0.8071, 2.8, 0.09, [20, 20, 20, 20, 20]), (6, 0.802, 0.802, 3.2, 0.06, [20, 20, 20, 20, 20]), (6, 0.797, 0.797, 3.4, 0.1, [20, 20, 20, 21, 26]), (6, 0.797, 0.797, 4.1, 0.12, [20, 48, 35, 59, 55]), (6, 0.797, 0.797, 4.1, 0.12, [20, 48, 35, 59, 55]), (6, 0.797, 0.797, 3.4, 0.1, [20, 20, 20, 21, 26]), (6, 0.7919, 0.7919, 3.3, 0.09, [20, 20, 20, 20, 20])]\n",
      "Generation 6: 49.4 s, best val metric 0.8173, [(7, 0.8173, 0.8173, 3.3, 0.09, [20, 20, 20, 20, 20]), (7, 0.8173, 0.8173, 3.3, 0.09, [20, 20, 20, 20, 20]), (7, 0.8122, 0.8122, 4.7, 0.06, [29, 60, 60, 60, 60]), (7, 0.8122, 0.8122, 4.7, 0.06, [29, 60, 60, 60, 60]), (7, 0.8122, 0.8122, 4.7, 0.06, [29, 60, 60, 60, 60]), (7, 0.8071, 0.8071, 3.9, 0.15, [20, 20, 20, 40, 40]), (7, 0.802, 0.802, 4.3, 0.08, [20, 60, 49, 79, 75]), (7, 0.802, 0.802, 3.9, -0.0, [20, 22, 20, 22, 31]), (7, 0.802, 0.802, 4.3, 0.08, [20, 60, 49, 79, 75]), (7, 0.802, 0.802, 3.5, 0.1, [20, 20, 20, 40, 28]), (7, 0.7868, 0.7868, 4.1, 0.12, [20, 55, 28, 75, 62])]\n",
      "Generation 7: 56.1 s, best val metric 0.8223, [(8, 0.8223, 0.8223, 3.1, 0.06, [20, 20, 20, 23, 20]), (8, 0.8223, 0.8223, 3.1, 0.06, [20, 20, 20, 23, 20]), (8, 0.8223, 0.8223, 3.1, 0.06, [20, 20, 20, 23, 20]), (8, 0.8122, 0.8122, 4.0, 0.19, [20, 60, 50, 72, 60]), (8, 0.8122, 0.8122, 4.7, 0.06, [38, 80, 80, 80, 80]), (8, 0.8071, 0.8071, 3.9, 0.1, [20, 20, 20, 40, 43]), (8, 0.7919, 0.7919, 4.0, 0.06, [20, 34, 34, 40, 39]), (8, 0.7919, 0.7919, 4.3, 0.08, [20, 78, 61, 99, 91]), (8, 0.7919, 0.7919, 4.0, 0.06, [20, 34, 34, 40, 39]), (8, 0.7868, 0.7868, 3.3, 0.09, [20, 20, 20, 20, 21]), (8, 0.7665, 0.7665, 4.7, 0.06, [42, 80, 80, 80, 80])]\n",
      "Generation 8: 59.9 s, best val metric 0.8325, [(9, 0.8325, 0.8325, 3.3, 0.15, [20, 20, 20, 20, 20]), (9, 0.8325, 0.8325, 3.3, 0.15, [20, 20, 20, 20, 20]), (9, 0.8122, 0.8122, 3.8, 0.06, [20, 34, 21, 47, 45]), (9, 0.8122, 0.8122, 3.3, 0.09, [20, 20, 20, 20, 24]), (9, 0.8122, 0.8122, 3.8, 0.06, [20, 34, 21, 47, 45]), (9, 0.8071, 0.8071, 3.6, 0.02, [20, 21, 20, 41, 35]), (9, 0.8071, 0.8071, 3.6, 0.02, [20, 21, 20, 41, 35]), (9, 0.8071, 0.8071, 3.1, 0.06, [20, 20, 20, 20, 20]), (9, 0.8071, 0.8071, 3.1, 0.06, [20, 20, 20, 20, 20]), (9, 0.802, 0.802, 4.1, 0.1, [35, 87, 74, 93, 77]), (9, 0.7817, 0.7817, 4.0, 0.06, [20, 44, 23, 59, 59])]\n",
      "Generation 9: 52.2 s, best val metric 0.8274, [(10, 0.8274, 0.8274, 3.8, 0.06, [20, 36, 20, 53, 52]), (10, 0.8274, 0.8274, 3.8, 0.06, [20, 36, 20, 53, 52]), (10, 0.8274, 0.8274, 3.8, 0.06, [20, 36, 20, 53, 52]), (10, 0.8223, 0.8223, 3.6, 0.02, [20, 21, 20, 24, 34]), (10, 0.8173, 0.8173, 3.3, 0.04, [20, 20, 20, 23, 37]), (10, 0.8122, 0.8122, 4.0, 0.06, [20, 29, 21, 64, 66]), (10, 0.797, 0.797, 3.1, 0.13, [20, 20, 20, 20, 20]), (10, 0.7919, 0.7919, 4.1, -0.05, [20, 39, 37, 40, 40]), (10, 0.7919, 0.7919, 3.6, 0.02, [20, 21, 20, 24, 41]), (10, 0.7919, 0.7919, 3.6, 0.02, [20, 21, 20, 24, 41]), (10, 0.7868, 0.7868, 3.8, 0.06, [20, 27, 20, 43, 47])]\n",
      "Generation 10: 49.8 s, best val metric 0.8223, [(11, 0.8223, 0.8223, 3.8, 0.06, [20, 20, 20, 38, 43]), (11, 0.8223, 0.8223, 3.8, 0.06, [20, 20, 20, 38, 43]), (11, 0.8223, 0.8223, 3.8, 0.06, [20, 20, 20, 38, 43]), (11, 0.8223, 0.8223, 3.8, 0.06, [20, 20, 20, 38, 43]), (11, 0.8122, 0.8122, 3.8, 0.06, [20, 30, 21, 54, 66]), (11, 0.8122, 0.8122, 3.5, 0.09, [20, 20, 20, 36, 40]), (11, 0.8071, 0.8071, 3.6, -0.1, [20, 23, 20, 28, 47]), (11, 0.8071, 0.8071, 3.8, 0.06, [20, 25, 20, 37, 55]), (11, 0.8071, 0.8071, 3.8, 0.06, [20, 25, 20, 37, 55]), (11, 0.8071, 0.8071, 3.8, 0.06, [20, 25, 20, 37, 55]), (11, 0.797, 0.797, 3.3, 0.04, [20, 20, 20, 20, 28])]\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "evolution = Evolution()\n",
    "evolution.run(x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test),\n",
    "              batch_size=32, layer_sizes=[20, 20, 20, 20, 20], output_neurons=10, learning_rate=0.0004, n_parents=5, strategy=[0.5, 0.05], \n",
    "              population_size=10, n_generations=50, tournament_size=3, n_introduced=2, age_penalty_period=20, use_static_graph=False,\n",
    "              mutation_strength=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: 39.6 s, best val metric 0.7157, [(1, 0.7157, 0.7157, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.7157, 0.7157, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.7157, 0.7157, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6853, 0.6853, 3.0, 0.06, [20, 20, 20, 20, 20]), (1, 0.6853, 0.6853, 3.0, 0.06, [20, 20, 20, 20, 20]), (1, 0.6853, 0.6853, 3.0, 0.06, [20, 20, 20, 20, 20]), (1, 0.6853, 0.6853, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6802, 0.6802, 3.1, 0.08, [20, 20, 20, 20, 20]), (1, 0.6802, 0.6802, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6751, 0.6751, 2.8, 0.08, [20, 20, 20, 20, 20]), (1, 0.6447, 0.6447, 3.2, 0.11, [20, 20, 20, 20, 20])]\n",
      "Generation 1: 43.8 s, best val metric 0.7766, [(2, 0.7766, 0.7766, 3.0, 0.06, [20, 20, 20, 20, 20]), (2, 0.7766, 0.7766, 3.0, 0.06, [20, 20, 20, 20, 20]), (2, 0.7766, 0.7766, 3.0, 0.06, [20, 20, 20, 20, 20]), (2, 0.7716, 0.7716, 3.0, 0.06, [20, 20, 20, 20, 20]), (2, 0.7665, 0.7665, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7665, 0.7665, 3.1, 0.01, [20, 20, 20, 20, 20]), (2, 0.7614, 0.7614, 2.8, 0.03, [20, 20, 20, 20, 20]), (2, 0.7614, 0.7614, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7563, 0.7563, 2.4, 0.03, [20, 20, 20, 20, 20]), (2, 0.7563, 0.7563, 2.4, 0.03, [20, 20, 20, 20, 20]), (2, 0.736, 0.736, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 2: 44.6 s, best val metric 0.7919, [(3, 0.7919, 0.7919, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7919, 0.7919, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7919, 0.7919, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7868, 0.7868, 3.2, 0.16, [20, 20, 20, 20, 20]), (3, 0.7868, 0.7868, 3.2, 0.16, [20, 20, 20, 20, 20]), (3, 0.7868, 0.7868, 3.2, 0.16, [20, 20, 20, 20, 20]), (3, 0.7868, 0.7868, 3.2, 0.16, [20, 20, 20, 20, 20]), (3, 0.7766, 0.7766, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7766, 0.7766, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 2.7, 0.06, [20, 20, 20, 20, 20]), (3, 0.7563, 0.7563, 2.8, 0.03, [20, 20, 20, 20, 20])]\n",
      "Generation 3: 45.0 s, best val metric 0.8071, [(4, 0.8071, 0.8071, 3.4, 0.16, [20, 20, 20, 20, 20]), (4, 0.8071, 0.8071, 3.4, 0.16, [20, 20, 20, 20, 20]), (4, 0.802, 0.802, 3.3, 0.16, [20, 20, 20, 20, 20]), (4, 0.802, 0.802, 3.3, 0.16, [20, 20, 20, 20, 20]), (4, 0.797, 0.797, 3.3, 0.08, [20, 20, 20, 20, 20]), (4, 0.797, 0.797, 3.3, 0.08, [20, 20, 20, 20, 20]), (4, 0.7868, 0.7868, 3.0, 0.1, [20, 20, 20, 20, 20]), (4, 0.7817, 0.7817, 3.6, 0.19, [20, 20, 20, 20, 21]), (4, 0.7766, 0.7766, 2.7, 0.06, [20, 20, 20, 20, 20]), (4, 0.7665, 0.7665, 3.5, 0.16, [20, 20, 20, 20, 20]), (4, 0.7665, 0.7665, 3.5, 0.16, [20, 20, 20, 20, 20])]\n",
      "Generation 4: 44.6 s, best val metric 0.797, [(5, 0.797, 0.797, 3.7, 0.16, [20, 20, 20, 25, 28]), (5, 0.797, 0.797, 3.7, 0.16, [20, 20, 20, 25, 28]), (5, 0.7919, 0.7919, 3.7, 0.07, [20, 20, 20, 20, 21]), (5, 0.7868, 0.7868, 3.2, 0.18, [20, 20, 20, 20, 20]), (5, 0.7868, 0.7868, 3.6, 0.19, [20, 20, 20, 20, 20]), (5, 0.7868, 0.7868, 3.6, 0.19, [20, 20, 20, 20, 20]), (5, 0.7868, 0.7868, 3.6, 0.19, [20, 20, 20, 20, 20]), (5, 0.7817, 0.7817, 3.4, 0.16, [20, 20, 20, 20, 20]), (5, 0.7817, 0.7817, 3.3, 0.16, [20, 20, 20, 20, 20]), (5, 0.7817, 0.7817, 3.5, 0.16, [20, 20, 20, 20, 20]), (5, 0.7665, 0.7665, 2.7, 0.06, [20, 20, 20, 20, 20])]\n",
      "Generation 5: 47.3 s, best val metric 0.8122, [(6, 0.8122, 0.8122, 3.7, 0.16, [20, 20, 20, 22, 42]), (6, 0.8122, 0.8122, 3.7, 0.16, [20, 20, 20, 22, 42]), (6, 0.8122, 0.8122, 3.7, 0.16, [20, 20, 20, 22, 42]), (6, 0.8122, 0.8122, 3.7, 0.16, [20, 20, 20, 22, 42]), (6, 0.8071, 0.8071, 3.4, 0.2, [20, 20, 20, 20, 23]), (6, 0.8071, 0.8071, 3.4, 0.2, [20, 20, 20, 20, 23]), (6, 0.802, 0.802, 3.6, 0.19, [20, 20, 20, 20, 20]), (6, 0.797, 0.797, 3.4, 0.16, [20, 20, 20, 20, 20]), (6, 0.7919, 0.7919, 3.7, 0.16, [20, 20, 20, 22, 30]), (6, 0.7919, 0.7919, 3.9, 0.13, [20, 22, 20, 35, 35]), (6, 0.7766, 0.7766, 4.4, 0.14, [21, 39, 39, 40, 40])]\n",
      "Generation 6: 48.2 s, best val metric 0.8071, [(7, 0.8071, 0.8071, 3.6, 0.19, [20, 20, 20, 22, 43]), (7, 0.8071, 0.8071, 3.6, 0.19, [20, 20, 20, 22, 43]), (7, 0.8071, 0.8071, 3.6, 0.19, [20, 20, 20, 22, 43]), (7, 0.8071, 0.8071, 3.6, 0.19, [20, 20, 20, 22, 43]), (7, 0.802, 0.802, 3.4, 0.13, [20, 20, 20, 20, 27]), (7, 0.802, 0.802, 3.4, 0.2, [20, 20, 20, 20, 26]), (7, 0.797, 0.797, 3.3, 0.13, [20, 20, 20, 20, 20]), (7, 0.7919, 0.7919, 3.9, 0.13, [20, 25, 20, 53, 49]), (7, 0.7868, 0.7868, 4.4, 0.14, [21, 59, 58, 60, 60]), (7, 0.7817, 0.7817, 3.1, 0.08, [20, 20, 20, 20, 21]), (7, 0.7766, 0.7766, 4.0, 0.1, [20, 20, 23, 40, 43])]\n",
      "Generation 7: 48.5 s, best val metric 0.8274, [(8, 0.8274, 0.8274, 3.6, 0.2, [20, 20, 20, 20, 34]), (8, 0.8274, 0.8274, 3.6, 0.2, [20, 20, 20, 20, 34]), (8, 0.8173, 0.8173, 3.7, 0.15, [20, 20, 20, 20, 50]), (8, 0.8122, 0.8122, 4.4, 0.14, [20, 74, 75, 80, 78]), (8, 0.8071, 0.8071, 4.5, 0.22, [23, 40, 40, 40, 47]), (8, 0.802, 0.802, 3.6, 0.19, [20, 20, 20, 21, 39]), (8, 0.802, 0.802, 3.6, 0.19, [20, 20, 20, 21, 39]), (8, 0.802, 0.802, 4.0, 0.1, [20, 22, 20, 46, 55]), (8, 0.797, 0.797, 3.6, 0.18, [20, 38, 31, 55, 41]), (8, 0.7919, 0.7919, 3.9, 0.13, [20, 21, 20, 64, 60]), (8, 0.7919, 0.7919, 3.8, 0.13, [20, 20, 20, 29, 57])]\n",
      "Generation 8: 51.3 s, best val metric 0.8122, [(9, 0.8122, 0.8122, 3.5, 0.23, [20, 22, 21, 32, 33]), (9, 0.8122, 0.8122, 3.6, 0.19, [20, 20, 20, 22, 39]), (9, 0.8122, 0.8122, 4.1, 0.22, [20, 69, 53, 80, 81]), (9, 0.8122, 0.8122, 3.5, 0.23, [20, 22, 21, 32, 33]), (9, 0.8122, 0.8122, 4.1, 0.22, [20, 69, 53, 80, 81]), (9, 0.8122, 0.8122, 3.5, 0.23, [20, 22, 21, 32, 33]), (9, 0.8071, 0.8071, 3.7, 0.19, [20, 20, 20, 20, 40]), (9, 0.797, 0.797, 3.2, 0.18, [20, 20, 20, 20, 26]), (9, 0.797, 0.797, 3.6, 0.2, [20, 20, 20, 20, 42]), (9, 0.797, 0.797, 3.1, 0.16, [20, 20, 20, 22, 20]), (9, 0.7919, 0.7919, 3.9, 0.2, [20, 24, 20, 45, 51])]\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "evolution = Evolution()\n",
    "evolution.run(x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test),\n",
    "              batch_size=32, layer_sizes=[20, 20, 20, 20, 20], output_neurons=10, learning_rate=0.0004, n_parents=5, strategy=[0.5, 0.05], \n",
    "              population_size=10, n_generations=50, tournament_size=3, n_introduced=2, age_penalty_period=20, use_static_graph=False,\n",
    "              mutation_strength=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elitism by fitness (increasing age) - promising results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: 41.7 s, best val metric 0.736, [(1, 0.736, 0.736, 3.2, 0.1, [20, 20, 20, 20, 20]), (1, 0.736, 0.736, 3.2, 0.1, [20, 20, 20, 20, 20]), (1, 0.736, 0.736, 3.2, 0.1, [20, 20, 20, 20, 20]), (1, 0.6751, 0.6751, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6751, 0.6751, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6701, 0.6701, 4.6, 0.13, [29, 40, 40, 40, 40]), (1, 0.6701, 0.6701, 2.7, 0.07, [20, 20, 20, 20, 20]), (1, 0.6599, 0.6599, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6345, 0.6345, 2.7, 0.09, [20, 20, 20, 20, 20]), (1, 0.6294, 0.6294, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 1: 41.0 s, best val metric 0.7614, [(2, 0.7614, 0.7614, 3.9, 0.03, [20, 27, 20, 21, 23]), (2, 0.7411, 0.7411, 3.0, 0.14, [20, 20, 20, 20, 20]), (2, 0.7411, 0.7411, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7411, 0.7411, 3.0, 0.14, [20, 20, 20, 20, 20]), (2, 0.736, 0.736, 3.3, 0.11, [20, 20, 20, 20, 20]), (2, 0.736, 0.736, 3.2, 0.1, [20, 20, 20, 20, 20]), (2, 0.736, 0.736, 3.2, 0.1, [20, 20, 20, 20, 20]), (2, 0.731, 0.731, 2.7, 0.07, [20, 20, 20, 20, 20]), (2, 0.7259, 0.7259, 3.1, 0.08, [20, 20, 20, 20, 20]), (2, 0.7259, 0.7259, 3.1, 0.08, [20, 20, 20, 20, 20]), (2, 0.7208, 0.7208, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 2: 43.8 s, best val metric 0.7817, [(3, 0.7817, 0.7817, 4.0, 0.06, [20, 20, 20, 23, 27]), (3, 0.7817, 0.7817, 2.6, 0.01, [20, 20, 20, 20, 20]), (3, 0.7766, 0.7766, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7766, 0.7766, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7614, 0.7614, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7614, 0.7614, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7614, 0.7614, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7614, 0.7614, 3.9, 0.03, [20, 27, 20, 21, 23]), (3, 0.7563, 0.7563, 3.1, 0.08, [20, 20, 20, 20, 20]), (3, 0.7563, 0.7563, 3.2, 0.1, [20, 20, 20, 20, 20]), (3, 0.736, 0.736, 3.0, 0.14, [20, 20, 20, 20, 20])]\n",
      "Generation 3: 43.8 s, best val metric 0.7817, [(4, 0.7817, 0.7817, 2.8, 0.09, [20, 20, 20, 20, 20]), (4, 0.7817, 0.7817, 3.1, 0.08, [20, 20, 20, 20, 20]), (4, 0.7817, 0.7817, 3.2, 0.12, [20, 20, 20, 20, 20]), (4, 0.7817, 0.7817, 3.1, 0.08, [20, 20, 20, 20, 20]), (4, 0.7817, 0.7817, 2.8, 0.09, [20, 20, 20, 20, 20]), (4, 0.7817, 0.7817, 4.0, 0.06, [20, 20, 20, 23, 27]), (4, 0.7716, 0.7716, 3.0, 0.14, [20, 20, 20, 20, 20]), (4, 0.7716, 0.7716, 3.0, 0.14, [20, 20, 20, 20, 20]), (4, 0.7716, 0.7716, 3.0, 0.1, [20, 20, 20, 20, 20]), (4, 0.7716, 0.7716, 3.0, 0.1, [20, 20, 20, 20, 20]), (4, 0.7563, 0.7563, 3.2, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 4: 43.9 s, best val metric 0.8173, [(5, 0.8173, 0.8173, 3.0, 0.1, [20, 20, 20, 20, 20]), (5, 0.8173, 0.8173, 3.0, 0.1, [20, 20, 20, 20, 20]), (5, 0.8173, 0.8173, 3.0, 0.1, [20, 20, 20, 20, 20]), (5, 0.8071, 0.8071, 3.2, 0.12, [20, 20, 20, 20, 20]), (5, 0.8071, 0.8071, 3.2, 0.12, [20, 20, 20, 20, 20]), (5, 0.8071, 0.8071, 3.2, 0.12, [20, 20, 20, 20, 20]), (5, 0.8071, 0.8071, 4.2, 0.1, [20, 40, 34, 40, 40]), (5, 0.8071, 0.8071, 3.2, 0.13, [20, 20, 20, 20, 20]), (5, 0.797, 0.797, 3.2, 0.1, [20, 20, 20, 20, 20]), (5, 0.7817, 0.7817, 2.8, 0.09, [20, 20, 20, 20, 20]), (5, 0.7766, 0.7766, 3.1, 0.08, [20, 20, 20, 20, 20])]\n",
      "Generation 5: 46.4 s, best val metric 0.8325, [(6, 0.8325, 0.8325, 3.0, 0.1, [20, 20, 20, 20, 20]), (6, 0.8274, 0.8274, 3.3, 0.09, [20, 20, 20, 20, 20]), (6, 0.8274, 0.8274, 3.3, 0.09, [20, 20, 20, 20, 20]), (6, 0.8173, 0.8173, 3.0, 0.1, [20, 20, 20, 20, 20]), (6, 0.8122, 0.8122, 3.2, 0.12, [20, 20, 20, 20, 21]), (6, 0.8122, 0.8122, 3.2, 0.12, [20, 20, 20, 20, 21]), (6, 0.8071, 0.8071, 3.4, 0.06, [20, 20, 20, 20, 20]), (6, 0.8071, 0.8071, 3.3, 0.14, [20, 20, 20, 20, 20]), (6, 0.797, 0.797, 3.3, 0.14, [20, 20, 20, 20, 20]), (6, 0.7919, 0.7919, 3.2, 0.12, [20, 20, 20, 20, 20]), (6, 0.7868, 0.7868, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 6: 46.0 s, best val metric 0.8325, [(7, 0.8325, 0.8325, 3.0, 0.1, [20, 20, 20, 20, 20]), (7, 0.8274, 0.8274, 3.0, 0.11, [20, 20, 20, 20, 20]), (7, 0.8274, 0.8274, 3.0, 0.11, [20, 20, 20, 20, 20]), (7, 0.8223, 0.8223, 3.4, 0.06, [20, 20, 20, 20, 22]), (7, 0.8223, 0.8223, 3.4, 0.06, [20, 20, 20, 20, 22]), (7, 0.8122, 0.8122, 3.3, 0.09, [20, 20, 20, 20, 20]), (7, 0.8122, 0.8122, 2.9, 0.04, [20, 20, 20, 20, 20]), (7, 0.8071, 0.8071, 3.4, 0.15, [20, 20, 20, 20, 21]), (7, 0.8071, 0.8071, 3.3, 0.14, [20, 20, 20, 20, 20]), (7, 0.7817, 0.7817, 3.0, 0.1, [20, 20, 20, 20, 20]), (7, 0.7716, 0.7716, 3.2, 0.12, [20, 20, 20, 20, 20])]\n",
      "Generation 7: 45.4 s, best val metric 0.8325, [(8, 0.8325, 0.8325, 3.0, 0.1, [20, 20, 20, 20, 20]), (8, 0.8223, 0.8223, 4.4, 0.07, [20, 38, 40, 40, 40]), (8, 0.8173, 0.8173, 3.8, -0.01, [20, 20, 21, 39, 42]), (8, 0.8173, 0.8173, 3.8, -0.01, [20, 20, 21, 39, 42]), (8, 0.8071, 0.8071, 3.4, 0.14, [20, 20, 20, 20, 28]), (8, 0.802, 0.802, 3.0, 0.08, [20, 20, 20, 20, 20]), (8, 0.802, 0.802, 3.0, 0.11, [20, 20, 20, 20, 20]), (8, 0.802, 0.802, 3.0, 0.08, [20, 20, 20, 20, 20]), (8, 0.802, 0.802, 3.0, 0.08, [20, 20, 20, 20, 20]), (8, 0.802, 0.802, 3.3, 0.14, [20, 20, 20, 20, 21]), (8, 0.7614, 0.7614, 3.4, 0.06, [20, 20, 20, 20, 23])]\n",
      "Generation 8: 48.8 s, best val metric 0.8325, [(9, 0.8325, 0.8325, 4.4, 0.07, [22, 57, 57, 60, 60]), (9, 0.8325, 0.8325, 4.4, 0.07, [22, 57, 57, 60, 60]), (9, 0.8325, 0.8325, 3.0, 0.1, [20, 20, 20, 20, 20]), (9, 0.8274, 0.8274, 3.8, -0.01, [20, 20, 29, 46, 56]), (9, 0.8223, 0.8223, 3.0, 0.1, [20, 20, 20, 20, 20]), (9, 0.8223, 0.8223, 3.0, 0.1, [20, 20, 20, 20, 20]), (9, 0.8223, 0.8223, 3.0, 0.1, [20, 20, 20, 20, 20]), (9, 0.8173, 0.8173, 4.3, 0.05, [21, 40, 40, 40, 48]), (9, 0.8122, 0.8122, 4.6, -0.0, [26, 40, 41, 59, 62]), (9, 0.8122, 0.8122, 4.6, -0.0, [26, 40, 41, 59, 62]), (9, 0.8071, 0.8071, 3.6, 0.14, [20, 20, 19, 22, 33])]\n",
      "Generation 9: 52.6 s, best val metric 0.8325, [(10, 0.8325, 0.8325, 4.4, 0.07, [22, 57, 57, 60, 60]), (10, 0.8223, 0.8223, 3.3, -0.05, [20, 20, 19, 20, 29]), (10, 0.8223, 0.8223, 3.3, -0.05, [20, 20, 19, 20, 29]), (10, 0.8071, 0.8071, 3.4, 0.05, [20, 20, 20, 20, 25]), (10, 0.8071, 0.8071, 3.4, 0.05, [20, 20, 20, 20, 25]), (10, 0.8071, 0.8071, 4.4, 0.07, [37, 77, 75, 80, 79]), (10, 0.802, 0.802, 3.0, 0.1, [20, 20, 20, 20, 20]), (10, 0.802, 0.802, 3.0, 0.1, [20, 20, 20, 20, 20]), (10, 0.7919, 0.7919, 3.2, 0.19, [20, 20, 20, 27, 25]), (10, 0.7919, 0.7919, 3.2, 0.19, [20, 20, 20, 27, 25]), (10, 0.7716, 0.7716, 3.6, 0.13, [20, 20, 20, 33, 38])]\n",
      "Generation 10: 49.9 s, best val metric 0.8376, [(11, 0.8376, 0.8376, 4.4, 0.07, [27, 93, 78, 100, 97]), (11, 0.8325, 0.8325, 4.4, 0.07, [22, 57, 57, 60, 60]), (11, 0.8274, 0.8274, 3.6, 0.08, [20, 21, 18, 20, 39]), (11, 0.8223, 0.8223, 3.2, 0.19, [20, 20, 19, 20, 23]), (11, 0.8223, 0.8223, 3.3, -0.05, [20, 19, 16, 20, 27]), (11, 0.8223, 0.8223, 4.7, 0.12, [40, 40, 40, 47, 45]), (11, 0.8223, 0.8223, 3.2, 0.19, [20, 20, 19, 20, 23]), (11, 0.8173, 0.8173, 4.4, 0.07, [33, 77, 77, 80, 80]), (11, 0.8071, 0.8071, 2.9, 0.16, [20, 20, 19, 20, 22]), (11, 0.802, 0.802, 3.6, 0.05, [20, 35, 25, 49, 75]), (11, 0.797, 0.797, 3.4, 0.05, [20, 20, 20, 20, 28])]\n",
      "Generation 11: 56.3 s, best val metric 0.8376, [(12, 0.8376, 0.8376, 3.6, 0.09, [20, 20, 18, 36, 40]), (12, 0.8376, 0.8376, 3.6, 0.09, [20, 20, 18, 36, 40]), (12, 0.8376, 0.8376, 4.4, 0.07, [27, 93, 78, 100, 97]), (12, 0.8325, 0.8325, 4.4, 0.07, [38, 97, 90, 100, 98]), (12, 0.8173, 0.8173, 4.0, 0.08, [20, 36, 30, 40, 43]), (12, 0.8122, 0.8122, 4.7, 0.12, [60, 60, 60, 67, 65]), (12, 0.8122, 0.8122, 3.7, 0.03, [22, 42, 29, 47, 60]), (12, 0.8071, 0.8071, 3.6, 0.09, [20, 19, 16, 31, 33]), (12, 0.8071, 0.8071, 3.6, 0.09, [20, 19, 16, 31, 33]), (12, 0.802, 0.802, 3.3, 0.09, [20, 19, 15, 20, 32]), (12, 0.797, 0.797, 3.6, 0.05, [20, 23, 20, 30, 58])]\n",
      "Generation 12: 58.0 s, best val metric 0.8477, [(13, 0.8477, 0.8477, 4.3, -0.01, [26, 39, 36, 51, 53]), (13, 0.8376, 0.8376, 4.4, 0.05, [22, 40, 38, 56, 60]), (13, 0.8376, 0.8376, 4.4, 0.05, [22, 40, 38, 56, 60]), (13, 0.8376, 0.8376, 4.4, 0.05, [22, 40, 38, 56, 60]), (13, 0.8376, 0.8376, 4.4, 0.05, [22, 40, 38, 56, 60]), (13, 0.8376, 0.8376, 3.6, 0.09, [20, 20, 18, 36, 40]), (13, 0.8274, 0.8274, 4.5, 0.09, [68, 80, 80, 87, 85]), (13, 0.8274, 0.8274, 4.5, 0.09, [68, 80, 80, 87, 85]), (13, 0.8274, 0.8274, 4.4, -0.01, [21, 40, 38, 56, 60]), (13, 0.8223, 0.8223, 3.1, 0.04, [20, 20, 20, 29, 21]), (13, 0.8173, 0.8173, 3.6, 0.09, [20, 20, 17, 38, 56])]\n",
      "Generation 13: 63.6 s, best val metric 0.8477, [(14, 0.8477, 0.8477, 4.3, -0.01, [26, 39, 36, 51, 53]), (14, 0.8376, 0.8376, 4.4, 0.05, [34, 60, 58, 76, 80]), (14, 0.8376, 0.8376, 4.4, 0.05, [34, 60, 58, 76, 80]), (14, 0.8274, 0.8274, 4.4, 0.05, [23, 60, 58, 76, 80]), (14, 0.8223, 0.8223, 4.4, 0.05, [30, 60, 58, 76, 80]), (14, 0.8223, 0.8223, 4.4, 0.05, [30, 60, 58, 76, 80]), (14, 0.8223, 0.8223, 4.2, 0.13, [21, 58, 57, 76, 80]), (14, 0.8173, 0.8173, 3.1, 0.04, [20, 20, 17, 20, 25]), (14, 0.8173, 0.8173, 4.4, 0.05, [24, 60, 58, 76, 80]), (14, 0.8071, 0.8071, 3.6, 0.09, [20, 22, 16, 38, 63]), (14, 0.8071, 0.8071, 3.4, 0.09, [20, 20, 20, 20, 35])]\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "evolution = Evolution()\n",
    "evolution.run(x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test),\n",
    "              batch_size=32, layer_sizes=[20, 20, 20, 20, 20], output_neurons=10, learning_rate=0.0004, n_parents=5, strategy=[0.5, 0.05], \n",
    "              population_size=10, n_generations=50, tournament_size=3, n_introduced=2, age_penalty_period=20, use_static_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: 41.3 s, best val metric 0.7005, [(1, 0.7005, 0.7005, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.7005, 0.7005, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.7005, 0.7005, 3.1, 0.15, [20, 20, 20, 20, 20]), (1, 0.7005, 0.7005, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.7005, 0.7005, 2.9, 0.09, [20, 20, 20, 20, 20]), (1, 0.7005, 0.7005, 2.8, 0.05, [20, 20, 20, 20, 20]), (1, 0.7005, 0.7005, 2.8, 0.05, [20, 20, 20, 20, 20]), (1, 0.7005, 0.7005, 2.8, 0.05, [20, 20, 20, 20, 20]), (1, 0.6954, 0.6954, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6904, 0.6904, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 1: 41.4 s, best val metric 0.7766, [(2, 0.7766, 0.7766, 2.9, 0.09, [20, 20, 20, 20, 20]), (2, 0.7665, 0.7665, 2.8, 0.05, [20, 20, 20, 20, 20]), (2, 0.7665, 0.7665, 3.1, 0.02, [20, 20, 20, 20, 20]), (2, 0.7563, 0.7563, 2.8, 0.05, [20, 20, 20, 20, 20]), (2, 0.7563, 0.7563, 2.8, 0.05, [20, 20, 20, 20, 20]), (2, 0.7563, 0.7563, 2.7, 0.14, [20, 20, 20, 20, 20]), (2, 0.7513, 0.7513, 3.2, -0.0, [20, 20, 20, 20, 20]), (2, 0.7513, 0.7513, 3.2, -0.0, [20, 20, 20, 20, 20]), (2, 0.7462, 0.7462, 2.8, 0.05, [20, 20, 20, 20, 20]), (2, 0.731, 0.731, 3.4, 0.08, [20, 20, 20, 20, 20]), (2, 0.7005, 0.7005, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 2: 43.9 s, best val metric 0.7817, [(3, 0.7817, 0.7817, 3.1, 0.02, [20, 20, 20, 20, 20]), (3, 0.7817, 0.7817, 3.1, 0.02, [20, 20, 20, 20, 20]), (3, 0.7817, 0.7817, 2.9, 0.09, [20, 20, 20, 20, 20]), (3, 0.7817, 0.7817, 3.2, 0.07, [20, 20, 20, 20, 20]), (3, 0.7817, 0.7817, 3.1, 0.02, [20, 20, 20, 20, 20]), (3, 0.7766, 0.7766, 2.9, 0.09, [20, 20, 20, 20, 20]), (3, 0.7716, 0.7716, 2.8, 0.05, [20, 20, 20, 20, 20]), (3, 0.7665, 0.7665, 3.7, -0.01, [20, 20, 20, 20, 21]), (3, 0.7665, 0.7665, 3.2, -0.0, [20, 20, 20, 20, 20]), (3, 0.736, 0.736, 2.6, -0.04, [20, 20, 20, 20, 20]), (3, 0.736, 0.736, 2.6, -0.04, [20, 20, 20, 20, 20])]\n",
      "Generation 3: 42.6 s, best val metric 0.802, [(4, 0.802, 0.802, 3.1, 0.02, [20, 20, 20, 20, 20]), (4, 0.802, 0.802, 3.1, 0.02, [20, 20, 20, 20, 20]), (4, 0.7817, 0.7817, 3.2, 0.12, [20, 20, 20, 20, 20]), (4, 0.7817, 0.7817, 3.1, 0.02, [20, 20, 20, 20, 20]), (4, 0.7716, 0.7716, 3.6, 0.09, [20, 20, 20, 20, 22]), (4, 0.7716, 0.7716, 3.6, 0.09, [20, 20, 20, 20, 22]), (4, 0.7665, 0.7665, 3.1, 0.02, [20, 20, 20, 20, 20]), (4, 0.7665, 0.7665, 2.9, 0.09, [20, 20, 20, 20, 20]), (4, 0.7614, 0.7614, 3.7, -0.01, [20, 20, 20, 20, 23]), (4, 0.7563, 0.7563, 2.8, 0.06, [20, 20, 20, 20, 20]), (4, 0.736, 0.736, 2.1, -0.03, [20, 20, 20, 20, 20])]\n",
      "Generation 4: 44.6 s, best val metric 0.8071, [(5, 0.8071, 0.8071, 3.5, 0.1, [20, 20, 20, 20, 21]), (5, 0.8071, 0.8071, 3.5, 0.1, [20, 20, 20, 20, 21]), (5, 0.802, 0.802, 3.0, 0.11, [20, 20, 20, 20, 20]), (5, 0.802, 0.802, 3.0, 0.11, [20, 20, 20, 20, 20]), (5, 0.802, 0.802, 3.0, 0.11, [20, 20, 20, 20, 20]), (5, 0.802, 0.802, 3.1, 0.02, [20, 20, 20, 20, 20]), (5, 0.7817, 0.7817, 3.6, 0.09, [20, 20, 20, 20, 24]), (5, 0.7766, 0.7766, 3.5, -0.01, [20, 20, 20, 20, 23]), (5, 0.7766, 0.7766, 3.5, -0.01, [20, 20, 20, 20, 21]), (5, 0.7716, 0.7716, 3.7, -0.01, [20, 20, 20, 20, 24]), (5, 0.7665, 0.7665, 3.1, 0.02, [20, 20, 20, 20, 20])]\n",
      "Generation 5: 44.1 s, best val metric 0.8122, [(6, 0.8122, 0.8122, 3.0, 0.11, [20, 20, 20, 20, 20]), (6, 0.8122, 0.8122, 3.0, 0.11, [20, 20, 20, 20, 20]), (6, 0.8122, 0.8122, 4.3, 0.05, [20, 32, 27, 40, 40]), (6, 0.8122, 0.8122, 3.7, -0.01, [20, 20, 20, 21, 38]), (6, 0.8122, 0.8122, 3.0, 0.11, [20, 20, 20, 20, 20]), (6, 0.8071, 0.8071, 3.5, 0.1, [20, 20, 20, 20, 21]), (6, 0.797, 0.797, 3.5, 0.1, [20, 20, 20, 20, 22]), (6, 0.7919, 0.7919, 3.1, 0.04, [20, 20, 20, 20, 20]), (6, 0.7919, 0.7919, 3.1, 0.04, [20, 20, 20, 20, 20]), (6, 0.7868, 0.7868, 3.4, 0.06, [20, 20, 20, 20, 22]), (6, 0.7817, 0.7817, 3.5, 0.08, [20, 20, 20, 20, 28])]\n",
      "Generation 6: 45.2 s, best val metric 0.8223, [(7, 0.8223, 0.8223, 4.0, -0.0, [20, 21, 21, 40, 39]), (7, 0.8223, 0.8223, 4.0, -0.0, [20, 21, 21, 40, 39]), (7, 0.8122, 0.8122, 3.5, 0.1, [20, 20, 20, 20, 24]), (7, 0.8122, 0.8122, 3.0, 0.11, [20, 20, 20, 20, 20]), (7, 0.8071, 0.8071, 3.7, -0.01, [20, 20, 20, 20, 46]), (7, 0.8071, 0.8071, 3.0, 0.11, [20, 20, 20, 20, 20]), (7, 0.8071, 0.8071, 3.7, -0.01, [20, 20, 20, 20, 46]), (7, 0.797, 0.797, 3.1, 0.04, [20, 20, 20, 20, 20]), (7, 0.7919, 0.7919, 3.5, 0.1, [20, 20, 20, 20, 27]), (7, 0.7868, 0.7868, 3.9, 0.03, [20, 20, 20, 40, 40]), (7, 0.7766, 0.7766, 3.4, 0.06, [20, 20, 20, 20, 22])]\n",
      "Generation 7: 45.9 s, best val metric 0.8223, [(8, 0.8223, 0.8223, 4.0, -0.0, [20, 21, 21, 40, 39]), (8, 0.8173, 0.8173, 3.7, 0.09, [20, 20, 20, 26, 36]), (8, 0.8173, 0.8173, 3.7, 0.07, [20, 20, 20, 21, 40]), (8, 0.8173, 0.8173, 3.7, 0.07, [20, 20, 20, 21, 40]), (8, 0.8122, 0.8122, 3.9, 0.03, [20, 20, 20, 42, 54]), (8, 0.8071, 0.8071, 3.9, -0.03, [20, 20, 20, 35, 39]), (8, 0.8071, 0.8071, 3.1, 0.04, [20, 20, 20, 20, 20]), (8, 0.8071, 0.8071, 3.1, 0.04, [20, 20, 20, 20, 20]), (8, 0.8071, 0.8071, 3.9, -0.03, [20, 20, 20, 35, 39]), (8, 0.802, 0.802, 3.0, 0.11, [20, 20, 20, 20, 20]), (8, 0.797, 0.797, 3.7, -0.01, [20, 20, 20, 20, 41])]\n",
      "Generation 8: 46.5 s, best val metric 0.8376, [(9, 0.8376, 0.8376, 3.3, 0.09, [20, 18, 20, 20, 25]), (9, 0.8325, 0.8325, 4.0, 0.04, [20, 24, 24, 55, 58]), (9, 0.8325, 0.8325, 4.0, 0.04, [20, 24, 24, 55, 58]), (9, 0.8223, 0.8223, 3.7, -0.01, [20, 20, 20, 20, 48]), (9, 0.8223, 0.8223, 3.7, -0.01, [20, 20, 20, 20, 48]), (9, 0.8223, 0.8223, 4.0, -0.0, [20, 21, 21, 40, 39]), (9, 0.8173, 0.8173, 3.9, -0.03, [20, 21, 20, 45, 57]), (9, 0.8173, 0.8173, 3.9, -0.03, [20, 21, 20, 45, 57]), (9, 0.8173, 0.8173, 3.7, 0.09, [20, 20, 20, 23, 38]), (9, 0.8173, 0.8173, 3.9, -0.03, [20, 21, 20, 45, 57]), (9, 0.8071, 0.8071, 3.7, 0.07, [20, 20, 20, 23, 51])]\n",
      "Generation 9: 48.7 s, best val metric 0.8376, [(10, 0.8376, 0.8376, 3.3, 0.09, [20, 18, 20, 20, 25]), (10, 0.8274, 0.8274, 3.9, -0.03, [20, 24, 22, 44, 71]), (10, 0.8274, 0.8274, 3.9, -0.03, [20, 24, 22, 44, 71]), (10, 0.8274, 0.8274, 4.0, -0.0, [20, 24, 21, 59, 58]), (10, 0.8274, 0.8274, 3.9, -0.03, [20, 24, 22, 44, 71]), (10, 0.8223, 0.8223, 3.4, 0.06, [20, 17, 20, 20, 35]), (10, 0.8223, 0.8223, 4.0, 0.04, [20, 22, 33, 65, 74]), (10, 0.8223, 0.8223, 3.7, 0.07, [20, 20, 20, 23, 53]), (10, 0.8223, 0.8223, 4.0, 0.04, [20, 27, 24, 67, 77]), (10, 0.8071, 0.8071, 3.9, -0.03, [20, 20, 20, 51, 74]), (10, 0.802, 0.802, 3.3, 0.09, [20, 16, 20, 20, 26])]\n",
      "Generation 10: 49.2 s, best val metric 0.8376, [(11, 0.8376, 0.8301, 3.3, 0.09, [20, 18, 20, 20, 25]), (11, 0.8223, 0.815, 3.5, -0.02, [20, 19, 20, 30, 42]), (11, 0.8223, 0.815, 3.5, -0.02, [20, 19, 20, 30, 42]), (11, 0.8173, 0.81, 3.7, 0.04, [20, 19, 20, 38, 65]), (11, 0.8173, 0.81, 3.5, -0.03, [20, 20, 20, 20, 34]), (11, 0.8122, 0.8049, 3.7, 0.07, [20, 20, 20, 34, 68]), (11, 0.8122, 0.8049, 3.3, -0.09, [20, 18, 20, 23, 40]), (11, 0.802, 0.7949, 3.3, 0.09, [20, 16, 20, 20, 27]), (11, 0.802, 0.7949, 3.3, 0.09, [20, 16, 20, 20, 27]), (11, 0.802, 0.7949, 3.3, 0.09, [20, 16, 20, 20, 27]), (11, 0.7919, 0.7848, 4.1, 0.01, [20, 28, 24, 40, 45])]\n",
      "Generation 11: 47.7 s, best val metric 0.8376, [(12, 0.8376, 0.8242, 3.3, 0.09, [20, 18, 20, 20, 25]), (12, 0.8325, 0.8192, 3.3, 0.09, [20, 14, 20, 19, 31]), (12, 0.8325, 0.8192, 3.3, 0.09, [20, 14, 20, 19, 31]), (12, 0.8325, 0.8192, 3.3, 0.09, [20, 14, 20, 19, 31]), (12, 0.8325, 0.8192, 3.7, 0.06, [20, 19, 20, 30, 50]), (12, 0.8223, 0.8092, 3.7, -0.01, [20, 18, 20, 29, 57]), (12, 0.8223, 0.8092, 3.3, 0.05, [20, 18, 20, 21, 46]), (12, 0.8223, 0.8092, 3.4, -0.02, [20, 18, 20, 20, 39]), (12, 0.8223, 0.8092, 3.3, 0.05, [20, 18, 20, 21, 46]), (12, 0.802, 0.7892, 3.5, 0.02, [20, 16, 20, 20, 39]), (12, 0.802, 0.7892, 3.9, 0.08, [20, 16, 20, 40, 47])]\n",
      "Generation 12: 49.6 s, best val metric 0.8376, [(13, 0.8376, 0.8138, 3.3, 0.09, [20, 18, 20, 20, 25]), (13, 0.8325, 0.8089, 3.8, -0.01, [20, 18, 20, 27, 37]), (13, 0.8071, 0.7842, 3.5, 0.02, [20, 16, 20, 19, 44]), (13, 0.8071, 0.7842, 4.0, 0.08, [20, 23, 31, 41, 64]), (13, 0.802, 0.7793, 3.0, 0.08, [20, 13, 20, 18, 26]), (13, 0.802, 0.7793, 3.4, 0.0, [20, 15, 20, 20, 40]), (13, 0.802, 0.7793, 3.4, 0.0, [20, 15, 20, 20, 40]), (13, 0.802, 0.7793, 3.4, 0.0, [20, 15, 20, 20, 40]), (13, 0.797, 0.7744, 2.9, 0.08, [20, 14, 19, 19, 21]), (13, 0.7817, 0.7596, 2.8, 0.07, [20, 15, 19, 20, 21]), (13, 0.7817, 0.7596, 3.3, 0.05, [20, 16, 19, 20, 38])]\n",
      "Generation 13: 47.3 s, best val metric 0.8376, [(14, 0.8376, 0.7958, 3.3, 0.09, [20, 18, 20, 20, 25]), (14, 0.8223, 0.7813, 3.5, 0.01, [19, 13, 19, 21, 36]), (14, 0.8223, 0.7813, 3.5, 0.01, [19, 13, 19, 21, 36]), (14, 0.8223, 0.7813, 3.4, 0.0, [20, 14, 19, 19, 38]), (14, 0.8122, 0.7717, 3.4, 0.06, [20, 17, 20, 28, 54]), (14, 0.8071, 0.7669, 3.5, 0.15, [20, 15, 19, 20, 50]), (14, 0.802, 0.762, 3.9, 0.12, [20, 18, 20, 40, 45]), (14, 0.802, 0.762, 3.9, 0.12, [20, 18, 20, 40, 45]), (14, 0.802, 0.762, 4.0, 0.08, [20, 26, 27, 58, 80]), (14, 0.802, 0.762, 4.0, 0.08, [20, 26, 27, 58, 80]), (14, 0.797, 0.7572, 4.4, 0.11, [30, 35, 40, 40, 60])]\n",
      "Generation 14: 50.8 s, best val metric 0.8477, [(15, 0.8477, 0.7745, 3.6, 0.03, [20, 18, 20, 21, 34]), (15, 0.8477, 0.7745, 3.6, 0.03, [20, 18, 20, 21, 34]), (15, 0.8376, 0.7653, 3.6, 0.15, [20, 17, 20, 34, 44]), (15, 0.8376, 0.7653, 3.6, 0.15, [20, 17, 20, 34, 44]), (15, 0.8376, 0.7653, 3.6, 0.15, [20, 17, 20, 34, 44]), (15, 0.8376, 0.7653, 3.8, 0.08, [20, 18, 20, 39, 57]), (15, 0.8376, 0.7653, 4.0, 0.08, [20, 23, 23, 68, 97]), (15, 0.8376, 0.7653, 4.0, 0.08, [20, 23, 23, 68, 97]), (15, 0.8376, 0.7653, 3.6, 0.15, [20, 17, 20, 34, 44]), (15, 0.8376, 0.7653, 3.3, 0.09, [20, 18, 20, 20, 25]), (15, 0.8274, 0.756, 3.7, 0.15, [20, 18, 20, 40, 52])]\n",
      "Generation 15: 50.0 s, best val metric 0.8528, [(16, 0.8528, 0.7288, 4.0, 0.08, [21, 32, 23, 74, 109]), (16, 0.8528, 0.7288, 4.0, 0.08, [21, 32, 23, 74, 109]), (16, 0.8528, 0.7288, 4.0, 0.08, [21, 32, 23, 74, 109]), (16, 0.8528, 0.7288, 4.0, 0.08, [21, 32, 23, 74, 109]), (16, 0.8528, 0.7288, 4.0, 0.08, [21, 32, 23, 74, 109]), (16, 0.8477, 0.7245, 3.6, 0.03, [20, 18, 20, 21, 34]), (16, 0.8325, 0.7115, 3.2, 0.13, [20, 16, 20, 20, 23]), (16, 0.8223, 0.7028, 3.8, 0.08, [20, 17, 24, 44, 77]), (16, 0.8223, 0.7028, 3.8, 0.08, [20, 17, 24, 44, 77]), (16, 0.8223, 0.7028, 3.6, 0.15, [20, 16, 20, 22, 46]), (16, 0.8071, 0.6898, 3.6, 0.15, [20, 17, 20, 22, 46])]\n",
      "Generation 16: 53.2 s, best val metric 0.8528, [(17, 0.8528, 0.6529, 4.0, 0.08, [21, 32, 23, 74, 109]), (17, 0.8477, 0.649, 4.2, 0.12, [31, 50, 36, 94, 129]), (17, 0.8477, 0.649, 4.0, 0.08, [20, 25, 27, 68, 123]), (17, 0.8477, 0.649, 4.2, 0.12, [31, 50, 36, 94, 129]), (17, 0.8477, 0.649, 4.0, 0.08, [20, 25, 27, 68, 123]), (17, 0.8376, 0.6413, 4.0, 0.08, [20, 45, 31, 66, 128]), (17, 0.8173, 0.6257, 3.7, 0.04, [20, 17, 20, 42, 108]), (17, 0.8173, 0.6257, 3.6, 0.07, [20, 16, 20, 22, 43]), (17, 0.8173, 0.6257, 3.6, 0.07, [20, 16, 20, 22, 43]), (17, 0.8122, 0.6218, 3.6, 0.03, [20, 16, 20, 20, 44]), (17, 0.802, 0.6141, 3.5, 0.09, [20, 14, 18, 35, 85])]\n",
      "Generation 17: 54.5 s, best val metric 0.8528, [(1, 0.665, 0.665, 3.0, 0.1, [20, 20, 20, 20, 20]), (18, 0.8528, 0.5498, 4.0, 0.08, [21, 32, 23, 74, 109]), (18, 0.8376, 0.54, 3.7, 0.13, [20, 16, 20, 20, 52]), (18, 0.8376, 0.54, 3.6, 0.07, [20, 16, 20, 22, 44]), (18, 0.8376, 0.54, 3.7, 0.13, [20, 16, 20, 20, 52]), (18, 0.8274, 0.5335, 4.0, 0.12, [25, 54, 32, 93, 138]), (18, 0.8274, 0.5335, 4.1, 0.05, [29, 43, 35, 80, 143]), (18, 0.8274, 0.5335, 4.0, 0.08, [21, 37, 28, 64, 126]), (18, 0.8274, 0.5335, 4.1, 0.05, [29, 43, 35, 80, 143]), (18, 0.8274, 0.5335, 4.1, 0.05, [29, 43, 35, 80, 143]), (18, 0.8122, 0.5237, 4.2, 0.12, [34, 68, 50, 113, 153])]\n",
      "Generation 18: 57.1 s, best val metric 0.8325, [(2, 0.6954, 0.6954, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.6954, 0.6954, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6853, 0.6853, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6701, 0.6701, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.665, 0.665, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.6548, 0.6548, 4.5, -0.0, [21, 40, 40, 40, 40]), (19, 0.8325, 0.418, 4.1, 0.05, [30, 54, 46, 98, 168]), (19, 0.8325, 0.418, 3.7, 0.13, [20, 16, 20, 24, 63]), (19, 0.8173, 0.4103, 4.0, 0.08, [20, 31, 24, 62, 143]), (19, 0.8122, 0.4078, 3.5, 0.06, [20, 17, 20, 32, 71]), (19, 0.8122, 0.4078, 3.7, 0.13, [20, 16, 20, 22, 58])]\n",
      "Generation 19: 49.1 s, best val metric 0.7665, [(2, 0.7665, 0.7665, 3.2, 0.08, [20, 20, 20, 20, 20]), (3, 0.7462, 0.7462, 4.5, -0.0, [23, 60, 60, 60, 59]), (3, 0.7411, 0.7411, 4.4, 0.16, [21, 50, 52, 60, 54]), (3, 0.736, 0.736, 3.6, 0.03, [20, 20, 20, 20, 23]), (2, 0.731, 0.731, 3.8, 0.2, [20, 20, 20, 20, 20]), (2, 0.731, 0.731, 3.8, 0.2, [20, 20, 20, 20, 20]), (2, 0.731, 0.731, 3.8, 0.2, [20, 20, 20, 20, 20]), (3, 0.731, 0.731, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7208, 0.7208, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.6954, 0.6954, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6142, 0.6142, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 20: 46.8 s, best val metric 0.802, [(4, 0.802, 0.802, 4.5, -0.0, [25, 79, 71, 80, 77]), (4, 0.802, 0.802, 4.5, -0.0, [25, 79, 71, 80, 77]), (4, 0.797, 0.797, 4.1, 0.16, [20, 24, 21, 40, 34]), (4, 0.797, 0.797, 4.1, 0.16, [20, 24, 21, 40, 34]), (4, 0.7766, 0.7766, 3.3, 0.12, [20, 20, 20, 34, 38]), (4, 0.7716, 0.7716, 3.8, 0.16, [20, 20, 20, 20, 24]), (4, 0.7665, 0.7665, 3.7, 0.04, [20, 20, 20, 22, 23]), (3, 0.7665, 0.7665, 3.6, 0.17, [20, 20, 20, 20, 20]), (3, 0.7665, 0.7665, 3.2, 0.08, [20, 20, 20, 20, 20]), (3, 0.7614, 0.7614, 3.8, 0.2, [20, 20, 20, 20, 23]), (4, 0.7513, 0.7513, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 21: 53.3 s, best val metric 0.8071, [(5, 0.8071, 0.8071, 4.5, 0.11, [20, 40, 40, 40, 40]), (5, 0.8071, 0.8071, 4.5, 0.11, [20, 40, 40, 40, 40]), (5, 0.8071, 0.8071, 4.5, 0.11, [20, 40, 40, 40, 40]), (5, 0.8071, 0.8071, 4.5, 0.11, [20, 40, 40, 40, 40]), (5, 0.8071, 0.8071, 4.5, 0.11, [20, 40, 40, 40, 40]), (5, 0.802, 0.802, 4.5, -0.0, [26, 99, 80, 100, 88]), (5, 0.802, 0.802, 3.4, 0.03, [20, 20, 20, 32, 29]), (5, 0.802, 0.802, 4.5, -0.0, [25, 79, 71, 80, 77]), (4, 0.7868, 0.7868, 4.4, 0.12, [31, 40, 39, 40, 40]), (5, 0.7817, 0.7817, 4.1, 0.16, [20, 27, 20, 58, 39]), (4, 0.7614, 0.7614, 3.6, 0.17, [20, 20, 20, 20, 20])]\n",
      "Generation 22: 60.3 s, best val metric 0.8173, [(6, 0.8173, 0.8173, 4.3, 0.08, [21, 39, 39, 52, 49]), (6, 0.8122, 0.8122, 3.3, 0.09, [20, 20, 20, 23, 20]), (6, 0.8122, 0.8122, 3.3, 0.09, [20, 20, 20, 23, 20]), (6, 0.8071, 0.8071, 4.5, 0.11, [21, 59, 60, 60, 60]), (6, 0.8071, 0.8071, 4.5, 0.11, [20, 40, 40, 40, 40]), (6, 0.797, 0.797, 4.7, 0.06, [44, 99, 91, 100, 97]), (6, 0.797, 0.797, 4.0, 0.06, [20, 39, 41, 60, 50]), (6, 0.7919, 0.7919, 4.6, 0.2, [25, 60, 60, 60, 59]), (6, 0.7919, 0.7919, 4.5, -0.0, [36, 117, 91, 120, 108]), (5, 0.7919, 0.7919, 4.1, 0.06, [21, 39, 27, 52, 47]), (6, 0.7868, 0.7868, 3.5, 0.15, [20, 20, 20, 40, 40])]\n",
      "Generation 23: 63.2 s, best val metric 0.8223, [(7, 0.8223, 0.8223, 4.0, 0.06, [20, 39, 33, 76, 49]), (7, 0.8223, 0.8223, 4.0, 0.06, [20, 39, 33, 76, 49]), (7, 0.8223, 0.8223, 4.0, 0.06, [20, 39, 33, 76, 49]), (7, 0.8173, 0.8173, 4.3, 0.08, [21, 39, 39, 52, 49]), (7, 0.8122, 0.8122, 4.2, 0.02, [20, 50, 42, 72, 62]), (7, 0.8122, 0.8122, 3.5, 0.15, [20, 20, 20, 32, 41]), (7, 0.8071, 0.8071, 4.5, -0.0, [45, 137, 93, 144, 119]), (7, 0.8071, 0.8071, 4.5, -0.0, [45, 137, 93, 144, 119]), (7, 0.8071, 0.8071, 4.2, 0.1, [20, 63, 57, 80, 73]), (7, 0.802, 0.802, 4.0, 0.13, [20, 33, 34, 43, 40]), (7, 0.797, 0.797, 5.1, 0.03, [40, 59, 61, 80, 70])]\n",
      "Generation 24: 71.2 s, best val metric 0.8223, [(8, 0.8223, 0.8223, 4.0, 0.06, [20, 39, 33, 76, 49]), (8, 0.8173, 0.8173, 4.2, 0.05, [31, 75, 62, 99, 85]), (8, 0.8173, 0.8173, 4.5, -0.0, [48, 163, 103, 172, 139]), (8, 0.8173, 0.8173, 4.5, -0.0, [48, 163, 103, 172, 139]), (8, 0.8173, 0.8173, 4.2, 0.05, [31, 75, 62, 99, 85]), (8, 0.8122, 0.8122, 5.1, 0.03, [60, 79, 81, 100, 90]), (8, 0.8122, 0.8122, 4.0, 0.13, [20, 45, 48, 63, 57]), (8, 0.8071, 0.8071, 4.0, 0.06, [20, 39, 30, 73, 59]), (8, 0.802, 0.802, 3.5, 0.15, [20, 20, 20, 28, 41]), (8, 0.802, 0.802, 4.3, 0.08, [20, 58, 55, 72, 69]), (8, 0.797, 0.797, 4.2, 0.02, [20, 66, 55, 92, 81])]\n",
      "Generation 25: 82.0 s, best val metric 0.8223, [(9, 0.8223, 0.8223, 4.0, 0.06, [20, 39, 33, 76, 49]), (9, 0.8173, 0.8173, 4.6, 0.05, [28, 78, 75, 92, 89]), (9, 0.8173, 0.8173, 4.6, 0.05, [28, 78, 75, 92, 89]), (9, 0.8173, 0.8173, 4.6, 0.05, [28, 78, 75, 92, 89]), (9, 0.8173, 0.8173, 4.0, 0.06, [20, 46, 36, 93, 69]), (9, 0.8071, 0.8071, 4.1, 0.08, [30, 92, 45, 138, 103]), (9, 0.802, 0.802, 3.9, 0.11, [20, 22, 20, 39, 47]), (9, 0.802, 0.802, 3.9, 0.11, [20, 22, 20, 39, 47]), (9, 0.802, 0.802, 3.8, 0.07, [20, 47, 25, 81, 54]), (9, 0.802, 0.802, 3.8, 0.07, [20, 47, 25, 81, 54]), (9, 0.797, 0.797, 3.7, 0.06, [20, 29, 20, 55, 44])]\n",
      "Generation 26: 65.0 s, best val metric 0.8376, [(10, 0.8376, 0.8376, 4.0, 0.01, [20, 42, 33, 89, 74]), (10, 0.8223, 0.8223, 4.0, 0.06, [20, 39, 33, 76, 49]), (10, 0.8173, 0.8173, 3.8, 0.07, [20, 26, 20, 66, 62]), (10, 0.8173, 0.8173, 3.7, 0.06, [20, 27, 20, 47, 50]), (10, 0.8173, 0.8173, 3.7, 0.06, [20, 27, 20, 47, 50]), (10, 0.8173, 0.8173, 3.8, 0.07, [20, 26, 20, 66, 62]), (10, 0.8173, 0.8173, 3.8, 0.07, [20, 26, 20, 66, 62]), (10, 0.8122, 0.8122, 3.1, 0.05, [20, 20, 20, 20, 30]), (10, 0.8122, 0.8122, 3.1, 0.05, [20, 20, 20, 20, 30]), (10, 0.8122, 0.8122, 4.0, 0.05, [20, 49, 33, 81, 69]), (10, 0.8122, 0.8122, 3.6, 0.12, [20, 20, 20, 25, 42])]\n",
      "Generation 27: 52.2 s, best val metric 0.8376, [(11, 0.8376, 0.8301, 4.0, 0.01, [20, 42, 33, 89, 74]), (11, 0.8325, 0.8251, 4.0, 0.01, [20, 41, 30, 91, 83]), (11, 0.8223, 0.815, 3.8, 0.05, [20, 32, 24, 48, 72]), (11, 0.8223, 0.815, 4.1, 0.12, [20, 47, 31, 67, 68]), (11, 0.8223, 0.815, 3.8, 0.05, [20, 32, 24, 48, 72]), (11, 0.8223, 0.815, 3.8, 0.05, [20, 32, 24, 48, 72]), (11, 0.8223, 0.815, 3.8, 0.05, [20, 32, 24, 48, 72]), (11, 0.8173, 0.81, 4.0, 0.05, [20, 47, 28, 91, 84]), (11, 0.8071, 0.7999, 3.7, 0.06, [20, 21, 20, 35, 49]), (11, 0.7919, 0.7848, 3.6, 0.12, [20, 20, 20, 21, 51]), (11, 0.7868, 0.7798, 3.8, 0.07, [20, 21, 21, 56, 75])]\n",
      "Generation 28: 54.6 s, best val metric 0.8376, [(12, 0.8376, 0.8242, 4.0, 0.01, [20, 42, 33, 89, 74]), (12, 0.8325, 0.8192, 3.7, 0.1, [20, 32, 20, 44, 59]), (12, 0.8325, 0.8192, 3.7, 0.1, [20, 32, 20, 44, 59]), (12, 0.8325, 0.8192, 3.7, 0.1, [20, 32, 20, 44, 59]), (12, 0.8325, 0.8192, 4.0, 0.01, [20, 48, 30, 90, 76]), (12, 0.8223, 0.8092, 4.0, 0.05, [20, 59, 42, 109, 93]), (12, 0.8223, 0.8092, 4.0, 0.05, [20, 59, 42, 109, 93]), (12, 0.8122, 0.7992, 3.6, 0.12, [20, 20, 20, 21, 45]), (12, 0.8122, 0.7992, 3.8, 0.05, [20, 25, 22, 44, 71]), (12, 0.8071, 0.7942, 3.1, -0.05, [20, 20, 20, 20, 28]), (12, 0.797, 0.7842, 3.5, 0.04, [20, 20, 20, 21, 44])]\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "evolution = Evolution()\n",
    "evolution.run(x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test),\n",
    "              batch_size=32, layer_sizes=[20, 20, 20, 20, 20], output_neurons=10, learning_rate=0.0004, n_parents=5, strategy=[0.5, 0.05], \n",
    "              population_size=10, n_generations=50, tournament_size=3, n_introduced=2, age_penalty_period=10, use_static_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0c6f4ad160>]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 244,
       "width": 366
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [0] + [x[0] for x in evolution.val_metrics]\n",
    "y = [0] + [x[1] for x in evolution.val_metrics]\n",
    "plt.step(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratio 0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = get_fashion_mnist_dataset(fraction=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: 74.7 s, best val metric 0.7111, [(1, 0.7111, 0.7111, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.7111, 0.7111, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.7111, 0.7111, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.7111, 0.7111, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.706, 0.706, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.701, 0.701, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.701, 0.701, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6985, 0.6985, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6884, 0.6884, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.6759, 0.6759, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 1: 74.9 s, best val metric 0.7588, [(2, 0.7588, 0.7588, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7487, 0.7487, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7487, 0.7487, 3.5, 0.09, [20, 20, 20, 20, 21]), (2, 0.7487, 0.7487, 3.5, 0.09, [20, 20, 20, 20, 21]), (2, 0.7462, 0.7462, 3.2, 0.1, [20, 20, 20, 20, 20]), (2, 0.7437, 0.7437, 3.9, 0.13, [20, 20, 20, 29, 32]), (2, 0.7437, 0.7437, 3.9, 0.13, [20, 20, 20, 29, 32]), (2, 0.7412, 0.7412, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7387, 0.7387, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7261, 0.7261, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.7111, 0.7111, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 2: 82.9 s, best val metric 0.7839, [(3, 0.7839, 0.7839, 3.5, 0.09, [20, 20, 20, 20, 27]), (3, 0.7839, 0.7839, 3.5, 0.09, [20, 20, 20, 20, 27]), (3, 0.7839, 0.7839, 3.5, 0.09, [20, 20, 20, 20, 27]), (3, 0.7789, 0.7789, 3.5, 0.09, [20, 20, 20, 20, 21]), (3, 0.7789, 0.7789, 3.5, 0.09, [20, 20, 20, 20, 21]), (3, 0.7714, 0.7714, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7638, 0.7638, 3.3, 0.09, [20, 20, 20, 20, 23]), (3, 0.7638, 0.7638, 3.3, 0.09, [20, 20, 20, 20, 23]), (3, 0.7638, 0.7638, 3.1, 0.12, [20, 20, 20, 20, 20]), (3, 0.7638, 0.7638, 3.2, 0.12, [20, 20, 20, 20, 20]), (2, 0.7588, 0.7588, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 3: 82.5 s, best val metric 0.7915, [(4, 0.7915, 0.7915, 3.5, 0.09, [20, 20, 20, 20, 27]), (4, 0.7915, 0.7915, 3.5, 0.09, [20, 20, 20, 20, 27]), (4, 0.7864, 0.7864, 3.5, 0.09, [20, 20, 20, 20, 22]), (4, 0.7864, 0.7864, 3.5, 0.09, [20, 20, 20, 20, 22]), (3, 0.7839, 0.7839, 3.5, 0.09, [20, 20, 20, 20, 27]), (4, 0.7814, 0.7814, 3.2, 0.12, [20, 20, 20, 20, 20]), (4, 0.7764, 0.7764, 3.3, 0.09, [20, 20, 20, 20, 28]), (4, 0.7764, 0.7764, 3.5, 0.09, [20, 20, 20, 20, 22]), (4, 0.7563, 0.7563, 3.3, 0.06, [20, 20, 20, 20, 21]), (3, 0.7563, 0.7563, 3.4, 0.12, [20, 20, 20, 20, 21]), (4, 0.7412, 0.7412, 2.9, 0.09, [20, 20, 20, 20, 20])]\n",
      "Generation 4: 78.9 s, best val metric 0.794, [(5, 0.794, 0.794, 3.5, 0.09, [20, 20, 20, 20, 27]), (5, 0.794, 0.794, 3.5, 0.09, [20, 20, 20, 20, 27]), (5, 0.794, 0.794, 3.5, 0.09, [20, 20, 20, 20, 27]), (5, 0.794, 0.794, 3.5, 0.09, [20, 20, 20, 20, 27]), (5, 0.794, 0.794, 3.8, 0.15, [20, 20, 20, 20, 37]), (4, 0.7915, 0.7915, 3.5, 0.09, [20, 20, 20, 20, 27]), (5, 0.7764, 0.7764, 3.8, -0.0, [20, 20, 20, 24, 36]), (5, 0.7739, 0.7739, 3.8, 0.15, [20, 20, 20, 30, 41]), (5, 0.7739, 0.7739, 3.8, 0.15, [20, 20, 20, 30, 41]), (5, 0.7714, 0.7714, 3.5, 0.09, [20, 20, 20, 20, 22]), (5, 0.7688, 0.7688, 3.3, 0.15, [20, 20, 20, 20, 26])]\n",
      "Generation 5: 86.6 s, best val metric 0.809, [(6, 0.809, 0.809, 3.8, 0.15, [20, 21, 20, 35, 53]), (6, 0.804, 0.804, 4.5, 0.12, [37, 40, 40, 40, 47]), (6, 0.804, 0.804, 4.5, 0.12, [37, 40, 40, 40, 47]), (6, 0.804, 0.804, 4.5, 0.12, [37, 40, 40, 40, 47]), (6, 0.7965, 0.7965, 3.8, 0.15, [20, 20, 20, 20, 56]), (5, 0.794, 0.794, 3.5, 0.09, [20, 20, 20, 20, 27]), (6, 0.7915, 0.7915, 3.8, 0.15, [20, 20, 20, 34, 50]), (6, 0.7839, 0.7839, 3.5, 0.16, [20, 20, 20, 20, 26]), (6, 0.7839, 0.7839, 3.5, 0.16, [20, 20, 20, 20, 26]), (6, 0.7814, 0.7814, 3.4, 0.13, [20, 20, 20, 20, 32]), (6, 0.7688, 0.7688, 3.5, 0.09, [20, 20, 20, 20, 26])]\n",
      "Generation 6: 94.4 s, best val metric 0.809, [(6, 0.809, 0.809, 3.8, 0.15, [20, 21, 20, 35, 53]), (7, 0.8065, 0.8065, 3.6, 0.2, [20, 20, 20, 20, 27]), (7, 0.8065, 0.8065, 3.6, 0.2, [20, 20, 20, 20, 27]), (7, 0.804, 0.804, 4.5, 0.12, [46, 59, 60, 60, 67]), (7, 0.7965, 0.7965, 3.8, 0.15, [20, 20, 20, 27, 63]), (7, 0.794, 0.794, 3.5, 0.16, [20, 20, 20, 20, 42]), (7, 0.7915, 0.7915, 4.2, 0.23, [20, 40, 37, 40, 46]), (7, 0.7889, 0.7889, 3.5, 0.16, [20, 20, 19, 20, 27]), (7, 0.7864, 0.7864, 3.4, 0.13, [20, 19, 20, 20, 35]), (7, 0.7864, 0.7864, 3.4, 0.13, [20, 19, 20, 20, 35]), (6, 0.7764, 0.7764, 3.5, 0.09, [20, 20, 20, 20, 36])]\n",
      "Generation 7: 90.3 s, best val metric 0.8141, [(8, 0.8141, 0.8141, 3.5, 0.24, [20, 20, 19, 20, 43]), (8, 0.8141, 0.8141, 3.5, 0.24, [20, 20, 19, 20, 43]), (8, 0.809, 0.809, 3.7, 0.07, [20, 20, 20, 31, 43]), (8, 0.809, 0.809, 3.7, 0.07, [20, 20, 20, 31, 43]), (8, 0.809, 0.809, 4.2, 0.23, [20, 41, 37, 60, 66]), (6, 0.809, 0.809, 3.8, 0.15, [20, 21, 20, 35, 53]), (8, 0.8065, 0.8065, 3.7, 0.11, [20, 20, 20, 20, 56]), (8, 0.8065, 0.8065, 3.7, 0.11, [20, 20, 20, 20, 56]), (8, 0.804, 0.804, 4.1, 0.16, [24, 39, 36, 40, 47]), (8, 0.799, 0.799, 3.5, 0.16, [20, 20, 19, 20, 44]), (8, 0.7965, 0.7965, 4.4, 0.11, [20, 39, 40, 40, 55])]\n",
      "Generation 8: 92.8 s, best val metric 0.8191, [(9, 0.8191, 0.8191, 3.7, 0.11, [20, 20, 20, 20, 55]), (9, 0.8191, 0.8191, 3.7, 0.11, [20, 20, 20, 20, 55]), (9, 0.8141, 0.8141, 3.6, 0.05, [20, 20, 20, 20, 56]), (9, 0.8141, 0.8141, 3.6, 0.05, [20, 20, 20, 20, 56]), (9, 0.8141, 0.8141, 3.6, 0.05, [20, 20, 20, 20, 56]), (8, 0.8141, 0.8141, 3.5, 0.24, [20, 20, 19, 20, 43]), (9, 0.8116, 0.8116, 4.4, 0.11, [24, 58, 57, 60, 75]), (9, 0.804, 0.804, 3.4, 0.18, [20, 20, 19, 20, 40]), (9, 0.804, 0.804, 3.4, 0.18, [20, 20, 19, 20, 40]), (9, 0.804, 0.804, 3.5, 0.16, [20, 20, 19, 20, 40]), (9, 0.7965, 0.7965, 3.7, 0.14, [20, 20, 20, 26, 45])]\n",
      "Generation 9: 92.1 s, best val metric 0.8342, [(10, 0.8342, 0.8342, 3.6, 0.05, [20, 20, 19, 20, 52]), (10, 0.8342, 0.8342, 3.6, 0.05, [20, 20, 19, 20, 52]), (10, 0.8342, 0.8342, 3.6, 0.05, [20, 20, 19, 20, 52]), (10, 0.8342, 0.8342, 3.6, 0.05, [20, 20, 19, 20, 52]), (10, 0.8342, 0.8342, 3.6, 0.05, [20, 20, 19, 20, 52]), (9, 0.8191, 0.8191, 3.7, 0.11, [20, 20, 20, 20, 55]), (10, 0.8116, 0.8116, 3.6, 0.05, [20, 20, 19, 20, 54]), (10, 0.809, 0.809, 3.8, 0.15, [20, 20, 19, 31, 53]), (10, 0.809, 0.809, 4.4, 0.11, [26, 75, 75, 80, 94]), (10, 0.804, 0.804, 3.7, 0.11, [20, 20, 20, 20, 65]), (10, 0.804, 0.804, 4.0, 0.03, [20, 22, 20, 40, 73])]\n",
      "Generation 10: 94.0 s, best val metric 0.8342, [(10, 0.8342, 0.8342, 3.6, 0.05, [20, 20, 19, 20, 52]), (10, 0.8116, 0.8116, 3.7, 0.11, [20, 20, 20, 20, 60]), (10, 0.8116, 0.8116, 3.7, 0.11, [20, 20, 20, 20, 60]), (11, 0.8342, 0.7783, 4.0, 0.03, [19, 21, 20, 38, 80]), (11, 0.8216, 0.7666, 3.6, 0.05, [19, 19, 19, 20, 56]), (10, 0.7663, 0.7663, 3.2, 0.02, [20, 19, 19, 20, 33]), (11, 0.8141, 0.7596, 3.7, 0.11, [19, 20, 19, 20, 59]), (11, 0.8116, 0.7572, 3.6, 0.05, [19, 19, 19, 20, 51]), (11, 0.8116, 0.7572, 4.1, 0.05, [20, 39, 35, 60, 86]), (11, 0.8116, 0.7572, 3.5, 0.07, [19, 17, 19, 20, 54]), (11, 0.804, 0.7502, 3.6, 0.05, [19, 19, 19, 20, 57])]\n",
      "Generation 11: 89.3 s, best val metric 0.8342, [(11, 0.8342, 0.7783, 4.0, 0.03, [19, 21, 20, 38, 80]), (11, 0.8241, 0.7689, 3.9, 0.09, [20, 23, 22, 28, 73]), (11, 0.8241, 0.7689, 3.9, 0.09, [20, 23, 22, 28, 73]), (11, 0.8241, 0.7689, 3.9, 0.09, [20, 23, 22, 28, 73]), (11, 0.8166, 0.7619, 3.5, 0.12, [19, 20, 20, 20, 57]), (11, 0.7965, 0.7431, 3.2, 0.02, [19, 13, 17, 19, 37]), (11, 0.7965, 0.7431, 3.2, 0.02, [19, 13, 17, 19, 37]), (12, 0.8216, 0.7153, 3.6, 0.11, [19, 18, 19, 20, 66]), (12, 0.8216, 0.7153, 4.1, 0.05, [22, 45, 33, 61, 104]), (11, 0.7638, 0.7127, 3.0, 0.05, [19, 12, 17, 19, 30]), (1, 0.706, 0.706, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 12: 90.2 s, best val metric 0.8342, [(11, 0.8342, 0.7783, 4.0, 0.03, [19, 21, 20, 38, 80]), (2, 0.7462, 0.7462, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7462, 0.7462, 3.0, 0.1, [20, 20, 20, 20, 20]), (12, 0.8241, 0.7174, 3.4, 0.14, [19, 17, 19, 20, 52]), (12, 0.8166, 0.7109, 3.9, 0.11, [20, 20, 21, 44, 89]), (12, 0.8116, 0.7065, 3.9, 0.09, [20, 24, 20, 38, 77]), (12, 0.8116, 0.7065, 3.9, 0.09, [20, 24, 20, 38, 77]), (12, 0.804, 0.6999, 3.9, 0.09, [20, 20, 22, 41, 83]), (12, 0.804, 0.6999, 3.2, 0.02, [19, 11, 16, 17, 34]), (12, 0.804, 0.6999, 3.2, 0.02, [19, 11, 16, 17, 34]), (1, 0.696, 0.696, 3.0, 0.1, [20, 20, 20, 20, 20])]\n",
      "Generation 13: 87.6 s, best val metric 0.8342, [(11, 0.8342, 0.7783, 4.0, 0.03, [19, 21, 20, 38, 80]), (3, 0.7739, 0.7739, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7739, 0.7739, 3.0, 0.1, [20, 20, 20, 20, 20]), (3, 0.7663, 0.7663, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.7588, 0.7588, 3.7, 0.12, [20, 20, 20, 20, 23]), (2, 0.7588, 0.7588, 3.7, 0.12, [20, 20, 20, 20, 23]), (3, 0.7563, 0.7563, 3.0, 0.12, [20, 20, 20, 20, 20]), (1, 0.7362, 0.7362, 3.0, 0.1, [20, 20, 20, 20, 20]), (12, 0.7889, 0.6868, 3.3, 0.09, [19, 18, 19, 20, 30]), (13, 0.809, 0.6571, 3.2, 0.02, [19, 11, 13, 14, 33]), (13, 0.809, 0.6571, 3.2, 0.02, [19, 11, 13, 14, 33])]\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "evolution = Evolution()\n",
    "evolution.run(x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test),\n",
    "              batch_size=32, layer_sizes=[20, 20, 20, 20, 20], output_neurons=10, learning_rate=0.0004, n_parents=5, strategy=[0.5, 0.05], \n",
    "              population_size=10, n_generations=50, tournament_size=3, n_introduced=2, age_penalty_period=10, use_static_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_convolutional_model(fashion_mnist.X_train_norm, [20, 20, 20, 20, 20], output_neurons=10)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################################\n",
      "Epoch 1/5\n",
      "loss: 1.79873526096344 - metric: 0.3645569682121277 - val_loss: 0.9276854395866394 - val_metric: 0.6903553299492385 - penalty: 0.0\n",
      "hidden layer sizes: [20, 20, 20, 20, 20], total units: 100\n",
      "##########################################################\n",
      "Epoch 2/5\n",
      "loss: 1.1402456760406494 - metric: 0.5814346075057983 - val_loss: 0.7516965866088867 - val_metric: 0.7411167512690355 - penalty: 0.0\n",
      "hidden layer sizes: [20, 20, 20, 20, 20], total units: 100\n",
      "##########################################################\n",
      "Epoch 3/5\n",
      "loss: 0.8846589922904968 - metric: 0.6818565130233765 - val_loss: 0.6932170391082764 - val_metric: 0.7715736040609137 - penalty: 0.0\n",
      "hidden layer sizes: [20, 20, 20, 20, 20], total units: 100\n",
      "##########################################################\n",
      "Epoch 4/5\n",
      "loss: 0.7778072357177734 - metric: 0.7054852247238159 - val_loss: 0.7420883774757385 - val_metric: 0.7360406091370558 - penalty: 0.0\n",
      "hidden layer sizes: [20, 20, 20, 20, 20], total units: 100\n",
      "##########################################################\n",
      "Epoch 5/5\n",
      "loss: 0.7572510838508606 - metric: 0.7316455841064453 - val_loss: 0.6774919629096985 - val_metric: 0.7715736040609137 - penalty: 0.0\n",
      "hidden layer sizes: [20, 20, 20, 20, 20], total units: 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [1.79873526096344,\n",
       "  1.1402456760406494,\n",
       "  0.8846589922904968,\n",
       "  0.7778072357177734,\n",
       "  0.7572510838508606],\n",
       " 'metric': [0.3645569682121277,\n",
       "  0.5814346075057983,\n",
       "  0.6818565130233765,\n",
       "  0.7054852247238159,\n",
       "  0.7316455841064453],\n",
       " 'val_loss': [0.9276854395866394,\n",
       "  0.7516965866088867,\n",
       "  0.6932170391082764,\n",
       "  0.7420883774757385,\n",
       "  0.6774919629096985],\n",
       " 'val_metric': [0.6903553299492385,\n",
       "  0.7411167512690355,\n",
       "  0.7715736040609137,\n",
       "  0.7360406091370558,\n",
       "  0.7715736040609137],\n",
       " 'hidden_layer_sizes': [[20, 20, 20, 20, 20],\n",
       "  [20, 20, 20, 20, 20],\n",
       "  [20, 20, 20, 20, 20],\n",
       "  [20, 20, 20, 20, 20],\n",
       "  [20, 20, 20, 20, 20]]}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schedule = Schedule([StaticEpochNoRegularization()] * 5)\n",
    "model.fit(x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, optimizer=optimizer, schedule=schedule, batch_size=32, min_new_neurons=20, \n",
    "                    validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test), growth_percentage=0.2, verbose=True, \n",
    "                    use_static_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_copy = model.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_copy.mutate(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################################\n",
      "Epoch 1/1\n",
      "loss: 0.48167261481285095 - metric: 0.8337552547454834 - val_loss: 0.6683802604675293 - val_metric: 0.7868020304568528 - penalty: 0.0\n",
      "hidden layer sizes: [20, 20, 20, 20, 20], total units: 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.48167261481285095],\n",
       " 'metric': [0.8337552547454834],\n",
       " 'val_loss': [0.6683802604675293],\n",
       " 'val_metric': [0.7868020304568528],\n",
       " 'hidden_layer_sizes': [[20, 20, 20, 20, 20]]}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schedule = Schedule([StaticEpochNoRegularization()] * 1)\n",
    "model_copy.fit(x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, optimizer=optimizer, schedule=schedule, batch_size=32, min_new_neurons=20, \n",
    "                    validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test), growth_percentage=0.2, verbose=True, \n",
    "                    use_static_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################################\n",
      "Epoch 1/10\n",
      "loss: 1.7691866159439087 - metric: 0.3856540024280548 - val_loss: 0.9637795686721802 - val_metric: 0.6294416243654822 - penalty: 0.01\n",
      "hidden layer sizes: [20, 20, 20, 20, 20], total units: 100\n",
      "##########################################################\n",
      "Epoch 2/10\n",
      "loss: 1.149412751197815 - metric: 0.5797468423843384 - val_loss: 0.815110981464386 - val_metric: 0.7106598984771574 - penalty: 0.01\n",
      "hidden layer sizes: [20, 20, 20, 20, 20], total units: 100\n",
      "##########################################################\n",
      "Epoch 3/10\n",
      "loss: 0.9344738721847534 - metric: 0.6632911562919617 - val_loss: 0.7585346698760986 - val_metric: 0.7360406091370558 - penalty: 0.01\n",
      "hidden layer sizes: [20, 20, 20, 20, 20], total units: 100\n",
      "##########################################################\n",
      "Epoch 4/10\n",
      "loss: 0.8739542365074158 - metric: 0.6835442781448364 - val_loss: 0.7149614095687866 - val_metric: 0.7360406091370558 - penalty: 0.01\n",
      "hidden layer sizes: [20, 20, 20, 20, 20], total units: 100\n",
      "##########################################################\n",
      "Epoch 5/10\n",
      "loss: 0.8130970597267151 - metric: 0.703797459602356 - val_loss: 0.6972656846046448 - val_metric: 0.766497461928934 - penalty: 0.01\n",
      "hidden layer sizes: [20, 20, 20, 20, 20], total units: 100\n",
      "##########################################################\n",
      "Epoch 6/10\n",
      "loss: 0.782306969165802 - metric: 0.7308017015457153 - val_loss: 0.6756644248962402 - val_metric: 0.7715736040609137 - penalty: 0.01\n",
      "hidden layer sizes: [20, 20, 20, 20, 20], total units: 100\n",
      "##########################################################\n",
      "Epoch 7/10\n",
      "loss: 0.7758747339248657 - metric: 0.7375527620315552 - val_loss: 0.6646133661270142 - val_metric: 0.7817258883248731 - penalty: 0.01\n",
      "hidden layer sizes: [20, 20, 20, 20, 20], total units: 100\n",
      "##########################################################\n",
      "Epoch 8/10\n",
      "loss: 0.7479051947593689 - metric: 0.7409282922744751 - val_loss: 0.6601444482803345 - val_metric: 0.8121827411167513 - penalty: 0.01\n",
      "hidden layer sizes: [20, 20, 20, 20, 20], total units: 100\n",
      "##########################################################\n",
      "Epoch 9/10\n",
      "loss: 0.7485364675521851 - metric: 0.7426160573959351 - val_loss: 0.6600654125213623 - val_metric: 0.7969543147208121 - penalty: 0.01\n",
      "hidden layer sizes: [20, 20, 20, 20, 20], total units: 100\n",
      "##########################################################\n",
      "Epoch 10/10\n",
      "loss: 0.7588427662849426 - metric: 0.7358649969100952 - val_loss: 0.6731001138687134 - val_metric: 0.7817258883248731 - penalty: 0.01\n",
      "hidden layer sizes: [20, 20, 20, 20, 20], total units: 100\n",
      "8.791603565216064\n",
      "##########################################################\n",
      "Epoch 1/10\n",
      "loss: 0.765278697013855 - metric: 0.743459939956665 - val_loss: 0.6758772134780884 - val_metric: 0.7918781725888325 - penalty: 0.01\n",
      "hidden layer sizes: [20, 20, 20, 20, 20], total units: 100\n",
      "##########################################################\n",
      "Epoch 2/10\n",
      "loss: 0.7541205286979675 - metric: 0.7485232353210449 - val_loss: 0.6897119283676147 - val_metric: 0.7766497461928934 - penalty: 0.01\n",
      "hidden layer sizes: [20, 20, 20, 20, 20], total units: 100\n",
      "##########################################################\n",
      "Epoch 3/10\n",
      "loss: 0.7397605776786804 - metric: 0.7510548233985901 - val_loss: 0.7040494084358215 - val_metric: 0.7817258883248731 - penalty: 0.01\n",
      "hidden layer sizes: [20, 20, 20, 20, 20], total units: 100\n",
      "##########################################################\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-2a891350b5cd>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, optimizer, schedule, batch_size, min_new_neurons, validation_data, pruning_threshold, regularization_penalty_multiplier, stall_coefficient, growth_percentage, mini_epochs_per_epoch, verbose, print_neurons, use_static_graph, loss_fn, metric_fn)\u001b[0m\n\u001b[1;32m   1018\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrow_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m             \u001b[0msummed_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummed_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_single_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprune\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-2a891350b5cd>\u001b[0m in \u001b[0;36mfit_single_epoch\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    992\u001b[0m                 \u001b[0mfit_single_step_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_single_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_single_step_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m                 \u001b[0msummed_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m                 \u001b[0msummed_metric\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/self-scaling-nets/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mWe\u001b[0m \u001b[0muse\u001b[0m \u001b[0mthis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m \u001b[0mto\u001b[0m \u001b[0mallow\u001b[0m \u001b[0muser\u001b[0m \u001b[0mannotated\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mto\u001b[0m \u001b[0mremain\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0mFunction\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mobjects\u001b[0m \u001b[0mbut\u001b[0m \u001b[0mstill\u001b[0m \u001b[0mautomatically\u001b[0m \u001b[0menter\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mModule\u001b[0m \u001b[0mname_scope\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m     \u001b[0mwhen\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mevaluated\u001b[0m \u001b[0mlike\u001b[0m \u001b[0mall\u001b[0m \u001b[0mother\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m     \u001b[0mArgs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/self-scaling-nets/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdouble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m     \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/self-scaling-nets/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattributes\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_capture_by_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcapture_by_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2941\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/self-scaling-nets/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m   \u001b[0mWhen\u001b[0m \u001b[0meager\u001b[0m \u001b[0mexecution\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0menabled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mability\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcreate\u001b[0m \u001b[0mgraphs\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPython\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m   \u001b[0mfunctions\u001b[0m \u001b[0mmakes\u001b[0m \u001b[0mit\u001b[0m \u001b[0mpossible\u001b[0m \u001b[0mto\u001b[0m \u001b[0mincrementally\u001b[0m \u001b[0mtrade\u001b[0m \u001b[0moff\u001b[0m \u001b[0mdebuggability\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m   \u001b[0minteractivity\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mperformance\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mFunctions\u001b[0m \u001b[0mcompiled\u001b[0m \u001b[0;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdefun\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mbe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m   \u001b[0minspected\u001b[0m \u001b[0;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mhowever\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecuting\u001b[0m \u001b[0ma\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/self-scaling-nets/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     relaxed_arg_shapes = [\n\u001b[1;32m   3195\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3196\u001b[0;31m         for x in nest.flatten(relaxed_arg_specs, expand_composites=True)]\n\u001b[0m\u001b[1;32m   3197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many_composite_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/self-scaling-nets/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0mignored\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0msignature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mprovided\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPython\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mcalled\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mignored\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0msignature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mprovided\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m     \u001b[0msignature\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpossibly\u001b[0m \u001b[0mnested\u001b[0m \u001b[0msequence\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensorSpecs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mspecifying\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;32mand\u001b[0m \u001b[0mdtypes\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mWhen\u001b[0m \u001b[0ma\u001b[0m \u001b[0msignature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mprovided\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/self-scaling-nets/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0mkey\u001b[0m \u001b[0minstance\u001b[0m \u001b[0ma\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0meffort\u001b[0m \u001b[0mto\u001b[0m \u001b[0mpreserve\u001b[0m \u001b[0;32mglobal\u001b[0m \u001b[0mconsistency\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m     \"\"\"\n\u001b[0;32m--> 634\u001b[0;31m     \u001b[0mtarget_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m     \u001b[0;31m# `__wrapped__` is a conventional Python attribute that a higher-order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m     \u001b[0;31m# function keeps its original function's instance.  We also directly use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/self-scaling-nets/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m \u001b[0;31m# TODO(mdan): Too many threaded arguments. Accept an ACD ctx manager instead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m def func_graph_from_py_func(name,\n\u001b[1;32m    968\u001b[0m                             \u001b[0mpython_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/self-scaling-nets/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/tmpmqff5nnf.py\u001b[0m in \u001b[0;36mtf__fit_single_step\u001b[0;34m(self, x_batch, y_batch, optimizer, loss_fn, metric_fn)\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                 \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/self-scaling-nets/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    348\u001b[0m       \u001b[0mnew_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0mnew_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m     logging.log(3, 'Forwarding call of partial %s with\\n%s\\n%s\\n', f, new_args,\n\u001b[0m\u001b[1;32m    351\u001b[0m                 new_kwargs)\n\u001b[1;32m    352\u001b[0m     return converted_call(\n",
      "\u001b[0;32m~/.miniconda3/envs/self-scaling-nets/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    477\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     file_bug_message = (\n\u001b[0;32m--> 479\u001b[0;31m         \u001b[0;34m'Please report this to the TensorFlow team. When filing the bug, set'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m         \u001b[0;34m' the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         ' attach the full output.\\n')\n",
      "\u001b[0;32m~/.miniconda3/envs/self-scaling-nets/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1078\u001b[0m       output_gradients = [None if x is None else ops.convert_to_tensor(x)\n\u001b[1;32m   1079\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[0;32m-> 1080\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1081\u001b[0m     flat_grad = imperative_grad.imperative_grad(\n\u001b[1;32m   1082\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/self-scaling-nets/lib/python3.8/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m       \u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m       compat.as_str(unconnected_gradients.value))\n",
      "\u001b[0;32m~/.miniconda3/envs/self-scaling-nets/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    154\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/self-scaling-nets/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mexecuting_eagerly_outside_functions\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5772\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5773\u001b[0m   \"\"\"Uses the default session to run \"operation\".\n\u001b[1;32m   5774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/self-scaling-nets/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_get_outer_context_and_inner_device_stack\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5604\u001b[0m   \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5605\u001b[0;31m    \u001b[0mA\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0mmanager\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mspecifies\u001b[0m \u001b[0mcontrol\u001b[0m \u001b[0mdependencies\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5606\u001b[0m    \u001b[0moperations\u001b[0m \u001b[0mconstructed\u001b[0m \u001b[0mwithin\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5607\u001b[0m   \"\"\"\n",
      "\u001b[0;32m~/.miniconda3/envs/self-scaling-nets/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_device_function_stack\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5068\u001b[0m           (hasattr(c, \"_handle\") and hasattr(c, \"op\"))):\n\u001b[1;32m   5069\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5070\u001b[0;31m       \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5071\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5072\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for _ in range(3000):\n",
    "    start_time = time.time()\n",
    "    schedule = Schedule([StaticEpoch(0.01, 'l1')] * 10)\n",
    "    model.fit(x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, optimizer=optimizer, schedule=schedule, batch_size=32, min_new_neurons=20, \n",
    "                        validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test), growth_percentage=0.2, verbose=True, \n",
    "                        use_static_graph=True)\n",
    "    print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratio 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed value 0.00041534645368884667 to 6ac1742dea.\n",
      "Run with parameters (0.0004, 6ac1742dea, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 6ac1742dea, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 1.0397995710372925, best_val_metric: 0.6842105263157895, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.0013678179300379248 to cdc55f9239.\n",
      "Run with parameters (0.0004, cdc55f9239, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, cdc55f9239, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.8996500968933105, best_val_metric: 0.7105263157894737, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.000487782514601775 to 2eddbf0c7c.\n",
      "Run with parameters (0.0004, 2eddbf0c7c, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 2eddbf0c7c, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.8693010210990906, best_val_metric: 0.631578947368421, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.00011441483511794696 to f2955a0fe5.\n",
      "Run with parameters (0.0004, f2955a0fe5, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, f2955a0fe5, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.8831897377967834, best_val_metric: 0.7105263157894737, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.0004694789752938634 to d9724a9a99.\n",
      "Run with parameters (0.0004, d9724a9a99, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, d9724a9a99, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.8598389625549316, best_val_metric: 0.7631578947368421, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.0010269961867697178 to 6b38632ca6.\n",
      "Run with parameters (0.0004, 6b38632ca6, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 6b38632ca6, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.8992174863815308, best_val_metric: 0.6842105263157895, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.0009707670038514038 to 1210dc71b3.\n",
      "Run with parameters (0.0004, 1210dc71b3, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 1210dc71b3, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.9041606783866882, best_val_metric: 0.6578947368421053, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.0006781580596374959 to cae00569c5.\n",
      "Run with parameters (0.0004, cae00569c5, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Interrupted by user.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "histories, best_overall_combination = random_search(\n",
    "    train_fn_conv, x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test), \n",
    "    learning_rate=0.0004, schedule=PowerRange(-4, -2.5, lambda x: Schedule([DynamicEpoch(x, 'weighted_l1')] * 20)), layer_sizes=[20, 20, 20, 20, 20], \n",
    "    output_neurons=10, min_new_neurons=20, growth_percentage=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed value 0.001439351576826643 to 30be2b3482.\n",
      "Run with parameters (0.0004, 30be2b3482, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 30be2b3482, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.95672208070755, best_val_metric: 0.6842105263157895, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.00025685508461890423 to bdcb7b6396.\n",
      "Run with parameters (0.0004, bdcb7b6396, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, bdcb7b6396, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.7996328473091125, best_val_metric: 0.6578947368421053, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.0031164959282910234 to cd16e3065c.\n",
      "Run with parameters (0.0004, cd16e3065c, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, cd16e3065c, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 1.1780805587768555, best_val_metric: 0.5789473684210527, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.00039122798800858045 to 9c60aa4e6a.\n",
      "Run with parameters (0.0004, 9c60aa4e6a, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 9c60aa4e6a, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.910222589969635, best_val_metric: 0.7368421052631579, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.00016212355399062043 to dab48fe66b.\n",
      "Run with parameters (0.0004, dab48fe66b, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, dab48fe66b, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.9001054167747498, best_val_metric: 0.7105263157894737, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.0023621582857491306 to eed005961e.\n",
      "Run with parameters (0.0004, eed005961e, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Interrupted by user.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "histories, best_overall_combination = random_search(\n",
    "    train_fn_conv, x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test), \n",
    "    learning_rate=0.0004, schedule=PowerRange(-4, -2.5, lambda x: Schedule([DynamicEpoch(x, 'weighted_l1')] * 20)), layer_sizes=[20, 20, 20, 20, 20], \n",
    "    output_neurons=10, min_new_neurons=20, growth_percentage=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed value 0.00042521825721349133 to fdf215cf84.\n",
      "Run with parameters (0.0004, fdf215cf84, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "WARNING:tensorflow:5 out of the last 7 calls to <bound method Sequential.fit_single_step of <__main__.Sequential object at 0x7f4bedb603d0>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 9 calls to <bound method Sequential.fit_single_step of <__main__.Sequential object at 0x7f4bedb603d0>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Run with parameters (0.0004, fdf215cf84, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.9520576596260071, best_val_metric: 0.6842105263157895, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.0008922229271696954 to 1789056010.\n",
      "Run with parameters (0.0004, 1789056010, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 1789056010, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.9162994027137756, best_val_metric: 0.7631578947368421, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.0010076891993239365 to fedfb3f038.\n",
      "Run with parameters (0.0004, fedfb3f038, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, fedfb3f038, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 1.0485434532165527, best_val_metric: 0.7105263157894737, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.002091455785870768 to 0baa2d3c61.\n",
      "Run with parameters (0.0004, 0baa2d3c61, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 0baa2d3c61, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.9740272164344788, best_val_metric: 0.7105263157894737, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.00016785810302952562 to 90717144e8.\n",
      "Run with parameters (0.0004, 90717144e8, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 90717144e8, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.7982632517814636, best_val_metric: 0.7631578947368421, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.00040009195727464626 to 0fbf479b7d.\n",
      "Run with parameters (0.0004, 0fbf479b7d, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 0fbf479b7d, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 1.1521357297897339, best_val_metric: 0.7105263157894737, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.00027008488381032833 to 860ccde53c.\n",
      "Run with parameters (0.0004, 860ccde53c, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 860ccde53c, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.8630073070526123, best_val_metric: 0.7368421052631579, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.0002815967117190191 to b6a4f82635.\n",
      "Run with parameters (0.0004, b6a4f82635, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, b6a4f82635, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 1.0314395427703857, best_val_metric: 0.7368421052631579, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.00013232409394243645 to 864ecfe8ae.\n",
      "Run with parameters (0.0004, 864ecfe8ae, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 864ecfe8ae, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 1.0115591287612915, best_val_metric: 0.7105263157894737, best_hidden_layer_sizes: [20, 20, 20, 21, 20]\n",
      "Transformed value 0.0016032890361876884 to 48d5819f9e.\n",
      "Run with parameters (0.0004, 48d5819f9e, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomSearch()\n",
    "random_search.run(\n",
    "    train_fn_conv, x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test), \n",
    "    learning_rate=0.0004, schedule=PowerRange(-4, -2.5, lambda x: Schedule([DynamicEpoch(x, 'weighted_l1')] * 20)), layer_sizes=[20, 20, 20, 20, 20], \n",
    "    output_neurons=10, min_new_neurons=20, growth_percentage=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(21.270880222320557, 0.6842105263157895),\n",
       " (42.808112382888794, 0.7631578947368421),\n",
       " (64.3229489326477, 0.7631578947368421),\n",
       " (85.85527348518372, 0.7631578947368421),\n",
       " (107.26386427879333, 0.7631578947368421),\n",
       " (128.31746411323547, 0.7631578947368421),\n",
       " (150.12859892845154, 0.7631578947368421),\n",
       " (171.3938684463501, 0.7631578947368421),\n",
       " (192.60103964805603, 0.7631578947368421)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4bedefb4f0>]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuYAAAHwCAYAAADq/qpIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAABYlAAAWJQFJUiTwAAA5GElEQVR4nO3df1zV9d3/8edpeZIDGcLMg0DO1ZDTQFwtvdYvKqnMXStheIvE3C7WvHKhuXZ1Q1fJqtkPdusqg5qsAicpWmraYRursTW3FWu5sKsixo6jCwgzJaPDD3/g+f7h95wr4oBwPihv5HH/p/V+vz+fz4vXPuf05MPnfI7N5/P5BAAAAGBYnTbcBQAAAAAgmAMAAABGIJgDAAAABiCYAwAAAAYgmAMAAAAGIJgDAAAABiCYAwAAAAYgmAMAAAAGIJgDAAAABiCYAwAAAAYgmAMAAAAGIJgDAAAABiCYAwAAAAYgmAMAAAAGOH0odtLW1qbCwkJVVVVp7969ioyMVGpqqpYtW6YJEyYcd/uqqiqtXbtWHo9HnZ2dio2N1axZs5STk6OzzjprKEoEAAAAjGbz+Xw+Kzvo6OhQVlaWPB6PsrOzlZSUpIaGBpWUlCg6OlqbN2/W+PHj+9z+0Ucf1Zo1a5ScnKz09HSFhYWppqZGW7Zs0aRJk/TCCy8oIiLCSokAAACA8SxfMS8rK1NdXZ3y8/M1f/78wLjL5VJubq6Ki4u1fPnyoNt+/PHHevrppxUbG6v169frjDPOkCRlZGQoMjJSxcXF2rx5s7773e9aLRMAAAAwmuV7zN1utxwOhzIzM3uMp6Wlyel0yu12q6+L8nv27NGRI0eUnJwcCOV+F154oSTpgw8+sFoiAAAAYDxLwdzr9aq+vl4ul0t2u73HnM1mU0pKivbt26empqag28fHx8tut6uhoaHXnH+bc88910qJAAAAwIhg6VYWf3iOiYkJOu90OiVJjY2Nio+P7zUfERGhW2+9VY8//rjuvfdeLViwQBEREdq1a5eefPJJJSQk6IYbbui3hp07d1r5EQAAAIBB8d/ZMdQsBfP29nZJUlhYWNB5/7jX6+1zH7fddpuioqL0wAMPaMOGDYHxK6+8Ug899JDGjh1rpUQAAABgRLAUzG02myT1eQ/559cF8+yzz+qBBx7Q5Zdfrm9961sKCwvTrl27tG7dOi1atEhPPfXUgB6ZeKJ+c+lPbW2tpGMfdMXg0LvQ0bvQ0bvQ0bvQ0bvQ0bvQ0bvQ9de7E32nhqVg7n+MYUdHR9B5/xX1vh536PF49MADD+iSSy7RmjVrAuNXXXWVXC6Xbr/9dv385z/v86kuAAAAwKnC0oc/4+LiZLPZ1NLSEnS+ublZkjR58uSg86+99pq6u7s1a9asXnNXXnmlbDabXn/9dSslAgAAACOCpWDucDjkcrlUW1urrq6uHnPd3d2qqalRbGysJk2aFHR7/zYHDx7sNXfw4EH5fD4dPnzYSokAAADAiGD5Oebp6enq6urSxo0be4xv375dra2tysjICIx5PB41NjYG/n369OmSpN/85je97lN/+eWXe6wBAAAATmWWv/kzKytLFRUVKigoUHNzs5KTk1VfX6/S0lIlJiYqJycnsHbOnDmaMmWKKisrJUlf//rXdc011+ill17STTfdpG9+85uKiIjQO++8o+eee07R0dFavHix1RIBAAAA41kO5na7XaWlpSoqKlJlZaXKy8sVHR2trKwsLV26VA6Ho9/tH330UW3YsEHbtm3TI488oiNHjujss8/W3Llz9YMf/CDwLHQAAADgVGY5mEtSeHi48vLylJeX1++6urq63gWcfroWLlyohQsXDkUpAAAAwIhk+R5zAAAAANYRzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAwzJN38CT+3Yrcd+9w+1H+oe5Ja7T0g9owO9Cx29Cx29Cx29Cx29C92p2btw+xe0LC1B37/8y8NdypDiijmGRGihHAAAYPDaD3XrqT+der90EMwxJAjlAADgZAm3f0Hfv+zUuloucSsLToCGh7553DW1tbWSJJfLdaLLOeXQu9DRu9DRu9DRu9DRu9DRu5GJK+YAAACAAQjmAAAAgAEI5gAAAIABCOYAAACAAQjmAAAAgAEI5gAAAIABCOYAAACAAQjmAAAAgAEI5gAAAIABCOYAAACAAQjmAAAAgAEI5gAAAIABCOYAAACAAQjmAAAAgAEI5gAAAIABCOYAAACAAQjmAAAAgAEI5gAAAIABCOYAAACAAQjmAAAAgAEI5gAAAIABCOYAAACAAQjmAAAAgAEI5gAAAIABTh+KnbS1tamwsFBVVVXau3evIiMjlZqaqmXLlmnChAl9brd161atWLGi333PmDFDZWVlQ1EmAAAAYCzLwbyjo0MLFiyQx+NRdna2kpKS1NDQoJKSElVXV2vz5s0aP3580G1nzpyp1atXB53bs2ePHnzwQX3lK1+xWiIAAABgPMvBvKysTHV1dcrPz9f8+fMD4y6XS7m5uSouLtby5cuDbhsbG6vY2Nigc4sWLVJ0dLRuv/12qyUCAAAAxrN8j7nb7ZbD4VBmZmaP8bS0NDmdTrndbvl8vkHt8ze/+Y3++Mc/6s4779RZZ51ltUQAAADAeJaCudfrVX19vVwul+x2e485m82mlJQU7du3T01NTQPeZ1dXl372s59p2rRpmjt3rpXyAAAAgBHD0q0s/sAdExMTdN7pdEqSGhsbFR8fP6B9rl+/Xs3NzXr44Ydls9kGXEttbe2A1w6Vzs7OYTu2yQbSD3oXOnoXOnoXOnoXOnoXOnoXOnoXuuHsnaUr5u3t7ZKksLCwoPP+ca/XO6D9dXZ26umnn9aMGTN00UUXWSkNAAAAGFEsXTH3X9E+3j3kA73y/eKLL6q1tVXZ2dmDrsXlcg16G6v8v0kNx7HNszvwvwbSD3oXOnoXOnoXOnoXOnoXOnoXOnoXuv56t3PnzhN6bEtXzCMiIiQde2RiMP4r6v51x/Pcc88pMjJSs2bNslIWAAAAMOJYCuZxcXGy2WxqaWkJOt/c3CxJmjx58nH31dTUpLfffluXXXaZxowZY6UsAAAAYMSxFMwdDodcLpdqa2vV1dXVY667u1s1NTWKjY3VpEmTjruvV199VdKxLx0CAAAARhvLzzFPT09XV1eXNm7c2GN8+/btam1tVUZGRmDM4/GosbEx6H7eeustSdLUqVOtlgQAAACMOJa/+TMrK0sVFRUqKChQc3OzkpOTVV9fr9LSUiUmJionJyewds6cOZoyZYoqKyt77ef999+XdOz2GAAAAGC0sRzM7Xa7SktLVVRUpMrKSpWXlys6OlpZWVlaunSpHA7HgPbzySefSBr4B0VNsOWdA1pf87E6j+w+/mIAAACgH5aDuSSFh4crLy9PeXl5/a6rq6vrc+7FF18cilJOqmOhvP9HRY424fYvDHcJAAAAI5Lle8xHM0J5T+H2L2hZWsJwlwEAADAiDckVc0gND31zuEsAAADACMYVcwAAAMAABHMAAADAAARzAAAAwAAEcwAAAMAABHMAAADAAARzAAAAwAAEcwAAAMAABHMAAADAAARzAAAAwAAEcwAAAMAABHMAAADAAARzAAAAwAAEcwAAAMAABHMAAADAAARzAAAAwAAEcwAAAMAABHMAAADAAARzAAAAwAAEcwAAAMAABHMAAADAAARzAAAAwAAEcwAAAMAABHMAAADAAARzAAAAwAAEcwAAAMAABHMAAADAAARzAAAAwAAEcwAAAMAABHMAAADAAARzAAAAwAAEcwAAAMAABHMAAADAAARzAAAAwAAEcwAAAMAABHMAAADAAKcPxU7a2tpUWFioqqoq7d27V5GRkUpNTdWyZcs0YcKE425/6NAhrVmzRm63W3v27FF0dLRSU1O1dOlSRUdHD0WJAAAAgNEsB/OOjg4tWLBAHo9H2dnZSkpKUkNDg0pKSlRdXa3Nmzdr/PjxfW5/5MgRLVq0SG+88YZuvvlmJSYm6t1331VZWZl27typrVu3ym63Wy0TAAAAMJrlYF5WVqa6ujrl5+dr/vz5gXGXy6Xc3FwVFxdr+fLlfW6/adMmvfbaa3rsscd03XXXSZJuuOEGjRs3Tlu3btWuXbt00UUXWS0TAAAAMJrle8zdbrccDocyMzN7jKelpcnpdMrtdsvn8/W5/fr16+VyuQKh3O+2225TVVUVoRwAAACjgqVg7vV6VV9fL5fL1et2E5vNppSUFO3bt09NTU1Bt//www/l8Xh06aWXBsYOHjyoo0ePWikLAAAAGHEs3criD9wxMTFB551OpySpsbFR8fHxveY9Ho8k6ZxzztEzzzyjsrIytbS0aMyYMbrkkku0fPlyTZkyZUC11NbWhvIjDJnhPv5I09nZKYm+hYLehY7ehY7ehY7ehY7ehY7ehW44e2cpmLe3t0uSwsLCgs77x71eb9D5AwcOSDp2O4skLV26VGeddZaqq6u1fv167dq1S9u3b9fEiROtlAkAAAAYz1Iwt9lsktTvPeSfXfd5hw8fliR9+umnqqiokMPhkCTNmjVLEyZM0COPPKKSkhKtWLHiuLW4XK7BlD5Edg/z8Ucu/2+h9G3w6F3o6F3o6F3o6F3o6F3o6F3o+uvdzp07T+ixLd1jHhERIenYIxOD8V9R96/7PH8Qv+KKKwL/2y89PV2S9Le//c1KiQAAAMCIYCmYx8XFyWazqaWlJeh8c3OzJGny5Ml9bi9Jp53Wu4yoqCjZbLZAuAcAAABOZZaCucPhkMvlUm1trbq6unrMdXd3q6amRrGxsZo0aVLQ7c877zydeeaZqqur6zXX0tIin8+ns88+20qJAAAAwIhg+Tnm6enp6urq0saNG3uMb9++Xa2trcrIyAiMeTweNTY2Bv59zJgxuv766/X666/rjTfe6LH9s88+K0lKTU21WiIAAABgPMvf/JmVlaWKigoVFBSoublZycnJqq+vV2lpqRITE5WTkxNYO2fOHE2ZMkWVlZWBsdzcXO3YsUO33nqrcnJy5HQ69eqrr8rtdmvq1KnKzs62WiIAAABgPMvB3G63q7S0VEVFRaqsrFR5ebmio6OVlZWlpUuX9vpQ5+dFRUVp06ZNWr16tTZs2KADBw5owoQJWrhwoZYsWdLnoxgBAACAU4nlYC5J4eHhysvLU15eXr/rgt1LLknR0dG67777dN999w1FOQAAAMCIY/kecwAAAADWEcwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADnD4UO2lra1NhYaGqqqq0d+9eRUZGKjU1VcuWLdOECRP63Xbq1Kn9zv/tb3/TuHHjhqJMAAAAwFiWg3lHR4cWLFggj8ej7OxsJSUlqaGhQSUlJaqurtbmzZs1fvz4fvdx3nnnacmSJUHnwsLCrJYIAAAAGM9yMC8rK1NdXZ3y8/M1f/78wLjL5VJubq6Ki4u1fPnyfvcRFRWl2bNnWy0FAAAAGLEs32PudrvlcDiUmZnZYzwtLU1Op1Nut1s+n8/qYQAAAIBTmqVg7vV6VV9fL5fLJbvd3mPOZrMpJSVF+/btU1NT04D32dXVZaUkAAAAYESydCuLP3DHxMQEnXc6nZKkxsZGxcfH97mfjz/+WCtWrNDvf/97HThwQA6HQ1deeaXy8vI0ceLEAdVSW1s7yOqH1nAff6Tp7OyURN9CQe9CR+9CR+9CR+9CR+9CR+9CN5y9sxTM29vbJfX9AU3/uNfr7Xc/9fX1Ov/883XXXXfpjDPO0CuvvKKtW7fq73//u7Zu3aqoqCgrZQIAAADGsxTMbTabJB33HnL/umCeeuopjR8/XsnJyYGxa6+9VmeffbbWrFmjZ555Rnfeeedxa3G5XAOseijtHubjj1z+30Lp2+DRu9DRu9DRu9DRu9DRu9DRu9D117udO3ee0GNbusc8IiJC0rFHJgbjv6LuXxfM5Zdf3iOU+2VnZ0uSXnvtNSslAgAAACOCpWAeFxcnm82mlpaWoPPNzc2SpMmTJw9631FRUbLZbIFwDwAAAJzKLAVzh8Mhl8ul2traXk9T6e7uVk1NjWJjYzVp0qSg29fV1WnTpk1qbGzsNff+++/L5/P1+cFSAAAA4FRi+Tnm6enp6urq0saNG3uMb9++Xa2trcrIyAiMeTyeHiHc4/Fo5cqVevTRR3vt96mnnpIkXXPNNVZLBAAAAIxn+Zs/s7KyVFFRoYKCAjU3Nys5OVn19fUqLS1VYmKicnJyAmvnzJmjKVOmqLKyUpJ09dVX6+KLL9avfvUrffrpp7r66qt15MgRVVVV6c9//rMuvvhizZs3z2qJAAAAgPEsB3O73a7S0lIVFRWpsrJS5eXlio6OVlZWlpYuXSqHw9HntmPGjNGTTz6p9evXy+126+GHH9bhw4c1ZcoU3XnnnfrOd76jMWPGWC0RAAAAMJ7lYC5J4eHhysvLU15eXr/r6urqeo2FhYXplltu0S233DIUpQAAAAAjkuV7zAEAAABYRzAHAAAADEAwBwAAAAxAMAcAAAAMQDAHAAAADEAwBwAAAAxAMAcAAAAMQDAHAAAADEAwBwAAAAxAMAcAAAAMQDAHAAAADEAwBwAAAAxAMAcAAAAMQDAHAAAADEAwBwAAAAxAMAcAAAAMQDAHAAAADEAwBwAAAAxAMAcAAAAMQDAHAAAADEAwBwAAAAxAMAcAAAAMQDAHAAAADEAwBwAAAAxAMAcAAAAMQDAHAAAADEAwBwAAAAxAMAcAAAAMQDAHAAAADEAwBwAAAAxAMAcAAAAMQDAHAAAADEAwBwAAAAxAMAcAAAAMQDAHAAAADEAwBwAAAAxAMAcAAAAMMCTBvK2tTatWrdJVV12lpKQkXXrppbrrrrv00UcfDXpfBw8e1LXXXqupU6fqr3/961CUBwAAABjvdKs76Ojo0IIFC+TxeJSdna2kpCQ1NDSopKRE1dXV2rx5s8aPHz/g/T355JNqaGiwWhYAAAAwolgO5mVlZaqrq1N+fr7mz58fGHe5XMrNzVVxcbGWL18+oH3V1dXpmWeekcvlUm1trdXSAAAAgBHD8q0sbrdbDodDmZmZPcbT0tLkdDrldrvl8/mOu5+jR4/qnnvuUWxsrLKysqyWBQAAAIwoloK51+tVfX29XC6X7HZ7jzmbzaaUlBTt27dPTU1Nx93Xs88+q7feeks//elPe+0LAAAAONVZupXFH7hjYmKCzjudTklSY2Oj4uPj+9xPS0uLHn30Uc2bN08XXXSRGhsbB13LcN/6MtzHH2k6Ozsl0bdQ0LvQ0bvQ0bvQ0bvQ0bvQ0bvQDWfvLF0xb29vlySFhYUFnfePe73efvfzk5/8ROHh4brzzjutlAMAAACMWJaumNtsNkk67j3k/nXB/OpXv9Irr7yi1atXa9y4cSHX4nK5Qt42dLuH+fgjl/+3UPo2ePQudPQudPQudPQudPQudPQudP31bufOnSf02JaumEdEREg69sjEYPxX1P3rPu/AgQOB55/Pnj3bSikAAADAiGbpinlcXJxsNptaWlqCzjc3N0uSJk+eHHS+oKBAnZ2dWrx4sfbs2RMYb2trkyS1trZqz549ioqK4gOhAAAAOKVZCuYOhyPwzPGuri6NHTs2MNfd3a2amhrFxsZq0qRJQbevrq5WR0eH5s2bF3R+2bJlkqR169Zp5syZVkoFAAAAjGb5C4bS09O1atUqbdy4Ud/97ncD49u3b1dra6uWLFkSGPN4PLLb7YEntKxatUpdXV299vnaa6/pl7/8pe644w4lJCQoISHBapkAAACA0SwH86ysLFVUVKigoEDNzc1KTk5WfX29SktLlZiYqJycnMDaOXPmaMqUKaqsrJQkfeMb3wi6z48//liSNH36dK6UAwAAYFSwHMztdrtKS0tVVFSkyspKlZeXKzo6WllZWVq6dKkcDsdQ1AkAAACc0iwHc0kKDw9XXl6e8vLy+l1XV1c3oP1lZGQoIyNjKEoDAAAARgRLj0sEAAAAMDQI5gAAAIABCOYAAACAAQjmAAAAgAEI5gAAAIABCOYAAACAAQjmAAAAgAEI5gAAAIABCOYAAACAAQjmAAAAgAEI5gAAAIABCOYAAACAAQjmAAAAgAEI5gAAAIABCOYAAACAAQjmAAAAgAEI5gAAAIABCOYAAACAAQjmAAAAgAEI5gAAAIABCOYAAACAAQjmAAAAgAEI5gAAAIABCOYAAACAAQjmAAAAgAEI5gAAAIABCOYAAACAAQjmAAAAgAEI5gAAAIABCOYAAACAAQjmAAAAgAEI5gAAAIABCOYAAACAAQjmAAAAgAEI5gAAAIABCOYAAACAAU4fip20tbWpsLBQVVVV2rt3ryIjI5Wamqply5ZpwoQJ/W579OhR/epXv9KGDRu0e/duHT58WLGxsbruuuu0cOFCRUREDEWJAAAAgNEsB/OOjg4tWLBAHo9H2dnZSkpKUkNDg0pKSlRdXa3Nmzdr/PjxfW5/9913a8uWLbr44ov1wx/+UF/4whf0yiuvaPXq1Xr55Ze1adMm2e12q2UCAAAARrMczMvKylRXV6f8/HzNnz8/MO5yuZSbm6vi4mItX7486LZvv/22tmzZotTUVP3iF78IjM+bN08/+MEPVFVVpVdeeUXXXHON1TIBAAAAo1m+x9ztdsvhcCgzM7PHeFpampxOp9xut3w+X9Btx44dqzvuuEO5ubm95i6++GJJ0p49e6yWCAAAABjP0hVzr9er+vp6XXjhhb1uN7HZbEpJSdFvf/tbNTU1KT4+vtf25513ns4777yg+66rq5MkJSQkWCkRAAAAGBEsBfOmpiZJUkxMTNB5p9MpSWpsbAwazD/r0KFD6ujo0N69e1VRUaHnn39e8+bN07/9278NqJba2tpBVD70hvv4I01nZ6ck+hYKehc6ehc6ehc6ehc6ehc6ehe64eydpWDe3t4uSQoLCws67x/3er3H3VdFRYVWrFghSRo/frzuv/9+zZs3z0p5AAAAwIhhKZjbbDZJ6vMe8s+v689ll12mtWvX6qOPPtKf//xn5efn689//rN+9rOfDeipLC6Xa2BFD6ndw3z8kcv/Wyh9Gzx6Fzp6Fzp6Fzp6Fzp6Fzp6F7r+erdz584TemxLwdz/jPGOjo6g8/4r6gN5FvmECRMCzzy//vrrdf755+vBBx9UQkKCbrvtNitlAgAAAMaz9FSWuLg42Ww2tbS0BJ1vbm6WJE2ePHnQ+77hhhskSX/6059CLxAAAAAYISwFc4fDIZfLpdraWnV1dfWY6+7uVk1NjWJjYzVp0qSg2xcWFmrmzJn6y1/+0mvu0KFDgf0AAAAApzrLzzFPT09XV1eXNm7c2GN8+/btam1tVUZGRmDM4/GosbEx8O+JiYk6cOCAysrKeu1327ZtkqQLLrjAaokAAACA8Sx/82dWVpYqKipUUFCg5uZmJScnq76+XqWlpUpMTFROTk5g7Zw5czRlyhRVVlZKOvYlRFdccYX+8Ic/6Oabb9bs2bM1duxY/e1vf9O2bdvkdDp1yy23WC0RAAAAMJ7lYG6321VaWqqioiJVVlaqvLxc0dHRysrK0tKlS+VwOPrc1maz6YknntC2bdv0/PPPq7CwUF6vVxMnTtRNN92kH/zgB4EPhAIAAACnMsvBXJLCw8OVl5envLy8ftf5v82zRwGnn67MzExlZmYORSkAAADAiGT5HnMAAAAA1hHMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAA5w+FDtpa2tTYWGhqqqqtHfvXkVGRio1NVXLli3ThAkTjrv9G2+8oeLiYtXW1qq9vV3x8fGaPXu2cnJyNHbs2KEoEQAAADCa5WDe0dGhBQsWyOPxKDs7W0lJSWpoaFBJSYmqq6u1efNmjR8/vs/tf/3rX+uOO+7Ql770Jd1yyy2KiIjQjh07tHr1au3YsUMbNmzQaadxYR8AAACnNsvBvKysTHV1dcrPz9f8+fMD4y6XS7m5uSouLtby5cuDbnvo0CHdc889iomJ0fPPP68zzzxTkpSZmaklS5bopZde0o4dO3TFFVdYLRMAAAAwmuVL0W63Ww6HQ5mZmT3G09LS5HQ65Xa75fP5gm67b98+XX311Vq0aFEglPtddtllkqR//OMfVksEAAAAjGcpmHu9XtXX18vlcslut/eYs9lsSklJ0b59+9TU1BR0+0mTJumhhx7STTfd1Gvu008/laRegR0AAAA4FVm6lcUfuGNiYoLOO51OSVJjY6Pi4+MHvN9Dhw5py5Ytstvtuuqqqwa0TW1t7YD3fyIM9/FHms7OTkn0LRT0LnT0LnT0LnT0LnT0LnT0LnTD2TtLV8zb29slSWFhYUHn/eNer3fA+zx69KjuueceeTwe5ebmauLEiVZKBAAAAEYES1fMbTabJPV5D/nn1x1PV1eXfvSjH+l3v/ud5s2bp0WLFg24FpfLNeC1Q2f3MB9/5PL/FkrfBo/ehY7ehY7ehY7ehY7ehY7eha6/3u3cufOEHttSMI+IiJB07JGJwfivqPvX9ae1tVWLFy9WTU2Nbr31Vi1btmzAgR4AAAAY6SwF87i4ONlsNrW0tASdb25uliRNnjy53/3s27dP2dnZam5u1sMPP6y5c+daKQsAAAAYcSwFc4fDIZfLpdraWnV1dfX4ls7u7m7V1NQoNjZWkyZN6nMfXq9Xt9xyi/bs2aNf/OIXuvjii62UBAAAAIxIlp9jnp6erq6uLm3cuLHH+Pbt29Xa2qqMjIzAmMfjUWNjY491q1at0nvvvaf//u//JpQDAABg1LL8zZ9ZWVmqqKhQQUGBmpublZycrPr6epWWlioxMVE5OTmBtXPmzNGUKVNUWVkpSXrvvff0wgsvKCEhQYcPHw6Mf1ZUVJRmzJhhtUwAAADAaJaDud1uV2lpqYqKilRZWany8nJFR0crKytLS5culcPh6HPbd999Vz6fT3V1dbr99tuDrpkxY4bKysqslgkAAAAYzXIwl6Tw8HDl5eUpLy+v33V1dXU9/j0jI6PHrS4AAADAaGX5HnMAAAAA1hHMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAwxJMG9ra9OqVat01VVXKSkpSZdeeqnuuusuffTRRwPex/vvv6/MzExNnTpVW7duHYqyAAAAgBHjdKs76Ojo0IIFC+TxeJSdna2kpCQ1NDSopKRE1dXV2rx5s8aPH9/vPrZs2aKf/vSnVksBAAAARizLwbysrEx1dXXKz8/X/PnzA+Mul0u5ubkqLi7W8uXL+9x+06ZNWrlypW6++WZ95Stf0cqVK62WBAAAAIw4lm9lcbvdcjgcyszM7DGelpYmp9Mpt9stn8/X7z6eeOIJ3X333RozZozVcgAAAIARyVIw93q9qq+vl8vlkt1u7zFns9mUkpKiffv2qampqc993HjjjUpLS7NSBgAAADDiWbqVxR+4Y2Jigs47nU5JUmNjo+Lj460c6rhqa2tP6P5NP/5I09nZKYm+hYLehY7ehY7ehY7ehY7ehY7ehW44e2fpinl7e7skKSwsLOi8f9zr9Vo5DAAAAHDKs3TF3GazSdJx7yH3rzuRXC7XCT9Gb7uH+fgjl/+3UPo2ePQudPQudPQudPQudPQudPQudP31bufOnSf02JaumEdEREg69sjEYPxX1P3rAAAAAARnKZjHxcXJZrOppaUl6Hxzc7MkafLkyVYOAwAAAJzyLAVzh8Mhl8ul2tpadXV19Zjr7u5WTU2NYmNjNWnSJEtFAgAAAKc6y88xT09PV1dXlzZu3NhjfPv27WptbVVGRkZgzOPxqLGx0eohAQAAgFOO5W/+zMrKUkVFhQoKCtTc3Kzk5GTV19ertLRUiYmJysnJCaydM2eOpkyZosrKysDYH//4x8Bjad5+++3APx0OhyQpKipKM2bMsFomAAAAYDTLwdxut6u0tFRFRUWqrKxUeXm5oqOjlZWVpaVLlwYCdl/uvffewL3ofuvXr9f69eslSTNmzFBZWZnVMgEAAACjWQ7mkhQeHq68vDzl5eX1u66urq7X2O9///uhKAEAAAAY0SzfYw4AAADAOoI5AAAAYACCOQAAAGAAgjkAAABgAII5AAAAYACCOQAAAGAAgjkAAABgAII5AAAAYACCOQAAAGAAgjkAAABgAII5AAAAYACCOQAAAGAAgjkAAABgAII5AAAAYACCOQAAAGAAgjkAAABgAII5AAAAYACCOQAAAGAAgjkAAABgAII5AAAAYACCOQAAAGAAgjkAAABgAII5AAAAYACCOQAAAGAAgjkAAABgAII5AAAAYACCOQAAAGAAgjkAAABgAII5AAAAYACCOQAAAGAAgjkAAABgAII5AAAAYACCOQAAAGAAgjkAAABgAII5AAAAYACCOQAAAGAAgjkAAABggNOHYidtbW0qLCxUVVWV9u7dq8jISKWmpmrZsmWaMGHCcbevqanRE088oZqaGh08eFCTJ0/WjTfeqPnz5+u00/jdAQAAAKc+y8G8o6NDCxYskMfjUXZ2tpKSktTQ0KCSkhJVV1dr8+bNGj9+fJ/bv/baa/r+978vp9Op2267TZGRkXrppZd0//33q6GhQXfffbfVEgEAAADjWQ7mZWVlqqurU35+vubPnx8Yd7lcys3NVXFxsZYvXx50W5/Pp3vvvVdjx47Vhg0bdPbZZ0uS5s6dq8WLF+vZZ59VZmamEhMTrZYJAAAAGM3yfSJut1sOh0OZmZk9xtPS0uR0OuV2u+Xz+YJu+/bbb+tf//qXrrvuukAo97v55pvl8/n04osvWi0RAAAAMJ6lYO71elVfXy+XyyW73d5jzmazKSUlRfv27VNTU1PQ7Xft2iVJmjZtWq+5lJSUHmsAAACAU5mlW1n8gTsmJibovNPplCQ1NjYqPj6+13xjY2Of24eHh2vcuHGBNcdTW1s7oHUnynAff6Tp7OyURN9CQe9CR+9CR+9CR+9CR+9CR+9CN5y9s3TFvL29XZIUFhYWdN4/7vV6Q96+r21NMPZ0myQp7P//EwAAAAiVpSvmNtuxQNrXPeSfXxfK9n1t+3kul2tA64bSgukHtPWdT7T4ygS5XF8+6ccfyfy/hQ7H/28jHb0LHb0LHb0LHb0LHb0LHb0LXX+927lz5wk9tqVgHhERIenYIxOD8V8R968LZfszzzzTSokn1Le/GqlvfzWSUA4AAADLLN3KEhcXJ5vNppaWlqDzzc3NkqTJkycHnfffdx5s+08++URer1fnnHOOlRIBAACAEcFSMHc4HHK5XKqtrVVXV1ePue7ubtXU1Cg2NlaTJk0Kuv0FF1wg6dg3f37eG2+8IUn6+te/bqVEAAAAYESw/Bzz9PR0dXV1aePGjT3Gt2/frtbWVmVkZATGPB5Pj6esJCYm6vzzz1dlZWWPq+Y+n09r167V6aefrrlz51otEQAAADCe5W/+zMrKUkVFhQoKCtTc3Kzk5GTV19ertLRUiYmJysnJCaydM2eOpkyZosrKysBYfn6+Fi5cqOzsbH3nO9/RuHHjVFFRoddff1233347t7IAAABgVLAczO12u0pLS1VUVKTKykqVl5crOjpaWVlZWrp0qRwOR7/bT58+XeXl5Xr88cdVWFiow4cP69xzz9XDDz/M1XIAAACMGpaDuXTsy4Dy8vKUl5fX77q6urqg41/96ldVXFw8FKUAAAAAI5Lle8wBAAAAWEcwBwAAAAxAMAcAAAAMQDAHAAAADEAwBwAAAAxAMAcAAAAMQDAHAAAADEAwBwAAAAxAMAcAAAAMQDAHAAAADGDz+Xy+4S7Cip07dw53CQAAABhFLrzwwhOyX66YAwAAAAYY8VfMAQAAgFMBV8wBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADnD7cBYxEbW1tKiwsVFVVlfbu3avIyEilpqZq2bJlmjBhwnCXZ4T9+/drzZo12rFjh/bs2aMvfvGLmjZtmpYsWaIvf/nLgXWFhYUqKirqcz8LFy7UXXfddTJKNsLy5cv1wgsv9Dm/YsUKffe735UkHTx4UL/4xS9UUVGhDz74QBEREZoxY4Z++MMf6ktf+tLJKdggU6dOPe6aqqoqxcXFcd5JOnTokB577DGVlJTooosuUllZWa81gznHuru7VVZWpi1btuj999/X2LFjNX36dC1ZskTJyckn6ac6OQbSO6/Xq9LSUv32t79VU1OTzjrrLCUmJuq2227TtGnTAuu2bt2qFStW9HmsWbNm6cknnzwhP8dwOF7vBvva5Lz7P1dddZWam5v73ce6des0c+bMUXPeDTSLSOa83xHMB6mjo0MLFiyQx+NRdna2kpKS1NDQoJKSElVXV2vz5s0aP378cJc5rPbv36958+Zp//79uummm5SYmKiGhgatW7dOVVVVKi8v11e/+tUe2yxZskTnnXder32NxoApSfn5+YqKiuo17nK5JElHjx7VrbfeqldffVUZGRlavHix9u7dq9LSUt1444167rnnNHny5JNd9rBavXp1n3OPPPKIOjo6evV0tJ53u3fv1n/913/pX//6l/r6KovBnmP33HOPtmzZolmzZiknJ0dtbW1at26d5s+fr3Xr1ulrX/vayfrxTqiB9K6zs1MLFy7Ue++9p29/+9v63ve+p71792rdunW68cYb9fOf/1xXXHFFj22ys7M1Y8aMXvuaOHHiifgxhsVAeuc30Ncm593/yc/PV2dnZ9C50tJSvffeezrnnHN6jJ/K591gsohR73c+DMqaNWt8CQkJvvXr1/cYf+mll3wJCQm+Bx98cJgqM8fKlSt9CQkJvpdeeqnHeFVVlS8hIcG3ZMmSwNjjjz/uS0hI8FVXV5/sMo2Ul5fnS0hI8DU2Nva7zu12+xISEnwFBQU9xv/nf/7HN3XqVF9ubu6JLHNE+fWvf+1LSEjwvfjii4Gx0XzeHThwwJeSkuK7/vrrfR6Px5eQkOBbsGBBr3WDOcf+/ve/+xISEny33357j7UffPCBb/r06b709PQT8rOcbAPtXXFxsS8hIcFXWlraY7y2ttaXkJDgy8jICIxt2bLFl5CQ4NuyZcuJLn9YDbR3g3ltct4NzJtvvulLTEz0/fznPw+MjYbzbjBZxKT3O+4xHyS32y2Hw6HMzMwe42lpaXI6nXK73ce9EnCqmzBhgv793/9daWlpPcYvvfRS2Ww2/eMf/ximyk4dbrdb0rE/635WUlKSvva1r+kPf/iDPv300+EozSher1erVq3SzJkz9a1vfWu4yzHC4cOHdcMNN+i5557r9afczxrMOdbX2piYGM2aNUvvvPOO/vnPfw7ljzEsBtq78PBwXXvttfr2t7/dYzwxMVFnn332qHwPHGjvBoPz7vi6u7u1cuVKnXPOOcrJyTlBFZppMFnEpPc7gvkgeL1e1dfXy+VyyW6395iz2WxKSUnRvn371NTUNEwVmiE3N1ePPPKIbDZbj3Gv1yufz6dx48b1uW13d7cOHTp0okscMQ4fPqwjR470Gq+pqZHT6Qz658bp06fr8OHDevvtt09GiUZ78skntX///uPeLz6azrsvfvGLuvfee3XGGWf0u24w51hNTY1OO+00JSUlBV3rXzPSDbR32dnZevzxx3XmmWf2GO/u7lZnZ2e/74E+n08HDx4cknpNMtDefV5/r03Ou+PbuHGj6urq9OMf/7hXbvmsU/G8G0wWMen9jmA+CP7AHRMTE3Te6XRKkhobG09aTSPJxo0bJUmzZ8/uNVdZWanrr79eKSkpSk5O1nXXXaetW7ee7BKNUV5ermuvvVYpKSlKSkpSRkaG/vCHP0g69qZy4MCB456Ho/0XxD179qisrExz587t84OhnHfBDfYca2pqUnR0dND/8PO++H8qKir06aefBn0PrK6uVlZWlqZNm6Zp06bpqquu0jPPPKOjR48OQ6XDbyCvTc67/nV0dOiJJ57QzJkzlZqaGnTNaDzvPp9FTHu/48Ofg9De3i5JCgsLCzrvH/d6vSetppHij3/8o5588klNnTpV2dnZQeezs7N17rnnqrm5WU8//bRWrFih/fv36/vf//4wVDy8duzYoZtvvllxcXH65z//qaeeekqLFy/WI488oq9//euS+j4PHQ6HJM7D4uJiHTlyRIsXL+5zDeddcMd7r/v8Odbe3q7IyMh+1/r3OVq98847uu+++zRx4kTddtttveb9r/lFixZp//79WrdunQoKCtTY2Kif/OQnJ7/gYTaQ1ybnXf82bNig/fv369FHH+1zzWg774JlEdPe7wjmg+D/c8jx7iH//J9NRrtt27bp7rvvltPp1Jo1a3r8Oc5/RWT69Ok9/qw0e/ZsXXfddSosLNS8efP6fBGcav7jP/5D3/zmNzVz5szAb+NXXHGFrrjiCs2dO1cPPvigtmzZIonzsD9tbW164YUXdPnll/d6CoHEeTdQAz3HbDbbqP9sTX/+8pe/aMmSJRozZoyKi4t7PB3okksu0VNPPRW4/9zvW9/6lq6//nqVl5drwYIFQZ9QcioazGuT865v3d3devbZZ/WVr3xFM2fO7DU/Gs+7/rKIZM77HbeyDEJERISkY38eCsb/G5J/HaQnnnhCeXl5SkhI0IYNGzRp0qQe85MnT9bll1/e657L6OhozZ49WwcPHtSbb755MkseVlOnTtVll13W609k5513nmbOnKmPPvpIn3zyiSTOw/643W51dnb2+vCdH+dd/wb7XhceHn7ctZ+/33q02Lx5sxYtWqSoqCht2LAh8MhTv4kTJ+ryyy/vEY4kaezYsYHzt7q6+qTVO9wG89rkvOvbn/70J7W0tPT5Hjjazrv+sohp73cE80GIi4uTzWZTS0tL0Hn/g/1H2/Oj+7Jq1So9/vjjuuaaa7R+/fpebwDH47+qNJr/FPlZn+1HdHS0Pvjgg6Dr/PfBjebzsLKyUna7XZdeeumgt+W8O/YfnsGcY+ecc45aW1uDfnhsNL8vrl27VnfddZdSUlL03HPP6dxzzx3U9pyLPX2+H5x3fausrJR07EuHButUO++Ol0VMe78jmA+Cw+GQy+VSbW2turq6esx1d3erpqZGsbGxva4Kj0ZPPPGE1q1bp6ysLK1evTrovVuHDx/Wr3/9a1VUVATdx/vvvy/p/z5Mcarzer1yu92BD3l+nr8fMTExuuCCC/TRRx8F/Za3nTt3auzYsUE/MT4adHZ26s0331RycnLgfr/P4rwbmMGcYxdccIGOHj2qXbt29Vr7xhtvSJIuvPDCE1uwYbZt26aHHnpIV155pUpLS4N+YZgk/e53v9OmTZuCzo22c3Gwr03Ou769+uqrcjqdfQbE0XLeDSSLSGa93xHMByk9PV1dXV2BT/X6bd++Xa2trcrIyBimysxRXV2twsJCXXvttfrJT36i004LfpqNGTNGRUVFysvL6/Vc3927d+vll1+W0+lUSkrKySh72Nntdt1///3Ky8vT3r17e8xVV1dr165dmjZtmpxOp9LT0yUd+za3z/rrX/+qd999V3PmzOnzDehU9+677+rw4cN9PomF825gBnOOzZ07VzabTWvXru2xdvfu3XrllVc0c+ZMxcfHn5S6TeDxeLRy5UpNnz5djz/+eL+Pudu0aZNWrlypHTt29BhvbW3V888/r7CwMF122WUnumQjDPa1yXkX3IcffqgPP/ywz/dAaXScdwPNIpJZ73d8+HOQsrKyVFFRoYKCAjU3Nys5OVn19fUqLS1VYmLiqHuAfzAFBQWSpIsvvli//e1vg65JTU1VWFiYfvzjH+vWW2/VwoULlZ2drfj4eL3//vt69tlnJUn333+/xowZc9JqH052u115eXn68Y9/rBtvvFE33XSTzj77bL333nvasGGDzjzzTN13332SpFmzZiktLU1lZWXyer36xje+oebmZpWUlMjpdOqOO+4Y5p9m+Pzv//6vJCk2NrbPNaP5vPvnP//Z68svWltbA3/6lo69PgdzjrlcLi1cuFC//OUvdeutt2r27Nn6+OOPVVJSojPOOEP33HPPSfv5TqSB9u6xxx7TwYMHlZqaqt///vdB9zVjxgxFRUXpjjvu0Jtvvqnbb79dWVlZmjp1qvbs2aMNGzbok08+0f3339/n1faRZKC9G8xrk/OuZ+/8wdF/xbu/98DRcN4NJouY9H5n8/GR5kFrb29XUVGRKisr9dFHHyk6OlpXX321li5d2u8XR4wW/f2W7ldVVaW4uDhJ0ltvvaWnn35ab731lvbt26dx48bpoosu0n/+53/q/PPPP9HlGucvf/mL1q5dq9raWh04cEBRUVG65JJLtHjx4h5PGDl06JCeeeYZbdu2Tc3NzRo3bpwuv/xy/fCHPwz6JQmjxdq1a/Xggw/q3nvvVVZWVp/rRut5V1hYqKKion7X+F+fgznHfD6fysvLVV5eroaGBjkcDs2YMUPLli0b9L3Vphpo7xYuXBj0T+KftW7dusDTMjwej55++mm9/vrr+vDDDxUeHq6UlBR973vfC/pEjZFoMOfdYF6bnHfHfPa/qS+//LJyc3O1aNEi/ehHP+pzm1P9vBtsFjHl/Y5gDgAAABiAe8wBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAMQzAEAAAADEMwBAAAAAxDMAQAAAAP8P/faD6SIsaA8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 371
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [0] + [x[0] for x in random_search.results]\n",
    "y = [0] + [x[1] for x in random_search.results]\n",
    "plt.step(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratio 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed value 0.001962922452895973 to dc5ad78bf4.\n",
      "Run with parameters (0.0004, dc5ad78bf4, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, dc5ad78bf4, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.7617141604423523, best_val_metric: 0.7817258883248731, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.0017044215519336813 to 7fc4cb9d4b.\n",
      "Run with parameters (0.0004, 7fc4cb9d4b, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 7fc4cb9d4b, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.7128424644470215, best_val_metric: 0.7918781725888325, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.00030719592667436573 to c55841f332.\n",
      "Run with parameters (0.0004, c55841f332, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, c55841f332, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.6158793568611145, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.0012883276019508636 to e5537f8aae.\n",
      "Run with parameters (0.0004, e5537f8aae, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e5537f8aae, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.7366247177124023, best_val_metric: 0.7868020304568528, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.0026933512668004585 to 784580510f.\n",
      "Run with parameters (0.0004, 784580510f, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 784580510f, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.7838617563247681, best_val_metric: 0.7817258883248731, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.001121541873512991 to a7fef2ae90.\n",
      "Run with parameters (0.0004, a7fef2ae90, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, a7fef2ae90, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.5995513796806335, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.0022400190244408857 to 4f58ffe5ef.\n",
      "Run with parameters (0.0004, 4f58ffe5ef, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 4f58ffe5ef, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.704630970954895, best_val_metric: 0.7766497461928934, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.001462354502085726 to 56c62ab38c.\n",
      "Run with parameters (0.0004, 56c62ab38c, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 56c62ab38c, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.7265850901603699, best_val_metric: 0.7918781725888325, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.0008883571110733327 to ad791082e4.\n",
      "Run with parameters (0.0004, ad791082e4, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, ad791082e4, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.6637321710586548, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.0010604370063707698 to 40c31420b4.\n",
      "Run with parameters (0.0004, 40c31420b4, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 40c31420b4, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.6934686899185181, best_val_metric: 0.8020304568527918, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.0009355335118803783 to 5e790c7bbf.\n",
      "Run with parameters (0.0004, 5e790c7bbf, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 5e790c7bbf, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.7108433246612549, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.00027493362106969057 to 40915b7e95.\n",
      "Run with parameters (0.0004, 40915b7e95, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomSearch()\n",
    "random_search.run(\n",
    "    train_fn_conv, x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test), \n",
    "    learning_rate=0.0004, schedule=PowerRange(-4, -2.5, lambda x: Schedule([DynamicEpoch(x, 'weighted_l1')] * 20)), layer_sizes=[20, 20, 20, 20, 20], \n",
    "    output_neurons=10, min_new_neurons=20, growth_percentage=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc52e8e5550>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 244,
       "width": 372
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [0] + [x[0] for x in random_search.val_metrics]\n",
    "y = [0] + [x[1] for x in random_search.val_metrics]\n",
    "plt.step(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed value 56 to [56, 56, 56, 56, 56].\n",
      "Run with parameters (0.0004, e10c3a90f5, [56, 56, 56, 56, 56], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [56, 56, 56, 56, 56], 10, 20, 0.2) completed, best_val_loss: 0.7135776281356812, best_val_metric: 0.8020304568527918, best_hidden_layer_sizes: [56, 56, 56, 56, 56]\n",
      "Transformed value 17 to [17, 17, 17, 17, 17].\n",
      "Run with parameters (0.0004, e10c3a90f5, [17, 17, 17, 17, 17], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [17, 17, 17, 17, 17], 10, 20, 0.2) completed, best_val_loss: 0.5698947310447693, best_val_metric: 0.817258883248731, best_hidden_layer_sizes: [17, 17, 17, 17, 17]\n",
      "Transformed value 26 to [26, 26, 26, 26, 26].\n",
      "Run with parameters (0.0004, e10c3a90f5, [26, 26, 26, 26, 26], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [26, 26, 26, 26, 26], 10, 20, 0.2) completed, best_val_loss: 0.6505106687545776, best_val_metric: 0.8121827411167513, best_hidden_layer_sizes: [26, 26, 26, 26, 26]\n",
      "Transformed value 26 to [26, 26, 26, 26, 26].\n",
      "Run with parameters (0.0004, e10c3a90f5, [26, 26, 26, 26, 26], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [26, 26, 26, 26, 26], 10, 20, 0.2) completed, best_val_loss: 0.6386404037475586, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [26, 26, 26, 26, 26]\n",
      "Transformed value 14 to [14, 14, 14, 14, 14].\n",
      "Run with parameters (0.0004, e10c3a90f5, [14, 14, 14, 14, 14], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [14, 14, 14, 14, 14], 10, 20, 0.2) completed, best_val_loss: 0.7055838108062744, best_val_metric: 0.7868020304568528, best_hidden_layer_sizes: [14, 14, 14, 14, 14]\n",
      "Transformed value 47 to [47, 47, 47, 47, 47].\n",
      "Run with parameters (0.0004, e10c3a90f5, [47, 47, 47, 47, 47], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [47, 47, 47, 47, 47], 10, 20, 0.2) completed, best_val_loss: 0.6309370398521423, best_val_metric: 0.8223350253807107, best_hidden_layer_sizes: [47, 47, 47, 47, 47]\n",
      "Transformed value 26 to [26, 26, 26, 26, 26].\n",
      "Run with parameters (0.0004, e10c3a90f5, [26, 26, 26, 26, 26], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [26, 26, 26, 26, 26], 10, 20, 0.2) completed, best_val_loss: 0.55641770362854, best_val_metric: 0.8223350253807107, best_hidden_layer_sizes: [26, 26, 26, 26, 26]\n",
      "Transformed value 26 to [26, 26, 26, 26, 26].\n",
      "Run with parameters (0.0004, e10c3a90f5, [26, 26, 26, 26, 26], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [26, 26, 26, 26, 26], 10, 20, 0.2) completed, best_val_loss: 0.6167335510253906, best_val_metric: 0.8020304568527918, best_hidden_layer_sizes: [26, 26, 26, 26, 26]\n",
      "Transformed value 37 to [37, 37, 37, 37, 37].\n",
      "Run with parameters (0.0004, e10c3a90f5, [37, 37, 37, 37, 37], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [37, 37, 37, 37, 37], 10, 20, 0.2) completed, best_val_loss: 0.6037801504135132, best_val_metric: 0.7918781725888325, best_hidden_layer_sizes: [37, 37, 37, 37, 37]\n",
      "Transformed value 48 to [48, 48, 48, 48, 48].\n",
      "Run with parameters (0.0004, e10c3a90f5, [48, 48, 48, 48, 48], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [48, 48, 48, 48, 48], 10, 20, 0.2) completed, best_val_loss: 0.692441999912262, best_val_metric: 0.817258883248731, best_hidden_layer_sizes: [48, 48, 48, 48, 48]\n",
      "Transformed value 58 to [58, 58, 58, 58, 58].\n",
      "Run with parameters (0.0004, e10c3a90f5, [58, 58, 58, 58, 58], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [58, 58, 58, 58, 58], 10, 20, 0.2) completed, best_val_loss: 0.6479483842849731, best_val_metric: 0.817258883248731, best_hidden_layer_sizes: [58, 58, 58, 58, 58]\n",
      "Transformed value 34 to [34, 34, 34, 34, 34].\n",
      "Run with parameters (0.0004, e10c3a90f5, [34, 34, 34, 34, 34], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [34, 34, 34, 34, 34], 10, 20, 0.2) completed, best_val_loss: 0.6536931991577148, best_val_metric: 0.8020304568527918, best_hidden_layer_sizes: [34, 34, 34, 34, 34]\n",
      "Transformed value 27 to [27, 27, 27, 27, 27].\n",
      "Run with parameters (0.0004, e10c3a90f5, [27, 27, 27, 27, 27], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [27, 27, 27, 27, 27], 10, 20, 0.2) completed, best_val_loss: 0.6192494034767151, best_val_metric: 0.8121827411167513, best_hidden_layer_sizes: [27, 27, 27, 27, 27]\n",
      "Transformed value 44 to [44, 44, 44, 44, 44].\n",
      "Run with parameters (0.0004, e10c3a90f5, [44, 44, 44, 44, 44], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [44, 44, 44, 44, 44], 10, 20, 0.2) completed, best_val_loss: 0.653645932674408, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [44, 44, 44, 44, 44]\n",
      "Transformed value 19 to [19, 19, 19, 19, 19].\n",
      "Run with parameters (0.0004, e10c3a90f5, [19, 19, 19, 19, 19], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [19, 19, 19, 19, 19], 10, 20, 0.2) completed, best_val_loss: 0.5801151394844055, best_val_metric: 0.7868020304568528, best_hidden_layer_sizes: [19, 19, 19, 19, 19]\n",
      "Transformed value 15 to [15, 15, 15, 15, 15].\n",
      "Run with parameters (0.0004, e10c3a90f5, [15, 15, 15, 15, 15], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [15, 15, 15, 15, 15], 10, 20, 0.2) completed, best_val_loss: 0.6762995719909668, best_val_metric: 0.7817258883248731, best_hidden_layer_sizes: [15, 15, 15, 15, 15]\n",
      "Transformed value 19 to [19, 19, 19, 19, 19].\n",
      "Run with parameters (0.0004, e10c3a90f5, [19, 19, 19, 19, 19], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [19, 19, 19, 19, 19], 10, 20, 0.2) completed, best_val_loss: 0.625898540019989, best_val_metric: 0.8020304568527918, best_hidden_layer_sizes: [19, 19, 19, 19, 19]\n",
      "Transformed value 43 to [43, 43, 43, 43, 43].\n",
      "Run with parameters (0.0004, e10c3a90f5, [43, 43, 43, 43, 43], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [43, 43, 43, 43, 43], 10, 20, 0.2) completed, best_val_loss: 0.6648257374763489, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [43, 43, 43, 43, 43]\n",
      "Transformed value 43 to [43, 43, 43, 43, 43].\n",
      "Run with parameters (0.0004, e10c3a90f5, [43, 43, 43, 43, 43], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [43, 43, 43, 43, 43], 10, 20, 0.2) completed, best_val_loss: 0.6184338927268982, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [43, 43, 43, 43, 43]\n",
      "Transformed value 53 to [53, 53, 53, 53, 53].\n",
      "Run with parameters (0.0004, e10c3a90f5, [53, 53, 53, 53, 53], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [53, 53, 53, 53, 53], 10, 20, 0.2) completed, best_val_loss: 0.5871742367744446, best_val_metric: 0.8121827411167513, best_hidden_layer_sizes: [53, 53, 53, 53, 53]\n",
      "Transformed value 23 to [23, 23, 23, 23, 23].\n",
      "Run with parameters (0.0004, e10c3a90f5, [23, 23, 23, 23, 23], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [23, 23, 23, 23, 23], 10, 20, 0.2) completed, best_val_loss: 0.5771534442901611, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [23, 23, 23, 23, 23]\n",
      "Transformed value 12 to [12, 12, 12, 12, 12].\n",
      "Run with parameters (0.0004, e10c3a90f5, [12, 12, 12, 12, 12], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [12, 12, 12, 12, 12], 10, 20, 0.2) completed, best_val_loss: 0.7894598245620728, best_val_metric: 0.751269035532995, best_hidden_layer_sizes: [12, 12, 12, 12, 12]\n",
      "Transformed value 11 to [11, 11, 11, 11, 11].\n",
      "Run with parameters (0.0004, e10c3a90f5, [11, 11, 11, 11, 11], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [11, 11, 11, 11, 11], 10, 20, 0.2) completed, best_val_loss: 0.82330322265625, best_val_metric: 0.7411167512690355, best_hidden_layer_sizes: [11, 11, 11, 11, 11]\n",
      "Transformed value 18 to [18, 18, 18, 18, 18].\n",
      "Run with parameters (0.0004, e10c3a90f5, [18, 18, 18, 18, 18], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [18, 18, 18, 18, 18], 10, 20, 0.2) completed, best_val_loss: 0.6359153985977173, best_val_metric: 0.7918781725888325, best_hidden_layer_sizes: [18, 18, 18, 18, 18]\n",
      "Transformed value 48 to [48, 48, 48, 48, 48].\n",
      "Run with parameters (0.0004, e10c3a90f5, [48, 48, 48, 48, 48], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [48, 48, 48, 48, 48], 10, 20, 0.2) completed, best_val_loss: 0.615038275718689, best_val_metric: 0.8121827411167513, best_hidden_layer_sizes: [48, 48, 48, 48, 48]\n",
      "Transformed value 55 to [55, 55, 55, 55, 55].\n",
      "Run with parameters (0.0004, e10c3a90f5, [55, 55, 55, 55, 55], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [55, 55, 55, 55, 55], 10, 20, 0.2) completed, best_val_loss: 0.6389309763908386, best_val_metric: 0.8121827411167513, best_hidden_layer_sizes: [55, 55, 55, 55, 55]\n",
      "Transformed value 33 to [33, 33, 33, 33, 33].\n",
      "Run with parameters (0.0004, e10c3a90f5, [33, 33, 33, 33, 33], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [33, 33, 33, 33, 33], 10, 20, 0.2) completed, best_val_loss: 0.5888888239860535, best_val_metric: 0.8121827411167513, best_hidden_layer_sizes: [33, 33, 33, 33, 33]\n",
      "Transformed value 46 to [46, 46, 46, 46, 46].\n",
      "Run with parameters (0.0004, e10c3a90f5, [46, 46, 46, 46, 46], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [46, 46, 46, 46, 46], 10, 20, 0.2) completed, best_val_loss: 0.6148332357406616, best_val_metric: 0.817258883248731, best_hidden_layer_sizes: [46, 46, 46, 46, 46]\n",
      "Transformed value 15 to [15, 15, 15, 15, 15].\n",
      "Run with parameters (0.0004, e10c3a90f5, [15, 15, 15, 15, 15], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [15, 15, 15, 15, 15], 10, 20, 0.2) completed, best_val_loss: 0.6512161493301392, best_val_metric: 0.7969543147208121, best_hidden_layer_sizes: [15, 15, 15, 15, 15]\n",
      "Transformed value 58 to [58, 58, 58, 58, 58].\n",
      "Run with parameters (0.0004, e10c3a90f5, [58, 58, 58, 58, 58], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [58, 58, 58, 58, 58], 10, 20, 0.2) completed, best_val_loss: 0.6825313568115234, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [58, 58, 58, 58, 58]\n",
      "Transformed value 42 to [42, 42, 42, 42, 42].\n",
      "Run with parameters (0.0004, e10c3a90f5, [42, 42, 42, 42, 42], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [42, 42, 42, 42, 42], 10, 20, 0.2) completed, best_val_loss: 0.6816088557243347, best_val_metric: 0.8121827411167513, best_hidden_layer_sizes: [42, 42, 42, 42, 42]\n",
      "Transformed value 15 to [15, 15, 15, 15, 15].\n",
      "Run with parameters (0.0004, e10c3a90f5, [15, 15, 15, 15, 15], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [15, 15, 15, 15, 15], 10, 20, 0.2) completed, best_val_loss: 0.598649799823761, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [15, 15, 15, 15, 15]\n",
      "Transformed value 28 to [28, 28, 28, 28, 28].\n",
      "Run with parameters (0.0004, e10c3a90f5, [28, 28, 28, 28, 28], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e10c3a90f5, [28, 28, 28, 28, 28], 10, 20, 0.2) completed, best_val_loss: 0.5302263498306274, best_val_metric: 0.8324873096446701, best_hidden_layer_sizes: [28, 28, 28, 28, 28]\n",
      "Transformed value 44 to [44, 44, 44, 44, 44].\n",
      "Run with parameters (0.0004, e10c3a90f5, [44, 44, 44, 44, 44], 10, 20, 0.2) started...\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomSearch()\n",
    "random_search.run(\n",
    "    train_fn_conv, x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test), \n",
    "    learning_rate=0.0004, schedule=Schedule([StaticEpochNoRegularization()] * 20), \n",
    "    layer_sizes=UniformRange(10, 60, lambda x: [x] * 5, integer=True),\n",
    "    output_neurons=10, min_new_neurons=20, growth_percentage=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0c761dfcd0>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 244,
       "width": 368
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [0] + [x[0] for x in random_search.val_metrics]\n",
    "y = [0] + [x[1] for x in random_search.val_metrics]\n",
    "plt.step(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed value 0.0015647224510419461 to 70ad510894.\n",
      "Transformed value 50 to [50, 50, 50, 50, 50].\n",
      "Run with parameters (0.0004, 70ad510894, [50, 50, 50, 50, 50], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 70ad510894, [50, 50, 50, 50, 50], 10, 20, 0.2) completed, best_val_loss: 0.63899827003479, best_val_metric: 0.8121827411167513, best_hidden_layer_sizes: [50, 50, 50, 50, 50]\n",
      "Transformed value 0.0055191252041712924 to 054379149d.\n",
      "Transformed value 41 to [41, 41, 41, 41, 41].\n",
      "Run with parameters (0.0004, 054379149d, [41, 41, 41, 41, 41], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 054379149d, [41, 41, 41, 41, 41], 10, 20, 0.2) completed, best_val_loss: 0.569776177406311, best_val_metric: 0.817258883248731, best_hidden_layer_sizes: [41, 41, 41, 41, 41]\n",
      "Transformed value 0.004552519234309237 to 0f0ab74ebe.\n",
      "Transformed value 26 to [26, 26, 26, 26, 26].\n",
      "Run with parameters (0.0004, 0f0ab74ebe, [26, 26, 26, 26, 26], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 0f0ab74ebe, [26, 26, 26, 26, 26], 10, 20, 0.2) completed, best_val_loss: 0.5940284729003906, best_val_metric: 0.8274111675126904, best_hidden_layer_sizes: [26, 26, 26, 26, 26]\n",
      "Transformed value 0.005133110204876473 to 6350f6cb0c.\n",
      "Transformed value 25 to [25, 25, 25, 25, 25].\n",
      "Run with parameters (0.0004, 6350f6cb0c, [25, 25, 25, 25, 25], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 6350f6cb0c, [25, 25, 25, 25, 25], 10, 20, 0.2) completed, best_val_loss: 0.6243699789047241, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [25, 25, 25, 25, 25]\n",
      "Transformed value 0.00021446572425355153 to da57dd77b6.\n",
      "Transformed value 32 to [32, 32, 32, 32, 32].\n",
      "Run with parameters (0.0004, da57dd77b6, [32, 32, 32, 32, 32], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, da57dd77b6, [32, 32, 32, 32, 32], 10, 20, 0.2) completed, best_val_loss: 0.589191198348999, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [32, 32, 32, 32, 32]\n",
      "Transformed value 0.033202394068185 to 5459570308.\n",
      "Transformed value 21 to [21, 21, 21, 21, 21].\n",
      "Run with parameters (0.0004, 5459570308, [21, 21, 21, 21, 21], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 5459570308, [21, 21, 21, 21, 21], 10, 20, 0.2) completed, best_val_loss: 1.0416383743286133, best_val_metric: 0.751269035532995, best_hidden_layer_sizes: [21, 21, 21, 21, 21]\n",
      "Transformed value 0.026408635827319078 to 600981266e.\n",
      "Transformed value 36 to [36, 36, 36, 36, 36].\n",
      "Run with parameters (0.0004, 600981266e, [36, 36, 36, 36, 36], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 600981266e, [36, 36, 36, 36, 36], 10, 20, 0.2) completed, best_val_loss: 0.920419454574585, best_val_metric: 0.7817258883248731, best_hidden_layer_sizes: [36, 36, 36, 36, 36]\n",
      "Transformed value 0.08259861254601521 to e6f065d79d.\n",
      "Transformed value 24 to [24, 24, 24, 24, 24].\n",
      "Run with parameters (0.0004, e6f065d79d, [24, 24, 24, 24, 24], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e6f065d79d, [24, 24, 24, 24, 24], 10, 20, 0.2) completed, best_val_loss: 1.5962752103805542, best_val_metric: 0.5736040609137056, best_hidden_layer_sizes: [24, 24, 24, 24, 24]\n",
      "Transformed value 0.008138825180589601 to 159257ff6a.\n",
      "Transformed value 24 to [24, 24, 24, 24, 24].\n",
      "Run with parameters (0.0004, 159257ff6a, [24, 24, 24, 24, 24], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 159257ff6a, [24, 24, 24, 24, 24], 10, 20, 0.2) completed, best_val_loss: 0.6448870301246643, best_val_metric: 0.7868020304568528, best_hidden_layer_sizes: [24, 24, 24, 24, 24]\n",
      "Transformed value 0.0018871621788592863 to d2b6f6b4a8.\n",
      "Transformed value 45 to [45, 45, 45, 45, 45].\n",
      "Run with parameters (0.0004, d2b6f6b4a8, [45, 45, 45, 45, 45], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, d2b6f6b4a8, [45, 45, 45, 45, 45], 10, 20, 0.2) completed, best_val_loss: 0.5838249921798706, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [45, 45, 45, 45, 45]\n",
      "Transformed value 0.0018871094070385744 to 76f9801225.\n",
      "Transformed value 15 to [15, 15, 15, 15, 15].\n",
      "Run with parameters (0.0004, 76f9801225, [15, 15, 15, 15, 15], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 76f9801225, [15, 15, 15, 15, 15], 10, 20, 0.2) completed, best_val_loss: 0.7118884921073914, best_val_metric: 0.7715736040609137, best_hidden_layer_sizes: [15, 15, 15, 15, 15]\n",
      "Transformed value 0.0008751905792931696 to 6962dff2fb.\n",
      "Transformed value 39 to [39, 39, 39, 39, 39].\n",
      "Run with parameters (0.0004, 6962dff2fb, [39, 39, 39, 39, 39], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 6962dff2fb, [39, 39, 39, 39, 39], 10, 20, 0.2) completed, best_val_loss: 0.5942760705947876, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [39, 39, 39, 39, 39]\n",
      "Transformed value 0.061482535292347935 to 2219a1319c.\n",
      "Transformed value 21 to [21, 21, 21, 21, 21].\n",
      "Run with parameters (0.0004, 2219a1319c, [21, 21, 21, 21, 21], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 2219a1319c, [21, 21, 21, 21, 21], 10, 20, 0.2) completed, best_val_loss: 1.553512692451477, best_val_metric: 0.6649746192893401, best_hidden_layer_sizes: [21, 21, 21, 21, 21]\n",
      "Transformed value 0.05001956477418346 to 8f8639ea8f.\n",
      "Transformed value 20 to [20, 20, 20, 20, 20].\n",
      "Run with parameters (0.0004, 8f8639ea8f, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 8f8639ea8f, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 1.3765919208526611, best_val_metric: 0.6802030456852792, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Transformed value 0.00013787443444573472 to 3d058668bb.\n",
      "Transformed value 31 to [31, 31, 31, 31, 31].\n",
      "Run with parameters (0.0004, 3d058668bb, [31, 31, 31, 31, 31], 10, 20, 0.2) started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x7f0d30d291f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vojta/.miniconda3/envs/self-scaling-nets/lib/python3.8/weakref.py\", line 345, in remove\n",
      "    def remove(k, selfref=ref(self)):\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomSearch()\n",
    "random_search.run(\n",
    "    train_fn_conv, x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test), \n",
    "    learning_rate=0.0004, schedule=PowerRange(-4, -1, lambda x: Schedule([StaticEpoch(x, 'l1')] * 20)), \n",
    "    layer_sizes=UniformRange(10, 60, lambda x: [x] * 5, integer=True),\n",
    "    output_neurons=10, min_new_neurons=20, growth_percentage=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0c75134340>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 244,
       "width": 366
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [0] + [x[0] for x in random_search.val_metrics]\n",
    "y = [0] + [x[1] for x in random_search.val_metrics]\n",
    "plt.step(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Promising results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed value 0.0002690672152324276 to 0ca5a9c378.\n",
      "Run with parameters (0.0004, 0ca5a9c378, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 0ca5a9c378, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.6647390723228455, best_val_metric: 0.8020304568527918, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Best overall combination: (0.0004, 0ca5a9c378, [20, 20, 20, 20, 20], 10, 20, 0.2), val_metric: 0.8020304568527918\n",
      "Transformed value 0.0006377418780501754 to 4dd7336522.\n",
      "Run with parameters (0.0004, 4dd7336522, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 4dd7336522, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.6458284854888916, best_val_metric: 0.8223350253807107, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Best overall combination: (0.0004, 4dd7336522, [20, 20, 20, 20, 20], 10, 20, 0.2), val_metric: 0.8223350253807107\n",
      "Transformed value 0.001561167177574867 to 91ab607077.\n",
      "Run with parameters (0.0004, 91ab607077, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 91ab607077, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.7537733316421509, best_val_metric: 0.7868020304568528, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Best overall combination: (0.0004, 4dd7336522, [20, 20, 20, 20, 20], 10, 20, 0.2), val_metric: 0.8223350253807107\n",
      "Transformed value 0.00020740296014105678 to 198b985111.\n",
      "Run with parameters (0.0004, 198b985111, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 198b985111, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.6130691170692444, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [20, 20, 20, 24, 20]\n",
      "Best overall combination: (0.0004, 4dd7336522, [20, 20, 20, 20, 20], 10, 20, 0.2), val_metric: 0.8223350253807107\n",
      "Transformed value 0.0008690939421101265 to 97b5984bda.\n",
      "Run with parameters (0.0004, 97b5984bda, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 97b5984bda, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.6295524835586548, best_val_metric: 0.8121827411167513, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Best overall combination: (0.0004, 4dd7336522, [20, 20, 20, 20, 20], 10, 20, 0.2), val_metric: 0.8223350253807107\n",
      "Transformed value 0.0009709147004166403 to 9dd2273800.\n",
      "Run with parameters (0.0004, 9dd2273800, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 9dd2273800, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.6747143864631653, best_val_metric: 0.7969543147208121, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Best overall combination: (0.0004, 4dd7336522, [20, 20, 20, 20, 20], 10, 20, 0.2), val_metric: 0.8223350253807107\n",
      "Transformed value 0.00262432615624027 to a93c7beb9e.\n",
      "Run with parameters (0.0004, a93c7beb9e, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, a93c7beb9e, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.7783379554748535, best_val_metric: 0.7563451776649747, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Best overall combination: (0.0004, 4dd7336522, [20, 20, 20, 20, 20], 10, 20, 0.2), val_metric: 0.8223350253807107\n",
      "Transformed value 0.0005402132278921486 to 513d20a942.\n",
      "Run with parameters (0.0004, 513d20a942, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 513d20a942, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.6281912326812744, best_val_metric: 0.817258883248731, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Best overall combination: (0.0004, 4dd7336522, [20, 20, 20, 20, 20], 10, 20, 0.2), val_metric: 0.8223350253807107\n",
      "Transformed value 0.0017649916825280005 to df1593f268.\n",
      "Run with parameters (0.0004, df1593f268, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, df1593f268, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.7240856289863586, best_val_metric: 0.7969543147208121, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Best overall combination: (0.0004, 4dd7336522, [20, 20, 20, 20, 20], 10, 20, 0.2), val_metric: 0.8223350253807107\n",
      "Transformed value 0.0001236840194794754 to 4d3cfccecb.\n",
      "Run with parameters (0.0004, 4d3cfccecb, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 4d3cfccecb, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.5904365181922913, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [20, 20, 20, 36, 20]\n",
      "Best overall combination: (0.0004, 4dd7336522, [20, 20, 20, 20, 20], 10, 20, 0.2), val_metric: 0.8223350253807107\n",
      "Transformed value 0.0002625172138964074 to 3c2c29e42e.\n",
      "Run with parameters (0.0004, 3c2c29e42e, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 3c2c29e42e, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.563244104385376, best_val_metric: 0.8223350253807107, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Best overall combination: (0.0004, 4dd7336522, [20, 20, 20, 20, 20], 10, 20, 0.2), val_metric: 0.8223350253807107\n",
      "Transformed value 0.0012199664418025154 to 105872b29c.\n",
      "Run with parameters (0.0004, 105872b29c, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 105872b29c, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.6989495158195496, best_val_metric: 0.7918781725888325, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Best overall combination: (0.0004, 4dd7336522, [20, 20, 20, 20, 20], 10, 20, 0.2), val_metric: 0.8223350253807107\n",
      "Transformed value 0.00023941504033734638 to 4e4b5351bc.\n",
      "Run with parameters (0.0004, 4e4b5351bc, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 4e4b5351bc, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.6718299388885498, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Best overall combination: (0.0004, 4dd7336522, [20, 20, 20, 20, 20], 10, 20, 0.2), val_metric: 0.8223350253807107\n",
      "Transformed value 0.0008227679377546587 to 8b33afd200.\n",
      "Run with parameters (0.0004, 8b33afd200, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 8b33afd200, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.6489322781562805, best_val_metric: 0.8121827411167513, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Best overall combination: (0.0004, 4dd7336522, [20, 20, 20, 20, 20], 10, 20, 0.2), val_metric: 0.8223350253807107\n",
      "Transformed value 0.0002332011238121414 to 4f303adac3.\n",
      "Run with parameters (0.0004, 4f303adac3, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 4f303adac3, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.6119394302368164, best_val_metric: 0.817258883248731, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Best overall combination: (0.0004, 4dd7336522, [20, 20, 20, 20, 20], 10, 20, 0.2), val_metric: 0.8223350253807107\n",
      "Transformed value 0.0001650670873121798 to d3f48dedd5.\n",
      "Run with parameters (0.0004, d3f48dedd5, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, d3f48dedd5, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.6706271171569824, best_val_metric: 0.817258883248731, best_hidden_layer_sizes: [20, 20, 20, 29, 20]\n",
      "Best overall combination: (0.0004, 4dd7336522, [20, 20, 20, 20, 20], 10, 20, 0.2), val_metric: 0.8223350253807107\n",
      "Transformed value 0.0003851713863589798 to 4014cca45b.\n",
      "Run with parameters (0.0004, 4014cca45b, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 4014cca45b, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.5571435689926147, best_val_metric: 0.8223350253807107, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Best overall combination: (0.0004, 4dd7336522, [20, 20, 20, 20, 20], 10, 20, 0.2), val_metric: 0.8223350253807107\n",
      "Transformed value 0.00011904825182900448 to 5bd16e27fa.\n",
      "Run with parameters (0.0004, 5bd16e27fa, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 5bd16e27fa, [20, 20, 20, 20, 20], 10, 20, 0.2) completed, best_val_loss: 0.5576596260070801, best_val_metric: 0.8426395939086294, best_hidden_layer_sizes: [20, 20, 20, 32, 20]\n",
      "Best overall combination: (0.0004, 5bd16e27fa, [20, 20, 20, 20, 20], 10, 20, 0.2), val_metric: 0.8426395939086294\n",
      "Transformed value 0.00012431359174522758 to 92429bbeee.\n",
      "Run with parameters (0.0004, 92429bbeee, [20, 20, 20, 20, 20], 10, 20, 0.2) started...\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomSearch()\n",
    "random_search.run(\n",
    "    train_fn_conv, x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test), \n",
    "    learning_rate=0.0004, schedule=PowerRange(-4, -2.5, lambda x: Schedule([DynamicEpoch(x, 'weighted_l1')] * 20)), layer_sizes=[20, 20, 20, 20, 20], \n",
    "    output_neurons=10, min_new_neurons=20, growth_percentage=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0c6ec61100>]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAt0AAAHpCAYAAABeNIDUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAABYlAAAWJQFJUiTwAAAp80lEQVR4nO3de5jXdZ3//8eYTTKgcQgbTqLZjkyBmHjYtgxLKrM2hcUNxVyjMk1AOuxipy9ZacV1uaaoCx3ARMVaLN2hIout9XdtkknhZiLRGC0ghISKw0nEz+8PvzPfRgYUP7wcRm+36/Ky3ofPvMZnn7zPm/e8PzWVSqUSAACgmAM6ewEAAPBiJ7oBAKAw0Q0AAIWJbgAAKEx0AwBAYaIbAAAKE90AAFCY6AYAgMJENwAAFCa6AQCgMNENAACFiW4AACjswM5eQLWWLFnS2UsAAOAlZMSIEXt9jivdAABQWJe/0t3q+fzEUa1ly5YlSRobG1/wr031zK/rM8Ouzwy7NvPr+sxw71Rzh4Ur3QAAUJjoBgCAwkQ3AAAUJroBAKAw0Q0AAIWJbgAAKEx0AwBAYaIbAAAKE90AAFCY6AYAgMJENwAAFCa6AQCgMNENAACFiW4AAChMdAMAQGGiGwAACjuwsxcAAMD+7Rt3Ppiv/fT32fzEzs5eSpKke+3LMmVUQz78ltd09lKeM1e6AQDYo/0puJNk8xM7843/78HOXsZeEd0AAOzR/hTcydNXuj98Ute5yp24vQQAgL2w8ivv7uwldEmudAMAQGGiGwAAChPdAABQmOgGAIDCRDcAABQmugEAoDCPDHwR2N8+Jarr6VoP16cjZtj1mWHXZn5dnxmW5kr3i4DgBgBeCN1rX9bZS+iyRPeLgOAGAErrXvuyTBnV0NnL6LLcXvIi41Oinrtly5YlSRobGzt5JTxfZtj1mWHXZn5dnxm+cFzpBgCAwkQ3AAAUtk9uL9m0aVNmzJiRRYsWZf369enZs2dGjhyZKVOmpG/fvs96/qJFi3L99denubk5W7duzYABA3LKKadkwoQJeeUrX7kvlggAAJ2m6ujesmVLzjnnnDQ3N2f8+PEZOnRoVq5cmdmzZ2fx4sWZP39+evXqtdvzr7zyysycOTPDhg3LRRddlG7dumXp0qX55je/mR/+8If5/ve/nx49elS7TAAA6DRVR/fcuXOzfPnyTJs2LWeffXbb9sbGxkycODGzZs3KJZdc0uG5jzzySL75zW9mwIABuemmm/KKV7wiSTJmzJj07Nkzs2bNyvz583PeeedVu0wAAOg0Vd/T3dTUlLq6uowdO7bd9lGjRqW+vj5NTU2pVCodnrtu3bo8+eSTGTZsWFtwtxoxYkSS5KGHHqp2iQAA0KmqutLd0tKSFStWZMSIEamtrW23r6amJsOHD8+Pf/zjrF69OoMGDdrl/EGDBqW2tjYrV67cZd/q1auTJEceeeRzWkvrI29eSLcsfTjf+V1Ltj25/3yKU2f8c+iqtm7dmsQ/s67MDLs+M+zazK/rM8MXTlVXulvDuF+/fh3ur6+vT5KsWrWqw/09evTIBRdckAceeCCXXnppmpub8+c//zl33HFHrrvuujQ0NOT000+vZolFPR3cHV/F7wzdDqzp7CUAANCBqq50b968OUnSrVu3Dve3bm9padnta1x00UXp3bt3Lr/88tx8881t29/61rfmK1/5Sg466KDntJbOeKj7/nSFu/VTohobX9PZS+kyfCBA12eGXZ8Zdm3m1/WZ4d5ZsmTJ8z63quiuqXn6yuru7tl+5nEdufHGG3P55ZfnLW95S/7+7/8+3bp1y7333psbbrgh559/fr7xjW90iccG+iRIAAB2p6robn2U35YtWzrc33olfHeP/Gtubs7ll1+eN73pTZk5c2bb9re97W1pbGzMxRdfnH/7t3/b7dNPAACgK6jqnu6BAwempqYma9eu7XD/mjVrkiSDBw/ucP9dd92VnTt35pRTTtll31vf+tbU1NTk7rvvrmaJAADQ6aqK7rq6ujQ2NmbZsmXZtm1bu307d+7M0qVLM2DAgPTv37/D81vP2b59+y77tm/fnkqlkh07dlSzRAAA6HRVP6d79OjR2bZtW2655ZZ222+//fZs3LgxY8aMadvW3Nzc7kkmxxxzTJLkRz/60S73hf/kJz9pdwwAAHRVVX8i5bhx47JgwYJMnz49a9asybBhw7JixYrMmTMnQ4YMyYQJE9qOPe2003LEEUdk4cKFSZLjjjsu73jHO3LHHXfkrLPOyrvf/e706NEjv/vd7/Ld7343ffr0yYUXXljtEgEAoFNVHd21tbWZM2dOrrnmmixcuDDz5s1Lnz59Mm7cuEyePDl1dXV7PP/KK6/MzTffnNtuuy1XXHFFnnzyyRx66KE544wz8tGPfrTtWd8AANBVVR3dSdK9e/dMnTo1U6dO3eNxy5cv33UBBx6Yc889N+eee+6+WAoAAOx3qr6nGwAA2DPRDQAAhYluAAAoTHQDAEBhohsAAAoT3QAAUJjoBgCAwkQ3AAAUJroBAKAw0Q0AAIWJbgAAKEx0AwBAYaIbAAAKE90AAFCY6AYAgMJENwAAFCa6AQCgMNENAACFiW4AAChMdAMAQGGiGwAAChPdAABQmOgGAIDCRDcAABQmugEAoDDRDQAAhYluAAAoTHQDAEBhohsAAAoT3QAAUJjoBgCAwkQ3AAAUJroBAKAw0Q0AAIWJbgAAKEx0AwBAYaIbAAAKE90AAFCY6AYAgMJENwAAFCa6AQCgMNENAACFiW4AAChMdAMAQGGiGwAAChPdAABQmOgGAIDCRDcAABQmugEAoDDRDQAAhYluAAAoTHQDAEBhohsAAAoT3QAAUJjoBgCAwkQ3AAAUJroBAKAw0Q0AAIWJbgAAKEx0AwBAYaIbAAAKE90AAFCY6AYAgMJENwAAFCa6AQCgMNENAACFiW4AAChMdAMAQGGiGwAAChPdAABQmOgGAIDCRDcAABQmugEAoDDRDQAAhYluAAAoTHQDAEBhohsAAAoT3QAAUJjoBgCAwg7cFy+yadOmzJgxI4sWLcr69evTs2fPjBw5MlOmTEnfvn2f9fwnnngiM2fOTFNTU9atW5c+ffpk5MiRmTx5cvr06bMvlggAAJ2m6ujesmVLzjnnnDQ3N2f8+PEZOnRoVq5cmdmzZ2fx4sWZP39+evXqtdvzn3zyyZx//vm555578v73vz9DhgzJ/fffn7lz52bJkiX53ve+l9ra2mqXCQAAnabq6J47d26WL1+eadOm5eyzz27b3tjYmIkTJ2bWrFm55JJLdnv+d77zndx111352te+lne9611JktNPPz2HHHJIvve97+Xee+/N8ccfX+0yAQCg01R9T3dTU1Pq6uoyduzYdttHjRqV+vr6NDU1pVKp7Pb8m266KY2NjW3B3eqiiy7KokWLBDcAAF1eVVe6W1pasmLFiowYMWKXW0BqamoyfPjw/PjHP87q1aszaNCgXc7/85//nObm5nz4wx9u27Z9+/a8/OUvzwEH7N3PA8uWLXt+38Q+0tlfn723devWJGbXlZlh12eGXZv5dX1m+MKp6kr36tWrkyT9+vXrcH99fX2SZNWqVR3ub25uTpIcdthh+da3vpWTTz45Rx99dI4++uh85CMfyR//+MdqlgcAAPuFqq50b968OUnSrVu3Dve3bm9paelw/6OPPprk6VtMkmTy5Ml55StfmcWLF+emm27Kvffem9tvvz2vfvWrn3UtjY2Ne7v8feDBTv76VKP1p3qz67rMsOszw67N/Lo+M9w7S5Ysed7nVhXdNTU1SbLHe7b/+rhn2rFjR5Lk8ccfz4IFC1JXV5ckOeWUU9K3b99cccUVmT17dj71qU9Vs0wAAOhUVd1e0qNHjyRPPzawI61XwluPe6bWyD755JPb/nOr0aNHJ0l+9atfVbNEAADodFVF98CBA1NTU5O1a9d2uH/NmjVJksGDB+/2/CQd/tJk7969U1NT0xbuAADQVVUV3XV1dWlsbMyyZcuybdu2dvt27tyZpUuXZsCAAenfv3+H57/2ta/NwQcfnOXLl++yb+3atalUKjn00EOrWSIAAHS6qp/TPXr06Gzbti233HJLu+233357Nm7cmDFjxrRta25ubvckk5e//OV573vfm7vvvjv33HNPu/NvvPHGJMnIkSOrXSIAAHSqqj+Rcty4cVmwYEGmT5+eNWvWZNiwYVmxYkXmzJmTIUOGZMKECW3HnnbaaTniiCOycOHCtm0TJ07MnXfemQsuuCATJkxIfX19fvGLX6SpqSlHHXVUxo8fX+0SAQCgU1Ud3bW1tZkzZ06uueaaLFy4MPPmzUufPn0ybty4TJ48eZdfkHym3r175zvf+U6uuuqq3HzzzXn00UfTt2/fnHvuuZk0adJuH0cIAABdRdXRnSTdu3fP1KlTM3Xq1D0e19G920nSp0+ffOELX8gXvvCFfbEcAADYr1R9TzcAALBnohsAAAoT3QAAUJjoBgCAwkQ3AAAUJroBAKAw0Q0AAIWJbgAAKEx0AwBAYaIbAAAKE90AAFCY6AYAgMJENwAAFCa6AQCgMNENAACFiW4AAChMdAMAQGGiGwAAChPdAABQmOgGAIDCRDcAABQmugEAoDDRDQAAhYluAAAoTHQDAEBhohsAAAoT3QAAUJjoBgCAwkQ3AAAUJroBAKAw0Q0AAIWJbgAAKEx0AwBAYaIbAAAKE90AAFCY6AYAgMJENwAAFCa6AQCgMNENAACFiW4AAChMdAMAQGGiGwAAChPdAABQmOgGAIDCRDcAABQmugEAoDDRDQAAhYluAAAoTHQDAEBhohsAAAoT3QAAUJjoBgCAwkQ3AAAUJroBAKAw0Q0AAIWJbgAAKEx0AwBAYaIbAAAKE90AAFCY6AYAgMJENwAAFCa6AQCgMNENAACFiW4AAChMdAMAQGGiGwAAChPdAABQmOgGAIDCRDcAABQmugEAoDDRDQAAhYluAAAoTHQDAEBhohsAAAoT3QAAUJjoBgCAwkQ3AAAUJroBAKCwfRLdmzZtymWXXZa3ve1tGTp0aN785jfnM5/5TB5++OG9fq3t27fnne98Z4466qj88pe/3BfLAwCATnVgtS+wZcuWnHPOOWlubs748eMzdOjQrFy5MrNnz87ixYszf/789OrV6zm/3nXXXZeVK1dWuywAANhvVB3dc+fOzfLlyzNt2rScffbZbdsbGxszceLEzJo1K5dccslzeq3ly5fnW9/6VhobG7Ns2bJqlwYAAPuFqm8vaWpqSl1dXcaOHdtu+6hRo1JfX5+mpqZUKpVnfZ2nnnoqn/vc5zJgwICMGzeu2mUBAMB+o6robmlpyYoVK9LY2Jja2tp2+2pqajJ8+PBs2LAhq1evftbXuvHGG/M///M/+dKXvrTLawEAQFdW1e0lrTHdr1+/DvfX19cnSVatWpVBgwbt9nXWrl2bK6+8MmeeeWaOP/74rFq1aq/X0tm3o3T212fvbd26NYnZdWVm2PWZYddmfl2fGb5wqrrSvXnz5iRJt27dOtzfur2lpWWPr/P5z38+3bt3zz//8z9XsxwAANgvVXWlu6amJkme9Z7t1uM68oMf/CA///nPc9VVV+WQQw553mtpbGx83uc+fw928tenGq0/1Ztd12WGXZ8Zdm3m1/WZ4d5ZsmTJ8z63qivdPXr0SPL0YwM70nolvPW4Z3r00Ufbnu996qmnVrMUAADYb1V1pXvgwIGpqanJ2rVrO9y/Zs2aJMngwYM73D99+vRs3bo1F154YdatW9e2fdOmTUmSjRs3Zt26dendu7dfrgQAoMuqKrrr6uranqm9bdu2HHTQQW37du7cmaVLl2bAgAHp379/h+cvXrw4W7ZsyZlnntnh/ilTpiRJbrjhhpx44onVLBUAADpN1R+OM3r06Fx22WW55ZZbct5557Vtv/3227Nx48ZMmjSpbVtzc3Nqa2vbnmRy2WWXZdu2bbu85l133ZVvf/vb+fjHP56GhoY0NDRUu0wAAOg0VUf3uHHjsmDBgkyfPj1r1qzJsGHDsmLFisyZMydDhgzJhAkT2o497bTTcsQRR2ThwoVJkje+8Y0dvuYjjzySJDnmmGNc4QYAoMurOrpra2szZ86cXHPNNVm4cGHmzZuXPn36ZNy4cZk8eXLq6ur2xToBAKDLqjq6k6R79+6ZOnVqpk6dusfjli9f/pxeb8yYMRkzZsy+WBoAAHS6qh4ZCAAAPDvRDQAAhYluAAAoTHQDAEBhohsAAAoT3QAAUJjoBgCAwkQ3AAAUJroBAKAw0Q0AAIWJbgAAKEx0AwBAYaIbAAAKE90AAFCY6AYAgMJENwAAFCa6AQCgMNENAACFiW4AAChMdAMAQGGiGwAAChPdAABQmOgGAIDCRDcAABQmugEAoDDRDQAAhYluAAAoTHQDAEBhohsAAAoT3QAAUJjoBgCAwkQ3AAAUJroBAKAw0Q0AAIWJbgAAKEx0AwBAYaIbAAAKE90AAFCY6AYAgMJENwAAFCa6AQCgMNENAACFiW4AAChMdAMAQGGiGwAAChPdAABQmOgGAIDCRDcAABQmugEAoDDRDQAAhYluAAAoTHQDAEBhohsAAAoT3QAAUJjoBgCAwkQ3AAAUJroBAKAw0Q0AAIWJbgAAKEx0AwBAYaIbAAAKE90AAFCY6AYAgMJENwAAFCa6AQCgMNENAACFiW4AAChMdAMAQGGiGwAAChPdAABQmOgGAIDCRDcAABQmugEAoDDRDQAAhYluAAAoTHQDAEBhohsAAAoT3QAAUJjoBgCAwg7cFy+yadOmzJgxI4sWLcr69evTs2fPjBw5MlOmTEnfvn2f9fx77rkns2bNyrJly7J58+YMGjQop556aiZMmJCDDjpoXywRAAA6TdXRvWXLlpxzzjlpbm7O+PHjM3To0KxcuTKzZ8/O4sWLM3/+/PTq1Wu35//whz/Mxz/+8Rx++OH50Ic+lB49euTOO+/MVVddlTvvvDM333xzDjjABXkAALquqqN77ty5Wb58eaZNm5azzz67bXtjY2MmTpyYWbNm5ZJLLunw3CeeeCKf+9zn0q9fv/z7v/97Dj744CTJ2LFjM2nSpNxxxx258847c/LJJ1e7TAAA6DRVX0JuampKXV1dxo4d2277qFGjUl9fn6amplQqlQ7P3bBhQ97+9rfn/PPPbwvuVieddFKS5Pe//321SwQAgE5VVXS3tLRkxYoVaWxsTG1tbbt9NTU1GT58eDZs2JDVq1d3eH7//v3zla98JWedddYu+x5//PEk2SXGAQCgq6nq9pLWmO7Xr1+H++vr65Mkq1atyqBBg57z6z7xxBO59dZbU1tbm7e97W3P6Zxly5Y959cvobO/Pntv69atScyuKzPDrs8Muzbz6/rM8IVT1ZXuzZs3J0m6devW4f7W7S0tLc/5NZ966ql87nOfS3NzcyZOnJhXv/rV1SwRAAA6XVVXumtqapJkt/dsP/O4Z7Nt27Z84hOfyE9/+tOceeaZOf/885/zWhobG5/zsfvOg5389alG60/1Ztd1mWHXZ4Zdm/l1fWa4d5YsWfK8z60qunv06JHk6ccGdqT1SnjrcXuycePGXHjhhVm6dGkuuOCCTJky5TnHOgAA7M+qiu6BAwempqYma9eu7XD/mjVrkiSDBw/e4+ts2LAh48ePz5o1a/LVr341Z5xxRjXLAgCA/UpV0V1XV5fGxsYsW7Ys27Zta/fpkTt37szSpUszYMCA9O/ff7ev0dLSkg996ENZt25dvv71r+fv/u7vqlkSAADsd6p+Tvfo0aOzbdu23HLLLe2233777dm4cWPGjBnTtq25uTmrVq1qd9xll12WBx54IP/6r/8quAEAeFGq+hMpx40blwULFmT69OlZs2ZNhg0blhUrVmTOnDkZMmRIJkyY0HbsaaedliOOOCILFy5MkjzwwAP5/ve/n4aGhuzYsaNt+1/r3bt3TjjhhGqXCQAAnabq6K6trc2cOXNyzTXXZOHChZk3b1769OmTcePGZfLkyamrq9vtuffff38qlUqWL1+eiy++uMNjTjjhhMydO7faZQIAQKepOrqTpHv37pk6dWqmTp26x+OWL1/e7r+PGTOm3e0nAADwYlT1Pd0AAMCeiW4AAChMdAMAQGGiGwAAChPdAABQmOgGAIDCRDcAABQmugEAoDDRDQAAhYluAAAoTHQDAEBhohsAAAoT3QAAUJjoBgCAwkQ3AAAUJroBAKAw0Q0AAIWJbgAAKEx0AwBAYaIbAAAKE90AAFCY6AYAgMJENwAAFCa6AQCgMNENAACFiW4AAChMdAMAQGGiGwAAChPdAABQmOgGAIDCRDcAABQmugEAoDDRDQAAhYluAAAoTHQDAEBhohsAAAoT3QAAUJjoBgCAwkQ3AAAUJroBAKAw0Q0AAIWJbgAAKEx0AwBAYaIbAAAKE90AAFCY6AYAgMJENwAAFCa6AQCgMNENAACFiW4AAChMdAMAQGGiGwAAChPdAABQmOgGAIDCRDcAABQmugEAoDDRDQAAhYluAAAoTHQDAEBhohsAAAoT3QAAUJjoBgCAwkQ3AAAUJroBAKAw0Q0AAIWJbgAAKEx0AwBAYaIbAAAKE90AAFCY6AYAgMJENwAAFCa6AQCgMNENAACFiW4AAChMdAMAQGGiGwAAChPdAABQmOgGAIDCRDcAABR24L54kU2bNmXGjBlZtGhR1q9fn549e2bkyJGZMmVK+vbt+6znL126NNdee22WLl2a7du3Z/DgwXnf+96Xs88+Owcc4OcCAAC6tqqje8uWLTnnnHPS3Nyc8ePHZ+jQoVm5cmVmz56dxYsXZ/78+enVq9duz7/rrrvy4Q9/OPX19bnooovSs2fP3HHHHfniF7+YlStX5rOf/Wy1SwQAgE5VdXTPnTs3y5cvz7Rp03L22We3bW9sbMzEiRMza9asXHLJJR2eW6lUcumll+aggw7KzTffnEMPPTRJcsYZZ+TCCy/MjTfemLFjx2bIkCHVLhMAADpN1fduNDU1pa6uLmPHjm23fdSoUamvr09TU1MqlUqH595333354x//mHe9611twd3q/e9/fyqVSv7jP/6j2iUCAECnqiq6W1pasmLFijQ2Nqa2trbdvpqamgwfPjwbNmzI6tWrOzz/3nvvTZIcffTRu+wbPnx4u2MAAKCrqur2ktaY7tevX4f76+vrkySrVq3KoEGDdtm/atWq3Z7fvXv3HHLIIW3HPJtly5Y9p+NK6eyvz97bunVrErPrysyw6zPDrs38uj4zfOFUdaV78+bNSZJu3bp1uL91e0tLy/M+f3fn7g8OOrAmSdLt//4dAAA6UtWV7pqap2Nzd/dsP/O453P+7s59psbGxud03L50zjGP5nu/eywXvrUhjY2vecG/PtVp/am+M/63w75hhl2fGXZt5tf1meHeWbJkyfM+t6ro7tGjR5KnHxvYkdYr2a3HPZ/zDz744GqWWNQ/vL5n/uH1PQU3AAB7VNXtJQMHDkxNTU3Wrl3b4f41a9YkSQYPHtzh/tb7vDs6/7HHHktLS0sOO+ywapYIAACdrqrorqurS2NjY5YtW5Zt27a127dz584sXbo0AwYMSP/+/Ts8/9hjj03y9CdSPtM999yTJDnuuOOqWSIAAHS6qp/TPXr06Gzbti233HJLu+233357Nm7cmDFjxrRta25ubvc0kiFDhuR1r3tdFi5c2O5qd6VSyfXXX58DDzwwZ5xxRrVLBACATlX1J1KOGzcuCxYsyPTp07NmzZoMGzYsK1asyJw5czJkyJBMmDCh7djTTjstRxxxRBYuXNi2bdq0aTn33HMzfvz4/NM//VMOOeSQLFiwIHfffXcuvvhit5cAANDlVR3dtbW1mTNnTq655posXLgw8+bNS58+fTJu3LhMnjw5dXV1ezz/mGOOybx583L11VdnxowZ2bFjR4488sh89atfdZUbAIAXhaqjO3n6g2ymTp2aqVOn7vG45cuXd7j99a9/fWbNmrUvlgIAAPudqu/pBgAA9kx0AwBAYaIbAAAKE90AAFCY6AYAgMJENwAAFCa6AQCgMNENAACFiW4AAChMdAMAQGE1lUql0tmLqMaSJUs6ewkAALyEjBgxYq/PcaUbAAAK6/JXugEAYH/nSjcAABQmugEAoDDRDQAAhYluAAAoTHQDAEBhohsAAAo7sLMX0BVt2rQpM2bMyKJFi7J+/fr07NkzI0eOzJQpU9K3b9/OXt5L1hNPPJGvfe1rmT17do4//vjMnTt3l2O2b9+er3/961mwYEEeeuih9OjRIyeccEI+9rGP5fDDD2937M6dOzN37tzceuut+dOf/pSDDjooxxxzTCZNmpRhw4a9QN/VS8Nf/vKXzJw5M3feeWfWrVuXV73qVTn66KMzadKkvOY1r2l3rBnuv1asWJGZM2fmN7/5TTZs2JC+fftm+PDhueCCC9LQ0NB2nBl2DVdddVWuu+66jB49Ol/5ylfatu/tTG677bbceOONaW5uzgEHHJDXve51Of/883PSSSe9kN/Oi94ll1yS73//+7vd/6lPfSrnnXdeEu/BzuI53Xtpy5YtGTduXJqbmzN+/PgMHTo0K1euzOzZs9OnT5/Mnz8/vXr16uxlvuQ8+OCD+eQnP5k//vGP2bJlS0444YRdovupp57KBz/4wfziF7/ImDFjcuKJJ2b9+vWZM2dOnnrqqXz3u9/N4MGD247/9Kc/nVtvvTWnnHJK3v72t2fTpk254YYbsn79+txwww15wxve8EJ/my9Kf/nLX3LmmWfmL3/5S84666wMGTIkK1euzA033JAnn3wy8+bNy+tf//okZrg/+8UvfpHzzz8/vXr1yvjx41NfX58HH3wwN954Y3bs2JHrr78+I0aMMMMuYsWKFRk9enR27NixS3TvzUyuvfbaXH311TnhhBPy3ve+Nzt37sy8efOyfPnyfO1rX8upp57aGd/ei1JrdE+bNi29e/feZX9jY2MGDx7sPdiZKuyVmTNnVhoaGio33XRTu+133HFHpaGhofLlL3+5k1b20vXoo49Whg8fXnnve99baW5urjQ0NFTOOeecXY5ramqqNDQ0VKZPn95u+29/+9vKUUcdVZk4cWLbtl//+teVhoaGysUXX9zu2IceeqhyzDHHVEaPHl3ke3kp+j//5/9UGhoaKnfccUe77YsWLao0NDRUJk2a1LbNDPdf73nPeypHH310ZdWqVe22/+QnP6k0NDRUPvKRj1QqFTPsCnbu3Fl53/veVzn99NMrDQ0NlalTp7bt25uZrFmzpvL617++8r73va+yc+fOtu2PP/545aSTTqq86U1vqmzfvr349/NSMXXq1EpDQ8Mu78Fn8h7sPO7p3ktNTU2pq6vL2LFj220fNWpU6uvr09TUlIo/PHhB7dixI6effnq++93v7nIrwl9rampKkpx77rnttg8dOjRveMMb8rOf/SyPP/74Ho/t169fTjnllPzud7/LH/7wh335bbxk9e3bN+95z3syatSodtvf/OY3p6amJr///e/btpnh/umpp57KmDFj8pnPfCYDBw5st++Nb3xjkuTPf/5zEjPsCubNm5ff/OY3ueSSS3bZtzcz+dGPfpQdO3Zk/PjxOeCA/5cbPXr0yOjRo/Pwww/nrrvuKvid0BHvwc4juvdCS0tLVqxYkcbGxtTW1rbbV1NTk+HDh2fDhg1ZvXp1J63wpelVr3pVLr300rziFa/Y43FLly5NfX19Xv3qV++y75hjjsmOHTty3333tR17wAEHZOjQoR0e23oM1Zs4cWKuuOKK1NTUtNve0tKSSqWSQw45pG2bGe6fDjjggHzgAx/IP/7jP+6yb/ny5UnSdk+3Ge7f1q1blyuuuCL/8A//kL/927/dZf/ezOTee+9NkgwfPvxZj2Xf27FjR5588sldtnsPdh7RvRdaY7pfv34d7q+vr0+SrFq16gVbE89NS0tLHn300WedXeuMV69enT59+uzyw9VfH2vOZd1yyy1J0nbPpxl2HZs2bcrq1avzgx/8IJ/4xCdy2GGHZfLkyWbYBVx66aXp1q1bpk6d2uH+vZlJ699bt/+11v8NmN++N2/evLzzne/M8OHDM3To0IwZMyY/+9nPkvj/0c7m6SV7YfPmzUmSbt26dbi/dXtLS8sLtiaem2ebXV1dXZL/N7vNmzenZ8+eezy29TXZ9/7rv/4r1113XY466qiMHz8+iRl2Jccff3ySp/8EcPTo0fmXf/mX9OrVq+0WEzPcPy1cuDD/+Z//mSuvvDKvfOUrOzxmb2ayefPmHHjggR0Gm39flnPnnXfm/e9/fwYOHJg//OEP+cY3vpELL7wwV1xxRY477rgk3oOdRXTvhdY//n62e7af+cfk7D+e6+xqamrcm99Jbrvttnz2s59NfX19Zs6cucttQ2a4/7vhhhvy+OOP5/e//31uuumm3H333bn66qvzqle9KokZ7o82bdqUL33pSzn55JNz2mmn7fa4vZnJcznWvy/3nQ984AN597vfnRNPPLHtB52TTz45J598cs4444x8+ctfzq233prEe7CzuL1kL/To0SPJ048N7EjrT3utx7H/2NvZde/e/VmPPfjgg/f1Ml/yrr322kydOjUNDQ25+eab079//7Z9Zth1nHjiiRk1alQ++tGP5jvf+U4ee+yxfOxjH0v37t2TmOH+aPr06dm8eXOmTZu2x+P2Zibdu3fPzp07s3379mc9luodddRROemkk3b5k4XXvva1OfHEE/Pwww/nscceS+I92FlE914YOHBgampqsnbt2g73r1mzJknaPd+S/UP37t3Tp0+fPPTQQx3ub71/rXV2hx12WDZu3NjhvyzMuYzLLrssV199dd7xjnfkpptuyqGHHtpuvxl2TQMHDsxxxx2XP/3pT9mwYYMZ7od+9atfZf78+fngBz+YAw44IOvWrWv7K0m2bt2adevW5bHHHturmRx22GFJ0uG8W49tPYayWp/bvXnzZu/BTiS690JdXV0aGxuzbNmybNu2rd2+nTt3ZunSpRkwYEC7q3PsP4499tg8/PDDbf9H8deWLFmSgw46qO03tI899tg89dRTbb99/9fuueeeJMmIESPKLvgl5Nprr80NN9yQcePG5aqrrtrt/YZmuH964IEHMnLkyA4fMZek7V/YO3fuNMP90OLFi1OpVDJjxoyMHDmy3V/J0/d6jxw5Ml/+8pf3aibHHntsko6fbtF6bOs9xlSnpaUlTU1Nbb8w+Ux/+tOfkjz9C6zeg51HdO+l0aNHZ9u2bW1PVmh1++23Z+PGjRkzZkwnrYxnM3r06CTJnDlz2m3/5S9/mfvvvz+nnXZaW+ydccYZqampyfXXX9/u2AcffDA///nPc+KJJ2bQoEEvyLpf7BYvXpwZM2bkne98Zz7/+c+3e57vM5nh/uk1r3lNnnjiidxxxx27PMngf//3f/PrX/86vXv3zuGHH26G+6H3vOc9mTlzZod/JU8/a33mzJk577zz9mom73rXu3LQQQdl7ty57R5dt3Hjxtx22205/PDD237plurU1tbmi1/8YqZOnZr169e327d48eLce++9Ofroo1NfX+892Il8DPxeeuKJJ3LOOefkvvvuy/jx4zNs2LCsWLEic+bMyZFHHpl58+a1/UYvL4w//OEP7R7Of/HFF+e1r31tJk2a1LZt5MiR6datWy666KL89Kc/zejRo/PGN74xa9asyezZs9O9e/fMnz8/ffv2bTvn8ssvz7e//e289a1vzamnnppHHnkks2fPzpYtW3LLLbfkb/7mb17Q7/PFasyYMbn//vvz+c9/fre/Jd86vyRmuJ/6wQ9+kE9+8pPp1atXzj777AwcODCrV6/OTTfdlEceeSRf/epXc/rppycxw67kqKOO2uVj4PdmJt/+9rdz+eWXZ8SIERkzZky2b9+euXPnZvXq1fnmN7/Z4bPAeX5uvfXWfPrTn07//v1z1lln5dBDD80DDzyQm2++ObW1tZk7d24aGxuTeA92FtH9PGzevDnXXHNNFi5cmIcffjh9+vTJ29/+9kyePLndB3nwwpgxY0auueaaPR6zaNGiDBw4ME888US+9a1v5bbbbsuaNWtyyCGH5C1veUs+9rGP7fJBAZVKJfPmzcu8efOycuXK1NXV5YQTTsiUKVNy5JFHlvyWXlKOOuqoZz2mdX5JzHA/dt999+Ub3/hGfvvb32b9+vXp3r17hg0blg9+8INtn0yZmGFX0lF07+1MfvjDH2bOnDlZsWJFXvayl+WYY47JpEmT2j5chX3nv//7v3P99ddn2bJlefTRR9O7d++86U1vyoUXXtju/nnvwc4hugEAoDD3dAMAQGGiGwAAChPdAABQmOgGAIDCRDcAABQmugEAoDDRDQAAhYluAAAoTHQDAEBhohsAAAoT3QAAUJjoBgCAwkQ3AAAUJroBAKAw0Q0AAIWJbgAAKEx0AwBAYf8/kf/0X43k+KYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 244,
       "width": 366
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [0] + [x[0] for x in random_search.val_metrics]\n",
    "y = [0] + [x[1] for x in random_search.val_metrics]\n",
    "plt.step(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed value 0.02518520624046292 to 11241b38f7.\n",
      "Transformed value 42 to [42, 42, 42, 42, 42].\n",
      "Run with parameters (0.0004, 11241b38f7, [42, 42, 42, 42, 42], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 11241b38f7, [42, 42, 42, 42, 42], 10, 20, 0.2) completed, best_val_loss: 0.917365550994873, best_val_metric: 0.7766497461928934, best_hidden_layer_sizes: [42, 42, 42, 42, 42]\n",
      "Best overall combination: (0.0004, 11241b38f7, [42, 42, 42, 42, 42], 10, 20, 0.2), val_metric: 0.7766497461928934\n",
      "Transformed value 0.0005932439705257152 to e54cffd593.\n",
      "Transformed value 35 to [35, 35, 35, 35, 35].\n",
      "Run with parameters (0.0004, e54cffd593, [35, 35, 35, 35, 35], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, e54cffd593, [35, 35, 35, 35, 35], 10, 20, 0.2) completed, best_val_loss: 0.6492508053779602, best_val_metric: 0.7918781725888325, best_hidden_layer_sizes: [35, 35, 35, 35, 35]\n",
      "Best overall combination: (0.0004, e54cffd593, [35, 35, 35, 35, 35], 10, 20, 0.2), val_metric: 0.7918781725888325\n",
      "Transformed value 0.0067576057681541036 to 3c32d4ec40.\n",
      "Transformed value 59 to [59, 59, 59, 59, 59].\n",
      "Run with parameters (0.0004, 3c32d4ec40, [59, 59, 59, 59, 59], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 3c32d4ec40, [59, 59, 59, 59, 59], 10, 20, 0.2) completed, best_val_loss: 0.6045005321502686, best_val_metric: 0.8020304568527918, best_hidden_layer_sizes: [59, 59, 59, 59, 59]\n",
      "Best overall combination: (0.0004, 3c32d4ec40, [59, 59, 59, 59, 59], 10, 20, 0.2), val_metric: 0.8020304568527918\n",
      "Transformed value 0.031716486990618034 to 0eae487762.\n",
      "Transformed value 85 to [85, 85, 85, 85, 85].\n",
      "Run with parameters (0.0004, 0eae487762, [85, 85, 85, 85, 85], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 0eae487762, [85, 85, 85, 85, 85], 10, 20, 0.2) completed, best_val_loss: 0.8672013878822327, best_val_metric: 0.7461928934010152, best_hidden_layer_sizes: [85, 85, 85, 85, 85]\n",
      "Best overall combination: (0.0004, 3c32d4ec40, [59, 59, 59, 59, 59], 10, 20, 0.2), val_metric: 0.8020304568527918\n",
      "Transformed value 0.00010558103266208073 to 6ab8215a75.\n",
      "Transformed value 27 to [27, 27, 27, 27, 27].\n",
      "Run with parameters (0.0004, 6ab8215a75, [27, 27, 27, 27, 27], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 6ab8215a75, [27, 27, 27, 27, 27], 10, 20, 0.2) completed, best_val_loss: 0.6382116079330444, best_val_metric: 0.817258883248731, best_hidden_layer_sizes: [27, 27, 27, 27, 27]\n",
      "Best overall combination: (0.0004, 6ab8215a75, [27, 27, 27, 27, 27], 10, 20, 0.2), val_metric: 0.817258883248731\n",
      "Transformed value 0.0010855411347295168 to d0247ac9ae.\n",
      "Transformed value 54 to [54, 54, 54, 54, 54].\n",
      "Run with parameters (0.0004, d0247ac9ae, [54, 54, 54, 54, 54], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, d0247ac9ae, [54, 54, 54, 54, 54], 10, 20, 0.2) completed, best_val_loss: 0.6505343317985535, best_val_metric: 0.817258883248731, best_hidden_layer_sizes: [54, 54, 54, 54, 54]\n",
      "Best overall combination: (0.0004, 6ab8215a75, [27, 27, 27, 27, 27], 10, 20, 0.2), val_metric: 0.817258883248731\n",
      "Transformed value 0.025547077534522976 to 6e9fe0256a.\n",
      "Transformed value 72 to [72, 72, 72, 72, 72].\n",
      "Run with parameters (0.0004, 6e9fe0256a, [72, 72, 72, 72, 72], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 6e9fe0256a, [72, 72, 72, 72, 72], 10, 20, 0.2) completed, best_val_loss: 1.1000986099243164, best_val_metric: 0.751269035532995, best_hidden_layer_sizes: [72, 72, 72, 72, 72]\n",
      "Best overall combination: (0.0004, 6ab8215a75, [27, 27, 27, 27, 27], 10, 20, 0.2), val_metric: 0.817258883248731\n",
      "Transformed value 0.00011352331199763304 to 250a1fd27b.\n",
      "Transformed value 71 to [71, 71, 71, 71, 71].\n",
      "Run with parameters (0.0004, 250a1fd27b, [71, 71, 71, 71, 71], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 250a1fd27b, [71, 71, 71, 71, 71], 10, 20, 0.2) completed, best_val_loss: 0.6816633939743042, best_val_metric: 0.8121827411167513, best_hidden_layer_sizes: [71, 71, 71, 71, 71]\n",
      "Best overall combination: (0.0004, 6ab8215a75, [27, 27, 27, 27, 27], 10, 20, 0.2), val_metric: 0.817258883248731\n",
      "Transformed value 0.00026588810769201306 to a2a7abb8cd.\n",
      "Transformed value 38 to [38, 38, 38, 38, 38].\n",
      "Run with parameters (0.0004, a2a7abb8cd, [38, 38, 38, 38, 38], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, a2a7abb8cd, [38, 38, 38, 38, 38], 10, 20, 0.2) completed, best_val_loss: 0.6418183445930481, best_val_metric: 0.8121827411167513, best_hidden_layer_sizes: [38, 38, 38, 38, 38]\n",
      "Best overall combination: (0.0004, 6ab8215a75, [27, 27, 27, 27, 27], 10, 20, 0.2), val_metric: 0.817258883248731\n",
      "Transformed value 0.07649630678247213 to 398807bb2a.\n",
      "Transformed value 48 to [48, 48, 48, 48, 48].\n",
      "Run with parameters (0.0004, 398807bb2a, [48, 48, 48, 48, 48], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 398807bb2a, [48, 48, 48, 48, 48], 10, 20, 0.2) completed, best_val_loss: 1.720521092414856, best_val_metric: 0.6192893401015228, best_hidden_layer_sizes: [48, 48, 48, 48, 48]\n",
      "Best overall combination: (0.0004, 6ab8215a75, [27, 27, 27, 27, 27], 10, 20, 0.2), val_metric: 0.817258883248731\n",
      "Transformed value 0.08258641902178498 to 07d31c1b54.\n",
      "Transformed value 72 to [72, 72, 72, 72, 72].\n",
      "Run with parameters (0.0004, 07d31c1b54, [72, 72, 72, 72, 72], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 07d31c1b54, [72, 72, 72, 72, 72], 10, 20, 0.2) completed, best_val_loss: 1.6467883586883545, best_val_metric: 0.5786802030456852, best_hidden_layer_sizes: [72, 72, 72, 72, 72]\n",
      "Best overall combination: (0.0004, 6ab8215a75, [27, 27, 27, 27, 27], 10, 20, 0.2), val_metric: 0.817258883248731\n",
      "Transformed value 0.005866164344880614 to 99215f1c85.\n",
      "Transformed value 72 to [72, 72, 72, 72, 72].\n",
      "Run with parameters (0.0004, 99215f1c85, [72, 72, 72, 72, 72], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 99215f1c85, [72, 72, 72, 72, 72], 10, 20, 0.2) completed, best_val_loss: 0.629795491695404, best_val_metric: 0.8020304568527918, best_hidden_layer_sizes: [72, 72, 72, 72, 72]\n",
      "Best overall combination: (0.0004, 6ab8215a75, [27, 27, 27, 27, 27], 10, 20, 0.2), val_metric: 0.817258883248731\n",
      "Transformed value 0.0007037099140120587 to b03360c3a6.\n",
      "Transformed value 12 to [12, 12, 12, 12, 12].\n",
      "Run with parameters (0.0004, b03360c3a6, [12, 12, 12, 12, 12], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, b03360c3a6, [12, 12, 12, 12, 12], 10, 20, 0.2) completed, best_val_loss: 0.778631865978241, best_val_metric: 0.7817258883248731, best_hidden_layer_sizes: [12, 12, 12, 12, 12]\n",
      "Best overall combination: (0.0004, 6ab8215a75, [27, 27, 27, 27, 27], 10, 20, 0.2), val_metric: 0.817258883248731\n",
      "Transformed value 0.0037262864270087943 to f11b740c0b.\n",
      "Transformed value 44 to [44, 44, 44, 44, 44].\n",
      "Run with parameters (0.0004, f11b740c0b, [44, 44, 44, 44, 44], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, f11b740c0b, [44, 44, 44, 44, 44], 10, 20, 0.2) completed, best_val_loss: 0.581730306148529, best_val_metric: 0.8223350253807107, best_hidden_layer_sizes: [44, 44, 44, 44, 44]\n",
      "Best overall combination: (0.0004, f11b740c0b, [44, 44, 44, 44, 44], 10, 20, 0.2), val_metric: 0.8223350253807107\n",
      "Transformed value 0.06252139897778165 to eb84386d86.\n",
      "Transformed value 69 to [69, 69, 69, 69, 69].\n",
      "Run with parameters (0.0004, eb84386d86, [69, 69, 69, 69, 69], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, eb84386d86, [69, 69, 69, 69, 69], 10, 20, 0.2) completed, best_val_loss: 1.6392066478729248, best_val_metric: 0.6192893401015228, best_hidden_layer_sizes: [69, 69, 69, 69, 69]\n",
      "Best overall combination: (0.0004, f11b740c0b, [44, 44, 44, 44, 44], 10, 20, 0.2), val_metric: 0.8223350253807107\n",
      "Transformed value 0.0001216480339915858 to dcff9a786c.\n",
      "Transformed value 28 to [28, 28, 28, 28, 28].\n",
      "Run with parameters (0.0004, dcff9a786c, [28, 28, 28, 28, 28], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, dcff9a786c, [28, 28, 28, 28, 28], 10, 20, 0.2) completed, best_val_loss: 0.6551024913787842, best_val_metric: 0.7817258883248731, best_hidden_layer_sizes: [28, 28, 28, 28, 28]\n",
      "Best overall combination: (0.0004, f11b740c0b, [44, 44, 44, 44, 44], 10, 20, 0.2), val_metric: 0.8223350253807107\n",
      "Transformed value 0.002585323590519585 to 47689195ee.\n",
      "Transformed value 81 to [81, 81, 81, 81, 81].\n",
      "Run with parameters (0.0004, 47689195ee, [81, 81, 81, 81, 81], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 47689195ee, [81, 81, 81, 81, 81], 10, 20, 0.2) completed, best_val_loss: 0.5728757381439209, best_val_metric: 0.817258883248731, best_hidden_layer_sizes: [81, 81, 81, 81, 81]\n",
      "Best overall combination: (0.0004, f11b740c0b, [44, 44, 44, 44, 44], 10, 20, 0.2), val_metric: 0.8223350253807107\n",
      "Transformed value 0.012982566393891632 to a15dbfa5b3.\n",
      "Transformed value 55 to [55, 55, 55, 55, 55].\n",
      "Run with parameters (0.0004, a15dbfa5b3, [55, 55, 55, 55, 55], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, a15dbfa5b3, [55, 55, 55, 55, 55], 10, 20, 0.2) completed, best_val_loss: 0.7188591361045837, best_val_metric: 0.7817258883248731, best_hidden_layer_sizes: [55, 55, 55, 55, 55]\n",
      "Best overall combination: (0.0004, f11b740c0b, [44, 44, 44, 44, 44], 10, 20, 0.2), val_metric: 0.8223350253807107\n",
      "Transformed value 0.005612650114691618 to 9cb459323c.\n",
      "Transformed value 39 to [39, 39, 39, 39, 39].\n",
      "Run with parameters (0.0004, 9cb459323c, [39, 39, 39, 39, 39], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 9cb459323c, [39, 39, 39, 39, 39], 10, 20, 0.2) completed, best_val_loss: 0.6023359894752502, best_val_metric: 0.7969543147208121, best_hidden_layer_sizes: [39, 39, 39, 39, 39]\n",
      "Best overall combination: (0.0004, f11b740c0b, [44, 44, 44, 44, 44], 10, 20, 0.2), val_metric: 0.8223350253807107\n",
      "Transformed value 0.0059750844903088485 to ee3b21e920.\n",
      "Transformed value 88 to [88, 88, 88, 88, 88].\n",
      "Run with parameters (0.0004, ee3b21e920, [88, 88, 88, 88, 88], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, ee3b21e920, [88, 88, 88, 88, 88], 10, 20, 0.2) completed, best_val_loss: 0.5763115286827087, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [88, 88, 88, 88, 88]\n",
      "Best overall combination: (0.0004, f11b740c0b, [44, 44, 44, 44, 44], 10, 20, 0.2), val_metric: 0.8223350253807107\n",
      "Transformed value 0.007762479723226058 to 69c4f72bdd.\n",
      "Transformed value 50 to [50, 50, 50, 50, 50].\n",
      "Run with parameters (0.0004, 69c4f72bdd, [50, 50, 50, 50, 50], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 69c4f72bdd, [50, 50, 50, 50, 50], 10, 20, 0.2) completed, best_val_loss: 0.5877772569656372, best_val_metric: 0.8121827411167513, best_hidden_layer_sizes: [50, 50, 50, 50, 50]\n",
      "Best overall combination: (0.0004, f11b740c0b, [44, 44, 44, 44, 44], 10, 20, 0.2), val_metric: 0.8223350253807107\n",
      "Transformed value 0.004243211296776639 to 046088dc5d.\n",
      "Transformed value 61 to [61, 61, 61, 61, 61].\n",
      "Run with parameters (0.0004, 046088dc5d, [61, 61, 61, 61, 61], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 046088dc5d, [61, 61, 61, 61, 61], 10, 20, 0.2) completed, best_val_loss: 0.5926029682159424, best_val_metric: 0.8223350253807107, best_hidden_layer_sizes: [61, 61, 61, 61, 61]\n",
      "Best overall combination: (0.0004, f11b740c0b, [44, 44, 44, 44, 44], 10, 20, 0.2), val_metric: 0.8223350253807107\n",
      "Transformed value 0.00010723884338690138 to 52907a8ce7.\n",
      "Transformed value 37 to [37, 37, 37, 37, 37].\n",
      "Run with parameters (0.0004, 52907a8ce7, [37, 37, 37, 37, 37], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 52907a8ce7, [37, 37, 37, 37, 37], 10, 20, 0.2) completed, best_val_loss: 0.612751841545105, best_val_metric: 0.817258883248731, best_hidden_layer_sizes: [37, 37, 37, 37, 37]\n",
      "Best overall combination: (0.0004, f11b740c0b, [44, 44, 44, 44, 44], 10, 20, 0.2), val_metric: 0.8223350253807107\n",
      "Transformed value 0.0447185030506941 to f0d77edf2d.\n",
      "Transformed value 12 to [12, 12, 12, 12, 12].\n",
      "Run with parameters (0.0004, f0d77edf2d, [12, 12, 12, 12, 12], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, f0d77edf2d, [12, 12, 12, 12, 12], 10, 20, 0.2) completed, best_val_loss: 1.322764277458191, best_val_metric: 0.6903553299492385, best_hidden_layer_sizes: [12, 12, 12, 12, 12]\n",
      "Best overall combination: (0.0004, f11b740c0b, [44, 44, 44, 44, 44], 10, 20, 0.2), val_metric: 0.8223350253807107\n",
      "Transformed value 0.00015288883833861983 to 732c7d8aeb.\n",
      "Transformed value 82 to [82, 82, 82, 82, 82].\n",
      "Run with parameters (0.0004, 732c7d8aeb, [82, 82, 82, 82, 82], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 732c7d8aeb, [82, 82, 82, 82, 82], 10, 20, 0.2) completed, best_val_loss: 0.713379442691803, best_val_metric: 0.8274111675126904, best_hidden_layer_sizes: [82, 82, 82, 82, 82]\n",
      "Best overall combination: (0.0004, 732c7d8aeb, [82, 82, 82, 82, 82], 10, 20, 0.2), val_metric: 0.8274111675126904\n",
      "Transformed value 0.000323296450116621 to 3d3873286a.\n",
      "Transformed value 78 to [78, 78, 78, 78, 78].\n",
      "Run with parameters (0.0004, 3d3873286a, [78, 78, 78, 78, 78], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 3d3873286a, [78, 78, 78, 78, 78], 10, 20, 0.2) completed, best_val_loss: 0.691140353679657, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [78, 78, 78, 78, 78]\n",
      "Best overall combination: (0.0004, 732c7d8aeb, [82, 82, 82, 82, 82], 10, 20, 0.2), val_metric: 0.8274111675126904\n",
      "Transformed value 0.0268892719069578 to f78b1582eb.\n",
      "Transformed value 16 to [16, 16, 16, 16, 16].\n",
      "Run with parameters (0.0004, f78b1582eb, [16, 16, 16, 16, 16], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, f78b1582eb, [16, 16, 16, 16, 16], 10, 20, 0.2) completed, best_val_loss: 0.9768710732460022, best_val_metric: 0.7715736040609137, best_hidden_layer_sizes: [16, 16, 16, 16, 16]\n",
      "Best overall combination: (0.0004, 732c7d8aeb, [82, 82, 82, 82, 82], 10, 20, 0.2), val_metric: 0.8274111675126904\n",
      "Transformed value 0.009932223320446434 to ffd8b55cc4.\n",
      "Transformed value 81 to [81, 81, 81, 81, 81].\n",
      "Run with parameters (0.0004, ffd8b55cc4, [81, 81, 81, 81, 81], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, ffd8b55cc4, [81, 81, 81, 81, 81], 10, 20, 0.2) completed, best_val_loss: 0.7042295336723328, best_val_metric: 0.7969543147208121, best_hidden_layer_sizes: [81, 81, 81, 81, 81]\n",
      "Best overall combination: (0.0004, 732c7d8aeb, [82, 82, 82, 82, 82], 10, 20, 0.2), val_metric: 0.8274111675126904\n",
      "Transformed value 0.00013481168190782112 to c534172f6c.\n",
      "Transformed value 22 to [22, 22, 22, 22, 22].\n",
      "Run with parameters (0.0004, c534172f6c, [22, 22, 22, 22, 22], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, c534172f6c, [22, 22, 22, 22, 22], 10, 20, 0.2) completed, best_val_loss: 0.594963788986206, best_val_metric: 0.8121827411167513, best_hidden_layer_sizes: [22, 22, 22, 22, 22]\n",
      "Best overall combination: (0.0004, 732c7d8aeb, [82, 82, 82, 82, 82], 10, 20, 0.2), val_metric: 0.8274111675126904\n",
      "Transformed value 0.012567519489627655 to 3048018e8f.\n",
      "Transformed value 68 to [68, 68, 68, 68, 68].\n",
      "Run with parameters (0.0004, 3048018e8f, [68, 68, 68, 68, 68], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 3048018e8f, [68, 68, 68, 68, 68], 10, 20, 0.2) completed, best_val_loss: 0.670939028263092, best_val_metric: 0.7868020304568528, best_hidden_layer_sizes: [68, 68, 68, 68, 68]\n",
      "Best overall combination: (0.0004, 732c7d8aeb, [82, 82, 82, 82, 82], 10, 20, 0.2), val_metric: 0.8274111675126904\n",
      "Transformed value 0.013575940336101756 to b8d370810e.\n",
      "Transformed value 19 to [19, 19, 19, 19, 19].\n",
      "Run with parameters (0.0004, b8d370810e, [19, 19, 19, 19, 19], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, b8d370810e, [19, 19, 19, 19, 19], 10, 20, 0.2) completed, best_val_loss: 0.7341808676719666, best_val_metric: 0.7868020304568528, best_hidden_layer_sizes: [19, 19, 19, 19, 19]\n",
      "Best overall combination: (0.0004, 732c7d8aeb, [82, 82, 82, 82, 82], 10, 20, 0.2), val_metric: 0.8274111675126904\n",
      "Transformed value 0.017518479756426543 to 569a54842b.\n",
      "Transformed value 85 to [85, 85, 85, 85, 85].\n",
      "Run with parameters (0.0004, 569a54842b, [85, 85, 85, 85, 85], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 569a54842b, [85, 85, 85, 85, 85], 10, 20, 0.2) completed, best_val_loss: 0.7000278234481812, best_val_metric: 0.7969543147208121, best_hidden_layer_sizes: [85, 85, 85, 85, 85]\n",
      "Best overall combination: (0.0004, 732c7d8aeb, [82, 82, 82, 82, 82], 10, 20, 0.2), val_metric: 0.8274111675126904\n",
      "Transformed value 0.004734958977745231 to c1e95b4ec8.\n",
      "Transformed value 27 to [27, 27, 27, 27, 27].\n",
      "Run with parameters (0.0004, c1e95b4ec8, [27, 27, 27, 27, 27], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, c1e95b4ec8, [27, 27, 27, 27, 27], 10, 20, 0.2) completed, best_val_loss: 0.6005941033363342, best_val_metric: 0.7969543147208121, best_hidden_layer_sizes: [27, 27, 27, 27, 27]\n",
      "Best overall combination: (0.0004, 732c7d8aeb, [82, 82, 82, 82, 82], 10, 20, 0.2), val_metric: 0.8274111675126904\n",
      "Transformed value 0.00030222374477935327 to ef1133c658.\n",
      "Transformed value 59 to [59, 59, 59, 59, 59].\n",
      "Run with parameters (0.0004, ef1133c658, [59, 59, 59, 59, 59], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, ef1133c658, [59, 59, 59, 59, 59], 10, 20, 0.2) completed, best_val_loss: 0.7433546781539917, best_val_metric: 0.7969543147208121, best_hidden_layer_sizes: [59, 59, 59, 59, 59]\n",
      "Best overall combination: (0.0004, 732c7d8aeb, [82, 82, 82, 82, 82], 10, 20, 0.2), val_metric: 0.8274111675126904\n",
      "Transformed value 0.05132549793521158 to 1a5b0737d9.\n",
      "Transformed value 54 to [54, 54, 54, 54, 54].\n",
      "Run with parameters (0.0004, 1a5b0737d9, [54, 54, 54, 54, 54], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 1a5b0737d9, [54, 54, 54, 54, 54], 10, 20, 0.2) completed, best_val_loss: 1.2915805578231812, best_val_metric: 0.7157360406091371, best_hidden_layer_sizes: [54, 54, 54, 54, 54]\n",
      "Best overall combination: (0.0004, 732c7d8aeb, [82, 82, 82, 82, 82], 10, 20, 0.2), val_metric: 0.8274111675126904\n",
      "Transformed value 0.0024737873822741224 to 3db807b2d4.\n",
      "Transformed value 30 to [30, 30, 30, 30, 30].\n",
      "Run with parameters (0.0004, 3db807b2d4, [30, 30, 30, 30, 30], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 3db807b2d4, [30, 30, 30, 30, 30], 10, 20, 0.2) completed, best_val_loss: 0.5782633423805237, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [30, 30, 30, 30, 30]\n",
      "Best overall combination: (0.0004, 732c7d8aeb, [82, 82, 82, 82, 82], 10, 20, 0.2), val_metric: 0.8274111675126904\n",
      "Transformed value 0.0003891889673489107 to 0e9c86e392.\n",
      "Transformed value 62 to [62, 62, 62, 62, 62].\n",
      "Run with parameters (0.0004, 0e9c86e392, [62, 62, 62, 62, 62], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 0e9c86e392, [62, 62, 62, 62, 62], 10, 20, 0.2) completed, best_val_loss: 0.6443434953689575, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [62, 62, 62, 62, 62]\n",
      "Best overall combination: (0.0004, 732c7d8aeb, [82, 82, 82, 82, 82], 10, 20, 0.2), val_metric: 0.8274111675126904\n",
      "Transformed value 0.09398639528389059 to 6a3217e08a.\n",
      "Transformed value 98 to [98, 98, 98, 98, 98].\n",
      "Run with parameters (0.0004, 6a3217e08a, [98, 98, 98, 98, 98], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 6a3217e08a, [98, 98, 98, 98, 98], 10, 20, 0.2) completed, best_val_loss: 1.9753344058990479, best_val_metric: 0.6243654822335025, best_hidden_layer_sizes: [98, 98, 98, 98, 98]\n",
      "Best overall combination: (0.0004, 732c7d8aeb, [82, 82, 82, 82, 82], 10, 20, 0.2), val_metric: 0.8274111675126904\n",
      "Transformed value 0.0007173333754176066 to 472661eb57.\n",
      "Transformed value 26 to [26, 26, 26, 26, 26].\n",
      "Run with parameters (0.0004, 472661eb57, [26, 26, 26, 26, 26], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 472661eb57, [26, 26, 26, 26, 26], 10, 20, 0.2) completed, best_val_loss: 0.5951873660087585, best_val_metric: 0.8274111675126904, best_hidden_layer_sizes: [26, 26, 26, 26, 26]\n",
      "Best overall combination: (0.0004, 732c7d8aeb, [82, 82, 82, 82, 82], 10, 20, 0.2), val_metric: 0.8274111675126904\n",
      "Transformed value 0.01738653733457648 to a1eb63af43.\n",
      "Transformed value 31 to [31, 31, 31, 31, 31].\n",
      "Run with parameters (0.0004, a1eb63af43, [31, 31, 31, 31, 31], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, a1eb63af43, [31, 31, 31, 31, 31], 10, 20, 0.2) completed, best_val_loss: 0.8035193681716919, best_val_metric: 0.7766497461928934, best_hidden_layer_sizes: [31, 31, 31, 31, 31]\n",
      "Best overall combination: (0.0004, 732c7d8aeb, [82, 82, 82, 82, 82], 10, 20, 0.2), val_metric: 0.8274111675126904\n",
      "Transformed value 0.001686418919675677 to aa42fcd419.\n",
      "Transformed value 16 to [16, 16, 16, 16, 16].\n",
      "Run with parameters (0.0004, aa42fcd419, [16, 16, 16, 16, 16], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, aa42fcd419, [16, 16, 16, 16, 16], 10, 20, 0.2) completed, best_val_loss: 0.5805888772010803, best_val_metric: 0.7969543147208121, best_hidden_layer_sizes: [16, 16, 16, 16, 16]\n",
      "Best overall combination: (0.0004, 732c7d8aeb, [82, 82, 82, 82, 82], 10, 20, 0.2), val_metric: 0.8274111675126904\n",
      "Transformed value 0.0064990429611016705 to 287fc2177b.\n",
      "Transformed value 77 to [77, 77, 77, 77, 77].\n",
      "Run with parameters (0.0004, 287fc2177b, [77, 77, 77, 77, 77], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 287fc2177b, [77, 77, 77, 77, 77], 10, 20, 0.2) completed, best_val_loss: 0.6464052796363831, best_val_metric: 0.8020304568527918, best_hidden_layer_sizes: [77, 77, 77, 77, 77]\n",
      "Best overall combination: (0.0004, 732c7d8aeb, [82, 82, 82, 82, 82], 10, 20, 0.2), val_metric: 0.8274111675126904\n",
      "Transformed value 0.006350974874379029 to 807bd92bdf.\n",
      "Transformed value 45 to [45, 45, 45, 45, 45].\n",
      "Run with parameters (0.0004, 807bd92bdf, [45, 45, 45, 45, 45], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, 807bd92bdf, [45, 45, 45, 45, 45], 10, 20, 0.2) completed, best_val_loss: 0.6257602572441101, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [45, 45, 45, 45, 45]\n",
      "Best overall combination: (0.0004, 732c7d8aeb, [82, 82, 82, 82, 82], 10, 20, 0.2), val_metric: 0.8274111675126904\n",
      "Transformed value 0.0009257323406461388 to a9d0e4233b.\n",
      "Transformed value 52 to [52, 52, 52, 52, 52].\n",
      "Run with parameters (0.0004, a9d0e4233b, [52, 52, 52, 52, 52], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, a9d0e4233b, [52, 52, 52, 52, 52], 10, 20, 0.2) completed, best_val_loss: 0.6369279026985168, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [52, 52, 52, 52, 52]\n",
      "Best overall combination: (0.0004, 732c7d8aeb, [82, 82, 82, 82, 82], 10, 20, 0.2), val_metric: 0.8274111675126904\n",
      "Transformed value 0.02844214139060114 to eb22d9a24a.\n",
      "Transformed value 13 to [13, 13, 13, 13, 13].\n",
      "Run with parameters (0.0004, eb22d9a24a, [13, 13, 13, 13, 13], 10, 20, 0.2) started...\n",
      "Run with parameters (0.0004, eb22d9a24a, [13, 13, 13, 13, 13], 10, 20, 0.2) completed, best_val_loss: 1.0578173398971558, best_val_metric: 0.751269035532995, best_hidden_layer_sizes: [13, 13, 13, 13, 13]\n",
      "Best overall combination: (0.0004, 732c7d8aeb, [82, 82, 82, 82, 82], 10, 20, 0.2), val_metric: 0.8274111675126904\n",
      "Transformed value 0.0011169226047401295 to f02a6026fb.\n",
      "Transformed value 99 to [99, 99, 99, 99, 99].\n",
      "Run with parameters (0.0004, f02a6026fb, [99, 99, 99, 99, 99], 10, 20, 0.2) started...\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomSearch()\n",
    "random_search.run(\n",
    "    train_fn_conv, x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test), \n",
    "    learning_rate=0.0004, schedule=PowerRange(-4, -1, lambda x: Schedule([StaticEpoch(x, 'l1')] * 20)), \n",
    "    layer_sizes=UniformRange(10, 100, lambda x: [x] * 5, integer=True),\n",
    "    output_neurons=10, min_new_neurons=20, growth_percentage=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed value 0.0009662030509360944 to b65eaa8e93.\n",
      "Transformed value 15 to [15, 15, 15, 15, 15].\n",
      "Run with parameters (0.0004, b65eaa8e93, [15, 15, 15, 15, 15], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, b65eaa8e93, [15, 15, 15, 15, 15], 10, 20, 0.2, False) completed, best_val_loss: 0.6498957872390747, best_val_metric: 0.7817258883248731, best_hidden_layer_sizes: [15, 15, 15, 15, 15]\n",
      "Best overall combination: (0.0004, b65eaa8e93, [15, 15, 15, 15, 15], 10, 20, 0.2, False), val_metric: 0.7817258883248731\n",
      "Transformed value 0.0003267030556988157 to 273236d7f9.\n",
      "Transformed value 18 to [18, 18, 18, 18, 18].\n",
      "Run with parameters (0.0004, 273236d7f9, [18, 18, 18, 18, 18], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, 273236d7f9, [18, 18, 18, 18, 18], 10, 20, 0.2, False) completed, best_val_loss: 0.6477029919624329, best_val_metric: 0.7918781725888325, best_hidden_layer_sizes: [18, 18, 18, 18, 18]\n",
      "Best overall combination: (0.0004, 273236d7f9, [18, 18, 18, 18, 18], 10, 20, 0.2, False), val_metric: 0.7918781725888325\n",
      "Transformed value 0.00038789693402950303 to 3f4687524b.\n",
      "Transformed value 86 to [86, 86, 86, 86, 86].\n",
      "Run with parameters (0.0004, 3f4687524b, [86, 86, 86, 86, 86], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, 3f4687524b, [86, 86, 86, 86, 86], 10, 20, 0.2, False) completed, best_val_loss: 0.7787258625030518, best_val_metric: 0.8020304568527918, best_hidden_layer_sizes: [86, 86, 86, 86, 86]\n",
      "Best overall combination: (0.0004, 3f4687524b, [86, 86, 86, 86, 86], 10, 20, 0.2, False), val_metric: 0.8020304568527918\n",
      "Transformed value 0.0002574693734049669 to 89b2dbb792.\n",
      "Transformed value 75 to [75, 75, 75, 75, 75].\n",
      "Run with parameters (0.0004, 89b2dbb792, [75, 75, 75, 75, 75], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, 89b2dbb792, [75, 75, 75, 75, 75], 10, 20, 0.2, False) completed, best_val_loss: 0.8018823862075806, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [75, 75, 75, 75, 75]\n",
      "Best overall combination: (0.0004, 89b2dbb792, [75, 75, 75, 75, 75], 10, 20, 0.2, False), val_metric: 0.8071065989847716\n",
      "Transformed value 0.0014874947006337479 to 9ff69115b2.\n",
      "Transformed value 29 to [29, 29, 29, 29, 29].\n",
      "Run with parameters (0.0004, 9ff69115b2, [29, 29, 29, 29, 29], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, 9ff69115b2, [29, 29, 29, 29, 29], 10, 20, 0.2, False) completed, best_val_loss: 0.5801375508308411, best_val_metric: 0.8071065989847716, best_hidden_layer_sizes: [29, 29, 29, 29, 29]\n",
      "Best overall combination: (0.0004, 89b2dbb792, [75, 75, 75, 75, 75], 10, 20, 0.2, False), val_metric: 0.8071065989847716\n",
      "Transformed value 0.0013880220414808396 to 63eade0ba7.\n",
      "Transformed value 77 to [77, 77, 77, 77, 77].\n",
      "Run with parameters (0.0004, 63eade0ba7, [77, 77, 77, 77, 77], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, 63eade0ba7, [77, 77, 77, 77, 77], 10, 20, 0.2, False) completed, best_val_loss: 0.6101655960083008, best_val_metric: 0.8223350253807107, best_hidden_layer_sizes: [77, 77, 77, 77, 77]\n",
      "Best overall combination: (0.0004, 63eade0ba7, [77, 77, 77, 77, 77], 10, 20, 0.2, False), val_metric: 0.8223350253807107\n",
      "Transformed value 0.002591441191860945 to b8eb2852e2.\n",
      "Transformed value 34 to [34, 34, 34, 34, 34].\n",
      "Run with parameters (0.0004, b8eb2852e2, [34, 34, 34, 34, 34], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, b8eb2852e2, [34, 34, 34, 34, 34], 10, 20, 0.2, False) completed, best_val_loss: 0.6003416776657104, best_val_metric: 0.817258883248731, best_hidden_layer_sizes: [34, 34, 34, 34, 34]\n",
      "Best overall combination: (0.0004, 63eade0ba7, [77, 77, 77, 77, 77], 10, 20, 0.2, False), val_metric: 0.8223350253807107\n",
      "Transformed value 0.00043650509988754307 to 4961ec7c0b.\n",
      "Transformed value 14 to [14, 14, 14, 14, 14].\n",
      "Run with parameters (0.0004, 4961ec7c0b, [14, 14, 14, 14, 14], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, 4961ec7c0b, [14, 14, 14, 14, 14], 10, 20, 0.2, False) completed, best_val_loss: 0.64192795753479, best_val_metric: 0.7868020304568528, best_hidden_layer_sizes: [14, 14, 14, 14, 14]\n",
      "Best overall combination: (0.0004, 63eade0ba7, [77, 77, 77, 77, 77], 10, 20, 0.2, False), val_metric: 0.8223350253807107\n",
      "Transformed value 0.0005399207675525052 to 6c5d260257.\n",
      "Transformed value 73 to [73, 73, 73, 73, 73].\n",
      "Run with parameters (0.0004, 6c5d260257, [73, 73, 73, 73, 73], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, 6c5d260257, [73, 73, 73, 73, 73], 10, 20, 0.2, False) completed, best_val_loss: 0.7608206272125244, best_val_metric: 0.817258883248731, best_hidden_layer_sizes: [73, 73, 73, 73, 73]\n",
      "Best overall combination: (0.0004, 63eade0ba7, [77, 77, 77, 77, 77], 10, 20, 0.2, False), val_metric: 0.8223350253807107\n",
      "Transformed value 0.00018785967271847215 to 874cb1676c.\n",
      "Transformed value 47 to [47, 47, 47, 47, 47].\n",
      "Run with parameters (0.0004, 874cb1676c, [47, 47, 47, 47, 47], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, 874cb1676c, [47, 47, 47, 47, 47], 10, 20, 0.2, False) completed, best_val_loss: 0.5728524923324585, best_val_metric: 0.8121827411167513, best_hidden_layer_sizes: [47, 47, 47, 47, 47]\n",
      "Best overall combination: (0.0004, 63eade0ba7, [77, 77, 77, 77, 77], 10, 20, 0.2, False), val_metric: 0.8223350253807107\n",
      "Transformed value 0.0017403421504741871 to 5588bc3dd9.\n",
      "Transformed value 51 to [51, 51, 51, 51, 51].\n",
      "Run with parameters (0.0004, 5588bc3dd9, [51, 51, 51, 51, 51], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, 5588bc3dd9, [51, 51, 51, 51, 51], 10, 20, 0.2, False) completed, best_val_loss: 0.6114529967308044, best_val_metric: 0.8121827411167513, best_hidden_layer_sizes: [51, 51, 51, 51, 51]\n",
      "Best overall combination: (0.0004, 63eade0ba7, [77, 77, 77, 77, 77], 10, 20, 0.2, False), val_metric: 0.8223350253807107\n",
      "Transformed value 0.0017007622738529566 to 2f8566c43b.\n",
      "Transformed value 95 to [95, 95, 95, 95, 95].\n",
      "Run with parameters (0.0004, 2f8566c43b, [95, 95, 95, 95, 95], 10, 20, 0.2, False) started...\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomSearch()\n",
    "random_search.run(\n",
    "    train_fn_conv, x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test), \n",
    "    learning_rate=0.0004, schedule=PowerRange(-4, -2.5, lambda x: Schedule([StaticEpoch(x, 'l1')] * 20)), \n",
    "    layer_sizes=UniformRange(10, 100, lambda x: [x] * 5, integer=True),\n",
    "    output_neurons=10, min_new_neurons=20, growth_percentage=0.2, use_static_graph=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0c6e4c8af0>]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 244,
       "width": 366
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [0] + [x[0] for x in random_search.val_metrics]\n",
    "y = [0] + [x[1] for x in random_search.val_metrics]\n",
    "plt.step(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cifar 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratio 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = get_cifar_10_dataset(fraction=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed value 0.0008065605947991057 to 806a72f301.\n",
      "Run with parameters (0.0004, 806a72f301, [20, 20, 20, 20, 20], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, 806a72f301, [20, 20, 20, 20, 20], 10, 20, 0.2, False) completed, best_val_loss: 1.8997548818588257, best_val_metric: 0.37055837563451777, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Best overall combination: (0.0004, 806a72f301, [20, 20, 20, 20, 20], 10, 20, 0.2, False), val_metric: 0.37055837563451777\n",
      "Transformed value 4.787375323359042e-05 to 9f3dfa33a4.\n",
      "Run with parameters (0.0004, 9f3dfa33a4, [20, 20, 20, 20, 20], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, 9f3dfa33a4, [20, 20, 20, 20, 20], 10, 20, 0.2, False) completed, best_val_loss: 1.9053282737731934, best_val_metric: 0.37055837563451777, best_hidden_layer_sizes: [23, 21, 20, 41, 20]\n",
      "Best overall combination: (0.0004, 806a72f301, [20, 20, 20, 20, 20], 10, 20, 0.2, False), val_metric: 0.37055837563451777\n",
      "Transformed value 9.088304270775486e-05 to dd3be467b2.\n",
      "Run with parameters (0.0004, dd3be467b2, [20, 20, 20, 20, 20], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, dd3be467b2, [20, 20, 20, 20, 20], 10, 20, 0.2, False) completed, best_val_loss: 1.916114091873169, best_val_metric: 0.350253807106599, best_hidden_layer_sizes: [20, 25, 20, 22, 20]\n",
      "Best overall combination: (0.0004, 806a72f301, [20, 20, 20, 20, 20], 10, 20, 0.2, False), val_metric: 0.37055837563451777\n",
      "Transformed value 1.5105432519915344e-05 to 320f39d6a0.\n",
      "Run with parameters (0.0004, 320f39d6a0, [20, 20, 20, 20, 20], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, 320f39d6a0, [20, 20, 20, 20, 20], 10, 20, 0.2, False) completed, best_val_loss: 1.977583646774292, best_val_metric: 0.39086294416243655, best_hidden_layer_sizes: [156, 231, 85, 208, 35]\n",
      "Best overall combination: (0.0004, 320f39d6a0, [20, 20, 20, 20, 20], 10, 20, 0.2, False), val_metric: 0.39086294416243655\n",
      "Transformed value 4.131036925617146e-05 to aae22bd4bf.\n",
      "Run with parameters (0.0004, aae22bd4bf, [20, 20, 20, 20, 20], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, aae22bd4bf, [20, 20, 20, 20, 20], 10, 20, 0.2, False) completed, best_val_loss: 1.8851412534713745, best_val_metric: 0.38578680203045684, best_hidden_layer_sizes: [26, 47, 22, 53, 20]\n",
      "Best overall combination: (0.0004, 320f39d6a0, [20, 20, 20, 20, 20], 10, 20, 0.2, False), val_metric: 0.39086294416243655\n",
      "Transformed value 0.00013715653923871332 to 9e28341a05.\n",
      "Run with parameters (0.0004, 9e28341a05, [20, 20, 20, 20, 20], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, 9e28341a05, [20, 20, 20, 20, 20], 10, 20, 0.2, False) completed, best_val_loss: 1.9178253412246704, best_val_metric: 0.36548223350253806, best_hidden_layer_sizes: [20, 21, 20, 20, 20]\n",
      "Best overall combination: (0.0004, 320f39d6a0, [20, 20, 20, 20, 20], 10, 20, 0.2, False), val_metric: 0.39086294416243655\n",
      "Transformed value 0.0006040139141699555 to 5ad2b2e9d1.\n",
      "Run with parameters (0.0004, 5ad2b2e9d1, [20, 20, 20, 20, 20], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, 5ad2b2e9d1, [20, 20, 20, 20, 20], 10, 20, 0.2, False) completed, best_val_loss: 1.8618627786636353, best_val_metric: 0.38071065989847713, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Best overall combination: (0.0004, 320f39d6a0, [20, 20, 20, 20, 20], 10, 20, 0.2, False), val_metric: 0.39086294416243655\n",
      "Transformed value 0.0030033449141685827 to dab9724eed.\n",
      "Run with parameters (0.0004, dab9724eed, [20, 20, 20, 20, 20], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, dab9724eed, [20, 20, 20, 20, 20], 10, 20, 0.2, False) completed, best_val_loss: 2.0501132011413574, best_val_metric: 0.26903553299492383, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Best overall combination: (0.0004, 320f39d6a0, [20, 20, 20, 20, 20], 10, 20, 0.2, False), val_metric: 0.39086294416243655\n",
      "Transformed value 1.1840228270660207e-05 to 8dca1e0c0e.\n",
      "Run with parameters (0.0004, 8dca1e0c0e, [20, 20, 20, 20, 20], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, 8dca1e0c0e, [20, 20, 20, 20, 20], 10, 20, 0.2, False) completed, best_val_loss: 2.037465810775757, best_val_metric: 0.4010152284263959, best_hidden_layer_sizes: [159, 222, 102, 250, 42]\n",
      "Best overall combination: (0.0004, 8dca1e0c0e, [20, 20, 20, 20, 20], 10, 20, 0.2, False), val_metric: 0.4010152284263959\n",
      "Transformed value 0.0030220018934383813 to 09377e4a84.\n",
      "Run with parameters (0.0004, 09377e4a84, [20, 20, 20, 20, 20], 10, 20, 0.2, False) started...\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomSearch()\n",
    "random_search.run(\n",
    "    train_fn_conv, x=cifar10.X_train_norm, y=cifar10.y_train, validation_data=(cifar10.X_test_norm, cifar10.y_test), \n",
    "    learning_rate=0.0004, schedule=PowerRange(-5, -2.5, lambda x: Schedule([DynamicEpoch(x, 'weighted_l1')] * 20)), layer_sizes=[20, 20, 20, 20, 20], \n",
    "    output_neurons=10, min_new_neurons=20, growth_percentage=0.2, use_static_graph=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0c776f5820>]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAugAAAHpCAYAAADQ7smoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAABYlAAAWJQFJUiTwAABBwUlEQVR4nO3dfVzV9f3H/+fx4nz1YP5AZx4uxFxGnEKpvGquZmNU5nelEE4SdcvKaalZrtBlsW5lmftuRuh+2hq4SLGJSwd6owsrXRdMY1EzkQhnAdkIrZSrMD2/P/yds4gDAh9O54097v90833x+bw/r31Wz/PxfT7H5na73QIAAABghB6BXgAAAACA/yKgAwAAAAYhoAMAAAAGIaADAAAABiGgAwAAAAYhoAMAAAAGIaADAAAABiGgAwAAAAYhoAMAAAAGIaADAAAABiGgAwAAAAYhoAMAAAAG6RXoBXybioqKAr0EAAAAfIeMGjWqw3N4gg4AAAAY5Dv1BN2jM59krCopKZEkuVyub/3c3wXU17+or39RX/+jxv5Fff2L+vqXv+prZecGT9ABAAAAgxDQAQAAAIMQ0AEAAACDENABAAAAgxDQAQAAAIMQ0AEAAACDENABAAAAgxDQAQAAAIMQ0AEAAACDENABAAAAgxDQAQAAAIMQ0AEAAACDENABAAAAg3RJQD927JiWL1+uuLg4xcTE6IorrtB9992nTz/9tMPH+vLLL3Xttdfqwgsv1D/+8Y8W/f/5z3+0dOlSXXHFFYqJiVFcXJweffRR1dbWdsWlAAAAAAHVy+oB6uvrNWPGDJWXlyslJUUxMTE6dOiQMjMzVVhYqNzcXIWEhLT7eH/4wx906NAhn33V1dWaOnWqjh8/rl/84hcaNmyY3nvvPWVnZ6uoqEgbN26U3W63ekkAAABAwFgO6NnZ2SotLVVaWpqmT5/ubXe5XJo/f77WrVunJUuWtOtYpaWl+tOf/iSXy6WSkpIW/atXr9Z//vMfPfnkk5owYYIk6YYbblBoaKgeffRRPfvss5o5c6bVSwIAAAACxnJAz8vLk8PhUFJSUrP2+Ph4OZ1O5eXlKTU1VTabrc3jnDp1Svfff7/Cw8OVnJystLS0Zv1fffWVduzYofPOO88bzj1+9rOf6f/+7/+0bds2AjoAAF3gj7sP6vGX3ldd08kOzDrot/VAor6dF2TvqUXxUbrtR98P9FLaxVJAr62tVVlZmUaNGtVia4nNZlNsbKyef/55VVZWasiQIW0e65lnntG7776r7OxsVVRUtOg/ePCgjh8/rh//+Mct+hwOh6KiorR//341NTWdcZuLr6fz/tbQ0BCwc38XUF//or7+RX39jxp33O9f+LcavnIHehlAl6hrOqn/95X3dcWgL1v0mfjvB0tfEq2srJQkhYaG+ux3Op2S5DNwf93hw4e1atUqTZ06VWPGjPE5xnOM1s4VGhqqkydP6vDhw+1aOwAAaB3hHGeTvr1sSrz4/wn0MtrN0hP0uro6SVLfvn199nvaz/SGld/85jcKCgrSPffc4/dzSaf3x3/bPJ/KAnHu7wLq61/U17+or/9R487473aKQyv+t82R1Ne/qK9/+au+RUVFnZ5rKaB79pW73W1/ym5r//n27dv16quvKj09Xf379/fruQAAAADTWdri0q9fP0mnX7Xoi+ept2fcN33++efe96dPnDixS851zjnnnHnhAAAAgKEsPUGPiIiQzWZrdd93VVWVJGno0KE++1euXKmGhgbNmzdPn3zyibf92LFjkqSjR4/qk08+0YABAxQZGSlJbZ6rd+/ere5RBwAAALoDSwHd4XB431ne2NioPn36ePtOnjyp4uJihYeHKywszOf8wsJC1dfXa+rUqT77Fy1aJEl6+umnNWbMGIWEhOjtt99uMe6LL77QBx98oMsuu0y9ell+cyQAAAAQMJbTbEJCgpYvX65NmzbpF7/4hbd927ZtOnr0qBYsWOBtKy8vl91u975ycfny5WpsbGxxzDfffFN//vOfdffddysqKkpRUVHq0aOHJk+erPXr1+vFF1/U1Vdf7R3/9NNP6+TJky3exQ4AAAB0N5YDenJysvLz87Vy5UpVVVVpxIgRKisrU1ZWlqKjozV79mzv2EmTJmnYsGEqKCiQJP3gBz/weczPPvtMknTJJZdo3Lhx3va5c+fq5Zdf1j333KObb75Zw4YN0z//+U9t2rRJV1xxhW644QarlwMAAAAElOWAbrfblZWVpdWrV6ugoEA5OTkaOHCgkpOTtXDhQjkcjq5YpyQpJCREmzZt0uOPP67Nmzfr888/l9Pp1O23365f/vKX6tHD0ndegS7RuV/f6y74FTv/or7+R40BmK9LNmwHBQUpNTVVqampbY4rLS1t1/ESExOVmJjos2/gwIF66KGHOrxG4Nty9oZzAN9FQfaegV4C8J3DI2egixHOAZwtguw9tSg+KtDLAL5zeOUJ4Edn+vW97oJfsfMv6ut/1BhAd8ITdAAAAMAgBHQAAADAIAR0AAAAwCAEdAAAAMAgBHQAAADAIAR0AAAAwCAEdAAAAMAgBHQAAADAIAR0AAAAwCAEdAAAAMAgBHQAAADAIAR0AAAAwCAEdAAAAMAgBHQAAADAIAR0AAAAwCAEdAAAAMAgBHQAAADAIL0CvYDvii3vfa4NxZ+p4auDgV7KWY76AgCA7o0n6N+S0+HcHehl4FsUZO8Z6CUAAIBuiID+LSGcf7cE2XtqUXxUoJcBAAC6Iba4BMChFf8b6CWcdUpKSiRJLpcrwCsBAACwhifoAAAAgEEI6AAAAIBBCOgAAACAQQjoAAAAgEEI6AAAAIBBCOgAAACAQQjoAAAAgEEI6AAAAIBBCOgAAACAQQjoAAAAgEEI6AAAAIBBenXFQY4dO6aMjAzt3LlT1dXVCg4O1oQJE7Ro0SINGjSozbmnTp3S9u3btXHjRh08eFAnTpxQeHi4rrvuOs2aNUv9+vXzjo2Li1NVVVWrx9q6datcLldXXBIAAAAQEJYDen19vWbMmKHy8nKlpKQoJiZGhw4dUmZmpgoLC5Wbm6uQkJBW5y9btkxbtmzR+PHjddddd6lnz5569dVXlZ6erhdffFHPPvus7Ha7d/yAAQOUlpbm81gRERFWLwcAAAAIKMsBPTs7W6WlpUpLS9P06dO97S6XS/Pnz9e6deu0ZMkSn3P37dunLVu2aMKECXryySe97VOnTtXtt9+unTt36tVXX9U111zj7evbt68mTpxoddkAAACAkSzvQc/Ly5PD4VBSUlKz9vj4eDmdTuXl5cntdvuc26dPH919992aP39+i77x48dLkj755BOrSwQAAAC6DUtP0Gtra1VWVqZRo0Y124YiSTabTbGxsXr++edVWVmpIUOGtJg/fPhwDR8+3OexS0tLJUlRUVGtnr+pqUm9e/eWzWazcBUAAACAOSwF9MrKSklSaGioz36n0ylJqqio8BnQv66pqUn19fWqrq5Wfn6+Nm/erKlTp+ryyy9vNq6xsVGPPPKItm/frpqaGtntdo0fP1733HNPq2H/m0pKSto1zl8Cff6zUUNDgyRq6y/U17+or/9RY/+ivv5Fff3LxPpaCuh1dXWSTu8L98XTXltbe8Zj5efna+nSpZKkkJAQPfTQQ5o6dWqLcUeOHNFHH32kxYsXq3///tqzZ482bNigoqIibd68WcOGDevs5QAAAAABZymge7aWtLbH/Jvj2nLllVdq/fr1+vTTT/Xaa68pLS1Nr732mn772996t8+sWLFCPXr00OjRo73z4uPjdcEFF2jZsmVKT0/X448/fsZzBeZVjAcDfP6zm+dTL7X1D+rrX9TX/6ixf1Ff/6K+/uWv+hYVFXV6rqWA7nlHeX19vc9+zxP2r7/LvDWDBg3yvjP9hhtu0EUXXaRHH31UUVFRuuOOOyRJY8eO9Tn3xhtv1MMPP6w333yzw9cAAAAAmMTSW1wiIiJks9l0+PBhn/2eHxUaOnRoh489efJkSdLf//73M47t0aOHgoODvR8IAAAAgO7KUkB3OBxyuVwqKSlRY2Njs76TJ0+quLhY4eHhCgsL8zk/IyND48aN0+uvv96ir6mpyXsc6fQXTXNzc7V///4WYz1fLm3ty6oAAABAd2H5PegJCQlqbGzUpk2bmrVv27ZNR48eVWJioretvLxcFRUV3j9HR0fr888/V3Z2dovjbt26VZJ02WWXSZI+++wz3XfffXr44Yf11VdfNRv71FNP6dSpU81+0AgAAADojiz/kmhycrLy8/O1cuVKVVVVacSIESorK1NWVpaio6M1e/Zs79hJkyZp2LBhKigokHT6C55XXXWVXnnlFc2cOVMTJ05Unz59tHfvXm3dulVOp1O33nqrJGnkyJFKSEjQc889pxkzZuj666+X3W7XG2+8oR07digqKkrz5s2zejkAAABAQFkO6Ha7XVlZWVq9erUKCgqUk5OjgQMHKjk5WQsXLpTD4Wh1rs1m05o1a7R161Zt3rxZGRkZqq2t1eDBg3XTTTfp9ttv935xVJKWL1+uSy+9VLm5uUpPT1dDQ4MiIiI0d+5c3Xbbbe36MioAAABgMssBXZKCgoKUmpqq1NTUNsd5fh202QJ69VJSUpKSkpLOeJ6ePXtq2rRpmjZtWqfXCgAAAJjM8h50AAAAAF2HgA4AAAAYhIAOAAAAGISADgAAABiEgA4AAAAYhIAOAAAAGISADgAAABiEgA4AAAAYhIAOAAAAGISADgAAABiEgA4AAAAYhIAOAAAAGISADgAAABiEgA4AAAAYhIAOAAAAGISADgAAABiEgA4AAAAYhIAOAAAAGISADgAAABiEgA4AAAAYhIAOAAAAGISADgAAABiEgA4AAAAYhIAOAAAAGISADgAAABiEgA4AAAAYhIAOAAAAGISADgAAABiEgA4AAAAYhIAOAAAAGISADgAAABiEgA4AAAAYhIAOAAAAGISADgAAABikV1cc5NixY8rIyNDOnTtVXV2t4OBgTZgwQYsWLdKgQYPanHvq1Clt375dGzdu1MGDB3XixAmFh4fruuuu06xZs9SvX79m48vLy5Wenq49e/aorq5OYWFhuv766zVnzhzZ7fauuBwAAAAgYCwH9Pr6es2YMUPl5eVKSUlRTEyMDh06pMzMTBUWFio3N1chISGtzl+2bJm2bNmi8ePH66677lLPnj316quvKj09XS+++KKeffZZb/AuKytTcnKy7Ha7br75ZjmdThUWFiojI0P79u3T2rVrrV4OAAAAEFCWA3p2drZKS0uVlpam6dOne9tdLpfmz5+vdevWacmSJT7n7tu3T1u2bNGECRP05JNPetunTp2q22+/XTt37tSrr76qa665RpK0YsUKNTQ0KCcnR1FRUZKkyZMnKygoSNnZ2Xr55ZcVFxdn9ZIAAACAgLG8Bz0vL08Oh0NJSUnN2uPj4+V0OpWXlye32+1zbp8+fXT33Xdr/vz5LfrGjx8vSfrkk08kSUeOHNHrr7+uyy+/3BvOPWbOnClJ2rZtm9XLAQAAAALK0hP02tpalZWVadSoUS32f9tsNsXGxur5559XZWWlhgwZ0mL+8OHDNXz4cJ/HLi0tlSRvGH/33Xfldrs1cuTIFmOHDh2q4OBgvfPOO1YuBwAAAAg4SwG9srJSkhQaGuqz3+l0SpIqKip8BvSva2pqUn19vaqrq5Wfn6/Nmzdr6tSpuvzyy73HaOtcoaGhOnDggE6cOKHevXu3ea6SkpI2+/0t0Oc/GzU0NEiitv5Cff2L+vofNfYv6utf1Ne/TKyvpYBeV1cnSerbt6/Pfk97bW3tGY+Vn5+vpUuXSpJCQkL00EMPaerUqR06l9vtVl1dnYKDg9t9DQAAAIBJLAV0m80mSa3uMf/muLZceeWVWr9+vT799FO99tprSktL02uvvabf/va3stvtXXoul8t1xjFd72CAz39283zqpbb+QX39i/r6HzX2L+rrX9TXv/xV36Kiok7PtRTQPe8or6+v99nveer9zXeZ+zJo0CDvO9NvuOEGXXTRRXr00UcVFRWlO+64o13nstlsCgoK6vB1AAAAAKaw9BaXiIgI2Ww2HT582Gd/VVWVpNNf4uyoyZMnS5L+/ve/S5J3D7uvc7ndbn388ccKDw9Xr15d8ttLAAAAQEBYCugOh0Mul0slJSVqbGxs1nfy5EkVFxcrPDxcYWFhPudnZGRo3Lhxev3111v0NTU1eY8jSbGxserZs6fefvvtFmNLS0t1/PhxjR492srlAAAAAAFn+T3oCQkJamxs1KZNm5q1b9u2TUePHlViYqK3rby83Ps2FkmKjo7W559/ruzs7BbH3bp1qyTpsssukyQFBwcrLi5Oe/fu1Xvvvdds7Pr16yWpxbvYAQAAgO7G8n6Q5ORk5efna+XKlaqqqtKIESNUVlamrKwsRUdHa/bs2d6xkyZN0rBhw1RQUCDp9I8ZXXXVVXrllVc0c+ZMTZw4UX369NHevXu1detWOZ1O3Xrrrd759957r/bu3avZs2frlltu0eDBg7Vr1y5t375dSUlJGjNmjNXLAQAAAALKckC32+3KysrS6tWrVVBQoJycHA0cOFDJyclauHChHA5Hq3NtNpvWrFmjrVu3avPmzcrIyFBtba0GDx6sm266Sbfffrv3i6OSFBkZqc2bN2vVqlXKzMxUXV2dIiMjtXTpUs2aNcvqpQAAAAAB1yXfqAwKClJqaqpSU1PbHOf5ddBmC+jVS0lJSe3enhIZGalVq1Z1ap0AAACA6SzvQQcAAADQdQjoAAAAgEEI6AAAAIBBCOgAAACAQQjoAAAAgEEI6AAAAIBBCOgAAACAQQjoAAAAgEEI6AAAAIBBCOgAAACAQQjoAAAAgEEI6AAAAIBBCOgAAACAQQjoAAAAgEEI6AAAAIBBCOgAAACAQQjoAAAAgEEI6AAAAIBBCOgAAACAQQjoAAAAgEEI6AAAAIBBCOgAAACAQQjoAAAAgEEI6AAAAIBBCOgAAACAQQjoAAAAgEEI6AAAAIBBCOgAAACAQQjoAAAAgEEI6AAAAIBBCOgAAACAQQjoAAAAgEEI6AAAAIBBCOgAAACAQQjoAAAAgEF6dcVBjh07poyMDO3cuVPV1dUKDg7WhAkTtGjRIg0aNOiM89966y2tW7dOJSUlqqur05AhQzRx4kTNnj1bffr08Y6Li4tTVVVVq8fZunWrXC5XV1wSAAAAEBCWA3p9fb1mzJih8vJypaSkKCYmRocOHVJmZqYKCwuVm5urkJCQVufv2LFDd999t8477zzdeuut6tevn3bv3q309HTt3r1bGzduVI8e/33QP2DAAKWlpfk8VkREhNXLAQAAAALKckDPzs5WaWmp0tLSNH36dG+7y+XS/PnztW7dOi1ZssTn3KamJt1///0KDQ3V5s2bdc4550iSkpKStGDBAr3wwgvavXu3rrrqKu+cvn37auLEiVaXDQAAABjJ8h70vLw8ORwOJSUlNWuPj4+X0+lUXl6e3G63z7k1NTW6+uqrNWfOHG8497jyyislSe+//77VJQIAAADdhqUn6LW1tSorK9OoUaNkt9ub9dlsNsXGxur5559XZWWlhgwZ0mJ+WFiYVqxY4fPYx48fl6QWwf3rmpqa1Lt3b9lstg6tu6SkpEPju1qgz382amhokERt/YX6+hf19T9q7F/U17+or3+ZWF9LT9ArKyslSaGhoT77nU6nJKmioqJDx21qatKWLVtkt9sVFxfXrK+xsVGPPPKIfvjDH2rEiBEaOXKkfvnLX+qDDz7oxBUAAAAAZrH0BL2urk7S6X3hvnjaa2tr233MU6dO6f7771d5ebnuvvtuDR48uFn/kSNH9NFHH2nx4sXq37+/9uzZow0bNqioqEibN2/WsGHDzniOwLzp5WCAz39283zqpbb+QX39i/r6HzX2L+rrX9TXv/xV36Kiok7PtRTQPVtLWttj/s1xZ9LY2KjFixfrpZde0tSpUzVnzpxm/StWrFCPHj00evRob1t8fLwuuOACLVu2TOnp6Xr88cc7dhEAAACAQSxtcenXr5+k069a9MXzhN0zri1Hjx7Vz3/+c7300kuaO3euHnrooRbBfuzYsc3CuceNN96oPn366M033+zoJQAAAABGsfQEPSIiQjabTYcPH/bZ7/lRoaFDh7Z5nJqaGqWkpKiqqkqPPfaYpkyZ0qF19OjRQ8HBwTpy5EiH5gEAAACmsfQE3eFwyOVyqaSkRI2Njc36Tp48qeLiYoWHhyssLKzVY9TW1urWW2/VJ598oieffLLVcF5RUaHc3Fzt37+/RV99fb2qq6tb/bIqAAAA0F1Yfg96QkKCGhsbtWnTpmbt27Zt09GjR5WYmOhtKy8vb/FGl+XLl+vAgQP6/e9/r/Hjx7d6ns8++0z33XefHn74YX311VfN+p566imdOnVK11xzjdXLAQAAAALK8i+JJicnKz8/XytXrlRVVZVGjBihsrIyZWVlKTo6WrNnz/aOnTRpkoYNG6aCggJJ0oEDB/Tcc88pKipKJ06c8LZ/3YABAzR27FiNHDlSCQkJeu655zRjxgxdf/31stvteuONN7Rjxw5FRUVp3rx5Vi8HAAAACCjLAd1utysrK0urV69WQUGBcnJyNHDgQCUnJ2vhwoVyOBytzt2/f7/cbrdKS0t15513+hwzduxYZWdnSzr9tP3SSy9Vbm6u0tPT1dDQoIiICM2dO1e33XZbu76MCgAAAJjMckCXpKCgIKWmpio1NbXNcaWlpc3+nJiY2GwLzJn07NlT06ZN07Rp0zq1TgAAAMB0lvegAwAAAOg6BHQAAADAIAR0AAAAwCAEdAAAAMAgBHQAAADAIAR0AAAAwCAEdAAAAMAgBHQAAADAIAR0AAAAwCAEdAAAAMAgBHQAAADAIAR0AAAAwCAEdAAAAMAgBHQAAADAIAR0AAAAwCAEdAAAAMAgBHQAAADAIAR0AAAAwCAEdAAAAMAgBHQAAADAIAR0AAAAwCAEdAAAAMAgBHQAAADAIAR0AAAAwCAEdAAAAMAgBHQAAADAIAR0AAAAwCAEdAAAAMAgBHQAAADAIAR0AAAAwCAEdAAAAMAgBHQAAADAIAR0AAAAwCAEdAAAAMAgvbriIMeOHVNGRoZ27typ6upqBQcHa8KECVq0aJEGDRp0xvlvvfWW1q1bp5KSEtXV1WnIkCGaOHGiZs+erT59+jQbW15ervT0dO3Zs0d1dXUKCwvT9ddfrzlz5shut3fF5QAAAAABYzmg19fXa8aMGSovL1dKSopiYmJ06NAhZWZmqrCwULm5uQoJCWl1/o4dO3T33XfrvPPO06233qp+/fpp9+7dSk9P1+7du7Vx40b16HH6QX9ZWZmSk5Nlt9t18803y+l0qrCwUBkZGdq3b5/Wrl1r9XIAAACAgLIc0LOzs1VaWqq0tDRNnz7d2+5yuTR//nytW7dOS5Ys8Tm3qalJ999/v0JDQ7V582adc845kqSkpCQtWLBAL7zwgnbv3q2rrrpKkrRixQo1NDQoJydHUVFRkqTJkycrKChI2dnZevnllxUXF2f1kgAAAICAsbwHPS8vTw6HQ0lJSc3a4+Pj5XQ6lZeXJ7fb7XNuTU2Nrr76as2ZM8cbzj2uvPJKSdL7778vSTpy5Ihef/11XX755d5w7jFz5kxJ0rZt26xeDgAAABBQlgJ6bW2tysrK5HK5Wuz/ttlsio2NVU1NjSorK33ODwsL04oVK3TTTTe16Dt+/LgkeYP7u+++K7fbrZEjR7YYO3ToUAUHB+udd96xcjkAAABAwFna4uIJ3qGhoT77nU6nJKmiokJDhgxp93Gbmpq0ZcsW2e1275aVioqKNs8VGhqqAwcO6MSJE+rdu3ebxy8pKWn3Wvwh0Oc/GzU0NEiitv5Cff2L+vofNfYv6utf1Ne/TKyvpSfodXV1kqS+ffv67Pe019bWtvuYp06d0v3336/y8nLNnz9fgwcPbve53G63dxwAAADQHVl6gm6z2SSp1T3m3xx3Jo2NjVq8eLFeeuklTZ06VXPmzPHLuVwuV7vW07UOBvj8ZzfPp15q6x/U17+or/9RY/+ivv5Fff3LX/UtKirq9FxLAb1fv36STr9q0RfP02zPuLYcPXpU8+bNU3FxsebOnatFixY1C9vtOZfNZlNQUFCHrgEAAAAwiaWAHhERIZvNpsOHD/vsr6qqknT6S5xtqampUUpKiqqqqvTYY49pypQpLcZ49rD7Opfb7dbHH3+s8PBw9erVJb+9BAAAAASEpT3oDodDLpdLJSUlamxsbNZ38uRJFRcXKzw8XGFhYa0eo7a2Vrfeeqs++eQTPfnkkz7DuSTFxsaqZ8+eevvtt1v0lZaW6vjx4xo9erSVywEAAAACzvJ70BMSEtTY2KhNmzY1a9+2bZuOHj2qxMREb1t5ebn3bSwey5cv14EDB/T73/9e48ePb/U8wcHBiouL0969e/Xee+8161u/fr0ktXgXOwAAANDdWN4PkpycrPz8fK1cuVJVVVUaMWKEysrKlJWVpejoaM2ePds7dtKkSRo2bJgKCgokSQcOHNBzzz2nqKgonThxwtv+dQMGDNDYsWMlSffee6/27t2r2bNn65ZbbtHgwYO1a9cubd++XUlJSRozZozVywEAAAACynJAt9vtysrK0urVq1VQUKCcnBwNHDhQycnJWrhwoRwOR6tz9+/fL7fbrdLSUt15550+x4wdO1bZ2dmSpMjISG3evFmrVq1SZmam6urqFBkZqaVLl2rWrFlWLwUAAAAIuC75RmVQUJBSU1OVmpra5rjS0tJmf05MTGy2BaY9IiMjtWrVqg6vEQAAAOgOLO9BBwAAANB1COgAAACAQQjoAAAAgEEI6AAAAIBBCOgAAACAQQjoAAAAgEEI6AAAAIBBCOgAAACAQQjoAAAAgEEI6AAAAIBBCOgAAACAQQjoAAAAgEEI6AAAAIBBCOgAAACAQQjoAAAAgEEI6AAAAIBBCOgAAACAQQjoAAAAgEEI6AAAAIBBCOgAAACAQQjoAAAAgEEI6AAAAIBBCOgAAACAQQjoAAAAgEEI6AAAAIBBCOgAAACAQQjoAAAAgEEI6AAAAIBBCOgAAACAQQjoAAAAgEEI6AAAAIBBCOgAAACAQQjoAAAAgEEI6AAAAIBBenXFQY4dO6aMjAzt3LlT1dXVCg4O1oQJE7Ro0SINGjSoXcf48MMPtXjxYv3rX//So48+qsTExBZj4uLiVFVV1eoxtm7dKpfL1enrAAAAAALNckCvr6/XjBkzVF5erpSUFMXExOjQoUPKzMxUYWGhcnNzFRIS0uYxtmzZoocffrhd5xswYIDS0tJ89kVERHR4/QAAAIBJLAf07OxslZaWKi0tTdOnT/e2u1wuzZ8/X+vWrdOSJUtanf/ss8/qgQce0MyZM3XBBRfogQceaPN8ffv21cSJE60uGwAAADCS5T3oeXl5cjgcSkpKatYeHx8vp9OpvLw8ud3uNo+xZs0aLVu2TL1797a6HAAAAKBbsxTQa2trVVZWJpfLJbvd3qzPZrMpNjZWNTU1qqysbPUY06ZNU3x8fKfO39TUdMbwDwAAAHQnlra4eIJ3aGioz36n0ylJqqio0JAhQ6ycyquxsVGPPPKItm/frpqaGtntdo0fP1733HOPhg8f3q5jlJSUdMlaOivQ5z8bNTQ0SKK2/kJ9/Yv6+h819i/q61/U179MrK+lgF5XVyfp9L5wXzzttbW1Vk7TzJEjR/TRRx9p8eLF6t+/v/bs2aMNGzaoqKhImzdv1rBhw7rsXAAAAMC3zVJAt9lsknTGbSaecVatWLFCPXr00OjRo71t8fHxuuCCC7Rs2TKlp6fr8ccfP+NxAvMqxoMBPv/ZzfOpl9r6B/X1L+rrf9TYv6ivf1Ff//JXfYuKijo919Ie9H79+kk6/apFXzxP2D3jrBo7dmyzcO5x4403qk+fPnrzzTe75DwAAABAoFgK6BEREbLZbDp8+LDPfs+PCg0dOtTKac6oR48eCg4O9n4gAAAAALorSwHd4XDI5XKppKREjY2NzfpOnjyp4uJihYeHKywszNIipdNfNM3NzdX+/ftb9NXX16u6urrVL6sCAAAA3YXl96AnJCSosbFRmzZtata+bds2HT16VImJid628vJyVVRUdOo8n332me677z49/PDD+uqrr5r1PfXUUzp16pSuueaaTh0bAAAAMIXlXxJNTk5Wfn6+Vq5cqaqqKo0YMUJlZWXKyspSdHS0Zs+e7R07adIkDRs2TAUFBd62Xbt2eV9vs2/fPu8/HQ6HJGnAgAEaO3asRo4cqYSEBD333HOaMWOGrr/+etntdr3xxhvasWOHoqKiNG/ePKuXAwAAAASU5YBut9uVlZWl1atXq6CgQDk5ORo4cKCSk5O1cOFCb9BuzYMPPujdq+6xYcMGbdiwQdLpL4ZmZ2dLkpYvX65LL71Uubm5Sk9PV0NDgyIiIjR37lzddtttXfZlVAAAACBQLAd0SQoKClJqaqpSU1PbHFdaWtqi7eWXX273eXr27Klp06Zp2rRpHV4jAAAA0B1Y3oMOAAAAoOsQ0AEAAACDENABAAAAgxDQAQAAAIMQ0AEAAACDENABAAAAgxDQAQAAAIMQ0AEAAACDENABAAAAgxDQAQAAAIMQ0AEAAACDENABAAAAgxDQAQAAAIMQ0AEAAACDENABAAAAgxDQAQAAAIMQ0AEAAACDENABAAAAgxDQAQAAAIMQ0AEAAACDENABAAAAgxDQAQAAAIMQ0AEAAACDENABAAAAgxDQAQAAAIMQ0AEAAACDENABAAAAgxDQAQAAAIMQ0AEAAACDENABAAAAgxDQAQAAAIMQ0AEAAACDENABAAAAgxDQAQAAAIN0SUA/duyYli9frri4OMXExOiKK67Qfffdp08//bTdx/jwww+VlJSkCy+8UH/9619bHVdeXq6FCxfq8ssv14gRI3Tttddq9erVampq6opLAQAAAAKql9UD1NfXa8aMGSovL1dKSopiYmJ06NAhZWZmqrCwULm5uQoJCWnzGFu2bNHDDz98xnOVlZUpOTlZdrtdN998s5xOpwoLC5WRkaF9+/Zp7dq1Vi8HAAAACCjLAT07O1ulpaVKS0vT9OnTve0ul0vz58/XunXrtGTJklbnP/vss3rggQc0c+ZMXXDBBXrggQdaHbtixQo1NDQoJydHUVFRkqTJkycrKChI2dnZevnllxUXF2f1kgAAAICAsbzFJS8vTw6HQ0lJSc3a4+Pj5XQ6lZeXJ7fb3eYx1qxZo2XLlql3796tjjly5Ihef/11XX755d5w7jFz5kxJ0rZt2zp5FQAAAIAZLAX02tpalZWVyeVyyW63N+uz2WyKjY1VTU2NKisrWz3GtGnTFB8ff8Zzvfvuu3K73Ro5cmSLvqFDhyo4OFjvvPNOxy8CAAAAMIilLS6e4B0aGuqz3+l0SpIqKio0ZMgQK6dSRUVFm+cKDQ3VgQMHdOLEiTafxEtSSUmJpbVYFejzn40aGhokUVt/ob7+RX39jxr7F/X1L+rrXybW19IT9Lq6OklS3759ffZ72mtra62cpt3ncrvd3nEAAABAd2TpCbrNZpOkM+4x94wz5Vwul8vyejruYIDPf3bzfOqltv5Bff2L+vofNfYv6utf1Ne//FXfoqKiTs+19AS9X79+kk6/atEXz9Nszzh/n8tmsykoKMjyuQAAAIBAsRTQIyIiZLPZdPjwYZ/9VVVVkk5/idMqzx52X+dyu936+OOPFR4erl69LL85EgAAAAgYSwHd4XDI5XKppKREjY2NzfpOnjyp4uJihYeHKywszNIiJSk2NlY9e/bU22+/3aKvtLRUx48f1+jRoy2fBwAAAAgky+9BT0hIUGNjozZt2tSsfdu2bTp69KgSExO9beXl5d63sXRUcHCw4uLitHfvXr333nvN+tavXy9JLd7FDgAAAHQ3lveDJCcnKz8/XytXrlRVVZVGjBihsrIyZWVlKTo6WrNnz/aOnTRpkoYNG6aCggJv265du7yvt9m3b5/3nw6HQ5I0YMAAjR07VpJ07733au/evZo9e7ZuueUWDR48WLt27dL27duVlJSkMWPGWL0cAAAAIKAsB3S73a6srCytXr1aBQUFysnJ0cCBA5WcnKyFCxd6g3ZrHnzwQe9edY8NGzZow4YNkqSxY8cqOztbkhQZGanNmzdr1apVyszMVF1dnSIjI7V06VLNmjXL6qUAAAAAAdcl36gMCgpSamqqUlNT2xxXWlraou3ll1/u0LkiIyO1atWqDs0BAAAAugvLe9ABAAAAdB0COgAAAGAQAjoAAABgEAI6AAAAYBACOgAAAGAQAjoAAABgEAI6AAAAYBACOgAAAGAQAjoAAABgEAI6AAAAYBACOgAAAGAQAjoAAABgEAI6AAAAYBACOgAAAGAQAjoAAABgEAI6AAAAYBACOgAAAGAQAjoAAABgEAI6AAAAYBACOgAAAGAQAjoAAABgEAI6AAAAYBACOgAAAGAQAjoAAABgEAI6AAAAYBACOgAAAGAQAjoAAABgEAI6AAAAYBACOgAAAGAQAjoAAABgEAI6AAAAYBACOgAAAGAQAjoAAABgEAI6AAAAYBACOgAAAGCQXl1xkGPHjikjI0M7d+5UdXW1goODNWHCBC1atEiDBg064/zi4mKtWbNGxcXF+vLLLzV06FBNmzZN06dPV48e//0MERcXp6qqqlaPs3XrVrlcrq64JAAAACAgLAf0+vp6zZgxQ+Xl5UpJSVFMTIwOHTqkzMxMFRYWKjc3VyEhIa3Of/PNN3XbbbfJ6XTqjjvuUHBwsF544QU99NBDOnTokJYtW9Zs/IABA5SWlubzWBEREVYvBwAAAAgoywE9OztbpaWlSktL0/Tp073tLpdL8+fP17p167RkyRKfc91utx588EH16dNHGzdu1LnnnitJmjJliubNm6dnnnlGSUlJio6O9s7p27evJk6caHXZAAAAgJEs70HPy8uTw+FQUlJSs/b4+Hg5nU7l5eXJ7Xb7nLtv3z79+9//1nXXXecN5x4zZ86U2+3W3/72N6tLBAAAALoNSwG9trZWZWVlcrlcstvtzfpsNptiY2NVU1OjyspKn/PfeecdSdLIkSNb9MXGxjYb40tTU1Or4R8AAADojixtcfEE79DQUJ/9TqdTklRRUaEhQ4a06K+oqGh1flBQkPr37+8d49HY2KhHHnlE27dvV01Njex2u8aPH6977rlHw4cPb9e6S0pK2jXOXwJ9/rNRQ0ODJGrrL9TXv6iv/1Fj/6K+/kV9/cvE+loK6HV1dZJO7wv3xdNeW1vb6fnfnHvkyBF99NFHWrx4sfr37689e/Zow4YNKioq0ubNmzVs2LBOXQsAAABgAksB3WazSdIZt5l4xnVm/tfnrlixQj169NDo0aO9bfHx8brgggu0bNkypaen6/HHHz/jugPzKsaDAT7/2c3zqZfa+gf19S/q63/U2L+or39RX//yV32Lioo6PdfSHvR+/fpJOv2qRV88T8g94zoz/5xzzvH+eezYsc3CuceNN96oPn366M0332z/4gEAAAADWQroERERstlsOnz4sM9+z48KDR061Ge/Z1+6r/lffPGFamtrFRkZecZ19OjRQ8HBwd4PBAAAAEB3ZSmgOxwOuVwulZSUqLGxsVnfyZMnVVxcrPDwcIWFhfmcf9lll0k6/Uui3/TWW29JkveJeUVFhXJzc7V///4WY+vr61VdXd3ql1UBAACA7sLye9ATEhLU2NioTZs2NWvftm2bjh49qsTERG9beXl5s7eyREdH66KLLlJBQUGzp+hut1vr169Xr169NGXKFEnSZ599pvvuu08PP/ywvvrqq2bneuqpp3Tq1Cldc801Vi8HAAAACCjLvySanJys/Px8rVy5UlVVVRoxYoTKysqUlZWl6OhozZ492zt20qRJGjZsmAoKCrxtaWlpmjVrllJSUvTzn/9c/fv3V35+vvbs2aM777zTu8Vl5MiRSkhI0HPPPacZM2bo+uuvl91u1xtvvKEdO3YoKipK8+bNs3o5AAAAQEBZDuh2u11ZWVlavXq1CgoKlJOTo4EDByo5OVkLFy6Uw+Foc/4ll1yinJwcPfHEE8rIyNCJEyd0/vnn67HHHvM+PfdYvny5Lr30UuXm5io9PV0NDQ2KiIjQ3Llzddttt7X6ZVQAAACgu7Ac0KXTPyqUmpqq1NTUNseVlpb6bL/44ou1bt26M56nZ8+emjZtmqZNm9apdQIAAACms7wHHQAAAEDXIaADAAAABiGgAwAAAAYhoAMAAAAGIaADAAAABiGgAwAAAAYhoAMAAAAGIaADAAAABiGgAwAAAAYhoAMAAAAGIaADAAAABiGgAwAAAAYhoAMAAAAGIaADAAAABiGgAwAAAAYhoAMAAAAGIaADAAAABiGgAwAAAAYhoAMAAAAGIaADAAAABiGgAwAAAAYhoAMAAAAGIaADAAAABiGgAwAAAAYhoAMAAAAGIaADAAAABiGgAwAAAAYhoAMAAAAGIaADAAAABiGgAwAAAAYhoAMAAAAGIaADAAAABiGgAwAAAAYhoAMAAAAG6dUVBzl27JgyMjK0c+dOVVdXKzg4WBMmTNCiRYs0aNCgM84vLi7WmjVrVFxcrC+//FJDhw7VtGnTNH36dPXo0fwzRHl5udLT07Vnzx7V1dUpLCxM119/vebMmSO73d4VlwMAAAAEjOWAXl9frxkzZqi8vFwpKSmKiYnRoUOHlJmZqcLCQuXm5iokJKTV+W+++aZuu+02OZ1O3XHHHQoODtYLL7yghx56SIcOHdKyZcu8Y8vKypScnCy73a6bb75ZTqdThYWFysjI0L59+7R27VqrlwMAAAAElOWAnp2drdLSUqWlpWn69OnedpfLpfnz52vdunVasmSJz7lut1sPPvig+vTpo40bN+rcc8+VJE2ZMkXz5s3TM888o6SkJEVHR0uSVqxYoYaGBuXk5CgqKkqSNHnyZAUFBSk7O1svv/yy4uLirF4SAAAAEDCW96Dn5eXJ4XAoKSmpWXt8fLycTqfy8vLkdrt9zt23b5/+/e9/67rrrvOGc4+ZM2fK7Xbrb3/7myTpyJEjev3113X55Zd7w/nXx0rStm3brF4OAAAAEFCWAnptba3Kysrkcrla7P+22WyKjY1VTU2NKisrfc5/5513JEkjR45s0RcbG9tszLvvviu32+1z7NChQxUcHOwdCwAAAHRXlra4eIJ3aGioz36n0ylJqqio0JAhQ1r0V1RUtDo/KChI/fv3945pa6yn/cCBAzpx4oR69+7d5rpLSkra7Pe3QJ//bNTQ0CCJ2voL9fUv6ut/1Ni/qK9/UV//MrG+lp6g19XVSZL69u3rs9/TXltb2+n5nrntGet2u73jTNOnl02S1Pf//ycAAADgi6Un6Dbb6bDZ2h7zb47rzHzPGKvn+jqXy3XGMV1txiWf66/vfaF5P46Sy/X9b/38ZzvPp95A/G/7XUB9/Yv6+h819i/q61/U17/8Vd+ioqJOz7UU0Pv16yfp9KsWffE8zfaM68z8c845p91jbTabgoKC2rn6b9eNFwfrxouDCecAAABok6UtLhEREbLZbDp8+LDP/qqqKkmnv8Tpi2dfuq/5X3zxhWpraxUZGXnGsW63Wx9//LHCw8PVq1eX/PYSAAAAEBCWArrD4ZDL5VJJSYkaGxub9Z08eVLFxcUKDw9XWFiYz/mXXXaZpNO/JPpNb731liRp9OjRkk6/1aVnz556++23W4wtLS3V8ePHvWMBAACA7srye9ATEhLU2NioTZs2NWvftm2bjh49qsTERG9beXm5920skhQdHa2LLrpIBQUFzZ6Mu91urV+/Xr169dKUKVMkScHBwYqLi9PevXv13nvvNTvX+vXrJanFu9gBAACA7sbyfpDk5GTl5+dr5cqVqqqq0ogRI1RWVqasrCxFR0dr9uzZ3rGTJk3SsGHDVFBQ4G1LS0vTrFmzlJKSop///Ofq37+/8vPztWfPHt15553eLS6SdO+992rv3r2aPXu2brnlFg0ePFi7du3S9u3blZSUpDFjxli9HAAAACCgLAd0u92urKwsrV69WgUFBcrJydHAgQOVnJyshQsXyuFwtDn/kksuUU5Ojp544gllZGToxIkTOv/88/XYY495n557REZGavPmzVq1apUyMzNVV1enyMhILV26VLNmzbJ6KQAAAEDAdck3KoOCgpSamqrU1NQ2x5WWlvpsv/jii7Vu3bp2nSsyMlKrVq3q8BoBAACA7sDyHnQAAAAAXYeADgAAABiEgA4AAAAYhIAOAAAAGISADgAAABiEgA4AAAAYhIAOAAAAGISADgAAABiEgA4AAAAYhIAOAAAAGMTmdrvdgV7Et6WoqCjQSwAAAMB3yKhRozo8hyfoAAAAgEG+U0/QAQAAANPxBB0AAAAwCAEdAAAAMAgBHQAAADAIAR0AAAAwCAEdAAAAMAgBHQAAADBIr0Av4Gx37NgxZWRkaOfOnaqurlZwcLAmTJigRYsWadCgQYFeXrexZMkSPffcc632L126VL/4xS8kSV9++aWefPJJ5efn6+OPP1a/fv00duxY3XXXXTrvvPO+nQUbrqmpSY8//rgyMzM1ZswYZWdntxjTkTqePHlS2dnZ2rJliz788EP16dNHl1xyiRYsWKARI0Z8S1dljjPVNyMjQ6tXr251/qxZs3Tfffd5/0x9/+vIkSNau3atdu/erU8++UTf+973NHLkSC1YsEDf//73m43lHu649taXe7jzysrKtHbtWr399tuqqanRoEGDFBsbq7lz5yoqKso7jvu3c9pT3+5w//IedD+qr69XcnKyysvLlZKSopiYGB06dEiZmZkaOHCgcnNzFRISEuhldguegJ6WlqYBAwa06He5XBo6dKhOnTqlW265RW+88YYSExM1btw4VVdXKysrS6dOndJf/vIXDR06NABXYI6DBw/qV7/6lf7973+rvr5eY8eObREgO1rHX//619qyZYt+8pOf6Oqrr9axY8f09NNPq7q6Wk8//bQuvfTSb/syA6Y99fX8x2HBggUaPnx4i2Ocd955io6O9v6Z+p525MgRTZ06VUeOHNFNN92k6OhoHTp0SE8//bS++uor5eTk6OKLL5bEPdwZHakv93DnvPHGG5ozZ45CQkKUkpIip9OpgwcP6plnntGJEye0fv16jRo1ivu3k9pb325x/7rhN2vXrnVHRUW5N2zY0Kz9hRdecEdFRbkfffTRAK2s+0lNTXVHRUW5Kyoq2hyXl5fnjoqKcq9cubJZ+7/+9S/3hRde6J4/f74/l2m8zz//3B0bG+u+4YYb3OXl5e6oqCj3jBkzWozrSB3/+c9/uqOiotx33nlns7Eff/yx+5JLLnEnJCT45VpM1N76PvHEE+6oqCh3YWHhGY9Jff/rgQcecEdFRblfeOGFZu07d+50R0VFuRcsWOBt4x7uuI7Ul3u4c37605+6R44c2eK/ZS+++KI7KirK/ctf/tLtdnP/dlZ769sd7l/2oPtRXl6eHA6HkpKSmrXHx8fL6XQqLy9Pbv4Co0vl5eVJOv3XU18XExOjSy+9VK+88oqOHz8eiKUZ4cSJE5o8ebL+8pe/tNgO8HUdqWNrY0NDQ/WTn/xE7733nj744IOuvAxjtbe+HUF9/2vQoEH66U9/qvj4+GbtV1xxhWw2m95//31vG/dwx3Wkvh1BfU87deqUEhMTdd999ykiIqJZ3w9+8ANJ0n/+8x9J3L+d0ZH6dkSg6ktA95Pa2lqVlZXJ5XLJbrc367PZbIqNjVVNTY0qKysDtMLu7cSJE/rqq69atBcXF8vpdGrw4MEt+i655BKdOHFC+/bt+zaWaKTvfe97evDBB/U///M/bY7rSB2Li4vVo0cPxcTE+BzrGfNd0N76ftPJkyfV1NTks4/6/tf8+fP1u9/9TjabrVl7bW2t3G63+vfv723jHu64jtT3m7iHz6xHjx66+eab9bOf/axFX2lpqSR590hz/3ZcR+r7TSbevwR0P/EE79DQUJ/9TqdTklRRUfGtrelskJOTo2uvvVaxsbGKiYlRYmKiXnnlFUmn/yPy+eefn7HmfChqW0frWFlZqYEDB7b4IPr1sdznvhUUFOiGG25QbGysRowYoeuuu05//etfm42hvme2adMmSdLEiRMlcQ93tW/W9+u4hzvv2LFjqqys1Pbt27V48WJFRkZq4cKF3L9dpLX6fp3J9y9vcfGTuro6SVLfvn199nvaa2trv7U1nQ12796tmTNnKiIiQh988IH++Mc/at68efrd736n0aNHS2q95g6HQxI1P5Mz3bvfrGNdXZ2Cg4PbHOs5JprbtWuXUlJSdP7556uqqkpPPfWUli5dqiNHjui2226TRH3PZNeuXfrDH/6gCy+8UCkpKZK4h7uSr/p+s597uHPGjBkj6fTfqickJOjee+9VSEiIdxsG9681rdX360y+fwnofuL5K8Iz7TH/5l8lwrebb75Z//u//6tx48Z5P8VeddVVuuqqqzRlyhQ9+uij2rJliyRq3lXaW0ebzcZ3KTrI88TmkksuabZtYOLEibruuuuUkZGhqVOnKjg4mPq2YevWrVq2bJmcTqfWrl3bYmsR97A1bdWXe9i6p59+WsePH9f777+vDRs2aM+ePXriiSf0ve99TxL3r1Wt1ffiiy/uFvcvW1z8pF+/fpJOv2rRF8+nLc84tO3CCy/UlVde2eKvmIYPH65x48bp008/1RdffCGJmlvV0Xs3KCjojGPPOeecrl5mtzZ06FD96Ec/arGnd+DAgZo4caK+/PJLvf3225Kob2vWrFmj1NRURUVFaePGjQoLC/P2cQ9b11Z9Je7hrjBu3DjFx8fr9ttv17PPPqsvvvhCd911l4KCgiRx/1rVWn1PnTrVLe5fArqfREREyGaz6fDhwz77q6qqJOk7/07uruB5L3pdXZ0GDhyojz/+2Oc4z349at62oKCgDtUxMjJSR48e1ZdfftliLPd5x339fpaory/Lly/XE088oWuuuUYbNmzQueee26yfe9iaM9X3TLiHOy4iIkKjR4/Whx9+qJqaGu7fLvb1+n700UdtjjXl/iWg+4nD4ZDL5VJJSYkaGxub9Z08eVLFxcUKDw9v8VQCLdXW1iovL8/7ZdBv+vDDDyWd/kLuZZddpk8//dT7f5qvKyoqUp8+fXx+ExvNdaSOl112mU6dOqV33nmnxdi33npLkjRq1Cj/LrgbOXHihHbs2KH8/Hyf/Z772fPlI+rb3Jo1a/T0008rOTlZ6enpre7T5R7unPbUl3u4cw4cOKAJEyZoyZIlPvs9AfDkyZPcv53Q3vp++eWX3eL+JaD7UUJCghobG73fgPfYtm2bjh49qsTExACtrHux2+166KGHlJqaqurq6mZ9hYWFeueddzRy5Eg5nU4lJCRIkrKyspqN+8c//qH9+/dr0qRJrf4HHf/VkTpOmTJFNptN69evbzb24MGDevXVVzVu3DgNGTLkW1l3d9C7d2+tXr1aqampLd4rffDgQb344otyOp2KjY2VRH2/rrCwUBkZGbr22mv1m9/8Rj16tP6fMO7hjmtvfbmHO+f73/++mpqa9MILL7R468dHH32kf/7znxowYIDOO+887t9OaG99hw8f3i3uX5ubbxb4TVNTk2bMmKF9+/YpJSVFI0aMUFlZmbKysnT++ecrJyfH+w1gtG3Lli369a9/rbCwMN10000699xzdeDAAW3cuFF2u13Z2dlyuVySpDvuuEMvvfSSEhIS9IMf/EBVVVXKzMxUUFCQcnNzNWjQoABfTeB88MEHzX5Q4c4779Tw4cO1YMECb9uECRPUt2/fDtXxkUce0Z///Gf9+Mc/1sSJE/XZZ58pMzNT9fX12rRpky644IJv9ToDpb31LSoq0ty5c9WvXz+lpKRoyJAh+vDDD/XMM8+ooaFBf/jDH/SjH/3IO4f6npaYmKj9+/frN7/5TatvVfDcv1LH/l1AjTtW39dee417uBO2b9+uX/3qVwoJCdH06dMVERGhyspKbdiwQZ999pkee+wxTZ48WRL3b2e0t77d4f4loPtZXV2dVq9erYKCAn366acaOHCgrr76ai1cuLDNH31AS6+//rrWr1+vkpISff755xowYIB++MMfat68eYqMjPSOa2pq0p/+9Cdt3bpVVVVV6t+/v370ox/prrvu8vmjD98lGRkZWr16dZtjdu7cqYiIiA7V0e12KycnRzk5OTp06JAcDofGjh2rRYsW6fzzz/fnJRmlI/V999139dRTT+ndd99VTU2N+vfvrzFjxuiXv/ylLrroomZzqO9pF1544RnHeOordezfBdS44/XlHu6cffv26Y9//KP+9a9/qbq6WkFBQRoxYoRuueUW7y9eSty/ndXe+pp+/xLQAQAAAIOwBx0AAAAwCAEdAAAAMAgBHQAAADAIAR0AAAAwCAEdAAAAMAgBHQAAADAIAR0AAAAwCAEdAAAAMAgBHQAAADAIAR0AAAAwCAEdAAAAMAgBHQAAADAIAR0AAAAwCAEdAAAAMAgBHQAAADAIAR0AAAAwCAEdAAAAMMj/B0/CTXk7l1h7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 244,
       "width": 372
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [0] + [x[0] for x in random_search.val_metrics]\n",
    "y = [0] + [x[1] for x in random_search.val_metrics]\n",
    "plt.step(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed value 0.002057566238721228 to c8b5b57561.\n",
      "Transformed value 94 to [94, 94, 94, 94, 94].\n",
      "Run with parameters (0.0004, c8b5b57561, [94, 94, 94, 94, 94], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, c8b5b57561, [94, 94, 94, 94, 94], 10, 20, 0.2, False) completed, best_val_loss: 2.152656316757202, best_val_metric: 0.38071065989847713, best_hidden_layer_sizes: [94, 94, 94, 94, 94]\n",
      "Best overall combination: (0.0004, c8b5b57561, [94, 94, 94, 94, 94], 10, 20, 0.2, False), val_metric: 0.38071065989847713\n",
      "Transformed value 0.0002216839724327367 to 2efac85a7b.\n",
      "Transformed value 53 to [53, 53, 53, 53, 53].\n",
      "Run with parameters (0.0004, 2efac85a7b, [53, 53, 53, 53, 53], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, 2efac85a7b, [53, 53, 53, 53, 53], 10, 20, 0.2, False) completed, best_val_loss: 1.9773730039596558, best_val_metric: 0.3248730964467005, best_hidden_layer_sizes: [53, 53, 53, 53, 53]\n",
      "Best overall combination: (0.0004, c8b5b57561, [94, 94, 94, 94, 94], 10, 20, 0.2, False), val_metric: 0.38071065989847713\n",
      "Transformed value 0.00013559501794891942 to 6d662d05a1.\n",
      "Transformed value 63 to [63, 63, 63, 63, 63].\n",
      "Run with parameters (0.0004, 6d662d05a1, [63, 63, 63, 63, 63], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, 6d662d05a1, [63, 63, 63, 63, 63], 10, 20, 0.2, False) completed, best_val_loss: 2.113967180252075, best_val_metric: 0.3299492385786802, best_hidden_layer_sizes: [63, 63, 63, 63, 63]\n",
      "Best overall combination: (0.0004, c8b5b57561, [94, 94, 94, 94, 94], 10, 20, 0.2, False), val_metric: 0.38071065989847713\n",
      "Transformed value 8.530397781957828e-05 to 85b8b88d92.\n",
      "Transformed value 24 to [24, 24, 24, 24, 24].\n",
      "Run with parameters (0.0004, 85b8b88d92, [24, 24, 24, 24, 24], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, 85b8b88d92, [24, 24, 24, 24, 24], 10, 20, 0.2, False) completed, best_val_loss: 1.9083201885223389, best_val_metric: 0.3401015228426396, best_hidden_layer_sizes: [24, 24, 24, 24, 24]\n",
      "Best overall combination: (0.0004, c8b5b57561, [94, 94, 94, 94, 94], 10, 20, 0.2, False), val_metric: 0.38071065989847713\n",
      "Transformed value 1.0356324560593474e-05 to 8aeebf5d0f.\n",
      "Transformed value 20 to [20, 20, 20, 20, 20].\n",
      "Run with parameters (0.0004, 8aeebf5d0f, [20, 20, 20, 20, 20], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, 8aeebf5d0f, [20, 20, 20, 20, 20], 10, 20, 0.2, False) completed, best_val_loss: 1.9384976625442505, best_val_metric: 0.3350253807106599, best_hidden_layer_sizes: [20, 20, 20, 20, 20]\n",
      "Best overall combination: (0.0004, c8b5b57561, [94, 94, 94, 94, 94], 10, 20, 0.2, False), val_metric: 0.38071065989847713\n",
      "Transformed value 0.0011751412148038863 to 5a0cb15375.\n",
      "Transformed value 59 to [59, 59, 59, 59, 59].\n",
      "Run with parameters (0.0004, 5a0cb15375, [59, 59, 59, 59, 59], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, 5a0cb15375, [59, 59, 59, 59, 59], 10, 20, 0.2, False) completed, best_val_loss: 1.9852824211120605, best_val_metric: 0.34517766497461927, best_hidden_layer_sizes: [59, 59, 59, 59, 59]\n",
      "Best overall combination: (0.0004, c8b5b57561, [94, 94, 94, 94, 94], 10, 20, 0.2, False), val_metric: 0.38071065989847713\n",
      "Transformed value 0.0003642426667380799 to 0483bcd68e.\n",
      "Transformed value 17 to [17, 17, 17, 17, 17].\n",
      "Run with parameters (0.0004, 0483bcd68e, [17, 17, 17, 17, 17], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, 0483bcd68e, [17, 17, 17, 17, 17], 10, 20, 0.2, False) completed, best_val_loss: 1.8622817993164062, best_val_metric: 0.39086294416243655, best_hidden_layer_sizes: [17, 17, 17, 17, 17]\n",
      "Best overall combination: (0.0004, 0483bcd68e, [17, 17, 17, 17, 17], 10, 20, 0.2, False), val_metric: 0.39086294416243655\n",
      "Transformed value 9.837279996682278e-05 to dfe86afe9c.\n",
      "Transformed value 39 to [39, 39, 39, 39, 39].\n",
      "Run with parameters (0.0004, dfe86afe9c, [39, 39, 39, 39, 39], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, dfe86afe9c, [39, 39, 39, 39, 39], 10, 20, 0.2, False) completed, best_val_loss: 1.896994709968567, best_val_metric: 0.350253807106599, best_hidden_layer_sizes: [39, 39, 39, 39, 39]\n",
      "Best overall combination: (0.0004, 0483bcd68e, [17, 17, 17, 17, 17], 10, 20, 0.2, False), val_metric: 0.39086294416243655\n",
      "Transformed value 0.0030450392446942504 to 8151ddda73.\n",
      "Transformed value 33 to [33, 33, 33, 33, 33].\n",
      "Run with parameters (0.0004, 8151ddda73, [33, 33, 33, 33, 33], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, 8151ddda73, [33, 33, 33, 33, 33], 10, 20, 0.2, False) completed, best_val_loss: 1.913184404373169, best_val_metric: 0.34517766497461927, best_hidden_layer_sizes: [33, 33, 33, 33, 33]\n",
      "Best overall combination: (0.0004, 0483bcd68e, [17, 17, 17, 17, 17], 10, 20, 0.2, False), val_metric: 0.39086294416243655\n",
      "Transformed value 0.001105022689513515 to d0505c8f54.\n",
      "Transformed value 30 to [30, 30, 30, 30, 30].\n",
      "Run with parameters (0.0004, d0505c8f54, [30, 30, 30, 30, 30], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, d0505c8f54, [30, 30, 30, 30, 30], 10, 20, 0.2, False) completed, best_val_loss: 2.0159218311309814, best_val_metric: 0.3604060913705584, best_hidden_layer_sizes: [30, 30, 30, 30, 30]\n",
      "Best overall combination: (0.0004, 0483bcd68e, [17, 17, 17, 17, 17], 10, 20, 0.2, False), val_metric: 0.39086294416243655\n",
      "Transformed value 0.0006481770319938059 to 24b0d584bf.\n",
      "Transformed value 44 to [44, 44, 44, 44, 44].\n",
      "Run with parameters (0.0004, 24b0d584bf, [44, 44, 44, 44, 44], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, 24b0d584bf, [44, 44, 44, 44, 44], 10, 20, 0.2, False) completed, best_val_loss: 1.8860324621200562, best_val_metric: 0.38071065989847713, best_hidden_layer_sizes: [44, 44, 44, 44, 44]\n",
      "Best overall combination: (0.0004, 0483bcd68e, [17, 17, 17, 17, 17], 10, 20, 0.2, False), val_metric: 0.39086294416243655\n",
      "Transformed value 0.00043945261675633384 to 159a54e0a0.\n",
      "Transformed value 40 to [40, 40, 40, 40, 40].\n",
      "Run with parameters (0.0004, 159a54e0a0, [40, 40, 40, 40, 40], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, 159a54e0a0, [40, 40, 40, 40, 40], 10, 20, 0.2, False) completed, best_val_loss: 1.9010725021362305, best_val_metric: 0.38578680203045684, best_hidden_layer_sizes: [40, 40, 40, 40, 40]\n",
      "Best overall combination: (0.0004, 0483bcd68e, [17, 17, 17, 17, 17], 10, 20, 0.2, False), val_metric: 0.39086294416243655\n",
      "Transformed value 0.0001386898411290395 to 4f7a18c4ea.\n",
      "Transformed value 23 to [23, 23, 23, 23, 23].\n",
      "Run with parameters (0.0004, 4f7a18c4ea, [23, 23, 23, 23, 23], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, 4f7a18c4ea, [23, 23, 23, 23, 23], 10, 20, 0.2, False) completed, best_val_loss: 1.8640389442443848, best_val_metric: 0.38578680203045684, best_hidden_layer_sizes: [23, 23, 23, 23, 23]\n",
      "Best overall combination: (0.0004, 0483bcd68e, [17, 17, 17, 17, 17], 10, 20, 0.2, False), val_metric: 0.39086294416243655\n",
      "Transformed value 8.730009328671003e-05 to 77dfa746c0.\n",
      "Transformed value 28 to [28, 28, 28, 28, 28].\n",
      "Run with parameters (0.0004, 77dfa746c0, [28, 28, 28, 28, 28], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, 77dfa746c0, [28, 28, 28, 28, 28], 10, 20, 0.2, False) completed, best_val_loss: 2.061760425567627, best_val_metric: 0.3401015228426396, best_hidden_layer_sizes: [28, 28, 28, 28, 28]\n",
      "Best overall combination: (0.0004, 0483bcd68e, [17, 17, 17, 17, 17], 10, 20, 0.2, False), val_metric: 0.39086294416243655\n",
      "Transformed value 7.379161190573105e-05 to e2114f244d.\n",
      "Transformed value 67 to [67, 67, 67, 67, 67].\n",
      "Run with parameters (0.0004, e2114f244d, [67, 67, 67, 67, 67], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, e2114f244d, [67, 67, 67, 67, 67], 10, 20, 0.2, False) completed, best_val_loss: 1.9266518354415894, best_val_metric: 0.3248730964467005, best_hidden_layer_sizes: [67, 67, 67, 67, 67]\n",
      "Best overall combination: (0.0004, 0483bcd68e, [17, 17, 17, 17, 17], 10, 20, 0.2, False), val_metric: 0.39086294416243655\n",
      "Transformed value 0.00010899782020833731 to ffed7e1e3f.\n",
      "Transformed value 54 to [54, 54, 54, 54, 54].\n",
      "Run with parameters (0.0004, ffed7e1e3f, [54, 54, 54, 54, 54], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, ffed7e1e3f, [54, 54, 54, 54, 54], 10, 20, 0.2, False) completed, best_val_loss: 2.0072922706604004, best_val_metric: 0.3401015228426396, best_hidden_layer_sizes: [54, 54, 54, 54, 54]\n",
      "Best overall combination: (0.0004, 0483bcd68e, [17, 17, 17, 17, 17], 10, 20, 0.2, False), val_metric: 0.39086294416243655\n",
      "Transformed value 3.0966853909774265e-05 to e749a2d075.\n",
      "Transformed value 94 to [94, 94, 94, 94, 94].\n",
      "Run with parameters (0.0004, e749a2d075, [94, 94, 94, 94, 94], 10, 20, 0.2, False) started...\n",
      "Run with parameters (0.0004, e749a2d075, [94, 94, 94, 94, 94], 10, 20, 0.2, False) completed, best_val_loss: 2.2023770809173584, best_val_metric: 0.3299492385786802, best_hidden_layer_sizes: [94, 94, 94, 94, 94]\n",
      "Best overall combination: (0.0004, 0483bcd68e, [17, 17, 17, 17, 17], 10, 20, 0.2, False), val_metric: 0.39086294416243655\n",
      "Transformed value 0.0004464463790612888 to a530f51b50.\n",
      "Transformed value 86 to [86, 86, 86, 86, 86].\n",
      "Run with parameters (0.0004, a530f51b50, [86, 86, 86, 86, 86], 10, 20, 0.2, False) started...\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomSearch()\n",
    "random_search.run(\n",
    "    train_fn_conv, x=cifar10.X_train_norm, y=cifar10.y_train, validation_data=(cifar10.X_test_norm, cifar10.y_test), \n",
    "    learning_rate=0.0004, schedule=PowerRange(-5, -2.5, lambda x: Schedule([StaticEpoch(x, 'l1')] * 20)), \n",
    "    layer_sizes=UniformRange(10, 100, lambda x: [x] * 5, integer=True),\n",
    "    output_neurons=10, min_new_neurons=20, growth_percentage=0.2, use_static_graph=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0c734bc2e0>]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 244,
       "width": 372
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [0] + [x[0] for x in random_search.val_metrics]\n",
    "y = [0] + [x[1] for x in random_search.val_metrics]\n",
    "plt.step(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: 39.4 s, best val metric 0.269, [(1, 0.269, 0.269, 2.7, 0.03, [20, 20, 20, 20, 20]), (1, 0.269, 0.269, 2.7, 0.03, [20, 20, 20, 20, 20]), (1, 0.2487, 0.2487, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.2487, 0.2487, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.2487, 0.2487, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.2437, 0.2437, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.2386, 0.2386, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.2335, 0.2335, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.2183, 0.2183, 3.0, 0.1, [20, 20, 20, 20, 20]), (1, 0.203, 0.203, 3.0, -0.02, [20, 20, 20, 20, 20])]\n",
      "Generation 1: 41.9 s, best val metric 0.335, [(2, 0.335, 0.335, 3.2, 0.03, [20, 20, 20, 20, 20]), (2, 0.335, 0.335, 3.2, 0.03, [20, 20, 20, 20, 20]), (2, 0.335, 0.335, 3.2, 0.03, [20, 20, 20, 20, 20]), (2, 0.335, 0.335, 3.2, 0.03, [20, 20, 20, 20, 20]), (2, 0.3249, 0.3249, 2.7, 0.03, [20, 20, 20, 20, 20]), (2, 0.3249, 0.3249, 2.7, 0.03, [20, 20, 20, 20, 20]), (2, 0.3249, 0.3249, 2.7, 0.03, [20, 20, 20, 20, 20]), (2, 0.2944, 0.2944, 3.4, 0.07, [20, 20, 20, 20, 20]), (2, 0.2893, 0.2893, 3.0, 0.1, [20, 20, 20, 20, 20]), (2, 0.2843, 0.2843, 3.3, 0.06, [20, 20, 20, 20, 20]), (2, 0.269, 0.269, 2.7, 0.03, [20, 20, 20, 20, 20])]\n",
      "Generation 2: 43.5 s, best val metric 0.3401, [(3, 0.3401, 0.3401, 3.3, -0.02, [20, 20, 20, 20, 20]), (3, 0.3401, 0.3401, 3.3, -0.02, [20, 20, 20, 20, 20]), (3, 0.335, 0.335, 3.2, 0.03, [20, 20, 20, 20, 20]), (3, 0.3299, 0.3299, 3.5, 0.01, [20, 20, 20, 20, 20]), (3, 0.3249, 0.3249, 3.2, 0.04, [20, 20, 20, 20, 20]), (3, 0.3096, 0.3096, 3.2, 0.03, [20, 20, 20, 20, 20]), (3, 0.3046, 0.3046, 3.3, 0.05, [20, 20, 20, 20, 20]), (3, 0.3046, 0.3046, 2.6, 0.03, [20, 20, 20, 20, 20]), (3, 0.3046, 0.3046, 2.6, 0.03, [20, 20, 20, 20, 20]), (3, 0.2995, 0.2995, 3.4, 0.12, [20, 20, 20, 20, 20]), (3, 0.2944, 0.2944, 2.7, 0.03, [20, 20, 20, 20, 20])]\n",
      "Generation 3: 44.7 s, best val metric 0.3604, [(4, 0.3604, 0.3604, 3.2, 0.04, [20, 20, 20, 20, 20]), (4, 0.3553, 0.3553, 3.4, 0.12, [20, 20, 20, 20, 20]), (4, 0.3503, 0.3503, 3.0, -0.03, [20, 20, 20, 20, 20]), (4, 0.3401, 0.3401, 3.3, -0.02, [20, 20, 20, 20, 20]), (4, 0.335, 0.335, 3.6, -0.05, [20, 20, 20, 20, 20]), (4, 0.335, 0.335, 3.6, -0.05, [20, 20, 20, 20, 20]), (4, 0.335, 0.335, 3.6, -0.05, [20, 20, 20, 20, 20]), (4, 0.3299, 0.3299, 3.5, 0.01, [20, 20, 20, 20, 20]), (4, 0.3299, 0.3299, 3.5, 0.01, [20, 20, 20, 20, 20]), (4, 0.3249, 0.3249, 2.9, 0.1, [20, 20, 20, 20, 20]), (4, 0.3147, 0.3147, 3.3, -0.02, [20, 20, 20, 20, 20])]\n",
      "Generation 4: 46.2 s, best val metric 0.3858, [(5, 0.3858, 0.3858, 3.4, 0.12, [20, 20, 20, 20, 20]), (5, 0.3756, 0.3756, 2.9, 0.1, [20, 20, 20, 20, 20]), (5, 0.3756, 0.3756, 2.9, 0.1, [20, 20, 20, 20, 20]), (5, 0.3604, 0.3604, 3.2, 0.04, [20, 20, 20, 20, 20]), (5, 0.3401, 0.3401, 3.3, 0.04, [20, 20, 20, 20, 20]), (5, 0.3401, 0.3401, 3.3, 0.04, [20, 20, 20, 20, 20]), (5, 0.335, 0.335, 3.3, -0.02, [20, 20, 20, 20, 20]), (5, 0.335, 0.335, 3.6, -0.05, [20, 20, 20, 20, 20]), (5, 0.335, 0.335, 4.3, -0.14, [32, 40, 40, 40, 35]), (5, 0.3198, 0.3198, 2.5, -0.03, [20, 20, 20, 20, 20]), (5, 0.2995, 0.2995, 3.5, 0.01, [20, 20, 20, 20, 20])]\n",
      "Generation 5: 47.5 s, best val metric 0.3959, [(6, 0.3959, 0.3959, 3.4, 0.05, [20, 20, 20, 20, 20]), (6, 0.3959, 0.3959, 3.4, 0.05, [20, 20, 20, 20, 20]), (6, 0.3959, 0.3959, 3.4, 0.05, [20, 20, 20, 20, 20]), (6, 0.3858, 0.3858, 3.4, 0.12, [20, 20, 20, 20, 20]), (6, 0.3604, 0.3604, 3.4, 0.12, [20, 20, 20, 20, 20]), (6, 0.3604, 0.3604, 3.1, 0.02, [20, 20, 20, 20, 20]), (6, 0.3553, 0.3553, 3.5, -0.03, [20, 20, 20, 20, 20]), (6, 0.3553, 0.3553, 3.5, -0.03, [20, 20, 20, 20, 20]), (6, 0.3452, 0.3452, 3.0, 0.05, [20, 20, 20, 20, 20]), (6, 0.3401, 0.3401, 2.8, -0.05, [20, 20, 20, 20, 20]), (6, 0.3299, 0.3299, 3.3, 0.04, [20, 20, 20, 20, 20])]\n",
      "Generation 6: 44.7 s, best val metric 0.401, [(7, 0.401, 0.401, 3.7, 0.02, [20, 26, 20, 22, 20]), (7, 0.401, 0.401, 3.7, 0.02, [20, 26, 20, 22, 20]), (7, 0.3959, 0.3959, 3.4, 0.05, [20, 20, 20, 20, 20]), (7, 0.3756, 0.3756, 3.4, 0.12, [20, 20, 20, 20, 20]), (7, 0.3756, 0.3756, 3.2, -0.0, [20, 20, 20, 20, 20]), (7, 0.3756, 0.3756, 2.9, 0.0, [20, 20, 20, 20, 20]), (7, 0.3401, 0.3401, 3.4, 0.0, [20, 20, 20, 20, 20]), (7, 0.3401, 0.3401, 3.1, 0.02, [20, 20, 20, 20, 20]), (7, 0.3401, 0.3401, 3.4, 0.0, [20, 20, 20, 20, 20]), (7, 0.3401, 0.3401, 3.4, 0.0, [20, 20, 20, 20, 20]), (7, 0.3299, 0.3299, 3.2, 0.05, [20, 20, 20, 20, 20])]\n",
      "Generation 7: 46.0 s, best val metric 0.401, [(8, 0.401, 0.401, 3.7, 0.02, [20, 26, 20, 22, 20]), (8, 0.3706, 0.3706, 3.1, 0.02, [20, 20, 20, 20, 20]), (8, 0.3706, 0.3706, 3.1, 0.02, [20, 20, 20, 20, 20]), (8, 0.3655, 0.3655, 3.4, 0.0, [20, 20, 20, 20, 20]), (8, 0.3655, 0.3655, 3.4, 0.0, [20, 20, 20, 20, 20]), (8, 0.3503, 0.3503, 3.4, 0.0, [20, 20, 20, 20, 20]), (8, 0.3503, 0.3503, 3.4, 0.0, [20, 20, 20, 20, 20]), (8, 0.3503, 0.3503, 3.4, 0.0, [20, 20, 20, 20, 20]), (8, 0.3452, 0.3452, 2.6, 0.09, [20, 20, 20, 20, 20]), (8, 0.3401, 0.3401, 3.4, 0.0, [20, 20, 20, 20, 20]), (8, 0.3249, 0.3249, 3.2, -0.0, [20, 20, 20, 20, 20])]\n",
      "Generation 8: 44.9 s, best val metric 0.401, [(9, 0.401, 0.401, 3.4, 0.04, [20, 25, 20, 20, 20]), (9, 0.401, 0.401, 3.4, 0.04, [20, 25, 20, 20, 20]), (9, 0.401, 0.401, 3.7, 0.02, [20, 26, 20, 22, 20]), (9, 0.3909, 0.3909, 3.2, -0.0, [20, 20, 20, 20, 20]), (9, 0.3909, 0.3909, 3.2, -0.0, [20, 20, 20, 20, 20]), (9, 0.3807, 0.3807, 3.4, 0.0, [20, 20, 20, 20, 20]), (9, 0.3807, 0.3807, 3.1, -0.01, [20, 20, 20, 20, 20]), (9, 0.3706, 0.3706, 3.5, -0.04, [20, 28, 20, 20, 21]), (9, 0.3553, 0.3553, 3.3, 0.08, [20, 20, 20, 20, 20]), (9, 0.3553, 0.3553, 3.7, 0.1, [20, 26, 20, 33, 25]), (9, 0.335, 0.335, 3.7, 0.02, [20, 32, 20, 30, 25])]\n",
      "Generation 9: 46.9 s, best val metric 0.401, [(10, 0.401, 0.401, 3.4, 0.04, [20, 25, 20, 20, 20]), (10, 0.3959, 0.3959, 3.7, -0.08, [20, 27, 20, 23, 26]), (10, 0.3959, 0.3959, 3.4, 0.04, [20, 20, 20, 20, 20]), (10, 0.3959, 0.3959, 3.4, 0.04, [20, 20, 20, 20, 20]), (10, 0.3959, 0.3959, 3.7, -0.08, [20, 27, 20, 23, 26]), (10, 0.3909, 0.3909, 3.2, -0.06, [20, 20, 20, 20, 20]), (10, 0.3858, 0.3858, 3.4, 0.0, [20, 26, 20, 20, 20]), (10, 0.3807, 0.3807, 2.6, 0.02, [20, 20, 20, 20, 20]), (10, 0.3807, 0.3807, 2.6, 0.02, [20, 20, 20, 20, 20]), (10, 0.3706, 0.3706, 3.2, -0.0, [20, 20, 20, 20, 20]), (10, 0.3553, 0.3553, 3.7, 0.02, [20, 26, 20, 23, 23])]\n",
      "Generation 10: 48.1 s, best val metric 0.401, [(11, 0.401, 0.3974, 3.4, 0.04, [20, 25, 20, 20, 20]), (11, 0.3706, 0.3673, 4.1, -0.03, [40, 45, 40, 40, 40]), (11, 0.3604, 0.3572, 3.4, 0.0, [20, 32, 20, 21, 20]), (11, 0.3604, 0.3572, 3.4, 0.0, [20, 32, 20, 21, 20]), (11, 0.3604, 0.3572, 3.4, 0.0, [20, 32, 20, 21, 20]), (11, 0.3503, 0.3471, 3.0, -0.0, [20, 20, 20, 20, 20]), (11, 0.3503, 0.3471, 3.2, -0.06, [20, 20, 20, 20, 20]), (11, 0.3452, 0.3421, 3.3, -0.02, [20, 20, 20, 20, 20]), (11, 0.3452, 0.3421, 3.3, -0.02, [20, 20, 20, 20, 20]), (11, 0.3401, 0.3371, 3.4, 0.04, [20, 20, 20, 20, 21]), (11, 0.3198, 0.3169, 3.2, -0.0, [20, 20, 20, 20, 21])]\n",
      "Generation 11: 48.7 s, best val metric 0.401, [(12, 0.401, 0.3946, 3.4, 0.04, [20, 25, 20, 20, 20]), (12, 0.3807, 0.3746, 3.4, 0.0, [20, 20, 20, 20, 20]), (12, 0.3807, 0.3746, 4.1, -0.01, [57, 65, 60, 60, 54]), (12, 0.3756, 0.3696, 3.8, 0.03, [20, 36, 25, 37, 30]), (12, 0.3756, 0.3696, 3.8, 0.03, [20, 36, 25, 37, 30]), (12, 0.3604, 0.3547, 3.5, 0.06, [20, 23, 20, 21, 20]), (12, 0.3604, 0.3547, 3.5, 0.06, [20, 23, 20, 21, 20]), (12, 0.3452, 0.3397, 3.7, -0.04, [20, 38, 26, 34, 23]), (12, 0.3452, 0.3397, 3.7, -0.04, [20, 38, 26, 34, 23]), (12, 0.3401, 0.3347, 3.0, -0.0, [20, 19, 19, 20, 20]), (12, 0.335, 0.3297, 3.5, 0.04, [20, 30, 20, 20, 20])]\n",
      "Generation 12: 51.3 s, best val metric 0.401, [(13, 0.401, 0.3897, 3.7, -0.03, [26, 31, 24, 37, 32]), (13, 0.401, 0.3897, 3.3, 0.02, [20, 22, 20, 21, 20]), (13, 0.401, 0.3897, 3.4, 0.04, [20, 25, 20, 20, 20]), (13, 0.3909, 0.3798, 3.0, -0.0, [20, 18, 18, 18, 20]), (13, 0.3909, 0.3798, 3.4, 0.04, [20, 25, 20, 21, 20]), (13, 0.3909, 0.3798, 3.5, -0.02, [32, 57, 40, 57, 40]), (13, 0.3706, 0.3601, 3.2, -0.11, [20, 21, 20, 20, 20]), (13, 0.3655, 0.3551, 2.9, 0.01, [20, 21, 20, 20, 20]), (13, 0.3553, 0.3453, 3.5, 0.06, [20, 26, 21, 22, 23]), (13, 0.3503, 0.3403, 3.2, -0.0, [20, 20, 20, 20, 21]), (13, 0.3401, 0.3305, 4.1, -0.01, [74, 85, 78, 80, 68])]\n",
      "Generation 13: 52.6 s, best val metric 0.401, [(14, 0.401, 0.381, 3.7, -0.03, [26, 31, 24, 37, 32]), (14, 0.3858, 0.3665, 3.4, 0.04, [20, 27, 20, 20, 20]), (14, 0.3858, 0.3665, 3.4, 0.04, [20, 27, 20, 20, 20]), (14, 0.3807, 0.3617, 3.6, -0.01, [20, 36, 22, 36, 33]), (14, 0.3807, 0.3617, 3.6, -0.01, [20, 36, 22, 36, 33]), (14, 0.3756, 0.3569, 2.9, 0.03, [20, 20, 20, 24, 21]), (14, 0.3756, 0.3569, 3.7, -0.01, [24, 46, 38, 41, 34]), (14, 0.3756, 0.3569, 3.7, -0.01, [24, 46, 38, 41, 34]), (14, 0.3655, 0.3473, 3.2, -0.0, [20, 20, 20, 20, 20]), (14, 0.3655, 0.3473, 3.4, 0.04, [20, 22, 20, 20, 20]), (14, 0.3503, 0.3328, 3.7, -0.03, [22, 44, 29, 47, 41])]\n",
      "Generation 14: 52.2 s, best val metric 0.401, [(15, 0.401, 0.3664, 3.7, -0.03, [26, 31, 24, 37, 32]), (15, 0.3909, 0.3571, 3.4, 0.04, [20, 25, 20, 20, 20]), (15, 0.3807, 0.3478, 3.9, -0.03, [33, 52, 41, 56, 50]), (15, 0.3807, 0.3478, 3.9, -0.03, [33, 52, 41, 56, 50]), (15, 0.3807, 0.3478, 3.9, -0.03, [33, 52, 41, 56, 50]), (15, 0.3807, 0.3478, 3.9, -0.03, [33, 52, 41, 56, 50]), (15, 0.3706, 0.3386, 3.7, -0.03, [22, 52, 36, 55, 45]), (15, 0.3706, 0.3386, 3.5, -0.0, [20, 29, 22, 33, 27]), (15, 0.3706, 0.3386, 3.7, -0.03, [22, 52, 36, 55, 45]), (15, 0.3553, 0.3247, 3.4, 0.04, [20, 22, 20, 20, 21]), (15, 0.3553, 0.3247, 3.8, -0.04, [30, 55, 39, 56, 45])]\n",
      "Generation 15: 56.7 s, best val metric 0.4162, [(16, 0.4162, 0.3557, 3.4, -0.08, [22, 34, 38, 50, 36]), (16, 0.4162, 0.3557, 3.4, -0.08, [22, 34, 38, 50, 36]), (16, 0.401, 0.3427, 3.7, -0.03, [26, 31, 24, 37, 32]), (16, 0.3807, 0.3254, 2.7, 0.06, [20, 21, 19, 25, 23]), (16, 0.3807, 0.3254, 2.7, 0.06, [20, 21, 19, 25, 23]), (16, 0.3756, 0.321, 3.0, -0.06, [20, 18, 20, 36, 24]), (16, 0.3756, 0.321, 4.1, 0.03, [37, 42, 40, 40, 41]), (16, 0.3756, 0.321, 4.1, 0.03, [37, 42, 40, 40, 41]), (16, 0.3706, 0.3167, 3.9, -0.03, [49, 71, 60, 76, 62]), (16, 0.3553, 0.3037, 3.4, 0.07, [22, 37, 25, 36, 41]), (16, 0.3503, 0.2993, 3.7, -0.03, [23, 69, 50, 61, 48])]\n",
      "Generation 16: 56.8 s, best val metric 0.4162, [(17, 0.4162, 0.3187, 2.7, 0.06, [20, 17, 17, 19, 21]), (17, 0.4162, 0.3187, 2.7, 0.06, [20, 17, 17, 19, 21]), (17, 0.4162, 0.3187, 3.4, -0.08, [22, 34, 38, 50, 36]), (17, 0.3909, 0.2993, 2.4, -0.08, [20, 14, 16, 15, 20]), (17, 0.3706, 0.2837, 3.7, -0.03, [35, 45, 37, 47, 40]), (17, 0.3706, 0.2837, 4.0, 0.03, [40, 41, 39, 45, 43]), (17, 0.3655, 0.2798, 3.9, 0.0, [33, 49, 44, 57, 47]), (17, 0.3655, 0.2798, 3.9, 0.0, [33, 49, 44, 57, 47]), (17, 0.3655, 0.2798, 3.4, -0.08, [20, 25, 21, 39, 37]), (17, 0.3604, 0.2759, 3.0, 0.1, [22, 25, 22, 41, 31]), (17, 0.3452, 0.2643, 3.7, -0.03, [32, 74, 48, 63, 54])]\n",
      "Generation 17: 57.0 s, best val metric 0.4162, [(18, 0.4162, 0.2684, 2.7, 0.06, [20, 17, 17, 19, 21]), (18, 0.3909, 0.252, 2.9, 0.0, [21, 19, 21, 34, 21]), (18, 0.3909, 0.252, 2.9, 0.0, [21, 19, 21, 34, 21]), (18, 0.3909, 0.252, 2.9, 0.0, [21, 19, 21, 34, 21]), (18, 0.3858, 0.2487, 3.1, 0.03, [20, 20, 20, 23, 30]), (18, 0.3807, 0.2455, 3.3, -0.1, [20, 14, 16, 21, 26]), (18, 0.3807, 0.2455, 3.3, -0.1, [20, 14, 16, 21, 26]), (18, 0.3807, 0.2455, 3.3, -0.1, [20, 14, 16, 21, 26]), (18, 0.3655, 0.2356, 3.9, 0.0, [46, 68, 61, 76, 58]), (18, 0.3655, 0.2356, 3.7, 0.02, [31, 37, 34, 39, 37]), (18, 0.335, 0.216, 4.0, -0.02, [39, 45, 41, 59, 57])]\n",
      "Generation 18: 53.4 s, best val metric 0.4162, [(19, 0.4162, 0.209, 2.7, 0.06, [20, 17, 17, 19, 21]), (19, 0.3909, 0.1962, 3.1, 0.03, [20, 16, 17, 18, 29]), (19, 0.3909, 0.1962, 3.1, 0.03, [20, 16, 17, 18, 29]), (19, 0.3909, 0.1962, 3.1, 0.03, [20, 16, 17, 18, 29]), (19, 0.3909, 0.1962, 2.9, 0.0, [20, 17, 19, 20, 20]), (19, 0.3909, 0.1962, 2.9, 0.0, [20, 17, 19, 20, 20]), (19, 0.3858, 0.1937, 3.3, -0.1, [19, 25, 23, 21, 25]), (19, 0.3706, 0.186, 2.9, 0.05, [20, 17, 16, 18, 21]), (19, 0.3706, 0.186, 3.1, -0.01, [20, 19, 20, 20, 20]), (19, 0.3655, 0.1835, 3.5, 0.05, [31, 59, 35, 55, 55]), (19, 0.3503, 0.1758, 3.6, -0.05, [45, 51, 51, 62, 55])]\n",
      "Interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "evolution = Evolution()\n",
    "evolution.run(x=cifar10.X_train_norm, y=cifar10.y_train, validation_data=(cifar10.X_test_norm, cifar10.y_test),\n",
    "              batch_size=32, layer_sizes=[20, 20, 20, 20, 20], output_neurons=10, learning_rate=0.0004, n_parents=5, strategy=[0.5, 0.05], \n",
    "              population_size=10, n_generations=50, tournament_size=3, n_introduced=2, age_penalty_period=10, use_static_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0c6e8d1850>]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAt0AAAHpCAYAAABeNIDUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAABYlAAAWJQFJUiTwAAApDklEQVR4nO3df5SWdYH//9eoTTCgqxI1CPijbGQSArUw21xco1K2LWHxiIz9ONZaGiq5ZxdbLeyUZexpS1GP2AopKbThpgu15GqZ2660yUa7JtE0hgcmEZQUhx+icH//4DvzcWRE8ObNzMjjcQ5HvX7d7zn329vnXF73ddVUKpVKAACAYg7o7gEAAMBrnegGAIDCRDcAABQmugEAoDDRDQAAhYluAAAoTHQDAEBhohsAAAoT3QAAUJjoBgCAwkQ3AAAUJroBAKCwg7p7ANVaunRpdw8BAID9yEknnbTH+zjTDQAAhfX6M93tXs1vHNVavnx5kqSxsXGfvzY9j/nAi5kPvJj5QDtzoXer5goLZ7oBAKAw0Q0AAIWJbgAAKEx0AwBAYaIbAAAKE90AAFCY6AYAgMJENwAAFCa6AQCgMNENAACFiW4AAChMdAMAQGGiGwAAChPdAABQmOgGAIDCRDcAABR2UHcPAAB47fvWA4/mm/f+Nhu3buvuofQQj3b3AHq1frUHZurYhvz1n725u4ey25zpBgCKE9zsTRu3bsu3/qN3/eIiugGA4gQ3e1O/2gPz16f2nrPcictLAIB9bOU1f9HdQ+g2y5cvT5I0NjZ280jY15zpBgCAwkQ3AAAUJroBAKAw0Q0AAIWJbgAAKEx0AwBAYaIbAAAK2yvRvWHDhlx99dU5/fTTM3z48LznPe/JFVdckXXr1u3xsZ577rl84AMfyHHHHZef//zne2N4AADQrap+OM6mTZty3nnnpaWlJU1NTRk+fHhWrlyZ2bNnZ8mSJVmwYEEOO+yw3T7ejTfemJUrV1Y7LAAA6DGqju65c+dmxYoVmT59eiZPntyxvLGxMVOmTMmsWbNy+eWX79axVqxYkVtuuSWNjY0dT2wCAIDerurLSxYuXJi6urpMnDix0/KxY8emvr4+CxcuTKVSecXjbN++PZ///OczePDgTJo0qdphAQBAj1HVme62trY0NzfnpJNOSm1tbad1NTU1GTlyZH70ox9l9erVGTp06C6P9Z3vfCf/+7//m7lz52bVqlXVDAvYhW898Gi+ee9vs3Hrtu4eyn7i0e4eAD2K+QD7q6qie/Xq1UmSQYMGdbm+vr4+SbJq1apdRvfjjz+eb3zjGzn77LPzzne+81VFd3dcjrJ58+Zue216nt4yH/7xnt9n8wuv/H+fAEroe1BNj/+cLKm3/LeCva+qy0s2btyYJOnbt2+X69uXt7W17fI4V111Vfr165e//du/rWY4wG4Q3EB36XtQTZpG7f7NFeC1pKoz3TU1NUnyitdst2/XlR/84Ae5//77c+211+aQQw551WNpbGx81fu+Wu2/pXbHa9Pz9J758P/+9/bKa/6iG8fx2tZ75gP7gvlAO3Ohd1u6dOmr3reqM939+/dPsuO2gV1pPxPevt1LPf300x339z7jjDOqGQoAAPRYVZ3pHjJkSGpqavL44493ub61tTVJctRRR3W5fsaMGdm8eXMuvPDCrFmzpmP5hg0bkiTr16/PmjVrcvjhh+/0RU3orXyREQD2P1VFd11dXcc9tbds2ZI+ffp0rNu2bVuWLVuWwYMH54gjjuhy/yVLlmTTpk05++yzu1w/derUJMltt92Wk08+uZqhQo/RU4K7X+2B3T0EANhvVP1wnPHjx+fqq6/O/Pnz8/GPf7xj+d13353169fn4osv7ljW0tKS2trajjuZXH311dmyZctOx3zwwQdz66235rLLLktDQ0MaGhqqHSb0GD0luKeO9e8VAOwrVUf3pEmTsmjRosyYMSOtra0ZMWJEmpubM2fOnAwbNiznn39+x7bjxo3LMccck8WLFydJTjnllC6P+cc//jFJMmrUKGe4eU3zRUYA2D9UHd21tbWZM2dOrr/++ixevDjz5s3LgAEDMmnSpFxyySWpq6vbG+MEAIBeq+roTpJ+/fpl2rRpmTZt2i63W7FixW4db8KECZkwYcLeGBoAAHS7qm4ZCAAAvDLRDQAAhYluAAAobK9c0w29UbmH1Dz6ypsAAPsVZ7rZb3X3Q2o8nAYA9h+im/1Wdwe3h9MAwP7D5SWQvfOQmuXLlydJGhsbqz4WAPDa4kw3AAAUJroBAKAw0Q0AAIWJbgAAKEx0AwBAYaIbAAAKE90AAFCY6AYAgMJENwAAFCa6AQCgMNENAACFiW4AAChMdAMAQGGiGwAAChPdAABQmOgGAIDCRDcAABQmugEAoDDRDQAAhYluAAAoTHQDAEBhB3X3AOBbDzyab97722zcuq27hwIAUIQz3XS77g7ufrUHdttrAwD7B9FNt+vu4J46tqHbXh8A2D+4vIQeZeU1f9HdQwAA2Ouc6QYAgMJENwAAFCa6AQCgMNENAACFiW4AAChMdAMAQGGiGwAAChPdAABQmOgGAIDCRDcAABQmugEAoDDRDQAAhYluAAAoTHQDAEBhohsAAAo7qLsHQM/zrQcezTfv/W02bt3W3UMBAHhNcKabnXRXcPerPXCfvyYAwL4gutlJdwX31LEN+/x1AQD2BZeXsEsrr/mL7h4CAECv50w3AAAU5kx3L+CLjQAAvZsz3b2ALzYCAPRuorsX8MVGAIDezeUlvYwvNgIA9D7OdAMAQGGiGwAAChPdAABQmOgGAIDCRDcAABQmugEAoDDRDQAAhYluAAAoTHQDAEBhohsAAAoT3QAAUJjoBgCAwkQ3AAAUJroBAKAw0Q0AAIWJbgAAKEx0AwBAYaIbAAAKE90AAFCY6AYAgMJENwAAFCa6AQCgMNENAACFiW4AACjsoL1xkA0bNmTmzJm57777snbt2hx66KEZM2ZMpk6dmoEDB+5y3+3bt+cHP/hB7rjjjjz66KN5/vnnM3jw4Jx55pn56Ec/mv79+++NIQIAQLepOro3bdqU8847Ly0tLWlqasrw4cOzcuXKzJ49O0uWLMmCBQty2GGHvez+V155Ze688868+93vzmc/+9kceOCBuf/++3Pttdfm3//93/Pd7343tbW11Q4TAAC6TdXRPXfu3KxYsSLTp0/P5MmTO5Y3NjZmypQpmTVrVi6//PIu93344Ydz5513ZsyYMbn55ps7lp999tm56KKLct999+X+++/P+9///mqHCQAA3abqa7oXLlyYurq6TJw4sdPysWPHpr6+PgsXLkylUuly3z59+uSyyy7LlClTdlr37ne/O0myZs2aaocIAADdqqoz3W1tbWlubs5JJ5200yUgNTU1GTlyZH70ox9l9erVGTp06E77H3vssTn22GO7PPaKFSuSJA0NDdUMEQAAul1V0b169eokyaBBg7pcX19fnyRZtWpVl9H9Ylu3bs2mTZuydu3aLFq0KN/73vdy9tln513vetdujWX58uV7MPK9Y/Pmzfv8tbvj52T3dMd8oOcyH3gx84F25sL+q6ro3rhxY5Kkb9++Xa5vX97W1vaKx1q0aFE+97nPJUkOO+ywfOlLX8rZZ59dzfAAAKBHqCq6a2pqkuRlr9l+6Xa7cuqpp+bb3/521q1bl5/97GeZPn16fvazn+Uf/uEfduvuJY2Njbs36L2o/bfU8q/9aMffdcfPye7Zd/OB3sB84MXMB9qZC73b0qVLX/W+VUV3+z20N23a1OX69jPhu3Ov7YEDB3bc0/tDH/pQ3va2t+WrX/1qGhoa8pnPfKaaYQIAQLeq6u4lQ4YMSU1NTR5//PEu17e2tiZJjjrqqD0+9oc//OEkyX/8x3+8+gECAEAPUFV019XVpbGxMcuXL8+WLVs6rdu2bVuWLVuWwYMH54gjjuhy/5kzZ+bkk0/Of/7nf+60buvWrR3HAQCA3qzq+3SPHz8+W7Zsyfz58zstv/vuu7N+/fpMmDChY1lLS0tWrVrV8c/Dhg3L008/nblz5+503LvuuitJcuKJJ1Y7RAAA6FZVP5Fy0qRJWbRoUWbMmJHW1taMGDEizc3NmTNnToYNG5bzzz+/Y9tx48blmGOOyeLFi5PseIDOaaedlp/85Cf5yEc+kjPOOCN9+vTJL37xi9x1112pr6/PJz/5yWqHCAAA3arq6K6trc2cOXNy/fXXZ/HixZk3b14GDBiQSZMm5ZJLLkldXd3L7ltTU5Mbbrghd911V773ve9l5syZaWtry5ve9Kace+65ueiiizq+XAkAAL1V1dGdJP369cu0adMybdq0XW7X/pTJTgM46KBMnDhxp8fIAwDAa0XV13QDAAC7JroBAKAw0Q0AAIWJbgAAKEx0AwBAYaIbAAAKE90AAFCY6AYAgMJENwAAFCa6AQCgMNENAACFiW4AAChMdAMAQGGiGwAAChPdAABQmOgGAIDCRDcAABQmugEAoDDRDQAAhR3U3QPoze789dO5fdkfs/mFR7t7KAAA9GDOdFdhR3BX9tnr9as9cJ+9FgAAe4/orsK+Du6pYxv22esBALD3uLxkL1l5zV909xAAAOihnOkGAIDCRDcAABQmugEAoDDRDQAAhYluAAAoTHQDAEBhohsAAAoT3QAAUJjoBgCAwkQ3AAAUJroBAKAw0Q0AAIWJbgAAKEx0AwBAYaIbAAAKE90AAFCY6AYAgMJENwAAFCa6AQCgMNENAACFiW4AAChMdAMAQGGiGwAAChPdAABQmOgGAIDCRDcAABQmugEAoDDRDQAAhYluAAAoTHQDAEBhohsAAAoT3QAAUJjoBgCAwkQ3AAAUJroBAKAw0Q0AAIWJbgAAKEx0AwBAYaIbAAAKE90AAFCY6AYAgMJENwAAFCa6AQCgMNENAACFiW4AAChMdAMAQGGiGwAAChPdAABQmOgGAIDCRDcAABQmugEAoDDRDQAAhYluAAAoTHQDAEBhohsAAAoT3QAAUJjoBgCAwg7aGwfZsGFDZs6cmfvuuy9r167NoYcemjFjxmTq1KkZOHDgK+7/0EMPZdasWVm+fHk2btyYoUOH5owzzsj555+fPn367I0hAgBAt6k6ujdt2pTzzjsvLS0taWpqyvDhw7Ny5crMnj07S5YsyYIFC3LYYYe97P4//OEPc9lll+Xoo4/OJz/5yfTv3z8PPPBArr322jzwwAO54447csABTsgDANB7VR3dc+fOzYoVKzJ9+vRMnjy5Y3ljY2OmTJmSWbNm5fLLL+9y361bt+bzn/98Bg0alO9973s5+OCDkyQTJ07MxRdfnHvuuScPPPBATjvttGqHCQAA3abqU8gLFy5MXV1dJk6c2Gn52LFjU19fn4ULF6ZSqXS575NPPpn3ve99ueCCCzqCu92pp56aJPntb39b7RABAKBbVRXdbW1taW5uTmNjY2prazutq6mpyciRI/Pkk09m9erVXe5/xBFH5Jprrsm5556707pnn302SXaKcQAA6G2qurykPaYHDRrU5fr6+vokyapVqzJ06NDdPu7WrVtz5513pra2Nqeffvpu7bN8+fLdPn4J3f36dL/NmzcnMRfYwXzgxcwH2pkL+6+qznRv3LgxSdK3b98u17cvb2tr2+1jbt++PZ///OfT0tKSKVOm5E1velM1QwQAgG5X1ZnumpqaJHnZa7Zfut0r2bJlS/7mb/4m9957b84+++xccMEFuz2WxsbG3d5273m0m1+fnqT9rIW5QGI+0Jn5QDtzoXdbunTpq963quju379/kh23DexK+5nw9u12Zf369bnwwguzbNmyfPrTn87UqVN3O9YBAKAnqyq6hwwZkpqamjz++ONdrm9tbU2SHHXUUbs8zpNPPpmmpqa0trbma1/7Ws4666xqhgUAAD1KVdFdV1eXxsbGLF++PFu2bOn09Mht27Zl2bJlGTx4cI444oiXPUZbW1s++clPZs2aNbn55pvz7ne/u5ohAQBAj1P1fbrHjx+fLVu2ZP78+Z2W33333Vm/fn0mTJjQsaylpSWrVq3qtN3VV1+d3/zmN/nHf/xHwQ0AwGtS1U+knDRpUhYtWpQZM2aktbU1I0aMSHNzc+bMmZNhw4bl/PPP79h23LhxOeaYY7J48eIkyW9+85t8//vfT0NDQ55//vmO5S92+OGHZ/To0dUOEwAAuk3V0V1bW5s5c+bk+uuvz+LFizNv3rwMGDAgkyZNyiWXXJK6urqX3feRRx5JpVLJihUrcumll3a5zejRozN37txqhwkAAN2m6uhOkn79+mXatGmZNm3aLrdbsWJFp3+eMGFCp8tPAADgtajqa7oBAIBdE90AAFCY6AYAgMJENwAAFCa6AQCgMNENAACFiW4AAChMdAMAQGGiGwAAChPdAABQmOgGAIDCRDcAABQmugEAoDDRDQAAhYluAAAoTHQDAEBhohsAAAoT3QAAUJjoBgCAwkQ3AAAUJroBAKAw0Q0AAIWJbgAAKEx0AwBAYaIbAAAKE90AAFCY6AYAgMJENwAAFCa6AQCgMNENAACFiW4AAChMdAMAQGGiGwAAChPdAABQmOgGAIDCRDcAABQmugEAoDDRDQAAhYluAAAoTHQDAEBhohsAAAoT3QAAUJjoBgCAwkQ3AAAUJroBAKAw0Q0AAIWJbgAAKEx0AwBAYaIbAAAKE90AAFCY6AYAgMJENwAAFCa6AQCgMNENAACFiW4AAChMdAMAQGGiGwAAChPdAABQmOgGAIDCRDcAABQmugEAoDDRDQAAhYluAAAoTHQDAEBhohsAAAoT3QAAUJjoBgCAwkQ3AAAUJroBAKAw0Q0AAIWJbgAAKEx0AwBAYaIbAAAKE90AAFCY6AYAgMJENwAAFCa6AQCgMNENAACFiW4AAChMdAMAQGF7Jbo3bNiQq6++OqeffnqGDx+e97znPbniiiuybt263T7GY489lokTJ+a4447Lv/zLv+yNYQEAQI9wULUH2LRpU84777y0tLSkqakpw4cPz8qVKzN79uwsWbIkCxYsyGGHHbbLY9x555358pe/XO1QAACgR6o6uufOnZsVK1Zk+vTpmTx5csfyxsbGTJkyJbNmzcrll1/+svt/97vfzRe+8IV85CMfyVvf+tZ84QtfqHZIAADQo1R9ecnChQtTV1eXiRMndlo+duzY1NfXZ+HChalUKrs8xg033JArr7wyr3vd66odDgAA9DhVRXdbW1uam5vT2NiY2traTutqamoycuTIPPnkk1m9evXLHuOcc87J2LFjqxkGAAD0aFVdXtIe04MGDepyfX19fZJk1apVGTp0aDUv9YqWL19e9Pg9/fXpfps3b05iLrCD+cCLmQ+0Mxf2X1Wd6d64cWOSpG/fvl2ub1/e1tZWzcsAAECvVtWZ7pqamiR5xWu227crqbGxsfhr7OzRbn59epL2sxbmAon5QGfmA+3Mhd5t6dKlr3rfqs509+/fP8mO2wZ2pf1MePt2AACwP6oquocMGZKampo8/vjjXa5vbW1Nkhx11FHVvAwAAPRqVUV3XV1dGhsbs3z58mzZsqXTum3btmXZsmUZPHhwjjjiiKoGCQAAvVnV9+keP358tmzZkvnz53dafvfdd2f9+vWZMGFCx7KWlpasWrWq2pcEAIBepeonUk6aNCmLFi3KjBkz0tramhEjRqS5uTlz5szJsGHDcv7553dsO27cuBxzzDFZvHhxx7Kf/vSnHbfPefjhhzv+WldXlyQ5/PDDM3r06GqHCQAA3abq6K6trc2cOXNy/fXXZ/HixZk3b14GDBiQSZMm5ZJLLumI55fzxS9+sePa73a33357br/99iTJ6NGjM3fu3GqHCQAA3abq6E6Sfv36Zdq0aZk2bdout1uxYsVOy3784x/vjSEAAECPVfU13QAAwK6JbgAAKEx0AwBAYaIbAAAKE90AAFCY6AYAgMJENwAAFCa6AQCgMNENAACFiW4AAChMdAMAQGGiGwAAChPdAABQmOgGAIDCRDcAABQmugEAoDDRDQAAhYluAAAoTHQDAEBhohsAAAoT3QAAUJjoBgCAwkQ3AAAUJroBAKAw0Q0AAIWJbgAAKEx0AwBAYaIbAAAKE90AAFCY6AYAgMJENwAAFCa6AQCgMNENAACFiW4AAChMdAMAQGGiGwAAChPdAABQmOgGAIDCRDcAABQmugEAoDDRDQAAhYluAAAoTHQDAEBhohsAAAoT3QAAUJjoBgCAwkQ3AAAUJroBAKAw0Q0AAIWJbgAAKEx0AwBAYaIbAAAKE90AAFCY6AYAgMJENwAAFCa6AQCgMNENAACFiW4AAChMdAMAQGGiGwAAChPdAABQmOgGAIDCRDcAABQmugEAoDDRDQAAhYluAAAoTHQDAEBhohsAAAoT3QAAUJjoBgCAwkQ3AAAUJroBAKAw0Q0AAIWJbgAAKEx0AwBAYaIbAAAKE90AAFCY6AYAgMJENwAAFCa6AQCgsIP2xkE2bNiQmTNn5r777svatWtz6KGHZsyYMZk6dWoGDhz4ivsvW7YsN9xwQ5YtW5bnnnsuRx11VM4555xMnjw5Bxzg9wIAAHq3qqN706ZNOe+889LS0pKmpqYMHz48K1euzOzZs7NkyZIsWLAghx122Mvu/+CDD+av//qvU19fn8985jM59NBDc8899+RLX/pSVq5cmSuvvLLaIQIAQLeqOrrnzp2bFStWZPr06Zk8eXLH8sbGxkyZMiWzZs3K5Zdf3uW+lUolX/ziF9OnT5/ccccdeeMb35gkOeuss3LhhRfmO9/5TiZOnJhhw4ZVO0wAAOg2VV+7sXDhwtTV1WXixImdlo8dOzb19fVZuHBhKpVKl/s+/PDD+f3vf58zzzyzI7jbfeQjH0mlUsm//uu/VjtEAADoVlVFd1tbW5qbm9PY2Jja2tpO62pqajJy5Mg8+eSTWb16dZf7/+pXv0qSvP3tb99p3ciRIzttAwAAvVVVl5e0x/SgQYO6XF9fX58kWbVqVYYOHbrT+lWrVr3s/v369cshhxzSsc0rWb58+W5tV0p3vz7db/PmzUnMBXYwH3gx84F25sL+q6oz3Rs3bkyS9O3bt8v17cvb2tpe9f4vt29P0OegmiRJ3///rwAA0JWqznTX1OyIzZe7Zvul272a/V9u35dqbGzcre32pvNGPZ1/+fUzufDPG9LY+OZ9/vr0LO1nLbpjLtLzmA+8mPlAO3Ohd1u6dOmr3req6O7fv3+SHbcN7Er7mez27V7N/gcffHA1Qyzqr44/NH91/KGCGwCAXarq8pIhQ4akpqYmjz/+eJfrW1tbkyRHHXVUl+vbr/Puav9nnnkmbW1tOfLII6sZIgAAdLuqoruuri6NjY1Zvnx5tmzZ0mndtm3bsmzZsgwePDhHHHFEl/ufeOKJSXY8kfKlHnrooSTJO97xjmqGCAAA3a7q+3SPHz8+W7Zsyfz58zstv/vuu7N+/fpMmDChY1lLS0unu5EMGzYsb3vb27J48eJOZ7srlUq+/e1v56CDDspZZ51V7RABAKBbVf1EykmTJmXRokWZMWNGWltbM2LEiDQ3N2fOnDkZNmxYzj///I5tx40bl2OOOSaLFy/uWDZ9+vR89KMfTVNTUz72sY/lkEMOyaJFi/Lf//3fufTSS11eAgBAr1d1dNfW1mbOnDm5/vrrs3jx4sybNy8DBgzIpEmTcskll6Surm6X+48aNSrz5s3Lddddl5kzZ+b555/PW97ylnzta19zlhsAgNeEqqM72fEgm2nTpmXatGm73G7FihVdLj/++OMza9asvTEUAADocaq+phsAANg10Q0AAIWJbgAAKEx0AwBAYaIbAAAKE90AAFCY6AYAgMJENwAAFCa6AQCgMNENAACF1VQqlUp3D6IaS5cu7e4hAACwHznppJP2eB9nugEAoLBef6YbAAB6Ome6AQCgMNENAACFiW4AAChMdAMAQGGiGwAAChPdAABQ2EHdPYDeaMOGDZk5c2buu+++rF27NoceemjGjBmTqVOnZuDAgd09PKr01FNP5aabbsoDDzyQNWvW5A1veEPe/va35+KLL86b3/zmTts+99xzufnmm7No0aL84Q9/SP/+/TN69Oh89rOfzdFHH91p223btmXu3Lm5884789hjj6VPnz4ZNWpULr744owYMWIf/oRU49prr82NN96Y8ePH55prrulYvqfv71133ZXvfOc7aWlpyQEHHJC3ve1tueCCC3Lqqafuyx+HV+GnP/1pZs2aleXLl+d1r3tdGhsbc+GFF+Zd73pXp+18PuwfVq1alRtvvDEPPfRQnnjiibzhDW/I8ccfnwsuuKDTe2c+4D7de2jTpk2ZNGlSWlpa0tTUlOHDh2flypWZPXt2BgwYkAULFuSwww7r7mHyKj311FM5++yz89RTT+Xcc8/NsGHDsnLlytx222154YUXMm/evBx//PFJku3bt+cTn/hE/uu//isTJkzIySefnLVr12bOnDnZvn17/vmf/zlHHXVUx7H//u//PnfeeWfe+9735n3ve182bNiQ2267LWvXrs1tt92WE044obt+bHZTc3Nzxo8fn+eff36n6N6T9/eGG27Iddddl9GjR+dDH/pQtm3blnnz5mXFihX55je/mTPOOKM7fjx2w4IFC3LFFVfklFNOyV/+5V+mra0tt956a9auXZtbbrklJ598chKfD/uLRx55JE1NTXnd616XpqamHH300XniiSdyxx13ZO3atbn++utz+umnmw/sUGGP3HTTTZWGhobK7bff3mn5PffcU2loaKh89atf7aaRsTd84QtfqDQ0NFTuueeeTsvvu+++SkNDQ+Xiiy/uWLZw4cJKQ0NDZcaMGZ22/b//+7/KcccdV5kyZUrHsv/5n/+pNDQ0VC699NJO2/7hD3+ojBo1qjJ+/Pi9/8OwV23btq1yzjnnVD784Q9XGhoaKtOmTetYtyfvb2tra+X444+vnHPOOZVt27Z1LH/22Wcrp556auVP//RPK88991zxn4c9t27dusqoUaMqn/rUpyrbt2/vWP7YY49V3vWud1WuueaajmU+H/YPF110UaWhoaHywAMPdFre0tJSaWhoqHzoQx+qVCrmAzu4pnsPLVy4MHV1dZk4cWKn5WPHjk19fX0WLlyYiv950GsNHDgwH/zgBzN27NhOy9/znvekpqYmv/3tbzuWLVy4MEny0Y9+tNO2w4cPzwknnJCf/OQnefbZZ3e57aBBg/Le9743v/71r/O73/1ur/887D3z5s3LL3/5y1x++eU7rduT9/ff/u3f8vzzz6epqSkHHPD/PoL79++f8ePHZ926dXnwwQcL/iS8Wt///vezadOmTJ06NTU1NR3LjzzyyDz44IOZNm1axzKfD/uH1atXJ0ne8Y53dFr+5je/OYcffnj+8Ic/JDEf2EF074G2trY0NzensbExtbW1ndbV1NRk5MiRefLJJzv+JaT3mTJlSr7+9a93+g9qsuO9r1QqOeSQQzqWLVu2LPX19XnTm96003FGjRqV559/Pg8//HDHtgcccECGDx/e5bbt29AzrVmzJl//+tfzV3/1Vztdt5vs2fv7q1/9KkkycuTIV9yWnuXBBx/MwIEDM2zYsCQ7rrvdunVrl9v6fNg/HHvssUmSlStXdlre1taWZ555Jm95y1uSmA/sILr3QHtMDxo0qMv19fX1SXZ8qYLXlvnz5ydJx7W2bW1tefrpp19xLrTPmdWrV2fAgAE7/bL24m3Nm57ri1/8Yvr27dvpTOaL7cn72/7X9uUv1j6fzIWe6Xe/+12OPPLILFu2LJMnT86IESMyYsSInHnmmbn77rs7tvP5sP/41Kc+lYMPPjjTpk3LkiVLsm7duvz617/OZZddlgMOOCCXXnqp+UAHdy/ZAxs3bkyS9O3bt8v17cvb2tr22Zgo76c//WluvPHGHHfccWlqakryynOhrq4uyf+bCxs3bsyhhx66y23bj0nPsnjx4vz4xz/ON77xjfzJn/xJl9vsyfu7cePGHHTQQV3+B9VnSM/29NNPp2/fvrnooosyefLkXHDBBWltbc3NN9+cv/u7v8uWLVtyzjnn+HzYjzQ0NGTevHm59NJL87GPfaxj+Rvf+MaOL9Y+8cQTScwHRPceab/k4JWu2X7ppQn0XnfddVeuvPLK1NfX56abbsrrX//6Tut3dy7U1NS41r8X2rBhQ7785S/ntNNOy7hx4152uz15f3dnW58hPdMLL7yQlStXZtasWTnttNM6lo8ZMyZnnnlmvvnNb3b6vo/Ph9e+lpaWfOpTn0qlUsmVV16ZI488Mk888UTmzp2bT3/607nuuuvS0NCQxHxAdO+R/v37J9lx28CutP/m2b4dvVv7bd2OP/743HTTTXnjG9/YsW5P50K/fv1ecduDDz54r42dvWPGjBnZuHFjpk+fvsvt9uT97devX7Zt25bnnntup1/izIWerW/fvtm+fXun4E6SIUOGZPTo0fnZz36WlpaWDB48OInPh/3BFVdckaeeeio/+MEPMmTIkI7lZ555ZsaNG5fPfe5zWbx4cRLzAdd075EhQ4akpqYmjz/+eJfrW1tbk6TTvTbpna6++upcd911ef/735/bb7+9U3AnOz4UBwwY0PHN9JdqvzavfS4ceeSRWb9+fZ577rmdtjVveqZf/OIXWbBgQT7xiU/kgAMOyJo1azr+JMnmzZuzZs2aPPPMM3v0/h555JFJ0uXcad+2fRt6liFDhuTAAw/sct0b3vCGJDsuEfD5sH9oa2vLL3/5ywwbNqxTcCc7ovid73xn1q1bl9bWVvOBJKJ7j9TV1aWxsTHLly/Pli1bOq3btm1bli1blsGDB+eII47ophGyN9xwww257bbbMmnSpFx77bUvex3eiSee2PGB+lJLly5Nnz59Or59fuKJJ2b79u0dd654sYceeihJctJJJ+3Fn4JqLVmyJJVKJTNnzsyYMWM6/Ul2XOs9ZsyYfPWrX92j9/fEE09M0vXdB9q3fentx+gZTjjhhDz77LNd3qGqPajaf0H3+fDa137nmq7iOElHJzz//PPmA0lE9x4bP358tmzZ0nE3i3Z333131q9fnwkTJnTTyNgblixZkpkzZ+YDH/hArrrqqk73UX6p8ePHJ0nmzJnTafnPf/7zPPLIIxk3blxHsJ911lmpqanJt7/97U7bPvroo7n//vtz8sknZ+jQoXv3h6EqH/zgB3PTTTd1+SdJTjnllNx00035+Mc/vkfv75lnnpk+ffpk7ty5eeGFFzq2Xb9+fe66664cffTReec737nPfk52X/vn+4033thp+W9+85s89NBDOfbYYzvOePp8eO07/PDDM3To0DQ3N3d6hkOS/PGPf8zSpUvTr1+/vPWtbzUfSOIx8Hts69atOe+88/Lwww+nqakpI0aMSHNzc+bMmZO3vOUtmTdvXse3i+l9JkyYkEceeSRXXXXVy357fMyYMR0fjp/5zGdy7733Zvz48TnllFPS2tqa2bNnp1+/flmwYEEGDhzYsd9XvvKV3HrrrfnzP//znHHGGfnjH/+Y2bNnZ9OmTZk/f37e+ta37osfkb3guOOO2+kx8Hvy/t566635yle+kpNOOikTJkzIc889l7lz52b16tX5p3/6py7vBU7PcPXVV+e2227LuHHjMmbMmLS2tubWW2/Npk2b8q1vfSunnHJKx7Y+H1777r333lx88cU55JBD0tTUlCOPPDJPPfVUvvvd7+axxx7LVVddlXPPPTeJ+YDoflU2btyY66+/PosXL866desyYMCAvO9978sll1zS6eEp9D7HHXfcK25z3333dZzN2rp1a2655ZbcddddaW1tzSGHHJI/+7M/y2c/+9mdHoJQqVQyb968zJs3LytXrkxdXV1Gjx6dqVOndjxAgd6hq+je0/f3hz/8YebMmZPm5uYceOCBGTVqVC6++OKOh1/QM1UqlcyfPz/z5s3L73//+7z+9a/PCSeckClTpuz0wCOfD/uHpUuX5pZbbskvf/nLPPPMM+nfv3+GDx+ej33sYx2XoyXmA6IbAACKc003AAAUJroBAKAw0Q0AAIWJbgAAKEx0AwBAYaIbAAAKE90AAFCY6AYAgMJENwAAFCa6AQCgMNENAACFiW4AAChMdAMAQGGiGwAAChPdAABQmOgGAIDCRDcAABT2/wFFDdy5cSCWTAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 244,
       "width": 366
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [0] + [x[0] for x in evolution.val_metrics]\n",
    "y = [0] + [x[1] for x in evolution.val_metrics]\n",
    "plt.step(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "machine_shape": "hm",
   "name": "tf_multi_layer_ssnet_inverse.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
