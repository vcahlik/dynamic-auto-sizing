{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_multi_layer_ssnet_inverse.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "background_execution": "on",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_deAUKlniFk",
        "outputId": "463a018f-137b-4253-b403-69ea9656db21"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jan 14 15:14:01 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    50W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKwUwV_NneIo"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from enum import Enum\n",
        "import imageio\n",
        "import os\n",
        "import hashlib\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "dtype = 'float32'\n",
        "tf.keras.backend.set_floatx(dtype)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTZq4KMpneIv"
      },
      "source": [
        "################################################################################\n",
        "# DATASETS\n",
        "################################################################################\n",
        "\n",
        "\n",
        "class Dataset:\n",
        "    def __init__(self, X_train, y_train, X_test, y_test, shape, shape_flattened, vision=True):\n",
        "        X_train = X_train.astype(dtype)\n",
        "        y_train = y_train.astype(dtype)\n",
        "        X_test = X_test.astype(dtype)\n",
        "        y_test = y_test.astype(dtype)\n",
        "\n",
        "        if vision:\n",
        "            X_train = X_train / 255.0\n",
        "            X_test = X_test / 255.0\n",
        "\n",
        "        X_train = np.reshape(X_train, shape_flattened)\n",
        "        X_test = np.reshape(X_test, shape_flattened)\n",
        "\n",
        "        X = np.concatenate((X_train, X_test), axis=0)\n",
        "        y = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "        from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(X_train)  # Scaling each feature independently\n",
        "\n",
        "        X_norm = scaler.transform(X)\n",
        "        X_train_norm = scaler.transform(X_train)\n",
        "        X_test_norm = scaler.transform(X_test)\n",
        "\n",
        "        X_norm = np.reshape(X_norm, shape)\n",
        "        X_train_norm = np.reshape(X_train_norm, shape)\n",
        "        X_test_norm = np.reshape(X_test_norm, shape)\n",
        "\n",
        "        del X, X_train, X_test\n",
        "\n",
        "        self.X_norm = X_norm\n",
        "        self.y = y\n",
        "        self.X_train_norm = X_train_norm\n",
        "        self.y_train = y_train\n",
        "        self.X_test_norm = X_test_norm\n",
        "        self.y_test = y_test\n",
        "\n",
        "\n",
        "def get_cifar_10_dataset():\n",
        "    cifar10 = tf.keras.datasets.cifar10\n",
        "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "    shape = (-1, 32, 32, 3)\n",
        "    shape_flattened = (-1, 3072)  # Scaling each feature independently\n",
        "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened)\n",
        "\n",
        "\n",
        "def get_cifar_100_dataset():\n",
        "    cifar100 = tf.keras.datasets.cifar100\n",
        "    (X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
        "    shape = (-1, 32, 32, 3)\n",
        "    shape_flattened = (-1, 3072)  # Scaling each feature independently\n",
        "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened)\n",
        "\n",
        "\n",
        "def get_svhn_dataset():\n",
        "    from urllib.request import urlretrieve\n",
        "    from scipy import io\n",
        "\n",
        "    train_filename, _ = urlretrieve('http://ufldl.stanford.edu/housenumbers/train_32x32.mat')\n",
        "    test_filename, _ = urlretrieve('http://ufldl.stanford.edu/housenumbers/test_32x32.mat')\n",
        "\n",
        "    X_train = io.loadmat(train_filename, variable_names='X').get('X')\n",
        "    y_train = io.loadmat(train_filename, variable_names='y').get('y')\n",
        "    X_test = io.loadmat(test_filename, variable_names='X').get('X')\n",
        "    y_test = io.loadmat(test_filename, variable_names='y').get('y')\n",
        "\n",
        "    X_train = np.moveaxis(X_train, -1, 0)\n",
        "    y_train -= 1\n",
        "    X_test = np.moveaxis(X_test, -1, 0)\n",
        "    y_test -= 1\n",
        "\n",
        "    shape = (-1, 32, 32, 3)\n",
        "    shape_flattened = (-1, 3072)  # Scaling each feature independently\n",
        "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened)\n",
        "\n",
        "\n",
        "def get_tiny_imagenet_dataset():\n",
        "    \"\"\"\n",
        "    Original source: https://github.com/sonugiri1043/Train_ResNet_On_Tiny_ImageNet/blob/master/Train_ResNet_On_Tiny_ImageNet.ipynb\n",
        "    Original author: sonugiri1043@gmail.com\n",
        "    \"\"\"\n",
        "\n",
        "    if not os.path.isdir('IMagenet'):\n",
        "        ! git clone https://github.com/seshuad/IMagenet\n",
        "\n",
        "    print(\"Processing the downloaded dataset...\")\n",
        "\n",
        "    path = 'IMagenet/tiny-imagenet-200/'\n",
        "\n",
        "    id_dict = {}\n",
        "    for i, line in enumerate(open(path + 'wnids.txt', 'r')):\n",
        "        id_dict[line.replace('\\n', '')] = i\n",
        "\n",
        "    train_data = list()\n",
        "    test_data = list()\n",
        "    train_labels = list()\n",
        "    test_labels = list()\n",
        "\n",
        "    for key, value in id_dict.items():\n",
        "        train_data += [imageio.imread(path + 'train/{}/images/{}_{}.JPEG'.format(key, key, str(i)), pilmode='RGB') for i in range(500)]\n",
        "        train_labels_ = np.array([[0]*200]*500)\n",
        "        train_labels_[:, value] = 1\n",
        "        train_labels += train_labels_.tolist()\n",
        "\n",
        "    for line in open(path + 'val/val_annotations.txt'):\n",
        "        img_name, class_id = line.split('\\t')[:2]\n",
        "        test_data.append(imageio.imread(path + 'val/images/{}'.format(img_name), pilmode='RGB'))\n",
        "        test_labels_ = np.array([[0]*200])\n",
        "        test_labels_[0, id_dict[class_id]] = 1\n",
        "        test_labels += test_labels_.tolist()\n",
        "\n",
        "    X_train = np.array(train_data)\n",
        "    y_train = np.argmax(np.array(train_labels), axis=1)\n",
        "    X_test = np.array(test_data)\n",
        "    y_test = np.argmax(np.array(test_labels), axis=1)\n",
        "\n",
        "    shape = (-1, 64, 64, 3)\n",
        "    shape_flattened = (-1, 12288)  # Scaling each feature independently\n",
        "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened)\n",
        "\n",
        "\n",
        "def get_mnist_dataset():\n",
        "    mnist = tf.keras.datasets.mnist\n",
        "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "    shape = (-1, 28, 28, 1)\n",
        "    shape_flattened = (-1, 1)  # Scaling all features together\n",
        "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened)\n",
        "\n",
        "\n",
        "def get_fashion_mnist_dataset():\n",
        "    fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "    (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "    shape = (-1, 28, 28, 1)\n",
        "    shape_flattened = (-1, 1)  # Scaling all features together\n",
        "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened)\n",
        "\n",
        "\n",
        "def get_fifteen_puzzle_dataset(frac):\n",
        "    from google.colab import drive\n",
        "    from sklearn.model_selection import train_test_split\n",
        "\n",
        "    drive.mount('/content/gdrive')\n",
        "    costs = pd.read_csv('gdrive/MyDrive/15-costs-v3.csv')\n",
        "    costs = costs.sample(frac=frac)\n",
        "\n",
        "    X_raw = costs.iloc[:,:-1].values\n",
        "    y = costs['cost'].values\n",
        "    X = np.apply_along_axis(lambda x: np.eye(16)[x].ravel(), 1, X_raw)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    del X, X_raw, y\n",
        "\n",
        "    shape = (-1, 256)\n",
        "    shape_flattened = (-1, 1)  # Scaling all features together\n",
        "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened, vision=False)\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# REGULARIZERS\n",
        "################################################################################\n",
        "\n",
        "\n",
        "class Regularizer(tf.keras.regularizers.Regularizer):\n",
        "    def __init__(self):\n",
        "        self.n_new_neurons = 0\n",
        "        self.scaling_tensor = None\n",
        "        self.set_regularization_penalty(0.)\n",
        "        self.set_regularization_method(None)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        if self.regularization_method is None or self.regularization_penalty == 0:\n",
        "            return 0\n",
        "        elif self.regularization_method == 'weighted_l1':\n",
        "            return self.weighted_l1(x)\n",
        "        elif self.regularization_method == 'weighted_l1_reordered':\n",
        "            return self.weighted_l1_reordered(x)\n",
        "        elif self.regularization_method == 'group_sparsity':\n",
        "            return self.group_sparsity(x)\n",
        "        elif self.regularization_method == 'l1':\n",
        "            return self.l1(x)\n",
        "        else:\n",
        "            raise NotImplementedError(f\"Unknown regularization method {self.regularization_method}\")\n",
        "    \n",
        "    def weighted_l1(self, x):\n",
        "        # I.e. for a parameter matrix of 4 input and 10 output neurons:\n",
        "        #\n",
        "        # [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]\n",
        "        #\n",
        "        # the scaling tensor, as well as the resulting weighted values, could be:\n",
        "        #\n",
        "        # [[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
        "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
        "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
        "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]\n",
        "        #\n",
        "        # Therefore every additional output neuron is regularized more.\n",
        "\n",
        "        scaling_tensor = tf.cumsum(tf.constant(self.regularization_penalty, shape=x.shape, dtype=dtype), axis=-1)\n",
        "        weighted_values = scaling_tensor * tf.abs(x)\n",
        "        return tf.reduce_sum(weighted_values)\n",
        "    \n",
        "    def weighted_l1_reordered(self, x):\n",
        "        # I.e. for a parameter matrix of 4 input and 10 output neurons:\n",
        "        #\n",
        "        # [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]\n",
        "        #\n",
        "        # the scaling tensor, as well as the resulting weighted values, could be:\n",
        "        #\n",
        "        # [[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
        "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
        "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
        "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]\n",
        "        #\n",
        "        # Therefore every additional output neuron is regularized more.\n",
        "\n",
        "        if self.update_scaling_tensor:\n",
        "            scaling_tensor_raw = tf.cumsum(tf.constant(self.regularization_penalty, shape=x.shape, dtype=dtype), axis=-1)\n",
        "\n",
        "            scaling_tensor_old_neurons = scaling_tensor_raw[:, :-self.n_new_neurons]\n",
        "            scaling_tensor_new_neurons = scaling_tensor_raw[:, -self.n_new_neurons:]\n",
        "            scaling_tensor_old_neurons_shuffled = tf.transpose(tf.random.shuffle(tf.transpose(scaling_tensor_old_neurons)))\n",
        "            self.scaling_tensor = tf.concat([scaling_tensor_old_neurons_shuffled, scaling_tensor_new_neurons], axis=-1)\n",
        "            self.update_scaling_tensor = False\n",
        "\n",
        "        weighted_values = self.scaling_tensor * tf.abs(x)\n",
        "        return tf.reduce_sum(weighted_values)\n",
        "    \n",
        "    def group_sparsity(self, x):\n",
        "        # I.e. for a parameter matrix of 3 input and 5 output neurons:\n",
        "        #\n",
        "        # [[1., 1., 1., 1., 1.],\n",
        "        #  [1., 2., 2., 1., 2.],\n",
        "        #  [2., 2., 3., 1., 3.]]\n",
        "        #\n",
        "        # The resulting vector of group norms is [2., 2., 3., 1., 3.], therefore for\n",
        "        # every output neuron, its incoming connections form a group.\n",
        "\n",
        "        group_norms = tf.norm(x, ord=2, axis=0)\n",
        "        # assert group_norms.shape[0] == x.shape[1]\n",
        "        return self.regularization_penalty * tf.reduce_sum(group_norms)\n",
        "    \n",
        "    def l1(self, x):\n",
        "        weighted_values = self.regularization_penalty * tf.abs(x)\n",
        "        return tf.reduce_sum(weighted_values)\n",
        "    \n",
        "    def prune(self):\n",
        "        self.n_new_neurons = 0\n",
        "        if self.regularization_method == 'weighted_l1_reordered':\n",
        "            self.update_scaling_tensor = True\n",
        "    \n",
        "    def grow(self, n_new_neurons):\n",
        "        self.n_new_neurons = n_new_neurons\n",
        "        if self.regularization_method == 'weighted_l1_reordered':\n",
        "            self.update_scaling_tensor = True\n",
        "    \n",
        "    def set_regularization_penalty(self, regularization_penalty):\n",
        "        self.regularization_penalty = regularization_penalty\n",
        "    \n",
        "    def set_regularization_method(self, regularization_method):\n",
        "        self.regularization_method = regularization_method\n",
        "        if self.regularization_method == 'weighted_l1_reordered':\n",
        "            self.update_scaling_tensor = True\n",
        "        else:\n",
        "            self.update_scaling_tensor = None\n",
        "\n",
        "    def get_config(self):\n",
        "        return {'regularization_penalty': float(self.regularization_penalty)}\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# LAYERS\n",
        "################################################################################\n",
        "\n",
        "\n",
        "class CustomLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, input_shape):\n",
        "        super().__init__()\n",
        "\n",
        "        self.inpt_shp = input_shape\n",
        "\n",
        "\n",
        "class Dense(CustomLayer):\n",
        "    def __init__(self, units, activation, kernel_initializer='glorot_uniform', \n",
        "                 bias_initializer='zeros', input_shape=None, fixed_size=False):\n",
        "        super().__init__(input_shape)\n",
        "\n",
        "        self.units = units\n",
        "        self.activation = activation\n",
        "        self.kernel_initializer = kernel_initializer\n",
        "        self.bias_initializer = bias_initializer\n",
        "        self.fixed_size = fixed_size\n",
        "        \n",
        "        self.A = tf.keras.activations.get(activation)\n",
        "        self.W_init = tf.keras.initializers.get(kernel_initializer)\n",
        "        self.b_init = tf.keras.initializers.get(bias_initializer)\n",
        "        self.regularizer = Regularizer()\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        input_units = input_shape[-1]\n",
        "\n",
        "        self.W = tf.Variable(\n",
        "            name='W',\n",
        "            initial_value=self.W_init(shape=(input_units, self.units), dtype=dtype),\n",
        "            trainable=True)\n",
        "        \n",
        "        self.b = tf.Variable(\n",
        "            name='b',\n",
        "            initial_value=self.b_init(shape=(self.units,), dtype=dtype),\n",
        "            trainable=True)\n",
        "        \n",
        "        self.add_loss(lambda: self.regularizer(tf.concat([self.W, tf.reshape(self.b, (1, -1))], axis=0)))\n",
        "    \n",
        "    def call(self, inputs, training=None):\n",
        "        return self.A(tf.matmul(inputs, self.W) + self.b)\n",
        "\n",
        "    def get_size(self):\n",
        "        return self.W.shape[0], self.W.shape[1]\n",
        "    \n",
        "    def prune(self, threshold, active_input_units_indices):\n",
        "        # Remove connections from pruned units in previous layer\n",
        "        new_W = tf.gather(self.W.value(), active_input_units_indices, axis=0)\n",
        "\n",
        "        if self.fixed_size:\n",
        "            active_output_neurons_indices = list(range(new_W.shape[1]))\n",
        "        else:\n",
        "            # Prune units in this layer\n",
        "            weights_with_biases = tf.concat([new_W, tf.reshape(self.b.value(), (1, -1))], axis=0)\n",
        "            neurons_are_active = tf.math.reduce_max(tf.abs(weights_with_biases), axis=0) >= threshold\n",
        "            active_output_neurons_indices = tf.reshape(tf.where(neurons_are_active), (-1,))\n",
        "            \n",
        "            new_W = tf.gather(new_W, active_output_neurons_indices, axis=1)\n",
        "            new_b = tf.gather(self.b.value(), active_output_neurons_indices, axis=0)\n",
        "\n",
        "            self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
        "\n",
        "        self.W = tf.Variable(name='W', initial_value=new_W, trainable=True)\n",
        "\n",
        "        self.regularizer.prune()\n",
        "        return active_output_neurons_indices\n",
        "    \n",
        "    def grow(self, n_new_input_units, percentage, min_new_units, scaling_factor):\n",
        "        if n_new_input_units > 0:\n",
        "            # Add connections to grown units in previous layer\n",
        "            W_growth = self.W_init(shape=(self.W.shape[0] + n_new_input_units, self.W.shape[1]), dtype=dtype)[-n_new_input_units:, :] * scaling_factor  # TODO is it better to be multiplying here by scaling_factor? It does help with not increasing the max weights of existing neurons when new neurons are added.\n",
        "            new_W = tf.concat([self.W.value(), W_growth], axis=0)\n",
        "        else:\n",
        "            new_W = self.W.value()\n",
        "\n",
        "        if self.fixed_size:\n",
        "            n_new_output_units = 0\n",
        "        else:\n",
        "            # Grow new units in this layer\n",
        "            n_new_output_units = max(min_new_units, int(new_W.shape[1] * percentage))\n",
        "            if n_new_output_units > 0:\n",
        "                W_growth = self.W_init(shape=(new_W.shape[0], new_W.shape[1] + n_new_output_units), dtype=dtype)[:, -n_new_output_units:] * scaling_factor\n",
        "                b_growth = self.b_init(shape=(n_new_output_units,), dtype=dtype)  # TODO for all possible bias initializers to work properly, the whole bias vector should be initialized at once\n",
        "                new_W = tf.concat([new_W, W_growth], axis=1)\n",
        "                new_b = tf.concat([self.b.value(), b_growth], axis=0)\n",
        "\n",
        "                self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
        "\n",
        "        self.W = tf.Variable(name='W', initial_value=new_W, trainable=True)\n",
        "\n",
        "        self.regularizer.grow(n_new_output_units)\n",
        "        return n_new_output_units\n",
        "    \n",
        "    def set_regularization_penalty(self, regularization_penalty):\n",
        "        if not self.fixed_size:\n",
        "            self.regularizer.set_regularization_penalty(regularization_penalty)\n",
        "    \n",
        "    def set_regularization_method(self, regularization_method):\n",
        "        if not self.fixed_size:\n",
        "            self.regularizer.set_regularization_method(regularization_method)\n",
        "    \n",
        "    def get_param_string():\n",
        "        param_string = \"\"\n",
        "        weights_with_bias = tf.concat([self.W, tf.reshape(self.b, (1, -1))], axis=0)\n",
        "        max_parameters = tf.math.reduce_max(tf.abs(weights_with_bias), axis=0).numpy()\n",
        "        magnitudes = np.floor(np.log10(max_parameters))\n",
        "        for m in magnitudes:\n",
        "            if m > 0:\n",
        "                m = 0\n",
        "            param_string += str(int(-m))\n",
        "        return param_string\n",
        "\n",
        "\n",
        "class Conv2D(CustomLayer):\n",
        "    def __init__(self, filters, filter_size, activation, strides=(1, 1), \n",
        "                 padding='SAME', kernel_initializer='glorot_uniform',\n",
        "                 bias_initializer='zeros', input_shape=None, fixed_size=False):\n",
        "        super().__init__(input_shape)\n",
        "    \n",
        "        self.filters = filters\n",
        "        self.filter_size = filter_size\n",
        "        self.activation = activation\n",
        "        self.strides = strides\n",
        "        self.padding = padding\n",
        "        self.kernel_initializer = kernel_initializer\n",
        "        self.bias_initializer = bias_initializer\n",
        "        self.fixed_size = fixed_size\n",
        "        \n",
        "        self.A = tf.keras.activations.get(activation)\n",
        "        self.F_init = tf.keras.initializers.get(kernel_initializer)\n",
        "        self.b_init = tf.keras.initializers.get(bias_initializer)\n",
        "        self.regularizer = Regularizer()\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        input_filters = input_shape[-1]\n",
        "\n",
        "        self.F = tf.Variable(\n",
        "            name='F',\n",
        "            initial_value=self.F_init(\n",
        "                shape=(self.filter_size[0], self.filter_size[1], input_filters, self.filters), dtype=dtype\n",
        "            ),\n",
        "            trainable=True)\n",
        "        \n",
        "        self.b = tf.Variable(\n",
        "            name='b',\n",
        "            initial_value=self.b_init(shape=(self.filters,), dtype=dtype),\n",
        "            trainable=True)\n",
        "\n",
        "        self.add_loss(lambda: self.regularizer(tf.concat([tf.reshape(self.F, (-1, self.F.shape[-1])), tf.reshape(self.b, (1, -1))], axis=0)))\n",
        "    \n",
        "    def call(self, inputs, training=None):\n",
        "        y = tf.nn.conv2d(inputs, self.F, strides=self.strides, padding=self.padding)\n",
        "        y = tf.nn.bias_add(y, self.b)\n",
        "        y = self.A(y)\n",
        "        return y\n",
        "    \n",
        "    def get_size(self):\n",
        "        return self.F.shape[-2], self.F.shape[-1]\n",
        "    \n",
        "    def prune(self, threshold, active_input_units_indices):\n",
        "        # Remove connections from pruned units in previous layer\n",
        "        new_F = tf.gather(self.F.value(), active_input_units_indices, axis=-2)\n",
        "\n",
        "        if self.fixed_size:\n",
        "            active_output_filters_indices = list(range(new_F.shape[-1]))\n",
        "        else:\n",
        "            # Prune units in this layer\n",
        "            F_reduced_max = tf.reshape(tf.math.reduce_max(tf.abs(new_F), axis=(0, 1, 2)), (1, -1))\n",
        "            F_reduced_max_with_biases = tf.concat([F_reduced_max, tf.reshape(self.b.value(), (1, -1))], axis=0)\n",
        "            filters_are_active = tf.math.reduce_max(tf.abs(F_reduced_max_with_biases), axis=0) >= threshold\n",
        "            active_output_filters_indices = tf.reshape(tf.where(filters_are_active), (-1,))\n",
        "            \n",
        "            new_F = tf.gather(new_F, active_output_filters_indices, axis=-1)\n",
        "            new_b = tf.gather(self.b.value(), active_output_filters_indices, axis=0)\n",
        "\n",
        "            self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
        "\n",
        "        self.F = tf.Variable(name='F', initial_value=new_F, trainable=True)\n",
        "\n",
        "        self.regularizer.prune()\n",
        "        return active_output_filters_indices\n",
        "\n",
        "    def grow(self, n_new_input_units, percentage, min_new_units, scaling_factor):\n",
        "        if n_new_input_units > 0:\n",
        "            # Add connections to grown units in previous layer\n",
        "            F_growth = self.F_init(shape=(self.F.shape[0], self.F.shape[1], self.F.shape[2] + n_new_input_units, self.F.shape[3]), dtype=dtype)[:, :, -n_new_input_units:, :] * scaling_factor  # TODO is it better to be multiplying here by scaling_factor? It does help with not increasing the max weights of existing neurons when new neurons are added.\n",
        "            new_F = tf.concat([self.F.value(), F_growth], axis=-2)\n",
        "        else:\n",
        "            new_F = self.F.value()\n",
        "\n",
        "        if self.fixed_size:\n",
        "            n_new_output_units = 0\n",
        "        else:\n",
        "            # Grow new units in this layer\n",
        "            n_new_output_units = max(min_new_units, int(new_F.shape[-1] * percentage))\n",
        "            if n_new_output_units > 0:\n",
        "                F_growth = self.F_init(shape=(new_F.shape[0], new_F.shape[1], new_F.shape[2], new_F.shape[3] + n_new_output_units), dtype=dtype)[:, :, :, -n_new_output_units:] * scaling_factor\n",
        "                b_growth = self.b_init(shape=(n_new_output_units,), dtype=dtype)  # TODO for all possible bias initializers to work properly, the whole bias vector should be initialized at once\n",
        "                new_F = tf.concat([new_F, F_growth], axis=-1)\n",
        "                new_b = tf.concat([self.b.value(), b_growth], axis=0)\n",
        "\n",
        "                self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
        "\n",
        "        self.F = tf.Variable(name='F', initial_value=new_F, trainable=True)\n",
        "\n",
        "        self.regularizer.grow(n_new_output_units)\n",
        "        return n_new_output_units\n",
        "    \n",
        "    def set_regularization_penalty(self, regularization_penalty):\n",
        "        if not self.fixed_size:\n",
        "            self.regularizer.set_regularization_penalty(regularization_penalty)\n",
        "    \n",
        "    def set_regularization_method(self, regularization_method):\n",
        "        if not self.fixed_size:\n",
        "            self.regularizer.set_regularization_method(regularization_method)\n",
        "\n",
        "    def get_param_string():\n",
        "        param_string = \"\"\n",
        "        # TODO\n",
        "        return param_string\n",
        "\n",
        "\n",
        "class Flatten(tf.keras.Model):\n",
        "    def call(self, inputs, training=None):\n",
        "        return tf.reshape(tf.transpose(inputs, perm=[0, 3, 1, 2]), (inputs.shape[0], -1))\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# MODELS\n",
        "################################################################################\n",
        "\n",
        "\n",
        "class Epoch:\n",
        "    def __init__(self, grow, prune, regularization_penalty, regularization_method):\n",
        "        self.grow = grow\n",
        "        self.prune = prune\n",
        "        self.regularization_penalty = regularization_penalty\n",
        "        self.regularization_method = regularization_method\n",
        "    \n",
        "    def __str__(self):\n",
        "        return f'{int(self.grow)}{int(self.prune)}{self.regularization_penalty}{self.regularization_method}'\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return self.__str__()\n",
        "\n",
        "\n",
        "class DynamicEpoch(Epoch):\n",
        "    def __init__(self, regularization_penalty, regularization_method):\n",
        "        super().__init__(True, True, regularization_penalty, regularization_method)\n",
        "\n",
        "\n",
        "class StaticEpoch(Epoch):\n",
        "    def __init__(self, regularization_penalty, regularization_method):\n",
        "        super().__init__(False, False, regularization_penalty, regularization_method)\n",
        "\n",
        "\n",
        "class StaticEpochNoRegularization(StaticEpoch):\n",
        "    def __init__(self):\n",
        "        super().__init__(0., None)\n",
        "\n",
        "\n",
        "class Schedule:\n",
        "    def __init__(self, epochs):\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self.epochs.__iter__()\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.epochs)\n",
        "    \n",
        "    def __str__(self):\n",
        "        text = ''.join([str(epoch) for epoch in self.epochs])\n",
        "        return hashlib.sha1(text.encode('utf-8')).hexdigest()[:10]\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return self.__str__()\n",
        "\n",
        "\n",
        "class Sequential(tf.keras.Model):\n",
        "    def __init__(self, layers, activation=None):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.lrs = layers\n",
        "        \n",
        "    def call(self, inputs, training=None):\n",
        "        x = inputs\n",
        "        for layer in self.lrs:\n",
        "            x = layer(x, training=training)\n",
        "        return x\n",
        "    \n",
        "    def get_layer_input_shape(self, target_layer):\n",
        "        if target_layer.inpt_shp is not None:\n",
        "            return target_layer.inpt_shp\n",
        "\n",
        "        input = np.random.normal(size=(1,) + self.lrs[0].inpt_shp)\n",
        "        for layer in self.lrs:\n",
        "            if layer is target_layer:\n",
        "                return tuple(input.shape[1:])\n",
        "            input = layer(input)\n",
        "        raise Exception(\"Layer not found in the model.\")\n",
        "\n",
        "    def get_layer_output_shape(self, target_layer):\n",
        "        input = np.random.normal(size=(1,) + self.lrs[0].inpt_shp)\n",
        "        for layer in self.lrs:\n",
        "            output = layer(input)\n",
        "            if layer is target_layer:\n",
        "                return tuple(output.shape[1:])\n",
        "            input = output\n",
        "        raise Exception(\"Layer not found in the model.\")\n",
        "    \n",
        "    def get_layer_sizes(self):\n",
        "        \"\"\"\n",
        "        Returns the sizes of all layers in the model, including the input and output layer.\n",
        "        \"\"\"\n",
        "        layer_sizes = list()\n",
        "        first_layer = True\n",
        "        for l in range(len(self.lrs)):\n",
        "            layer = self.lrs[l]\n",
        "            if isinstance(layer, CustomLayer):\n",
        "                layer_size = layer.get_size()\n",
        "                if first_layer:\n",
        "                    layer_sizes.append(layer_size[0])\n",
        "                    first_layer = False\n",
        "                layer_sizes.append(layer_size[1])\n",
        "        return layer_sizes\n",
        "    \n",
        "    def get_hidden_layer_sizes(self):\n",
        "        return self.get_layer_sizes()[1:-1]\n",
        "    \n",
        "    def get_regularization_penalty(self):\n",
        "        #TODO improve\n",
        "        return self.lrs[-2].regularizer.regularization_penalty\n",
        "    \n",
        "    def set_regularization_penalty(self, regularization_penalty):\n",
        "        for layer in self.lrs:\n",
        "            if isinstance(layer, CustomLayer) and not layer.fixed_size:\n",
        "                layer.set_regularization_penalty(regularization_penalty)\n",
        "    \n",
        "    def set_regularization_method(self, regularization_method):\n",
        "        for layer in self.lrs:\n",
        "            if isinstance(layer, CustomLayer) and not layer.fixed_size:\n",
        "                layer.set_regularization_method(regularization_method)\n",
        "\n",
        "    def prune(self, params):\n",
        "        input_shape = self.get_layer_input_shape(self.lrs[0])\n",
        "        n_input_units = input_shape[-1]\n",
        "        active_units_indices = list(range(n_input_units))\n",
        "\n",
        "        last_custom_layer = None\n",
        "        for layer in self.lrs:\n",
        "            if isinstance(layer, CustomLayer):\n",
        "                if last_custom_layer is not None and type(last_custom_layer) != type(layer):\n",
        "                    if type(last_custom_layer) == Conv2D and type(layer) == Dense:\n",
        "                        convolutional_shape = self.get_layer_output_shape(last_custom_layer)\n",
        "                        active_units_indices = self.convert_channel_indices_to_flattened_indices(active_units_indices, convolutional_shape)\n",
        "                    else:\n",
        "                        raise Exception(\"Incorrect order of custom layer types.\")\n",
        "                active_units_indices = layer.prune(params.pruning_threshold, active_units_indices)\n",
        "                last_custom_layer = layer\n",
        "    \n",
        "    def grow(self, params):   \n",
        "        n_new_units = 0\n",
        "\n",
        "        last_custom_layer = None\n",
        "        for layer in self.lrs:\n",
        "            if isinstance(layer, CustomLayer):\n",
        "                if last_custom_layer is not None and type(last_custom_layer) != type(layer):\n",
        "                    if type(last_custom_layer) == Conv2D and type(layer) == Dense:\n",
        "                        convolutional_shape = self.get_layer_output_shape(last_custom_layer)\n",
        "                        n_new_units = n_new_units * convolutional_shape[0] * convolutional_shape[1]\n",
        "                    else:\n",
        "                        raise Exception(\"Incorrect order of custom layer types.\")\n",
        "                n_new_units = layer.grow(n_new_units, params.growth_percentage, min_new_units=params.min_new_neurons, scaling_factor=params.pruning_threshold)\n",
        "                last_custom_layer = layer\n",
        "    \n",
        "    @staticmethod\n",
        "    def convert_channel_indices_to_flattened_indices(channel_indices, convolutional_shape):\n",
        "        dense_indices = list()\n",
        "        units_per_channel = convolutional_shape[0] * convolutional_shape[1]\n",
        "        for channel_index in channel_indices:\n",
        "            for iter in range(units_per_channel):\n",
        "                dense_indices.append(channel_index * units_per_channel + iter)\n",
        "        return dense_indices\n",
        "    \n",
        "    def print_neurons(self):\n",
        "        for layer in self.lrs[:-1]:\n",
        "            print(layer.get_param_string())\n",
        "    \n",
        "    def evaluate(self, params, summed_training_loss, summed_training_metric):\n",
        "        # Calculate training loss and metric\n",
        "        if summed_training_loss is not None:\n",
        "            loss = summed_training_loss / params.x.shape[0]\n",
        "        else:\n",
        "            loss = None\n",
        "        \n",
        "        if summed_training_metric is not None:\n",
        "            metric = summed_training_metric / params.x.shape[0]\n",
        "        else:\n",
        "            metric = None\n",
        "        \n",
        "        # Calculate val loss and metric\n",
        "        summed_val_loss = 0\n",
        "        summed_val_metric = 0\n",
        "        n_val_instances = 0\n",
        "        \n",
        "        for step, (x_batch, y_batch) in enumerate(params.val_dataset):\n",
        "            y_pred = self(x_batch, training=False)\n",
        "            summed_val_loss += tf.reduce_sum(params.loss_fn(y_batch, y_pred))\n",
        "            summed_val_metric += float(tf.reduce_sum(params.metric_fn(y_batch, y_pred)))\n",
        "            n_val_instances += x_batch.shape[0]\n",
        "        \n",
        "        val_loss = summed_val_loss / n_val_instances\n",
        "        val_metric = summed_val_metric / n_val_instances\n",
        "\n",
        "        return loss, metric, val_loss, val_metric\n",
        "    \n",
        "    def print_epoch_statistics(self, params, summed_training_loss, summed_training_metric, message=None, require_result=False):\n",
        "        if not params.verbose:\n",
        "            if require_result:\n",
        "                return self.evaluate(params, summed_training_loss, summed_training_metric)\n",
        "            else:\n",
        "                return\n",
        "        \n",
        "        loss, metric, val_loss, val_metric = self.evaluate(params, summed_training_loss, summed_training_metric)  \n",
        "\n",
        "        if message is not None:\n",
        "            print(message)\n",
        "        \n",
        "        print(f\"loss: {loss} - metric: {metric} - val_loss: {val_loss} - val_metric: {val_metric} - penalty: {self.get_regularization_penalty()}\")\n",
        "        hidden_layer_sizes = self.get_hidden_layer_sizes()\n",
        "        print(f\"hidden layer sizes: {hidden_layer_sizes}, total units: {sum(hidden_layer_sizes)}\")\n",
        "        if params.print_neurons:\n",
        "            self.print_neurons()\n",
        "        \n",
        "        if require_result:\n",
        "            return loss, metric, val_loss, val_metric\n",
        "    \n",
        "    def update_history(self, params, loss, metric, val_loss, val_metric):\n",
        "        params.history['loss'].append(loss)\n",
        "        params.history['metric'].append(metric)\n",
        "        params.history['val_loss'].append(val_loss)\n",
        "        params.history['val_metric'].append(val_metric)\n",
        "        params.history['hidden_layer_sizes'].append(self.get_hidden_layer_sizes())\n",
        "    \n",
        "    @staticmethod\n",
        "    def prepare_datasets(x, y, batch_size, validation_data):\n",
        "        train_dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "        train_dataset = train_dataset.shuffle(buffer_size=20000).batch(batch_size)\n",
        "        val_dataset = tf.data.Dataset.from_tensor_slices(validation_data).batch(batch_size)\n",
        "        return train_dataset.prefetch(tf.data.AUTOTUNE), val_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    \n",
        "    def manage_dynamic_regularization(self, params, val_loss):\n",
        "        if val_loss >= params.best_conditional_val_loss * params.stall_coefficient:\n",
        "            # Training is currently in stall\n",
        "            if not params.training_stalled:\n",
        "                penalty = self.get_regularization_penalty() * params.regularization_penalty_multiplier\n",
        "                print(\"Changing penalty...\")\n",
        "                # TODO this must be modified, penalty can differ for each layer\n",
        "                self.set_regularization_penalty(penalty)\n",
        "                params.training_stalled = True\n",
        "        else:\n",
        "            params.best_conditional_val_loss = val_loss\n",
        "            params.training_stalled = False\n",
        "    \n",
        "    def grow_wrapper(self, params):\n",
        "        dynamic_reqularization_active = params.regularization_penalty_multiplier != 1.\n",
        "        if dynamic_reqularization_active:\n",
        "            loss, metric, val_loss, val_metric = self.print_epoch_statistics(params, None, None, \"Before growing:\", require_result=True)\n",
        "            self.manage_dynamic_regularization(params, val_loss)\n",
        "        else:\n",
        "            self.print_epoch_statistics(params, None, None, \"Before growing:\")\n",
        "\n",
        "        self.grow(params)\n",
        "        self.print_epoch_statistics(params, None, None, \"After growing:\")\n",
        "    \n",
        "    def prune_wrapper(self, params, summed_loss, summed_metric):\n",
        "        loss, metric, _, _ = self.print_epoch_statistics(params, summed_loss, summed_metric, \"Before pruning:\", require_result=True)\n",
        "        self.prune(params)\n",
        "        _, _, val_loss, val_metric = self.print_epoch_statistics(params, None, None, \"After pruning:\", require_result=True)\n",
        "\n",
        "        self.update_history(params, loss, metric, val_loss, val_metric)\n",
        "    \n",
        "    class ParameterContainer:\n",
        "        def __init__(self, x, y, optimizer, batch_size, min_new_neurons, validation_data, pruning_threshold, regularization_penalty_multiplier, \n",
        "                     stall_coefficient, growth_percentage, mini_epochs_per_epoch, verbose, print_neurons, use_static_graph, loss_fn, metric_fn):\n",
        "            self.x = x\n",
        "            self.y = y\n",
        "            self.optimizer = optimizer\n",
        "            self.batch_size = batch_size\n",
        "            self.min_new_neurons = min_new_neurons\n",
        "            self.validation_data = validation_data\n",
        "            self.pruning_threshold = pruning_threshold\n",
        "            self.regularization_penalty_multiplier = regularization_penalty_multiplier\n",
        "            self.stall_coefficient = stall_coefficient\n",
        "            self.growth_percentage = growth_percentage\n",
        "            self.mini_epochs_per_epoch = mini_epochs_per_epoch\n",
        "            self.verbose = verbose\n",
        "            self.print_neurons = print_neurons\n",
        "            self.use_static_graph = use_static_graph\n",
        "            self.loss_fn = loss_fn\n",
        "            self.metric_fn = metric_fn\n",
        "\n",
        "            self.train_dataset, self.val_dataset = Sequential.prepare_datasets(x, y, batch_size, validation_data)\n",
        "            self.history = self.prepare_history()\n",
        "\n",
        "            self.best_conditional_val_loss = np.inf\n",
        "            self.training_stalled = False\n",
        "        \n",
        "        @staticmethod\n",
        "        def prepare_history():\n",
        "            history = {\n",
        "                'loss': list(),\n",
        "                'metric': list(),\n",
        "                'val_loss': list(),\n",
        "                'val_metric': list(),\n",
        "                'hidden_layer_sizes': list(),\n",
        "            }\n",
        "            return history\n",
        "    \n",
        "    def fit_single_step(self, params, x_batch, y_batch):\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x_batch, training=True)\n",
        "            raw_loss = params.loss_fn(y_batch, y_pred)\n",
        "            loss_value = tf.reduce_mean(raw_loss)\n",
        "            loss_value += sum(self.losses)  # Add losses registered by model.add_loss\n",
        "\n",
        "            loss = tf.reduce_sum(raw_loss)\n",
        "            metric = float(tf.reduce_sum(params.metric_fn(y_batch, y_pred)))\n",
        "\n",
        "        grads = tape.gradient(loss_value, self.trainable_variables)\n",
        "        params.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
        "\n",
        "        return loss, metric\n",
        "    \n",
        "    def fit_single_epoch(self, params):\n",
        "        summed_loss = 0\n",
        "        summed_metric = 0\n",
        "        \n",
        "        for mini_epoch in range(params.mini_epochs_per_epoch):\n",
        "            summed_loss = 0\n",
        "            summed_metric = 0\n",
        "\n",
        "            if params.use_static_graph:\n",
        "                fit_single_step_function = tf.function(self.fit_single_step)\n",
        "            else:\n",
        "                fit_single_step_function = self.fit_single_step\n",
        "            for step, (x_batch, y_batch) in enumerate(params.train_dataset):\n",
        "                loss, metric = fit_single_step_function(params, x_batch, y_batch)\n",
        "                summed_loss += loss\n",
        "                summed_metric += metric\n",
        "        \n",
        "        return summed_loss, summed_metric\n",
        "\n",
        "    def fit(self, x, y, optimizer, schedule, batch_size, min_new_neurons, validation_data, pruning_threshold=0.001, regularization_penalty_multiplier=1., \n",
        "            stall_coefficient=1, growth_percentage=0.2, mini_epochs_per_epoch=1, verbose=True, print_neurons=False, use_static_graph=True, \n",
        "            loss_fn=tf.keras.losses.sparse_categorical_crossentropy, metric_fn=tf.keras.metrics.sparse_categorical_accuracy):\n",
        "        params = self.ParameterContainer(x=x, y=y, optimizer=optimizer, batch_size=batch_size, min_new_neurons=min_new_neurons, validation_data=validation_data, \n",
        "                                         pruning_threshold=pruning_threshold, regularization_penalty_multiplier=regularization_penalty_multiplier, stall_coefficient=stall_coefficient, \n",
        "                                         growth_percentage=growth_percentage, mini_epochs_per_epoch=mini_epochs_per_epoch, verbose=verbose, print_neurons=print_neurons, \n",
        "                                         use_static_graph=use_static_graph, loss_fn=loss_fn, metric_fn=metric_fn)\n",
        "        self.build(x.shape)  # Necessary when verbose == False\n",
        "\n",
        "        for epoch_no, epoch in enumerate(schedule):\n",
        "            if verbose:\n",
        "                print(\"##########################################################\")\n",
        "                print(f\"Epoch {epoch_no + 1}/{len(schedule)}\")\n",
        "            \n",
        "            self.set_regularization_penalty(epoch.regularization_penalty)\n",
        "            self.set_regularization_method(epoch.regularization_method)\n",
        "\n",
        "            if epoch.grow:\n",
        "                self.grow_wrapper(params)\n",
        "            \n",
        "            summed_loss, summed_metric = self.fit_single_epoch(params)\n",
        "\n",
        "            if epoch.prune:\n",
        "                self.prune_wrapper(params, summed_loss, summed_metric)\n",
        "            else:\n",
        "                loss, metric, val_loss, val_metric = self.print_epoch_statistics(params, summed_loss, summed_metric, require_result=True)\n",
        "                self.update_history(params, loss, metric, val_loss, val_metric)\n",
        "        \n",
        "        return params.history\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# HELPER FUNCTIONS\n",
        "################################################################################\n",
        "\n",
        "\n",
        "def get_statistics_from_history(history):\n",
        "    best_epoch_number = np.argmin(history['val_loss'])\n",
        "    best_val_loss = history['val_loss'][best_epoch_number]\n",
        "    best_val_metric = history['val_metric'][best_epoch_number]\n",
        "    best_hidden_layer_sizes = history['hidden_layer_sizes'][best_epoch_number]\n",
        "    return best_val_loss, best_val_metric, best_hidden_layer_sizes\n",
        "\n",
        "\n",
        "def get_statistics_from_histories(histories):\n",
        "    best_val_losses = list()\n",
        "    best_val_metrics = list()\n",
        "    all_best_hidden_layer_sizes = list()\n",
        "\n",
        "    for history in histories:\n",
        "        best_val_loss, best_val_metric, best_hidden_layer_sizes = get_statistics_from_history(history)\n",
        "        best_val_losses.append(best_val_loss)\n",
        "        best_val_metrics.append(best_val_metric)\n",
        "        all_best_hidden_layer_sizes.append(best_hidden_layer_sizes)\n",
        "    \n",
        "    mean_best_val_loss = np.mean(best_val_losses)\n",
        "    mean_best_val_metric = np.mean(best_val_metrics)\n",
        "    mean_best_hidden_layer_sizes = [np.mean(layer) for layer in list(zip(*all_best_hidden_layer_sizes))]\n",
        "    \n",
        "    return mean_best_val_loss, mean_best_val_metric, mean_best_hidden_layer_sizes\n",
        "\n",
        "\n",
        "def cross_validate(train_fn, x, y, n_splits, random_state=42, *args, **kwargs):\n",
        "    from sklearn.model_selection import KFold\n",
        "\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "\n",
        "    histories = list()\n",
        "    for i, (train_index, test_index) in enumerate(kf.split(x)):\n",
        "        xtrain, xtest = x[train_index], x[test_index]\n",
        "        ytrain, ytest = y[train_index], y[test_index]\n",
        "\n",
        "        history = train_fn(xtrain, ytrain, validation_data=(xtest, ytest), *args, **kwargs)\n",
        "        histories.append(history)\n",
        "\n",
        "        best_val_loss, best_val_metric, best_hidden_layer_sizes = get_statistics_from_history(history)\n",
        "        print(f\"Run {i} completed, best_val_loss: {best_val_loss}, best_val_metric: {best_val_metric}, best_hidden_layer_sizes: {best_hidden_layer_sizes}\")\n",
        "\n",
        "    mean_best_val_loss, mean_best_val_metric, mean_best_hidden_layer_sizes = get_statistics_from_histories(histories)\n",
        "    print(f'mean_best_val_loss: {mean_best_val_loss}')\n",
        "    print(f'mean_best_val_metric: {mean_best_val_metric}')\n",
        "    print(f'mean_best_hidden_layer_sizes: {mean_best_hidden_layer_sizes}')\n",
        "\n",
        "    return histories, mean_best_hidden_layer_sizes\n",
        "\n",
        "\n",
        "def hyperparameter_search(train_fn, x, y, validation_data, *args, **kwargs):\n",
        "    from itertools import product\n",
        "\n",
        "    all_params = [*args] + list(kwargs.values())\n",
        "    histories = list()\n",
        "\n",
        "    best_overall_val_loss = np.inf\n",
        "    best_overall_val_metric = None\n",
        "    best_overall_combination = None\n",
        "\n",
        "    for combination in product(*all_params):\n",
        "        combination_args = combination[:len(args)]\n",
        "\n",
        "        combination_kwargs_values = combination[len(args):]\n",
        "        combination_kwargs = dict(zip(kwargs.keys(), combination_kwargs_values))\n",
        "\n",
        "        history = train_fn(x, y, validation_data, *combination_args, **combination_kwargs)\n",
        "        history['parameters'] = combination\n",
        "        histories.append(history)\n",
        "\n",
        "        best_val_loss, best_val_metric, best_hidden_layer_sizes = get_statistics_from_history(history)\n",
        "        print(f\"Run with parameters {combination} completed, best_val_loss: {best_val_loss}, best_val_metric: {best_val_metric}, best_hidden_layer_sizes: {best_hidden_layer_sizes}\")\n",
        "\n",
        "        if best_val_loss < best_overall_val_loss:\n",
        "            best_overall_val_loss = best_val_loss\n",
        "            best_overall_val_metric = best_val_metric\n",
        "            best_overall_combination = combination\n",
        "    \n",
        "    print(f'Best overall combination: {best_overall_combination}, val_metric: {best_overall_val_metric}')\n",
        "\n",
        "    return histories, best_overall_combination\n",
        "\n",
        "\n",
        "def get_convolutional_model(x, layer_sizes, output_neurons=10):\n",
        "    model = Sequential([\n",
        "        Conv2D(layer_sizes[0], filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', kernel_initializer='lecun_normal', input_shape=x[0,:,:,:].shape),\n",
        "        Conv2D(layer_sizes[1], filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(layer_sizes[2], filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', kernel_initializer='lecun_normal'),\n",
        "        Conv2D(layer_sizes[3], filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(layer_sizes[4], activation='selu', kernel_initializer='lecun_normal'),\n",
        "        Dense(output_neurons, activation='softmax', fixed_size=True),\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_dense_model(x, layer_sizes):\n",
        "    model = Sequential([\n",
        "        Dense(layer_sizes[0], activation='selu', kernel_initializer='lecun_normal', input_shape=x[0, :].shape),\n",
        "        Dense(layer_sizes[1], activation='selu', kernel_initializer='lecun_normal'),\n",
        "        Dense(layer_sizes[2], activation='selu', kernel_initializer='lecun_normal'),\n",
        "        # Dense(layer_sizes[3], activation='selu', kernel_initializer='lecun_normal'),\n",
        "        Dense(1, activation=None, fixed_size=True),\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_fn_conv(x, y, validation_data, learning_rate, schedule, layer_sizes, output_neurons=10, min_new_neurons=20, \n",
        "             growth_percentage=0.2, verbose=False, use_static_graph=True):\n",
        "    batch_size = 128\n",
        "\n",
        "    model = get_convolutional_model(x, layer_sizes, output_neurons)\n",
        "    \n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    history = model.fit(x=x, y=y, optimizer=optimizer, schedule=schedule, batch_size=batch_size, min_new_neurons=min_new_neurons, \n",
        "                        validation_data=validation_data, growth_percentage=growth_percentage, verbose=verbose, use_static_graph=use_static_graph)\n",
        "    \n",
        "    return history\n",
        "\n",
        "\n",
        "def train_fn_dense(x, y, validation_data, learning_rate, schedule, layer_sizes, min_new_neurons=20, \n",
        "             growth_percentage=0.2, verbose=False, use_static_graph=True):\n",
        "    batch_size = 128\n",
        "\n",
        "    model = get_dense_model(x, layer_sizes)\n",
        "    \n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    history = model.fit(x=x, y=y, optimizer=optimizer, schedule=schedule, batch_size=batch_size, min_new_neurons=min_new_neurons, \n",
        "                        validation_data=validation_data, growth_percentage=growth_percentage, verbose=verbose, use_static_graph=use_static_graph,\n",
        "                        loss_fn=tf.keras.losses.mean_squared_error, metric_fn=tf.keras.metrics.mean_squared_error)\n",
        "    \n",
        "    return history"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1MrQXUTFwOe"
      },
      "source": [
        "# Regression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fifteen_puzzle = get_fifteen_puzzle_dataset(frac=0.2)"
      ],
      "metadata": {
        "id": "inX5FRt-Y53t",
        "outputId": "e7679cee-6d90-45a2-a622-b85f4ee63429",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([DynamicEpoch(0.00002, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20)\n",
        "histories, best_overall_combination = hyperparameter_search(train_fn_dense, x=fifteen_puzzle.X_train_norm, y=fifteen_puzzle.y_train, validation_data=(fifteen_puzzle.X_test_norm, fifteen_puzzle.y_test), \n",
        "                                  learning_rate=[0.0001, 0.0002, 0.0004], schedule=[schedule], layer_sizes=[[100, 100, 100]], min_new_neurons=[20], growth_percentage=[0.2], verbose=[True])"
      ],
      "metadata": {
        "id": "ax1rlsHUVOSP",
        "outputId": "4ed0a5ca-abf9-4d72-865c-053b6ad0d2fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/40\n",
            "Before growing:\n",
            "loss: None - metric: None - val_loss: 1687.8966064453125 - val_metric: 1687.89544453125 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100], total units: 300\n",
            "After growing:\n",
            "loss: None - metric: None - val_loss: 1687.896484375 - val_metric: 1687.8954317708333 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120], total units: 360\n",
            "Before pruning:\n",
            "loss: 209.84051513671875 - metric: 209.84051513671875 - val_loss: 166.72499084472656 - val_metric: 166.7252125773112 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120], total units: 360\n",
            "After pruning:\n",
            "loss: None - metric: None - val_loss: 166.72499084472656 - val_metric: 166.7252125773112 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120], total units: 360\n",
            "##########################################################\n",
            "Epoch 2/40\n",
            "Before growing:\n",
            "loss: None - metric: None - val_loss: 166.72499084472656 - val_metric: 166.7252125773112 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120], total units: 360\n",
            "After growing:\n",
            "loss: None - metric: None - val_loss: 166.72499084472656 - val_metric: 166.72521249186198 - penalty: 2e-05\n",
            "hidden layer sizes: [144, 144, 144], total units: 432\n",
            "Before pruning:\n",
            "loss: 165.05780029296875 - metric: 165.05780029296875 - val_loss: 165.6662139892578 - val_metric: 165.6660707478841 - penalty: 2e-05\n",
            "hidden layer sizes: [144, 144, 144], total units: 432\n",
            "After pruning:\n",
            "loss: None - metric: None - val_loss: 165.6662139892578 - val_metric: 165.66607220458985 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 119, 120], total units: 359\n",
            "##########################################################\n",
            "Epoch 3/40\n",
            "Before growing:\n",
            "loss: None - metric: None - val_loss: 165.6662139892578 - val_metric: 165.66607220458985 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 119, 120], total units: 359\n",
            "After growing:\n",
            "loss: None - metric: None - val_loss: 165.6662139892578 - val_metric: 165.6660720662435 - penalty: 2e-05\n",
            "hidden layer sizes: [144, 142, 144], total units: 430\n",
            "Before pruning:\n",
            "loss: 164.92662048339844 - metric: 164.92662048339844 - val_loss: 165.6441192626953 - val_metric: 165.6441298421224 - penalty: 2e-05\n",
            "hidden layer sizes: [144, 142, 144], total units: 430\n",
            "After pruning:\n",
            "loss: None - metric: None - val_loss: 165.64413452148438 - val_metric: 165.64415338948567 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 111, 120], total units: 351\n",
            "##########################################################\n",
            "Epoch 4/40\n",
            "Before growing:\n",
            "loss: None - metric: None - val_loss: 165.64413452148438 - val_metric: 165.64415338948567 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 111, 120], total units: 351\n",
            "After growing:\n",
            "loss: None - metric: None - val_loss: 165.64413452148438 - val_metric: 165.6441531575521 - penalty: 2e-05\n",
            "hidden layer sizes: [144, 133, 144], total units: 421\n",
            "Before pruning:\n",
            "loss: 164.89471435546875 - metric: 164.89471435546875 - val_loss: 165.49630737304688 - val_metric: 165.49636397298178 - penalty: 2e-05\n",
            "hidden layer sizes: [144, 133, 144], total units: 421\n",
            "After pruning:\n",
            "loss: None - metric: None - val_loss: 165.49635314941406 - val_metric: 165.49638323974608 - penalty: 2e-05\n",
            "hidden layer sizes: [118, 100, 119], total units: 337\n",
            "##########################################################\n",
            "Epoch 5/40\n",
            "Before growing:\n",
            "loss: None - metric: None - val_loss: 165.49635314941406 - val_metric: 165.49638323974608 - penalty: 2e-05\n",
            "hidden layer sizes: [118, 100, 119], total units: 337\n",
            "After growing:\n",
            "loss: None - metric: None - val_loss: 165.49635314941406 - val_metric: 165.49638293863933 - penalty: 2e-05\n",
            "hidden layer sizes: [141, 120, 142], total units: 403\n",
            "Before pruning:\n",
            "loss: 164.8839111328125 - metric: 164.8839111328125 - val_loss: 165.52532958984375 - val_metric: 165.52538826904296 - penalty: 2e-05\n",
            "hidden layer sizes: [141, 120, 142], total units: 403\n",
            "After pruning:\n",
            "loss: None - metric: None - val_loss: 165.52520751953125 - val_metric: 165.52522844645182 - penalty: 2e-05\n",
            "hidden layer sizes: [117, 92, 119], total units: 328\n",
            "##########################################################\n",
            "Epoch 6/40\n",
            "Before growing:\n",
            "loss: None - metric: None - val_loss: 165.52520751953125 - val_metric: 165.52522844645182 - penalty: 2e-05\n",
            "hidden layer sizes: [117, 92, 119], total units: 328\n",
            "After growing:\n",
            "loss: None - metric: None - val_loss: 165.52520751953125 - val_metric: 165.52522832438152 - penalty: 2e-05\n",
            "hidden layer sizes: [140, 112, 142], total units: 394\n",
            "Before pruning:\n",
            "loss: 164.8745574951172 - metric: 164.8745574951172 - val_loss: 165.5309295654297 - val_metric: 165.53104407552084 - penalty: 2e-05\n",
            "hidden layer sizes: [140, 112, 142], total units: 394\n",
            "After pruning:\n",
            "loss: None - metric: None - val_loss: 165.5309295654297 - val_metric: 165.5310827392578 - penalty: 2e-05\n",
            "hidden layer sizes: [113, 84, 114], total units: 311\n",
            "##########################################################\n",
            "Epoch 7/40\n",
            "Before growing:\n",
            "loss: None - metric: None - val_loss: 165.5309295654297 - val_metric: 165.5310827392578 - penalty: 2e-05\n",
            "hidden layer sizes: [113, 84, 114], total units: 311\n",
            "After growing:\n",
            "loss: None - metric: None - val_loss: 165.5309295654297 - val_metric: 165.53108298746744 - penalty: 2e-05\n",
            "hidden layer sizes: [135, 104, 136], total units: 375\n",
            "Before pruning:\n",
            "loss: 164.88011169433594 - metric: 164.88011169433594 - val_loss: 165.46517944335938 - val_metric: 165.4653901529948 - penalty: 2e-05\n",
            "hidden layer sizes: [135, 104, 136], total units: 375\n",
            "After pruning:\n",
            "loss: None - metric: None - val_loss: 165.4651641845703 - val_metric: 165.4653784342448 - penalty: 2e-05\n",
            "hidden layer sizes: [110, 77, 110], total units: 297\n",
            "##########################################################\n",
            "Epoch 8/40\n",
            "Before growing:\n",
            "loss: None - metric: None - val_loss: 165.4651641845703 - val_metric: 165.4653784342448 - penalty: 2e-05\n",
            "hidden layer sizes: [110, 77, 110], total units: 297\n",
            "After growing:\n",
            "loss: None - metric: None - val_loss: 165.4651641845703 - val_metric: 165.46537841796874 - penalty: 2e-05\n",
            "hidden layer sizes: [132, 97, 132], total units: 361\n",
            "Before pruning:\n",
            "loss: 164.87442016601562 - metric: 164.87442016601562 - val_loss: 165.62249755859375 - val_metric: 165.6226314412435 - penalty: 2e-05\n",
            "hidden layer sizes: [132, 97, 132], total units: 361\n",
            "After pruning:\n",
            "loss: None - metric: None - val_loss: 165.62286376953125 - val_metric: 165.6229743774414 - penalty: 2e-05\n",
            "hidden layer sizes: [109, 77, 109], total units: 295\n",
            "##########################################################\n",
            "Epoch 9/40\n",
            "Before growing:\n",
            "loss: None - metric: None - val_loss: 165.62286376953125 - val_metric: 165.6229743774414 - penalty: 2e-05\n",
            "hidden layer sizes: [109, 77, 109], total units: 295\n",
            "After growing:\n",
            "loss: None - metric: None - val_loss: 165.62286376953125 - val_metric: 165.62297608235676 - penalty: 2e-05\n",
            "hidden layer sizes: [130, 97, 130], total units: 357\n",
            "Before pruning:\n",
            "loss: 164.87240600585938 - metric: 164.87240600585938 - val_loss: 165.47125244140625 - val_metric: 165.47129729410807 - penalty: 2e-05\n",
            "hidden layer sizes: [130, 97, 130], total units: 357\n",
            "After pruning:\n",
            "loss: None - metric: None - val_loss: 165.47122192382812 - val_metric: 165.47126959635418 - penalty: 2e-05\n",
            "hidden layer sizes: [105, 74, 109], total units: 288\n",
            "##########################################################\n",
            "Epoch 10/40\n",
            "Before growing:\n",
            "loss: None - metric: None - val_loss: 165.47122192382812 - val_metric: 165.47126959635418 - penalty: 2e-05\n",
            "hidden layer sizes: [105, 74, 109], total units: 288\n",
            "After growing:\n",
            "loss: None - metric: None - val_loss: 165.47122192382812 - val_metric: 165.4712696492513 - penalty: 2e-05\n",
            "hidden layer sizes: [126, 94, 130], total units: 350\n",
            "Before pruning:\n",
            "loss: 164.86297607421875 - metric: 164.86297607421875 - val_loss: 165.5205535888672 - val_metric: 165.5204528116862 - penalty: 2e-05\n",
            "hidden layer sizes: [126, 94, 130], total units: 350\n",
            "After pruning:\n",
            "loss: None - metric: None - val_loss: 165.52053833007812 - val_metric: 165.5203195719401 - penalty: 2e-05\n",
            "hidden layer sizes: [94, 70, 109], total units: 273\n",
            "##########################################################\n",
            "Epoch 11/40\n",
            "Before growing:\n",
            "loss: None - metric: None - val_loss: 165.52053833007812 - val_metric: 165.5203195719401 - penalty: 2e-05\n",
            "hidden layer sizes: [94, 70, 109], total units: 273\n",
            "After growing:\n",
            "loss: None - metric: None - val_loss: 165.52053833007812 - val_metric: 165.52031883951824 - penalty: 2e-05\n",
            "hidden layer sizes: [114, 90, 130], total units: 334\n",
            "Before pruning:\n",
            "loss: 164.85890197753906 - metric: 164.85890197753906 - val_loss: 165.45712280273438 - val_metric: 165.45713257242838 - penalty: 2e-05\n",
            "hidden layer sizes: [114, 90, 130], total units: 334\n",
            "After pruning:\n",
            "loss: None - metric: None - val_loss: 165.45712280273438 - val_metric: 165.4571323771159 - penalty: 2e-05\n",
            "hidden layer sizes: [91, 67, 106], total units: 264\n",
            "##########################################################\n",
            "Epoch 12/40\n",
            "Before growing:\n",
            "loss: None - metric: None - val_loss: 165.45712280273438 - val_metric: 165.4571323771159 - penalty: 2e-05\n",
            "hidden layer sizes: [91, 67, 106], total units: 264\n",
            "After growing:\n",
            "loss: None - metric: None - val_loss: 165.45712280273438 - val_metric: 165.45713266194662 - penalty: 2e-05\n",
            "hidden layer sizes: [111, 87, 127], total units: 325\n",
            "Before pruning:\n",
            "loss: 164.85536193847656 - metric: 164.85536193847656 - val_loss: 165.45184326171875 - val_metric: 165.4516104614258 - penalty: 2e-05\n",
            "hidden layer sizes: [111, 87, 127], total units: 325\n",
            "After pruning:\n",
            "loss: None - metric: None - val_loss: 165.45184326171875 - val_metric: 165.45162203776042 - penalty: 2e-05\n",
            "hidden layer sizes: [91, 64, 106], total units: 261\n",
            "##########################################################\n",
            "Epoch 13/40\n",
            "Before growing:\n",
            "loss: None - metric: None - val_loss: 165.45184326171875 - val_metric: 165.45162203776042 - penalty: 2e-05\n",
            "hidden layer sizes: [91, 64, 106], total units: 261\n",
            "After growing:\n",
            "loss: None - metric: None - val_loss: 165.45184326171875 - val_metric: 165.45162186279296 - penalty: 2e-05\n",
            "hidden layer sizes: [111, 84, 127], total units: 322\n",
            "Before pruning:\n",
            "loss: 164.85198974609375 - metric: 164.85198974609375 - val_loss: 165.6836395263672 - val_metric: 165.68361857910156 - penalty: 2e-05\n",
            "hidden layer sizes: [111, 84, 127], total units: 322\n",
            "After pruning:\n",
            "loss: None - metric: None - val_loss: 165.68362426757812 - val_metric: 165.68359541422527 - penalty: 2e-05\n",
            "hidden layer sizes: [88, 64, 105], total units: 257\n",
            "##########################################################\n",
            "Epoch 14/40\n",
            "Before growing:\n",
            "loss: None - metric: None - val_loss: 165.68362426757812 - val_metric: 165.68359541422527 - penalty: 2e-05\n",
            "hidden layer sizes: [88, 64, 105], total units: 257\n",
            "After growing:\n",
            "loss: None - metric: None - val_loss: 165.68362426757812 - val_metric: 165.6835951212565 - penalty: 2e-05\n",
            "hidden layer sizes: [108, 84, 126], total units: 318\n",
            "Before pruning:\n",
            "loss: 164.841796875 - metric: 164.841796875 - val_loss: 165.67161560058594 - val_metric: 165.6714920288086 - penalty: 2e-05\n",
            "hidden layer sizes: [108, 84, 126], total units: 318\n",
            "After pruning:\n",
            "loss: None - metric: None - val_loss: 165.67161560058594 - val_metric: 165.6714955932617 - penalty: 2e-05\n",
            "hidden layer sizes: [83, 63, 104], total units: 250\n",
            "##########################################################\n",
            "Epoch 15/40\n",
            "Before growing:\n",
            "loss: None - metric: None - val_loss: 165.67161560058594 - val_metric: 165.6714955932617 - penalty: 2e-05\n",
            "hidden layer sizes: [83, 63, 104], total units: 250\n",
            "After growing:\n",
            "loss: None - metric: None - val_loss: 165.67161560058594 - val_metric: 165.67149480387368 - penalty: 2e-05\n",
            "hidden layer sizes: [103, 83, 124], total units: 310\n",
            "Before pruning:\n",
            "loss: 164.84625244140625 - metric: 164.84625244140625 - val_loss: 165.45339965820312 - val_metric: 165.45325926920572 - penalty: 2e-05\n",
            "hidden layer sizes: [103, 83, 124], total units: 310\n",
            "After pruning:\n",
            "loss: None - metric: None - val_loss: 165.45339965820312 - val_metric: 165.45325858154297 - penalty: 2e-05\n",
            "hidden layer sizes: [81, 62, 104], total units: 247\n",
            "##########################################################\n",
            "Epoch 16/40\n",
            "Before growing:\n",
            "loss: None - metric: None - val_loss: 165.45339965820312 - val_metric: 165.45325858154297 - penalty: 2e-05\n",
            "hidden layer sizes: [81, 62, 104], total units: 247\n",
            "After growing:\n",
            "loss: None - metric: None - val_loss: 165.45339965820312 - val_metric: 165.45325883382162 - penalty: 2e-05\n",
            "hidden layer sizes: [101, 82, 124], total units: 307\n",
            "Before pruning:\n",
            "loss: 164.8423309326172 - metric: 164.8423309326172 - val_loss: 165.44857788085938 - val_metric: 165.4484494913737 - penalty: 2e-05\n",
            "hidden layer sizes: [101, 82, 124], total units: 307\n",
            "After pruning:\n",
            "loss: None - metric: None - val_loss: 165.44857788085938 - val_metric: 165.4484492553711 - penalty: 2e-05\n",
            "hidden layer sizes: [81, 64, 104], total units: 249\n",
            "##########################################################\n",
            "Epoch 17/40\n",
            "Before growing:\n",
            "loss: None - metric: None - val_loss: 165.44857788085938 - val_metric: 165.4484492553711 - penalty: 2e-05\n",
            "hidden layer sizes: [81, 64, 104], total units: 249\n",
            "After growing:\n",
            "loss: None - metric: None - val_loss: 165.44857788085938 - val_metric: 165.44844904785157 - penalty: 2e-05\n",
            "hidden layer sizes: [101, 84, 124], total units: 309\n",
            "Before pruning:\n",
            "loss: 164.83847045898438 - metric: 164.83847045898438 - val_loss: 165.44810485839844 - val_metric: 165.44819643147787 - penalty: 2e-05\n",
            "hidden layer sizes: [101, 84, 124], total units: 309\n",
            "After pruning:\n",
            "loss: None - metric: None - val_loss: 165.447998046875 - val_metric: 165.44818830159505 - penalty: 2e-05\n",
            "hidden layer sizes: [77, 63, 103], total units: 243\n",
            "##########################################################\n",
            "Epoch 18/40\n",
            "Before growing:\n",
            "loss: None - metric: None - val_loss: 165.447998046875 - val_metric: 165.44818830159505 - penalty: 2e-05\n",
            "hidden layer sizes: [77, 63, 103], total units: 243\n",
            "After growing:\n",
            "loss: None - metric: None - val_loss: 165.447998046875 - val_metric: 165.44818854980468 - penalty: 2e-05\n",
            "hidden layer sizes: [97, 83, 123], total units: 303\n",
            "Before pruning:\n",
            "loss: 164.8367156982422 - metric: 164.8367156982422 - val_loss: 165.4595489501953 - val_metric: 165.45972193603515 - penalty: 2e-05\n",
            "hidden layer sizes: [97, 83, 123], total units: 303\n",
            "After pruning:\n",
            "loss: None - metric: None - val_loss: 165.45953369140625 - val_metric: 165.4597185099284 - penalty: 2e-05\n",
            "hidden layer sizes: [73, 61, 102], total units: 236\n",
            "##########################################################\n",
            "Epoch 19/40\n",
            "Before growing:\n",
            "loss: None - metric: None - val_loss: 165.45953369140625 - val_metric: 165.4597185099284 - penalty: 2e-05\n",
            "hidden layer sizes: [73, 61, 102], total units: 236\n",
            "After growing:\n",
            "loss: None - metric: None - val_loss: 165.45953369140625 - val_metric: 165.45971876627604 - penalty: 2e-05\n",
            "hidden layer sizes: [93, 81, 122], total units: 296\n",
            "Before pruning:\n",
            "loss: 164.83509826660156 - metric: 164.83509826660156 - val_loss: 165.63748168945312 - val_metric: 165.63760289713542 - penalty: 2e-05\n",
            "hidden layer sizes: [93, 81, 122], total units: 296\n",
            "After pruning:\n",
            "loss: None - metric: None - val_loss: 165.63748168945312 - val_metric: 165.63764662679037 - penalty: 2e-05\n",
            "hidden layer sizes: [72, 60, 101], total units: 233\n",
            "##########################################################\n",
            "Epoch 20/40\n",
            "Before growing:\n",
            "loss: None - metric: None - val_loss: 165.63748168945312 - val_metric: 165.63764662679037 - penalty: 2e-05\n",
            "hidden layer sizes: [72, 60, 101], total units: 233\n",
            "After growing:\n",
            "loss: None - metric: None - val_loss: 165.63748168945312 - val_metric: 165.6376469156901 - penalty: 2e-05\n",
            "hidden layer sizes: [92, 80, 121], total units: 293\n",
            "Before pruning:\n",
            "loss: 164.8366241455078 - metric: 164.8366241455078 - val_loss: 165.5911102294922 - val_metric: 165.59118616536458 - penalty: 2e-05\n",
            "hidden layer sizes: [92, 80, 121], total units: 293\n",
            "After pruning:\n",
            "loss: None - metric: None - val_loss: 165.591064453125 - val_metric: 165.59117040201824 - penalty: 2e-05\n",
            "hidden layer sizes: [70, 68, 102], total units: 240\n",
            "##########################################################\n",
            "Epoch 21/40\n",
            "loss: 164.84315490722656 - metric: 164.84315490722656 - val_loss: 165.4958953857422 - val_metric: 165.49587537841796 - penalty: 0.0\n",
            "hidden layer sizes: [70, 68, 102], total units: 240\n",
            "##########################################################\n",
            "Epoch 22/40\n",
            "loss: 164.82196044921875 - metric: 164.82196044921875 - val_loss: 165.49813842773438 - val_metric: 165.49790482177735 - penalty: 0.0\n",
            "hidden layer sizes: [70, 68, 102], total units: 240\n",
            "##########################################################\n",
            "Epoch 23/40\n",
            "loss: 164.81973266601562 - metric: 164.81973266601562 - val_loss: 165.47657775878906 - val_metric: 165.4766086344401 - penalty: 0.0\n",
            "hidden layer sizes: [70, 68, 102], total units: 240\n",
            "##########################################################\n",
            "Epoch 24/40\n",
            "loss: 164.81809997558594 - metric: 164.81809997558594 - val_loss: 165.44674682617188 - val_metric: 165.4466631184896 - penalty: 0.0\n",
            "hidden layer sizes: [70, 68, 102], total units: 240\n",
            "##########################################################\n",
            "Epoch 25/40\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-c360f574f814>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\nschedule = Schedule([DynamicEpoch(0.00002, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20)\\nhistories, best_overall_combination = hyperparameter_search(train_fn_dense, x=fifteen_puzzle.X_train_norm, y=fifteen_puzzle.y_train, validation_data=(fifteen_puzzle.X_test_norm, fifteen_puzzle.y_test), \\n                                  learning_rate=[0.0001, 0.0002, 0.0004], schedule=[schedule], layer_sizes=[[100, 100, 100]], min_new_neurons=[20], growth_percentage=[0.2], verbose=[True])\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-12697064ea6e>\u001b[0m in \u001b[0;36mhyperparameter_search\u001b[0;34m(train_fn, x, y, validation_data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0mcombination_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombination_kwargs_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mcombination_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcombination_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m         \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parameters'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m         \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-12697064ea6e>\u001b[0m in \u001b[0;36mtrain_fn_dense\u001b[0;34m(x, y, validation_data, learning_rate, schedule, layer_sizes, min_new_neurons, growth_percentage, verbose, use_static_graph)\u001b[0m\n\u001b[1;32m   1008\u001b[0m     history = model.fit(x=x, y=y, optimizer=optimizer, schedule=schedule, batch_size=batch_size, min_new_neurons=min_new_neurons, \n\u001b[1;32m   1009\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrowth_percentage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrowth_percentage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_static_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_static_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m                         loss_fn=tf.keras.losses.mean_squared_error, metric_fn=tf.keras.metrics.mean_squared_error)\n\u001b[0m\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-12697064ea6e>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, optimizer, schedule, batch_size, min_new_neurons, validation_data, pruning_threshold, regularization_penalty_multiplier, stall_coefficient, growth_percentage, mini_epochs_per_epoch, verbose, print_neurons, use_static_graph, loss_fn, metric_fn)\u001b[0m\n\u001b[1;32m    864\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprune_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummed_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummed_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_epoch_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummed_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummed_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-12697064ea6e>\u001b[0m in \u001b[0;36mprint_epoch_statistics\u001b[0;34m(self, params, summed_training_loss, summed_training_metric, message, require_result)\u001b[0m\n\u001b[1;32m    709\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummed_training_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummed_training_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-12697064ea6e>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, params, summed_training_loss, summed_training_metric)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m             \u001b[0msummed_val_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0msummed_val_metric\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1081\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1082\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1083\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-12697064ea6e>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1081\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1082\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1083\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-12697064ea6e>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1381\u001b[0m         \u001b[0;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_same_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1383\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1384\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_add_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1731\u001b[0m   if not isinstance(y, ops.Tensor) and not isinstance(\n\u001b[1;32m   1732\u001b[0m       y, sparse_tensor.SparseTensor):\n\u001b[0;32m-> 1733\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1734\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1607\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1608\u001b[0m         ret = conversion_func(\n\u001b[0;32m-> 1609\u001b[0;31m             value, dtype=preferred_dtype, name=name, as_ref=as_ref)\n\u001b[0m\u001b[1;32m   1610\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1611\u001b[0m         \u001b[0;31m# Could not coerce the conversion to use the preferred dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_dense_var_to_tensor\u001b[0;34m(var, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   2061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2062\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_dense_var_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2063\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_var_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_dense_var_to_tensor\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1439\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iadd__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_other\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mvalue\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    588\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_existing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_read_variable_op\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m           \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mread_and_set_handle\u001b[0;34m()\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m       result = gen_resource_variable_ops.read_variable_op(\n\u001b[0;32m--> 690\u001b[0;31m           self.handle, self._dtype)\n\u001b[0m\u001b[1;32m    691\u001b[0m       \u001b[0m_maybe_set_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mread_variable_op\u001b[0;34m(resource, dtype, name)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m--> 471\u001b[0;31m         _ctx, \"ReadVariableOp\", name, resource, \"dtype\", dtype)\n\u001b[0m\u001b[1;32m    472\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([StaticEpochNoRegularization()] * 40)\n",
        "histories, best_overall_combination = hyperparameter_search(train_fn_dense, x=fifteen_puzzle.X_train_norm, y=fifteen_puzzle.y_train, validation_data=(fifteen_puzzle.X_test_norm, fifteen_puzzle.y_test), \n",
        "                                  learning_rate=[0.01, 0.001], schedule=[schedule], layer_sizes=[[500]], min_new_neurons=[20], growth_percentage=[0.2], verbose=[True])"
      ],
      "metadata": {
        "id": "W51RWp3_Nosv",
        "outputId": "6fe6231e-cbfd-40f9-f8e6-7f7c592bb248",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-be0da53f5f8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\nschedule = Schedule([StaticEpochNoRegularization()] * 40)\\nhistories, best_overall_combination = hyperparameter_search(train_fn_dense, x=fifteen_puzzle.X_train_norm, y=fifteen_puzzle.y_train, validation_data=(fifteen_puzzle.X_test_norm, fifteen_puzzle.y_test), \\n                                  learning_rate=[0.01, 0.001], schedule=[schedule], layer_sizes=[[500]], min_new_neurons=[20], growth_percentage=[0.2], verbose=[True])'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-12697064ea6e>\u001b[0m in \u001b[0;36mhyperparameter_search\u001b[0;34m(train_fn, x, y, validation_data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0mcombination_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombination_kwargs_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mcombination_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcombination_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m         \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parameters'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m         \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-12697064ea6e>\u001b[0m in \u001b[0;36mtrain_fn_dense\u001b[0;34m(x, y, validation_data, learning_rate, schedule, layer_sizes, min_new_neurons, growth_percentage, verbose, use_static_graph)\u001b[0m\n\u001b[1;32m   1002\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dense_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-12697064ea6e>\u001b[0m in \u001b[0;36mget_dense_model\u001b[0;34m(x, layer_sizes)\u001b[0m\n\u001b[1;32m    976\u001b[0m     model = Sequential([\n\u001b[1;32m    977\u001b[0m         \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'selu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lecun_normal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m         \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'selu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lecun_normal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m         \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'selu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lecun_normal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;31m# Dense(layer_sizes[3], activation='selu', kernel_initializer='lecun_normal'),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Legacy code"
      ],
      "metadata": {
        "id": "OVqa4IvxP2rZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rates = [0.0001 * 2 ** i for i in range(7)]\n",
        "learning_rates"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSsLiNHjWU6q",
        "outputId": "f2a1eb05-dc45-4826-8d2a-5791b302e161"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0001, 0.0002, 0.0004, 0.0008, 0.0016, 0.0032, 0.0064]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CIFAR100"
      ],
      "metadata": {
        "id": "l4mmt4NUZPrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cifar100 = get_cifar_100_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzVe14JzL4ve",
        "outputId": "750bb85e-7330-45e5-a3d7-fd8d076d9ede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 6s 0us/step\n",
            "169017344/169001437 [==============================] - 6s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([DynamicEpoch(0.00002, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20)\n",
        "histories, best_overall_combination = hyperparameter_search(train_fn, x=cifar100.X_train_norm, y=cifar100.y_train, validation_data=(cifar100.X_test_norm, cifar100.y_test), \n",
        "                                  learning_rate=[0.0001, 0.0002, 0.0004], schedule=[schedule], layer_sizes=[[100, 100, 100, 100, 100]], \n",
        "                                  output_neurons=[100], min_new_neurons=[20], growth_percentage=[0.2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "td7nnRPkOG0A",
        "outputId": "3fd61bd4-31a4-4ed8-b1cf-6c675379d0cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0001, ec4ba8ef9e, [100, 100, 100, 100, 100], 100, 20, 0.2) completed, best_val_accuracy: 0.44, best_hidden_layer_sizes sizes: [90, 29, 38, 43, 100]\n",
            "Run with parameters (0.0002, ec4ba8ef9e, [100, 100, 100, 100, 100], 100, 20, 0.2) completed, best_val_accuracy: 0.4448, best_hidden_layer_sizes sizes: [67, 23, 27, 73, 195]\n",
            "Run with parameters (0.0004, ec4ba8ef9e, [100, 100, 100, 100, 100], 100, 20, 0.2) completed, best_val_accuracy: 0.4358, best_hidden_layer_sizes sizes: [60, 18, 55, 120, 452]\n",
            "Best overall combination: (0.0002, ec4ba8ef9e, [100, 100, 100, 100, 100], 100, 20, 0.2), val_accuracy: 0.4448\n",
            "CPU times: user 9min 57s, sys: 20.8 s, total: 10min 18s\n",
            "Wall time: 9min 3s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_learning_rate = best_overall_combination[0]\n",
        "best_learning_rate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--jg7yrcdMOM",
        "outputId": "6eaeea7a-ca79-4212-e51e-4973e6ef24f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0002"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([DynamicEpoch(0.00002, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20)\n",
        "histories, mean_best_hidden_layer_sizes = cross_validate(\n",
        "    train_fn, cifar100.X_norm, cifar100.y, n_splits=6, learning_rate=best_learning_rate,\n",
        "    schedule=schedule, layer_sizes=[100, 100, 100, 100, 100], output_neurons=100, min_new_neurons=20, growth_percentage=0.2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WA3x6RkTlqt",
        "outputId": "ce80f1de-d326-4f44-bc37-03d906aedb13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best_val_accuracy: 0.4428, best_hidden_layer_sizes: [68, 19, 33, 74, 191]\n",
            "Run 1 completed, best_val_accuracy: 0.4512, best_hidden_layer_sizes: [62, 22, 29, 61, 195]\n",
            "Run 2 completed, best_val_accuracy: 0.4484, best_hidden_layer_sizes: [67, 19, 30, 61, 200]\n",
            "Run 3 completed, best_val_accuracy: 0.4485, best_hidden_layer_sizes: [67, 18, 33, 63, 199]\n",
            "Run 4 completed, best_val_accuracy: 0.4577, best_hidden_layer_sizes: [62, 20, 27, 62, 190]\n",
            "Run 5 completed, best_val_accuracy: 0.457, best_hidden_layer_sizes: [69, 23, 28, 66, 192]\n",
            "mean_best_val_accuracy: 0.45093333333333335\n",
            "mean_best_hidden_layer_sizes: [65.83333333333333, 20.166666666666668, 30.0, 64.5, 194.5]\n",
            "CPU times: user 19min 26s, sys: 41.6 s, total: 20min 8s\n",
            "Wall time: 17min 17s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rounded_mean_best_hidden_layer_sizes = [round(x) for x in mean_best_hidden_layer_sizes]\n",
        "rounded_mean_best_hidden_layer_sizes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3T6G7caLTKUb",
        "outputId": "359e5813-8b3c-423f-8ca4-a109f7984264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[66, 20, 30, 64, 194]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([StaticEpochNoRegularization()] * 40)\n",
        "histories, best_overall_combination = hyperparameter_search(train_fn, x=cifar100.X_train_norm, y=cifar100.y_train, validation_data=(cifar100.X_test_norm, cifar100.y_test), \n",
        "                                  learning_rate=[0.0001, 0.0002, 0.0004, 0.0008, 0.0016], schedule=[schedule], layer_sizes=[rounded_mean_best_hidden_layer_sizes], \n",
        "                                  output_neurons=[100], min_new_neurons=[20], growth_percentage=[0.2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vr-TsoVFaJbR",
        "outputId": "0453e6e8-733b-46ed-c90d-8314cfd5c88e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0001, 4a0f172746, [66, 20, 30, 64, 194], 100, 20, 0.2) completed, best_val_accuracy: 0.3397, best_hidden_layer_sizes sizes: [66, 20, 30, 64, 194]\n",
            "Run with parameters (0.0002, 4a0f172746, [66, 20, 30, 64, 194], 100, 20, 0.2) completed, best_val_accuracy: 0.3392, best_hidden_layer_sizes sizes: [66, 20, 30, 64, 194]\n",
            "Run with parameters (0.0004, 4a0f172746, [66, 20, 30, 64, 194], 100, 20, 0.2) completed, best_val_accuracy: 0.334, best_hidden_layer_sizes sizes: [66, 20, 30, 64, 194]\n",
            "Run with parameters (0.0008, 4a0f172746, [66, 20, 30, 64, 194], 100, 20, 0.2) completed, best_val_accuracy: 0.3272, best_hidden_layer_sizes sizes: [66, 20, 30, 64, 194]\n",
            "Run with parameters (0.0016, 4a0f172746, [66, 20, 30, 64, 194], 100, 20, 0.2) completed, best_val_accuracy: 0.3199, best_hidden_layer_sizes sizes: [66, 20, 30, 64, 194]\n",
            "Best overall combination: (0.0001, 4a0f172746, [66, 20, 30, 64, 194], 100, 20, 0.2), val_accuracy: 0.3397\n",
            "CPU times: user 11min 56s, sys: 29 s, total: 12min 25s\n",
            "Wall time: 9min 30s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_learning_rate = best_overall_combination[0]\n",
        "best_learning_rate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZzqgA1nmd7S",
        "outputId": "a4e73b2c-3ad8-40da-83c6-7742e995cc3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0001"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([StaticEpochNoRegularization()] * 40)\n",
        "histories, mean_best_hidden_layer_sizes = cross_validate(\n",
        "    train_fn, cifar100.X_norm, cifar100.y, n_splits=6, learning_rate=best_learning_rate,\n",
        "    schedule=schedule, layer_sizes=rounded_mean_best_hidden_layer_sizes, output_neurons=100, min_new_neurons=20, growth_percentage=0.2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RUzP8CXmgOI",
        "outputId": "82f33f74-804a-4bee-e87a-ed104da51e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best_val_accuracy: 0.3183, best_hidden_layer_sizes: [66, 20, 30, 64, 194]\n",
            "Run 1 completed, best_val_accuracy: 0.3265, best_hidden_layer_sizes: [66, 20, 30, 64, 194]\n",
            "Run 2 completed, best_val_accuracy: 0.3134, best_hidden_layer_sizes: [66, 20, 30, 64, 194]\n",
            "Run 3 completed, best_val_accuracy: 0.3345, best_hidden_layer_sizes: [66, 20, 30, 64, 194]\n",
            "Run 4 completed, best_val_accuracy: 0.325, best_hidden_layer_sizes: [66, 20, 30, 64, 194]\n",
            "Run 5 completed, best_val_accuracy: 0.3234, best_hidden_layer_sizes: [66, 20, 30, 64, 194]\n",
            "mean_best_val_accuracy: 0.3235166666666667\n",
            "mean_best_hidden_layer_sizes: [66.0, 20.0, 30.0, 64.0, 194.0]\n",
            "CPU times: user 14min 32s, sys: 34.6 s, total: 15min 7s\n",
            "Wall time: 11min 33s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Street View House Numbers"
      ],
      "metadata": {
        "id": "edvD6CfRmy9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svhn = get_svhn_dataset()"
      ],
      "metadata": {
        "id": "agjNnmNYnJnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([DynamicEpoch(0.00002, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20)\n",
        "histories, best_overall_combination = hyperparameter_search(train_fn, x=svhn.X_train_norm, y=svhn.y_train, validation_data=(svhn.X_test_norm, svhn.y_test), \n",
        "                                  learning_rate=[0.0001, 0.0002, 0.0004], schedule=[schedule], layer_sizes=[[100, 100, 100, 100, 100]], \n",
        "                                  output_neurons=[10], min_new_neurons=[20], growth_percentage=[0.2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsEq_PP8nQKV",
        "outputId": "4dd13533-fb4b-4edb-fc59-a1ea23960547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0001, ec4ba8ef9e, [100, 100, 100, 100, 100], 10, 20, 0.2) completed, best_val_accuracy: 0.9225568531038721, best_hidden_layer_sizes sizes: [35, 23, 18, 49, 56]\n",
            "Run with parameters (0.0002, ec4ba8ef9e, [100, 100, 100, 100, 100], 10, 20, 0.2) completed, best_val_accuracy: 0.9231330669944684, best_hidden_layer_sizes sizes: [23, 16, 18, 43, 68]\n",
            "Run with parameters (0.0004, ec4ba8ef9e, [100, 100, 100, 100, 100], 10, 20, 0.2) completed, best_val_accuracy: 0.9256684081130916, best_hidden_layer_sizes sizes: [17, 15, 27, 42, 172]\n",
            "Best overall combination: (0.0004, ec4ba8ef9e, [100, 100, 100, 100, 100], 10, 20, 0.2), val_accuracy: 0.9256684081130916\n",
            "CPU times: user 15min 7s, sys: 33.3 s, total: 15min 41s\n",
            "Wall time: 12min 49s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_learning_rate = best_overall_combination[0]\n",
        "best_learning_rate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnxsROtxpnkQ",
        "outputId": "52dd7e32-bd60-4c58-b5e0-0b1dbc2d5f57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0004"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([DynamicEpoch(0.00002, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20)\n",
        "histories, mean_best_hidden_layer_sizes = cross_validate(\n",
        "    train_fn, svhn.X_norm, svhn.y, n_splits=4, learning_rate=best_learning_rate,\n",
        "    schedule=schedule, layer_sizes=[100, 100, 100, 100, 100], output_neurons=10, min_new_neurons=20, growth_percentage=0.2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3dIJMnGpsBB",
        "outputId": "db81756b-5ca2-4917-f51e-1b60a11d45a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best_val_accuracy: 0.9326431132417516, best_hidden_layer_sizes: [19, 16, 17, 41, 148]\n",
            "Run 1 completed, best_val_accuracy: 0.9331238417532833, best_hidden_layer_sizes: [15, 17, 27, 48, 169]\n",
            "Run 2 completed, best_val_accuracy: 0.9300217548948514, best_hidden_layer_sizes: [18, 16, 19, 51, 158]\n",
            "Run 3 completed, best_val_accuracy: 0.929981468052534, best_hidden_layer_sizes: [16, 17, 21, 41, 159]\n",
            "mean_best_val_accuracy: 0.9314425444856052\n",
            "mean_best_hidden_layer_sizes: [17.0, 16.5, 21.0, 45.25, 158.5]\n",
            "CPU times: user 19min 51s, sys: 46.1 s, total: 20min 37s\n",
            "Wall time: 16min 40s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rounded_mean_best_hidden_layer_sizes = [round(x) for x in mean_best_hidden_layer_sizes]\n",
        "rounded_mean_best_hidden_layer_sizes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZ5wlnWSpsGS",
        "outputId": "b1fe69c9-d5e7-4e0c-f627-a26ef50e7cc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[17, 16, 21, 45, 158]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([StaticEpochNoRegularization()] * 40)\n",
        "histories, best_overall_combination = hyperparameter_search(train_fn, x=svhn.X_train_norm, y=svhn.y_train, validation_data=(svhn.X_test_norm, svhn.y_test), \n",
        "                                  learning_rate=[0.0001, 0.0002, 0.0004, 0.0008, 0.0016], schedule=[schedule], layer_sizes=[rounded_mean_best_hidden_layer_sizes], \n",
        "                                  output_neurons=[10], min_new_neurons=[20], growth_percentage=[0.2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGHdm0iJpsNJ",
        "outputId": "dce174f2-8ef4-4eb3-ba15-bcc2bc1faf28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0001, 4a0f172746, [17, 16, 21, 45, 158], 10, 20, 0.2) completed, best_val_accuracy: 0.8831438229870928, best_hidden_layer_sizes sizes: [17, 16, 21, 45, 158]\n",
            "Run with parameters (0.0002, 4a0f172746, [17, 16, 21, 45, 158], 10, 20, 0.2) completed, best_val_accuracy: 0.8705055316533498, best_hidden_layer_sizes sizes: [17, 16, 21, 45, 158]\n",
            "Run with parameters (0.0004, 4a0f172746, [17, 16, 21, 45, 158], 10, 20, 0.2) completed, best_val_accuracy: 0.8845651505838967, best_hidden_layer_sizes sizes: [17, 16, 21, 45, 158]\n",
            "Run with parameters (0.0008, 4a0f172746, [17, 16, 21, 45, 158], 10, 20, 0.2) completed, best_val_accuracy: 0.9056929932390904, best_hidden_layer_sizes sizes: [17, 16, 21, 45, 158]\n",
            "Run with parameters (0.0016, 4a0f172746, [17, 16, 21, 45, 158], 10, 20, 0.2) completed, best_val_accuracy: 0.8907882606023356, best_hidden_layer_sizes sizes: [17, 16, 21, 45, 158]\n",
            "Best overall combination: (0.0008, 4a0f172746, [17, 16, 21, 45, 158], 10, 20, 0.2), val_accuracy: 0.9056929932390904\n",
            "CPU times: user 19min 31s, sys: 47.7 s, total: 20min 19s\n",
            "Wall time: 15min 31s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_learning_rate = best_overall_combination[0]\n",
        "best_learning_rate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfwjPtX7qNim",
        "outputId": "2366acb7-4771-4781-8045-d798e9825ff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0008"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([StaticEpochNoRegularization()] * 40)\n",
        "histories, mean_best_hidden_layer_sizes = cross_validate(\n",
        "    train_fn, svhn.X_norm, svhn.y, n_splits=4, learning_rate=best_learning_rate,\n",
        "    schedule=schedule, layer_sizes=rounded_mean_best_hidden_layer_sizes, output_neurons=10, min_new_neurons=20, growth_percentage=0.2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MePaSfwqPSp",
        "outputId": "4e1feca5-e9a3-432a-8135-03af535d71c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best_val_accuracy: 0.9115739435201224, best_hidden_layer_sizes: [17, 16, 21, 45, 158]\n",
            "Run 1 completed, best_val_accuracy: 0.9151559100797679, best_hidden_layer_sizes: [17, 16, 21, 45, 158]\n",
            "Run 2 completed, best_val_accuracy: 0.9182177100958827, best_hidden_layer_sizes: [17, 16, 21, 45, 158]\n",
            "Run 3 completed, best_val_accuracy: 0.9090725968898558, best_hidden_layer_sizes: [17, 16, 21, 45, 158]\n",
            "mean_best_val_accuracy: 0.9135050401464072\n",
            "mean_best_hidden_layer_sizes: [17.0, 16.0, 21.0, 45.0, 158.0]\n",
            "CPU times: user 15min 31s, sys: 39.8 s, total: 16min 11s\n",
            "Wall time: 12min 19s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CIFAR10"
      ],
      "metadata": {
        "id": "M-FaQr8cro9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10 = get_cifar_10_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAyVYQ5Brqnq",
        "outputId": "cbe68b2e-9bc6-4974-8922-5fe63b46b145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n",
            "170508288/170498071 [==============================] - 6s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([DynamicEpoch(0.00002, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20)\n",
        "histories, best_overall_combination = hyperparameter_search(train_fn, x=cifar10.X_train_norm, y=cifar10.y_train, validation_data=(cifar10.X_test_norm, cifar10.y_test), \n",
        "                                  learning_rate=[0.0001, 0.0002, 0.0004], schedule=[schedule], layer_sizes=[[100, 100, 100, 100, 100]], \n",
        "                                  output_neurons=[10], min_new_neurons=[20], growth_percentage=[0.2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcPnlUpKrqux",
        "outputId": "48c969c5-edae-469d-8ee3-39da289c21ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0001, ec4ba8ef9e, [100, 100, 100, 100, 100], 10, 20, 0.2) completed, best_val_accuracy: 0.7309, best_hidden_layer_sizes sizes: [86, 24, 32, 48, 51]\n",
            "Run with parameters (0.0002, ec4ba8ef9e, [100, 100, 100, 100, 100], 10, 20, 0.2) completed, best_val_accuracy: 0.7502, best_hidden_layer_sizes sizes: [58, 18, 25, 48, 78]\n",
            "Run with parameters (0.0004, ec4ba8ef9e, [100, 100, 100, 100, 100], 10, 20, 0.2) completed, best_val_accuracy: 0.7699, best_hidden_layer_sizes sizes: [38, 20, 21, 56, 161]\n",
            "Best overall combination: (0.0004, ec4ba8ef9e, [100, 100, 100, 100, 100], 10, 20, 0.2), val_accuracy: 0.7699\n",
            "CPU times: user 9min 51s, sys: 19.3 s, total: 10min 11s\n",
            "Wall time: 8min 38s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_learning_rate = best_overall_combination[0]\n",
        "best_learning_rate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c_COXAgrqyJ",
        "outputId": "536489da-0042-4477-f37d-2c0092e79794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0004"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([DynamicEpoch(0.00002, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20)\n",
        "histories, mean_best_hidden_layer_sizes = cross_validate(\n",
        "    train_fn, cifar10.X_norm, cifar10.y, n_splits=6, learning_rate=best_learning_rate,\n",
        "    schedule=schedule, layer_sizes=[100, 100, 100, 100, 100], output_neurons=10, min_new_neurons=20, growth_percentage=0.2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DQlPH90rq1l",
        "outputId": "79afd198-1fd8-4e4d-d4f7-88ffcd7823e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best_val_accuracy: 0.7729, best_hidden_layer_sizes: [41, 16, 27, 59, 215]\n",
            "Run 1 completed, best_val_accuracy: 0.7684, best_hidden_layer_sizes: [39, 17, 32, 55, 147]\n",
            "Run 2 completed, best_val_accuracy: 0.773, best_hidden_layer_sizes: [38, 19, 24, 54, 177]\n",
            "Run 3 completed, best_val_accuracy: 0.7674, best_hidden_layer_sizes: [37, 20, 22, 67, 174]\n",
            "Run 4 completed, best_val_accuracy: 0.7749, best_hidden_layer_sizes: [38, 18, 26, 57, 145]\n",
            "Run 5 completed, best_val_accuracy: 0.7662, best_hidden_layer_sizes: [42, 19, 25, 51, 192]\n",
            "mean_best_val_accuracy: 0.7704666666666666\n",
            "mean_best_hidden_layer_sizes: [39.166666666666664, 18.166666666666668, 26.0, 57.166666666666664, 175.0]\n",
            "CPU times: user 19min 26s, sys: 39 s, total: 20min 5s\n",
            "Wall time: 16min 45s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rounded_mean_best_hidden_layer_sizes = [round(x) for x in mean_best_hidden_layer_sizes]\n",
        "rounded_mean_best_hidden_layer_sizes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_1Gql57rq4v",
        "outputId": "13768f9d-5395-4c86-8e40-8c2dabac552e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[39, 18, 26, 57, 175]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([StaticEpochNoRegularization()] * 40)\n",
        "histories, best_overall_combination = hyperparameter_search(train_fn, x=cifar10.X_train_norm, y=cifar10.y_train, validation_data=(cifar10.X_test_norm, cifar10.y_test), \n",
        "                                  learning_rate=[0.0001, 0.0002, 0.0004, 0.0008, 0.0016, 0.0032], schedule=[schedule], layer_sizes=[rounded_mean_best_hidden_layer_sizes], \n",
        "                                  output_neurons=[10], min_new_neurons=[20], growth_percentage=[0.2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6BK6222sD1m",
        "outputId": "d357bdf1-ef16-4752-d5ae-3e69abfd0c5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0001, 4a0f172746, [39, 18, 26, 57, 175], 10, 20, 0.2) completed, best_val_accuracy: 0.6574, best_hidden_layer_sizes sizes: [39, 18, 26, 57, 175]\n",
            "Run with parameters (0.0002, 4a0f172746, [39, 18, 26, 57, 175], 10, 20, 0.2) completed, best_val_accuracy: 0.6557, best_hidden_layer_sizes sizes: [39, 18, 26, 57, 175]\n",
            "Run with parameters (0.0004, 4a0f172746, [39, 18, 26, 57, 175], 10, 20, 0.2) completed, best_val_accuracy: 0.6811, best_hidden_layer_sizes sizes: [39, 18, 26, 57, 175]\n",
            "Run with parameters (0.0008, 4a0f172746, [39, 18, 26, 57, 175], 10, 20, 0.2) completed, best_val_accuracy: 0.7077, best_hidden_layer_sizes sizes: [39, 18, 26, 57, 175]\n",
            "Run with parameters (0.0016, 4a0f172746, [39, 18, 26, 57, 175], 10, 20, 0.2) completed, best_val_accuracy: 0.7281, best_hidden_layer_sizes sizes: [39, 18, 26, 57, 175]\n",
            "Run with parameters (0.0032, 4a0f172746, [39, 18, 26, 57, 175], 10, 20, 0.2) completed, best_val_accuracy: 0.7032, best_hidden_layer_sizes sizes: [39, 18, 26, 57, 175]\n",
            "Best overall combination: (0.0016, 4a0f172746, [39, 18, 26, 57, 175], 10, 20, 0.2), val_accuracy: 0.7281\n",
            "CPU times: user 14min 41s, sys: 34.4 s, total: 15min 15s\n",
            "Wall time: 11min 40s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_learning_rate = best_overall_combination[0]\n",
        "best_learning_rate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LnzcDWasD4P",
        "outputId": "2afff0a6-8e0c-467b-cf8e-071f4708b352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0016"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([StaticEpochNoRegularization()] * 40)\n",
        "histories, mean_best_hidden_layer_sizes = cross_validate(\n",
        "    train_fn, cifar10.X_norm, cifar10.y, n_splits=6, learning_rate=best_learning_rate,\n",
        "    schedule=schedule, layer_sizes=rounded_mean_best_hidden_layer_sizes, output_neurons=10, min_new_neurons=20, growth_percentage=0.2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TjO54M6sD7J",
        "outputId": "c7b4d272-870e-44e2-9731-78a7325a7771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best_val_accuracy: 0.7312, best_hidden_layer_sizes: [39, 18, 26, 57, 175]\n",
            "Run 1 completed, best_val_accuracy: 0.7296, best_hidden_layer_sizes: [39, 18, 26, 57, 175]\n",
            "Run 2 completed, best_val_accuracy: 0.7286, best_hidden_layer_sizes: [39, 18, 26, 57, 175]\n",
            "Run 3 completed, best_val_accuracy: 0.7299, best_hidden_layer_sizes: [39, 18, 26, 57, 175]\n",
            "Run 4 completed, best_val_accuracy: 0.7389, best_hidden_layer_sizes: [39, 18, 26, 57, 175]\n",
            "Run 5 completed, best_val_accuracy: 0.7186, best_hidden_layer_sizes: [39, 18, 26, 57, 175]\n",
            "mean_best_val_accuracy: 0.7294666666666667\n",
            "mean_best_hidden_layer_sizes: [39.0, 18.0, 26.0, 57.0, 175.0]\n",
            "CPU times: user 14min 48s, sys: 38.2 s, total: 15min 26s\n",
            "Wall time: 11min 49s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fashion MNIST"
      ],
      "metadata": {
        "id": "vLDo_10YsgNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = get_fashion_mnist_dataset()"
      ],
      "metadata": {
        "id": "_ipVjRDqrq8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([DynamicEpoch(0.00002, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20)\n",
        "histories, best_overall_combination = hyperparameter_search(train_fn, x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test), \n",
        "                                  learning_rate=[0.0001, 0.0002, 0.0004], schedule=[schedule], layer_sizes=[[100, 100, 100, 100, 100]], \n",
        "                                  output_neurons=[10], min_new_neurons=[20], growth_percentage=[0.2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g43wcgugsuIh",
        "outputId": "5b00a71a-de2d-4971-ea07-c13d4d6f2003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0001, ec4ba8ef9e, [100, 100, 100, 100, 100], 10, 20, 0.2) completed, best_val_accuracy: 0.9215, best_hidden_layer_sizes sizes: [50, 20, 18, 42, 49]\n",
            "Run with parameters (0.0002, ec4ba8ef9e, [100, 100, 100, 100, 100], 10, 20, 0.2) completed, best_val_accuracy: 0.9263, best_hidden_layer_sizes sizes: [35, 15, 20, 30, 77]\n",
            "Run with parameters (0.0004, ec4ba8ef9e, [100, 100, 100, 100, 100], 10, 20, 0.2) completed, best_val_accuracy: 0.931, best_hidden_layer_sizes sizes: [28, 13, 28, 31, 119]\n",
            "Best overall combination: (0.0004, ec4ba8ef9e, [100, 100, 100, 100, 100], 10, 20, 0.2), val_accuracy: 0.931\n",
            "CPU times: user 8min 13s, sys: 20.3 s, total: 8min 33s\n",
            "Wall time: 7min 29s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_learning_rate = best_overall_combination[0]\n",
        "best_learning_rate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnaZ5sW6svYn",
        "outputId": "6626998b-be51-495e-b151-47ce32c8188c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0004"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([DynamicEpoch(0.00002, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20)\n",
        "histories, mean_best_hidden_layer_sizes = cross_validate(\n",
        "    train_fn, fashion_mnist.X_norm, fashion_mnist.y, n_splits=7, learning_rate=best_learning_rate,\n",
        "    schedule=schedule, layer_sizes=[100, 100, 100, 100, 100], output_neurons=10, min_new_neurons=20, growth_percentage=0.2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkOlyqQbsvbB",
        "outputId": "df3528ae-7ace-44b9-fe1f-d327dde242ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best_val_accuracy: 0.9333, best_hidden_layer_sizes: [25, 15, 24, 35, 121]\n",
            "Run 1 completed, best_val_accuracy: 0.9314, best_hidden_layer_sizes: [25, 13, 30, 39, 108]\n",
            "Run 2 completed, best_val_accuracy: 0.9313, best_hidden_layer_sizes: [23, 14, 31, 35, 119]\n",
            "Run 3 completed, best_val_accuracy: 0.9325, best_hidden_layer_sizes: [22, 14, 12, 40, 113]\n",
            "Run 4 completed, best_val_accuracy: 0.9384, best_hidden_layer_sizes: [21, 15, 18, 32, 141]\n",
            "Run 5 completed, best_val_accuracy: 0.9298, best_hidden_layer_sizes: [19, 17, 19, 38, 122]\n",
            "Run 6 completed, best_val_accuracy: 0.9321, best_hidden_layer_sizes: [20, 15, 15, 33, 143]\n",
            "mean_best_val_accuracy: 0.9326857142857143\n",
            "mean_best_hidden_layer_sizes: [22.142857142857142, 14.714285714285714, 21.285714285714285, 36.0, 123.85714285714286]\n",
            "CPU times: user 19min 2s, sys: 49.2 s, total: 19min 51s\n",
            "Wall time: 16min 58s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rounded_mean_best_hidden_layer_sizes = [round(x) for x in mean_best_hidden_layer_sizes]\n",
        "rounded_mean_best_hidden_layer_sizes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Plo75e8lsvdj",
        "outputId": "a72138eb-802a-4366-c28d-39c88393be56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[22, 15, 21, 36, 124]"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([StaticEpochNoRegularization()] * 40)\n",
        "histories, best_overall_combination = hyperparameter_search(train_fn, x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test), \n",
        "                                  learning_rate=[0.0001, 0.0002, 0.0004, 0.0008, 0.0016, 0.0032], schedule=[schedule], layer_sizes=[rounded_mean_best_hidden_layer_sizes], \n",
        "                                  output_neurons=[10], min_new_neurons=[20], growth_percentage=[0.2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPLGINjQsvgd",
        "outputId": "e9f81dc7-0284-4cc5-e4c3-5cadc5788c5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0001, 4a0f172746, [22, 15, 21, 36, 124], 10, 20, 0.2) completed, best_val_accuracy: 0.9066, best_hidden_layer_sizes sizes: [22, 15, 21, 36, 124]\n",
            "Run with parameters (0.0002, 4a0f172746, [22, 15, 21, 36, 124], 10, 20, 0.2) completed, best_val_accuracy: 0.9126, best_hidden_layer_sizes sizes: [22, 15, 21, 36, 124]\n",
            "Run with parameters (0.0004, 4a0f172746, [22, 15, 21, 36, 124], 10, 20, 0.2) completed, best_val_accuracy: 0.921, best_hidden_layer_sizes sizes: [22, 15, 21, 36, 124]\n",
            "Run with parameters (0.0008, 4a0f172746, [22, 15, 21, 36, 124], 10, 20, 0.2) completed, best_val_accuracy: 0.9189, best_hidden_layer_sizes sizes: [22, 15, 21, 36, 124]\n",
            "Run with parameters (0.0016, 4a0f172746, [22, 15, 21, 36, 124], 10, 20, 0.2) completed, best_val_accuracy: 0.9187, best_hidden_layer_sizes sizes: [22, 15, 21, 36, 124]\n",
            "Run with parameters (0.0032, 4a0f172746, [22, 15, 21, 36, 124], 10, 20, 0.2) completed, best_val_accuracy: 0.9066, best_hidden_layer_sizes sizes: [22, 15, 21, 36, 124]\n",
            "Best overall combination: (0.0004, 4a0f172746, [22, 15, 21, 36, 124], 10, 20, 0.2), val_accuracy: 0.921\n",
            "CPU times: user 13min 8s, sys: 35.1 s, total: 13min 43s\n",
            "Wall time: 10min 55s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_learning_rate = best_overall_combination[0]\n",
        "best_learning_rate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBMFxM9VszsW",
        "outputId": "20d6890f-a737-47b2-be36-68add8cae092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0004"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([StaticEpochNoRegularization()] * 40)\n",
        "histories, mean_best_hidden_layer_sizes = cross_validate(\n",
        "    train_fn, fashion_mnist.X_norm, fashion_mnist.y, n_splits=7, learning_rate=best_learning_rate,\n",
        "    schedule=schedule, layer_sizes=rounded_mean_best_hidden_layer_sizes, output_neurons=10, min_new_neurons=20, growth_percentage=0.2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVO0wAZUszx0",
        "outputId": "a6c6f687-95f7-4743-bd7e-95d05abd020b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best_val_accuracy: 0.923, best_hidden_layer_sizes: [22, 15, 21, 36, 124]\n",
            "Run 1 completed, best_val_accuracy: 0.9246, best_hidden_layer_sizes: [22, 15, 21, 36, 124]\n",
            "Run 2 completed, best_val_accuracy: 0.9233, best_hidden_layer_sizes: [22, 15, 21, 36, 124]\n",
            "Run 3 completed, best_val_accuracy: 0.9269, best_hidden_layer_sizes: [22, 15, 21, 36, 124]\n",
            "Run 4 completed, best_val_accuracy: 0.9218, best_hidden_layer_sizes: [22, 15, 21, 36, 124]\n",
            "Run 5 completed, best_val_accuracy: 0.9249, best_hidden_layer_sizes: [22, 15, 21, 36, 124]\n",
            "Run 6 completed, best_val_accuracy: 0.9231, best_hidden_layer_sizes: [22, 15, 21, 36, 124]\n",
            "mean_best_val_accuracy: 0.9239428571428572\n",
            "mean_best_hidden_layer_sizes: [22.0, 15.0, 21.0, 36.0, 124.0]\n",
            "CPU times: user 15min 17s, sys: 41 s, total: 15min 58s\n",
            "Wall time: 12min 44s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MNIST"
      ],
      "metadata": {
        "id": "yq2h8XESsjwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = get_mnist_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5lL2sS2slBO",
        "outputId": "aaff070b-c6f5-4217-f8d7-5467c7dd77a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([DynamicEpoch(0.00002, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20)\n",
        "histories, best_overall_combination = hyperparameter_search(train_fn, x=mnist.X_train_norm, y=mnist.y_train, validation_data=(mnist.X_test_norm, mnist.y_test), \n",
        "                                  learning_rate=[0.0001, 0.0002, 0.0004], schedule=[schedule], layer_sizes=[[100, 100, 100, 100, 100]], \n",
        "                                  output_neurons=[10], min_new_neurons=[20], growth_percentage=[0.2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nj58iVyUtVEX",
        "outputId": "0b7076a6-73b0-4d0b-9ec4-b15ee4f3807f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0001, ec4ba8ef9e, [100, 100, 100, 100, 100], 10, 20, 0.2) completed, best_val_accuracy: 0.9924, best_hidden_layer_sizes sizes: [36, 20, 18, 35, 44]\n",
            "Run with parameters (0.0002, ec4ba8ef9e, [100, 100, 100, 100, 100], 10, 20, 0.2) completed, best_val_accuracy: 0.9931, best_hidden_layer_sizes sizes: [19, 19, 14, 31, 39]\n",
            "Run with parameters (0.0004, ec4ba8ef9e, [100, 100, 100, 100, 100], 10, 20, 0.2) completed, best_val_accuracy: 0.9933, best_hidden_layer_sizes sizes: [16, 14, 19, 45, 109]\n",
            "Best overall combination: (0.0004, ec4ba8ef9e, [100, 100, 100, 100, 100], 10, 20, 0.2), val_accuracy: 0.9933\n",
            "CPU times: user 8min 4s, sys: 20.5 s, total: 8min 25s\n",
            "Wall time: 7min 18s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_learning_rate = best_overall_combination[0]\n",
        "best_learning_rate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixVarQOxtVG-",
        "outputId": "562fdc28-0e80-40e2-e5f5-cf6576092d88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0004"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([DynamicEpoch(0.00002, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20)\n",
        "histories, mean_best_hidden_layer_sizes = cross_validate(\n",
        "    train_fn, mnist.X_norm, mnist.y, n_splits=7, learning_rate=best_learning_rate,\n",
        "    schedule=schedule, layer_sizes=[100, 100, 100, 100, 100], output_neurons=10, min_new_neurons=20, growth_percentage=0.2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T-FpKMrtVJy",
        "outputId": "d4ec9991-3a9c-4120-9f08-ca63c5dc901a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best_val_accuracy: 0.9926, best_hidden_layer_sizes: [18, 15, 16, 34, 77]\n",
            "Run 1 completed, best_val_accuracy: 0.9936, best_hidden_layer_sizes: [16, 13, 16, 38, 91]\n",
            "Run 2 completed, best_val_accuracy: 0.9928, best_hidden_layer_sizes: [20, 13, 14, 32, 102]\n",
            "Run 3 completed, best_val_accuracy: 0.9938, best_hidden_layer_sizes: [18, 14, 16, 35, 81]\n",
            "Run 4 completed, best_val_accuracy: 0.9946, best_hidden_layer_sizes: [18, 14, 19, 31, 88]\n",
            "Run 5 completed, best_val_accuracy: 0.9933, best_hidden_layer_sizes: [17, 16, 13, 34, 113]\n",
            "Run 6 completed, best_val_accuracy: 0.994, best_hidden_layer_sizes: [23, 14, 29, 31, 100]\n",
            "mean_best_val_accuracy: 0.9935285714285714\n",
            "mean_best_hidden_layer_sizes: [18.571428571428573, 14.142857142857142, 17.571428571428573, 33.57142857142857, 93.14285714285714]\n",
            "CPU times: user 18min 40s, sys: 50.5 s, total: 19min 31s\n",
            "Wall time: 16min 42s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rounded_mean_best_hidden_layer_sizes = [round(x) for x in mean_best_hidden_layer_sizes]\n",
        "rounded_mean_best_hidden_layer_sizes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMDDfv8MtVMM",
        "outputId": "a27b973d-1584-4467-b5e1-5d73ada7c1cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[19, 14, 18, 34, 93]"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([StaticEpochNoRegularization()] * 40)\n",
        "histories, best_overall_combination = hyperparameter_search(train_fn, x=mnist.X_train_norm, y=mnist.y_train, validation_data=(mnist.X_test_norm, mnist.y_test), \n",
        "                                  learning_rate=[0.0001, 0.0002, 0.0004, 0.0008, 0.0016, 0.0032], schedule=[schedule], layer_sizes=[rounded_mean_best_hidden_layer_sizes], \n",
        "                                  output_neurons=[10], min_new_neurons=[20], growth_percentage=[0.2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWRd6SvYtVOu",
        "outputId": "29c2a5ee-33da-4f07-fd53-7b550ffd7fb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0001, 4a0f172746, [19, 14, 18, 34, 93], 10, 20, 0.2) completed, best_val_accuracy: 0.9917, best_hidden_layer_sizes sizes: [19, 14, 18, 34, 93]\n",
            "Run with parameters (0.0002, 4a0f172746, [19, 14, 18, 34, 93], 10, 20, 0.2) completed, best_val_accuracy: 0.9925, best_hidden_layer_sizes sizes: [19, 14, 18, 34, 93]\n",
            "Run with parameters (0.0004, 4a0f172746, [19, 14, 18, 34, 93], 10, 20, 0.2) completed, best_val_accuracy: 0.9929, best_hidden_layer_sizes sizes: [19, 14, 18, 34, 93]\n",
            "Run with parameters (0.0008, 4a0f172746, [19, 14, 18, 34, 93], 10, 20, 0.2) completed, best_val_accuracy: 0.9919, best_hidden_layer_sizes sizes: [19, 14, 18, 34, 93]\n",
            "Run with parameters (0.0016, 4a0f172746, [19, 14, 18, 34, 93], 10, 20, 0.2) completed, best_val_accuracy: 0.9925, best_hidden_layer_sizes sizes: [19, 14, 18, 34, 93]\n",
            "Run with parameters (0.0032, 4a0f172746, [19, 14, 18, 34, 93], 10, 20, 0.2) completed, best_val_accuracy: 0.9902, best_hidden_layer_sizes sizes: [19, 14, 18, 34, 93]\n",
            "Best overall combination: (0.0004, 4a0f172746, [19, 14, 18, 34, 93], 10, 20, 0.2), val_accuracy: 0.9929\n",
            "CPU times: user 12min 45s, sys: 34.9 s, total: 13min 20s\n",
            "Wall time: 10min 36s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_learning_rate = best_overall_combination[0]\n",
        "best_learning_rate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-LTH8KftVQ9",
        "outputId": "8ff14774-f25e-45a4-ff0f-f351818c3cda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0004"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([StaticEpochNoRegularization()] * 40)\n",
        "histories, mean_best_hidden_layer_sizes = cross_validate(\n",
        "    train_fn, mnist.X_norm, mnist.y, n_splits=7, learning_rate=best_learning_rate,\n",
        "    schedule=schedule, layer_sizes=rounded_mean_best_hidden_layer_sizes, output_neurons=10, min_new_neurons=20, growth_percentage=0.2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxZEUlxytawY",
        "outputId": "eb5e171d-d3a1-434f-fac9-1a06391aa3c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best_val_accuracy: 0.9923, best_hidden_layer_sizes: [19, 14, 18, 34, 93]\n",
            "Run 1 completed, best_val_accuracy: 0.9935, best_hidden_layer_sizes: [19, 14, 18, 34, 93]\n",
            "Run 2 completed, best_val_accuracy: 0.9937, best_hidden_layer_sizes: [19, 14, 18, 34, 93]\n",
            "Run 3 completed, best_val_accuracy: 0.9932, best_hidden_layer_sizes: [19, 14, 18, 34, 93]\n",
            "Run 4 completed, best_val_accuracy: 0.9941, best_hidden_layer_sizes: [19, 14, 18, 34, 93]\n",
            "Run 5 completed, best_val_accuracy: 0.9924, best_hidden_layer_sizes: [19, 14, 18, 34, 93]\n",
            "Run 6 completed, best_val_accuracy: 0.9943, best_hidden_layer_sizes: [19, 14, 18, 34, 93]\n",
            "mean_best_val_accuracy: 0.9933571428571427\n",
            "mean_best_hidden_layer_sizes: [19.0, 14.0, 18.0, 34.0, 93.0]\n",
            "CPU times: user 14min 52s, sys: 41.7 s, total: 15min 34s\n",
            "Wall time: 12min 25s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tiny ImageNet"
      ],
      "metadata": {
        "id": "8nyE3FnKtzfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tiny_imagenet = get_tiny_imagenet_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7f4aAUTuAwM",
        "outputId": "dbfb2d0f-d3a2-4250-9e50-e2d582d8275f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing the downloaded dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([DynamicEpoch(0.00002, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20)\n",
        "histories, best_overall_combination = hyperparameter_search(train_fn, x=tiny_imagenet.X_train_norm, y=tiny_imagenet.y_train, validation_data=(tiny_imagenet.X_test_norm, tiny_imagenet.y_test), \n",
        "                                  learning_rate=[0.0001, 0.0002, 0.0004], schedule=[schedule], layer_sizes=[[100, 100, 100, 100, 100]], \n",
        "                                  output_neurons=[200], min_new_neurons=[20], growth_percentage=[0.2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1If_JhQjuBVx",
        "outputId": "3bba4ad4-9e90-4acb-ecf3-3a92fb98b59e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0001, ec4ba8ef9e, [100, 100, 100, 100, 100], 200, 20, 0.2) completed, best_val_accuracy: 0.1674, best_hidden_layer_sizes sizes: [76, 22, 33, 36, 120]\n",
            "Run with parameters (0.0002, ec4ba8ef9e, [100, 100, 100, 100, 100], 200, 20, 0.2) completed, best_val_accuracy: 0.1669, best_hidden_layer_sizes sizes: [66, 14, 29, 51, 190]\n",
            "Run with parameters (0.0004, ec4ba8ef9e, [100, 100, 100, 100, 100], 200, 20, 0.2) completed, best_val_accuracy: 0.1766, best_hidden_layer_sizes sizes: [48, 15, 45, 38, 381]\n",
            "Best overall combination: (0.0004, ec4ba8ef9e, [100, 100, 100, 100, 100], 200, 20, 0.2), val_accuracy: 0.1766\n",
            "CPU times: user 46min 45s, sys: 54 s, total: 47min 39s\n",
            "Wall time: 38min 22s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_learning_rate = best_overall_combination[0]\n",
        "best_learning_rate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4J7PduGCuBYr",
        "outputId": "69a6fbc0-d7f6-4110-9d81-0aae0ef536da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0004"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([DynamicEpoch(0.00002, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20)\n",
        "histories, mean_best_hidden_layer_sizes = cross_validate(\n",
        "    train_fn, tiny_imagenet.X_norm, tiny_imagenet.y, n_splits=11, learning_rate=best_learning_rate,\n",
        "    schedule=schedule, layer_sizes=[100, 100, 100, 100, 100], output_neurons=200, min_new_neurons=20, growth_percentage=0.2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ6EeXZBuBbE",
        "outputId": "1075017e-26e2-4c02-8f57-c756eacda717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best_val_accuracy: 0.1862, best_hidden_layer_sizes: [49, 12, 38, 46, 404]\n",
            "Run 1 completed, best_val_accuracy: 0.1854, best_hidden_layer_sizes: [51, 15, 46, 46, 384]\n",
            "Run 2 completed, best_val_accuracy: 0.1917, best_hidden_layer_sizes: [46, 14, 40, 47, 391]\n",
            "Run 3 completed, best_val_accuracy: 0.1792, best_hidden_layer_sizes: [49, 12, 48, 62, 376]\n",
            "Run 4 completed, best_val_accuracy: 0.2002, best_hidden_layer_sizes: [45, 13, 38, 41, 371]\n",
            "Run 5 completed, best_val_accuracy: 0.1792, best_hidden_layer_sizes: [42, 12, 56, 49, 358]\n",
            "Run 6 completed, best_val_accuracy: 0.19, best_hidden_layer_sizes: [52, 13, 66, 52, 348]\n",
            "Run 7 completed, best_val_accuracy: 0.213, best_hidden_layer_sizes: [45, 13, 53, 31, 388]\n",
            "Run 8 completed, best_val_accuracy: 0.1825, best_hidden_layer_sizes: [45, 13, 38, 80, 396]\n",
            "Run 9 completed, best_val_accuracy: 0.1743, best_hidden_layer_sizes: [43, 15, 54, 79, 368]\n",
            "Run 10 completed, best_val_accuracy: 0.1804, best_hidden_layer_sizes: [46, 13, 50, 66, 362]\n",
            "mean_best_val_accuracy: 0.18746363636363642\n",
            "mean_best_hidden_layer_sizes: [46.63636363636363, 13.181818181818182, 47.90909090909091, 54.45454545454545, 376.90909090909093]\n",
            "CPU times: user 2h 56min 7s, sys: 3min 42s, total: 2h 59min 49s\n",
            "Wall time: 2h 25min 21s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rounded_mean_best_hidden_layer_sizes = [round(x) for x in mean_best_hidden_layer_sizes]\n",
        "rounded_mean_best_hidden_layer_sizes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug2Y9m3JuBdu",
        "outputId": "97dd80a5-0279-4923-ace1-067da960f974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[47, 13, 48, 54, 377]"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([StaticEpochNoRegularization()] * 40)\n",
        "histories, best_overall_combination = hyperparameter_search(train_fn, x=tiny_imagenet.X_train_norm, y=tiny_imagenet.y_train, validation_data=(tiny_imagenet.X_test_norm, tiny_imagenet.y_test), \n",
        "                                  learning_rate=[0.0001, 0.0002, 0.0004, 0.0008, 0.0016, 0.0032], schedule=[schedule], layer_sizes=[rounded_mean_best_hidden_layer_sizes], \n",
        "                                  output_neurons=[200], min_new_neurons=[20], growth_percentage=[0.2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnoswIOWuSgP",
        "outputId": "869f0369-ecc3-4026-c13c-50c78558e781"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0001, 4a0f172746, [47, 13, 48, 54, 377], 200, 20, 0.2) completed, best_val_accuracy: 0.088, best_hidden_layer_sizes sizes: [47, 13, 48, 54, 377]\n",
            "Run with parameters (0.0002, 4a0f172746, [47, 13, 48, 54, 377], 200, 20, 0.2) completed, best_val_accuracy: 0.0932, best_hidden_layer_sizes sizes: [47, 13, 48, 54, 377]\n",
            "Run with parameters (0.0004, 4a0f172746, [47, 13, 48, 54, 377], 200, 20, 0.2) completed, best_val_accuracy: 0.0995, best_hidden_layer_sizes sizes: [47, 13, 48, 54, 377]\n",
            "Run with parameters (0.0008, 4a0f172746, [47, 13, 48, 54, 377], 200, 20, 0.2) completed, best_val_accuracy: 0.0923, best_hidden_layer_sizes sizes: [47, 13, 48, 54, 377]\n",
            "Run with parameters (0.0016, 4a0f172746, [47, 13, 48, 54, 377], 200, 20, 0.2) completed, best_val_accuracy: 0.0852, best_hidden_layer_sizes sizes: [47, 13, 48, 54, 377]\n",
            "Run with parameters (0.0032, 4a0f172746, [47, 13, 48, 54, 377], 200, 20, 0.2) completed, best_val_accuracy: 0.005, best_hidden_layer_sizes sizes: [47, 13, 48, 54, 377]\n",
            "Best overall combination: (0.0004, 4a0f172746, [47, 13, 48, 54, 377], 200, 20, 0.2), val_accuracy: 0.0995\n",
            "CPU times: user 1h 4min 38s, sys: 1min 31s, total: 1h 6min 9s\n",
            "Wall time: 49min 26s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_learning_rate = best_overall_combination[0]\n",
        "best_learning_rate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYtSsbjuuSi-",
        "outputId": "b6f9ba4d-aad5-4234-e5ba-f0f9e0c511a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0004"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([StaticEpochNoRegularization()] * 40)\n",
        "histories, mean_best_hidden_layer_sizes = cross_validate(\n",
        "    train_fn, tiny_imagenet.X_norm, tiny_imagenet.y, n_splits=11, learning_rate=best_learning_rate,\n",
        "    schedule=schedule, layer_sizes=rounded_mean_best_hidden_layer_sizes, output_neurons=200, min_new_neurons=20, growth_percentage=0.2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGsq3IK9uSld",
        "outputId": "0e3eb75c-1ae8-4ff2-bc33-672952e062ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best_val_accuracy: 0.1087, best_hidden_layer_sizes: [47, 13, 48, 54, 377]\n",
            "Run 1 completed, best_val_accuracy: 0.1094, best_hidden_layer_sizes: [47, 13, 48, 54, 377]\n",
            "Run 2 completed, best_val_accuracy: 0.1176, best_hidden_layer_sizes: [47, 13, 48, 54, 377]\n",
            "Run 3 completed, best_val_accuracy: 0.111, best_hidden_layer_sizes: [47, 13, 48, 54, 377]\n",
            "Run 4 completed, best_val_accuracy: 0.1162, best_hidden_layer_sizes: [47, 13, 48, 54, 377]\n",
            "Run 5 completed, best_val_accuracy: 0.1078, best_hidden_layer_sizes: [47, 13, 48, 54, 377]\n",
            "Run 6 completed, best_val_accuracy: 0.1183, best_hidden_layer_sizes: [47, 13, 48, 54, 377]\n",
            "Run 7 completed, best_val_accuracy: 0.1164, best_hidden_layer_sizes: [47, 13, 48, 54, 377]\n",
            "Run 8 completed, best_val_accuracy: 0.1093, best_hidden_layer_sizes: [47, 13, 48, 54, 377]\n",
            "Run 9 completed, best_val_accuracy: 0.1149, best_hidden_layer_sizes: [47, 13, 48, 54, 377]\n",
            "Run 10 completed, best_val_accuracy: 0.1138, best_hidden_layer_sizes: [47, 13, 48, 54, 377]\n",
            "mean_best_val_accuracy: 0.11303636363636362\n",
            "mean_best_hidden_layer_sizes: [47.0, 13.0, 48.0, 54.0, 377.0]\n",
            "CPU times: user 2h 51s, sys: 3min 16s, total: 2h 4min 8s\n",
            "Wall time: 1h 33min 1s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bMrz149vtoST"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}