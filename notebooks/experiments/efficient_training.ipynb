{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "tf_multi_layer_ssnet_inverse.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_deAUKlniFk",
        "outputId": "863e8aac-5188-4de6-a833-878d33c90bcc"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Aug  3 13:02:17 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKwUwV_NneIo"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOoXBq05neIt"
      },
      "source": [
        "dtype = 'float32'\n",
        "tf.keras.backend.set_floatx(dtype)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfMGB9KZneIu"
      },
      "source": [
        "# fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "# (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# X_train = X_train.astype(dtype) / 255.0\n",
        "# y_train = y_train.astype(dtype)\n",
        "# X_test = X_test.astype(dtype)  / 255.0\n",
        "# y_test = y_test.astype(dtype)\n",
        "\n",
        "# X_train = np.reshape(X_train, (-1, 784))\n",
        "# X_test = np.reshape(X_test, (-1, 784))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BrJPdkBneIv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83ac7ebf-c5d0-4364-ef6d-4bbe92d0044a"
      },
      "source": [
        "cifar10 = tf.keras.datasets.cifar10\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "X_train = X_train.astype(dtype) / 255.0\n",
        "y_train = y_train.astype(dtype)\n",
        "X_test = X_test.astype(dtype)  / 255.0\n",
        "y_test = y_test.astype(dtype)\n",
        "\n",
        "X_train = np.reshape(X_train, (-1, 3072))\n",
        "X_test = np.reshape(X_test, (-1, 3072))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 25s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5uTvu5kxF-b"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train_norm = scaler.transform(X_train)\n",
        "X_test_norm = scaler.transform(X_test)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTZq4KMpneIv"
      },
      "source": [
        "class SSRegularizer(tf.keras.regularizers.Regularizer):\n",
        "    def __init__(self, regularization_penalty, regularization_method):\n",
        "        self.regularization_penalty = regularization_penalty\n",
        "        self.regularization_method = regularization_method\n",
        "\n",
        "    def __call__(self, x):\n",
        "        if self.regularization_method == 'weighted_l1':\n",
        "            return self.weighted_l1(x)\n",
        "        elif self.regularization_method == 'group_sparsity':\n",
        "            return self.group_sparsity(x)\n",
        "        else:\n",
        "            raise NotImplementedError(f\"Unknown regularization method {self.regularization_method}\")\n",
        "    \n",
        "    def weighted_l1(self, x):\n",
        "        # I.e. for a parameter matrix of 4 input and 10 output neurons:\n",
        "        #\n",
        "        # [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]\n",
        "        #\n",
        "        # The scaling vector could be [0., 1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
        "        # and the resulting weighted values could be\n",
        "        #\n",
        "        # [[0., 1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
        "        #  [0., 1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
        "        #  [0., 1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
        "        #  [0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]]\n",
        "        #\n",
        "        # Therefore every additional output neuron is regularized more.\n",
        "\n",
        "        scaling_vector = tf.cumsum(tf.constant(self.regularization_penalty, shape=(x.shape[-1],), dtype=dtype), axis=0)\n",
        "        weighted_values = scaling_vector * tf.abs(x)\n",
        "        return tf.reduce_sum(weighted_values)\n",
        "    \n",
        "    def group_sparsity(self, x):\n",
        "        # I.e. for a parameter matrix of 3 input and 5 output neurons:\n",
        "        #\n",
        "        # [[1., 1., 1., 1., 1.],\n",
        "        #  [1., 2., 2., 1., 2.],\n",
        "        #  [2., 2., 3., 1., 3.]]\n",
        "        #\n",
        "        # The resulting vector of group norms is [2., 2., 3., 1., 3.], therefore for\n",
        "        # every output neuron, its incoming connections form a group.\n",
        "\n",
        "        group_norms = tf.norm(x, ord=2, axis=0)\n",
        "        # assert group_norms.shape[0] == x.shape[1]\n",
        "        return self.regularization_penalty * tf.reduce_sum(group_norms)\n",
        "\n",
        "    def get_config(self):\n",
        "        return {'regularization_penalty': float(self.regularization_penalty)}\n",
        "\n",
        "\n",
        "class SSLayer(tf.keras.Model):\n",
        "    def __init__(self, input_units, units, activation, regularization_penalty, regularization_method, kernel_initializer, bias_initializer, regularize=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_units = input_units\n",
        "        self.units = units\n",
        "        self.activation = activation\n",
        "        self.regularization_penalty = regularization_penalty\n",
        "        self.regularization_method = regularization_method\n",
        "        self.kernel_initializer = kernel_initializer\n",
        "        self.bias_initializer = bias_initializer\n",
        "        \n",
        "        self.A = tf.keras.activations.get(activation)\n",
        "        self.W_init = tf.keras.initializers.get(kernel_initializer)\n",
        "        self.b_init = tf.keras.initializers.get(bias_initializer)\n",
        "        self.regularizer = SSRegularizer(self.regularization_penalty, self.regularization_method)\n",
        "        \n",
        "        self.W = tf.Variable(\n",
        "            name='W',\n",
        "            initial_value=self.W_init(shape=(input_units, units), dtype=dtype),\n",
        "            trainable=True)\n",
        "        \n",
        "        self.b = tf.Variable(\n",
        "            name='b',\n",
        "            initial_value=self.b_init(shape=(units,), dtype=dtype),\n",
        "            trainable=True)\n",
        "        \n",
        "        if self.regularization_method is not None:\n",
        "            self.add_loss(lambda: self.regularizer(tf.concat([self.W, tf.reshape(self.b, (1, -1))], axis=0)))\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        return self.A(tf.matmul(inputs, self.W) + self.b)\n",
        "    \n",
        "    def copy_without_regularization(self):\n",
        "        copy = SSLayer(\n",
        "            self.input_units, \n",
        "            self.units, \n",
        "            self.activation, \n",
        "            regularization_penalty=self.regularization_penalty, \n",
        "            regularization_method=None, \n",
        "            kernel_initializer=self.kernel_initializer, \n",
        "            bias_initializer=self.bias_initializer\n",
        "        )\n",
        "        copy.W = self.W\n",
        "        copy.b = self.b\n",
        "        return copy\n",
        "\n",
        "\n",
        "class SSModel(tf.keras.Model):\n",
        "    def __init__(self, layer_sizes, activation=None, regularization_penalty=0.01, regularization_method='weighted_l1', kernel_initializer='glorot_uniform', bias_initializer='zeros'):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.sslayers = list()\n",
        "        for l in range(len(layer_sizes) - 1):\n",
        "            input_units = layer_sizes[l]\n",
        "            units = layer_sizes[l + 1]\n",
        "            if l < len(layer_sizes) - 2:\n",
        "                layer = SSLayer(input_units, units, activation, regularization_penalty, regularization_method, kernel_initializer, bias_initializer)\n",
        "            else:  # Last layer\n",
        "                layer = SSLayer(input_units, units, 'softmax', 0., regularization_method, kernel_initializer, bias_initializer)\n",
        "            self.sslayers.append(layer)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs\n",
        "        for layer in self.sslayers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "    \n",
        "    def get_layer_sizes(self):\n",
        "        layer_sizes = list()\n",
        "        for l in range(len(self.sslayers)):\n",
        "            layer = self.sslayers[l]\n",
        "            layer_sizes.append(layer.W.shape[0])\n",
        "            if l == len(self.sslayers) - 1:  # Last layer\n",
        "                layer_sizes.append(layer.W.shape[1])\n",
        "        return layer_sizes\n",
        "    \n",
        "    def print_neurons(self):\n",
        "        for layer in self.sslayers[:-1]:\n",
        "            print(get_param_string(layer.W, layer.b))\n",
        "    \n",
        "    def remove_regularization(self):\n",
        "        for l in range(len(self.sslayers)):\n",
        "            self.sslayers[l] = self.sslayers[l].copy_without_regularization()\n",
        "    \n",
        "    def get_regularization_penalty(self):\n",
        "        return self.sslayers[0].regularizer.regularization_penalty\n",
        "    \n",
        "    def set_regularization_penalty(self, regularization_penalty):\n",
        "        for l in range(0, len(self.sslayers) - 1):  # Every layer except of the last is regularized\n",
        "            self.sslayers[l].regularizer.regularization_penalty = regularization_penalty\n",
        "    \n",
        "    def prune(self, threshold=0.001):\n",
        "        for l in range(len(self.sslayers) - 1):\n",
        "            layer1 = self.sslayers[l]\n",
        "            layer2 = self.sslayers[l + 1]\n",
        "            \n",
        "            W1 = layer1.W.value()\n",
        "            b1 = layer1.b.value()\n",
        "            W2 = layer2.W.value()\n",
        "\n",
        "            weights_with_biases = tf.concat([W1, tf.reshape(b1, (1, -1))], axis=0)\n",
        "            neurons_are_active = tf.math.reduce_max(tf.abs(weights_with_biases), axis=0) >= threshold\n",
        "            active_neurons_indices = tf.reshape(tf.where(neurons_are_active), (-1,))\n",
        "            \n",
        "            new_W1 = tf.gather(W1, active_neurons_indices, axis=1)\n",
        "            new_b1 = tf.gather(b1, active_neurons_indices, axis=0)\n",
        "            new_W2 = tf.gather(W2, active_neurons_indices, axis=0)\n",
        "\n",
        "            layer1.W = tf.Variable(name='W', initial_value=new_W1, trainable=True)\n",
        "            layer1.b = tf.Variable(name='b', initial_value=new_b1, trainable=True)\n",
        "            layer2.W = tf.Variable(name='W', initial_value=new_W2, trainable=True)\n",
        "    \n",
        "    def grow(self, min_new_neurons=5, scaling_factor=0.001):   \n",
        "        for l in range(len(self.sslayers) - 1):\n",
        "            layer1 = self.sslayers[l]\n",
        "            layer2 = self.sslayers[l + 1]\n",
        "       \n",
        "            W1 = layer1.W.value()\n",
        "            b1 = layer1.b.value()\n",
        "            W2 = layer2.W.value()\n",
        "\n",
        "            n_new_neurons = max(min_new_neurons, int(W1.shape[1] * 0.2))\n",
        "\n",
        "            W1_growth = layer1.W_init(shape=(W1.shape[0], W1.shape[1] + n_new_neurons), dtype=dtype)[:, -n_new_neurons:] * scaling_factor\n",
        "            b1_growth = layer1.b_init(shape=(n_new_neurons,), dtype=dtype)\n",
        "            W2_growth = layer2.W_init(shape=(W2.shape[0] + n_new_neurons, W2.shape[1]), dtype=dtype)[-n_new_neurons:, :] * scaling_factor  # TODO is it better to be multiplying here by scaling_factor? It does help with not increasing the max weights of existing neurons when new neurons are added.\n",
        "\n",
        "            new_W1 = tf.concat([W1, W1_growth], axis=1)\n",
        "            new_b1 = tf.concat([b1, b1_growth], axis=0)\n",
        "            new_W2 = tf.concat([W2, W2_growth], axis=0)\n",
        "\n",
        "            layer1.W = tf.Variable(name='W1', initial_value=new_W1, trainable=True)\n",
        "            layer1.b = tf.Variable(name='b1', initial_value=new_b1, trainable=True)\n",
        "            layer2.W = tf.Variable(name='W2', initial_value=new_W2, trainable=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WPKvoQQneIx"
      },
      "source": [
        "def get_param_string(weights, bias):\n",
        "    param_string = \"\"\n",
        "    weights_with_bias = tf.concat([weights, tf.reshape(bias, (1, -1))], axis=0)\n",
        "    max_parameters = tf.math.reduce_max(tf.abs(weights_with_bias), axis=0).numpy()\n",
        "    magnitudes = np.floor(np.log10(max_parameters))\n",
        "    for m in magnitudes:\n",
        "        if m > 0:\n",
        "            m = 0\n",
        "        param_string += str(int(-m))\n",
        "    return param_string\n",
        "\n",
        "\n",
        "def print_epoch_statistics(model, x, y, validation_data):\n",
        "    x_val = validation_data[0]\n",
        "    y_val = validation_data[1]\n",
        "\n",
        "    y_pred = model(x)\n",
        "    loss = tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(y, y_pred))\n",
        "    accuracy = tf.reduce_mean(tf.keras.metrics.sparse_categorical_accuracy(y, y_pred))\n",
        "    \n",
        "    y_val_pred = model(x_val)\n",
        "    val_loss = tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(y_val, y_val_pred))\n",
        "    val_accuracy = tf.reduce_mean(tf.keras.metrics.sparse_categorical_accuracy(y_val, y_val_pred))\n",
        "    print(f\"loss: {loss} - accuracy: {accuracy} - val_loss: {val_loss} - val_accuracy: {val_accuracy} - penalty: {model.get_regularization_penalty()}\")\n",
        "    print(f\"layer sizes: {model.get_layer_sizes()}\")\n",
        "    # model.print_neurons()\n",
        "\n",
        "    return val_loss\n",
        "\n",
        "\n",
        "def train_model(model, x, y, optimizer, epochs, self_scaling_epochs, batch_size, min_new_neurons, validation_data, regularization_penalty_multiplier=1.):\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "    train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "    best_val_loss = np.inf\n",
        "    training_stalled = False\n",
        "    for epoch in range(epochs):\n",
        "        print(\"##########################################################\")\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "        if epoch < self_scaling_epochs:\n",
        "            print(\"Before growing:\")\n",
        "\n",
        "            val_loss = print_epoch_statistics(model, x, y, validation_data)\n",
        "            if val_loss >= best_val_loss:\n",
        "                if not training_stalled:\n",
        "                    penalty = model.get_regularization_penalty() * regularization_penalty_multiplier\n",
        "                    model.set_regularization_penalty(penalty)\n",
        "                    training_stalled = True\n",
        "            else:\n",
        "                best_val_loss = val_loss\n",
        "                training_stalled = False\n",
        "\n",
        "            model.grow(min_new_neurons=min_new_neurons, scaling_factor=0.001)\n",
        "            print(\"After growing:\")\n",
        "            print_epoch_statistics(model, x, y, validation_data)\n",
        "        \n",
        "        if epoch == self_scaling_epochs:\n",
        "            model.remove_regularization()\n",
        "\n",
        "        for step, (x_batch, y_batch) in enumerate(train_dataset):\n",
        "            with tf.GradientTape() as tape:\n",
        "                y_pred = model(x_batch, training=True)\n",
        "                loss_value = tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(y_batch, y_pred))\n",
        "                loss_value += sum(model.losses)\n",
        "\n",
        "            grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "        \n",
        "        if epoch < self_scaling_epochs:\n",
        "            print(\"Before pruning:\")\n",
        "            print_epoch_statistics(model, x, y, validation_data)\n",
        "            model.prune(threshold=0.001)\n",
        "            print(\"After pruning:\")\n",
        "            print_epoch_statistics(model, x, y, validation_data)\n",
        "        else:\n",
        "            print_epoch_statistics(model, x, y, validation_data)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1MrQXUTFwOe"
      },
      "source": [
        "# Efficient training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOgW8Vb5Ghcg"
      },
      "source": [
        "epochs = 10\n",
        "self_scaling_epochs = 10\n",
        "batch_size = 32\n",
        "min_new_neurons = 20"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdrNMmzqGBMV",
        "outputId": "466d3fea-3f4b-4e32-8d6a-e24ea986aad7"
      },
      "source": [
        "%%time\n",
        "\n",
        "model = SSModel(layer_sizes=[3072, 1000, 1000, 1000, 1000, 10], activation='selu', regularization_penalty=0.0001, regularization_method='weighted_l1', kernel_initializer='lecun_normal')\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "train_model(model, X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "Before growing:\n",
            "loss: 2.7915027141571045 - accuracy: 0.11311999708414078 - val_loss: 2.766880750656128 - val_accuracy: 0.11949999630451202\n",
            "layer sizes: [3072, 1000, 1000, 1000, 1000, 10]\n",
            "2222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222\n",
            "2222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222\n",
            "2222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222\n",
            "2222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222\n",
            "After growing:\n",
            "loss: 2.7915027141571045 - accuracy: 0.11311999708414078 - val_loss: 2.766880750656128 - val_accuracy: 0.11949999630451202\n",
            "layer sizes: [3072, 1200, 1200, 1200, 1200, 10]\n",
            "222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222255555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555\n",
            "222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222255555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555\n",
            "222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222255555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555\n",
            "222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222255555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555\n",
            "Before pruning:\n",
            "loss: 2.006772518157959 - accuracy: 0.186039999127388 - val_loss: 2.010066270828247 - val_accuracy: 0.1859000027179718\n",
            "layer sizes: [3072, 1200, 1200, 1200, 1200, 10]\n",
            "222222222444444554444544454444544555544454454454544455455545455545544455555555555445554545445555455555555455554455555455454444554555555554555555555545554555544555555555555555555455455555555555555555555555555455455545555555555555455555554555555555555545555555555555555455555445455455545555555555555555555555555555555544555545554545555555555555555555555555545555544555555555555554555555545455555555555555555555555555555545555545545555554555555555555555555555555555555455555555555555555555555555555455555555555555555555555555554555555555454545555555455555555555555554555555545545555555555555555555555545555555554555555545555555555555554555455554555554555555554555555555555455555555554455455455545555555555545555555545555555555555554555545554455555555555554555555455545455555555555555545555555455555555555555555555555545544455555445454554555554455545554545454554554555455545555545454555555545554555555555555454555555545555545554455545554555454545555555545555555455554544455555545555454554554545455455555455555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555\n",
            "122111121252111224422255425552244445444444455554554545445544454444454544444444444444454454454444444454444444445444445454544454545544444444444445444444544444444444444454544444444444444444444445445444545444444544555444444444544444544554545444444444454444444444445454445454454444445445454444444444444444444444545444544454445444444444444445445444555544544444444444444445444454444444454444455454454445454444544444444454544544445545445444454444444444444445444444444544545445454444554445444444444444444544544444444444454454444444444445444454444444455444454544444444444444454454445544444544444444544444544444444444444455454444444444444444444444444444444554444444444444444444444455445544444544444544445445444545444444454454444444454444444444454445444444444544444454444444444444444455444444445444444445544444454444444444444444544444444444444444444454444445444544444444444544445445444444444444445444445444444454445444444444444444444444444445444444444444444444454444444444544455455444444444454444445544444444444455555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555\n",
            "111111511121144455155245444545544444555444455444455445454545544554545545444455445444444444545544555454455555454555544454445455455544445544455545444455455545444544545445445554545454554444455544445554455555445444445454545454445455445554444544545545554454554445544454444554554445555555554444554555445445545445545454545445544554554554444454545445444455454444444555445555445455454444555444454445444454555544555455545445445445545444554444454555544555455445555445555555444455454544444554454444445544444444445544454444455444445545444545445544554444544454444454454454555445444545544544444454444454554444554444544545454454544545445554444554455544454454444444554454445444454444544545554445544444454444554555454544455544455445444444455444455444445444544554444544544444444555444444444544544544455444544444544544554444444444545444444445444444545444454544444444554444455445454445554455454554444444444555554544444444454445454454445445454554454444445445545545444444444545544444444454444445444444544445544555454444545455555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555\n",
            "111121111212211112142222322422422444434342444244444444444444444444445444444454444444445445444444444444445454444454454444445444444544554545554444444445444545544454544444555444545444445444444444544545445554444444445455444445454444545545545444544445544455454444454445554554554554554455555445454545555545445554544455445445445454444445445454544454444544454445454554445545545544544555545544554445445545445445544445555445444545554555455445445544445554544554454544444544544444445445445455555554455555444445555445544554544454444445555455444454455554455555555554554544555444554544454454554554545445454444444445454445545554445555544454455545444445545455545444544445455554455554544445545545444454544445545555554444555444555444545544455444454545545454445444454444545444545545455454444544445455545444455454444454444444555454444444444455444545554554454445454444454455455544444444455445555455444544454544454544545454454544555444445444544444444444445445545444454545444554444444444544445445544444445555454444454545444555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555\n",
            "After pruning:\n",
            "loss: 2.008625030517578 - accuracy: 0.1859000027179718 - val_loss: 2.0118825435638428 - val_accuracy: 0.1850000023841858\n",
            "layer sizes: [3072, 9, 21, 14, 34, 10]\n",
            "222222222\n",
            "122111121211122222222\n",
            "11111111121112\n",
            "1111211112122111121222232222223322\n",
            "Epoch 2/10\n",
            "Before growing:\n",
            "loss: 2.008625030517578 - accuracy: 0.1859000027179718 - val_loss: 2.0118825435638428 - val_accuracy: 0.1850000023841858\n",
            "layer sizes: [3072, 9, 21, 14, 34, 10]\n",
            "222222222\n",
            "122111121211122222222\n",
            "11111111121112\n",
            "1111211112122111121222232222223322\n",
            "After growing:\n",
            "loss: 2.008624792098999 - accuracy: 0.1859000027179718 - val_loss: 2.011882781982422 - val_accuracy: 0.1850000023841858\n",
            "layer sizes: [3072, 29, 41, 34, 54, 10]\n",
            "22222222255555555555555555555\n",
            "12211112121112222222244444444444444444444\n",
            "1111111112111244444444444444444444\n",
            "111121111212211112122223222222332244444444444444444444\n",
            "Before pruning:\n",
            "loss: 1.9791231155395508 - accuracy: 0.2035599946975708 - val_loss: 1.9832959175109863 - val_accuracy: 0.19869999587535858\n",
            "layer sizes: [3072, 29, 41, 34, 54, 10]\n",
            "12214512445554445444445445445\n",
            "11111112151125522252255555555555555555555\n",
            "1111111113121555555555555555555555\n",
            "111121111211221222122234322422444454445444455544444444\n",
            "After pruning:\n",
            "loss: 1.9792321920394897 - accuracy: 0.20374000072479248 - val_loss: 1.9834089279174805 - val_accuracy: 0.1987999975681305\n",
            "layer sizes: [3072, 6, 17, 13, 28, 10]\n",
            "122112\n",
            "11111112111222222\n",
            "1111111113121\n",
            "1111211112112212221222332222\n",
            "Epoch 3/10\n",
            "Before growing:\n",
            "loss: 1.9792321920394897 - accuracy: 0.20374000072479248 - val_loss: 1.9834089279174805 - val_accuracy: 0.1987999975681305\n",
            "layer sizes: [3072, 6, 17, 13, 28, 10]\n",
            "122112\n",
            "11111112111222222\n",
            "1111111113121\n",
            "1111211112112212221222332222\n",
            "After growing:\n",
            "loss: 1.9792320728302002 - accuracy: 0.20374000072479248 - val_loss: 1.9834089279174805 - val_accuracy: 0.1987999975681305\n",
            "layer sizes: [3072, 26, 37, 33, 48, 10]\n",
            "12211255555555555555555555\n",
            "1111111211122222244444444444444444444\n",
            "111111111312144444444444444444444\n",
            "111121111211221222122233222244444444444444444444\n",
            "Before pruning:\n",
            "loss: 1.8738772869110107 - accuracy: 0.2679600119590759 - val_loss: 1.8785133361816406 - val_accuracy: 0.2687000036239624\n",
            "layer sizes: [3072, 26, 37, 33, 48, 10]\n",
            "11212244444444444444444444\n",
            "1111111111121251255555555545555555545\n",
            "111111111511155555555555555555555\n",
            "111111111111221122121223422143114431444222444444\n",
            "After pruning:\n",
            "loss: 1.8738850355148315 - accuracy: 0.2679600119590759 - val_loss: 1.8785232305526733 - val_accuracy: 0.2689000070095062\n",
            "layer sizes: [3072, 6, 16, 12, 35, 10]\n",
            "112122\n",
            "1111111111121212\n",
            "111111111111\n",
            "11111111111122112212122322131131222\n",
            "Epoch 4/10\n",
            "Before growing:\n",
            "loss: 1.8738850355148315 - accuracy: 0.2679600119590759 - val_loss: 1.8785232305526733 - val_accuracy: 0.2689000070095062\n",
            "layer sizes: [3072, 6, 16, 12, 35, 10]\n",
            "112122\n",
            "1111111111121212\n",
            "111111111111\n",
            "11111111111122112212122322131131222\n",
            "After growing:\n",
            "loss: 1.8738850355148315 - accuracy: 0.2679600119590759 - val_loss: 1.8785232305526733 - val_accuracy: 0.2689000070095062\n",
            "layer sizes: [3072, 26, 36, 32, 55, 10]\n",
            "11212255555555555555555555\n",
            "111111111112121244444444444444444444\n",
            "11111111111144444444444444444444\n",
            "1111111111112211221212232213113122244444444444444444444\n",
            "Before pruning:\n",
            "loss: 1.8299658298492432 - accuracy: 0.3102400004863739 - val_loss: 1.8361601829528809 - val_accuracy: 0.31040000915527344\n",
            "layer sizes: [3072, 26, 36, 32, 55, 10]\n",
            "11112145444444444445444444\n",
            "111111111112111155555555555555555555\n",
            "11111111111155555555555555555555\n",
            "1111111111111111121111232114114122344444444444444454444\n",
            "After pruning:\n",
            "loss: 1.830153465270996 - accuracy: 0.3100399971008301 - val_loss: 1.8363468647003174 - val_accuracy: 0.3100999891757965\n",
            "layer sizes: [3072, 6, 16, 12, 33, 10]\n",
            "111121\n",
            "1111111111121111\n",
            "111111111111\n",
            "111111111111111112111123211111223\n",
            "Epoch 5/10\n",
            "Before growing:\n",
            "loss: 1.830153465270996 - accuracy: 0.3100399971008301 - val_loss: 1.8363468647003174 - val_accuracy: 0.3100999891757965\n",
            "layer sizes: [3072, 6, 16, 12, 33, 10]\n",
            "111121\n",
            "1111111111121111\n",
            "111111111111\n",
            "111111111111111112111123211111223\n",
            "After growing:\n",
            "loss: 1.8301535844802856 - accuracy: 0.3100399971008301 - val_loss: 1.8363471031188965 - val_accuracy: 0.3100999891757965\n",
            "layer sizes: [3072, 26, 36, 32, 53, 10]\n",
            "11112155555555555555555555\n",
            "111111111112111144444444444444444444\n",
            "11111111111144444444444444444444\n",
            "11111111111111111211112321111122344444444444444444444\n",
            "Before pruning:\n",
            "loss: 1.7904762029647827 - accuracy: 0.33281999826431274 - val_loss: 1.7992058992385864 - val_accuracy: 0.32760000228881836\n",
            "layer sizes: [3072, 26, 36, 32, 53, 10]\n",
            "11112144444444444444444444\n",
            "111111111112111155555555455555555555\n",
            "11111111121155555555555555555555\n",
            "11111111111111111211112311111132245444444454444444545\n",
            "After pruning:\n",
            "loss: 1.7905278205871582 - accuracy: 0.3328000009059906 - val_loss: 1.799251914024353 - val_accuracy: 0.3276999890804291\n",
            "layer sizes: [3072, 6, 16, 12, 33, 10]\n",
            "111121\n",
            "1111111111121111\n",
            "111111111211\n",
            "111111111111111112111123111111322\n",
            "Epoch 6/10\n",
            "Before growing:\n",
            "loss: 1.7905278205871582 - accuracy: 0.3328000009059906 - val_loss: 1.799251914024353 - val_accuracy: 0.3276999890804291\n",
            "layer sizes: [3072, 6, 16, 12, 33, 10]\n",
            "111121\n",
            "1111111111121111\n",
            "111111111211\n",
            "111111111111111112111123111111322\n",
            "After growing:\n",
            "loss: 1.7905279397964478 - accuracy: 0.3328000009059906 - val_loss: 1.7992521524429321 - val_accuracy: 0.3276999890804291\n",
            "layer sizes: [3072, 26, 36, 32, 53, 10]\n",
            "11112155555555555555555555\n",
            "111111111112111144444444444444444444\n",
            "11111111121144444444444444444444\n",
            "11111111111111111211112311111132244444444444444444444\n",
            "Before pruning:\n",
            "loss: 1.7708803415298462 - accuracy: 0.3397200107574463 - val_loss: 1.7796789407730103 - val_accuracy: 0.3361000120639801\n",
            "layer sizes: [3072, 26, 36, 32, 53, 10]\n",
            "11112145545444444444444444\n",
            "111111111112111155554555555555555555\n",
            "11111111122155555555555555555555\n",
            "11111111111111111311112312111233244454444444444544444\n",
            "After pruning:\n",
            "loss: 1.7708762884140015 - accuracy: 0.33965998888015747 - val_loss: 1.779669165611267 - val_accuracy: 0.3361000120639801\n",
            "layer sizes: [3072, 6, 16, 12, 33, 10]\n",
            "111121\n",
            "1111111111121111\n",
            "111111111221\n",
            "111111111111111113111123121112332\n",
            "Epoch 7/10\n",
            "Before growing:\n",
            "loss: 1.7708762884140015 - accuracy: 0.33965998888015747 - val_loss: 1.779669165611267 - val_accuracy: 0.3361000120639801\n",
            "layer sizes: [3072, 6, 16, 12, 33, 10]\n",
            "111121\n",
            "1111111111121111\n",
            "111111111221\n",
            "111111111111111113111123121112332\n",
            "After growing:\n",
            "loss: 1.7708762884140015 - accuracy: 0.33965998888015747 - val_loss: 1.779669165611267 - val_accuracy: 0.3361000120639801\n",
            "layer sizes: [3072, 26, 36, 32, 53, 10]\n",
            "11112155555555555555555555\n",
            "111111111112111144444444444444444444\n",
            "11111111122144444444444444444444\n",
            "11111111111111111311112312111233244444444444444444444\n",
            "Before pruning:\n",
            "loss: 1.7550849914550781 - accuracy: 0.3478600084781647 - val_loss: 1.7649648189544678 - val_accuracy: 0.3425999879837036\n",
            "layer sizes: [3072, 26, 36, 32, 53, 10]\n",
            "11111145444545544454455444\n",
            "111111111112111155555555555555555555\n",
            "11111111122155555555555555555555\n",
            "11111111111111111311112312122244244444454444444444444\n",
            "After pruning:\n",
            "loss: 1.7550926208496094 - accuracy: 0.34790000319480896 - val_loss: 1.7649720907211304 - val_accuracy: 0.3425000011920929\n",
            "layer sizes: [3072, 6, 16, 12, 31, 10]\n",
            "111111\n",
            "1111111111121111\n",
            "111111111221\n",
            "1111111111111111131111231212222\n",
            "Epoch 8/10\n",
            "Before growing:\n",
            "loss: 1.7550926208496094 - accuracy: 0.34790000319480896 - val_loss: 1.7649720907211304 - val_accuracy: 0.3425000011920929\n",
            "layer sizes: [3072, 6, 16, 12, 31, 10]\n",
            "111111\n",
            "1111111111121111\n",
            "111111111221\n",
            "1111111111111111131111231212222\n",
            "After growing:\n",
            "loss: 1.7550925016403198 - accuracy: 0.34790000319480896 - val_loss: 1.7649720907211304 - val_accuracy: 0.3425000011920929\n",
            "layer sizes: [3072, 26, 36, 32, 51, 10]\n",
            "11111155555555555555555555\n",
            "111111111112111144444444444444444444\n",
            "11111111122144444444444444444444\n",
            "111111111111111113111123121222244444444444444444444\n",
            "Before pruning:\n",
            "loss: 1.75437593460083 - accuracy: 0.34553998708724976 - val_loss: 1.7662519216537476 - val_accuracy: 0.3379000127315521\n",
            "layer sizes: [3072, 26, 36, 32, 51, 10]\n",
            "11111154445554444444444444\n",
            "111111111112111155455455555554555555\n",
            "11111111122155555555455555555555\n",
            "111111111111111113211223121222344444444444444444444\n",
            "After pruning:\n",
            "loss: 1.7543823719024658 - accuracy: 0.34558001160621643 - val_loss: 1.7662583589553833 - val_accuracy: 0.337799996137619\n",
            "layer sizes: [3072, 6, 16, 12, 31, 10]\n",
            "111111\n",
            "1111111111121111\n",
            "111111111221\n",
            "1111111111111111132112231212223\n",
            "Epoch 9/10\n",
            "Before growing:\n",
            "loss: 1.7543823719024658 - accuracy: 0.34558001160621643 - val_loss: 1.7662583589553833 - val_accuracy: 0.337799996137619\n",
            "layer sizes: [3072, 6, 16, 12, 31, 10]\n",
            "111111\n",
            "1111111111121111\n",
            "111111111221\n",
            "1111111111111111132112231212223\n",
            "After growing:\n",
            "loss: 1.7543823719024658 - accuracy: 0.34558001160621643 - val_loss: 1.7662583589553833 - val_accuracy: 0.337799996137619\n",
            "layer sizes: [3072, 26, 36, 32, 51, 10]\n",
            "11111155555555555555555555\n",
            "111111111112111144444444444444444444\n",
            "11111111122144444444444444444444\n",
            "111111111111111113211223121222344444444444444444444\n",
            "Before pruning:\n",
            "loss: 1.7563860416412354 - accuracy: 0.3457399904727936 - val_loss: 1.7703708410263062 - val_accuracy: 0.33719998598098755\n",
            "layer sizes: [3072, 26, 36, 32, 51, 10]\n",
            "11111145544455544444444454\n",
            "111111111112111155555555555555555555\n",
            "11111111122255555555455555555545\n",
            "111111111111111113211224121222344444444444454445444\n",
            "After pruning:\n",
            "loss: 1.7564443349838257 - accuracy: 0.34564000368118286 - val_loss: 1.7704277038574219 - val_accuracy: 0.33709999918937683\n",
            "layer sizes: [3072, 6, 16, 12, 30, 10]\n",
            "111111\n",
            "1111111111121111\n",
            "111111111222\n",
            "111111111111111113211221212223\n",
            "Epoch 10/10\n",
            "Before growing:\n",
            "loss: 1.7564443349838257 - accuracy: 0.34564000368118286 - val_loss: 1.7704277038574219 - val_accuracy: 0.33709999918937683\n",
            "layer sizes: [3072, 6, 16, 12, 30, 10]\n",
            "111111\n",
            "1111111111121111\n",
            "111111111222\n",
            "111111111111111113211221212223\n",
            "After growing:\n",
            "loss: 1.7564443349838257 - accuracy: 0.34564000368118286 - val_loss: 1.7704277038574219 - val_accuracy: 0.33709999918937683\n",
            "layer sizes: [3072, 26, 36, 32, 50, 10]\n",
            "11111155555555555555555555\n",
            "111111111112111144444444444444444444\n",
            "11111111122244444444444444444444\n",
            "11111111111111111321122121222344444444444444444444\n",
            "Before pruning:\n",
            "loss: 1.7317959070205688 - accuracy: 0.35662001371383667 - val_loss: 1.7456492185592651 - val_accuracy: 0.3537999987602234\n",
            "layer sizes: [3072, 26, 36, 32, 50, 10]\n",
            "11111144445444444444444444\n",
            "111111111112111155555555555555555555\n",
            "11111111122255555555555555555555\n",
            "11111111111111111421122121222344444544544445445445\n",
            "After pruning:\n",
            "loss: 1.731806755065918 - accuracy: 0.3566800057888031 - val_loss: 1.7456566095352173 - val_accuracy: 0.3537999987602234\n",
            "layer sizes: [3072, 6, 16, 12, 29, 10]\n",
            "111111\n",
            "1111111111121111\n",
            "111111111222\n",
            "11111111111111111211221212223\n",
            "CPU times: user 5min 46s, sys: 4.84 s, total: 5min 51s\n",
            "Wall time: 5min 47s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2isqn13d00Q3",
        "outputId": "e8876dac-a51c-4dee-cea9-33d4cab839ff"
      },
      "source": [
        "%%time\n",
        "\n",
        "model = SSModel(layer_sizes=[3072, 1000, 1000, 1000, 1000, 10], activation='selu', regularization_penalty=0.00001, regularization_method='weighted_l1', kernel_initializer='lecun_normal')\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "train_model(model, X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "Before growing:\n",
            "loss: 2.701932430267334 - accuracy: 0.09616000205278397 - val_loss: 2.6937167644500732 - val_accuracy: 0.10040000081062317\n",
            "layer sizes: [3072, 1000, 1000, 1000, 1000, 10]\n",
            "2222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222\n",
            "2222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222\n",
            "2222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222\n",
            "2222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222\n",
            "After growing:\n",
            "loss: 2.701932430267334 - accuracy: 0.09616000205278397 - val_loss: 2.6937172412872314 - val_accuracy: 0.10040000081062317\n",
            "layer sizes: [3072, 1200, 1200, 1200, 1200, 10]\n",
            "222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222255555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555\n",
            "222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222255555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555\n",
            "222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222255555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555\n",
            "222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222255555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555\n",
            "Before pruning:\n",
            "loss: 1.6422853469848633 - accuracy: 0.4048599898815155 - val_loss: 1.6402077674865723 - val_accuracy: 0.4049000144004822\n",
            "layer sizes: [3072, 1200, 1200, 1200, 1200, 10]\n",
            "222222222222222222222222222222222222223222223232234434443444444442442444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444454444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444445444444444444444444444444444444544444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444445445445444444444444444444444444455555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555\n",
            "112112111121122222212212122222222212222212222222212222122222222222222222222222222222222222222222222222242222322223222222222223222224232222222224332442242224323244223334343223434443323244424224324234344434244434442434422344444244434442444444424444444444443444444444444344443443444444344444444344434444444444444444443444444444444444444444444444444444444444444544444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444454445444444444444444444444444444444454444444444444444444444444444444444444444444444454444444545444444444445445444444444444454444444444445444444454444444444444444444445444454444454544454444454444444454445444444444444444444544444454444444444444444444444544454445444444444444444454444444544444445444544444454444444444554455444444454444454444544444444444444444444454444444444544445444444444444444544445445554444444444554454445444444444544444444544444445454444444554444544454544444444444444544445544445554454445444544444444545444454454454555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555\n",
            "121111111112221212211222221221211222222222222222222222222222222223222242222222232324232242223222224322242322243442444434444424424424444444454444434544444444444454455444544444445444444454444444444444544354444444444544445544454444445444444444554444444445444544444444444445445554444554444555454445444445445445455544455444444454544445445444545544554454444545444444555554445554444455544554444444444545454444545554544554444554454555554444545454444544454545554544545455454454455444555545544455545544444455455544444544555445545455544444545455554545454454544544455545555454454545555455444555455444544545545454455445545545454545555455554555545554455454545455545555455444555544544544554554455554544444545554545554555455454554554544554555444555545454554555455445554554445555555555555555455554555544555544545555545545545554554455554554455444455545455455454555545555555555555555555545554555545444555455445454555555545454545545545455545555545554455555455555455555555555545555554445454545455454555455555554545555554555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555\n",
            "111112111211111121212212221221122212222211112222122222222222222222222222122212222222222222222222222222222222222222222223222222222222223222223332222222322232232234222342322322332323333322324442332344433334323323423233333333343433332342334233444344422343442432444344333434344333343243443434324343443444334444443444444443244434444433434434443444433434244444433344443344434343444344343444443444344444444444434343344434444444443444444444444443444444444444444444444344444444444444444444444344444443444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444344444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444454444444444444444444444454444444444444444444444444444444444444444444444444444544444544444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444445444444455555454555554555545554455545455455555555444455555455555555455555545554555555454555554455555454555555554554554555554555555555555555555555545554555445555555555555555554555555545555555554555555555544455\n",
            "After pruning:\n",
            "loss: 1.6407244205474854 - accuracy: 0.4054200053215027 - val_loss: 1.638981819152832 - val_accuracy: 0.40869998931884766\n",
            "layer sizes: [3072, 54, 197, 112, 293, 10]\n",
            "222222222222222222222222222222222222223222223232233322\n",
            "11211211112112222221221212222222221222221222222221222212222222222222222222222222222222222222222222222222222322223222222222223222222322222222233222222323222333332233332322223223332323223232233333333\n",
            "1211111111122212122112222212212112222222222222222222222222222222232222222222223232232222232222232222322232322233\n",
            "11111211121111112121221222122112221222221111222212222222222222222222222212221222222222222222222222222222222222222222222322222222222222322222333222222232223223223222323223223323233333223223323333332332323233333333333333232332333223323233333333333233332333333323333333332333333333333333333333333\n",
            "Epoch 2/10\n",
            "Before growing:\n",
            "loss: 1.6407244205474854 - accuracy: 0.4054200053215027 - val_loss: 1.638981819152832 - val_accuracy: 0.40869998931884766\n",
            "layer sizes: [3072, 54, 197, 112, 293, 10]\n",
            "222222222222222222222222222222222222223222223232233322\n",
            "11211211112112222221221212222222221222221222222221222212222222222222222222222222222222222222222222222222222322223222222222223222222322222222233222222323222333332233332322223223332323223232233333333\n",
            "1211111111122212122112222212212112222222222222222222222222222222232222222222223232232222232222232222322232322233\n",
            "11111211121111112121221222122112221222221111222212222222222222222222222212221222222222222222222222222222222222222222222322222222222222322222333222222232223223223222323223223323233333223223323333332332323233333333333333232332333223323233333333333233332333333323333333332333333333333333333333333\n",
            "After growing:\n",
            "loss: 1.6407244205474854 - accuracy: 0.4054200053215027 - val_loss: 1.6389816999435425 - val_accuracy: 0.40869998931884766\n",
            "layer sizes: [3072, 74, 236, 134, 351, 10]\n",
            "22222222222222222222222222222222222222322222323223332255555555555555555555\n",
            "11211211112112222221221212222222221222221222222221222212222222222222222222222222222222222222222222222222222322223222222222223222222322222222233222222323222333332233332322223223332323223232233333333444444444444444444444444444444444444444\n",
            "12111111111222121221122222122121122222222222222222222222222222222322222222222232322322222322222322223222323222334444444444444444444444\n",
            "111112111211111121212212221221122212222211112222122222222222222222222222122212222222222222222222222222222222222222222223222222222222223222223332222222322232232232223232232233232333332232233233333323323232333333333333332323323332233232333333333332333323333333233333333323333333333333333333333334444444444444444444444444444444444444444444444444444444444\n",
            "Before pruning:\n",
            "loss: 1.556762456893921 - accuracy: 0.43751999735832214 - val_loss: 1.571761131286621 - val_accuracy: 0.4309999942779541\n",
            "layer sizes: [3072, 74, 236, 134, 351, 10]\n",
            "12122211211122212222122423323223442244443314344444334444444444444444444454\n",
            "11111111111111112211211212121222221221221212222221222212222222222421121222331222322222222222422412222324232532255422442244225425422542355442244234552535522554543454553424555545554545535453455554554555555555555555555555555555555555555555\n",
            "11111111111111121121111222112111122122222222224422254225422542225522424225244554554542525554545555555454545555555555555555555555555555\n",
            "111111111111111111212112221111122211221211111122122222212222122222221222122212232232222222214222222222233242222222422234422332244342234333434443243222423344243443424442233344342444434344444444444444434243444444444344344443443343244342444434344444444444444444444444344444444444444444434444443344444444444444444444444444444444444444444444444444444444444\n",
            "After pruning:\n",
            "loss: 1.5569236278533936 - accuracy: 0.4376400113105774 - val_loss: 1.571966290473938 - val_accuracy: 0.42989999055862427\n",
            "layer sizes: [3072, 39, 130, 64, 170, 10]\n",
            "121222112111222122221222332322322331333\n",
            "1111111111111111221121121212122222122122121222222122221222222222221121222331222322222222222221222232232322222222222232223232233233\n",
            "1111111111111112112111122211211112212222222222222222222222222222\n",
            "11111111111111111121211222111112221122121111112212222221222212222222122212221223223222222221222222222233222222222223223322322333333232222332332223333233323333333232333333\n",
            "Epoch 3/10\n",
            "Before growing:\n",
            "loss: 1.5569236278533936 - accuracy: 0.4376400113105774 - val_loss: 1.571966290473938 - val_accuracy: 0.42989999055862427\n",
            "layer sizes: [3072, 39, 130, 64, 170, 10]\n",
            "121222112111222122221222332322322331333\n",
            "1111111111111111221121121212122222122122121222222122221222222222221121222331222322222222222221222232232322222222222232223232233233\n",
            "1111111111111112112111122211211112212222222222222222222222222222\n",
            "11111111111111111121211222111112221122121111112212222221222212222222122212221223223222222221222222222233222222222223223322322333333232222332332223333233323333333232333333\n",
            "After growing:\n",
            "loss: 1.5569233894348145 - accuracy: 0.4376400113105774 - val_loss: 1.571966290473938 - val_accuracy: 0.42989999055862427\n",
            "layer sizes: [3072, 59, 156, 84, 204, 10]\n",
            "12122211211122212222122233232232233133355555555555555555555\n",
            "111111111111111122112112121212222212212212122222212222122222222222112122233122232222222222222122223223232222222222223222323223323344444444444444444444444444\n",
            "111111111111111211211112221121111221222222222222222222222222222244444444444444444444\n",
            "111111111111111111212112221111122211221211111122122222212222122222221222122212232232222222212222222222332222222222232233223223333332322223323322233332333233333332323333334444444444444444444444444444444444\n",
            "Before pruning:\n",
            "loss: 1.5130418539047241 - accuracy: 0.45427998900413513 - val_loss: 1.5379393100738525 - val_accuracy: 0.44620001316070557\n",
            "layer sizes: [3072, 59, 156, 84, 204, 10]\n",
            "11121211111122212331112334232233433134444444444444444444444\n",
            "111111111111111122111112121112222211112112141222212222122222222222112124245115244343222222242122324325353242222222325234544224424455555555554555555555555554\n",
            "111111111111111111111112241121111241122242252522224222344445244545555555445555555545\n",
            "111111111111111111211112211111112111221211111122122222222212122222221222132212242243222222212222232222442222223222442444434444444342422433424424243443344344333433334443433343443444443434444444444444444434\n",
            "After pruning:\n",
            "loss: 1.5129624605178833 - accuracy: 0.4542999863624573 - val_loss: 1.5378872156143188 - val_accuracy: 0.44679999351501465\n",
            "layer sizes: [3072, 35, 108, 50, 141, 10]\n",
            "11121211111122212331112332322333313\n",
            "111111111111111122111112121112222211112112112222122221222222222221121221123322222222122323233222222223223222\n",
            "11111111111111111111111221121111211222222222222232\n",
            "111111111111111111211112211111112111221211111122122222222212122222221222132212222322222221222223222222222232222332223322233333333333333333333\n",
            "Epoch 4/10\n",
            "Before growing:\n",
            "loss: 1.5129624605178833 - accuracy: 0.4542999863624573 - val_loss: 1.5378872156143188 - val_accuracy: 0.44679999351501465\n",
            "layer sizes: [3072, 35, 108, 50, 141, 10]\n",
            "11121211111122212331112332322333313\n",
            "111111111111111122111112121112222211112112112222122221222222222221121221123322222222122323233222222223223222\n",
            "11111111111111111111111221121111211222222222222232\n",
            "111111111111111111211112211111112111221211111122122222222212122222221222132212222322222221222223222222222232222332223322233333333333333333333\n",
            "After growing:\n",
            "loss: 1.5129624605178833 - accuracy: 0.4542999863624573 - val_loss: 1.5378872156143188 - val_accuracy: 0.44679999351501465\n",
            "layer sizes: [3072, 55, 129, 70, 169, 10]\n",
            "1112121111112221233111233232233331355555555555555555555\n",
            "111111111111111122111112121112222211112112112222122221222222222221121221123322222222122323233222222223223222444444444444444444444\n",
            "1111111111111111111111122112111121122222222222223244444444444444444444\n",
            "1111111111111111112111122111111121112212111111221222222222121222222212221322122223222222212222232222222222322223322233222333333333333333333334444444444444444444444444444\n",
            "Before pruning:\n",
            "loss: 1.4740278720855713 - accuracy: 0.4695799946784973 - val_loss: 1.50686776638031 - val_accuracy: 0.4593000113964081\n",
            "layer sizes: [3072, 55, 129, 70, 169, 10]\n",
            "1111111111111221133121234232343444344444444444444444444\n",
            "111111111111111112111112121112212211112111112221122221222222222221122222234452222341123434344212222225234422555555555555555555555\n",
            "1111111111111111111111122112111121155354124424425255445455554555555555\n",
            "1111111111111111111111112111111121111212111111221222212222111212222212221422122224322222212223342222222232422223422344233434444434444444444444444444444444444443444444444\n",
            "After pruning:\n",
            "loss: 1.4739677906036377 - accuracy: 0.46959999203681946 - val_loss: 1.5068124532699585 - val_accuracy: 0.45879998803138733\n",
            "layer sizes: [3072, 30, 97, 41, 117, 10]\n",
            "111111111111122113312123232333\n",
            "1111111111111111121111121211122122111121111122211222212222222222211222222322223112333212222222322\n",
            "11111111111111111111111221121111211312222\n",
            "111111111111111111111111211111112111121211111122122221222211121222221222122122223222222122233222222223222223223233333\n",
            "Epoch 5/10\n",
            "Before growing:\n",
            "loss: 1.4739677906036377 - accuracy: 0.46959999203681946 - val_loss: 1.5068124532699585 - val_accuracy: 0.45879998803138733\n",
            "layer sizes: [3072, 30, 97, 41, 117, 10]\n",
            "111111111111122113312123232333\n",
            "1111111111111111121111121211122122111121111122211222212222222222211222222322223112333212222222322\n",
            "11111111111111111111111221121111211312222\n",
            "111111111111111111111111211111112111121211111122122221222211121222221222122122223222222122233222222223222223223233333\n",
            "After growing:\n",
            "loss: 1.4739677906036377 - accuracy: 0.46959999203681946 - val_loss: 1.5068124532699585 - val_accuracy: 0.45879998803138733\n",
            "layer sizes: [3072, 50, 117, 61, 140, 10]\n",
            "11111111111112211331212323233355555555555555555555\n",
            "111111111111111112111112121112212211112111112221122221222222222221122222232222311233321222222232244444444444444444444\n",
            "1111111111111111111111122112111121131222244444444444444444444\n",
            "11111111111111111111111121111111211112121111112212222122221112122222122212212222322222212223322222222322222322323333344444444444444444444444\n",
            "Before pruning:\n",
            "loss: 1.4465709924697876 - accuracy: 0.4802800118923187 - val_loss: 1.4885493516921997 - val_accuracy: 0.4666000008583069\n",
            "layer sizes: [3072, 50, 117, 61, 140, 10]\n",
            "11111111111112211341312423233444444444444444444444\n",
            "111111111111111112111111111111112211112112112221122221222222223221122232242222411144421223223244345555555555555555555\n",
            "1111111111111111111111144111211121141243355455555555555555555\n",
            "11111111111111111111111111111111111112122111112212222121221122122222123212212222422233212224422322222322223432323334334334444444444443443444\n",
            "After pruning:\n",
            "loss: 1.446600317955017 - accuracy: 0.4800800085067749 - val_loss: 1.4885764122009277 - val_accuracy: 0.4668000042438507\n",
            "layer sizes: [3072, 27, 90, 37, 117, 10]\n",
            "111111111111122113131223233\n",
            "111111111111111112111111111111112211112112112221122221222222223221122232222221112122322323\n",
            "1111111111111111111111111121112111233\n",
            "111111111111111111111111111111111111121221111122122221212211221222221232122122222223321222223222223222233232333333333\n",
            "Epoch 6/10\n",
            "Before growing:\n",
            "loss: 1.446600317955017 - accuracy: 0.4800800085067749 - val_loss: 1.4885764122009277 - val_accuracy: 0.4668000042438507\n",
            "layer sizes: [3072, 27, 90, 37, 117, 10]\n",
            "111111111111122113131223233\n",
            "111111111111111112111111111111112211112112112221122221222222223221122232222221112122322323\n",
            "1111111111111111111111111121112111233\n",
            "111111111111111111111111111111111111121221111122122221212211221222221232122122222223321222223222223222233232333333333\n",
            "After growing:\n",
            "loss: 1.446600317955017 - accuracy: 0.4800800085067749 - val_loss: 1.4885764122009277 - val_accuracy: 0.4668000042438507\n",
            "layer sizes: [3072, 47, 110, 57, 140, 10]\n",
            "11111111111112211313122323355555555555555555555\n",
            "11111111111111111211111111111111221111211211222112222122222222322112223222222111212232232344444444444444444444\n",
            "111111111111111111111111112111211123344444444444444444444\n",
            "11111111111111111111111111111111111112122111112212222121221122122222123212212222222332122222322222322223323233333333344444444444444444444444\n",
            "Before pruning:\n",
            "loss: 1.4308992624282837 - accuracy: 0.4865399897098541 - val_loss: 1.4813296794891357 - val_accuracy: 0.4675000011920929\n",
            "layer sizes: [3072, 47, 110, 57, 140, 10]\n",
            "11111111111111211313123324344444444444444444444\n",
            "11111111111111111211111111111111221111211211222112222112222231422111223222223111312242332455555555555555555555\n",
            "111111111111111111111111112111211144555555555555555554545\n",
            "11111111111111111111111111111111111112122111112212212122221122122222224213112232222442122222422222422234434244444444444444444444444444443434\n",
            "After pruning:\n",
            "loss: 1.4308849573135376 - accuracy: 0.48664000630378723 - val_loss: 1.4813146591186523 - val_accuracy: 0.46799999475479126\n",
            "layer sizes: [3072, 26, 87, 34, 102, 10]\n",
            "11111111111111211313123323\n",
            "111111111111111112111111111111112211112112112221122221122222312211122322222311131222332\n",
            "1111111111111111111111111121112111\n",
            "111111111111111111111111111111111111121221111122122121222211221222222221311223222221222222222222233233\n",
            "Epoch 7/10\n",
            "Before growing:\n",
            "loss: 1.4308849573135376 - accuracy: 0.48664000630378723 - val_loss: 1.4813146591186523 - val_accuracy: 0.46799999475479126\n",
            "layer sizes: [3072, 26, 87, 34, 102, 10]\n",
            "11111111111111211313123323\n",
            "111111111111111112111111111111112211112112112221122221122222312211122322222311131222332\n",
            "1111111111111111111111111121112111\n",
            "111111111111111111111111111111111111121221111122122121222211221222222221311223222221222222222222233233\n",
            "After growing:\n",
            "loss: 1.4308849573135376 - accuracy: 0.48664000630378723 - val_loss: 1.4813146591186523 - val_accuracy: 0.46799999475479126\n",
            "layer sizes: [3072, 46, 107, 54, 122, 10]\n",
            "1111111111111121131312332355555555555555555555\n",
            "11111111111111111211111111111111221111211211222112222112222231221112232222231113122233244444444444444444444\n",
            "111111111111111111111111112111211144444444444444444444\n",
            "11111111111111111111111111111111111112122111112212212122221122122222222131122322222122222222222223323344444444444444444444\n",
            "Before pruning:\n",
            "loss: 1.4076555967330933 - accuracy: 0.49535998702049255 - val_loss: 1.465956687927246 - val_accuracy: 0.47350001335144043\n",
            "layer sizes: [3072, 46, 107, 54, 122, 10]\n",
            "1111111111111121131312342444444444444444444444\n",
            "11111111111111111211111111111111221111211211222113222113222241231112242222231124132244255455555555555555555\n",
            "111111111111111111111111112111211155555555555555555554\n",
            "11111111111111111111111111111111111112122211112212212122221222122222222132122422222132222233223223424444444444444444444444\n",
            "After pruning:\n",
            "loss: 1.4078251123428345 - accuracy: 0.495279997587204 - val_loss: 1.4661099910736084 - val_accuracy: 0.47360000014305115\n",
            "layer sizes: [3072, 24, 82, 34, 98, 10]\n",
            "111111111111112113131232\n",
            "1111111111111111121111111111111122111121121122211322211322221231112222222311213222\n",
            "1111111111111111111111111121112111\n",
            "11111111111111111111111111111111111112122211112212212122221222122222222132122222221322222332232232\n",
            "Epoch 8/10\n",
            "Before growing:\n",
            "loss: 1.4078251123428345 - accuracy: 0.495279997587204 - val_loss: 1.4661099910736084 - val_accuracy: 0.47360000014305115\n",
            "layer sizes: [3072, 24, 82, 34, 98, 10]\n",
            "111111111111112113131232\n",
            "1111111111111111121111111111111122111121121122211322211322221231112222222311213222\n",
            "1111111111111111111111111121112111\n",
            "11111111111111111111111111111111111112122211112212212122221222122222222132122222221322222332232232\n",
            "After growing:\n",
            "loss: 1.4078251123428345 - accuracy: 0.495279997587204 - val_loss: 1.4661098718643188 - val_accuracy: 0.47360000014305115\n",
            "layer sizes: [3072, 44, 102, 54, 118, 10]\n",
            "11111111111111211313123255555555555555555555\n",
            "111111111111111112111111111111112211112112112221132221132222123111222222231121322244444444444444444444\n",
            "111111111111111111111111112111211144444444444444444444\n",
            "1111111111111111111111111111111111111212221111221221212222122212222222213212222222132222233223223244444444444444444444\n",
            "Before pruning:\n",
            "loss: 1.3994313478469849 - accuracy: 0.4967400133609772 - val_loss: 1.4618608951568604 - val_accuracy: 0.47540000081062317\n",
            "layer sizes: [3072, 44, 102, 54, 118, 10]\n",
            "11111111111111111313113344334443333434334434\n",
            "111111111111111111111111111111112211112112112231132251142222223111322224241121322345555554545555555555\n",
            "111111111111111111111121112111211155554555555555555545\n",
            "1111111111111111111111112111111111121212221111221221212222122222223222214212222322132232234224224243444344444444444444\n",
            "After pruning:\n",
            "loss: 1.3994557857513428 - accuracy: 0.4967400133609772 - val_loss: 1.4618722200393677 - val_accuracy: 0.47600001096725464\n",
            "layer sizes: [3072, 34, 78, 34, 96, 10]\n",
            "1111111111111111131311333333333333\n",
            "111111111111111111111111111111112211112112112231132211222222311132222211213223\n",
            "1111111111111111111111211121112111\n",
            "111111111111111111111111211111111112121222111122122121222212222222322221212222322132232232222233\n",
            "Epoch 9/10\n",
            "Before growing:\n",
            "loss: 1.3994557857513428 - accuracy: 0.4967400133609772 - val_loss: 1.4618722200393677 - val_accuracy: 0.47600001096725464\n",
            "layer sizes: [3072, 34, 78, 34, 96, 10]\n",
            "1111111111111111131311333333333333\n",
            "111111111111111111111111111111112211112112112231132211222222311132222211213223\n",
            "1111111111111111111111211121112111\n",
            "111111111111111111111111211111111112121222111122122121222212222222322221212222322132232232222233\n",
            "After growing:\n",
            "loss: 1.3994559049606323 - accuracy: 0.4967400133609772 - val_loss: 1.4618722200393677 - val_accuracy: 0.47600001096725464\n",
            "layer sizes: [3072, 54, 98, 54, 116, 10]\n",
            "111111111111111113131133333333333355555555555555555555\n",
            "11111111111111111111111111111111221111211211223113221122222231113222221121322344444444444444444444\n",
            "111111111111111111111121112111211144444444444444444444\n",
            "11111111111111111111111121111111111212122211112212212122221222222232222121222232213223223222223344444444444444444444\n",
            "Before pruning:\n",
            "loss: 1.3949309587478638 - accuracy: 0.4991999864578247 - val_loss: 1.4618464708328247 - val_accuracy: 0.47269999980926514\n",
            "layer sizes: [3072, 54, 98, 54, 116, 10]\n",
            "111111111111111113131133444434444444444444444444444444\n",
            "11111111111111111111111111111111221111211211224115221132222241114222221121432355555555555555555545\n",
            "111111111111111111111121112111311155555555555555455555\n",
            "11111111111111111111111121111111111212122211112212212122221222222232222121322232214224323322223444444444444444444344\n",
            "After pruning:\n",
            "loss: 1.3949415683746338 - accuracy: 0.4991999864578247 - val_loss: 1.4618685245513916 - val_accuracy: 0.47269999980926514\n",
            "layer sizes: [3072, 25, 73, 34, 94, 10]\n",
            "1111111111111111131311333\n",
            "1111111111111111111111111111111122111121121122112211322222111222221121323\n",
            "1111111111111111111111211121113111\n",
            "1111111111111111111111112111111111121212221111221221212222122222223222212132223221223233222233\n",
            "Epoch 10/10\n",
            "Before growing:\n",
            "loss: 1.3949415683746338 - accuracy: 0.4991999864578247 - val_loss: 1.4618685245513916 - val_accuracy: 0.47269999980926514\n",
            "layer sizes: [3072, 25, 73, 34, 94, 10]\n",
            "1111111111111111131311333\n",
            "1111111111111111111111111111111122111121121122112211322222111222221121323\n",
            "1111111111111111111111211121113111\n",
            "1111111111111111111111112111111111121212221111221221212222122222223222212132223221223233222233\n",
            "After growing:\n",
            "loss: 1.3949416875839233 - accuracy: 0.4991999864578247 - val_loss: 1.4618685245513916 - val_accuracy: 0.47269999980926514\n",
            "layer sizes: [3072, 45, 93, 54, 114, 10]\n",
            "111111111111111113131133355555555555555555555\n",
            "111111111111111111111111111111112211112112112211221132222211122222112132344444444444444444444\n",
            "111111111111111111111121112111311144444444444444444444\n",
            "111111111111111111111111211111111112121222111122122121222212222222322221213222322122323322223344444444444444444444\n",
            "Before pruning:\n",
            "loss: 1.3745191097259521 - accuracy: 0.5087800025939941 - val_loss: 1.450331449508667 - val_accuracy: 0.4821000099182129\n",
            "layer sizes: [3072, 45, 93, 54, 114, 10]\n",
            "111111111111111113131133333344433434333434444\n",
            "111111111111111111111111111111112111112112112211221142232311132322112143455555555555555554555\n",
            "111111111111111111111121112111411155555554555455555545\n",
            "111111111111111111111111211111111112121222111123121131222212222222422221213223422122324432324333444343443444344443\n",
            "After pruning:\n",
            "loss: 1.3745399713516235 - accuracy: 0.5087599754333496 - val_loss: 1.4503381252288818 - val_accuracy: 0.48179998993873596\n",
            "layer sizes: [3072, 35, 70, 33, 96, 10]\n",
            "11111111111111111313113333333333333\n",
            "1111111111111111111111111111111121111121121122112211223231113232211213\n",
            "111111111111111111111121112111111\n",
            "111111111111111111111111211111111112121222111123121131222212222222222212132232212232323233333333\n",
            "CPU times: user 5min 47s, sys: 5.01 s, total: 5min 52s\n",
            "Wall time: 5min 48s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a29DTkin27Ai",
        "outputId": "c18fa3d9-2081-4836-baab-5ed34cae0638"
      },
      "source": [
        "%%time\n",
        "\n",
        "model = SSModel(layer_sizes=[3072, 1000, 1000, 1000, 1000, 10], activation='selu', regularization_penalty=0.000001, regularization_method='weighted_l1', kernel_initializer='lecun_normal')\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "train_model(model, X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "Before growing:\n",
            "loss: 2.662282705307007 - accuracy: 0.1032399982213974 - val_loss: 2.657341718673706 - val_accuracy: 0.10700000077486038\n",
            "layer sizes: [3072, 1000, 1000, 1000, 1000, 10]\n",
            "2222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222\n",
            "2222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222\n",
            "2222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222\n",
            "2222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222\n",
            "After growing:\n",
            "loss: 2.662282705307007 - accuracy: 0.1032399982213974 - val_loss: 2.657341718673706 - val_accuracy: 0.10700000077486038\n",
            "layer sizes: [3072, 1200, 1200, 1200, 1200, 10]\n",
            "222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222255555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555\n",
            "222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222255555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555\n",
            "222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222255555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555\n",
            "222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222255555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555\n",
            "Before pruning:\n",
            "loss: 1.6055657863616943 - accuracy: 0.424560010433197 - val_loss: 1.6237467527389526 - val_accuracy: 0.4180999994277954\n",
            "layer sizes: [3072, 1200, 1200, 1200, 1200, 10]\n",
            "222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222232222223222222233222223223222222232233233232333323222233223222223332323332343324243333432322343242333342344433432333224234224434423343333343444434443334443443443244344443324444343444444444334444444444443444444344344444444444442244444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444455555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555455555555555555555555555555555555555555555555555555555555555555555555555555555\n",
            "222222222222222222222222222222222222222222222222222222222222222222222222222221222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222232222222222222222222222222222222222232222222222222222222222222222222323222222222222222223233242324222222222222222222222222322222222223222223222222222232322223323222233232342333322323232232232222222322322332222333333233233222333222222223322432342323224434222422242422243232333233322333233223324332423224243333224332333234244322233342223324334344422334233332334343232224434322423444243432324333255555555555555555555555555545555555555555545555545555555544555545555555555555554455554554554555555555555555555555555555555555555555555555555555555555555455555555555555545555545555555545555555555555555\n",
            "222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222223222222222222222222222222222222222222222222222222232222222222222222222222222222222232222223232222222222322232322222322222222222222222222222332222234322232322222232222222332232333223232223222242332232223222222242222223232222222223423333242222342322322232234333222232223242224333422322422332442242432343242333324323322232232233324342223243222324222422422322222223223443322233234424234443344324434242224432434444423433322344442224443344443323434244234442444333433333432455555554554455555455445554555545545555455555545455555455455555555545554555545545554555455445555555554555445545555555455555545554455545454455454455545554454554545455555555455555555555555555555545545554\n",
            "222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222232222222223222222222222222222222222222222222222222222222322222222222222222222222222322222222222222222222222222222222222222222222222222222222222222222322222222222222222222222222222222222222222232222222222222223222222222222222444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\n",
            "After pruning:\n",
            "loss: 1.5971894264221191 - accuracy: 0.4270800054073334 - val_loss: 1.6151868104934692 - val_accuracy: 0.42179998755455017\n",
            "layer sizes: [3072, 404, 961, 927, 999, 10]\n",
            "22222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222223222222322222223322222322322222223223323323233332322223322322222333232333233322333332322332233332333323332223223233333333333333323332333333322\n",
            "2222222222222222222222222222222222222222222222222222222222222222222222222222212222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222322222222222222222222222222222222222322222222222222222222222222222223232222222222222222232332232222222222222222222222222322222222223222223222222222232322223323222233232323333223232322322322222223223223322223333332332332223332222222233223232323223222222222232323332333223332332233233223222333322332333232322233322233233322332333323333232223322232332323332\n",
            "222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222223222222222222222222222222222222222222222222222222232222222222222222222222222222222232222223232222222222322232322222322222222222222222222222332222233222323222222322222223322323332232322232222233223222322222222222223232222222223233332222232322322232233332222322232222333223222233222232332233332323322232232233323222323222322222222322222223223332223222333323222232323333223222333323322323333333332\n",
            "222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222232222222223222222222222222222222222222222222222222222222322222222222222222222222222322222222222222222222222222222222222222222222222222222222222222222322222222222222222222222222222222222222222232222222222222223222222222222222\n",
            "Epoch 2/10\n",
            "Before growing:\n",
            "loss: 1.5971894264221191 - accuracy: 0.4270800054073334 - val_loss: 1.6151868104934692 - val_accuracy: 0.42179998755455017\n",
            "layer sizes: [3072, 404, 961, 927, 999, 10]\n",
            "22222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222223222222322222223322222322322222223223323323233332322223322322222333232333233322333332322332233332333323332223223233333333333333323332333333322\n",
            "2222222222222222222222222222222222222222222222222222222222222222222222222222212222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222322222222222222222222222222222222222322222222222222222222222222222223232222222222222222232332232222222222222222222222222322222222223222223222222222232322223323222233232323333223232322322322222223223223322223333332332332223332222222233223232323223222222222232323332333223332332233233223222333322332333232322233322233233322332333323333232223322232332323332\n",
            "222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222223222222222222222222222222222222222222222222222222232222222222222222222222222222222232222223232222222222322232322222322222222222222222222222332222233222323222222322222223322323332232322232222233223222322222222222223232222222223233332222232322322232233332222322232222333223222233222232332233332323322232232233323222323222322222222322222223223332223222333323222232323333223222333323322323333333332\n",
            "222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222232222222223222222222222222222222222222222222222222222222322222222222222222222222222322222222222222222222222222222222222222222222222222222222222222222322222222222222222222222222222222222222222232222222222222223222222222222222\n",
            "After growing:\n",
            "loss: 1.5971894264221191 - accuracy: 0.4270800054073334 - val_loss: 1.6151866912841797 - val_accuracy: 0.42179998755455017\n",
            "layer sizes: [3072, 484, 1153, 1112, 1198, 10]\n",
            "2222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222322222232222222332222232232222222322332332323333232222332232222233323233323332233333232233223333233332333222322323333333333333332333233333332255555555555555555555555555555555555555555555555555555555555555555555555555555555\n",
            "2222222222222222222222222222222222222222222222222222222222222222222222222222212222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222322222222222222222222222222222222222322222222222222222222222222222223232222222222222222232332232222222222222222222222222322222222223222223222222222232322223323222233232323333223232322322322222223223223322223333332332332223332222222233223232323223222222222232323332333223332332233233223222333322332333232322233322233233322332333323333232223322232332323332444444444544444444444444444444444445444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444544444544445444444444444444544444444444444454444444\n",
            "22222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222322222222222222222222222222222222222222222222222223222222222222222222222222222222223222222323222222222232223232222232222222222222222222222233222223322232322222232222222332232333223232223222223322322232222222222222323222222222323333222223232232223223333222232223222233322322223322223233223333232332223223223332322232322232222222232222222322333222322233332322223232333322322233332332232333333333255555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555\n",
            "2222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222322222222232222222222222222222222222222222222222222222223222222222222222222222222223222222222222222222222222222222222222222222222222222222222222222223222222222222222222222222222222222222222222322222222222222232222222222222225555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555\n",
            "Before pruning:\n",
            "loss: 1.4313263893127441 - accuracy: 0.48646000027656555 - val_loss: 1.4675519466400146 - val_accuracy: 0.4772000014781952\n",
            "layer sizes: [3072, 484, 1153, 1112, 1198, 10]\n",
            "2222222222221222212121221222222222222222222222222211222221222223212221222121223222222222222232323222312233323312333333223232232333333322323233323333333233334432333343333332332333323433344333334343333433234334333443434433334334333433343334433334334443433334333343443243444344444444344343434444344434443433344444444444444444444444443444444443433444434444444444444444434444344444444444444444444434444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\n",
            "2211221122212122221122222222222122222222222222222212221222221222122222222221212212222222212222212212222222122222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222223222222222222322222222222222222222222222222232223222222222222422222232222232222222222322222222223224232233232222223223333322322423322223242323223223332322232223232222242232322443332333324423342342332343334423333423334322443433332323323343444334432334333234424324434434334424244333443444334244333332433424433344434424333434433443344334344424444333444433443444444444234444444343444334444444444433444344434344443434444444444444444344444444444344434443444443444344444444444443443444444444434343434444444444344444444444444343444444444444444434434434444444444444444444444444444444444444444444344444344344434444444444444444444444444444444444444433444433434444444444443434444443444344444444444444434444444444444443444344444444444444444444545545454555544454454555445445545554444555555544445454454455555554555545444545555555555555555554455545455544455555455555445445545555555545544544545555544545555545454455544444554555455455455545\n",
            "21222222222211122222212222221222222122222222222222222222222221222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222223222222222221222332242223222222222222332323222223223423222422432242222242242224422224224443444444423432244444444423424234444324222442432444444244432244243324444234444344433434244444244444422434442444434444344434444424444443444344444444444444444442434444444444444444444444444344434442444444444444444444334444444444444444444434244444444444444444444444444444444444444444444443444444443444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444443444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444445554545554454545445555545545444455454545445554544455445554545555545455445544555544554545445545555455444444455554544544444455554445555555545554555455445554554445545454455554545445554554\n",
            "2112222222222222122222222222222122222222212222222222222222222222222222222222222122222222222222222222222222222222222222212222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222242222222222222222222222222222222222222222223222222222322222232222222242222222222222222223222222222222222232232222322222222222222222422222222223224222223222442222222422222222222424434222223223223324224222222242422442222223222224222222222422222224222222223422243232322222422442232243222234422224222222324444343422242242332444323232332324224222224234324242222244442223442332332232244243232224434233324244423233242423423244432434224432343244232322422232423342422342242423444243343442242223444344424222324343334434242442444344443444443442442434443444444244333344424444434442342444434444442434344434444334333434444443444444424443444333344244443434424444344443444434244443422434444444444444443442444344442344442444344423334444434324444444444444434344434444443343444444444444444334444444434444443343444444444444444343444434444444444444444444443433434344334334444444344444444434443444444444433443434443444434344444444344334444443344433444444434444443444433434444443444443444443444434\n",
            "After pruning:\n",
            "loss: 1.4318718910217285 - accuracy: 0.48625999689102173 - val_loss: 1.4681748151779175 - val_accuracy: 0.476500004529953\n",
            "layer sizes: [3072, 255, 555, 294, 745, 10]\n",
            "222222222222122221212122122222222222222222222222221122222122222321222122212122322222222222223232322231223332331233333322323223233333332232323332333333323333323333333333233233332333333333333333323333333333333333333333333333333333333333233333333333333333333\n",
            "221122112221212222112222222222212222222222222222221222122222122212222222222121221222222221222221221222222212222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222322222222222232222222222222222222222222222223222322222222222222222232222232222222222322222222223222322332322222232233333223222332222322323223223332322232223232222222323223332333322332323323333233332333322333332323323333332333332323233332233333323333323323333233333333333233333323333333333333333333333333333333333333333333333\n",
            "212222222222111222222122222212222221222222222222222222222222212222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222232222222222212223322222322222222222233232322222322323222223222222222222222222323322232233222223223222332233333222232333233233323332333\n",
            "2112222222222222122222222222222122222222212222222222222222222222222222222222222122222222222222222222222222222222222222212222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222232222222223222222322222222222222222222222222322222222222222223223222232222222222222222222222222223222222232222222222222222222222322222322322332222222222222222222322222222222222222222222222222322232323222222222322322223222222222232332222223323232323323222222222332222222222323323322322232322232333222323322232323232232332232322222322332223222232333222223322223233333222333223323333232323233333333332333332332333232233232323233333233333333333333333333333333333333333333333333333333\n",
            "Epoch 3/10\n",
            "Before growing:\n",
            "loss: 1.4318718910217285 - accuracy: 0.48625999689102173 - val_loss: 1.4681748151779175 - val_accuracy: 0.476500004529953\n",
            "layer sizes: [3072, 255, 555, 294, 745, 10]\n",
            "222222222222122221212122122222222222222222222222221122222122222321222122212122322222222222223232322231223332331233333322323223233333332232323332333333323333323333333333233233332333333333333333323333333333333333333333333333333333333333233333333333333333333\n",
            "221122112221212222112222222222212222222222222222221222122222122212222222222121221222222221222221221222222212222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222322222222222232222222222222222222222222222223222322222222222222222232222232222222222322222222223222322332322222232233333223222332222322323223223332322232223232222222323223332333322332323323333233332333322333332323323333332333332323233332233333323333323323333233333333333233333323333333333333333333333333333333333333333333333\n",
            "212222222222111222222122222212222221222222222222222222222222212222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222232222222222212223322222322222222222233232322222322323222223222222222222222222323322232233222223223222332233333222232333233233323332333\n",
            "2112222222222222122222222222222122222222212222222222222222222222222222222222222122222222222222222222222222222222222222212222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222232222222223222222322222222222222222222222222322222222222222223223222232222222222222222222222222223222222232222222222222222222222322222322322332222222222222222222322222222222222222222222222222322232323222222222322322223222222222232332222223323232323323222222222332222222222323323322322232322232333222323322232323232232332232322222322332223222232333222223322223233333222333223323333232323233333333332333332332333232233232323233333233333333333333333333333333333333333333333333333333\n",
            "After growing:\n",
            "loss: 1.4318718910217285 - accuracy: 0.48625999689102173 - val_loss: 1.4681748151779175 - val_accuracy: 0.476500004529953\n",
            "layer sizes: [3072, 306, 666, 352, 894, 10]\n",
            "222222222222122221212122122222222222222222222222221122222122222321222122212122322222222222223232322231223332331233333322323223233333332232323332333333323333323333333333233233332333333333333333323333333333333333333333333333333333333333233333333333333333333555555555555555555555555555555555555555555555555555\n",
            "221122112221212222112222222222212222222222222222221222122222122212222222222121221222222221222221221222222212222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222322222222222232222222222222222222222222222223222322222222222222222232222232222222222322222222223222322332322222232233333223222332222322323223223332322232223232222222323223332333322332323323333233332333322333332323323333332333332323233332233333323333323323333233333333333233333323333333333333333333333333333333333333333333333444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\n",
            "2122222222221112222221222222122222212222222222222222222222222122222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222322222222222122233222223222222222222332323222223223232222232222222222222222223233222322332222232232223322333332222323332332333233323335555555555555555555555555555555555555555555555555555555555\n",
            "211222222222222212222222222222212222222221222222222222222222222222222222222222212222222222222222222222222222222222222221222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222223222222222322222232222222222222222222222222232222222222222222322322223222222222222222222222222222322222223222222222222222222222232222232232233222222222222222222232222222222222222222222222222232223232322222222232232222322222222223233222222332323232332322222222233222222222232332332232223232223233322232332223232323223233223232222232233222322223233322222332222323333322233322332333323232323333333333233333233233323223323232323333323333333333333333333333333333333333333333333333333344444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\n",
            "Before pruning:\n",
            "loss: 1.3631645441055298 - accuracy: 0.5158799886703491 - val_loss: 1.4235961437225342 - val_accuracy: 0.4952000081539154\n",
            "layer sizes: [3072, 306, 666, 352, 894, 10]\n",
            "112122111122111221111111112111121211211221121222111122222121222321223123212122313232322212233232333231323333331233333332333313333343331133433333433333313333333333333333333243333343333333333333333334343334443343433344443444434343433434334344433343344344443444444444443443444444444443444444444444444444444444\n",
            "111121111211212122112111121111212221222222112212121221112222121212212122222121211221212121222121221222112211212212222222222222212222222222222222222222222222212222221212212212222222112222222222332222232222222222222222224322222222222332222233222232232322222323323222232323322224223432322332332223232342333232233332334322323332333323432332333233332433344233324333233323343223443432442333333343333233433323343433343343434334344243442444333443344333443333443434334333434444334343443443434334344433443334434344444433444444434344443354444443444443444444444444434444454445454544444454445444544455444445544544454545455544444454544454444444454554444544545444454555444545554454\n",
            "2112112112221112112221222121112222211222212211222222222222222112222212232221221222222122211222224221243223222222224322222332123221233243322424324422222223224323424424244423144244242424342424444444344324432244234344444434444433442344444444444244342444444444444444444444444444444344444444344443445454544544455445545545454545555444544455454544545554545454\n",
            "111221122112211212211212222222211122122221222122221222222122222212222222221212212122122222222222221222222221222222221221222222221222212222242222222222222222422222222222222232222222222224222422222222222234232222212222322222222222242422224224222322223222424222232242244234222442442244242422222222432222223244222244322224422442422444444224242224424442222422442344242444344424344222232443442243344244422444244444424224424432322342444242444334432442344444242444444244244444324244444444442442443244424444443324444444442444444444342344424234444444444442444444442444444444444442444444444444444224242444443444434442444444444442444444424444444444434442444444444434444444444444444444444424444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\n",
            "After pruning:\n",
            "loss: 1.3628919124603271 - accuracy: 0.515779972076416 - val_loss: 1.4233094453811646 - val_accuracy: 0.4952999949455261\n",
            "layer sizes: [3072, 222, 445, 184, 386, 10]\n",
            "112122111122111221111111112111121211211221121222111122222121222321223123212122313232322212233232333231323333331233333332333313333333311333333333333313333333333333333333233333333333333333333333333333333333333333333333333333\n",
            "1111211112112121221121111211112122212222221122121212211122221212122121222221212112212121212221212212221122112122122222222222222122222222222222222222222222222122222212122122122222221122222222223322222322222222222222222232222222222233222223322223223232222232332322223232332222223323223323322232323233323223333233322323332333323323323332333323332333233323332333223332233333333333233333233333333333332323333333333333333333333333333333333333333333333\n",
            "2112112112221112112221222121112222211222212211222222222222222112222212232221221222222122211222222212322322222222322222332123221233233222322222222322323222231222232233232223333323232333\n",
            "11122112211221121221121222222221112212222122212222122222212222221222222222121221212212222222222222122222222122222222122122222222122221222222222222222222222222222222222222322222222222222222222222222232322222122223222222222222222222222232222322222222322222322222222222222223222222322222322222222222222222222222322323222232322332222222232322322233322322223222232233223232232222222332223232\n",
            "Epoch 4/10\n",
            "Before growing:\n",
            "loss: 1.3628919124603271 - accuracy: 0.515779972076416 - val_loss: 1.4233094453811646 - val_accuracy: 0.4952999949455261\n",
            "layer sizes: [3072, 222, 445, 184, 386, 10]\n",
            "112122111122111221111111112111121211211221121222111122222121222321223123212122313232322212233232333231323333331233333332333313333333311333333333333313333333333333333333233333333333333333333333333333333333333333333333333333\n",
            "1111211112112121221121111211112122212222221122121212211122221212122121222221212112212121212221212212221122112122122222222222222122222222222222222222222222222122222212122122122222221122222222223322222322222222222222222232222222222233222223322223223232222232332322223232332222223323223323322232323233323223333233322323332333323323323332333323332333233323332333223332233333333333233333233333333333332323333333333333333333333333333333333333333333333\n",
            "2112112112221112112221222121112222211222212211222222222222222112222212232221221222222122211222222212322322222222322222332123221233233222322222222322323222231222232233232223333323232333\n",
            "11122112211221121221121222222221112212222122212222122222212222221222222222121221212212222222222222122222222122222222122122222222122221222222222222222222222222222222222222322222222222222222222222222232322222122223222222222222222222222232222322222222322222322222222222222223222222322222322222222222222222222222322323222232322332222222232322322233322322223222232233223232232222222332223232\n",
            "After growing:\n",
            "loss: 1.3628919124603271 - accuracy: 0.515779972076416 - val_loss: 1.423309564590454 - val_accuracy: 0.4952999949455261\n",
            "layer sizes: [3072, 266, 534, 220, 463, 10]\n",
            "11212211112211122111111111211112121121122112122211112222212122232122312321212231323232221223323233323132333333123333333233331333333331133333333333331333333333333333333323333333333333333333333333333333333333333333333333333355555555555555555555555555555555555555555555\n",
            "111121111211212122112111121111212221222222112212121221112222121212212122222121211221212121222121221222112211212212222222222222212222222222222222222222222222212222221212212212222222112222222222332222232222222222222222223222222222223322222332222322323222223233232222323233222222332322332332223232323332322333323332232333233332332332333233332333233323332333233322333223333333333323333323333333333333232333333333333333333333333333333333333333333333344444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\n",
            "2112112112221112112221222121112222211222212211222222222222222112222212232221221222222122211222222212322322222222322222332123221233233222322222222322323222231222232233232223333323232333555555555555555555555555555555555555\n",
            "1112211221122112122112122222222111221222212221222212222221222222122222222212122121221222222222222212222222212222222212212222222212222122222222222222222222222222222222222232222222222222222222222222223232222212222322222222222222222222223222232222222232222232222222222222222322222232222232222222222222222222222232232322223232233222222223232232223332232222322223223322323223222222233222323244444444444444444444444444444444444444444444444444444444444444444444444444444\n",
            "Before pruning:\n",
            "loss: 1.3042412996292114 - accuracy: 0.5326799750328064 - val_loss: 1.3891916275024414 - val_accuracy: 0.5052000284194946\n",
            "layer sizes: [3072, 266, 534, 220, 463, 10]\n",
            "11111111111111111111111111111112121111111112121111112222121123232122312331213331323231331333323233333133333333123333333333331333333331133333333333331333333333433333334323333333333333343443333333333333343334343333333333443444343434343433344443443444444343444443443444\n",
            "111121111111111121112111121111111211212111112211111111111222111212112112222111211221112111222111211122112211112212222222212122211222222222122222221222222322212222221212212312232222112222222322432323232213232234122232323223222223223332233443333422334232223333233222334333232323433422332432333343433434432333333332342433244333343443443343442444233423343434244433444233443333444333344433333444433344243433344344434344444443443443444444444444434343455555554445445455555555555455554455445555355555555555544555555545455355555555455554555555\n",
            "1112111111221112112211111121111112211211112111221222121122222113223212233331321132222122411422233212432333423334322223342144331433333223422333324334434413341233432144243344433423344433544454454445545454555545444455454445\n",
            "1112111221122112122112122222221111212222111221221212222211222222122122122212111121221232221221222112232212212412222212412222122212222122222222222222422224222421222222224342222242242222244422222222323232422212224422322242222322422222244222242222222242242242222232322222424423224242224242244422422222444222424442434442324442344444442244342343444444442222443324244424444234444444444424424444444444443444443444443444444444444444443444444434444444444444444444434444344\n",
            "After pruning:\n",
            "loss: 1.3042476177215576 - accuracy: 0.5328999757766724 - val_loss: 1.3890563249588013 - val_accuracy: 0.5049999952316284\n",
            "layer sizes: [3072, 225, 358, 157, 301, 10]\n",
            "111111111111111111111111111111121211111111121211111122221211232321223123312133313232313313333232333331333333331233333333333313333333311333333333333313333333333333333323333333333333333333333333333333333333333333333333333333333\n",
            "1111211111111111211121111211111112112121111122111111111112221112121121122221112112211121112221112111221122111122122222222121222112222222221222222212222223222122222212122123122322221122222223223232323221323223122232323223222223223332233333322332322233332332223333323232333223323233333333323333333323233233333333322332333323323333333333333333332333333333333333\n",
            "1112111111221112112211111121111112211211112111221222121122222113223212233331321132222122112223321232333233332222332133133333223223333233313312333212333323333\n",
            "1112111221122112122112122222221111212222111221221212222211222222122122122212111121221232221221222112232212212122222121222212221222212222222222222222222222122222222322222222222222222222323232222122222322222223222222222222222222222222222223232222222322222222222222222222232322322323322223322223223333333\n",
            "Epoch 5/10\n",
            "Before growing:\n",
            "loss: 1.3042476177215576 - accuracy: 0.5328999757766724 - val_loss: 1.3890563249588013 - val_accuracy: 0.5049999952316284\n",
            "layer sizes: [3072, 225, 358, 157, 301, 10]\n",
            "111111111111111111111111111111121211111111121211111122221211232321223123312133313232313313333232333331333333331233333333333313333333311333333333333313333333333333333323333333333333333333333333333333333333333333333333333333333\n",
            "1111211111111111211121111211111112112121111122111111111112221112121121122221112112211121112221112111221122111122122222222121222112222222221222222212222223222122222212122123122322221122222223223232323221323223122232323223222223223332233333322332322233332332223333323232333223323233333333323333333323233233333333322332333323323333333333333333332333333333333333\n",
            "1112111111221112112211111121111112211211112111221222121122222113223212233331321132222122112223321232333233332222332133133333223223333233313312333212333323333\n",
            "1112111221122112122112122222221111212222111221221212222211222222122122122212111121221232221221222112232212212122222121222212221222212222222222222222222222122222222322222222222222222222323232222122222322222223222222222222222222222222222223232222222322222222222222222222232322322323322223322223223333333\n",
            "After growing:\n",
            "loss: 1.3042476177215576 - accuracy: 0.5328999757766724 - val_loss: 1.3890563249588013 - val_accuracy: 0.5049999952316284\n",
            "layer sizes: [3072, 270, 429, 188, 361, 10]\n",
            "111111111111111111111111111111121211111111121211111122221211232321223123312133313232313313333232333331333333331233333333333313333333311333333333333313333333333333333323333333333333333333333333333333333333333333333333333333333555555555555555555555555555555555555555555555\n",
            "111121111111111121112111121111111211212111112211111111111222111212112112222111211221112111222111211122112211112212222222212122211222222222122222221222222322212222221212212312232222112222222322323232322132322312223232322322222322333223333332233232223333233222333332323233322332323333333332333333332323323333333332233233332332333333333333333333233333333333333344444444444444444444444444444444444444444444444444444444444444444444444\n",
            "11121111112211121122111111211111122112111121112212221211222221132232122333313211322221221122233212323332333322223321331333332232233332333133123332123333233334444444444444444444444444444444\n",
            "1112111221122112122112122222221111212222111221221212222211222222122122122212111121221232221221222112232212212122222121222212221222212222222222222222222222122222222322222222222222222222323232222122222322222223222222222222222222222222222223232222222322222222222222222222232322322323322223322223223333333444444444444444444444444444444444444444444444444444444444444\n",
            "Before pruning:\n",
            "loss: 1.2620947360992432 - accuracy: 0.5509600043296814 - val_loss: 1.3633660078048706 - val_accuracy: 0.5145999789237976\n",
            "layer sizes: [3072, 270, 429, 188, 361, 10]\n",
            "111111111111111111111111111111111211111111111211111122221212232311223123312133323232313323333233333331333333331233333333333313333333311333333343433423333333333333333324333443333344333343333333343333333343334444444444444444444444444444444444444444443444444444444444444434\n",
            "111111111111111111112111111111111211211111111111111111111212111111111112222111211111112111122111211112112211112211222122212112311222132222122232221222223332312232221212212312242223113222222312323233423132322312333333322322332422333223333333333232233443233323433442333334332432323333434332433333433433434334434433234334342332434333344333343344234344444443444444544444444444444444454444454444444444444444444444444444444444444444445\n",
            "11111111112211121112111111111111121111111121112212221211222321142342123443313311432231221111443212334343443434343431341444434233233332434133124441124344244435454545554455555545554444454545\n",
            "1112111211122112112112121222221111111222111221211212222212122224122122122212111121211242221221221112242212212121222121242212221222212422242222224222222222112232222422222222222221222224424242222122424424222244224344242224224122242444424324244222424442242243422342442244342433444444422424422444224444444444444444444444444443444443444444444444444444444444444444444\n",
            "After pruning:\n",
            "loss: 1.262412667274475 - accuracy: 0.5507799983024597 - val_loss: 1.363599181175232 - val_accuracy: 0.5142999887466431\n",
            "layer sizes: [3072, 197, 315, 125, 236, 10]\n",
            "11111111111111111111111111111111121111111111121111112222121223231122312331213332323231332333323333333133333333123333333333331333333331133333333332333333333333333332333333333333333333333333333333333\n",
            "111111111111111111112111111111111211211111111111111111111212111111111112222111211111112111122111211112112211112211222122212112311222132222122232221222223332312232221212212312222231132222223123232332313232231233333332232233222333223333333333232233323332333233333332323233333332333333333333333233332332333333333332333\n",
            "11111111112211121112111111111111121111111121112212221211222321123212333133113223122111132123333333331313233233332313312112323\n",
            "11121112111221121121121212222211111112221112212112122222121222212212212221211112121122221221221112222122121212221212221222122221222222222222222222211223222222222222222221222222222221222222222232222221222223222222222232232223233222222233\n",
            "Epoch 6/10\n",
            "Before growing:\n",
            "loss: 1.262412667274475 - accuracy: 0.5507799983024597 - val_loss: 1.363599181175232 - val_accuracy: 0.5142999887466431\n",
            "layer sizes: [3072, 197, 315, 125, 236, 10]\n",
            "11111111111111111111111111111111121111111111121111112222121223231122312331213332323231332333323333333133333333123333333333331333333331133333333332333333333333333332333333333333333333333333333333333\n",
            "111111111111111111112111111111111211211111111111111111111212111111111112222111211111112111122111211112112211112211222122212112311222132222122232221222223332312232221212212312222231132222223123232332313232231233333332232233222333223333333333232233323332333233333332323233333332333333333333333233332332333333333332333\n",
            "11111111112211121112111111111111121111111121112212221211222321123212333133113223122111132123333333331313233233332313312112323\n",
            "11121112111221121121121212222211111112221112212112122222121222212212212221211112121122221221221112222122121212221212221222122221222222222222222222211223222222222222222221222222222221222222222232222221222223222222222232232223233222222233\n",
            "After growing:\n",
            "loss: 1.262412667274475 - accuracy: 0.5507799983024597 - val_loss: 1.363599181175232 - val_accuracy: 0.5142999887466431\n",
            "layer sizes: [3072, 236, 378, 150, 283, 10]\n",
            "11111111111111111111111111111111121111111111121111112222121223231122312331213332323231332333323333333133333333123333333333331333333331133333333332333333333333333332333333333333333333333333333333333555555555555555555555555555555555555555\n",
            "111111111111111111112111111111111211211111111111111111111212111111111112222111211111112111122111211112112211112211222122212112311222132222122232221222223332312232221212212312222231132222223123232332313232231233333332232233222333223333333333232233323332333233333332323233333332333333333333333233332332333333333332333444444444444444444444444444444444444444444444444444444444444444\n",
            "111111111122111211121111111111111211111111211122122212112223211232123331331132231221111321233333333313132332333323133121123234444444444444444444444444\n",
            "1112111211122112112112121222221111111222111221211212222212122221221221222121111212112222122122111222212212121222121222122212222122222222222222222221122322222222222222222122222222222122222222223222222122222322222222223223222323322222223344444444444444444444444444444444444444444444444\n",
            "Before pruning:\n",
            "loss: 1.2218199968338013 - accuracy: 0.5629199743270874 - val_loss: 1.3430185317993164 - val_accuracy: 0.5236999988555908\n",
            "layer sizes: [3072, 236, 378, 150, 283, 10]\n",
            "11111111111111111111111111111111121111111111121111112222131213231122311331213333323331332333313333333133333333133333333333331333333431133333333333433333433433333332333333333334333343333334333343344344333334333433434344434433433433443443\n",
            "111111111111111111112111111111111111111111111111111111111211111111111112112111111111112111122111211112113211113211212122212112311322132232122232221223223332312232221212213312322231132322213124232432313332341333333342333233322333323343443344242233424333343243333333434233434433344344333344343343343432343444444432444444444444444444444444444544454444444554444544445444444444444444\n",
            "111111111122111111221111111111111211111111211122122312112223211332123341331132341231111321243333333313132333333423134111124345545554555555544445455555\n",
            "1112111111121112111112121221121111111122111121221412222211122211221421222111111212112212122122111422212212121222121222222212222122222222222222242221122422224224222222222132222222222122244222224242223124242442442242244224422434422334444444444443444344443444444434444444444434444444444\n",
            "After pruning:\n",
            "loss: 1.2218291759490967 - accuracy: 0.5627400279045105 - val_loss: 1.343051552772522 - val_accuracy: 0.5235000252723694\n",
            "layer sizes: [3072, 209, 275, 118, 211, 10]\n",
            "11111111111111111111111111111111121111111111121111112222131213231122311331213333323331332333313333333133333333133333333333331333333311333333333333333333333333323333333333333333333333333333333333333333333333333\n",
            "11111111111111111111211111111111111111111111111111111111121111111111111211211111111111211112211121111211321111321121212221211231132213223212223222122322333231223222121221331232223113232221312232323133323133333332333233322333323333322233233333233333333233333333333333333323332\n",
            "1111111111221111112211111111111112111111112111221223121122232113321233133113231231111321233333333131323333332313111123\n",
            "1112111111121112111112121221121111111122111121221122222111222112212122211111121211221212212211122212212121222121222222212222122222222222222222211222222222222222221322222222221222222222222312222222222223223333333\n",
            "Epoch 7/10\n",
            "Before growing:\n",
            "loss: 1.2218291759490967 - accuracy: 0.5627400279045105 - val_loss: 1.343051552772522 - val_accuracy: 0.5235000252723694\n",
            "layer sizes: [3072, 209, 275, 118, 211, 10]\n",
            "11111111111111111111111111111111121111111111121111112222131213231122311331213333323331332333313333333133333333133333333333331333333311333333333333333333333333323333333333333333333333333333333333333333333333333\n",
            "11111111111111111111211111111111111111111111111111111111121111111111111211211111111111211112211121111211321111321121212221211231132213223212223222122322333231223222121221331232223113232221312232323133323133333332333233322333323333322233233333233333333233333333333333333323332\n",
            "1111111111221111112211111111111112111111112111221223121122232113321233133113231231111321233333333131323333332313111123\n",
            "1112111111121112111112121221121111111122111121221122222111222112212122211111121211221212212211122212212121222121222222212222122222222222222222211222222222222222221322222222221222222222222312222222222223223333333\n",
            "After growing:\n",
            "loss: 1.2218291759490967 - accuracy: 0.5627400279045105 - val_loss: 1.343051552772522 - val_accuracy: 0.5235000252723694\n",
            "layer sizes: [3072, 250, 330, 141, 253, 10]\n",
            "1111111111111111111111111111111112111111111112111111222213121323112231133121333332333133233331333333313333333313333333333333133333331133333333333333333333333332333333333333333333333333333333333333333333333333355555555555555555555555555555555555555555\n",
            "111111111111111111112111111111111111111111111111111111111211111111111112112111111111112111122111211112113211113211212122212112311322132232122232221223223332312232221212213312322231132322213122323231333231333333323332333223333233333222332333332333333332333333333333333333233324444444444444444444444444444444444444444444444444444444\n",
            "111111111122111111221111111111111211111111211122122312112223211332123313311323123111132123333333313132333333231311112344444444444444444444444\n",
            "1112111111121112111112121221121111111122111121221122222111222112212122211111121211221212212211122212212121222121222222212222122222222222222222211222222222222222221322222222221222222222222312222222222223223333333444444444444444444444444444444444444444444\n",
            "Before pruning:\n",
            "loss: 1.2028262615203857 - accuracy: 0.57396000623703 - val_loss: 1.3463820219039917 - val_accuracy: 0.5214999914169312\n",
            "layer sizes: [3072, 250, 330, 141, 253, 10]\n",
            "1111111111111111111111111111111111111111111113111111222213121323113331133111333333333133333331333343313334333313333333333333133333331133333333333333334333333332333333433333333343343434333444343433444433444343444443344443434444344343443333344444344344\n",
            "111111111111111111111111111111111111111111111111111111111211111111111112111111121111112111123111211112113211113211212122212113311322132232122231221333223342422232221313313312322231143322223122333231434331333433323432334234333343333322342443442333333332334434434434333333234435444445444454444544444544444444445444444454454445445454\n",
            "111111111122111111211111111111111211111111211132122312111323311432124313311423134111132124343443413142434343231311113345444455444554454544454\n",
            "1112111111121112111112111221121111111122111141121122222111122112212121211111121211221212212211141212212121214111422222214224122222222223242422211224222222421242222442232224231244222322242312243422244444324434443444443444433443444434444433443444344334334\n",
            "After pruning:\n",
            "loss: 1.2026666402816772 - accuracy: 0.5739799737930298 - val_loss: 1.3462284803390503 - val_accuracy: 0.5213000178337097\n",
            "layer sizes: [3072, 201, 251, 105, 195, 10]\n",
            "111111111111111111111111111111111111111111111311111122221312132311333113311133333333313333333133333313333333133333333333331333333311333333333333333333333333233333333333333333333333333333333333333333333\n",
            "11111111111111111111111111111111111111111111111111111111121111111111111211111112111111211112311121111211321111321121212221211331132213223212223122133322332222322213133133123222311332222312233323133313333332332332333333333322323233333333233333333333233\n",
            "111111111122111111211111111111111211111111211132122312111323311321231331123131111321233313123332313111133\n",
            "111211111112111211111211122112111111112211111121122222111122112212121211111121211221212212211112122121212111122222212212222222222322222112222222221222222232222312222322223122322232333333333333333\n",
            "Epoch 8/10\n",
            "Before growing:\n",
            "loss: 1.2026666402816772 - accuracy: 0.5739799737930298 - val_loss: 1.3462284803390503 - val_accuracy: 0.5213000178337097\n",
            "layer sizes: [3072, 201, 251, 105, 195, 10]\n",
            "111111111111111111111111111111111111111111111311111122221312132311333113311133333333313333333133333313333333133333333333331333333311333333333333333333333333233333333333333333333333333333333333333333333\n",
            "11111111111111111111111111111111111111111111111111111111121111111111111211111112111111211112311121111211321111321121212221211331132213223212223122133322332222322213133133123222311332222312233323133313333332332332333333333322323233333333233333333333233\n",
            "111111111122111111211111111111111211111111211132122312111323311321231331123131111321233313123332313111133\n",
            "111211111112111211111211122112111111112211111121122222111122112212121211111121211221212212211112122121212111122222212212222222222322222112222222221222222232222312222322223122322232333333333333333\n",
            "After growing:\n",
            "loss: 1.2026665210723877 - accuracy: 0.5739799737930298 - val_loss: 1.3462284803390503 - val_accuracy: 0.5213000178337097\n",
            "layer sizes: [3072, 241, 301, 126, 234, 10]\n",
            "1111111111111111111111111111111111111111111113111111222213121323113331133111333333333133333331333333133333331333333333333313333333113333333333333333333333332333333333333333333333333333333333333333333335555555555555555555555555555555555555555\n",
            "1111111111111111111111111111111111111111111111111111111112111111111111121111111211111121111231112111121132111132112121222121133113221322321222312213332233222232221313313312322231133222231223332313331333333233233233333333332232323333333323333333333323344444444444444444444444444444444444444444444444444\n",
            "111111111122111111211111111111111211111111211132122312111323311321231331123131111321233313123332313111133444444444444444444444\n",
            "111211111112111211111211122112111111112211111121122222111122112212121211111121211221212212211112122121212111122222212212222222222322222112222222221222222232222312222322223122322232333333333333333444444444444444444444444444444444444444\n",
            "Before pruning:\n",
            "loss: 1.1618068218231201 - accuracy: 0.5839599967002869 - val_loss: 1.3246874809265137 - val_accuracy: 0.5256999731063843\n",
            "layer sizes: [3072, 241, 301, 126, 234, 10]\n",
            "1111111111111111111111111111111111111111111113111111122213131333123331133111333333333133333331333433133333331333333333333313443333113333333334333433433333332343333334343433333333344443433444334443444444334443344444444443334433444444434344344\n",
            "1111111111111111111111111111111111111111111111111111111111111111111111121111111211111121111221113111121132111132112121232121134113221322321212312213332233212242221313313322322231233222141223332413331333344233243234433443433333334444444323434343443324344444444454544444444544444444444454445444455444455\n",
            "111111111122111111211111111111111311111111211132132412111313411321331331123131111421244414123343413111133454444444444444545544\n",
            "111211111112111111111111122111111111112111111121121222111122111212121211111131211211212211211112122141212111122222212212242222224422222112222222221222322444422412222422424122422232444444444444444444444444444444444344344444344444344344\n",
            "After pruning:\n",
            "loss: 1.1616326570510864 - accuracy: 0.5839800238609314 - val_loss: 1.3244218826293945 - val_accuracy: 0.5260999798774719\n",
            "layer sizes: [3072, 187, 226, 96, 172, 10]\n",
            "1111111111111111111111111111111111111111111113111111122213131333123331133111333333333133333331333331333333313333333333333133333113333333333333333333332333333333333333333333333333333333333\n",
            "1111111111111111111111111111111111111111111111111111111111111111111111121111111211111121111221113111121132111132112121232121131132213223212123122133322332122222131331332232223123322211223332133313333233232333333333333233333323\n",
            "111111111122111111211111111111111311111111211132132121113131132133133112313111121211233313111133\n",
            "1112111111121111111111111221111111111121111111211212221111221112121212111111312112112122112111121221121211112222221221222222222222211222222222122232222122222221222223233333\n",
            "Epoch 9/10\n",
            "Before growing:\n",
            "loss: 1.1616326570510864 - accuracy: 0.5839800238609314 - val_loss: 1.3244218826293945 - val_accuracy: 0.5260999798774719\n",
            "layer sizes: [3072, 187, 226, 96, 172, 10]\n",
            "1111111111111111111111111111111111111111111113111111122213131333123331133111333333333133333331333331333333313333333333333133333113333333333333333333332333333333333333333333333333333333333\n",
            "1111111111111111111111111111111111111111111111111111111111111111111111121111111211111121111221113111121132111132112121232121131132213223212123122133322332122222131331332232223123322211223332133313333233232333333333333233333323\n",
            "111111111122111111211111111111111311111111211132132121113131132133133112313111121211233313111133\n",
            "1112111111121111111111111221111111111121111111211212221111221112121212111111312112112122112111121221121211112222221221222222222222211222222222122232222122222221222223233333\n",
            "After growing:\n",
            "loss: 1.1616326570510864 - accuracy: 0.5839800238609314 - val_loss: 1.3244218826293945 - val_accuracy: 0.5260999798774719\n",
            "layer sizes: [3072, 224, 271, 116, 206, 10]\n",
            "11111111111111111111111111111111111111111111131111111222131313331233311331113333333331333333313333313333333133333333333331333331133333333333333333333323333333333333333333333333333333333335555555555555555555555555555555555555\n",
            "1111111111111111111111111111111111111111111111111111111111111111111111121111111211111121111221113111121132111132112121232121131132213223212123122133322332122222131331332232223123322211223332133313333233232333333333333233333323444444444444444444444444444444444444444444444\n",
            "11111111112211111121111111111111131111111121113213212111313113213313311231311112121123331311113344444444444444444444\n",
            "11121111111211111111111112211111111111211111112112122211112211121212121111113121121121221121111212211212111122222212212222222222222112222222221222322221222222212222232333334444444444444444444444444444444444\n",
            "Before pruning:\n",
            "loss: 1.1420552730560303 - accuracy: 0.5938599705696106 - val_loss: 1.3206034898757935 - val_accuracy: 0.5289000272750854\n",
            "layer sizes: [3072, 224, 271, 116, 206, 10]\n",
            "11111111111111111111111111111111121111111111131111111131131313331233311331113333333331333333313333313333333133333333333331334332133333333333333333344323343333334433333333333334343344443343443343444443333344444434444343344444\n",
            "1111111111111111111111111111111111111111111111111111111111111111111111121111111211111121111231113111121132111132112121232121131132214224212124122133322342122222131331332232123123433211223332143413433234242333333333333333333333444454554455444545444554544454555444444545544\n",
            "11111111112211111121111111111111131111111121114313213111413114214314411331311112132114331411113455554445545555455545\n",
            "11121111111211111111111112211111111111211111112112112211111211121212121111114121121121221121111212211212111122122222212224222422334112242222241222423241222242214242242344444444444444444444433443443434344443\n",
            "After pruning:\n",
            "loss: 1.1420304775238037 - accuracy: 0.5938400030136108 - val_loss: 1.320600152015686 - val_accuracy: 0.5285999774932861\n",
            "layer sizes: [3072, 187, 216, 87, 163, 10]\n",
            "1111111111111111111111111111111112111111111113111111113113131333123331133111333333333133333331333331333333313333333333333133332133333333333333333332333333333333333333333333333333333333333\n",
            "111111111111111111111111111111111111111111111111111111111111111111111112111111121111112111123111311112113211113211212123212113113221222121212213332232122222131331332232123123332112233321313332322333333333333333333333\n",
            "111111111122111111211111111111111311111111211131321311113112131113313111121321133111113\n",
            "1112111111121111111111111221111111111121111111211211221111121112121212111111121121121221121111212211212111122122222212222222233112222222122223212222221222233333333\n",
            "Epoch 10/10\n",
            "Before growing:\n",
            "loss: 1.1420304775238037 - accuracy: 0.5938400030136108 - val_loss: 1.320600152015686 - val_accuracy: 0.5285999774932861\n",
            "layer sizes: [3072, 187, 216, 87, 163, 10]\n",
            "1111111111111111111111111111111112111111111113111111113113131333123331133111333333333133333331333331333333313333333333333133332133333333333333333332333333333333333333333333333333333333333\n",
            "111111111111111111111111111111111111111111111111111111111111111111111112111111121111112111123111311112113211113211212123212113113221222121212213332232122222131331332232123123332112233321313332322333333333333333333333\n",
            "111111111122111111211111111111111311111111211131321311113112131113313111121321133111113\n",
            "1112111111121111111111111221111111111121111111211211221111121112121212111111121121121221121111212211212111122122222212222222233112222222122223212222221222233333333\n",
            "After growing:\n",
            "loss: 1.1420304775238037 - accuracy: 0.5938400030136108 - val_loss: 1.320600152015686 - val_accuracy: 0.5285999774932861\n",
            "layer sizes: [3072, 224, 259, 107, 195, 10]\n",
            "11111111111111111111111111111111121111111111131111111131131313331233311331113333333331333333313333313333333133333333333331333321333333333333333333323333333333333333333333333333333333333335555555555555555555555555555555555555\n",
            "1111111111111111111111111111111111111111111111111111111111111111111111121111111211111121111231113111121132111132112121232121131132212221212122133322321222221313313322321231233321122333213133323223333333333333333333334444444444444444444444444444444444444444444\n",
            "11111111112211111121111111111111131111111121113132131111311213111331311112132113311111344444444444444444444\n",
            "111211111112111111111111122111111111112111111121121122111112111212121211111112112112122112111121221121211112212222221222222223311222222212222321222222122223333333344444444444444444444444444444444\n",
            "Before pruning:\n",
            "loss: 1.1198385953903198 - accuracy: 0.6008999943733215 - val_loss: 1.3173203468322754 - val_accuracy: 0.5303000211715698\n",
            "layer sizes: [3072, 224, 259, 107, 195, 10]\n",
            "11111111111111111111111111111111111111111111131111111131131313331333312331113333333331333333313333313333333133333333333331333332333343333333333333313333333333333334344434333433444433343433334344444433434444444444444444433434\n",
            "1111111111111111111111111111111111111111111111111111111111111111111111111111111211111121111231113111121132111132112121332221131132212221212112133322331222221313313332321231233321122333213133423223333333433333333343333343444443444445444444444443445444444443444\n",
            "11111111112211111121111111111111131111111121113142131111411214211331311113132124311111344444554444444444444\n",
            "111211111112111111111111122111111111112111111121121122111114111211121211111112122112122112111121221141211112312221221222222224311332222212222321232232122243333344443444444433444334344444444443444\n",
            "After pruning:\n",
            "loss: 1.1199510097503662 - accuracy: 0.6007999777793884 - val_loss: 1.3174477815628052 - val_accuracy: 0.5303999781608582\n",
            "layer sizes: [3072, 184, 219, 83, 163, 10]\n",
            "1111111111111111111111111111111111111111111113111111113113131333133331233111333333333133333331333331333333313333333333333133333233333333333333333313333333333333333333333333333333333333\n",
            "111111111111111111111111111111111111111111111111111111111111111111111111111111121111112111123111311112113211113211212133222113113221222121211213332233122222131331333232123123332112233321313323223333333333333333333333333\n",
            "11111111112211111121111111111111131111111121113121311111121211331311113132123111113\n",
            "1112111111121111111111111221111111111121111111211211221111111121112121111111212211212211211112122111211112312221221222222223113322222122223212322321222333333333333\n",
            "CPU times: user 5min 44s, sys: 15.3 s, total: 6min\n",
            "Wall time: 5min 56s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltB1QmpIMG7D"
      },
      "source": [
        "epochs = 50\n",
        "self_scaling_epochs = 50\n",
        "batch_size = 32\n",
        "min_new_neurons = 50"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7EQtWo_G8t2",
        "outputId": "1cca9586-6add-488e-d982-3e57ed0e1e38"
      },
      "source": [
        "%%time\n",
        "\n",
        "model = SSModel(layer_sizes=[3072, 300, 300, 300, 300, 10], activation='selu', regularization_penalty=0.0001, regularization_method='weighted_l1', kernel_initializer='lecun_normal')\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "train_model(model, X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, min_new_neurons, validation_data=(X_test_norm, y_test), regularization_penalty_multiplier=0.1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##########################################################\n",
            "Epoch 1/50\n",
            "Before growing:\n",
            "loss: 2.9734561443328857 - accuracy: 0.0878399983048439 - val_loss: 2.957174301147461 - val_accuracy: 0.0892999991774559 - penalty: 0.0001\n",
            "layer sizes: [3072, 300, 300, 300, 300, 10]\n",
            "After growing:\n",
            "loss: 2.973456621170044 - accuracy: 0.0878399983048439 - val_loss: 2.957174301147461 - val_accuracy: 0.0892999991774559 - penalty: 0.0001\n",
            "layer sizes: [3072, 360, 360, 360, 360, 10]\n",
            "Before pruning:\n",
            "loss: 1.8268446922302246 - accuracy: 0.3210600018501282 - val_loss: 1.8327789306640625 - val_accuracy: 0.3165000081062317 - penalty: 0.0001\n",
            "layer sizes: [3072, 360, 360, 360, 360, 10]\n",
            "After pruning:\n",
            "loss: 1.8263518810272217 - accuracy: 0.32137998938560486 - val_loss: 1.8324464559555054 - val_accuracy: 0.31679999828338623 - penalty: 0.0001\n",
            "layer sizes: [3072, 15, 58, 34, 70, 10]\n",
            "##########################################################\n",
            "Epoch 2/50\n",
            "Before growing:\n",
            "loss: 1.8263518810272217 - accuracy: 0.32137998938560486 - val_loss: 1.8324464559555054 - val_accuracy: 0.31679999828338623 - penalty: 0.0001\n",
            "layer sizes: [3072, 15, 58, 34, 70, 10]\n",
            "After growing:\n",
            "loss: 1.8263518810272217 - accuracy: 0.32137998938560486 - val_loss: 1.8324464559555054 - val_accuracy: 0.31679999828338623 - penalty: 0.0001\n",
            "layer sizes: [3072, 65, 108, 84, 120, 10]\n",
            "Before pruning:\n",
            "loss: 1.7552181482315063 - accuracy: 0.35148000717163086 - val_loss: 1.7627851963043213 - val_accuracy: 0.35010001063346863 - penalty: 0.0001\n",
            "layer sizes: [3072, 65, 108, 84, 120, 10]\n",
            "After pruning:\n",
            "loss: 1.755191683769226 - accuracy: 0.35172000527381897 - val_loss: 1.7627809047698975 - val_accuracy: 0.35019999742507935 - penalty: 0.0001\n",
            "layer sizes: [3072, 13, 41, 21, 55, 10]\n",
            "##########################################################\n",
            "Epoch 3/50\n",
            "Before growing:\n",
            "loss: 1.755191683769226 - accuracy: 0.35172000527381897 - val_loss: 1.7627809047698975 - val_accuracy: 0.35019999742507935 - penalty: 0.0001\n",
            "layer sizes: [3072, 13, 41, 21, 55, 10]\n",
            "After growing:\n",
            "loss: 1.7551919221878052 - accuracy: 0.35172000527381897 - val_loss: 1.7627809047698975 - val_accuracy: 0.35019999742507935 - penalty: 0.0001\n",
            "layer sizes: [3072, 63, 91, 71, 105, 10]\n",
            "Before pruning:\n",
            "loss: 1.7386107444763184 - accuracy: 0.3573000133037567 - val_loss: 1.7480753660202026 - val_accuracy: 0.3508000075817108 - penalty: 0.0001\n",
            "layer sizes: [3072, 63, 91, 71, 105, 10]\n",
            "After pruning:\n",
            "loss: 1.7385753393173218 - accuracy: 0.3576599955558777 - val_loss: 1.748012900352478 - val_accuracy: 0.35040000081062317 - penalty: 0.0001\n",
            "layer sizes: [3072, 8, 30, 17, 50, 10]\n",
            "##########################################################\n",
            "Epoch 4/50\n",
            "Before growing:\n",
            "loss: 1.7385753393173218 - accuracy: 0.3576599955558777 - val_loss: 1.748012900352478 - val_accuracy: 0.35040000081062317 - penalty: 0.0001\n",
            "layer sizes: [3072, 8, 30, 17, 50, 10]\n",
            "After growing:\n",
            "loss: 1.7385753393173218 - accuracy: 0.3576599955558777 - val_loss: 1.748012900352478 - val_accuracy: 0.35040000081062317 - penalty: 0.0001\n",
            "layer sizes: [3072, 58, 80, 67, 100, 10]\n",
            "Before pruning:\n",
            "loss: 1.7160193920135498 - accuracy: 0.3632200062274933 - val_loss: 1.7290109395980835 - val_accuracy: 0.35740000009536743 - penalty: 0.0001\n",
            "layer sizes: [3072, 58, 80, 67, 100, 10]\n",
            "After pruning:\n",
            "loss: 1.7160184383392334 - accuracy: 0.363180011510849 - val_loss: 1.729008436203003 - val_accuracy: 0.3573000133037567 - penalty: 0.0001\n",
            "layer sizes: [3072, 8, 24, 15, 48, 10]\n",
            "##########################################################\n",
            "Epoch 5/50\n",
            "Before growing:\n",
            "loss: 1.7160184383392334 - accuracy: 0.363180011510849 - val_loss: 1.729008436203003 - val_accuracy: 0.3573000133037567 - penalty: 0.0001\n",
            "layer sizes: [3072, 8, 24, 15, 48, 10]\n",
            "After growing:\n",
            "loss: 1.7160184383392334 - accuracy: 0.363180011510849 - val_loss: 1.7290081977844238 - val_accuracy: 0.3573000133037567 - penalty: 0.0001\n",
            "layer sizes: [3072, 58, 74, 65, 98, 10]\n",
            "Before pruning:\n",
            "loss: 1.7015681266784668 - accuracy: 0.37516000866889954 - val_loss: 1.7137393951416016 - val_accuracy: 0.3700999915599823 - penalty: 0.0001\n",
            "layer sizes: [3072, 58, 74, 65, 98, 10]\n",
            "After pruning:\n",
            "loss: 1.7015726566314697 - accuracy: 0.37512001395225525 - val_loss: 1.713741660118103 - val_accuracy: 0.3702999949455261 - penalty: 0.0001\n",
            "layer sizes: [3072, 7, 23, 13, 46, 10]\n",
            "##########################################################\n",
            "Epoch 6/50\n",
            "Before growing:\n",
            "loss: 1.7015726566314697 - accuracy: 0.37512001395225525 - val_loss: 1.713741660118103 - val_accuracy: 0.3702999949455261 - penalty: 0.0001\n",
            "layer sizes: [3072, 7, 23, 13, 46, 10]\n",
            "After growing:\n",
            "loss: 1.7015725374221802 - accuracy: 0.37512001395225525 - val_loss: 1.713741660118103 - val_accuracy: 0.3702999949455261 - penalty: 0.0001\n",
            "layer sizes: [3072, 57, 73, 63, 96, 10]\n",
            "Before pruning:\n",
            "loss: 1.6802533864974976 - accuracy: 0.38266000151634216 - val_loss: 1.6963818073272705 - val_accuracy: 0.37070000171661377 - penalty: 0.0001\n",
            "layer sizes: [3072, 57, 73, 63, 96, 10]\n",
            "After pruning:\n",
            "loss: 1.6802743673324585 - accuracy: 0.38273999094963074 - val_loss: 1.696408987045288 - val_accuracy: 0.37059998512268066 - penalty: 0.0001\n",
            "layer sizes: [3072, 7, 22, 13, 42, 10]\n",
            "##########################################################\n",
            "Epoch 7/50\n",
            "Before growing:\n",
            "loss: 1.6802743673324585 - accuracy: 0.38273999094963074 - val_loss: 1.696408987045288 - val_accuracy: 0.37059998512268066 - penalty: 0.0001\n",
            "layer sizes: [3072, 7, 22, 13, 42, 10]\n",
            "After growing:\n",
            "loss: 1.6802743673324585 - accuracy: 0.38273999094963074 - val_loss: 1.696408987045288 - val_accuracy: 0.37059998512268066 - penalty: 0.0001\n",
            "layer sizes: [3072, 57, 72, 63, 92, 10]\n",
            "Before pruning:\n",
            "loss: 1.6721540689468384 - accuracy: 0.38464000821113586 - val_loss: 1.6891363859176636 - val_accuracy: 0.37450000643730164 - penalty: 0.0001\n",
            "layer sizes: [3072, 57, 72, 63, 92, 10]\n",
            "After pruning:\n",
            "loss: 1.672197937965393 - accuracy: 0.3847399950027466 - val_loss: 1.68916916847229 - val_accuracy: 0.3749000132083893 - penalty: 0.0001\n",
            "layer sizes: [3072, 7, 20, 13, 41, 10]\n",
            "##########################################################\n",
            "Epoch 8/50\n",
            "Before growing:\n",
            "loss: 1.672197937965393 - accuracy: 0.3847399950027466 - val_loss: 1.68916916847229 - val_accuracy: 0.3749000132083893 - penalty: 0.0001\n",
            "layer sizes: [3072, 7, 20, 13, 41, 10]\n",
            "After growing:\n",
            "loss: 1.672197937965393 - accuracy: 0.3847399950027466 - val_loss: 1.689168930053711 - val_accuracy: 0.3749000132083893 - penalty: 0.0001\n",
            "layer sizes: [3072, 57, 70, 63, 91, 10]\n",
            "Before pruning:\n",
            "loss: 1.6482595205307007 - accuracy: 0.39664000272750854 - val_loss: 1.6642394065856934 - val_accuracy: 0.38199999928474426 - penalty: 0.0001\n",
            "layer sizes: [3072, 57, 70, 63, 91, 10]\n",
            "After pruning:\n",
            "loss: 1.6482621431350708 - accuracy: 0.39656001329421997 - val_loss: 1.664260983467102 - val_accuracy: 0.3822000026702881 - penalty: 0.0001\n",
            "layer sizes: [3072, 7, 20, 13, 38, 10]\n",
            "##########################################################\n",
            "Epoch 9/50\n",
            "Before growing:\n",
            "loss: 1.6482621431350708 - accuracy: 0.39656001329421997 - val_loss: 1.664260983467102 - val_accuracy: 0.3822000026702881 - penalty: 0.0001\n",
            "layer sizes: [3072, 7, 20, 13, 38, 10]\n",
            "After growing:\n",
            "loss: 1.6482621431350708 - accuracy: 0.39656001329421997 - val_loss: 1.664260983467102 - val_accuracy: 0.3822000026702881 - penalty: 0.0001\n",
            "layer sizes: [3072, 57, 70, 63, 88, 10]\n",
            "Before pruning:\n",
            "loss: 1.639958381652832 - accuracy: 0.39858001470565796 - val_loss: 1.6595935821533203 - val_accuracy: 0.3889000117778778 - penalty: 0.0001\n",
            "layer sizes: [3072, 57, 70, 63, 88, 10]\n",
            "After pruning:\n",
            "loss: 1.6399693489074707 - accuracy: 0.3985599875450134 - val_loss: 1.6596380472183228 - val_accuracy: 0.38920000195503235 - penalty: 0.0001\n",
            "layer sizes: [3072, 8, 20, 13, 39, 10]\n",
            "##########################################################\n",
            "Epoch 10/50\n",
            "Before growing:\n",
            "loss: 1.6399693489074707 - accuracy: 0.3985599875450134 - val_loss: 1.6596380472183228 - val_accuracy: 0.38920000195503235 - penalty: 0.0001\n",
            "layer sizes: [3072, 8, 20, 13, 39, 10]\n",
            "After growing:\n",
            "loss: 1.6399693489074707 - accuracy: 0.3985599875450134 - val_loss: 1.6596380472183228 - val_accuracy: 0.38920000195503235 - penalty: 0.0001\n",
            "layer sizes: [3072, 58, 70, 63, 89, 10]\n",
            "Before pruning:\n",
            "loss: 1.6317631006240845 - accuracy: 0.401419997215271 - val_loss: 1.6544878482818604 - val_accuracy: 0.390500009059906 - penalty: 0.0001\n",
            "layer sizes: [3072, 58, 70, 63, 89, 10]\n",
            "After pruning:\n",
            "loss: 1.6317174434661865 - accuracy: 0.401419997215271 - val_loss: 1.6544421911239624 - val_accuracy: 0.3905999958515167 - penalty: 0.0001\n",
            "layer sizes: [3072, 11, 20, 13, 36, 10]\n",
            "##########################################################\n",
            "Epoch 11/50\n",
            "Before growing:\n",
            "loss: 1.6317174434661865 - accuracy: 0.401419997215271 - val_loss: 1.6544421911239624 - val_accuracy: 0.3905999958515167 - penalty: 0.0001\n",
            "layer sizes: [3072, 11, 20, 13, 36, 10]\n",
            "After growing:\n",
            "loss: 1.6317174434661865 - accuracy: 0.401419997215271 - val_loss: 1.6544419527053833 - val_accuracy: 0.3905999958515167 - penalty: 0.0001\n",
            "layer sizes: [3072, 61, 70, 63, 86, 10]\n",
            "Before pruning:\n",
            "loss: 1.6235706806182861 - accuracy: 0.4086199998855591 - val_loss: 1.6457568407058716 - val_accuracy: 0.3978999853134155 - penalty: 0.0001\n",
            "layer sizes: [3072, 61, 70, 63, 86, 10]\n",
            "After pruning:\n",
            "loss: 1.6235668659210205 - accuracy: 0.4085800051689148 - val_loss: 1.6457544565200806 - val_accuracy: 0.3977999985218048 - penalty: 0.0001\n",
            "layer sizes: [3072, 7, 20, 13, 35, 10]\n",
            "##########################################################\n",
            "Epoch 12/50\n",
            "Before growing:\n",
            "loss: 1.6235668659210205 - accuracy: 0.4085800051689148 - val_loss: 1.6457544565200806 - val_accuracy: 0.3977999985218048 - penalty: 0.0001\n",
            "layer sizes: [3072, 7, 20, 13, 35, 10]\n",
            "After growing:\n",
            "loss: 1.6235668659210205 - accuracy: 0.4085800051689148 - val_loss: 1.6457544565200806 - val_accuracy: 0.3977999985218048 - penalty: 0.0001\n",
            "layer sizes: [3072, 57, 70, 63, 85, 10]\n",
            "Before pruning:\n",
            "loss: 1.617138385772705 - accuracy: 0.4111599922180176 - val_loss: 1.6445504426956177 - val_accuracy: 0.3953000009059906 - penalty: 0.0001\n",
            "layer sizes: [3072, 57, 70, 63, 85, 10]\n",
            "After pruning:\n",
            "loss: 1.6172422170639038 - accuracy: 0.4110400080680847 - val_loss: 1.6446533203125 - val_accuracy: 0.3952000141143799 - penalty: 0.0001\n",
            "layer sizes: [3072, 8, 19, 13, 35, 10]\n",
            "##########################################################\n",
            "Epoch 13/50\n",
            "Before growing:\n",
            "loss: 1.6172422170639038 - accuracy: 0.4110400080680847 - val_loss: 1.6446533203125 - val_accuracy: 0.3952000141143799 - penalty: 0.0001\n",
            "layer sizes: [3072, 8, 19, 13, 35, 10]\n",
            "After growing:\n",
            "loss: 1.6172422170639038 - accuracy: 0.4110400080680847 - val_loss: 1.6446533203125 - val_accuracy: 0.3952000141143799 - penalty: 0.0001\n",
            "layer sizes: [3072, 58, 69, 63, 85, 10]\n",
            "Before pruning:\n",
            "loss: 1.6178843975067139 - accuracy: 0.4103600084781647 - val_loss: 1.6414804458618164 - val_accuracy: 0.3993000090122223 - penalty: 0.0001\n",
            "layer sizes: [3072, 58, 69, 63, 85, 10]\n",
            "After pruning:\n",
            "loss: 1.61781644821167 - accuracy: 0.41054001450538635 - val_loss: 1.6413837671279907 - val_accuracy: 0.399399995803833 - penalty: 0.0001\n",
            "layer sizes: [3072, 7, 19, 13, 34, 10]\n",
            "##########################################################\n",
            "Epoch 14/50\n",
            "Before growing:\n",
            "loss: 1.61781644821167 - accuracy: 0.41054001450538635 - val_loss: 1.6413837671279907 - val_accuracy: 0.399399995803833 - penalty: 0.0001\n",
            "layer sizes: [3072, 7, 19, 13, 34, 10]\n",
            "After growing:\n",
            "loss: 1.6178165674209595 - accuracy: 0.41054001450538635 - val_loss: 1.6413837671279907 - val_accuracy: 0.399399995803833 - penalty: 0.0001\n",
            "layer sizes: [3072, 57, 69, 63, 84, 10]\n",
            "Before pruning:\n",
            "loss: 1.6128950119018555 - accuracy: 0.41207998991012573 - val_loss: 1.6364887952804565 - val_accuracy: 0.4016000032424927 - penalty: 0.0001\n",
            "layer sizes: [3072, 57, 69, 63, 84, 10]\n",
            "After pruning:\n",
            "loss: 1.6130259037017822 - accuracy: 0.4120599925518036 - val_loss: 1.6366331577301025 - val_accuracy: 0.4018999934196472 - penalty: 0.0001\n",
            "layer sizes: [3072, 7, 19, 13, 34, 10]\n",
            "##########################################################\n",
            "Epoch 15/50\n",
            "Before growing:\n",
            "loss: 1.6130259037017822 - accuracy: 0.4120599925518036 - val_loss: 1.6366331577301025 - val_accuracy: 0.4018999934196472 - penalty: 0.0001\n",
            "layer sizes: [3072, 7, 19, 13, 34, 10]\n",
            "After growing:\n",
            "loss: 1.6130259037017822 - accuracy: 0.4120599925518036 - val_loss: 1.6366331577301025 - val_accuracy: 0.4018999934196472 - penalty: 0.0001\n",
            "layer sizes: [3072, 57, 69, 63, 84, 10]\n",
            "Before pruning:\n",
            "loss: 1.606682300567627 - accuracy: 0.4142799973487854 - val_loss: 1.6321817636489868 - val_accuracy: 0.40380001068115234 - penalty: 0.0001\n",
            "layer sizes: [3072, 57, 69, 63, 84, 10]\n",
            "After pruning:\n",
            "loss: 1.6066315174102783 - accuracy: 0.414139986038208 - val_loss: 1.6321121454238892 - val_accuracy: 0.40400001406669617 - penalty: 0.0001\n",
            "layer sizes: [3072, 7, 18, 13, 33, 10]\n",
            "##########################################################\n",
            "Epoch 16/50\n",
            "Before growing:\n",
            "loss: 1.6066315174102783 - accuracy: 0.414139986038208 - val_loss: 1.6321121454238892 - val_accuracy: 0.40400001406669617 - penalty: 0.0001\n",
            "layer sizes: [3072, 7, 18, 13, 33, 10]\n",
            "After growing:\n",
            "loss: 1.6066315174102783 - accuracy: 0.414139986038208 - val_loss: 1.6321120262145996 - val_accuracy: 0.40400001406669617 - penalty: 0.0001\n",
            "layer sizes: [3072, 57, 68, 63, 83, 10]\n",
            "Before pruning:\n",
            "loss: 1.6030917167663574 - accuracy: 0.4169999957084656 - val_loss: 1.6305187940597534 - val_accuracy: 0.4050999879837036 - penalty: 0.0001\n",
            "layer sizes: [3072, 57, 68, 63, 83, 10]\n",
            "After pruning:\n",
            "loss: 1.6032369136810303 - accuracy: 0.41686001420021057 - val_loss: 1.6306980848312378 - val_accuracy: 0.4052000045776367 - penalty: 0.0001\n",
            "layer sizes: [3072, 7, 18, 13, 32, 10]\n",
            "##########################################################\n",
            "Epoch 17/50\n",
            "Before growing:\n",
            "loss: 1.6032369136810303 - accuracy: 0.41686001420021057 - val_loss: 1.6306980848312378 - val_accuracy: 0.4052000045776367 - penalty: 0.0001\n",
            "layer sizes: [3072, 7, 18, 13, 32, 10]\n",
            "After growing:\n",
            "loss: 1.6032369136810303 - accuracy: 0.41686001420021057 - val_loss: 1.6306980848312378 - val_accuracy: 0.4052000045776367 - penalty: 0.0001\n",
            "layer sizes: [3072, 57, 68, 63, 82, 10]\n",
            "Before pruning:\n",
            "loss: 1.6198312044143677 - accuracy: 0.4130600094795227 - val_loss: 1.6449429988861084 - val_accuracy: 0.40220001339912415 - penalty: 0.0001\n",
            "layer sizes: [3072, 57, 68, 63, 82, 10]\n",
            "After pruning:\n",
            "loss: 1.6204453706741333 - accuracy: 0.4130600094795227 - val_loss: 1.6455540657043457 - val_accuracy: 0.4016999900341034 - penalty: 0.0001\n",
            "layer sizes: [3072, 7, 18, 13, 32, 10]\n",
            "##########################################################\n",
            "Epoch 18/50\n",
            "Before growing:\n",
            "loss: 1.6204453706741333 - accuracy: 0.4130600094795227 - val_loss: 1.6455540657043457 - val_accuracy: 0.4016999900341034 - penalty: 0.0001\n",
            "layer sizes: [3072, 7, 18, 13, 32, 10]\n",
            "After growing:\n",
            "loss: 1.6204453706741333 - accuracy: 0.4130600094795227 - val_loss: 1.6455539464950562 - val_accuracy: 0.4016999900341034 - penalty: 1e-05\n",
            "layer sizes: [3072, 57, 68, 63, 82, 10]\n",
            "Before pruning:\n",
            "loss: 1.5841829776763916 - accuracy: 0.42107999324798584 - val_loss: 1.617518424987793 - val_accuracy: 0.412200003862381 - penalty: 1e-05\n",
            "layer sizes: [3072, 57, 68, 63, 82, 10]\n",
            "After pruning:\n",
            "loss: 1.5840712785720825 - accuracy: 0.4213399887084961 - val_loss: 1.6174110174179077 - val_accuracy: 0.41269999742507935 - penalty: 1e-05\n",
            "layer sizes: [3072, 39, 24, 13, 57, 10]\n",
            "##########################################################\n",
            "Epoch 19/50\n",
            "Before growing:\n",
            "loss: 1.5840712785720825 - accuracy: 0.4213399887084961 - val_loss: 1.6174110174179077 - val_accuracy: 0.41269999742507935 - penalty: 1e-05\n",
            "layer sizes: [3072, 39, 24, 13, 57, 10]\n",
            "After growing:\n",
            "loss: 1.5840712785720825 - accuracy: 0.4213399887084961 - val_loss: 1.6174110174179077 - val_accuracy: 0.41269999742507935 - penalty: 1e-05\n",
            "layer sizes: [3072, 89, 74, 63, 107, 10]\n",
            "Before pruning:\n",
            "loss: 1.5526175498962402 - accuracy: 0.4342400133609772 - val_loss: 1.5910006761550903 - val_accuracy: 0.4196000099182129 - penalty: 1e-05\n",
            "layer sizes: [3072, 89, 74, 63, 107, 10]\n",
            "After pruning:\n",
            "loss: 1.5528299808502197 - accuracy: 0.43397998809814453 - val_loss: 1.5910532474517822 - val_accuracy: 0.4198000133037567 - penalty: 1e-05\n",
            "layer sizes: [3072, 37, 26, 13, 43, 10]\n",
            "##########################################################\n",
            "Epoch 20/50\n",
            "Before growing:\n",
            "loss: 1.5528299808502197 - accuracy: 0.43397998809814453 - val_loss: 1.5910532474517822 - val_accuracy: 0.4198000133037567 - penalty: 1e-05\n",
            "layer sizes: [3072, 37, 26, 13, 43, 10]\n",
            "After growing:\n",
            "loss: 1.5528301000595093 - accuracy: 0.43397998809814453 - val_loss: 1.5910532474517822 - val_accuracy: 0.4198000133037567 - penalty: 1e-05\n",
            "layer sizes: [3072, 87, 76, 63, 93, 10]\n",
            "Before pruning:\n",
            "loss: 1.5383315086364746 - accuracy: 0.44071999192237854 - val_loss: 1.5824599266052246 - val_accuracy: 0.4275999963283539 - penalty: 1e-05\n",
            "layer sizes: [3072, 87, 76, 63, 93, 10]\n",
            "After pruning:\n",
            "loss: 1.538189172744751 - accuracy: 0.4408800005912781 - val_loss: 1.5822627544403076 - val_accuracy: 0.42800000309944153 - penalty: 1e-05\n",
            "layer sizes: [3072, 39, 28, 13, 65, 10]\n",
            "##########################################################\n",
            "Epoch 21/50\n",
            "Before growing:\n",
            "loss: 1.538189172744751 - accuracy: 0.4408800005912781 - val_loss: 1.5822627544403076 - val_accuracy: 0.42800000309944153 - penalty: 1e-05\n",
            "layer sizes: [3072, 39, 28, 13, 65, 10]\n",
            "After growing:\n",
            "loss: 1.5381890535354614 - accuracy: 0.4408800005912781 - val_loss: 1.5822627544403076 - val_accuracy: 0.42800000309944153 - penalty: 1e-05\n",
            "layer sizes: [3072, 89, 78, 63, 115, 10]\n",
            "Before pruning:\n",
            "loss: 1.5276154279708862 - accuracy: 0.44633999466896057 - val_loss: 1.5780283212661743 - val_accuracy: 0.42750000953674316 - penalty: 1e-05\n",
            "layer sizes: [3072, 89, 78, 63, 115, 10]\n",
            "After pruning:\n",
            "loss: 1.527547836303711 - accuracy: 0.44648000597953796 - val_loss: 1.5780357122421265 - val_accuracy: 0.42750000953674316 - penalty: 1e-05\n",
            "layer sizes: [3072, 43, 28, 14, 61, 10]\n",
            "##########################################################\n",
            "Epoch 22/50\n",
            "Before growing:\n",
            "loss: 1.527547836303711 - accuracy: 0.44648000597953796 - val_loss: 1.5780357122421265 - val_accuracy: 0.42750000953674316 - penalty: 1e-05\n",
            "layer sizes: [3072, 43, 28, 14, 61, 10]\n",
            "After growing:\n",
            "loss: 1.527547836303711 - accuracy: 0.44648000597953796 - val_loss: 1.5780357122421265 - val_accuracy: 0.42750000953674316 - penalty: 1e-05\n",
            "layer sizes: [3072, 93, 78, 64, 111, 10]\n",
            "Before pruning:\n",
            "loss: 1.509802222251892 - accuracy: 0.4552600085735321 - val_loss: 1.563576340675354 - val_accuracy: 0.4359999895095825 - penalty: 1e-05\n",
            "layer sizes: [3072, 93, 78, 64, 111, 10]\n",
            "After pruning:\n",
            "loss: 1.5095012187957764 - accuracy: 0.4553399980068207 - val_loss: 1.5633363723754883 - val_accuracy: 0.4359000027179718 - penalty: 1e-05\n",
            "layer sizes: [3072, 54, 28, 14, 68, 10]\n",
            "##########################################################\n",
            "Epoch 23/50\n",
            "Before growing:\n",
            "loss: 1.5095012187957764 - accuracy: 0.4553399980068207 - val_loss: 1.5633363723754883 - val_accuracy: 0.4359000027179718 - penalty: 1e-05\n",
            "layer sizes: [3072, 54, 28, 14, 68, 10]\n",
            "After growing:\n",
            "loss: 1.5095012187957764 - accuracy: 0.4553399980068207 - val_loss: 1.5633363723754883 - val_accuracy: 0.4359000027179718 - penalty: 1e-05\n",
            "layer sizes: [3072, 104, 78, 64, 118, 10]\n",
            "Before pruning:\n",
            "loss: 1.4971712827682495 - accuracy: 0.4598599970340729 - val_loss: 1.556594729423523 - val_accuracy: 0.43970000743865967 - penalty: 1e-05\n",
            "layer sizes: [3072, 104, 78, 64, 118, 10]\n",
            "After pruning:\n",
            "loss: 1.4973499774932861 - accuracy: 0.45989999175071716 - val_loss: 1.5568666458129883 - val_accuracy: 0.43939998745918274 - penalty: 1e-05\n",
            "layer sizes: [3072, 45, 28, 14, 56, 10]\n",
            "##########################################################\n",
            "Epoch 24/50\n",
            "Before growing:\n",
            "loss: 1.4973499774932861 - accuracy: 0.45989999175071716 - val_loss: 1.5568666458129883 - val_accuracy: 0.43939998745918274 - penalty: 1e-05\n",
            "layer sizes: [3072, 45, 28, 14, 56, 10]\n",
            "After growing:\n",
            "loss: 1.4973499774932861 - accuracy: 0.45989999175071716 - val_loss: 1.5568665266036987 - val_accuracy: 0.43939998745918274 - penalty: 1e-05\n",
            "layer sizes: [3072, 95, 78, 64, 106, 10]\n",
            "Before pruning:\n",
            "loss: 1.490395426750183 - accuracy: 0.4634400010108948 - val_loss: 1.5545532703399658 - val_accuracy: 0.43700000643730164 - penalty: 1e-05\n",
            "layer sizes: [3072, 95, 78, 64, 106, 10]\n",
            "After pruning:\n",
            "loss: 1.4906808137893677 - accuracy: 0.4629800021648407 - val_loss: 1.5547876358032227 - val_accuracy: 0.43720000982284546 - penalty: 1e-05\n",
            "layer sizes: [3072, 35, 28, 13, 49, 10]\n",
            "##########################################################\n",
            "Epoch 25/50\n",
            "Before growing:\n",
            "loss: 1.4906808137893677 - accuracy: 0.4629800021648407 - val_loss: 1.5547876358032227 - val_accuracy: 0.43720000982284546 - penalty: 1e-05\n",
            "layer sizes: [3072, 35, 28, 13, 49, 10]\n",
            "After growing:\n",
            "loss: 1.4906808137893677 - accuracy: 0.4629800021648407 - val_loss: 1.5547876358032227 - val_accuracy: 0.43720000982284546 - penalty: 1e-05\n",
            "layer sizes: [3072, 85, 78, 63, 99, 10]\n",
            "Before pruning:\n",
            "loss: 1.482893466949463 - accuracy: 0.465719997882843 - val_loss: 1.5524499416351318 - val_accuracy: 0.4413999915122986 - penalty: 1e-05\n",
            "layer sizes: [3072, 85, 78, 63, 99, 10]\n",
            "After pruning:\n",
            "loss: 1.4825448989868164 - accuracy: 0.46588000655174255 - val_loss: 1.5522544384002686 - val_accuracy: 0.4413999915122986 - penalty: 1e-05\n",
            "layer sizes: [3072, 33, 27, 13, 67, 10]\n",
            "##########################################################\n",
            "Epoch 26/50\n",
            "Before growing:\n",
            "loss: 1.4825448989868164 - accuracy: 0.46588000655174255 - val_loss: 1.5522544384002686 - val_accuracy: 0.4413999915122986 - penalty: 1e-05\n",
            "layer sizes: [3072, 33, 27, 13, 67, 10]\n",
            "After growing:\n",
            "loss: 1.4825448989868164 - accuracy: 0.46588000655174255 - val_loss: 1.5522544384002686 - val_accuracy: 0.4413999915122986 - penalty: 1e-05\n",
            "layer sizes: [3072, 83, 77, 63, 117, 10]\n",
            "Before pruning:\n",
            "loss: 1.480233073234558 - accuracy: 0.46696001291275024 - val_loss: 1.555190086364746 - val_accuracy: 0.4399000108242035 - penalty: 1e-05\n",
            "layer sizes: [3072, 83, 77, 63, 117, 10]\n",
            "After pruning:\n",
            "loss: 1.4800384044647217 - accuracy: 0.46682000160217285 - val_loss: 1.5550020933151245 - val_accuracy: 0.43959999084472656 - penalty: 1e-05\n",
            "layer sizes: [3072, 42, 27, 13, 77, 10]\n",
            "##########################################################\n",
            "Epoch 27/50\n",
            "Before growing:\n",
            "loss: 1.4800384044647217 - accuracy: 0.46682000160217285 - val_loss: 1.5550020933151245 - val_accuracy: 0.43959999084472656 - penalty: 1e-05\n",
            "layer sizes: [3072, 42, 27, 13, 77, 10]\n",
            "After growing:\n",
            "loss: 1.4800384044647217 - accuracy: 0.46682000160217285 - val_loss: 1.5550020933151245 - val_accuracy: 0.43959999084472656 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 92, 77, 63, 127, 10]\n",
            "Before pruning:\n",
            "loss: 1.4496673345565796 - accuracy: 0.47788000106811523 - val_loss: 1.5275428295135498 - val_accuracy: 0.45329999923706055 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 92, 77, 63, 127, 10]\n",
            "After pruning:\n",
            "loss: 1.4496662616729736 - accuracy: 0.4779199957847595 - val_loss: 1.5275418758392334 - val_accuracy: 0.45329999923706055 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 92, 77, 63, 77, 10]\n",
            "##########################################################\n",
            "Epoch 28/50\n",
            "Before growing:\n",
            "loss: 1.4496662616729736 - accuracy: 0.4779199957847595 - val_loss: 1.5275418758392334 - val_accuracy: 0.45329999923706055 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 92, 77, 63, 77, 10]\n",
            "After growing:\n",
            "loss: 1.4496662616729736 - accuracy: 0.4779199957847595 - val_loss: 1.5275417566299438 - val_accuracy: 0.45329999923706055 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 142, 127, 113, 127, 10]\n",
            "Before pruning:\n",
            "loss: 1.415971279144287 - accuracy: 0.4937399923801422 - val_loss: 1.5035312175750732 - val_accuracy: 0.4652000069618225 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 142, 127, 113, 127, 10]\n",
            "After pruning:\n",
            "loss: 1.4159611463546753 - accuracy: 0.4936800003051758 - val_loss: 1.5035231113433838 - val_accuracy: 0.4652000069618225 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 140, 126, 77, 104, 10]\n",
            "##########################################################\n",
            "Epoch 29/50\n",
            "Before growing:\n",
            "loss: 1.4159611463546753 - accuracy: 0.4936800003051758 - val_loss: 1.5035231113433838 - val_accuracy: 0.4652000069618225 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 140, 126, 77, 104, 10]\n",
            "After growing:\n",
            "loss: 1.4159612655639648 - accuracy: 0.4936800003051758 - val_loss: 1.5035229921340942 - val_accuracy: 0.4652000069618225 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 190, 176, 127, 154, 10]\n",
            "Before pruning:\n",
            "loss: 1.388051152229309 - accuracy: 0.5059000253677368 - val_loss: 1.4814006090164185 - val_accuracy: 0.47760000824928284 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 190, 176, 127, 154, 10]\n",
            "After pruning:\n",
            "loss: 1.3880300521850586 - accuracy: 0.505840003490448 - val_loss: 1.481391191482544 - val_accuracy: 0.47749999165534973 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 185, 155, 88, 93, 10]\n",
            "##########################################################\n",
            "Epoch 30/50\n",
            "Before growing:\n",
            "loss: 1.3880300521850586 - accuracy: 0.505840003490448 - val_loss: 1.481391191482544 - val_accuracy: 0.47749999165534973 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 185, 155, 88, 93, 10]\n",
            "After growing:\n",
            "loss: 1.3880300521850586 - accuracy: 0.505840003490448 - val_loss: 1.481391191482544 - val_accuracy: 0.47749999165534973 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 235, 205, 138, 143, 10]\n",
            "Before pruning:\n",
            "loss: 1.358595609664917 - accuracy: 0.5182600021362305 - val_loss: 1.459433674812317 - val_accuracy: 0.4853000044822693 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 235, 205, 138, 143, 10]\n",
            "After pruning:\n",
            "loss: 1.3586485385894775 - accuracy: 0.518060028553009 - val_loss: 1.4594615697860718 - val_accuracy: 0.48510000109672546 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 211, 176, 103, 93, 10]\n",
            "##########################################################\n",
            "Epoch 31/50\n",
            "Before growing:\n",
            "loss: 1.3586485385894775 - accuracy: 0.518060028553009 - val_loss: 1.4594615697860718 - val_accuracy: 0.48510000109672546 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 211, 176, 103, 93, 10]\n",
            "After growing:\n",
            "loss: 1.3586485385894775 - accuracy: 0.518060028553009 - val_loss: 1.4594616889953613 - val_accuracy: 0.48510000109672546 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 261, 226, 153, 143, 10]\n",
            "Before pruning:\n",
            "loss: 1.3334884643554688 - accuracy: 0.527180016040802 - val_loss: 1.4449195861816406 - val_accuracy: 0.4900999963283539 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 261, 226, 153, 143, 10]\n",
            "After pruning:\n",
            "loss: 1.3332840204238892 - accuracy: 0.527459979057312 - val_loss: 1.444771647453308 - val_accuracy: 0.4902999997138977 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 219, 201, 105, 48, 10]\n",
            "##########################################################\n",
            "Epoch 32/50\n",
            "Before growing:\n",
            "loss: 1.3332840204238892 - accuracy: 0.527459979057312 - val_loss: 1.444771647453308 - val_accuracy: 0.4902999997138977 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 219, 201, 105, 48, 10]\n",
            "After growing:\n",
            "loss: 1.3332840204238892 - accuracy: 0.527459979057312 - val_loss: 1.4447715282440186 - val_accuracy: 0.4902999997138977 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 269, 251, 155, 98, 10]\n",
            "Before pruning:\n",
            "loss: 1.330496907234192 - accuracy: 0.5290600061416626 - val_loss: 1.4535704851150513 - val_accuracy: 0.4862000048160553 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 269, 251, 155, 98, 10]\n",
            "After pruning:\n",
            "loss: 1.3302565813064575 - accuracy: 0.5290799736976624 - val_loss: 1.4533871412277222 - val_accuracy: 0.4862000048160553 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 227, 228, 95, 74, 10]\n",
            "##########################################################\n",
            "Epoch 33/50\n",
            "Before growing:\n",
            "loss: 1.3302565813064575 - accuracy: 0.5290799736976624 - val_loss: 1.4533871412277222 - val_accuracy: 0.4862000048160553 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 227, 228, 95, 74, 10]\n",
            "After growing:\n",
            "loss: 1.3302565813064575 - accuracy: 0.5290799736976624 - val_loss: 1.4533871412277222 - val_accuracy: 0.4862000048160553 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 277, 278, 145, 124, 10]\n",
            "Before pruning:\n",
            "loss: 1.2975372076034546 - accuracy: 0.5407199859619141 - val_loss: 1.4300810098648071 - val_accuracy: 0.492900013923645 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 277, 278, 145, 124, 10]\n",
            "After pruning:\n",
            "loss: 1.2975372076034546 - accuracy: 0.5407199859619141 - val_loss: 1.4300810098648071 - val_accuracy: 0.492900013923645 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 277, 278, 145, 124, 10]\n",
            "##########################################################\n",
            "Epoch 34/50\n",
            "Before growing:\n",
            "loss: 1.2975372076034546 - accuracy: 0.5407199859619141 - val_loss: 1.4300810098648071 - val_accuracy: 0.492900013923645 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 277, 278, 145, 124, 10]\n",
            "After growing:\n",
            "loss: 1.297537088394165 - accuracy: 0.5407199859619141 - val_loss: 1.4300810098648071 - val_accuracy: 0.492900013923645 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 332, 333, 195, 174, 10]\n",
            "Before pruning:\n",
            "loss: 1.2760323286056519 - accuracy: 0.5492200255393982 - val_loss: 1.4230144023895264 - val_accuracy: 0.4959000051021576 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 332, 333, 195, 174, 10]\n",
            "After pruning:\n",
            "loss: 1.2760323286056519 - accuracy: 0.5492200255393982 - val_loss: 1.4230142831802368 - val_accuracy: 0.4959000051021576 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 332, 333, 195, 173, 10]\n",
            "##########################################################\n",
            "Epoch 35/50\n",
            "Before growing:\n",
            "loss: 1.2760323286056519 - accuracy: 0.5492200255393982 - val_loss: 1.4230142831802368 - val_accuracy: 0.4959000051021576 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 332, 333, 195, 173, 10]\n",
            "After growing:\n",
            "loss: 1.2760323286056519 - accuracy: 0.5492200255393982 - val_loss: 1.4230144023895264 - val_accuracy: 0.4959000051021576 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 398, 399, 245, 223, 10]\n",
            "Before pruning:\n",
            "loss: 1.2480413913726807 - accuracy: 0.5601599812507629 - val_loss: 1.4040998220443726 - val_accuracy: 0.4991999864578247 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 398, 399, 245, 223, 10]\n",
            "After pruning:\n",
            "loss: 1.248040795326233 - accuracy: 0.5601599812507629 - val_loss: 1.4040992259979248 - val_accuracy: 0.4991999864578247 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 398, 399, 245, 188, 10]\n",
            "##########################################################\n",
            "Epoch 36/50\n",
            "Before growing:\n",
            "loss: 1.248040795326233 - accuracy: 0.5601599812507629 - val_loss: 1.4040992259979248 - val_accuracy: 0.4991999864578247 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 398, 399, 245, 188, 10]\n",
            "After growing:\n",
            "loss: 1.248040795326233 - accuracy: 0.5601599812507629 - val_loss: 1.4040992259979248 - val_accuracy: 0.4991999864578247 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 477, 478, 295, 238, 10]\n",
            "Before pruning:\n",
            "loss: 1.229069471359253 - accuracy: 0.565500020980835 - val_loss: 1.3987220525741577 - val_accuracy: 0.5044000148773193 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 477, 478, 295, 238, 10]\n",
            "After pruning:\n",
            "loss: 1.229068636894226 - accuracy: 0.565500020980835 - val_loss: 1.3987213373184204 - val_accuracy: 0.5044000148773193 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 477, 478, 295, 198, 10]\n",
            "##########################################################\n",
            "Epoch 37/50\n",
            "Before growing:\n",
            "loss: 1.229068636894226 - accuracy: 0.565500020980835 - val_loss: 1.3987213373184204 - val_accuracy: 0.5044000148773193 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 477, 478, 295, 198, 10]\n",
            "After growing:\n",
            "loss: 1.229068636894226 - accuracy: 0.565500020980835 - val_loss: 1.3987213373184204 - val_accuracy: 0.5044000148773193 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 572, 573, 354, 248, 10]\n",
            "Before pruning:\n",
            "loss: 1.192228078842163 - accuracy: 0.578279972076416 - val_loss: 1.3821673393249512 - val_accuracy: 0.5112000107765198 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 572, 573, 354, 248, 10]\n",
            "After pruning:\n",
            "loss: 1.1922270059585571 - accuracy: 0.578279972076416 - val_loss: 1.3821660280227661 - val_accuracy: 0.5112000107765198 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 572, 572, 354, 209, 10]\n",
            "##########################################################\n",
            "Epoch 38/50\n",
            "Before growing:\n",
            "loss: 1.1922270059585571 - accuracy: 0.578279972076416 - val_loss: 1.3821660280227661 - val_accuracy: 0.5112000107765198 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 572, 572, 354, 209, 10]\n",
            "After growing:\n",
            "loss: 1.1922270059585571 - accuracy: 0.578279972076416 - val_loss: 1.3821660280227661 - val_accuracy: 0.5112000107765198 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 686, 686, 424, 259, 10]\n",
            "Before pruning:\n",
            "loss: 1.1635173559188843 - accuracy: 0.5899199843406677 - val_loss: 1.3703094720840454 - val_accuracy: 0.5174000263214111 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 686, 686, 424, 259, 10]\n",
            "After pruning:\n",
            "loss: 1.163524866104126 - accuracy: 0.5898399949073792 - val_loss: 1.3703056573867798 - val_accuracy: 0.5171999931335449 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 679, 684, 424, 236, 10]\n",
            "##########################################################\n",
            "Epoch 39/50\n",
            "Before growing:\n",
            "loss: 1.163524866104126 - accuracy: 0.5898399949073792 - val_loss: 1.3703056573867798 - val_accuracy: 0.5171999931335449 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 679, 684, 424, 236, 10]\n",
            "After growing:\n",
            "loss: 1.163524866104126 - accuracy: 0.5898399949073792 - val_loss: 1.3703056573867798 - val_accuracy: 0.5171999931335449 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 814, 820, 508, 286, 10]\n",
            "Before pruning:\n",
            "loss: 1.1468786001205444 - accuracy: 0.5948600172996521 - val_loss: 1.3657418489456177 - val_accuracy: 0.5149999856948853 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 814, 820, 508, 286, 10]\n",
            "After pruning:\n",
            "loss: 1.1468708515167236 - accuracy: 0.5948799848556519 - val_loss: 1.3657286167144775 - val_accuracy: 0.5151000022888184 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 809, 815, 508, 232, 10]\n",
            "##########################################################\n",
            "Epoch 40/50\n",
            "Before growing:\n",
            "loss: 1.1468708515167236 - accuracy: 0.5948799848556519 - val_loss: 1.3657286167144775 - val_accuracy: 0.5151000022888184 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 809, 815, 508, 232, 10]\n",
            "After growing:\n",
            "loss: 1.146870732307434 - accuracy: 0.5948799848556519 - val_loss: 1.365728497505188 - val_accuracy: 0.5151000022888184 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 970, 978, 609, 282, 10]\n",
            "Before pruning:\n",
            "loss: 1.1286396980285645 - accuracy: 0.6017400026321411 - val_loss: 1.3652913570404053 - val_accuracy: 0.515500009059906 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 970, 978, 609, 282, 10]\n",
            "After pruning:\n",
            "loss: 1.1285964250564575 - accuracy: 0.6017400026321411 - val_loss: 1.3652578592300415 - val_accuracy: 0.5152999758720398 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 958, 955, 609, 250, 10]\n",
            "##########################################################\n",
            "Epoch 41/50\n",
            "Before growing:\n",
            "loss: 1.1285964250564575 - accuracy: 0.6017400026321411 - val_loss: 1.3652578592300415 - val_accuracy: 0.5152999758720398 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 958, 955, 609, 250, 10]\n",
            "After growing:\n",
            "loss: 1.1285964250564575 - accuracy: 0.6017400026321411 - val_loss: 1.3652578592300415 - val_accuracy: 0.5152999758720398 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 1149, 1146, 730, 300, 10]\n",
            "Before pruning:\n",
            "loss: 1.1135743856430054 - accuracy: 0.6068000197410583 - val_loss: 1.3654240369796753 - val_accuracy: 0.5170999765396118 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 1149, 1146, 730, 300, 10]\n",
            "After pruning:\n",
            "loss: 1.11354660987854 - accuracy: 0.6066200137138367 - val_loss: 1.3653552532196045 - val_accuracy: 0.5170000195503235 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 1108, 1141, 726, 273, 10]\n",
            "##########################################################\n",
            "Epoch 42/50\n",
            "Before growing:\n",
            "loss: 1.11354660987854 - accuracy: 0.6066200137138367 - val_loss: 1.3653552532196045 - val_accuracy: 0.5170000195503235 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 1108, 1141, 726, 273, 10]\n",
            "After growing:\n",
            "loss: 1.11354660987854 - accuracy: 0.6066200137138367 - val_loss: 1.365355134010315 - val_accuracy: 0.5170000195503235 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 1329, 1369, 871, 327, 10]\n",
            "Before pruning:\n",
            "loss: 1.1243542432785034 - accuracy: 0.6030799746513367 - val_loss: 1.3839462995529175 - val_accuracy: 0.513700008392334 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 1329, 1369, 871, 327, 10]\n",
            "After pruning:\n",
            "loss: 1.1243542432785034 - accuracy: 0.6030799746513367 - val_loss: 1.3839462995529175 - val_accuracy: 0.513700008392334 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 1329, 1369, 871, 327, 10]\n",
            "##########################################################\n",
            "Epoch 43/50\n",
            "Before growing:\n",
            "loss: 1.1243542432785034 - accuracy: 0.6030799746513367 - val_loss: 1.3839462995529175 - val_accuracy: 0.513700008392334 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 1329, 1369, 871, 327, 10]\n",
            "After growing:\n",
            "loss: 1.124354362487793 - accuracy: 0.6030799746513367 - val_loss: 1.3839462995529175 - val_accuracy: 0.513700008392334 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 1594, 1642, 1045, 392, 10]\n",
            "Before pruning:\n",
            "loss: 1.1195056438446045 - accuracy: 0.6016600131988525 - val_loss: 1.3772610425949097 - val_accuracy: 0.5116999745368958 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 1594, 1642, 1045, 392, 10]\n",
            "After pruning:\n",
            "loss: 1.1195056438446045 - accuracy: 0.6016600131988525 - val_loss: 1.3772610425949097 - val_accuracy: 0.5116999745368958 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 1594, 1642, 1045, 392, 10]\n",
            "##########################################################\n",
            "Epoch 44/50\n",
            "Before growing:\n",
            "loss: 1.1195056438446045 - accuracy: 0.6016600131988525 - val_loss: 1.3772610425949097 - val_accuracy: 0.5116999745368958 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 1594, 1642, 1045, 392, 10]\n",
            "After growing:\n",
            "loss: 1.1195056438446045 - accuracy: 0.6016600131988525 - val_loss: 1.3772611618041992 - val_accuracy: 0.5116999745368958 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 1912, 1970, 1254, 470, 10]\n",
            "Before pruning:\n",
            "loss: 1.1194733381271362 - accuracy: 0.6023200154304504 - val_loss: 1.3971736431121826 - val_accuracy: 0.5121999979019165 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 1912, 1970, 1254, 470, 10]\n",
            "After pruning:\n",
            "loss: 1.1194733381271362 - accuracy: 0.6023200154304504 - val_loss: 1.3971736431121826 - val_accuracy: 0.5121999979019165 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 1912, 1970, 1254, 470, 10]\n",
            "##########################################################\n",
            "Epoch 45/50\n",
            "Before growing:\n",
            "loss: 1.1194733381271362 - accuracy: 0.6023200154304504 - val_loss: 1.3971736431121826 - val_accuracy: 0.5121999979019165 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 1912, 1970, 1254, 470, 10]\n",
            "After growing:\n",
            "loss: 1.1194733381271362 - accuracy: 0.6023200154304504 - val_loss: 1.3971736431121826 - val_accuracy: 0.5121999979019165 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 2294, 2364, 1504, 564, 10]\n",
            "Before pruning:\n",
            "loss: 1.1225438117980957 - accuracy: 0.6032000184059143 - val_loss: 1.4037624597549438 - val_accuracy: 0.5181999802589417 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 2294, 2364, 1504, 564, 10]\n",
            "After pruning:\n",
            "loss: 1.1225438117980957 - accuracy: 0.6032000184059143 - val_loss: 1.4037624597549438 - val_accuracy: 0.5181999802589417 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 2294, 2364, 1504, 564, 10]\n",
            "##########################################################\n",
            "Epoch 46/50\n",
            "Before growing:\n",
            "loss: 1.1225438117980957 - accuracy: 0.6032000184059143 - val_loss: 1.4037624597549438 - val_accuracy: 0.5181999802589417 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 2294, 2364, 1504, 564, 10]\n",
            "After growing:\n",
            "loss: 1.1225439310073853 - accuracy: 0.6032000184059143 - val_loss: 1.4037624597549438 - val_accuracy: 0.5181999802589417 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 2752, 2836, 1804, 676, 10]\n",
            "Before pruning:\n",
            "loss: 1.0946334600448608 - accuracy: 0.6144999861717224 - val_loss: 1.3642951250076294 - val_accuracy: 0.5235999822616577 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 2752, 2836, 1804, 676, 10]\n",
            "After pruning:\n",
            "loss: 1.094636082649231 - accuracy: 0.6144999861717224 - val_loss: 1.364301323890686 - val_accuracy: 0.5235999822616577 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 2740, 2836, 1804, 676, 10]\n",
            "##########################################################\n",
            "Epoch 47/50\n",
            "Before growing:\n",
            "loss: 1.094636082649231 - accuracy: 0.6144999861717224 - val_loss: 1.364301323890686 - val_accuracy: 0.5235999822616577 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 2740, 2836, 1804, 676, 10]\n",
            "After growing:\n",
            "loss: 1.094636082649231 - accuracy: 0.6144999861717224 - val_loss: 1.364301323890686 - val_accuracy: 0.5235999822616577 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 3288, 3403, 2164, 811, 10]\n",
            "Before pruning:\n",
            "loss: 1.0735093355178833 - accuracy: 0.6183800101280212 - val_loss: 1.379501223564148 - val_accuracy: 0.5253999829292297 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 3288, 3403, 2164, 811, 10]\n",
            "After pruning:\n",
            "loss: 1.0735034942626953 - accuracy: 0.6182600259780884 - val_loss: 1.3794472217559814 - val_accuracy: 0.5256999731063843 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 3201, 3403, 2164, 811, 10]\n",
            "##########################################################\n",
            "Epoch 48/50\n",
            "Before growing:\n",
            "loss: 1.0735034942626953 - accuracy: 0.6182600259780884 - val_loss: 1.3794472217559814 - val_accuracy: 0.5256999731063843 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 3201, 3403, 2164, 811, 10]\n",
            "After growing:\n",
            "loss: 1.0735034942626953 - accuracy: 0.6182600259780884 - val_loss: 1.3794472217559814 - val_accuracy: 0.5256999731063843 - penalty: 1.0000000000000005e-09\n",
            "layer sizes: [3072, 3841, 4083, 2596, 973, 10]\n",
            "Before pruning:\n",
            "loss: 1.1313385963439941 - accuracy: 0.6038200259208679 - val_loss: 1.4001394510269165 - val_accuracy: 0.5216000080108643 - penalty: 1.0000000000000005e-09\n",
            "layer sizes: [3072, 3841, 4083, 2596, 973, 10]\n",
            "After pruning:\n",
            "loss: 1.1313385963439941 - accuracy: 0.6038200259208679 - val_loss: 1.4001394510269165 - val_accuracy: 0.5216000080108643 - penalty: 1.0000000000000005e-09\n",
            "layer sizes: [3072, 3841, 4083, 2596, 973, 10]\n",
            "##########################################################\n",
            "Epoch 49/50\n",
            "Before growing:\n",
            "loss: 1.1313385963439941 - accuracy: 0.6038200259208679 - val_loss: 1.4001394510269165 - val_accuracy: 0.5216000080108643 - penalty: 1.0000000000000005e-09\n",
            "layer sizes: [3072, 3841, 4083, 2596, 973, 10]\n",
            "After growing:\n",
            "loss: 1.1313385963439941 - accuracy: 0.6038200259208679 - val_loss: 1.400139570236206 - val_accuracy: 0.5216000080108643 - penalty: 1.0000000000000005e-09\n",
            "layer sizes: [3072, 4609, 4899, 3115, 1167, 10]\n",
            "Before pruning:\n",
            "loss: 1.1265474557876587 - accuracy: 0.5961400270462036 - val_loss: 1.3908588886260986 - val_accuracy: 0.5202000141143799 - penalty: 1.0000000000000005e-09\n",
            "layer sizes: [3072, 4609, 4899, 3115, 1167, 10]\n",
            "After pruning:\n",
            "loss: 1.1265474557876587 - accuracy: 0.5961400270462036 - val_loss: 1.3908588886260986 - val_accuracy: 0.5202000141143799 - penalty: 1.0000000000000005e-09\n",
            "layer sizes: [3072, 4609, 4899, 3115, 1167, 10]\n",
            "##########################################################\n",
            "Epoch 50/50\n",
            "Before growing:\n",
            "loss: 1.1265474557876587 - accuracy: 0.5961400270462036 - val_loss: 1.3908588886260986 - val_accuracy: 0.5202000141143799 - penalty: 1.0000000000000005e-09\n",
            "layer sizes: [3072, 4609, 4899, 3115, 1167, 10]\n",
            "After growing:\n",
            "loss: 1.1265474557876587 - accuracy: 0.5961400270462036 - val_loss: 1.3908588886260986 - val_accuracy: 0.5202000141143799 - penalty: 1.0000000000000005e-09\n",
            "layer sizes: [3072, 5530, 5878, 3738, 1400, 10]\n",
            "Before pruning:\n",
            "loss: 1.2126522064208984 - accuracy: 0.5607200264930725 - val_loss: 1.4103004932403564 - val_accuracy: 0.5037999749183655 - penalty: 1.0000000000000005e-09\n",
            "layer sizes: [3072, 5530, 5878, 3738, 1400, 10]\n",
            "After pruning:\n",
            "loss: 1.2126522064208984 - accuracy: 0.5607200264930725 - val_loss: 1.4103004932403564 - val_accuracy: 0.5037999749183655 - penalty: 1.0000000000000005e-09\n",
            "layer sizes: [3072, 5530, 5878, 3738, 1400, 10]\n",
            "CPU times: user 18min 38s, sys: 14.9 s, total: 18min 53s\n",
            "Wall time: 19min 13s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3Xtj5FYfMkP",
        "outputId": "c9fa85e4-ca5e-45e0-f4f6-4654c380be28"
      },
      "source": [
        "%%time\n",
        "\n",
        "model = SSModel(layer_sizes=[3072, 300, 300, 300, 300, 10], activation='selu', regularization_penalty=0.0001, regularization_method='weighted_l1', kernel_initializer='lecun_normal')\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "train_model(model, X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, min_new_neurons, validation_data=(X_test_norm, y_test), regularization_penalty_multiplier=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##########################################################\n",
            "Epoch 1/50\n",
            "Before growing:\n",
            "loss: 2.72518253326416 - accuracy: 0.10886000096797943 - val_loss: 2.734980821609497 - val_accuracy: 0.10670000314712524 - penalty: 0.0001\n",
            "layer sizes: [3072, 300, 300, 300, 300, 10]\n",
            "After growing:\n",
            "loss: 2.72518253326416 - accuracy: 0.10886000096797943 - val_loss: 2.734980821609497 - val_accuracy: 0.10670000314712524 - penalty: 0.0001\n",
            "layer sizes: [3072, 360, 360, 360, 360, 10]\n",
            "Before pruning:\n",
            "loss: 1.8462209701538086 - accuracy: 0.3119400143623352 - val_loss: 1.8498504161834717 - val_accuracy: 0.30640000104904175 - penalty: 0.0001\n",
            "layer sizes: [3072, 360, 360, 360, 360, 10]\n",
            "After pruning:\n",
            "loss: 1.8453584909439087 - accuracy: 0.3140600025653839 - val_loss: 1.848866581916809 - val_accuracy: 0.30880001187324524 - penalty: 0.0001\n",
            "layer sizes: [3072, 13, 62, 33, 64, 10]\n",
            "##########################################################\n",
            "Epoch 2/50\n",
            "Before growing:\n",
            "loss: 1.8453584909439087 - accuracy: 0.3140600025653839 - val_loss: 1.848866581916809 - val_accuracy: 0.30880001187324524 - penalty: 0.0001\n",
            "layer sizes: [3072, 13, 62, 33, 64, 10]\n",
            "After growing:\n",
            "loss: 1.8453584909439087 - accuracy: 0.3140600025653839 - val_loss: 1.848866581916809 - val_accuracy: 0.30880001187324524 - penalty: 0.0001\n",
            "layer sizes: [3072, 63, 112, 83, 114, 10]\n",
            "Before pruning:\n",
            "loss: 1.7795809507369995 - accuracy: 0.35482001304626465 - val_loss: 1.7862861156463623 - val_accuracy: 0.35190001130104065 - penalty: 0.0001\n",
            "layer sizes: [3072, 63, 112, 83, 114, 10]\n",
            "After pruning:\n",
            "loss: 1.7795488834381104 - accuracy: 0.3548400104045868 - val_loss: 1.7862470149993896 - val_accuracy: 0.352400004863739 - penalty: 0.0001\n",
            "layer sizes: [3072, 9, 43, 20, 55, 10]\n",
            "##########################################################\n",
            "Epoch 3/50\n",
            "Before growing:\n",
            "loss: 1.7795488834381104 - accuracy: 0.3548400104045868 - val_loss: 1.7862470149993896 - val_accuracy: 0.352400004863739 - penalty: 0.0001\n",
            "layer sizes: [3072, 9, 43, 20, 55, 10]\n",
            "After growing:\n",
            "loss: 1.7795488834381104 - accuracy: 0.3548400104045868 - val_loss: 1.7862470149993896 - val_accuracy: 0.352400004863739 - penalty: 0.0001\n",
            "layer sizes: [3072, 59, 93, 70, 105, 10]\n",
            "Before pruning:\n",
            "loss: 1.7359932661056519 - accuracy: 0.3706200122833252 - val_loss: 1.7434598207473755 - val_accuracy: 0.3635999858379364 - penalty: 0.0001\n",
            "layer sizes: [3072, 59, 93, 70, 105, 10]\n",
            "After pruning:\n",
            "loss: 1.7360093593597412 - accuracy: 0.3706200122833252 - val_loss: 1.7434773445129395 - val_accuracy: 0.3634999990463257 - penalty: 0.0001\n",
            "layer sizes: [3072, 9, 33, 18, 50, 10]\n",
            "##########################################################\n",
            "Epoch 4/50\n",
            "Before growing:\n",
            "loss: 1.7360093593597412 - accuracy: 0.3706200122833252 - val_loss: 1.7434773445129395 - val_accuracy: 0.3634999990463257 - penalty: 0.0001\n",
            "layer sizes: [3072, 9, 33, 18, 50, 10]\n",
            "After growing:\n",
            "loss: 1.7360094785690308 - accuracy: 0.3706200122833252 - val_loss: 1.7434773445129395 - val_accuracy: 0.3634999990463257 - penalty: 0.0001\n",
            "layer sizes: [3072, 59, 83, 68, 100, 10]\n",
            "Before pruning:\n",
            "loss: 1.7196085453033447 - accuracy: 0.3804199993610382 - val_loss: 1.729251503944397 - val_accuracy: 0.3709999918937683 - penalty: 0.0001\n",
            "layer sizes: [3072, 59, 83, 68, 100, 10]\n",
            "After pruning:\n",
            "loss: 1.7196271419525146 - accuracy: 0.3804599940776825 - val_loss: 1.7292747497558594 - val_accuracy: 0.3709999918937683 - penalty: 0.0001\n",
            "layer sizes: [3072, 9, 33, 16, 47, 10]\n",
            "##########################################################\n",
            "Epoch 5/50\n",
            "Before growing:\n",
            "loss: 1.7196271419525146 - accuracy: 0.3804599940776825 - val_loss: 1.7292747497558594 - val_accuracy: 0.3709999918937683 - penalty: 0.0001\n",
            "layer sizes: [3072, 9, 33, 16, 47, 10]\n",
            "After growing:\n",
            "loss: 1.7196273803710938 - accuracy: 0.3804599940776825 - val_loss: 1.7292747497558594 - val_accuracy: 0.3709999918937683 - penalty: 0.0001\n",
            "layer sizes: [3072, 59, 83, 66, 97, 10]\n",
            "Before pruning:\n",
            "loss: 1.7003880739212036 - accuracy: 0.3849799931049347 - val_loss: 1.7113796472549438 - val_accuracy: 0.3831000030040741 - penalty: 0.0001\n",
            "layer sizes: [3072, 59, 83, 66, 97, 10]\n",
            "After pruning:\n",
            "loss: 1.7003179788589478 - accuracy: 0.38514000177383423 - val_loss: 1.7112910747528076 - val_accuracy: 0.382999986410141 - penalty: 0.0001\n",
            "layer sizes: [3072, 8, 33, 16, 47, 10]\n",
            "##########################################################\n",
            "Epoch 6/50\n",
            "Before growing:\n",
            "loss: 1.7003179788589478 - accuracy: 0.38514000177383423 - val_loss: 1.7112910747528076 - val_accuracy: 0.382999986410141 - penalty: 0.0001\n",
            "layer sizes: [3072, 8, 33, 16, 47, 10]\n",
            "After growing:\n",
            "loss: 1.7003179788589478 - accuracy: 0.38514000177383423 - val_loss: 1.7112910747528076 - val_accuracy: 0.382999986410141 - penalty: 0.0001\n",
            "layer sizes: [3072, 58, 83, 66, 97, 10]\n",
            "Before pruning:\n",
            "loss: 1.6788606643676758 - accuracy: 0.3943600058555603 - val_loss: 1.6921656131744385 - val_accuracy: 0.3862999975681305 - penalty: 0.0001\n",
            "layer sizes: [3072, 58, 83, 66, 97, 10]\n",
            "After pruning:\n",
            "loss: 1.6788583993911743 - accuracy: 0.39427998661994934 - val_loss: 1.6921603679656982 - val_accuracy: 0.3862999975681305 - penalty: 0.0001\n",
            "layer sizes: [3072, 8, 29, 16, 45, 10]\n",
            "##########################################################\n",
            "Epoch 7/50\n",
            "Before growing:\n",
            "loss: 1.6788583993911743 - accuracy: 0.39427998661994934 - val_loss: 1.6921603679656982 - val_accuracy: 0.3862999975681305 - penalty: 0.0001\n",
            "layer sizes: [3072, 8, 29, 16, 45, 10]\n",
            "After growing:\n",
            "loss: 1.6788583993911743 - accuracy: 0.39427998661994934 - val_loss: 1.6921603679656982 - val_accuracy: 0.3862999975681305 - penalty: 0.0001\n",
            "layer sizes: [3072, 58, 79, 66, 95, 10]\n",
            "Before pruning:\n",
            "loss: 1.6621378660202026 - accuracy: 0.3998599946498871 - val_loss: 1.6773020029067993 - val_accuracy: 0.3905999958515167 - penalty: 0.0001\n",
            "layer sizes: [3072, 58, 79, 66, 95, 10]\n",
            "After pruning:\n",
            "loss: 1.6621677875518799 - accuracy: 0.3998199999332428 - val_loss: 1.6773256063461304 - val_accuracy: 0.3905999958515167 - penalty: 0.0001\n",
            "layer sizes: [3072, 8, 27, 15, 40, 10]\n",
            "##########################################################\n",
            "Epoch 8/50\n",
            "Before growing:\n",
            "loss: 1.6621677875518799 - accuracy: 0.3998199999332428 - val_loss: 1.6773256063461304 - val_accuracy: 0.3905999958515167 - penalty: 0.0001\n",
            "layer sizes: [3072, 8, 27, 15, 40, 10]\n",
            "After growing:\n",
            "loss: 1.6621676683425903 - accuracy: 0.3998199999332428 - val_loss: 1.6773253679275513 - val_accuracy: 0.3905999958515167 - penalty: 0.0001\n",
            "layer sizes: [3072, 58, 77, 65, 90, 10]\n",
            "Before pruning:\n",
            "loss: 1.647430658340454 - accuracy: 0.40220001339912415 - val_loss: 1.6642810106277466 - val_accuracy: 0.3937000036239624 - penalty: 0.0001\n",
            "layer sizes: [3072, 58, 77, 65, 90, 10]\n",
            "After pruning:\n",
            "loss: 1.6474415063858032 - accuracy: 0.40215998888015747 - val_loss: 1.664294719696045 - val_accuracy: 0.3937000036239624 - penalty: 0.0001\n",
            "layer sizes: [3072, 8, 27, 12, 39, 10]\n",
            "##########################################################\n",
            "Epoch 9/50\n",
            "Before growing:\n",
            "loss: 1.6474415063858032 - accuracy: 0.40215998888015747 - val_loss: 1.664294719696045 - val_accuracy: 0.3937000036239624 - penalty: 0.0001\n",
            "layer sizes: [3072, 8, 27, 12, 39, 10]\n",
            "After growing:\n",
            "loss: 1.6474415063858032 - accuracy: 0.40215998888015747 - val_loss: 1.6642944812774658 - val_accuracy: 0.3937000036239624 - penalty: 0.0001\n",
            "layer sizes: [3072, 58, 77, 62, 89, 10]\n",
            "Before pruning:\n",
            "loss: 1.6389553546905518 - accuracy: 0.40446001291275024 - val_loss: 1.6572824716567993 - val_accuracy: 0.39149999618530273 - penalty: 0.0001\n",
            "layer sizes: [3072, 58, 77, 62, 89, 10]\n",
            "After pruning:\n",
            "loss: 1.6379327774047852 - accuracy: 0.4047999978065491 - val_loss: 1.656313419342041 - val_accuracy: 0.39149999618530273 - penalty: 0.0001\n",
            "layer sizes: [3072, 8, 25, 12, 39, 10]\n",
            "##########################################################\n",
            "Epoch 10/50\n",
            "Before growing:\n",
            "loss: 1.6379327774047852 - accuracy: 0.4047999978065491 - val_loss: 1.656313419342041 - val_accuracy: 0.39149999618530273 - penalty: 0.0001\n",
            "layer sizes: [3072, 8, 25, 12, 39, 10]\n",
            "After growing:\n",
            "loss: 1.6379326581954956 - accuracy: 0.4047999978065491 - val_loss: 1.656313419342041 - val_accuracy: 0.39149999618530273 - penalty: 0.0001\n",
            "layer sizes: [3072, 58, 75, 62, 89, 10]\n",
            "Before pruning:\n",
            "loss: 1.6295086145401 - accuracy: 0.4113599956035614 - val_loss: 1.6471565961837769 - val_accuracy: 0.40290001034736633 - penalty: 0.0001\n",
            "layer sizes: [3072, 58, 75, 62, 89, 10]\n",
            "After pruning:\n",
            "loss: 1.6294755935668945 - accuracy: 0.4115400016307831 - val_loss: 1.6471439599990845 - val_accuracy: 0.40290001034736633 - penalty: 0.0001\n",
            "layer sizes: [3072, 8, 25, 12, 38, 10]\n",
            "##########################################################\n",
            "Epoch 11/50\n",
            "Before growing:\n",
            "loss: 1.6294755935668945 - accuracy: 0.4115400016307831 - val_loss: 1.6471439599990845 - val_accuracy: 0.40290001034736633 - penalty: 0.0001\n",
            "layer sizes: [3072, 8, 25, 12, 38, 10]\n",
            "After growing:\n",
            "loss: 1.6294758319854736 - accuracy: 0.4115400016307831 - val_loss: 1.6471441984176636 - val_accuracy: 0.40290001034736633 - penalty: 0.0001\n",
            "layer sizes: [3072, 58, 75, 62, 88, 10]\n",
            "Before pruning:\n",
            "loss: 1.6239887475967407 - accuracy: 0.4093399941921234 - val_loss: 1.64248788356781 - val_accuracy: 0.4016999900341034 - penalty: 0.0001\n",
            "layer sizes: [3072, 58, 75, 62, 88, 10]\n",
            "After pruning:\n",
            "loss: 1.623927354812622 - accuracy: 0.40926000475883484 - val_loss: 1.6424373388290405 - val_accuracy: 0.40149998664855957 - penalty: 0.0001\n",
            "layer sizes: [3072, 8, 24, 12, 38, 10]\n",
            "##########################################################\n",
            "Epoch 12/50\n",
            "Before growing:\n",
            "loss: 1.623927354812622 - accuracy: 0.40926000475883484 - val_loss: 1.6424373388290405 - val_accuracy: 0.40149998664855957 - penalty: 0.0001\n",
            "layer sizes: [3072, 8, 24, 12, 38, 10]\n",
            "After growing:\n",
            "loss: 1.6239272356033325 - accuracy: 0.40926000475883484 - val_loss: 1.6424373388290405 - val_accuracy: 0.40149998664855957 - penalty: 0.0001\n",
            "layer sizes: [3072, 58, 74, 62, 88, 10]\n",
            "Before pruning:\n",
            "loss: 1.6083757877349854 - accuracy: 0.41971999406814575 - val_loss: 1.6299922466278076 - val_accuracy: 0.40369999408721924 - penalty: 0.0001\n",
            "layer sizes: [3072, 58, 74, 62, 88, 10]\n",
            "After pruning:\n",
            "loss: 1.608512043952942 - accuracy: 0.41958001255989075 - val_loss: 1.630104899406433 - val_accuracy: 0.4041999876499176 - penalty: 0.0001\n",
            "layer sizes: [3072, 12, 24, 12, 38, 10]\n",
            "##########################################################\n",
            "Epoch 13/50\n",
            "Before growing:\n",
            "loss: 1.608512043952942 - accuracy: 0.41958001255989075 - val_loss: 1.630104899406433 - val_accuracy: 0.4041999876499176 - penalty: 0.0001\n",
            "layer sizes: [3072, 12, 24, 12, 38, 10]\n",
            "After growing:\n",
            "loss: 1.608512043952942 - accuracy: 0.41958001255989075 - val_loss: 1.630104899406433 - val_accuracy: 0.4041999876499176 - penalty: 0.0001\n",
            "layer sizes: [3072, 62, 74, 62, 88, 10]\n",
            "Before pruning:\n",
            "loss: 1.610434889793396 - accuracy: 0.4178999960422516 - val_loss: 1.6314300298690796 - val_accuracy: 0.41100001335144043 - penalty: 0.0001\n",
            "layer sizes: [3072, 62, 74, 62, 88, 10]\n",
            "After pruning:\n",
            "loss: 1.6104421615600586 - accuracy: 0.41797998547554016 - val_loss: 1.63144052028656 - val_accuracy: 0.4106000065803528 - penalty: 0.0001\n",
            "layer sizes: [3072, 8, 24, 12, 38, 10]\n",
            "##########################################################\n",
            "Epoch 14/50\n",
            "Before growing:\n",
            "loss: 1.6104421615600586 - accuracy: 0.41797998547554016 - val_loss: 1.63144052028656 - val_accuracy: 0.4106000065803528 - penalty: 0.0001\n",
            "layer sizes: [3072, 8, 24, 12, 38, 10]\n",
            "After growing:\n",
            "loss: 1.6104421615600586 - accuracy: 0.41797998547554016 - val_loss: 1.6314406394958496 - val_accuracy: 0.4106000065803528 - penalty: 1e-05\n",
            "layer sizes: [3072, 58, 74, 62, 88, 10]\n",
            "Before pruning:\n",
            "loss: 1.5841261148452759 - accuracy: 0.4314599931240082 - val_loss: 1.6132171154022217 - val_accuracy: 0.41929998993873596 - penalty: 1e-05\n",
            "layer sizes: [3072, 58, 74, 62, 88, 10]\n",
            "After pruning:\n",
            "loss: 1.584245204925537 - accuracy: 0.4314199984073639 - val_loss: 1.6133265495300293 - val_accuracy: 0.4196999967098236 - penalty: 1e-05\n",
            "layer sizes: [3072, 33, 24, 12, 66, 10]\n",
            "##########################################################\n",
            "Epoch 15/50\n",
            "Before growing:\n",
            "loss: 1.584245204925537 - accuracy: 0.4314199984073639 - val_loss: 1.6133265495300293 - val_accuracy: 0.4196999967098236 - penalty: 1e-05\n",
            "layer sizes: [3072, 33, 24, 12, 66, 10]\n",
            "After growing:\n",
            "loss: 1.584244966506958 - accuracy: 0.4314199984073639 - val_loss: 1.6133263111114502 - val_accuracy: 0.4196999967098236 - penalty: 1e-05\n",
            "layer sizes: [3072, 83, 74, 62, 116, 10]\n",
            "Before pruning:\n",
            "loss: 1.5600205659866333 - accuracy: 0.4397200047969818 - val_loss: 1.5928893089294434 - val_accuracy: 0.4239000082015991 - penalty: 1e-05\n",
            "layer sizes: [3072, 83, 74, 62, 116, 10]\n",
            "After pruning:\n",
            "loss: 1.5603649616241455 - accuracy: 0.43974000215530396 - val_loss: 1.5932536125183105 - val_accuracy: 0.42399999499320984 - penalty: 1e-05\n",
            "layer sizes: [3072, 40, 28, 14, 51, 10]\n",
            "##########################################################\n",
            "Epoch 16/50\n",
            "Before growing:\n",
            "loss: 1.5603649616241455 - accuracy: 0.43974000215530396 - val_loss: 1.5932536125183105 - val_accuracy: 0.42399999499320984 - penalty: 1e-05\n",
            "layer sizes: [3072, 40, 28, 14, 51, 10]\n",
            "After growing:\n",
            "loss: 1.5603649616241455 - accuracy: 0.43974000215530396 - val_loss: 1.5932536125183105 - val_accuracy: 0.42399999499320984 - penalty: 1e-05\n",
            "layer sizes: [3072, 90, 78, 64, 101, 10]\n",
            "Before pruning:\n",
            "loss: 1.5468981266021729 - accuracy: 0.4472399950027466 - val_loss: 1.5824804306030273 - val_accuracy: 0.4334000051021576 - penalty: 1e-05\n",
            "layer sizes: [3072, 90, 78, 64, 101, 10]\n",
            "After pruning:\n",
            "loss: 1.546866536140442 - accuracy: 0.4476799964904785 - val_loss: 1.5826170444488525 - val_accuracy: 0.4334999918937683 - penalty: 1e-05\n",
            "layer sizes: [3072, 45, 29, 12, 52, 10]\n",
            "##########################################################\n",
            "Epoch 17/50\n",
            "Before growing:\n",
            "loss: 1.546866536140442 - accuracy: 0.4476799964904785 - val_loss: 1.5826170444488525 - val_accuracy: 0.4334999918937683 - penalty: 1e-05\n",
            "layer sizes: [3072, 45, 29, 12, 52, 10]\n",
            "After growing:\n",
            "loss: 1.546866536140442 - accuracy: 0.4476799964904785 - val_loss: 1.5826170444488525 - val_accuracy: 0.4334999918937683 - penalty: 1e-05\n",
            "layer sizes: [3072, 95, 79, 62, 102, 10]\n",
            "Before pruning:\n",
            "loss: 1.5230534076690674 - accuracy: 0.45576000213623047 - val_loss: 1.5663713216781616 - val_accuracy: 0.4381999969482422 - penalty: 1e-05\n",
            "layer sizes: [3072, 95, 79, 62, 102, 10]\n",
            "After pruning:\n",
            "loss: 1.5226233005523682 - accuracy: 0.4560199975967407 - val_loss: 1.5659899711608887 - val_accuracy: 0.4390000104904175 - penalty: 1e-05\n",
            "layer sizes: [3072, 38, 28, 12, 48, 10]\n",
            "##########################################################\n",
            "Epoch 18/50\n",
            "Before growing:\n",
            "loss: 1.5226233005523682 - accuracy: 0.4560199975967407 - val_loss: 1.5659899711608887 - val_accuracy: 0.4390000104904175 - penalty: 1e-05\n",
            "layer sizes: [3072, 38, 28, 12, 48, 10]\n",
            "After growing:\n",
            "loss: 1.5226233005523682 - accuracy: 0.4560199975967407 - val_loss: 1.5659898519515991 - val_accuracy: 0.4390000104904175 - penalty: 1e-05\n",
            "layer sizes: [3072, 88, 78, 62, 98, 10]\n",
            "Before pruning:\n",
            "loss: 1.5146815776824951 - accuracy: 0.4582599997520447 - val_loss: 1.5641071796417236 - val_accuracy: 0.44110000133514404 - penalty: 1e-05\n",
            "layer sizes: [3072, 88, 78, 62, 98, 10]\n",
            "After pruning:\n",
            "loss: 1.514621615409851 - accuracy: 0.45844000577926636 - val_loss: 1.564042329788208 - val_accuracy: 0.4406999945640564 - penalty: 1e-05\n",
            "layer sizes: [3072, 43, 34, 12, 43, 10]\n",
            "##########################################################\n",
            "Epoch 19/50\n",
            "Before growing:\n",
            "loss: 1.514621615409851 - accuracy: 0.45844000577926636 - val_loss: 1.564042329788208 - val_accuracy: 0.4406999945640564 - penalty: 1e-05\n",
            "layer sizes: [3072, 43, 34, 12, 43, 10]\n",
            "After growing:\n",
            "loss: 1.514621615409851 - accuracy: 0.45844000577926636 - val_loss: 1.564042329788208 - val_accuracy: 0.4406999945640564 - penalty: 1e-05\n",
            "layer sizes: [3072, 93, 84, 62, 93, 10]\n",
            "Before pruning:\n",
            "loss: 1.5013014078140259 - accuracy: 0.4640600085258484 - val_loss: 1.5546541213989258 - val_accuracy: 0.44600000977516174 - penalty: 1e-05\n",
            "layer sizes: [3072, 93, 84, 62, 93, 10]\n",
            "After pruning:\n",
            "loss: 1.500988245010376 - accuracy: 0.4643799960613251 - val_loss: 1.554347276687622 - val_accuracy: 0.44609999656677246 - penalty: 1e-05\n",
            "layer sizes: [3072, 33, 32, 12, 43, 10]\n",
            "##########################################################\n",
            "Epoch 20/50\n",
            "Before growing:\n",
            "loss: 1.500988245010376 - accuracy: 0.4643799960613251 - val_loss: 1.554347276687622 - val_accuracy: 0.44609999656677246 - penalty: 1e-05\n",
            "layer sizes: [3072, 33, 32, 12, 43, 10]\n",
            "After growing:\n",
            "loss: 1.5009881258010864 - accuracy: 0.4643799960613251 - val_loss: 1.554347276687622 - val_accuracy: 0.44609999656677246 - penalty: 1e-05\n",
            "layer sizes: [3072, 83, 82, 62, 93, 10]\n",
            "Before pruning:\n",
            "loss: 1.4905756711959839 - accuracy: 0.4663800001144409 - val_loss: 1.5536754131317139 - val_accuracy: 0.44359999895095825 - penalty: 1e-05\n",
            "layer sizes: [3072, 83, 82, 62, 93, 10]\n",
            "After pruning:\n",
            "loss: 1.490293025970459 - accuracy: 0.4664199948310852 - val_loss: 1.5534402132034302 - val_accuracy: 0.4442000091075897 - penalty: 1e-05\n",
            "layer sizes: [3072, 57, 31, 12, 65, 10]\n",
            "##########################################################\n",
            "Epoch 21/50\n",
            "Before growing:\n",
            "loss: 1.490293025970459 - accuracy: 0.4664199948310852 - val_loss: 1.5534402132034302 - val_accuracy: 0.4442000091075897 - penalty: 1e-05\n",
            "layer sizes: [3072, 57, 31, 12, 65, 10]\n",
            "After growing:\n",
            "loss: 1.490293025970459 - accuracy: 0.4664199948310852 - val_loss: 1.5534402132034302 - val_accuracy: 0.4442000091075897 - penalty: 1e-05\n",
            "layer sizes: [3072, 107, 81, 62, 115, 10]\n",
            "Before pruning:\n",
            "loss: 1.4797459840774536 - accuracy: 0.47218000888824463 - val_loss: 1.5460437536239624 - val_accuracy: 0.44780001044273376 - penalty: 1e-05\n",
            "layer sizes: [3072, 107, 81, 62, 115, 10]\n",
            "After pruning:\n",
            "loss: 1.4807277917861938 - accuracy: 0.4716799855232239 - val_loss: 1.5468471050262451 - val_accuracy: 0.44690001010894775 - penalty: 1e-05\n",
            "layer sizes: [3072, 30, 30, 12, 47, 10]\n",
            "##########################################################\n",
            "Epoch 22/50\n",
            "Before growing:\n",
            "loss: 1.4807277917861938 - accuracy: 0.4716799855232239 - val_loss: 1.5468471050262451 - val_accuracy: 0.44690001010894775 - penalty: 1e-05\n",
            "layer sizes: [3072, 30, 30, 12, 47, 10]\n",
            "After growing:\n",
            "loss: 1.4807279109954834 - accuracy: 0.4716799855232239 - val_loss: 1.5468471050262451 - val_accuracy: 0.44690001010894775 - penalty: 1e-05\n",
            "layer sizes: [3072, 80, 80, 62, 97, 10]\n",
            "Before pruning:\n",
            "loss: 1.4747068881988525 - accuracy: 0.4749000072479248 - val_loss: 1.5468600988388062 - val_accuracy: 0.45080000162124634 - penalty: 1e-05\n",
            "layer sizes: [3072, 80, 80, 62, 97, 10]\n",
            "After pruning:\n",
            "loss: 1.4751282930374146 - accuracy: 0.47477999329566956 - val_loss: 1.5475765466690063 - val_accuracy: 0.4512999951839447 - penalty: 1e-05\n",
            "layer sizes: [3072, 33, 30, 12, 48, 10]\n",
            "##########################################################\n",
            "Epoch 23/50\n",
            "Before growing:\n",
            "loss: 1.4751282930374146 - accuracy: 0.47477999329566956 - val_loss: 1.5475765466690063 - val_accuracy: 0.4512999951839447 - penalty: 1e-05\n",
            "layer sizes: [3072, 33, 30, 12, 48, 10]\n",
            "After growing:\n",
            "loss: 1.4751282930374146 - accuracy: 0.47477999329566956 - val_loss: 1.547576665878296 - val_accuracy: 0.4512999951839447 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 83, 80, 62, 98, 10]\n",
            "Before pruning:\n",
            "loss: 1.4349408149719238 - accuracy: 0.4882600009441376 - val_loss: 1.509688138961792 - val_accuracy: 0.4634000062942505 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 83, 80, 62, 98, 10]\n",
            "After pruning:\n",
            "loss: 1.4349403381347656 - accuracy: 0.4882600009441376 - val_loss: 1.5096867084503174 - val_accuracy: 0.4634000062942505 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 83, 80, 57, 74, 10]\n",
            "##########################################################\n",
            "Epoch 24/50\n",
            "Before growing:\n",
            "loss: 1.4349403381347656 - accuracy: 0.4882600009441376 - val_loss: 1.5096867084503174 - val_accuracy: 0.4634000062942505 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 83, 80, 57, 74, 10]\n",
            "After growing:\n",
            "loss: 1.4349403381347656 - accuracy: 0.4882600009441376 - val_loss: 1.5096867084503174 - val_accuracy: 0.4634000062942505 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 133, 130, 107, 124, 10]\n",
            "Before pruning:\n",
            "loss: 1.3959015607833862 - accuracy: 0.5062199831008911 - val_loss: 1.480178952217102 - val_accuracy: 0.47440001368522644 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 133, 130, 107, 124, 10]\n",
            "After pruning:\n",
            "loss: 1.3958929777145386 - accuracy: 0.5062800049781799 - val_loss: 1.4801687002182007 - val_accuracy: 0.47429999709129333 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 133, 115, 84, 88, 10]\n",
            "##########################################################\n",
            "Epoch 25/50\n",
            "Before growing:\n",
            "loss: 1.3958929777145386 - accuracy: 0.5062800049781799 - val_loss: 1.4801687002182007 - val_accuracy: 0.47429999709129333 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 133, 115, 84, 88, 10]\n",
            "After growing:\n",
            "loss: 1.3958930969238281 - accuracy: 0.5062800049781799 - val_loss: 1.4801687002182007 - val_accuracy: 0.47429999709129333 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 183, 165, 134, 138, 10]\n",
            "Before pruning:\n",
            "loss: 1.3580067157745361 - accuracy: 0.5175600051879883 - val_loss: 1.4512299299240112 - val_accuracy: 0.48190000653266907 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 183, 165, 134, 138, 10]\n",
            "After pruning:\n",
            "loss: 1.3579909801483154 - accuracy: 0.5174999833106995 - val_loss: 1.4512126445770264 - val_accuracy: 0.48179998993873596 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 180, 155, 108, 98, 10]\n",
            "##########################################################\n",
            "Epoch 26/50\n",
            "Before growing:\n",
            "loss: 1.3579909801483154 - accuracy: 0.5174999833106995 - val_loss: 1.4512126445770264 - val_accuracy: 0.48179998993873596 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 180, 155, 108, 98, 10]\n",
            "After growing:\n",
            "loss: 1.3579909801483154 - accuracy: 0.5174999833106995 - val_loss: 1.4512125253677368 - val_accuracy: 0.48179998993873596 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 230, 205, 158, 148, 10]\n",
            "Before pruning:\n",
            "loss: 1.3317155838012695 - accuracy: 0.5283799767494202 - val_loss: 1.4406826496124268 - val_accuracy: 0.48829999566078186 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 230, 205, 158, 148, 10]\n",
            "After pruning:\n",
            "loss: 1.3317437171936035 - accuracy: 0.5285199880599976 - val_loss: 1.4407209157943726 - val_accuracy: 0.4884999990463257 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 222, 178, 88, 75, 10]\n",
            "##########################################################\n",
            "Epoch 27/50\n",
            "Before growing:\n",
            "loss: 1.3317437171936035 - accuracy: 0.5285199880599976 - val_loss: 1.4407209157943726 - val_accuracy: 0.4884999990463257 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 222, 178, 88, 75, 10]\n",
            "After growing:\n",
            "loss: 1.3317437171936035 - accuracy: 0.5285199880599976 - val_loss: 1.4407209157943726 - val_accuracy: 0.4884999990463257 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 272, 228, 138, 125, 10]\n",
            "Before pruning:\n",
            "loss: 1.3097078800201416 - accuracy: 0.534500002861023 - val_loss: 1.427473783493042 - val_accuracy: 0.4921000003814697 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 272, 228, 138, 125, 10]\n",
            "After pruning:\n",
            "loss: 1.3096956014633179 - accuracy: 0.5346800088882446 - val_loss: 1.4273957014083862 - val_accuracy: 0.49219998717308044 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 236, 173, 98, 73, 10]\n",
            "##########################################################\n",
            "Epoch 28/50\n",
            "Before growing:\n",
            "loss: 1.3096956014633179 - accuracy: 0.5346800088882446 - val_loss: 1.4273957014083862 - val_accuracy: 0.49219998717308044 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 236, 173, 98, 73, 10]\n",
            "After growing:\n",
            "loss: 1.3096956014633179 - accuracy: 0.5346800088882446 - val_loss: 1.4273957014083862 - val_accuracy: 0.49219998717308044 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 286, 223, 148, 123, 10]\n",
            "Before pruning:\n",
            "loss: 1.289367914199829 - accuracy: 0.5420799851417542 - val_loss: 1.420088529586792 - val_accuracy: 0.49959999322891235 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 286, 223, 148, 123, 10]\n",
            "After pruning:\n",
            "loss: 1.2895053625106812 - accuracy: 0.5420200228691101 - val_loss: 1.4200977087020874 - val_accuracy: 0.4997999966144562 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 243, 200, 97, 77, 10]\n",
            "##########################################################\n",
            "Epoch 29/50\n",
            "Before growing:\n",
            "loss: 1.2895053625106812 - accuracy: 0.5420200228691101 - val_loss: 1.4200977087020874 - val_accuracy: 0.4997999966144562 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 243, 200, 97, 77, 10]\n",
            "After growing:\n",
            "loss: 1.2895054817199707 - accuracy: 0.5420200228691101 - val_loss: 1.4200977087020874 - val_accuracy: 0.4997999966144562 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 293, 250, 147, 127, 10]\n",
            "Before pruning:\n",
            "loss: 1.2665081024169922 - accuracy: 0.5515000224113464 - val_loss: 1.4087936878204346 - val_accuracy: 0.4977000057697296 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 293, 250, 147, 127, 10]\n",
            "After pruning:\n",
            "loss: 1.2665753364562988 - accuracy: 0.5515199899673462 - val_loss: 1.4088596105575562 - val_accuracy: 0.49790000915527344 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 241, 210, 105, 108, 10]\n",
            "##########################################################\n",
            "Epoch 30/50\n",
            "Before growing:\n",
            "loss: 1.2665753364562988 - accuracy: 0.5515199899673462 - val_loss: 1.4088596105575562 - val_accuracy: 0.49790000915527344 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 241, 210, 105, 108, 10]\n",
            "After growing:\n",
            "loss: 1.2665753364562988 - accuracy: 0.5515199899673462 - val_loss: 1.4088597297668457 - val_accuracy: 0.49790000915527344 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 291, 260, 155, 158, 10]\n",
            "Before pruning:\n",
            "loss: 1.258278489112854 - accuracy: 0.5540400147438049 - val_loss: 1.4098691940307617 - val_accuracy: 0.5026000142097473 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 291, 260, 155, 158, 10]\n",
            "After pruning:\n",
            "loss: 1.2582627534866333 - accuracy: 0.553879976272583 - val_loss: 1.409778356552124 - val_accuracy: 0.5024999976158142 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 255, 207, 99, 67, 10]\n",
            "##########################################################\n",
            "Epoch 31/50\n",
            "Before growing:\n",
            "loss: 1.2582627534866333 - accuracy: 0.553879976272583 - val_loss: 1.409778356552124 - val_accuracy: 0.5024999976158142 - penalty: 1.0000000000000002e-06\n",
            "layer sizes: [3072, 255, 207, 99, 67, 10]\n",
            "After growing:\n",
            "loss: 1.2582628726959229 - accuracy: 0.553879976272583 - val_loss: 1.409778356552124 - val_accuracy: 0.5024999976158142 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 306, 257, 149, 117, 10]\n",
            "Before pruning:\n",
            "loss: 1.2499921321868896 - accuracy: 0.5590800046920776 - val_loss: 1.4143530130386353 - val_accuracy: 0.5002999901771545 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 306, 257, 149, 117, 10]\n",
            "After pruning:\n",
            "loss: 1.2499921321868896 - accuracy: 0.5590800046920776 - val_loss: 1.4143530130386353 - val_accuracy: 0.5002999901771545 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 306, 257, 149, 117, 10]\n",
            "##########################################################\n",
            "Epoch 32/50\n",
            "Before growing:\n",
            "loss: 1.2499921321868896 - accuracy: 0.5590800046920776 - val_loss: 1.4143530130386353 - val_accuracy: 0.5002999901771545 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 306, 257, 149, 117, 10]\n",
            "After growing:\n",
            "loss: 1.2499921321868896 - accuracy: 0.5590800046920776 - val_loss: 1.4143530130386353 - val_accuracy: 0.5002999901771545 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 367, 308, 199, 167, 10]\n",
            "Before pruning:\n",
            "loss: 1.2217375040054321 - accuracy: 0.56632000207901 - val_loss: 1.402287244796753 - val_accuracy: 0.5054000020027161 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 367, 308, 199, 167, 10]\n",
            "After pruning:\n",
            "loss: 1.221737265586853 - accuracy: 0.56632000207901 - val_loss: 1.4022868871688843 - val_accuracy: 0.5054000020027161 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 367, 308, 199, 159, 10]\n",
            "##########################################################\n",
            "Epoch 33/50\n",
            "Before growing:\n",
            "loss: 1.221737265586853 - accuracy: 0.56632000207901 - val_loss: 1.4022868871688843 - val_accuracy: 0.5054000020027161 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 367, 308, 199, 159, 10]\n",
            "After growing:\n",
            "loss: 1.221737265586853 - accuracy: 0.56632000207901 - val_loss: 1.4022867679595947 - val_accuracy: 0.5054000020027161 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 440, 369, 249, 209, 10]\n",
            "Before pruning:\n",
            "loss: 1.2089563608169556 - accuracy: 0.5735599994659424 - val_loss: 1.3980793952941895 - val_accuracy: 0.5091999769210815 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 440, 369, 249, 209, 10]\n",
            "After pruning:\n",
            "loss: 1.2089561223983765 - accuracy: 0.5735599994659424 - val_loss: 1.3980792760849 - val_accuracy: 0.5091999769210815 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 440, 369, 249, 200, 10]\n",
            "##########################################################\n",
            "Epoch 34/50\n",
            "Before growing:\n",
            "loss: 1.2089561223983765 - accuracy: 0.5735599994659424 - val_loss: 1.3980792760849 - val_accuracy: 0.5091999769210815 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 440, 369, 249, 200, 10]\n",
            "After growing:\n",
            "loss: 1.2089561223983765 - accuracy: 0.5735599994659424 - val_loss: 1.3980791568756104 - val_accuracy: 0.5091999769210815 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 528, 442, 299, 250, 10]\n",
            "Before pruning:\n",
            "loss: 1.1975187063217163 - accuracy: 0.5762400031089783 - val_loss: 1.398771047592163 - val_accuracy: 0.5094000101089478 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 528, 442, 299, 250, 10]\n",
            "After pruning:\n",
            "loss: 1.1975301504135132 - accuracy: 0.5762199759483337 - val_loss: 1.3987796306610107 - val_accuracy: 0.5094000101089478 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 526, 442, 299, 199, 10]\n",
            "##########################################################\n",
            "Epoch 35/50\n",
            "Before growing:\n",
            "loss: 1.1975301504135132 - accuracy: 0.5762199759483337 - val_loss: 1.3987796306610107 - val_accuracy: 0.5094000101089478 - penalty: 1.0000000000000002e-07\n",
            "layer sizes: [3072, 526, 442, 299, 199, 10]\n",
            "After growing:\n",
            "loss: 1.1975301504135132 - accuracy: 0.5762199759483337 - val_loss: 1.3987796306610107 - val_accuracy: 0.5094000101089478 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 631, 530, 358, 249, 10]\n",
            "Before pruning:\n",
            "loss: 1.1732268333435059 - accuracy: 0.5859799981117249 - val_loss: 1.3816866874694824 - val_accuracy: 0.517300009727478 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 631, 530, 358, 249, 10]\n",
            "After pruning:\n",
            "loss: 1.1732268333435059 - accuracy: 0.5859799981117249 - val_loss: 1.3816866874694824 - val_accuracy: 0.517300009727478 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 631, 530, 358, 249, 10]\n",
            "##########################################################\n",
            "Epoch 36/50\n",
            "Before growing:\n",
            "loss: 1.1732268333435059 - accuracy: 0.5859799981117249 - val_loss: 1.3816866874694824 - val_accuracy: 0.517300009727478 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 631, 530, 358, 249, 10]\n",
            "After growing:\n",
            "loss: 1.1732268333435059 - accuracy: 0.5859799981117249 - val_loss: 1.3816866874694824 - val_accuracy: 0.517300009727478 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 757, 636, 429, 299, 10]\n",
            "Before pruning:\n",
            "loss: 1.1441746950149536 - accuracy: 0.5954399704933167 - val_loss: 1.3667200803756714 - val_accuracy: 0.5209000110626221 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 757, 636, 429, 299, 10]\n",
            "After pruning:\n",
            "loss: 1.1441746950149536 - accuracy: 0.5954399704933167 - val_loss: 1.3667200803756714 - val_accuracy: 0.5209000110626221 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 757, 636, 429, 299, 10]\n",
            "##########################################################\n",
            "Epoch 37/50\n",
            "Before growing:\n",
            "loss: 1.1441746950149536 - accuracy: 0.5954399704933167 - val_loss: 1.3667200803756714 - val_accuracy: 0.5209000110626221 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 757, 636, 429, 299, 10]\n",
            "After growing:\n",
            "loss: 1.1441746950149536 - accuracy: 0.5954399704933167 - val_loss: 1.3667200803756714 - val_accuracy: 0.5209000110626221 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 908, 763, 514, 358, 10]\n",
            "Before pruning:\n",
            "loss: 1.139864444732666 - accuracy: 0.5959799885749817 - val_loss: 1.3734679222106934 - val_accuracy: 0.5264999866485596 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 908, 763, 514, 358, 10]\n",
            "After pruning:\n",
            "loss: 1.139864444732666 - accuracy: 0.5959799885749817 - val_loss: 1.3734679222106934 - val_accuracy: 0.5264999866485596 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 908, 763, 514, 358, 10]\n",
            "##########################################################\n",
            "Epoch 38/50\n",
            "Before growing:\n",
            "loss: 1.139864444732666 - accuracy: 0.5959799885749817 - val_loss: 1.3734679222106934 - val_accuracy: 0.5264999866485596 - penalty: 1.0000000000000004e-08\n",
            "layer sizes: [3072, 908, 763, 514, 358, 10]\n",
            "After growing:\n",
            "loss: 1.139864444732666 - accuracy: 0.5959799885749817 - val_loss: 1.3734679222106934 - val_accuracy: 0.5264999866485596 - penalty: 1.0000000000000005e-09\n",
            "layer sizes: [3072, 1089, 915, 616, 429, 10]\n",
            "Before pruning:\n",
            "loss: 1.1308801174163818 - accuracy: 0.5980799794197083 - val_loss: 1.3821003437042236 - val_accuracy: 0.5169000029563904 - penalty: 1.0000000000000005e-09\n",
            "layer sizes: [3072, 1089, 915, 616, 429, 10]\n",
            "After pruning:\n",
            "loss: 1.1308801174163818 - accuracy: 0.5980799794197083 - val_loss: 1.3821003437042236 - val_accuracy: 0.5169000029563904 - penalty: 1.0000000000000005e-09\n",
            "layer sizes: [3072, 1089, 915, 616, 429, 10]\n",
            "##########################################################\n",
            "Epoch 39/50\n",
            "Before growing:\n",
            "loss: 1.1308801174163818 - accuracy: 0.5980799794197083 - val_loss: 1.3821003437042236 - val_accuracy: 0.5169000029563904 - penalty: 1.0000000000000005e-09\n",
            "layer sizes: [3072, 1089, 915, 616, 429, 10]\n",
            "After growing:\n",
            "loss: 1.1308799982070923 - accuracy: 0.5980799794197083 - val_loss: 1.3821003437042236 - val_accuracy: 0.5169000029563904 - penalty: 1.0000000000000005e-09\n",
            "layer sizes: [3072, 1306, 1098, 739, 514, 10]\n",
            "Before pruning:\n",
            "loss: 1.1096429824829102 - accuracy: 0.6060400009155273 - val_loss: 1.372436285018921 - val_accuracy: 0.5259000062942505 - penalty: 1.0000000000000005e-09\n",
            "layer sizes: [3072, 1306, 1098, 739, 514, 10]\n",
            "After pruning:\n",
            "loss: 1.1096429824829102 - accuracy: 0.6060400009155273 - val_loss: 1.372436285018921 - val_accuracy: 0.5259000062942505 - penalty: 1.0000000000000005e-09\n",
            "layer sizes: [3072, 1306, 1098, 739, 514, 10]\n",
            "##########################################################\n",
            "Epoch 40/50\n",
            "Before growing:\n",
            "loss: 1.1096429824829102 - accuracy: 0.6060400009155273 - val_loss: 1.372436285018921 - val_accuracy: 0.5259000062942505 - penalty: 1.0000000000000005e-09\n",
            "layer sizes: [3072, 1306, 1098, 739, 514, 10]\n",
            "After growing:\n",
            "loss: 1.1096429824829102 - accuracy: 0.6060400009155273 - val_loss: 1.372436285018921 - val_accuracy: 0.5259000062942505 - penalty: 1.0000000000000005e-09\n",
            "layer sizes: [3072, 1567, 1317, 886, 616, 10]\n",
            "Before pruning:\n",
            "loss: 1.0777684450149536 - accuracy: 0.610040009021759 - val_loss: 1.349364161491394 - val_accuracy: 0.5254999995231628 - penalty: 1.0000000000000005e-09\n",
            "layer sizes: [3072, 1567, 1317, 886, 616, 10]\n",
            "After pruning:\n",
            "loss: 1.0777684450149536 - accuracy: 0.610040009021759 - val_loss: 1.349364161491394 - val_accuracy: 0.5254999995231628 - penalty: 1.0000000000000005e-09\n",
            "layer sizes: [3072, 1567, 1317, 886, 616, 10]\n",
            "##########################################################\n",
            "Epoch 41/50\n",
            "Before growing:\n",
            "loss: 1.0777684450149536 - accuracy: 0.610040009021759 - val_loss: 1.349364161491394 - val_accuracy: 0.5254999995231628 - penalty: 1.0000000000000005e-09\n",
            "layer sizes: [3072, 1567, 1317, 886, 616, 10]\n",
            "After growing:\n",
            "loss: 1.0777684450149536 - accuracy: 0.610040009021759 - val_loss: 1.3493640422821045 - val_accuracy: 0.5254999995231628 - penalty: 1.0000000000000005e-09\n",
            "layer sizes: [3072, 1880, 1580, 1063, 739, 10]\n",
            "Before pruning:\n",
            "loss: 1.0937949419021606 - accuracy: 0.6132400035858154 - val_loss: 1.399574637413025 - val_accuracy: 0.5235999822616577 - penalty: 1.0000000000000005e-09\n",
            "layer sizes: [3072, 1880, 1580, 1063, 739, 10]\n",
            "After pruning:\n",
            "loss: 1.0937949419021606 - accuracy: 0.6132400035858154 - val_loss: 1.399574637413025 - val_accuracy: 0.5235999822616577 - penalty: 1.0000000000000005e-09\n",
            "layer sizes: [3072, 1880, 1580, 1063, 739, 10]\n",
            "##########################################################\n",
            "Epoch 42/50\n",
            "Before growing:\n",
            "loss: 1.0937949419021606 - accuracy: 0.6132400035858154 - val_loss: 1.399574637413025 - val_accuracy: 0.5235999822616577 - penalty: 1.0000000000000005e-09\n",
            "layer sizes: [3072, 1880, 1580, 1063, 739, 10]\n",
            "After growing:\n",
            "loss: 1.0937949419021606 - accuracy: 0.6132400035858154 - val_loss: 1.3995747566223145 - val_accuracy: 0.5235999822616577 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 2256, 1896, 1275, 886, 10]\n",
            "Before pruning:\n",
            "loss: 1.1086931228637695 - accuracy: 0.6081399917602539 - val_loss: 1.431315302848816 - val_accuracy: 0.5241000056266785 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 2256, 1896, 1275, 886, 10]\n",
            "After pruning:\n",
            "loss: 1.1086931228637695 - accuracy: 0.6081399917602539 - val_loss: 1.431315302848816 - val_accuracy: 0.5241000056266785 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 2256, 1896, 1275, 886, 10]\n",
            "##########################################################\n",
            "Epoch 43/50\n",
            "Before growing:\n",
            "loss: 1.1086931228637695 - accuracy: 0.6081399917602539 - val_loss: 1.431315302848816 - val_accuracy: 0.5241000056266785 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 2256, 1896, 1275, 886, 10]\n",
            "After growing:\n",
            "loss: 1.10869300365448 - accuracy: 0.6081399917602539 - val_loss: 1.431315302848816 - val_accuracy: 0.5241000056266785 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 2707, 2275, 1530, 1063, 10]\n",
            "Before pruning:\n",
            "loss: 1.0340038537979126 - accuracy: 0.6299600005149841 - val_loss: 1.3525187969207764 - val_accuracy: 0.5354999899864197 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 2707, 2275, 1530, 1063, 10]\n",
            "After pruning:\n",
            "loss: 1.0340038537979126 - accuracy: 0.6299600005149841 - val_loss: 1.3525187969207764 - val_accuracy: 0.5354999899864197 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 2707, 2275, 1530, 1063, 10]\n",
            "##########################################################\n",
            "Epoch 44/50\n",
            "Before growing:\n",
            "loss: 1.0340038537979126 - accuracy: 0.6299600005149841 - val_loss: 1.3525187969207764 - val_accuracy: 0.5354999899864197 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 2707, 2275, 1530, 1063, 10]\n",
            "After growing:\n",
            "loss: 1.0340038537979126 - accuracy: 0.6299600005149841 - val_loss: 1.3525185585021973 - val_accuracy: 0.5354999899864197 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 3248, 2730, 1836, 1275, 10]\n",
            "Before pruning:\n",
            "loss: 1.0874229669570923 - accuracy: 0.611519992351532 - val_loss: 1.3770283460617065 - val_accuracy: 0.5254999995231628 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 3248, 2730, 1836, 1275, 10]\n",
            "After pruning:\n",
            "loss: 1.0874229669570923 - accuracy: 0.611519992351532 - val_loss: 1.3770283460617065 - val_accuracy: 0.5254999995231628 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 3248, 2730, 1836, 1275, 10]\n",
            "##########################################################\n",
            "Epoch 45/50\n",
            "Before growing:\n",
            "loss: 1.0874229669570923 - accuracy: 0.611519992351532 - val_loss: 1.3770283460617065 - val_accuracy: 0.5254999995231628 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 3248, 2730, 1836, 1275, 10]\n",
            "After growing:\n",
            "loss: 1.0874228477478027 - accuracy: 0.611519992351532 - val_loss: 1.3770281076431274 - val_accuracy: 0.5254999995231628 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 3897, 3276, 2203, 1530, 10]\n",
            "Before pruning:\n",
            "loss: 1.0345796346664429 - accuracy: 0.6231600046157837 - val_loss: 1.3914750814437866 - val_accuracy: 0.5182999968528748 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 3897, 3276, 2203, 1530, 10]\n",
            "After pruning:\n",
            "loss: 1.0345796346664429 - accuracy: 0.6231600046157837 - val_loss: 1.3914750814437866 - val_accuracy: 0.5182999968528748 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 3897, 3276, 2203, 1530, 10]\n",
            "##########################################################\n",
            "Epoch 46/50\n",
            "Before growing:\n",
            "loss: 1.0345796346664429 - accuracy: 0.6231600046157837 - val_loss: 1.3914750814437866 - val_accuracy: 0.5182999968528748 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 3897, 3276, 2203, 1530, 10]\n",
            "After growing:\n",
            "loss: 1.0345795154571533 - accuracy: 0.6231600046157837 - val_loss: 1.3914748430252075 - val_accuracy: 0.5182999968528748 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 4676, 3931, 2643, 1836, 10]\n",
            "Before pruning:\n",
            "loss: 1.053978443145752 - accuracy: 0.6288599967956543 - val_loss: 1.3523423671722412 - val_accuracy: 0.5295000076293945 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 4676, 3931, 2643, 1836, 10]\n",
            "After pruning:\n",
            "loss: 1.053978443145752 - accuracy: 0.6288599967956543 - val_loss: 1.3523423671722412 - val_accuracy: 0.5295000076293945 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 4676, 3931, 2643, 1836, 10]\n",
            "##########################################################\n",
            "Epoch 47/50\n",
            "Before growing:\n",
            "loss: 1.053978443145752 - accuracy: 0.6288599967956543 - val_loss: 1.3523423671722412 - val_accuracy: 0.5295000076293945 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 4676, 3931, 2643, 1836, 10]\n",
            "After growing:\n",
            "loss: 1.0539788007736206 - accuracy: 0.6288599967956543 - val_loss: 1.3523426055908203 - val_accuracy: 0.5295000076293945 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 5611, 4717, 3171, 2203, 10]\n",
            "Before pruning:\n",
            "loss: 1.297102451324463 - accuracy: 0.5451200008392334 - val_loss: 1.4886653423309326 - val_accuracy: 0.4934000074863434 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 5611, 4717, 3171, 2203, 10]\n",
            "After pruning:\n",
            "loss: 1.297102451324463 - accuracy: 0.5451200008392334 - val_loss: 1.4886653423309326 - val_accuracy: 0.4934000074863434 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 5611, 4717, 3171, 2203, 10]\n",
            "##########################################################\n",
            "Epoch 48/50\n",
            "Before growing:\n",
            "loss: 1.297102451324463 - accuracy: 0.5451200008392334 - val_loss: 1.4886653423309326 - val_accuracy: 0.4934000074863434 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 5611, 4717, 3171, 2203, 10]\n",
            "After growing:\n",
            "loss: 1.2971022129058838 - accuracy: 0.5451200008392334 - val_loss: 1.4886648654937744 - val_accuracy: 0.4934000074863434 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 6733, 5660, 3805, 2643, 10]\n",
            "Before pruning:\n",
            "loss: 1.1188875436782837 - accuracy: 0.5988799929618835 - val_loss: 1.4333966970443726 - val_accuracy: 0.510200023651123 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 6733, 5660, 3805, 2643, 10]\n",
            "After pruning:\n",
            "loss: 1.1188875436782837 - accuracy: 0.5988799929618835 - val_loss: 1.4333966970443726 - val_accuracy: 0.510200023651123 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 6733, 5660, 3805, 2643, 10]\n",
            "##########################################################\n",
            "Epoch 49/50\n",
            "Before growing:\n",
            "loss: 1.1188875436782837 - accuracy: 0.5988799929618835 - val_loss: 1.4333966970443726 - val_accuracy: 0.510200023651123 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 6733, 5660, 3805, 2643, 10]\n",
            "After growing:\n",
            "loss: 1.1188876628875732 - accuracy: 0.5988799929618835 - val_loss: 1.4333966970443726 - val_accuracy: 0.510200023651123 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 8079, 6792, 4566, 3171, 10]\n",
            "Before pruning:\n",
            "loss: 1.2127140760421753 - accuracy: 0.5672600269317627 - val_loss: 1.4324830770492554 - val_accuracy: 0.5016000270843506 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 8079, 6792, 4566, 3171, 10]\n",
            "After pruning:\n",
            "loss: 1.2127140760421753 - accuracy: 0.5672600269317627 - val_loss: 1.4324830770492554 - val_accuracy: 0.5016000270843506 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 8079, 6792, 4566, 3171, 10]\n",
            "##########################################################\n",
            "Epoch 50/50\n",
            "Before growing:\n",
            "loss: 1.2127140760421753 - accuracy: 0.5672600269317627 - val_loss: 1.4324830770492554 - val_accuracy: 0.5016000270843506 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 8079, 6792, 4566, 3171, 10]\n",
            "After growing:\n",
            "loss: 1.21271550655365 - accuracy: 0.5672600269317627 - val_loss: 1.4324841499328613 - val_accuracy: 0.5016000270843506 - penalty: 1.0000000000000006e-10\n",
            "layer sizes: [3072, 9694, 8150, 5479, 3805, 10]\n",
            "Before pruning:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPE4AGtXg3Nw"
      },
      "source": [
        "## Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ue6f5dEe7rG"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(3072, activation='selu', kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dense(1108, activation='selu', kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dense(1108, activation='selu', kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dense(1108, activation='selu', kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dense(1108, activation='selu', kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax', kernel_initializer='lecun_normal'),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ5w_e-65EnL"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjZ7lqpF5E2Z",
        "outputId": "6e98202f-9132-4816-e927-df22db439ef9"
      },
      "source": [
        "%%time\n",
        "\n",
        "model.fit(X_train_norm, y_train, epochs=15, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.9114 - accuracy: 0.3848 - val_loss: 1.4940 - val_accuracy: 0.4722\n",
            "Epoch 2/15\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4642 - accuracy: 0.4813 - val_loss: 1.4827 - val_accuracy: 0.4778\n",
            "Epoch 3/15\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.3553 - accuracy: 0.5187 - val_loss: 1.4176 - val_accuracy: 0.5004\n",
            "Epoch 4/15\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.2516 - accuracy: 0.5545 - val_loss: 1.3573 - val_accuracy: 0.5251\n",
            "Epoch 5/15\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.1249 - accuracy: 0.5983 - val_loss: 1.4309 - val_accuracy: 0.5205\n",
            "Epoch 6/15\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.0061 - accuracy: 0.6386 - val_loss: 1.4089 - val_accuracy: 0.5283\n",
            "Epoch 7/15\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.8637 - accuracy: 0.6877 - val_loss: 1.4936 - val_accuracy: 0.5290\n",
            "Epoch 8/15\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.7196 - accuracy: 0.7405 - val_loss: 1.6128 - val_accuracy: 0.5371\n",
            "Epoch 9/15\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5846 - accuracy: 0.7886 - val_loss: 1.7695 - val_accuracy: 0.5353\n",
            "Epoch 10/15\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4794 - accuracy: 0.8278 - val_loss: 1.8793 - val_accuracy: 0.5341\n",
            "Epoch 11/15\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3997 - accuracy: 0.8576 - val_loss: 2.0999 - val_accuracy: 0.5383\n",
            "Epoch 12/15\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3412 - accuracy: 0.8796 - val_loss: 2.2986 - val_accuracy: 0.5344\n",
            "Epoch 13/15\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3044 - accuracy: 0.8930 - val_loss: 2.4497 - val_accuracy: 0.5350\n",
            "Epoch 14/15\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2714 - accuracy: 0.9063 - val_loss: 2.5763 - val_accuracy: 0.5188\n",
            "Epoch 15/15\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2504 - accuracy: 0.9139 - val_loss: 2.7446 - val_accuracy: 0.5358\n",
            "CPU times: user 1min 39s, sys: 20.3 s, total: 1min 59s\n",
            "Wall time: 1min 39s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa3766b62d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLkoFgNf5Q4s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}