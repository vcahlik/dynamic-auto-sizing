{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "tf_multi_layer_ssnet_inverse.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_deAUKlniFk",
        "outputId": "be625b4c-7f4d-47b1-afa4-c2302557720d"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Aug 20 19:55:06 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    40W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKwUwV_NneIo"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOoXBq05neIt"
      },
      "source": [
        "dtype = 'float32'\n",
        "tf.keras.backend.set_floatx(dtype)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BrJPdkBneIv"
      },
      "source": [
        "cifar10 = tf.keras.datasets.cifar10\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "X_train = X_train.astype(dtype) / 255.0\n",
        "y_train = y_train.astype(dtype)\n",
        "X_test = X_test.astype(dtype)  / 255.0\n",
        "y_test = y_test.astype(dtype)\n",
        "\n",
        "X_train = np.reshape(X_train, (-1, 3072))\n",
        "X_test = np.reshape(X_test, (-1, 3072))\n",
        "\n",
        "X = np.concatenate((X_train, X_test), axis=0)\n",
        "y = np.concatenate((y_train, y_test), axis=0)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5uTvu5kxF-b"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_norm = scaler.transform(X)\n",
        "X_train_norm = scaler.transform(X_train)\n",
        "X_test_norm = scaler.transform(X_test)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtK-2JsoAfT9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "automobile_indices = np.where(y == 1)[0]\n",
        "dog_indices = np.where(y == 5)[0]\n",
        "\n",
        "X_norm_automobiles = X_norm[automobile_indices]\n",
        "X_norm_dogs = X_norm[dog_indices]\n",
        "\n",
        "y_automobiles = y[automobile_indices]\n",
        "y_dogs = y[dog_indices]\n",
        "\n",
        "X_norm_automobiles_dogs = np.concatenate((X_norm_automobiles, X_norm_dogs), axis=0)\n",
        "y_automobiles_dogs = np.concatenate((y_automobiles, y_dogs), axis=0)\n",
        "\n",
        "X_norm_automobiles_dogs_train, X_norm_automobiles_dogs_test, y_automobiles_dogs_train, y_automobiles_dogs_test = train_test_split(X_norm_automobiles_dogs, y_automobiles_dogs, test_size=0.3, random_state=42)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTZq4KMpneIv"
      },
      "source": [
        "class SSRegularizer(tf.keras.regularizers.Regularizer):\n",
        "    def __init__(self, regularization_penalty, regularization_method):\n",
        "        self.regularization_penalty = regularization_penalty\n",
        "        self.regularization_method = regularization_method\n",
        "\n",
        "    def __call__(self, x):\n",
        "        if self.regularization_method == 'weighted_l1':\n",
        "            return self.weighted_l1(x)\n",
        "        elif self.regularization_method == 'group_sparsity':\n",
        "            return self.group_sparsity(x)\n",
        "        else:\n",
        "            raise NotImplementedError(f\"Unknown regularization method {self.regularization_method}\")\n",
        "    \n",
        "    def weighted_l1(self, x):\n",
        "        # I.e. for a parameter matrix of 4 input and 10 output neurons:\n",
        "        #\n",
        "        # [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]\n",
        "        #\n",
        "        # The scaling vector could be [0., 1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
        "        # and the resulting weighted values could be\n",
        "        #\n",
        "        # [[0., 1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
        "        #  [0., 1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
        "        #  [0., 1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
        "        #  [0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]]\n",
        "        #\n",
        "        # Therefore every additional output neuron is regularized more.\n",
        "\n",
        "        scaling_vector = tf.cumsum(tf.constant(self.regularization_penalty, shape=(x.shape[-1],), dtype=dtype), axis=0)\n",
        "        weighted_values = scaling_vector * tf.abs(x)\n",
        "        return tf.reduce_sum(weighted_values)\n",
        "    \n",
        "    def group_sparsity(self, x):\n",
        "        # I.e. for a parameter matrix of 3 input and 5 output neurons:\n",
        "        #\n",
        "        # [[1., 1., 1., 1., 1.],\n",
        "        #  [1., 2., 2., 1., 2.],\n",
        "        #  [2., 2., 3., 1., 3.]]\n",
        "        #\n",
        "        # The resulting vector of group norms is [2., 2., 3., 1., 3.], therefore for\n",
        "        # every output neuron, its incoming connections form a group.\n",
        "\n",
        "        group_norms = tf.norm(x, ord=2, axis=0)\n",
        "        # assert group_norms.shape[0] == x.shape[1]\n",
        "        return self.regularization_penalty * tf.reduce_sum(group_norms)\n",
        "\n",
        "    def get_config(self):\n",
        "        return {'regularization_penalty': float(self.regularization_penalty)}\n",
        "\n",
        "\n",
        "class SSLayer(tf.keras.Model):\n",
        "    def __init__(self, input_units, units, activation, regularization_penalty, regularization_method, kernel_initializer, bias_initializer, regularize=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_units = input_units\n",
        "        self.units = units\n",
        "        self.activation = activation\n",
        "        self.regularization_penalty = regularization_penalty\n",
        "        self.regularization_method = regularization_method\n",
        "        self.kernel_initializer = kernel_initializer\n",
        "        self.bias_initializer = bias_initializer\n",
        "        \n",
        "        self.A = tf.keras.activations.get(activation)\n",
        "        self.W_init = tf.keras.initializers.get(kernel_initializer)\n",
        "        self.b_init = tf.keras.initializers.get(bias_initializer)\n",
        "        self.regularizer = SSRegularizer(self.regularization_penalty, self.regularization_method)\n",
        "        \n",
        "        self.W = tf.Variable(\n",
        "            name='W',\n",
        "            initial_value=self.W_init(shape=(input_units, units), dtype=dtype),\n",
        "            trainable=True)\n",
        "        \n",
        "        self.b = tf.Variable(\n",
        "            name='b',\n",
        "            initial_value=self.b_init(shape=(units,), dtype=dtype),\n",
        "            trainable=True)\n",
        "        \n",
        "        if self.regularization_method is not None:\n",
        "            self.add_loss(lambda: self.regularizer(tf.concat([self.W, tf.reshape(self.b, (1, -1))], axis=0)))\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        return self.A(tf.matmul(inputs, self.W) + self.b)\n",
        "    \n",
        "    def copy_without_regularization(self):\n",
        "        copy = SSLayer(\n",
        "            self.input_units, \n",
        "            self.units, \n",
        "            self.activation, \n",
        "            regularization_penalty=self.regularization_penalty, \n",
        "            regularization_method=None, \n",
        "            kernel_initializer=self.kernel_initializer, \n",
        "            bias_initializer=self.bias_initializer\n",
        "        )\n",
        "        copy.W = self.W\n",
        "        copy.b = self.b\n",
        "        return copy\n",
        "\n",
        "\n",
        "class SSModel(tf.keras.Model):\n",
        "    def __init__(self, layer_sizes, activation=None, regularization_penalty=0.01, regularization_method='weighted_l1', kernel_initializer='glorot_uniform', bias_initializer='zeros'):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.sslayers = list()\n",
        "        for l in range(len(layer_sizes) - 1):\n",
        "            input_units = layer_sizes[l]\n",
        "            units = layer_sizes[l + 1]\n",
        "            if l < len(layer_sizes) - 2:\n",
        "                layer = SSLayer(input_units, units, activation, regularization_penalty, regularization_method, kernel_initializer, bias_initializer)\n",
        "            else:  # Last layer\n",
        "                layer = SSLayer(input_units, units, 'softmax', 0., regularization_method, kernel_initializer, bias_initializer)\n",
        "            self.sslayers.append(layer)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs\n",
        "        for layer in self.sslayers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "    \n",
        "    def get_layer_sizes(self):\n",
        "        layer_sizes = list()\n",
        "        for l in range(len(self.sslayers)):\n",
        "            layer = self.sslayers[l]\n",
        "            layer_sizes.append(layer.W.shape[0])\n",
        "            if l == len(self.sslayers) - 1:  # Last layer\n",
        "                layer_sizes.append(layer.W.shape[1])\n",
        "        return layer_sizes\n",
        "    \n",
        "    def get_hidden_layer_sizes(self):\n",
        "        return self.get_layer_sizes()[1:-1]\n",
        "    \n",
        "    def remove_regularization(self):\n",
        "        for l in range(len(self.sslayers)):\n",
        "            self.sslayers[l] = self.sslayers[l].copy_without_regularization()\n",
        "    \n",
        "    def get_regularization_penalty(self):\n",
        "        return self.sslayers[0].regularizer.regularization_penalty\n",
        "    \n",
        "    def set_regularization_penalty(self, regularization_penalty):\n",
        "        for l in range(0, len(self.sslayers) - 1):  # Every layer except of the last is regularized\n",
        "            self.sslayers[l].regularizer.regularization_penalty = regularization_penalty\n",
        "    \n",
        "    def prune(self, threshold=0.001):\n",
        "        for l in range(len(self.sslayers) - 1):\n",
        "            layer1 = self.sslayers[l]\n",
        "            layer2 = self.sslayers[l + 1]\n",
        "            \n",
        "            W1 = layer1.W.value()\n",
        "            b1 = layer1.b.value()\n",
        "            W2 = layer2.W.value()\n",
        "\n",
        "            weights_with_biases = tf.concat([W1, tf.reshape(b1, (1, -1))], axis=0)\n",
        "            neurons_are_active = tf.math.reduce_max(tf.abs(weights_with_biases), axis=0) >= threshold\n",
        "            active_neurons_indices = tf.reshape(tf.where(neurons_are_active), (-1,))\n",
        "            \n",
        "            new_W1 = tf.gather(W1, active_neurons_indices, axis=1)\n",
        "            new_b1 = tf.gather(b1, active_neurons_indices, axis=0)\n",
        "            new_W2 = tf.gather(W2, active_neurons_indices, axis=0)\n",
        "\n",
        "            layer1.W = tf.Variable(name='W', initial_value=new_W1, trainable=True)\n",
        "            layer1.b = tf.Variable(name='b', initial_value=new_b1, trainable=True)\n",
        "            layer2.W = tf.Variable(name='W', initial_value=new_W2, trainable=True)\n",
        "    \n",
        "    def grow(self, percentage, min_new_neurons=5, scaling_factor=0.001):   \n",
        "        for l in range(len(self.sslayers) - 1):\n",
        "            layer1 = self.sslayers[l]\n",
        "            layer2 = self.sslayers[l + 1]\n",
        "       \n",
        "            W1 = layer1.W.value()\n",
        "            b1 = layer1.b.value()\n",
        "            W2 = layer2.W.value()\n",
        "\n",
        "            n_new_neurons = max(min_new_neurons, int(W1.shape[1] * percentage))\n",
        "\n",
        "            W1_growth = layer1.W_init(shape=(W1.shape[0], W1.shape[1] + n_new_neurons), dtype=dtype)[:, -n_new_neurons:] * scaling_factor\n",
        "            b1_growth = layer1.b_init(shape=(n_new_neurons,), dtype=dtype)\n",
        "            W2_growth = layer2.W_init(shape=(W2.shape[0] + n_new_neurons, W2.shape[1]), dtype=dtype)[-n_new_neurons:, :] * scaling_factor  # TODO is it better to be multiplying here by scaling_factor? It does help with not increasing the max weights of existing neurons when new neurons are added.\n",
        "\n",
        "            new_W1 = tf.concat([W1, W1_growth], axis=1)\n",
        "            new_b1 = tf.concat([b1, b1_growth], axis=0)\n",
        "            new_W2 = tf.concat([W2, W2_growth], axis=0)\n",
        "\n",
        "            layer1.W = tf.Variable(name='W1', initial_value=new_W1, trainable=True)\n",
        "            layer1.b = tf.Variable(name='b1', initial_value=new_b1, trainable=True)\n",
        "            layer2.W = tf.Variable(name='W2', initial_value=new_W2, trainable=True)\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_param_string(weights, bias):\n",
        "        param_string = \"\"\n",
        "        weights_with_bias = tf.concat([weights, tf.reshape(bias, (1, -1))], axis=0)\n",
        "        max_parameters = tf.math.reduce_max(tf.abs(weights_with_bias), axis=0).numpy()\n",
        "        magnitudes = np.floor(np.log10(max_parameters))\n",
        "        for m in magnitudes:\n",
        "            if m > 0:\n",
        "                m = 0\n",
        "            param_string += str(int(-m))\n",
        "        return param_string\n",
        "    \n",
        "    def print_neurons(self):\n",
        "        for layer in self.sslayers[:-1]:\n",
        "            print(self.get_param_string(layer.W, layer.b))\n",
        "    \n",
        "    def evaluate(self, x, y, validation_data):\n",
        "        x_val = validation_data[0]\n",
        "        y_val = validation_data[1]\n",
        "\n",
        "        y_pred = self(x)\n",
        "        loss = float(tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(y, y_pred)))\n",
        "        accuracy = float(tf.reduce_mean(tf.keras.metrics.sparse_categorical_accuracy(y, y_pred)))\n",
        "        \n",
        "        y_val_pred = self(x_val)\n",
        "        val_loss = float(tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(y_val, y_val_pred)))\n",
        "        val_accuracy = float(tf.reduce_mean(tf.keras.metrics.sparse_categorical_accuracy(y_val, y_val_pred)))\n",
        "\n",
        "        return loss, accuracy, val_loss, val_accuracy\n",
        "    \n",
        "    def print_epoch_statistics(self, x, y, validation_data, print_neurons):\n",
        "        loss, accuracy, val_loss, val_accuracy = self.evaluate(x, y, validation_data)\n",
        "        print(f\"loss: {loss} - accuracy: {accuracy} - val_loss: {val_loss} - val_accuracy: {val_accuracy} - penalty: {model.get_regularization_penalty()}\")\n",
        "        hidden_layer_sizes = self.get_hidden_layer_sizes()\n",
        "        print(f\"hidden layer sizes: {hidden_layer_sizes}, total neurons: {sum(hidden_layer_sizes)}\")\n",
        "        if print_neurons:\n",
        "            self.print_neurons()\n",
        "    \n",
        "    def update_history(self, x, y, validation_data, history):\n",
        "        loss, accuracy, val_loss, val_accuracy = self.evaluate(x, y, validation_data)\n",
        "        history['loss'].append(loss)\n",
        "        history['accuracy'].append(accuracy)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_accuracy'].append(val_accuracy)\n",
        "\n",
        "    def fit(self, x, y, optimizer, epochs, self_scaling_epochs, batch_size, min_new_neurons, validation_data, pruning_threshold=0.001, \n",
        "            regularization_penalty_multiplier=1., stall_coefficient=1, growth_percentage=0.2, mini_epochs_per_epoch=1, verbose=True, print_neurons=False):\n",
        "        train_dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "        train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "        history = {\n",
        "            'loss': list(),\n",
        "            'accuracy': list(),\n",
        "            'val_loss': list(),\n",
        "            'val_accuracy': list(),\n",
        "        }\n",
        "\n",
        "        best_val_loss = np.inf\n",
        "        training_stalled = False\n",
        "        for epoch in range(epochs):\n",
        "            if verbose:\n",
        "                print(\"##########################################################\")\n",
        "                print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "            if epoch < self_scaling_epochs:\n",
        "                if verbose:\n",
        "                    print(\"Before growing:\")\n",
        "                    self.print_epoch_statistics(x, y, validation_data, print_neurons)\n",
        "\n",
        "                loss, accuracy, val_loss, val_accuracy = self.evaluate(x, y, validation_data)\n",
        "                if val_loss >= best_val_loss * stall_coefficient:\n",
        "                    if not training_stalled:\n",
        "                        penalty = self.get_regularization_penalty() * regularization_penalty_multiplier\n",
        "                        self.set_regularization_penalty(penalty)\n",
        "                        training_stalled = True\n",
        "                else:\n",
        "                    best_val_loss = val_loss\n",
        "                    training_stalled = False\n",
        "\n",
        "                self.grow(percentage=growth_percentage, min_new_neurons=min_new_neurons, scaling_factor=pruning_threshold)\n",
        "                if verbose:\n",
        "                    print(\"After growing:\")\n",
        "                    self.print_epoch_statistics(x, y, validation_data, print_neurons)\n",
        "            \n",
        "            if epoch == self_scaling_epochs:\n",
        "                self.remove_regularization()\n",
        "\n",
        "            for mini_epoch in range(mini_epochs_per_epoch):\n",
        "                for step, (x_batch, y_batch) in enumerate(train_dataset):\n",
        "                    with tf.GradientTape() as tape:\n",
        "                        y_pred = self(x_batch, training=True)\n",
        "                        loss_value = tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(y_batch, y_pred))\n",
        "                        loss_value += sum(self.losses)\n",
        "\n",
        "                    grads = tape.gradient(loss_value, self.trainable_variables)\n",
        "                    optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
        "            \n",
        "            if epoch < self_scaling_epochs:\n",
        "                if verbose:\n",
        "                    print(\"Before pruning:\")\n",
        "                    self.print_epoch_statistics(x, y, validation_data, print_neurons)\n",
        "                self.prune(threshold=pruning_threshold)\n",
        "                if verbose:\n",
        "                    print(\"After pruning:\")\n",
        "                    self.print_epoch_statistics(x, y, validation_data, print_neurons)\n",
        "            else:\n",
        "                if verbose:\n",
        "                    self.print_epoch_statistics(x, y, validation_data, print_neurons)\n",
        "            \n",
        "            self.update_history(x, y, validation_data, history)\n",
        "\n",
        "        return history"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1MrQXUTFwOe"
      },
      "source": [
        "# Concept drift"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JOH1vXCTk4b"
      },
      "source": [
        "## Dynamic auto-sizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByLRkOAPoGcc"
      },
      "source": [
        "epochs = 40\n",
        "self_scaling_epochs = 40\n",
        "batch_size = 32\n",
        "min_new_neurons = 100"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoJydQX7bsmq",
        "outputId": "0095522c-339f-4492-9664-e9b8ce0bec1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model = SSModel(layer_sizes=[3072, 300, 300, 300, 300, 10], activation='selu', regularization_penalty=0.000001, \n",
        "                regularization_method='weighted_l1', kernel_initializer='lecun_normal')\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_norm_automobiles_dogs_train, y_automobiles_dogs_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_norm_automobiles_dogs_test, y_automobiles_dogs_test))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##########################################################\n",
            "Epoch 1/40\n",
            "Before growing:\n",
            "loss: 2.7479329109191895 - accuracy: 0.0773809552192688 - val_loss: 2.7470860481262207 - val_accuracy: 0.07833333313465118 - penalty: 1e-06\n",
            "hidden layer sizes: [300, 300, 300, 300], total neurons: 1200\n",
            "After growing:\n",
            "loss: 2.7479329109191895 - accuracy: 0.0773809552192688 - val_loss: 2.747086524963379 - val_accuracy: 0.07833333313465118 - penalty: 1e-06\n",
            "hidden layer sizes: [400, 400, 400, 400], total neurons: 1600\n",
            "Before pruning:\n",
            "loss: 0.23003938794136047 - accuracy: 0.9123809337615967 - val_loss: 0.3350624144077301 - val_accuracy: 0.8761110901832581 - penalty: 1e-06\n",
            "hidden layer sizes: [400, 400, 400, 400], total neurons: 1600\n",
            "After pruning:\n",
            "loss: 0.23006406426429749 - accuracy: 0.9123809337615967 - val_loss: 0.3350726366043091 - val_accuracy: 0.8761110901832581 - penalty: 1e-06\n",
            "hidden layer sizes: [318, 302, 307, 379], total neurons: 1306\n",
            "##########################################################\n",
            "Epoch 2/40\n",
            "Before growing:\n",
            "loss: 0.23006406426429749 - accuracy: 0.9123809337615967 - val_loss: 0.3350726366043091 - val_accuracy: 0.8761110901832581 - penalty: 1e-06\n",
            "hidden layer sizes: [318, 302, 307, 379], total neurons: 1306\n",
            "After growing:\n",
            "loss: 0.23006409406661987 - accuracy: 0.9123809337615967 - val_loss: 0.3350726366043091 - val_accuracy: 0.8761110901832581 - penalty: 1e-06\n",
            "hidden layer sizes: [418, 402, 407, 479], total neurons: 1706\n",
            "Before pruning:\n",
            "loss: 0.16224229335784912 - accuracy: 0.9351190328598022 - val_loss: 0.26103872060775757 - val_accuracy: 0.8963888883590698 - penalty: 1e-06\n",
            "hidden layer sizes: [418, 402, 407, 479], total neurons: 1706\n",
            "After pruning:\n",
            "loss: 0.16227783262729645 - accuracy: 0.9348809719085693 - val_loss: 0.2610712945461273 - val_accuracy: 0.8963888883590698 - penalty: 1e-06\n",
            "hidden layer sizes: [300, 300, 301, 364], total neurons: 1265\n",
            "##########################################################\n",
            "Epoch 3/40\n",
            "Before growing:\n",
            "loss: 0.16227783262729645 - accuracy: 0.9348809719085693 - val_loss: 0.2610712945461273 - val_accuracy: 0.8963888883590698 - penalty: 1e-06\n",
            "hidden layer sizes: [300, 300, 301, 364], total neurons: 1265\n",
            "After growing:\n",
            "loss: 0.16227783262729645 - accuracy: 0.9348809719085693 - val_loss: 0.26107126474380493 - val_accuracy: 0.8963888883590698 - penalty: 1e-06\n",
            "hidden layer sizes: [400, 400, 401, 464], total neurons: 1665\n",
            "Before pruning:\n",
            "loss: 0.16581280529499054 - accuracy: 0.9340476393699646 - val_loss: 0.2768351435661316 - val_accuracy: 0.8961111307144165 - penalty: 1e-06\n",
            "hidden layer sizes: [400, 400, 401, 464], total neurons: 1665\n",
            "After pruning:\n",
            "loss: 0.16587474942207336 - accuracy: 0.934166669845581 - val_loss: 0.27689510583877563 - val_accuracy: 0.8961111307144165 - penalty: 1e-06\n",
            "hidden layer sizes: [300, 300, 312, 310], total neurons: 1222\n",
            "##########################################################\n",
            "Epoch 4/40\n",
            "Before growing:\n",
            "loss: 0.16587474942207336 - accuracy: 0.934166669845581 - val_loss: 0.27689510583877563 - val_accuracy: 0.8961111307144165 - penalty: 1e-06\n",
            "hidden layer sizes: [300, 300, 312, 310], total neurons: 1222\n",
            "After growing:\n",
            "loss: 0.16587474942207336 - accuracy: 0.934166669845581 - val_loss: 0.276895135641098 - val_accuracy: 0.8961111307144165 - penalty: 1e-06\n",
            "hidden layer sizes: [400, 400, 412, 410], total neurons: 1622\n",
            "Before pruning:\n",
            "loss: 0.1515287607908249 - accuracy: 0.9409523606300354 - val_loss: 0.2606343924999237 - val_accuracy: 0.8966666460037231 - penalty: 1e-06\n",
            "hidden layer sizes: [400, 400, 412, 410], total neurons: 1622\n",
            "After pruning:\n",
            "loss: 0.15154427289962769 - accuracy: 0.9409523606300354 - val_loss: 0.26066720485687256 - val_accuracy: 0.8966666460037231 - penalty: 1e-06\n",
            "hidden layer sizes: [300, 300, 301, 294], total neurons: 1195\n",
            "##########################################################\n",
            "Epoch 5/40\n",
            "Before growing:\n",
            "loss: 0.15154427289962769 - accuracy: 0.9409523606300354 - val_loss: 0.26066720485687256 - val_accuracy: 0.8966666460037231 - penalty: 1e-06\n",
            "hidden layer sizes: [300, 300, 301, 294], total neurons: 1195\n",
            "After growing:\n",
            "loss: 0.15154433250427246 - accuracy: 0.9409523606300354 - val_loss: 0.26066726446151733 - val_accuracy: 0.8966666460037231 - penalty: 1e-06\n",
            "hidden layer sizes: [400, 400, 401, 394], total neurons: 1595\n",
            "Before pruning:\n",
            "loss: 0.1372801512479782 - accuracy: 0.9510714411735535 - val_loss: 0.24569718539714813 - val_accuracy: 0.9016666412353516 - penalty: 1e-06\n",
            "hidden layer sizes: [400, 400, 401, 394], total neurons: 1595\n",
            "After pruning:\n",
            "loss: 0.13726554811000824 - accuracy: 0.9510714411735535 - val_loss: 0.24566762149333954 - val_accuracy: 0.9019444584846497 - penalty: 1e-06\n",
            "hidden layer sizes: [299, 300, 308, 283], total neurons: 1190\n",
            "##########################################################\n",
            "Epoch 6/40\n",
            "Before growing:\n",
            "loss: 0.13726554811000824 - accuracy: 0.9510714411735535 - val_loss: 0.24566762149333954 - val_accuracy: 0.9019444584846497 - penalty: 1e-06\n",
            "hidden layer sizes: [299, 300, 308, 283], total neurons: 1190\n",
            "After growing:\n",
            "loss: 0.13726553320884705 - accuracy: 0.9510714411735535 - val_loss: 0.24566765129566193 - val_accuracy: 0.9019444584846497 - penalty: 1e-06\n",
            "hidden layer sizes: [399, 400, 408, 383], total neurons: 1590\n",
            "Before pruning:\n",
            "loss: 0.13188046216964722 - accuracy: 0.9519047737121582 - val_loss: 0.23871734738349915 - val_accuracy: 0.9058333039283752 - penalty: 1e-06\n",
            "hidden layer sizes: [399, 400, 408, 383], total neurons: 1590\n",
            "After pruning:\n",
            "loss: 0.13192041218280792 - accuracy: 0.9520238041877747 - val_loss: 0.23876219987869263 - val_accuracy: 0.9058333039283752 - penalty: 1e-06\n",
            "hidden layer sizes: [297, 300, 300, 252], total neurons: 1149\n",
            "##########################################################\n",
            "Epoch 7/40\n",
            "Before growing:\n",
            "loss: 0.13192041218280792 - accuracy: 0.9520238041877747 - val_loss: 0.23876219987869263 - val_accuracy: 0.9058333039283752 - penalty: 1e-06\n",
            "hidden layer sizes: [297, 300, 300, 252], total neurons: 1149\n",
            "After growing:\n",
            "loss: 0.1319204419851303 - accuracy: 0.9520238041877747 - val_loss: 0.23876219987869263 - val_accuracy: 0.9058333039283752 - penalty: 1e-06\n",
            "hidden layer sizes: [397, 400, 400, 352], total neurons: 1549\n",
            "Before pruning:\n",
            "loss: 0.11164059489965439 - accuracy: 0.9598809480667114 - val_loss: 0.2334757298231125 - val_accuracy: 0.9125000238418579 - penalty: 1e-06\n",
            "hidden layer sizes: [397, 400, 400, 352], total neurons: 1549\n",
            "After pruning:\n",
            "loss: 0.11159026622772217 - accuracy: 0.9598809480667114 - val_loss: 0.23336978256702423 - val_accuracy: 0.9130555391311646 - penalty: 1e-06\n",
            "hidden layer sizes: [262, 300, 300, 224], total neurons: 1086\n",
            "##########################################################\n",
            "Epoch 8/40\n",
            "Before growing:\n",
            "loss: 0.11159026622772217 - accuracy: 0.9598809480667114 - val_loss: 0.23336978256702423 - val_accuracy: 0.9130555391311646 - penalty: 1e-06\n",
            "hidden layer sizes: [262, 300, 300, 224], total neurons: 1086\n",
            "After growing:\n",
            "loss: 0.11159027367830276 - accuracy: 0.9598809480667114 - val_loss: 0.23336981236934662 - val_accuracy: 0.9130555391311646 - penalty: 1e-06\n",
            "hidden layer sizes: [362, 400, 400, 324], total neurons: 1486\n",
            "Before pruning:\n",
            "loss: 0.09242690354585648 - accuracy: 0.9682142734527588 - val_loss: 0.23873373866081238 - val_accuracy: 0.9111111164093018 - penalty: 1e-06\n",
            "hidden layer sizes: [362, 400, 400, 324], total neurons: 1486\n",
            "After pruning:\n",
            "loss: 0.09244874864816666 - accuracy: 0.9683333039283752 - val_loss: 0.2387416958808899 - val_accuracy: 0.9111111164093018 - penalty: 1e-06\n",
            "hidden layer sizes: [232, 300, 299, 195], total neurons: 1026\n",
            "##########################################################\n",
            "Epoch 9/40\n",
            "Before growing:\n",
            "loss: 0.09244874864816666 - accuracy: 0.9683333039283752 - val_loss: 0.2387416958808899 - val_accuracy: 0.9111111164093018 - penalty: 1e-06\n",
            "hidden layer sizes: [232, 300, 299, 195], total neurons: 1026\n",
            "After growing:\n",
            "loss: 0.09244875609874725 - accuracy: 0.9683333039283752 - val_loss: 0.2387416958808899 - val_accuracy: 0.9111111164093018 - penalty: 1e-06\n",
            "hidden layer sizes: [332, 400, 399, 295], total neurons: 1426\n",
            "Before pruning:\n",
            "loss: 0.08319241553544998 - accuracy: 0.9710714221000671 - val_loss: 0.24065162241458893 - val_accuracy: 0.9133333563804626 - penalty: 1e-06\n",
            "hidden layer sizes: [332, 400, 399, 295], total neurons: 1426\n",
            "After pruning:\n",
            "loss: 0.0832521989941597 - accuracy: 0.9710714221000671 - val_loss: 0.24075575172901154 - val_accuracy: 0.9133333563804626 - penalty: 1e-06\n",
            "hidden layer sizes: [208, 300, 287, 177], total neurons: 972\n",
            "##########################################################\n",
            "Epoch 10/40\n",
            "Before growing:\n",
            "loss: 0.0832521989941597 - accuracy: 0.9710714221000671 - val_loss: 0.24075575172901154 - val_accuracy: 0.9133333563804626 - penalty: 1e-06\n",
            "hidden layer sizes: [208, 300, 287, 177], total neurons: 972\n",
            "After growing:\n",
            "loss: 0.0832521989941597 - accuracy: 0.9710714221000671 - val_loss: 0.24075573682785034 - val_accuracy: 0.9133333563804626 - penalty: 1e-06\n",
            "hidden layer sizes: [308, 400, 387, 277], total neurons: 1372\n",
            "Before pruning:\n",
            "loss: 0.08086379617452621 - accuracy: 0.9735714197158813 - val_loss: 0.26681631803512573 - val_accuracy: 0.9058333039283752 - penalty: 1e-06\n",
            "hidden layer sizes: [308, 400, 387, 277], total neurons: 1372\n",
            "After pruning:\n",
            "loss: 0.08085968345403671 - accuracy: 0.9735714197158813 - val_loss: 0.2667829692363739 - val_accuracy: 0.9058333039283752 - penalty: 1e-06\n",
            "hidden layer sizes: [186, 298, 248, 169], total neurons: 901\n",
            "##########################################################\n",
            "Epoch 11/40\n",
            "Before growing:\n",
            "loss: 0.08085968345403671 - accuracy: 0.9735714197158813 - val_loss: 0.2667829692363739 - val_accuracy: 0.9058333039283752 - penalty: 1e-06\n",
            "hidden layer sizes: [186, 298, 248, 169], total neurons: 901\n",
            "After growing:\n",
            "loss: 0.0808596983551979 - accuracy: 0.9735714197158813 - val_loss: 0.2667829990386963 - val_accuracy: 0.9058333039283752 - penalty: 1e-06\n",
            "hidden layer sizes: [286, 398, 348, 269], total neurons: 1301\n",
            "Before pruning:\n",
            "loss: 0.06410396099090576 - accuracy: 0.9795238375663757 - val_loss: 0.2468670755624771 - val_accuracy: 0.9133333563804626 - penalty: 1e-06\n",
            "hidden layer sizes: [286, 398, 348, 269], total neurons: 1301\n",
            "After pruning:\n",
            "loss: 0.06403237581253052 - accuracy: 0.9795238375663757 - val_loss: 0.24674567580223083 - val_accuracy: 0.9127777814865112 - penalty: 1e-06\n",
            "hidden layer sizes: [180, 292, 215, 154], total neurons: 841\n",
            "##########################################################\n",
            "Epoch 12/40\n",
            "Before growing:\n",
            "loss: 0.06403237581253052 - accuracy: 0.9795238375663757 - val_loss: 0.24674567580223083 - val_accuracy: 0.9127777814865112 - penalty: 1e-06\n",
            "hidden layer sizes: [180, 292, 215, 154], total neurons: 841\n",
            "After growing:\n",
            "loss: 0.06403238326311111 - accuracy: 0.9795238375663757 - val_loss: 0.24674570560455322 - val_accuracy: 0.9127777814865112 - penalty: 1e-06\n",
            "hidden layer sizes: [280, 392, 315, 254], total neurons: 1241\n",
            "Before pruning:\n",
            "loss: 0.07014858722686768 - accuracy: 0.9753571152687073 - val_loss: 0.281462162733078 - val_accuracy: 0.9061111211776733 - penalty: 1e-06\n",
            "hidden layer sizes: [280, 392, 315, 254], total neurons: 1241\n",
            "After pruning:\n",
            "loss: 0.07015635073184967 - accuracy: 0.9753571152687073 - val_loss: 0.28146639466285706 - val_accuracy: 0.9061111211776733 - penalty: 1e-06\n",
            "hidden layer sizes: [172, 291, 189, 146], total neurons: 798\n",
            "##########################################################\n",
            "Epoch 13/40\n",
            "Before growing:\n",
            "loss: 0.07015635073184967 - accuracy: 0.9753571152687073 - val_loss: 0.28146639466285706 - val_accuracy: 0.9061111211776733 - penalty: 1e-06\n",
            "hidden layer sizes: [172, 291, 189, 146], total neurons: 798\n",
            "After growing:\n",
            "loss: 0.07015635073184967 - accuracy: 0.9753571152687073 - val_loss: 0.28146639466285706 - val_accuracy: 0.9061111211776733 - penalty: 1e-06\n",
            "hidden layer sizes: [272, 391, 289, 246], total neurons: 1198\n",
            "Before pruning:\n",
            "loss: 0.05584428086876869 - accuracy: 0.9815475940704346 - val_loss: 0.2880551218986511 - val_accuracy: 0.9105555415153503 - penalty: 1e-06\n",
            "hidden layer sizes: [272, 391, 289, 246], total neurons: 1198\n",
            "After pruning:\n",
            "loss: 0.0558963343501091 - accuracy: 0.9813095331192017 - val_loss: 0.28815507888793945 - val_accuracy: 0.9105555415153503 - penalty: 1e-06\n",
            "hidden layer sizes: [184, 287, 178, 131], total neurons: 780\n",
            "##########################################################\n",
            "Epoch 14/40\n",
            "Before growing:\n",
            "loss: 0.0558963343501091 - accuracy: 0.9813095331192017 - val_loss: 0.28815507888793945 - val_accuracy: 0.9105555415153503 - penalty: 1e-06\n",
            "hidden layer sizes: [184, 287, 178, 131], total neurons: 780\n",
            "After growing:\n",
            "loss: 0.0558963380753994 - accuracy: 0.9813095331192017 - val_loss: 0.28815504908561707 - val_accuracy: 0.9105555415153503 - penalty: 1e-06\n",
            "hidden layer sizes: [284, 387, 278, 231], total neurons: 1180\n",
            "Before pruning:\n",
            "loss: 0.05263989418745041 - accuracy: 0.9829761981964111 - val_loss: 0.2776375114917755 - val_accuracy: 0.9155555367469788 - penalty: 1e-06\n",
            "hidden layer sizes: [284, 387, 278, 231], total neurons: 1180\n",
            "After pruning:\n",
            "loss: 0.052631452679634094 - accuracy: 0.9829761981964111 - val_loss: 0.2776004374027252 - val_accuracy: 0.9155555367469788 - penalty: 1e-06\n",
            "hidden layer sizes: [168, 282, 155, 125], total neurons: 730\n",
            "##########################################################\n",
            "Epoch 15/40\n",
            "Before growing:\n",
            "loss: 0.052631452679634094 - accuracy: 0.9829761981964111 - val_loss: 0.2776004374027252 - val_accuracy: 0.9155555367469788 - penalty: 1e-06\n",
            "hidden layer sizes: [168, 282, 155, 125], total neurons: 730\n",
            "After growing:\n",
            "loss: 0.0526314452290535 - accuracy: 0.9829761981964111 - val_loss: 0.27760040760040283 - val_accuracy: 0.9155555367469788 - penalty: 1e-06\n",
            "hidden layer sizes: [268, 382, 255, 225], total neurons: 1130\n",
            "Before pruning:\n",
            "loss: 0.04035406932234764 - accuracy: 0.9873809814453125 - val_loss: 0.290965735912323 - val_accuracy: 0.9152777791023254 - penalty: 1e-06\n",
            "hidden layer sizes: [268, 382, 255, 225], total neurons: 1130\n",
            "After pruning:\n",
            "loss: 0.04037197306752205 - accuracy: 0.9873809814453125 - val_loss: 0.29101765155792236 - val_accuracy: 0.9152777791023254 - penalty: 1e-06\n",
            "hidden layer sizes: [187, 275, 139, 145], total neurons: 746\n",
            "##########################################################\n",
            "Epoch 16/40\n",
            "Before growing:\n",
            "loss: 0.04037197306752205 - accuracy: 0.9873809814453125 - val_loss: 0.29101765155792236 - val_accuracy: 0.9152777791023254 - penalty: 1e-06\n",
            "hidden layer sizes: [187, 275, 139, 145], total neurons: 746\n",
            "After growing:\n",
            "loss: 0.04037197306752205 - accuracy: 0.9873809814453125 - val_loss: 0.2910176217556 - val_accuracy: 0.9152777791023254 - penalty: 1e-06\n",
            "hidden layer sizes: [287, 375, 239, 245], total neurons: 1146\n",
            "Before pruning:\n",
            "loss: 0.038092292845249176 - accuracy: 0.988095223903656 - val_loss: 0.28914791345596313 - val_accuracy: 0.9161111116409302 - penalty: 1e-06\n",
            "hidden layer sizes: [287, 375, 239, 245], total neurons: 1146\n",
            "After pruning:\n",
            "loss: 0.03808999061584473 - accuracy: 0.988095223903656 - val_loss: 0.2891513407230377 - val_accuracy: 0.9161111116409302 - penalty: 1e-06\n",
            "hidden layer sizes: [159, 271, 127, 121], total neurons: 678\n",
            "##########################################################\n",
            "Epoch 17/40\n",
            "Before growing:\n",
            "loss: 0.03808999061584473 - accuracy: 0.988095223903656 - val_loss: 0.2891513407230377 - val_accuracy: 0.9161111116409302 - penalty: 1e-06\n",
            "hidden layer sizes: [159, 271, 127, 121], total neurons: 678\n",
            "After growing:\n",
            "loss: 0.03808999061584473 - accuracy: 0.988095223903656 - val_loss: 0.2891513407230377 - val_accuracy: 0.9161111116409302 - penalty: 1e-06\n",
            "hidden layer sizes: [259, 371, 227, 221], total neurons: 1078\n",
            "Before pruning:\n",
            "loss: 0.03116607666015625 - accuracy: 0.9904761910438538 - val_loss: 0.28833067417144775 - val_accuracy: 0.918055534362793 - penalty: 1e-06\n",
            "hidden layer sizes: [259, 371, 227, 221], total neurons: 1078\n",
            "After pruning:\n",
            "loss: 0.0311949010938406 - accuracy: 0.9903571605682373 - val_loss: 0.28836414217948914 - val_accuracy: 0.9183333516120911 - penalty: 1e-06\n",
            "hidden layer sizes: [151, 270, 120, 123], total neurons: 664\n",
            "##########################################################\n",
            "Epoch 18/40\n",
            "Before growing:\n",
            "loss: 0.0311949010938406 - accuracy: 0.9903571605682373 - val_loss: 0.28836414217948914 - val_accuracy: 0.9183333516120911 - penalty: 1e-06\n",
            "hidden layer sizes: [151, 270, 120, 123], total neurons: 664\n",
            "After growing:\n",
            "loss: 0.031194904819130898 - accuracy: 0.9903571605682373 - val_loss: 0.28836411237716675 - val_accuracy: 0.9183333516120911 - penalty: 1e-06\n",
            "hidden layer sizes: [251, 370, 220, 223], total neurons: 1064\n",
            "Before pruning:\n",
            "loss: 0.03311369940638542 - accuracy: 0.9905952215194702 - val_loss: 0.2940188944339752 - val_accuracy: 0.9208333492279053 - penalty: 1e-06\n",
            "hidden layer sizes: [251, 370, 220, 223], total neurons: 1064\n",
            "After pruning:\n",
            "loss: 0.03310292586684227 - accuracy: 0.9905952215194702 - val_loss: 0.29403531551361084 - val_accuracy: 0.9208333492279053 - penalty: 1e-06\n",
            "hidden layer sizes: [155, 272, 103, 95], total neurons: 625\n",
            "##########################################################\n",
            "Epoch 19/40\n",
            "Before growing:\n",
            "loss: 0.03310292586684227 - accuracy: 0.9905952215194702 - val_loss: 0.29403531551361084 - val_accuracy: 0.9208333492279053 - penalty: 1e-06\n",
            "hidden layer sizes: [155, 272, 103, 95], total neurons: 625\n",
            "After growing:\n",
            "loss: 0.03310291841626167 - accuracy: 0.9905952215194702 - val_loss: 0.2940351366996765 - val_accuracy: 0.9208333492279053 - penalty: 1e-06\n",
            "hidden layer sizes: [255, 372, 203, 195], total neurons: 1025\n",
            "Before pruning:\n",
            "loss: 0.024394476786255836 - accuracy: 0.992976188659668 - val_loss: 0.3036887049674988 - val_accuracy: 0.9194444417953491 - penalty: 1e-06\n",
            "hidden layer sizes: [255, 372, 203, 195], total neurons: 1025\n",
            "After pruning:\n",
            "loss: 0.024430563673377037 - accuracy: 0.9927380681037903 - val_loss: 0.3036232590675354 - val_accuracy: 0.9191666841506958 - penalty: 1e-06\n",
            "hidden layer sizes: [153, 256, 101, 97], total neurons: 607\n",
            "##########################################################\n",
            "Epoch 20/40\n",
            "Before growing:\n",
            "loss: 0.024430563673377037 - accuracy: 0.9927380681037903 - val_loss: 0.3036232590675354 - val_accuracy: 0.9191666841506958 - penalty: 1e-06\n",
            "hidden layer sizes: [153, 256, 101, 97], total neurons: 607\n",
            "After growing:\n",
            "loss: 0.024430567398667336 - accuracy: 0.9927380681037903 - val_loss: 0.3036232590675354 - val_accuracy: 0.9191666841506958 - penalty: 1e-06\n",
            "hidden layer sizes: [253, 356, 201, 197], total neurons: 1007\n",
            "Before pruning:\n",
            "loss: 0.03773413971066475 - accuracy: 0.986547589302063 - val_loss: 0.3400239944458008 - val_accuracy: 0.9113888740539551 - penalty: 1e-06\n",
            "hidden layer sizes: [253, 356, 201, 197], total neurons: 1007\n",
            "After pruning:\n",
            "loss: 0.03775045648217201 - accuracy: 0.9864285588264465 - val_loss: 0.3401058316230774 - val_accuracy: 0.9113888740539551 - penalty: 1e-06\n",
            "hidden layer sizes: [149, 251, 91, 100], total neurons: 591\n",
            "##########################################################\n",
            "Epoch 21/40\n",
            "Before growing:\n",
            "loss: 0.03775045648217201 - accuracy: 0.9864285588264465 - val_loss: 0.3401058316230774 - val_accuracy: 0.9113888740539551 - penalty: 1e-06\n",
            "hidden layer sizes: [149, 251, 91, 100], total neurons: 591\n",
            "After growing:\n",
            "loss: 0.03775046393275261 - accuracy: 0.9864285588264465 - val_loss: 0.34010589122772217 - val_accuracy: 0.9113888740539551 - penalty: 1e-06\n",
            "hidden layer sizes: [249, 351, 191, 200], total neurons: 991\n",
            "Before pruning:\n",
            "loss: 0.02669849433004856 - accuracy: 0.9923809766769409 - val_loss: 0.2920295298099518 - val_accuracy: 0.9188888669013977 - penalty: 1e-06\n",
            "hidden layer sizes: [249, 351, 191, 200], total neurons: 991\n",
            "After pruning:\n",
            "loss: 0.026714038103818893 - accuracy: 0.9923809766769409 - val_loss: 0.29197958111763 - val_accuracy: 0.9188888669013977 - penalty: 1e-06\n",
            "hidden layer sizes: [155, 249, 85, 86], total neurons: 575\n",
            "##########################################################\n",
            "Epoch 22/40\n",
            "Before growing:\n",
            "loss: 0.026714038103818893 - accuracy: 0.9923809766769409 - val_loss: 0.29197958111763 - val_accuracy: 0.9188888669013977 - penalty: 1e-06\n",
            "hidden layer sizes: [155, 249, 85, 86], total neurons: 575\n",
            "After growing:\n",
            "loss: 0.026714038103818893 - accuracy: 0.9923809766769409 - val_loss: 0.2919795513153076 - val_accuracy: 0.9188888669013977 - penalty: 1e-06\n",
            "hidden layer sizes: [255, 349, 185, 186], total neurons: 975\n",
            "Before pruning:\n",
            "loss: 0.02179667167365551 - accuracy: 0.9940476417541504 - val_loss: 0.3138357102870941 - val_accuracy: 0.9202777743339539 - penalty: 1e-06\n",
            "hidden layer sizes: [255, 349, 185, 186], total neurons: 975\n",
            "After pruning:\n",
            "loss: 0.02183080092072487 - accuracy: 0.9940476417541504 - val_loss: 0.31360581517219543 - val_accuracy: 0.9205555319786072 - penalty: 1e-06\n",
            "hidden layer sizes: [118, 248, 98, 91], total neurons: 555\n",
            "##########################################################\n",
            "Epoch 23/40\n",
            "Before growing:\n",
            "loss: 0.02183080092072487 - accuracy: 0.9940476417541504 - val_loss: 0.31360581517219543 - val_accuracy: 0.9205555319786072 - penalty: 1e-06\n",
            "hidden layer sizes: [118, 248, 98, 91], total neurons: 555\n",
            "After growing:\n",
            "loss: 0.021830793470144272 - accuracy: 0.9940476417541504 - val_loss: 0.31360578536987305 - val_accuracy: 0.9205555319786072 - penalty: 1e-06\n",
            "hidden layer sizes: [218, 348, 198, 191], total neurons: 955\n",
            "Before pruning:\n",
            "loss: 0.021885104477405548 - accuracy: 0.993571400642395 - val_loss: 0.35466572642326355 - val_accuracy: 0.9138888716697693 - penalty: 1e-06\n",
            "hidden layer sizes: [218, 348, 198, 191], total neurons: 955\n",
            "After pruning:\n",
            "loss: 0.021829571574926376 - accuracy: 0.9936904907226562 - val_loss: 0.354594349861145 - val_accuracy: 0.9138888716697693 - penalty: 1e-06\n",
            "hidden layer sizes: [127, 231, 86, 87], total neurons: 531\n",
            "##########################################################\n",
            "Epoch 24/40\n",
            "Before growing:\n",
            "loss: 0.021829571574926376 - accuracy: 0.9936904907226562 - val_loss: 0.354594349861145 - val_accuracy: 0.9138888716697693 - penalty: 1e-06\n",
            "hidden layer sizes: [127, 231, 86, 87], total neurons: 531\n",
            "After growing:\n",
            "loss: 0.021829605102539062 - accuracy: 0.9936904907226562 - val_loss: 0.35459426045417786 - val_accuracy: 0.9138888716697693 - penalty: 1e-06\n",
            "hidden layer sizes: [227, 331, 186, 187], total neurons: 931\n",
            "Before pruning:\n",
            "loss: 0.021879494190216064 - accuracy: 0.9919047355651855 - val_loss: 0.3352314829826355 - val_accuracy: 0.9158333539962769 - penalty: 1e-06\n",
            "hidden layer sizes: [227, 331, 186, 187], total neurons: 931\n",
            "After pruning:\n",
            "loss: 0.021908609196543694 - accuracy: 0.9917857050895691 - val_loss: 0.33519110083580017 - val_accuracy: 0.9158333539962769 - penalty: 1e-06\n",
            "hidden layer sizes: [148, 221, 83, 80], total neurons: 532\n",
            "##########################################################\n",
            "Epoch 25/40\n",
            "Before growing:\n",
            "loss: 0.021908609196543694 - accuracy: 0.9917857050895691 - val_loss: 0.33519110083580017 - val_accuracy: 0.9158333539962769 - penalty: 1e-06\n",
            "hidden layer sizes: [148, 221, 83, 80], total neurons: 532\n",
            "After growing:\n",
            "loss: 0.021908607333898544 - accuracy: 0.9917857050895691 - val_loss: 0.33519113063812256 - val_accuracy: 0.9158333539962769 - penalty: 1e-06\n",
            "hidden layer sizes: [248, 321, 183, 180], total neurons: 932\n",
            "Before pruning:\n",
            "loss: 0.017865978181362152 - accuracy: 0.9946428537368774 - val_loss: 0.37841951847076416 - val_accuracy: 0.9138888716697693 - penalty: 1e-06\n",
            "hidden layer sizes: [248, 321, 183, 180], total neurons: 932\n",
            "After pruning:\n",
            "loss: 0.01787557080388069 - accuracy: 0.9946428537368774 - val_loss: 0.3785117268562317 - val_accuracy: 0.9138888716697693 - penalty: 1e-06\n",
            "hidden layer sizes: [160, 212, 89, 99], total neurons: 560\n",
            "##########################################################\n",
            "Epoch 26/40\n",
            "Before growing:\n",
            "loss: 0.01787557080388069 - accuracy: 0.9946428537368774 - val_loss: 0.3785117268562317 - val_accuracy: 0.9138888716697693 - penalty: 1e-06\n",
            "hidden layer sizes: [160, 212, 89, 99], total neurons: 560\n",
            "After growing:\n",
            "loss: 0.01787557266652584 - accuracy: 0.9946428537368774 - val_loss: 0.3785117268562317 - val_accuracy: 0.9138888716697693 - penalty: 1e-06\n",
            "hidden layer sizes: [260, 312, 189, 199], total neurons: 960\n",
            "Before pruning:\n",
            "loss: 0.08361741155385971 - accuracy: 0.9714285731315613 - val_loss: 0.4533095359802246 - val_accuracy: 0.8924999833106995 - penalty: 1e-06\n",
            "hidden layer sizes: [260, 312, 189, 199], total neurons: 960\n",
            "After pruning:\n",
            "loss: 0.08371038734912872 - accuracy: 0.9714285731315613 - val_loss: 0.45343485474586487 - val_accuracy: 0.8924999833106995 - penalty: 1e-06\n",
            "hidden layer sizes: [170, 236, 77, 82], total neurons: 565\n",
            "##########################################################\n",
            "Epoch 27/40\n",
            "Before growing:\n",
            "loss: 0.08371038734912872 - accuracy: 0.9714285731315613 - val_loss: 0.45343485474586487 - val_accuracy: 0.8924999833106995 - penalty: 1e-06\n",
            "hidden layer sizes: [170, 236, 77, 82], total neurons: 565\n",
            "After growing:\n",
            "loss: 0.08371041715145111 - accuracy: 0.9714285731315613 - val_loss: 0.45343485474586487 - val_accuracy: 0.8924999833106995 - penalty: 1e-06\n",
            "hidden layer sizes: [270, 336, 177, 182], total neurons: 965\n",
            "Before pruning:\n",
            "loss: 0.016984494403004646 - accuracy: 0.9954761862754822 - val_loss: 0.364671528339386 - val_accuracy: 0.9125000238418579 - penalty: 1e-06\n",
            "hidden layer sizes: [270, 336, 177, 182], total neurons: 965\n",
            "After pruning:\n",
            "loss: 0.017018886283040047 - accuracy: 0.9954761862754822 - val_loss: 0.36471518874168396 - val_accuracy: 0.9122222065925598 - penalty: 1e-06\n",
            "hidden layer sizes: [109, 211, 77, 87], total neurons: 484\n",
            "##########################################################\n",
            "Epoch 28/40\n",
            "Before growing:\n",
            "loss: 0.017018886283040047 - accuracy: 0.9954761862754822 - val_loss: 0.36471518874168396 - val_accuracy: 0.9122222065925598 - penalty: 1e-06\n",
            "hidden layer sizes: [109, 211, 77, 87], total neurons: 484\n",
            "After growing:\n",
            "loss: 0.01701885648071766 - accuracy: 0.9954761862754822 - val_loss: 0.3647153377532959 - val_accuracy: 0.9122222065925598 - penalty: 1e-06\n",
            "hidden layer sizes: [209, 311, 177, 187], total neurons: 884\n",
            "Before pruning:\n",
            "loss: 0.015636738389730453 - accuracy: 0.9955952167510986 - val_loss: 0.3747572600841522 - val_accuracy: 0.9177777767181396 - penalty: 1e-06\n",
            "hidden layer sizes: [209, 311, 177, 187], total neurons: 884\n",
            "After pruning:\n",
            "loss: 0.015601452440023422 - accuracy: 0.9955952167510986 - val_loss: 0.37486907839775085 - val_accuracy: 0.9175000190734863 - penalty: 1e-06\n",
            "hidden layer sizes: [113, 188, 70, 91], total neurons: 462\n",
            "##########################################################\n",
            "Epoch 29/40\n",
            "Before growing:\n",
            "loss: 0.015601452440023422 - accuracy: 0.9955952167510986 - val_loss: 0.37486907839775085 - val_accuracy: 0.9175000190734863 - penalty: 1e-06\n",
            "hidden layer sizes: [113, 188, 70, 91], total neurons: 462\n",
            "After growing:\n",
            "loss: 0.015601454302668571 - accuracy: 0.9955952167510986 - val_loss: 0.37486907839775085 - val_accuracy: 0.9175000190734863 - penalty: 1e-06\n",
            "hidden layer sizes: [213, 288, 170, 191], total neurons: 862\n",
            "Before pruning:\n",
            "loss: 0.023085124790668488 - accuracy: 0.9913095235824585 - val_loss: 0.3606010675430298 - val_accuracy: 0.9122222065925598 - penalty: 1e-06\n",
            "hidden layer sizes: [213, 288, 170, 191], total neurons: 862\n",
            "After pruning:\n",
            "loss: 0.02315978705883026 - accuracy: 0.9913095235824585 - val_loss: 0.36084043979644775 - val_accuracy: 0.9122222065925598 - penalty: 1e-06\n",
            "hidden layer sizes: [134, 192, 72, 71], total neurons: 469\n",
            "##########################################################\n",
            "Epoch 30/40\n",
            "Before growing:\n",
            "loss: 0.02315978705883026 - accuracy: 0.9913095235824585 - val_loss: 0.36084043979644775 - val_accuracy: 0.9122222065925598 - penalty: 1e-06\n",
            "hidden layer sizes: [134, 192, 72, 71], total neurons: 469\n",
            "After growing:\n",
            "loss: 0.023159777745604515 - accuracy: 0.9913095235824585 - val_loss: 0.36084043979644775 - val_accuracy: 0.9122222065925598 - penalty: 1e-06\n",
            "hidden layer sizes: [234, 292, 172, 171], total neurons: 869\n",
            "Before pruning:\n",
            "loss: 0.014395221136510372 - accuracy: 0.9958333373069763 - val_loss: 0.357686847448349 - val_accuracy: 0.914722204208374 - penalty: 1e-06\n",
            "hidden layer sizes: [234, 292, 172, 171], total neurons: 869\n",
            "After pruning:\n",
            "loss: 0.014366218820214272 - accuracy: 0.9958333373069763 - val_loss: 0.35731786489486694 - val_accuracy: 0.9144444465637207 - penalty: 1e-06\n",
            "hidden layer sizes: [128, 194, 83, 82], total neurons: 487\n",
            "##########################################################\n",
            "Epoch 31/40\n",
            "Before growing:\n",
            "loss: 0.014366218820214272 - accuracy: 0.9958333373069763 - val_loss: 0.35731786489486694 - val_accuracy: 0.9144444465637207 - penalty: 1e-06\n",
            "hidden layer sizes: [128, 194, 83, 82], total neurons: 487\n",
            "After growing:\n",
            "loss: 0.014366211369633675 - accuracy: 0.9958333373069763 - val_loss: 0.35731786489486694 - val_accuracy: 0.9144444465637207 - penalty: 1e-06\n",
            "hidden layer sizes: [228, 294, 183, 182], total neurons: 887\n",
            "Before pruning:\n",
            "loss: 0.025937628000974655 - accuracy: 0.9901190400123596 - val_loss: 0.3694920837879181 - val_accuracy: 0.9122222065925598 - penalty: 1e-06\n",
            "hidden layer sizes: [228, 294, 183, 182], total neurons: 887\n",
            "After pruning:\n",
            "loss: 0.025904912501573563 - accuracy: 0.9901190400123596 - val_loss: 0.36948055028915405 - val_accuracy: 0.9122222065925598 - penalty: 1e-06\n",
            "hidden layer sizes: [203, 215, 122, 101], total neurons: 641\n",
            "##########################################################\n",
            "Epoch 32/40\n",
            "Before growing:\n",
            "loss: 0.025904912501573563 - accuracy: 0.9901190400123596 - val_loss: 0.36948055028915405 - val_accuracy: 0.9122222065925598 - penalty: 1e-06\n",
            "hidden layer sizes: [203, 215, 122, 101], total neurons: 641\n",
            "After growing:\n",
            "loss: 0.02590489201247692 - accuracy: 0.9901190400123596 - val_loss: 0.36948052048683167 - val_accuracy: 0.9122222065925598 - penalty: 1e-06\n",
            "hidden layer sizes: [303, 315, 222, 201], total neurons: 1041\n",
            "Before pruning:\n",
            "loss: 0.018025703728199005 - accuracy: 0.9940476417541504 - val_loss: 0.42053693532943726 - val_accuracy: 0.9119444489479065 - penalty: 1e-06\n",
            "hidden layer sizes: [303, 315, 222, 201], total neurons: 1041\n",
            "After pruning:\n",
            "loss: 0.017799323424696922 - accuracy: 0.9942857027053833 - val_loss: 0.4196036756038666 - val_accuracy: 0.9113888740539551 - penalty: 1e-06\n",
            "hidden layer sizes: [141, 180, 71, 90], total neurons: 482\n",
            "##########################################################\n",
            "Epoch 33/40\n",
            "Before growing:\n",
            "loss: 0.017799323424696922 - accuracy: 0.9942857027053833 - val_loss: 0.4196036756038666 - val_accuracy: 0.9113888740539551 - penalty: 1e-06\n",
            "hidden layer sizes: [141, 180, 71, 90], total neurons: 482\n",
            "After growing:\n",
            "loss: 0.01779933087527752 - accuracy: 0.9942857027053833 - val_loss: 0.4196036159992218 - val_accuracy: 0.9113888740539551 - penalty: 1e-06\n",
            "hidden layer sizes: [241, 280, 171, 190], total neurons: 882\n",
            "Before pruning:\n",
            "loss: 0.017690099775791168 - accuracy: 0.993571400642395 - val_loss: 0.3891212046146393 - val_accuracy: 0.9083333611488342 - penalty: 1e-06\n",
            "hidden layer sizes: [241, 280, 171, 190], total neurons: 882\n",
            "After pruning:\n",
            "loss: 0.018034694716334343 - accuracy: 0.993571400642395 - val_loss: 0.3899381160736084 - val_accuracy: 0.9083333611488342 - penalty: 1e-06\n",
            "hidden layer sizes: [116, 221, 106, 87], total neurons: 530\n",
            "##########################################################\n",
            "Epoch 34/40\n",
            "Before growing:\n",
            "loss: 0.018034694716334343 - accuracy: 0.993571400642395 - val_loss: 0.3899381160736084 - val_accuracy: 0.9083333611488342 - penalty: 1e-06\n",
            "hidden layer sizes: [116, 221, 106, 87], total neurons: 530\n",
            "After growing:\n",
            "loss: 0.0180346816778183 - accuracy: 0.993571400642395 - val_loss: 0.3899381160736084 - val_accuracy: 0.9083333611488342 - penalty: 1e-06\n",
            "hidden layer sizes: [216, 321, 206, 187], total neurons: 930\n",
            "Before pruning:\n",
            "loss: 0.01645788736641407 - accuracy: 0.9946428537368774 - val_loss: 0.40228140354156494 - val_accuracy: 0.9094444513320923 - penalty: 1e-06\n",
            "hidden layer sizes: [216, 321, 206, 187], total neurons: 930\n",
            "After pruning:\n",
            "loss: 0.016532298177480698 - accuracy: 0.994523823261261 - val_loss: 0.40248382091522217 - val_accuracy: 0.9094444513320923 - penalty: 1e-06\n",
            "hidden layer sizes: [185, 209, 83, 83], total neurons: 560\n",
            "##########################################################\n",
            "Epoch 35/40\n",
            "Before growing:\n",
            "loss: 0.016532298177480698 - accuracy: 0.994523823261261 - val_loss: 0.40248382091522217 - val_accuracy: 0.9094444513320923 - penalty: 1e-06\n",
            "hidden layer sizes: [185, 209, 83, 83], total neurons: 560\n",
            "After growing:\n",
            "loss: 0.016532298177480698 - accuracy: 0.994523823261261 - val_loss: 0.4024837911128998 - val_accuracy: 0.9094444513320923 - penalty: 1e-06\n",
            "hidden layer sizes: [285, 309, 183, 183], total neurons: 960\n",
            "Before pruning:\n",
            "loss: 0.017749706283211708 - accuracy: 0.9936904907226562 - val_loss: 0.38128212094306946 - val_accuracy: 0.9100000262260437 - penalty: 1e-06\n",
            "hidden layer sizes: [285, 309, 183, 183], total neurons: 960\n",
            "After pruning:\n",
            "loss: 0.017798686400055885 - accuracy: 0.9936904907226562 - val_loss: 0.38137340545654297 - val_accuracy: 0.910277783870697 - penalty: 1e-06\n",
            "hidden layer sizes: [127, 184, 49, 91], total neurons: 451\n",
            "##########################################################\n",
            "Epoch 36/40\n",
            "Before growing:\n",
            "loss: 0.017798686400055885 - accuracy: 0.9936904907226562 - val_loss: 0.38137340545654297 - val_accuracy: 0.910277783870697 - penalty: 1e-06\n",
            "hidden layer sizes: [127, 184, 49, 91], total neurons: 451\n",
            "After growing:\n",
            "loss: 0.01779867708683014 - accuracy: 0.9936904907226562 - val_loss: 0.38137340545654297 - val_accuracy: 0.910277783870697 - penalty: 1e-06\n",
            "hidden layer sizes: [227, 284, 149, 191], total neurons: 851\n",
            "Before pruning:\n",
            "loss: 0.020262613892555237 - accuracy: 0.992976188659668 - val_loss: 0.37196406722068787 - val_accuracy: 0.9105555415153503 - penalty: 1e-06\n",
            "hidden layer sizes: [227, 284, 149, 191], total neurons: 851\n",
            "After pruning:\n",
            "loss: 0.02033868618309498 - accuracy: 0.992976188659668 - val_loss: 0.3721739947795868 - val_accuracy: 0.9105555415153503 - penalty: 1e-06\n",
            "hidden layer sizes: [162, 211, 46, 68], total neurons: 487\n",
            "##########################################################\n",
            "Epoch 37/40\n",
            "Before growing:\n",
            "loss: 0.02033868618309498 - accuracy: 0.992976188659668 - val_loss: 0.3721739947795868 - val_accuracy: 0.9105555415153503 - penalty: 1e-06\n",
            "hidden layer sizes: [162, 211, 46, 68], total neurons: 487\n",
            "After growing:\n",
            "loss: 0.020338688045740128 - accuracy: 0.992976188659668 - val_loss: 0.3721740245819092 - val_accuracy: 0.9105555415153503 - penalty: 1e-06\n",
            "hidden layer sizes: [262, 311, 146, 168], total neurons: 887\n",
            "Before pruning:\n",
            "loss: 0.011435259133577347 - accuracy: 0.996071457862854 - val_loss: 0.4047590494155884 - val_accuracy: 0.9119444489479065 - penalty: 1e-06\n",
            "hidden layer sizes: [262, 311, 146, 168], total neurons: 887\n",
            "After pruning:\n",
            "loss: 0.011450561694800854 - accuracy: 0.996071457862854 - val_loss: 0.4042786955833435 - val_accuracy: 0.9125000238418579 - penalty: 1e-06\n",
            "hidden layer sizes: [103, 209, 82, 77], total neurons: 471\n",
            "##########################################################\n",
            "Epoch 38/40\n",
            "Before growing:\n",
            "loss: 0.011450561694800854 - accuracy: 0.996071457862854 - val_loss: 0.4042786955833435 - val_accuracy: 0.9125000238418579 - penalty: 1e-06\n",
            "hidden layer sizes: [103, 209, 82, 77], total neurons: 471\n",
            "After growing:\n",
            "loss: 0.011450547724962234 - accuracy: 0.996071457862854 - val_loss: 0.4042787253856659 - val_accuracy: 0.9125000238418579 - penalty: 1e-06\n",
            "hidden layer sizes: [203, 309, 182, 177], total neurons: 871\n",
            "Before pruning:\n",
            "loss: 0.017377303913235664 - accuracy: 0.9940476417541504 - val_loss: 0.3915625214576721 - val_accuracy: 0.909166693687439 - penalty: 1e-06\n",
            "hidden layer sizes: [203, 309, 182, 177], total neurons: 871\n",
            "After pruning:\n",
            "loss: 0.017370888963341713 - accuracy: 0.9940476417541504 - val_loss: 0.39146071672439575 - val_accuracy: 0.9088888764381409 - penalty: 1e-06\n",
            "hidden layer sizes: [166, 280, 70, 70], total neurons: 586\n",
            "##########################################################\n",
            "Epoch 39/40\n",
            "Before growing:\n",
            "loss: 0.017370888963341713 - accuracy: 0.9940476417541504 - val_loss: 0.39146071672439575 - val_accuracy: 0.9088888764381409 - penalty: 1e-06\n",
            "hidden layer sizes: [166, 280, 70, 70], total neurons: 586\n",
            "After growing:\n",
            "loss: 0.01737089641392231 - accuracy: 0.9940476417541504 - val_loss: 0.39146071672439575 - val_accuracy: 0.9088888764381409 - penalty: 1e-06\n",
            "hidden layer sizes: [266, 380, 170, 170], total neurons: 986\n",
            "Before pruning:\n",
            "loss: 0.014367946423590183 - accuracy: 0.996071457862854 - val_loss: 0.4138217270374298 - val_accuracy: 0.9119444489479065 - penalty: 1e-06\n",
            "hidden layer sizes: [266, 380, 170, 170], total neurons: 986\n",
            "After pruning:\n",
            "loss: 0.014833066612482071 - accuracy: 0.9958333373069763 - val_loss: 0.4153132736682892 - val_accuracy: 0.9116666913032532 - penalty: 1e-06\n",
            "hidden layer sizes: [150, 254, 98, 71], total neurons: 573\n",
            "##########################################################\n",
            "Epoch 40/40\n",
            "Before growing:\n",
            "loss: 0.014833066612482071 - accuracy: 0.9958333373069763 - val_loss: 0.4153132736682892 - val_accuracy: 0.9116666913032532 - penalty: 1e-06\n",
            "hidden layer sizes: [150, 254, 98, 71], total neurons: 573\n",
            "After growing:\n",
            "loss: 0.014833081513643265 - accuracy: 0.9958333373069763 - val_loss: 0.41531306505203247 - val_accuracy: 0.9116666913032532 - penalty: 1e-06\n",
            "hidden layer sizes: [250, 354, 198, 171], total neurons: 973\n",
            "Before pruning:\n",
            "loss: 0.014598812907934189 - accuracy: 0.9954761862754822 - val_loss: 0.4114755392074585 - val_accuracy: 0.9138888716697693 - penalty: 1e-06\n",
            "hidden layer sizes: [250, 354, 198, 171], total neurons: 973\n",
            "After pruning:\n",
            "loss: 0.01459007989615202 - accuracy: 0.9955952167510986 - val_loss: 0.4113897979259491 - val_accuracy: 0.9138888716697693 - penalty: 1e-06\n",
            "hidden layer sizes: [232, 231, 66, 74], total neurons: 603\n",
            "CPU times: user 2min 35s, sys: 4.13 s, total: 2min 39s\n",
            "Wall time: 2min 39s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSqi6dsQNNcw",
        "outputId": "c096fade-8518-4789-ea18-68c3e1062c5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(603 + 573 + 586 + 471 + 487) / 5"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "544.0"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUCNgzWkFQbc",
        "outputId": "8865942b-5d47-41f1-a583-b2ad0f23cac5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "epochs = 5\n",
        "self_scaling_epochs = 5\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##########################################################\n",
            "Epoch 1/5\n",
            "Before growing:\n",
            "loss: 18.775209426879883 - accuracy: 0.19422000646591187 - val_loss: 18.74847412109375 - val_accuracy: 0.19419999420642853 - penalty: 1e-06\n",
            "hidden layer sizes: [232, 231, 66, 74], total neurons: 603\n",
            "After growing:\n",
            "loss: 18.775209426879883 - accuracy: 0.19422000646591187 - val_loss: 18.748472213745117 - val_accuracy: 0.19419999420642853 - penalty: 1e-06\n",
            "hidden layer sizes: [332, 331, 166, 174], total neurons: 1003\n",
            "Before pruning:\n",
            "loss: 1.5507994890213013 - accuracy: 0.4280799925327301 - val_loss: 1.5574026107788086 - val_accuracy: 0.42340001463890076 - penalty: 1e-06\n",
            "hidden layer sizes: [332, 331, 166, 174], total neurons: 1003\n",
            "After pruning:\n",
            "loss: 1.5505298376083374 - accuracy: 0.42805999517440796 - val_loss: 1.5571227073669434 - val_accuracy: 0.42399999499320984 - penalty: 1e-06\n",
            "hidden layer sizes: [102, 317, 166, 174], total neurons: 759\n",
            "##########################################################\n",
            "Epoch 2/5\n",
            "Before growing:\n",
            "loss: 1.5505298376083374 - accuracy: 0.42805999517440796 - val_loss: 1.5571227073669434 - val_accuracy: 0.42399999499320984 - penalty: 1e-06\n",
            "hidden layer sizes: [102, 317, 166, 174], total neurons: 759\n",
            "After growing:\n",
            "loss: 1.5505298376083374 - accuracy: 0.42805999517440796 - val_loss: 1.5571227073669434 - val_accuracy: 0.42399999499320984 - penalty: 1e-06\n",
            "hidden layer sizes: [202, 417, 266, 274], total neurons: 1159\n",
            "Before pruning:\n",
            "loss: 1.4292800426483154 - accuracy: 0.48212000727653503 - val_loss: 1.4638572931289673 - val_accuracy: 0.47380000352859497 - penalty: 1e-06\n",
            "hidden layer sizes: [202, 417, 266, 274], total neurons: 1159\n",
            "After pruning:\n",
            "loss: 1.428890347480774 - accuracy: 0.4823800027370453 - val_loss: 1.4634933471679688 - val_accuracy: 0.47369998693466187 - penalty: 1e-06\n",
            "hidden layer sizes: [129, 253, 169, 172], total neurons: 723\n",
            "##########################################################\n",
            "Epoch 3/5\n",
            "Before growing:\n",
            "loss: 1.428890347480774 - accuracy: 0.4823800027370453 - val_loss: 1.4634933471679688 - val_accuracy: 0.47369998693466187 - penalty: 1e-06\n",
            "hidden layer sizes: [129, 253, 169, 172], total neurons: 723\n",
            "After growing:\n",
            "loss: 1.4288899898529053 - accuracy: 0.4823800027370453 - val_loss: 1.4634932279586792 - val_accuracy: 0.47369998693466187 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 353, 269, 272], total neurons: 1123\n",
            "Before pruning:\n",
            "loss: 1.371253252029419 - accuracy: 0.5033599734306335 - val_loss: 1.4311336278915405 - val_accuracy: 0.48339998722076416 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 353, 269, 272], total neurons: 1123\n",
            "After pruning:\n",
            "loss: 1.3712053298950195 - accuracy: 0.503279983997345 - val_loss: 1.4311031103134155 - val_accuracy: 0.48339998722076416 - penalty: 1e-06\n",
            "hidden layer sizes: [143, 222, 220, 202], total neurons: 787\n",
            "##########################################################\n",
            "Epoch 4/5\n",
            "Before growing:\n",
            "loss: 1.3712053298950195 - accuracy: 0.503279983997345 - val_loss: 1.4311031103134155 - val_accuracy: 0.48339998722076416 - penalty: 1e-06\n",
            "hidden layer sizes: [143, 222, 220, 202], total neurons: 787\n",
            "After growing:\n",
            "loss: 1.3712053298950195 - accuracy: 0.503279983997345 - val_loss: 1.431102991104126 - val_accuracy: 0.48339998722076416 - penalty: 1e-06\n",
            "hidden layer sizes: [243, 322, 320, 302], total neurons: 1187\n",
            "Before pruning:\n",
            "loss: 1.321225643157959 - accuracy: 0.5201600193977356 - val_loss: 1.4023692607879639 - val_accuracy: 0.4968999922275543 - penalty: 1e-06\n",
            "hidden layer sizes: [243, 322, 320, 302], total neurons: 1187\n",
            "After pruning:\n",
            "loss: 1.321232795715332 - accuracy: 0.520039975643158 - val_loss: 1.4023185968399048 - val_accuracy: 0.4968000054359436 - penalty: 1e-06\n",
            "hidden layer sizes: [155, 210, 177, 203], total neurons: 745\n",
            "##########################################################\n",
            "Epoch 5/5\n",
            "Before growing:\n",
            "loss: 1.321232795715332 - accuracy: 0.520039975643158 - val_loss: 1.4023185968399048 - val_accuracy: 0.4968000054359436 - penalty: 1e-06\n",
            "hidden layer sizes: [155, 210, 177, 203], total neurons: 745\n",
            "After growing:\n",
            "loss: 1.321232795715332 - accuracy: 0.520039975643158 - val_loss: 1.4023185968399048 - val_accuracy: 0.4968000054359436 - penalty: 1e-06\n",
            "hidden layer sizes: [255, 310, 277, 303], total neurons: 1145\n",
            "Before pruning:\n",
            "loss: 1.281961441040039 - accuracy: 0.5402799844741821 - val_loss: 1.3823789358139038 - val_accuracy: 0.5051000118255615 - penalty: 1e-06\n",
            "hidden layer sizes: [255, 310, 277, 303], total neurons: 1145\n",
            "After pruning:\n",
            "loss: 1.2820333242416382 - accuracy: 0.5401600003242493 - val_loss: 1.3824816942214966 - val_accuracy: 0.5048999786376953 - penalty: 1e-06\n",
            "hidden layer sizes: [180, 206, 171, 150], total neurons: 707\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.42805999517440796,\n",
              "  0.4823800027370453,\n",
              "  0.503279983997345,\n",
              "  0.520039975643158,\n",
              "  0.5401600003242493],\n",
              " 'loss': [1.5505298376083374,\n",
              "  1.428890347480774,\n",
              "  1.3712053298950195,\n",
              "  1.321232795715332,\n",
              "  1.2820333242416382],\n",
              " 'val_accuracy': [0.42399999499320984,\n",
              "  0.47369998693466187,\n",
              "  0.48339998722076416,\n",
              "  0.4968000054359436,\n",
              "  0.5048999786376953],\n",
              " 'val_loss': [1.5571227073669434,\n",
              "  1.4634933471679688,\n",
              "  1.4311031103134155,\n",
              "  1.4023185968399048,\n",
              "  1.3824816942214966]}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laziXiqCMqwV",
        "outputId": "d45b6e45-33ef-486c-fd56-76e957443e45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##########################################################\n",
            "Epoch 1/5\n",
            "Before growing:\n",
            "loss: 1.2820333242416382 - accuracy: 0.5401600003242493 - val_loss: 1.3824816942214966 - val_accuracy: 0.5048999786376953 - penalty: 1e-06\n",
            "hidden layer sizes: [180, 206, 171, 150], total neurons: 707\n",
            "After growing:\n",
            "loss: 1.2820332050323486 - accuracy: 0.5401600003242493 - val_loss: 1.3824814558029175 - val_accuracy: 0.5048999786376953 - penalty: 1e-06\n",
            "hidden layer sizes: [280, 306, 271, 250], total neurons: 1107\n",
            "Before pruning:\n",
            "loss: 1.2507189512252808 - accuracy: 0.5523399710655212 - val_loss: 1.3719888925552368 - val_accuracy: 0.5103999972343445 - penalty: 1e-06\n",
            "hidden layer sizes: [280, 306, 271, 250], total neurons: 1107\n",
            "After pruning:\n",
            "loss: 1.2510151863098145 - accuracy: 0.5519999861717224 - val_loss: 1.372218370437622 - val_accuracy: 0.5094000101089478 - penalty: 1e-06\n",
            "hidden layer sizes: [142, 204, 164, 152], total neurons: 662\n",
            "##########################################################\n",
            "Epoch 2/5\n",
            "Before growing:\n",
            "loss: 1.2510151863098145 - accuracy: 0.5519999861717224 - val_loss: 1.372218370437622 - val_accuracy: 0.5094000101089478 - penalty: 1e-06\n",
            "hidden layer sizes: [142, 204, 164, 152], total neurons: 662\n",
            "After growing:\n",
            "loss: 1.2510151863098145 - accuracy: 0.5519800186157227 - val_loss: 1.372218370437622 - val_accuracy: 0.5094000101089478 - penalty: 1e-06\n",
            "hidden layer sizes: [242, 304, 264, 252], total neurons: 1062\n",
            "Before pruning:\n",
            "loss: 1.2328804731369019 - accuracy: 0.5580599904060364 - val_loss: 1.3693262338638306 - val_accuracy: 0.5091999769210815 - penalty: 1e-06\n",
            "hidden layer sizes: [242, 304, 264, 252], total neurons: 1062\n",
            "After pruning:\n",
            "loss: 1.2328946590423584 - accuracy: 0.5580000281333923 - val_loss: 1.36928129196167 - val_accuracy: 0.5092999935150146 - penalty: 1e-06\n",
            "hidden layer sizes: [148, 195, 171, 185], total neurons: 699\n",
            "##########################################################\n",
            "Epoch 3/5\n",
            "Before growing:\n",
            "loss: 1.2328946590423584 - accuracy: 0.5580000281333923 - val_loss: 1.36928129196167 - val_accuracy: 0.5092999935150146 - penalty: 1e-06\n",
            "hidden layer sizes: [148, 195, 171, 185], total neurons: 699\n",
            "After growing:\n",
            "loss: 1.2328945398330688 - accuracy: 0.5580000281333923 - val_loss: 1.3692810535430908 - val_accuracy: 0.5092999935150146 - penalty: 1e-06\n",
            "hidden layer sizes: [248, 295, 271, 285], total neurons: 1099\n",
            "Before pruning:\n",
            "loss: 1.194198489189148 - accuracy: 0.5748400092124939 - val_loss: 1.348921537399292 - val_accuracy: 0.5188999772071838 - penalty: 1e-06\n",
            "hidden layer sizes: [248, 295, 271, 285], total neurons: 1099\n",
            "After pruning:\n",
            "loss: 1.19416344165802 - accuracy: 0.5748999714851379 - val_loss: 1.3489078283309937 - val_accuracy: 0.5189999938011169 - penalty: 1e-06\n",
            "hidden layer sizes: [182, 203, 152, 160], total neurons: 697\n",
            "##########################################################\n",
            "Epoch 4/5\n",
            "Before growing:\n",
            "loss: 1.19416344165802 - accuracy: 0.5748999714851379 - val_loss: 1.3489078283309937 - val_accuracy: 0.5189999938011169 - penalty: 1e-06\n",
            "hidden layer sizes: [182, 203, 152, 160], total neurons: 697\n",
            "After growing:\n",
            "loss: 1.1941635608673096 - accuracy: 0.5748999714851379 - val_loss: 1.3489078283309937 - val_accuracy: 0.5189999938011169 - penalty: 1e-06\n",
            "hidden layer sizes: [282, 303, 252, 260], total neurons: 1097\n",
            "Before pruning:\n",
            "loss: 1.1806873083114624 - accuracy: 0.5791400074958801 - val_loss: 1.3520241975784302 - val_accuracy: 0.5152999758720398 - penalty: 1e-06\n",
            "hidden layer sizes: [282, 303, 252, 260], total neurons: 1097\n",
            "After pruning:\n",
            "loss: 1.1805680990219116 - accuracy: 0.5788400173187256 - val_loss: 1.3518704175949097 - val_accuracy: 0.5149999856948853 - penalty: 1e-06\n",
            "hidden layer sizes: [179, 223, 118, 178], total neurons: 698\n",
            "##########################################################\n",
            "Epoch 5/5\n",
            "Before growing:\n",
            "loss: 1.1805680990219116 - accuracy: 0.5788400173187256 - val_loss: 1.3518704175949097 - val_accuracy: 0.5149999856948853 - penalty: 1e-06\n",
            "hidden layer sizes: [179, 223, 118, 178], total neurons: 698\n",
            "After growing:\n",
            "loss: 1.1805682182312012 - accuracy: 0.5788400173187256 - val_loss: 1.3518706560134888 - val_accuracy: 0.5149999856948853 - penalty: 1e-06\n",
            "hidden layer sizes: [279, 323, 218, 278], total neurons: 1098\n",
            "Before pruning:\n",
            "loss: 1.1595497131347656 - accuracy: 0.5885199904441833 - val_loss: 1.3490227460861206 - val_accuracy: 0.5221999883651733 - penalty: 1e-06\n",
            "hidden layer sizes: [279, 323, 218, 278], total neurons: 1098\n",
            "After pruning:\n",
            "loss: 1.1596497297286987 - accuracy: 0.5884000062942505 - val_loss: 1.349127173423767 - val_accuracy: 0.5223000049591064 - penalty: 1e-06\n",
            "hidden layer sizes: [182, 241, 133, 175], total neurons: 731\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.5519999861717224,\n",
              "  0.5580000281333923,\n",
              "  0.5748999714851379,\n",
              "  0.5788400173187256,\n",
              "  0.5884000062942505],\n",
              " 'loss': [1.2510151863098145,\n",
              "  1.2328946590423584,\n",
              "  1.19416344165802,\n",
              "  1.1805680990219116,\n",
              "  1.1596497297286987],\n",
              " 'val_accuracy': [0.5094000101089478,\n",
              "  0.5092999935150146,\n",
              "  0.5189999938011169,\n",
              "  0.5149999856948853,\n",
              "  0.5223000049591064],\n",
              " 'val_loss': [1.372218370437622,\n",
              "  1.36928129196167,\n",
              "  1.3489078283309937,\n",
              "  1.3518704175949097,\n",
              "  1.349127173423767]}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wftJ2nhbNXKF",
        "outputId": "46b9adf0-484e-42d0-b71e-042a6ae8414e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(662 + 699 + 697 + 698 + 731) / 5"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "697.4"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l53lMogwTrBI"
      },
      "source": [
        "epochs = 40\n",
        "self_scaling_epochs = 40\n",
        "batch_size = 32\n",
        "min_new_neurons = 100"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3H8AkyaTr93",
        "outputId": "8fbc2db4-df0c-491e-b204-4c19a93b26fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model = SSModel(layer_sizes=[3072, 300, 300, 300, 300, 10], activation='selu', regularization_penalty=0.00001, \n",
        "                regularization_method='weighted_l1', kernel_initializer='lecun_normal')\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_norm_automobiles_dogs_train, y_automobiles_dogs_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_norm_automobiles_dogs_test, y_automobiles_dogs_test))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##########################################################\n",
            "Epoch 1/40\n",
            "Before growing:\n",
            "loss: 2.361034631729126 - accuracy: 0.19809523224830627 - val_loss: 2.411349058151245 - val_accuracy: 0.2013888955116272 - penalty: 1e-05\n",
            "hidden layer sizes: [300, 300, 300, 300], total neurons: 1200\n",
            "After growing:\n",
            "loss: 2.361035108566284 - accuracy: 0.19809523224830627 - val_loss: 2.411349296569824 - val_accuracy: 0.2013888955116272 - penalty: 1e-05\n",
            "hidden layer sizes: [400, 400, 400, 400], total neurons: 1600\n",
            "Before pruning:\n",
            "loss: 0.33096709847450256 - accuracy: 0.8698809742927551 - val_loss: 0.4045203626155853 - val_accuracy: 0.8422222137451172 - penalty: 1e-05\n",
            "hidden layer sizes: [400, 400, 400, 400], total neurons: 1600\n",
            "After pruning:\n",
            "loss: 0.33106324076652527 - accuracy: 0.8698809742927551 - val_loss: 0.4046081602573395 - val_accuracy: 0.8424999713897705 - penalty: 1e-05\n",
            "hidden layer sizes: [300, 300, 300, 300], total neurons: 1200\n",
            "##########################################################\n",
            "Epoch 2/40\n",
            "Before growing:\n",
            "loss: 0.33106324076652527 - accuracy: 0.8698809742927551 - val_loss: 0.4046081602573395 - val_accuracy: 0.8424999713897705 - penalty: 1e-05\n",
            "hidden layer sizes: [300, 300, 300, 300], total neurons: 1200\n",
            "After growing:\n",
            "loss: 0.3310631513595581 - accuracy: 0.8698809742927551 - val_loss: 0.4046080410480499 - val_accuracy: 0.8424999713897705 - penalty: 1e-05\n",
            "hidden layer sizes: [400, 400, 400, 400], total neurons: 1600\n",
            "Before pruning:\n",
            "loss: 0.25160714983940125 - accuracy: 0.9009523987770081 - val_loss: 0.31417301297187805 - val_accuracy: 0.8686110973358154 - penalty: 1e-05\n",
            "hidden layer sizes: [400, 400, 400, 400], total neurons: 1600\n",
            "After pruning:\n",
            "loss: 0.2503999173641205 - accuracy: 0.9019047617912292 - val_loss: 0.3126663565635681 - val_accuracy: 0.8683333396911621 - penalty: 1e-05\n",
            "hidden layer sizes: [132, 300, 300, 292], total neurons: 1024\n",
            "##########################################################\n",
            "Epoch 3/40\n",
            "Before growing:\n",
            "loss: 0.2503999173641205 - accuracy: 0.9019047617912292 - val_loss: 0.3126663565635681 - val_accuracy: 0.8683333396911621 - penalty: 1e-05\n",
            "hidden layer sizes: [132, 300, 300, 292], total neurons: 1024\n",
            "After growing:\n",
            "loss: 0.2503999173641205 - accuracy: 0.9019047617912292 - val_loss: 0.3126663863658905 - val_accuracy: 0.8683333396911621 - penalty: 1e-05\n",
            "hidden layer sizes: [232, 400, 400, 392], total neurons: 1424\n",
            "Before pruning:\n",
            "loss: 0.21643711626529694 - accuracy: 0.9209523797035217 - val_loss: 0.2805095911026001 - val_accuracy: 0.886388897895813 - penalty: 1e-05\n",
            "hidden layer sizes: [232, 400, 400, 392], total neurons: 1424\n",
            "After pruning:\n",
            "loss: 0.21713900566101074 - accuracy: 0.920119047164917 - val_loss: 0.2810043394565582 - val_accuracy: 0.8866666555404663 - penalty: 1e-05\n",
            "hidden layer sizes: [80, 282, 214, 241], total neurons: 817\n",
            "##########################################################\n",
            "Epoch 4/40\n",
            "Before growing:\n",
            "loss: 0.21713900566101074 - accuracy: 0.920119047164917 - val_loss: 0.2810043394565582 - val_accuracy: 0.8866666555404663 - penalty: 1e-05\n",
            "hidden layer sizes: [80, 282, 214, 241], total neurons: 817\n",
            "After growing:\n",
            "loss: 0.21713899075984955 - accuracy: 0.920119047164917 - val_loss: 0.28100430965423584 - val_accuracy: 0.8866666555404663 - penalty: 1e-05\n",
            "hidden layer sizes: [180, 382, 314, 341], total neurons: 1217\n",
            "Before pruning:\n",
            "loss: 0.20029476284980774 - accuracy: 0.9220238327980042 - val_loss: 0.2894284129142761 - val_accuracy: 0.8836110830307007 - penalty: 1e-05\n",
            "hidden layer sizes: [180, 382, 314, 341], total neurons: 1217\n",
            "After pruning:\n",
            "loss: 0.20018601417541504 - accuracy: 0.9219047427177429 - val_loss: 0.2892712950706482 - val_accuracy: 0.8838889002799988 - penalty: 1e-05\n",
            "hidden layer sizes: [66, 231, 121, 178], total neurons: 596\n",
            "##########################################################\n",
            "Epoch 5/40\n",
            "Before growing:\n",
            "loss: 0.20018601417541504 - accuracy: 0.9219047427177429 - val_loss: 0.2892712950706482 - val_accuracy: 0.8838889002799988 - penalty: 1e-05\n",
            "hidden layer sizes: [66, 231, 121, 178], total neurons: 596\n",
            "After growing:\n",
            "loss: 0.20018598437309265 - accuracy: 0.9219047427177429 - val_loss: 0.2892712652683258 - val_accuracy: 0.8838889002799988 - penalty: 1e-05\n",
            "hidden layer sizes: [166, 331, 221, 278], total neurons: 996\n",
            "Before pruning:\n",
            "loss: 0.15868841111660004 - accuracy: 0.9434523582458496 - val_loss: 0.23993831872940063 - val_accuracy: 0.9055555462837219 - penalty: 1e-05\n",
            "hidden layer sizes: [166, 331, 221, 278], total neurons: 996\n",
            "After pruning:\n",
            "loss: 0.15876063704490662 - accuracy: 0.9436904788017273 - val_loss: 0.2399277240037918 - val_accuracy: 0.9058333039283752 - penalty: 1e-05\n",
            "hidden layer sizes: [46, 170, 73, 138], total neurons: 427\n",
            "##########################################################\n",
            "Epoch 6/40\n",
            "Before growing:\n",
            "loss: 0.15876063704490662 - accuracy: 0.9436904788017273 - val_loss: 0.2399277240037918 - val_accuracy: 0.9058333039283752 - penalty: 1e-05\n",
            "hidden layer sizes: [46, 170, 73, 138], total neurons: 427\n",
            "After growing:\n",
            "loss: 0.15876063704490662 - accuracy: 0.9436904788017273 - val_loss: 0.2399277687072754 - val_accuracy: 0.9058333039283752 - penalty: 1e-05\n",
            "hidden layer sizes: [146, 270, 173, 238], total neurons: 827\n",
            "Before pruning:\n",
            "loss: 0.17499057948589325 - accuracy: 0.9357143044471741 - val_loss: 0.26572713255882263 - val_accuracy: 0.8958333134651184 - penalty: 1e-05\n",
            "hidden layer sizes: [146, 270, 173, 238], total neurons: 827\n",
            "After pruning:\n",
            "loss: 0.1751112937927246 - accuracy: 0.9355952143669128 - val_loss: 0.2659398317337036 - val_accuracy: 0.8955555558204651 - penalty: 1e-05\n",
            "hidden layer sizes: [41, 149, 58, 105], total neurons: 353\n",
            "##########################################################\n",
            "Epoch 7/40\n",
            "Before growing:\n",
            "loss: 0.1751112937927246 - accuracy: 0.9355952143669128 - val_loss: 0.2659398317337036 - val_accuracy: 0.8955555558204651 - penalty: 1e-05\n",
            "hidden layer sizes: [41, 149, 58, 105], total neurons: 353\n",
            "After growing:\n",
            "loss: 0.1751112937927246 - accuracy: 0.9355952143669128 - val_loss: 0.2659398317337036 - val_accuracy: 0.8955555558204651 - penalty: 1e-05\n",
            "hidden layer sizes: [141, 249, 158, 205], total neurons: 753\n",
            "Before pruning:\n",
            "loss: 0.14142394065856934 - accuracy: 0.9495238065719604 - val_loss: 0.25426408648490906 - val_accuracy: 0.8963888883590698 - penalty: 1e-05\n",
            "hidden layer sizes: [141, 249, 158, 205], total neurons: 753\n",
            "After pruning:\n",
            "loss: 0.14142853021621704 - accuracy: 0.9496428370475769 - val_loss: 0.25425419211387634 - val_accuracy: 0.8963888883590698 - penalty: 1e-05\n",
            "hidden layer sizes: [36, 116, 42, 93], total neurons: 287\n",
            "##########################################################\n",
            "Epoch 8/40\n",
            "Before growing:\n",
            "loss: 0.14142853021621704 - accuracy: 0.9496428370475769 - val_loss: 0.25425419211387634 - val_accuracy: 0.8963888883590698 - penalty: 1e-05\n",
            "hidden layer sizes: [36, 116, 42, 93], total neurons: 287\n",
            "After growing:\n",
            "loss: 0.14142853021621704 - accuracy: 0.9496428370475769 - val_loss: 0.25425416231155396 - val_accuracy: 0.8963888883590698 - penalty: 1e-05\n",
            "hidden layer sizes: [136, 216, 142, 193], total neurons: 687\n",
            "Before pruning:\n",
            "loss: 0.13264422118663788 - accuracy: 0.9524999856948853 - val_loss: 0.2573193907737732 - val_accuracy: 0.9030555486679077 - penalty: 1e-05\n",
            "hidden layer sizes: [136, 216, 142, 193], total neurons: 687\n",
            "After pruning:\n",
            "loss: 0.1327095776796341 - accuracy: 0.9524999856948853 - val_loss: 0.2573847770690918 - val_accuracy: 0.9030555486679077 - penalty: 1e-05\n",
            "hidden layer sizes: [49, 111, 40, 93], total neurons: 293\n",
            "##########################################################\n",
            "Epoch 9/40\n",
            "Before growing:\n",
            "loss: 0.1327095776796341 - accuracy: 0.9524999856948853 - val_loss: 0.2573847770690918 - val_accuracy: 0.9030555486679077 - penalty: 1e-05\n",
            "hidden layer sizes: [49, 111, 40, 93], total neurons: 293\n",
            "After growing:\n",
            "loss: 0.1327095627784729 - accuracy: 0.9524999856948853 - val_loss: 0.2573847472667694 - val_accuracy: 0.9030555486679077 - penalty: 1e-05\n",
            "hidden layer sizes: [149, 211, 140, 193], total neurons: 693\n",
            "Before pruning:\n",
            "loss: 0.11501763015985489 - accuracy: 0.9591666460037231 - val_loss: 0.24563002586364746 - val_accuracy: 0.9066666960716248 - penalty: 1e-05\n",
            "hidden layer sizes: [149, 211, 140, 193], total neurons: 693\n",
            "After pruning:\n",
            "loss: 0.11495570093393326 - accuracy: 0.9591666460037231 - val_loss: 0.24571093916893005 - val_accuracy: 0.9066666960716248 - penalty: 1e-05\n",
            "hidden layer sizes: [36, 85, 38, 103], total neurons: 262\n",
            "##########################################################\n",
            "Epoch 10/40\n",
            "Before growing:\n",
            "loss: 0.11495570093393326 - accuracy: 0.9591666460037231 - val_loss: 0.24571093916893005 - val_accuracy: 0.9066666960716248 - penalty: 1e-05\n",
            "hidden layer sizes: [36, 85, 38, 103], total neurons: 262\n",
            "After growing:\n",
            "loss: 0.11495572328567505 - accuracy: 0.9591666460037231 - val_loss: 0.24571096897125244 - val_accuracy: 0.9066666960716248 - penalty: 1e-05\n",
            "hidden layer sizes: [136, 185, 138, 203], total neurons: 662\n",
            "Before pruning:\n",
            "loss: 0.10914046317338943 - accuracy: 0.9628571271896362 - val_loss: 0.24556037783622742 - val_accuracy: 0.9072222113609314 - penalty: 1e-05\n",
            "hidden layer sizes: [136, 185, 138, 203], total neurons: 662\n",
            "After pruning:\n",
            "loss: 0.10929343104362488 - accuracy: 0.9629762172698975 - val_loss: 0.24555754661560059 - val_accuracy: 0.9072222113609314 - penalty: 1e-05\n",
            "hidden layer sizes: [36, 78, 36, 60], total neurons: 210\n",
            "##########################################################\n",
            "Epoch 11/40\n",
            "Before growing:\n",
            "loss: 0.10929343104362488 - accuracy: 0.9629762172698975 - val_loss: 0.24555754661560059 - val_accuracy: 0.9072222113609314 - penalty: 1e-05\n",
            "hidden layer sizes: [36, 78, 36, 60], total neurons: 210\n",
            "After growing:\n",
            "loss: 0.10929344594478607 - accuracy: 0.9629762172698975 - val_loss: 0.24555756151676178 - val_accuracy: 0.9072222113609314 - penalty: 1e-05\n",
            "hidden layer sizes: [136, 178, 136, 160], total neurons: 610\n",
            "Before pruning:\n",
            "loss: 0.10819000750780106 - accuracy: 0.9649999737739563 - val_loss: 0.2514682412147522 - val_accuracy: 0.9027777910232544 - penalty: 1e-05\n",
            "hidden layer sizes: [136, 178, 136, 160], total neurons: 610\n",
            "After pruning:\n",
            "loss: 0.10829534381628036 - accuracy: 0.9646428823471069 - val_loss: 0.25183722376823425 - val_accuracy: 0.9019444584846497 - penalty: 1e-05\n",
            "hidden layer sizes: [40, 73, 36, 55], total neurons: 204\n",
            "##########################################################\n",
            "Epoch 12/40\n",
            "Before growing:\n",
            "loss: 0.10829534381628036 - accuracy: 0.9646428823471069 - val_loss: 0.25183722376823425 - val_accuracy: 0.9019444584846497 - penalty: 1e-05\n",
            "hidden layer sizes: [40, 73, 36, 55], total neurons: 204\n",
            "After growing:\n",
            "loss: 0.10829535126686096 - accuracy: 0.9646428823471069 - val_loss: 0.25183722376823425 - val_accuracy: 0.9019444584846497 - penalty: 1e-05\n",
            "hidden layer sizes: [140, 173, 136, 155], total neurons: 604\n",
            "Before pruning:\n",
            "loss: 0.09368166327476501 - accuracy: 0.9691666960716248 - val_loss: 0.25951793789863586 - val_accuracy: 0.9086111187934875 - penalty: 1e-05\n",
            "hidden layer sizes: [140, 173, 136, 155], total neurons: 604\n",
            "After pruning:\n",
            "loss: 0.09371279925107956 - accuracy: 0.9688095450401306 - val_loss: 0.25981882214546204 - val_accuracy: 0.909166693687439 - penalty: 1e-05\n",
            "hidden layer sizes: [38, 66, 32, 55], total neurons: 191\n",
            "##########################################################\n",
            "Epoch 13/40\n",
            "Before growing:\n",
            "loss: 0.09371279925107956 - accuracy: 0.9688095450401306 - val_loss: 0.25981882214546204 - val_accuracy: 0.909166693687439 - penalty: 1e-05\n",
            "hidden layer sizes: [38, 66, 32, 55], total neurons: 191\n",
            "After growing:\n",
            "loss: 0.09371280670166016 - accuracy: 0.9688095450401306 - val_loss: 0.2598188519477844 - val_accuracy: 0.909166693687439 - penalty: 1e-05\n",
            "hidden layer sizes: [138, 166, 132, 155], total neurons: 591\n",
            "Before pruning:\n",
            "loss: 0.08566226810216904 - accuracy: 0.9735714197158813 - val_loss: 0.25129157304763794 - val_accuracy: 0.9077777862548828 - penalty: 1e-05\n",
            "hidden layer sizes: [138, 166, 132, 155], total neurons: 591\n",
            "After pruning:\n",
            "loss: 0.08570921421051025 - accuracy: 0.9735714197158813 - val_loss: 0.2516867518424988 - val_accuracy: 0.9080555438995361 - penalty: 1e-05\n",
            "hidden layer sizes: [33, 65, 30, 90], total neurons: 218\n",
            "##########################################################\n",
            "Epoch 14/40\n",
            "Before growing:\n",
            "loss: 0.08570921421051025 - accuracy: 0.9735714197158813 - val_loss: 0.2516867518424988 - val_accuracy: 0.9080555438995361 - penalty: 1e-05\n",
            "hidden layer sizes: [33, 65, 30, 90], total neurons: 218\n",
            "After growing:\n",
            "loss: 0.08570921421051025 - accuracy: 0.9735714197158813 - val_loss: 0.25168678164482117 - val_accuracy: 0.9080555438995361 - penalty: 1e-05\n",
            "hidden layer sizes: [133, 165, 130, 190], total neurons: 618\n",
            "Before pruning:\n",
            "loss: 0.08111703395843506 - accuracy: 0.9757142663002014 - val_loss: 0.24683409929275513 - val_accuracy: 0.9127777814865112 - penalty: 1e-05\n",
            "hidden layer sizes: [133, 165, 130, 190], total neurons: 618\n",
            "After pruning:\n",
            "loss: 0.08110575377941132 - accuracy: 0.9757142663002014 - val_loss: 0.24679462611675262 - val_accuracy: 0.9122222065925598 - penalty: 1e-05\n",
            "hidden layer sizes: [33, 62, 30, 47], total neurons: 172\n",
            "##########################################################\n",
            "Epoch 15/40\n",
            "Before growing:\n",
            "loss: 0.08110575377941132 - accuracy: 0.9757142663002014 - val_loss: 0.24679462611675262 - val_accuracy: 0.9122222065925598 - penalty: 1e-05\n",
            "hidden layer sizes: [33, 62, 30, 47], total neurons: 172\n",
            "After growing:\n",
            "loss: 0.08110573887825012 - accuracy: 0.9757142663002014 - val_loss: 0.24679462611675262 - val_accuracy: 0.9122222065925598 - penalty: 1e-05\n",
            "hidden layer sizes: [133, 162, 130, 147], total neurons: 572\n",
            "Before pruning:\n",
            "loss: 0.08252344280481339 - accuracy: 0.9732142686843872 - val_loss: 0.26292797923088074 - val_accuracy: 0.9066666960716248 - penalty: 1e-05\n",
            "hidden layer sizes: [133, 162, 130, 147], total neurons: 572\n",
            "After pruning:\n",
            "loss: 0.08253608644008636 - accuracy: 0.9732142686843872 - val_loss: 0.2628299593925476 - val_accuracy: 0.9066666960716248 - penalty: 1e-05\n",
            "hidden layer sizes: [33, 56, 30, 44], total neurons: 163\n",
            "##########################################################\n",
            "Epoch 16/40\n",
            "Before growing:\n",
            "loss: 0.08253608644008636 - accuracy: 0.9732142686843872 - val_loss: 0.2628299593925476 - val_accuracy: 0.9066666960716248 - penalty: 1e-05\n",
            "hidden layer sizes: [33, 56, 30, 44], total neurons: 163\n",
            "After growing:\n",
            "loss: 0.08253609389066696 - accuracy: 0.9732142686843872 - val_loss: 0.2628299593925476 - val_accuracy: 0.9066666960716248 - penalty: 1e-05\n",
            "hidden layer sizes: [133, 156, 130, 144], total neurons: 563\n",
            "Before pruning:\n",
            "loss: 0.07936976850032806 - accuracy: 0.9750000238418579 - val_loss: 0.2647203803062439 - val_accuracy: 0.9083333611488342 - penalty: 1e-05\n",
            "hidden layer sizes: [133, 156, 130, 144], total neurons: 563\n",
            "After pruning:\n",
            "loss: 0.0793524831533432 - accuracy: 0.9750000238418579 - val_loss: 0.2647351324558258 - val_accuracy: 0.9083333611488342 - penalty: 1e-05\n",
            "hidden layer sizes: [33, 58, 29, 65], total neurons: 185\n",
            "##########################################################\n",
            "Epoch 17/40\n",
            "Before growing:\n",
            "loss: 0.0793524831533432 - accuracy: 0.9750000238418579 - val_loss: 0.2647351324558258 - val_accuracy: 0.9083333611488342 - penalty: 1e-05\n",
            "hidden layer sizes: [33, 58, 29, 65], total neurons: 185\n",
            "After growing:\n",
            "loss: 0.07935244590044022 - accuracy: 0.9750000238418579 - val_loss: 0.2647351026535034 - val_accuracy: 0.9083333611488342 - penalty: 1e-05\n",
            "hidden layer sizes: [133, 158, 129, 165], total neurons: 585\n",
            "Before pruning:\n",
            "loss: 0.08193955570459366 - accuracy: 0.9732142686843872 - val_loss: 0.2760296165943146 - val_accuracy: 0.903333306312561 - penalty: 1e-05\n",
            "hidden layer sizes: [133, 158, 129, 165], total neurons: 585\n",
            "After pruning:\n",
            "loss: 0.08171796798706055 - accuracy: 0.9730952382087708 - val_loss: 0.2758427858352661 - val_accuracy: 0.9038888812065125 - penalty: 1e-05\n",
            "hidden layer sizes: [33, 52, 28, 41], total neurons: 154\n",
            "##########################################################\n",
            "Epoch 18/40\n",
            "Before growing:\n",
            "loss: 0.08171796798706055 - accuracy: 0.9730952382087708 - val_loss: 0.2758427858352661 - val_accuracy: 0.9038888812065125 - penalty: 1e-05\n",
            "hidden layer sizes: [33, 52, 28, 41], total neurons: 154\n",
            "After growing:\n",
            "loss: 0.08171803504228592 - accuracy: 0.9730952382087708 - val_loss: 0.27584293484687805 - val_accuracy: 0.9038888812065125 - penalty: 1e-05\n",
            "hidden layer sizes: [133, 152, 128, 141], total neurons: 554\n",
            "Before pruning:\n",
            "loss: 0.06847231835126877 - accuracy: 0.9788095355033875 - val_loss: 0.27096760272979736 - val_accuracy: 0.9080555438995361 - penalty: 1e-05\n",
            "hidden layer sizes: [133, 152, 128, 141], total neurons: 554\n",
            "After pruning:\n",
            "loss: 0.06829627603292465 - accuracy: 0.9788095355033875 - val_loss: 0.2710295021533966 - val_accuracy: 0.9080555438995361 - penalty: 1e-05\n",
            "hidden layer sizes: [39, 50, 26, 40], total neurons: 155\n",
            "##########################################################\n",
            "Epoch 19/40\n",
            "Before growing:\n",
            "loss: 0.06829627603292465 - accuracy: 0.9788095355033875 - val_loss: 0.2710295021533966 - val_accuracy: 0.9080555438995361 - penalty: 1e-05\n",
            "hidden layer sizes: [39, 50, 26, 40], total neurons: 155\n",
            "After growing:\n",
            "loss: 0.06829626113176346 - accuracy: 0.9788095355033875 - val_loss: 0.271029531955719 - val_accuracy: 0.9080555438995361 - penalty: 1e-05\n",
            "hidden layer sizes: [139, 150, 126, 140], total neurons: 555\n",
            "Before pruning:\n",
            "loss: 0.06434401869773865 - accuracy: 0.9816666841506958 - val_loss: 0.26499757170677185 - val_accuracy: 0.9083333611488342 - penalty: 1e-05\n",
            "hidden layer sizes: [139, 150, 126, 140], total neurons: 555\n",
            "After pruning:\n",
            "loss: 0.06449349224567413 - accuracy: 0.9816666841506958 - val_loss: 0.26466718316078186 - val_accuracy: 0.9080555438995361 - penalty: 1e-05\n",
            "hidden layer sizes: [30, 45, 25, 40], total neurons: 140\n",
            "##########################################################\n",
            "Epoch 20/40\n",
            "Before growing:\n",
            "loss: 0.06449349224567413 - accuracy: 0.9816666841506958 - val_loss: 0.26466718316078186 - val_accuracy: 0.9080555438995361 - penalty: 1e-05\n",
            "hidden layer sizes: [30, 45, 25, 40], total neurons: 140\n",
            "After growing:\n",
            "loss: 0.06449350714683533 - accuracy: 0.9816666841506958 - val_loss: 0.2646671533584595 - val_accuracy: 0.9080555438995361 - penalty: 1e-05\n",
            "hidden layer sizes: [130, 145, 125, 140], total neurons: 540\n",
            "Before pruning:\n",
            "loss: 0.07366212457418442 - accuracy: 0.9757142663002014 - val_loss: 0.2856151759624481 - val_accuracy: 0.9038888812065125 - penalty: 1e-05\n",
            "hidden layer sizes: [130, 145, 125, 140], total neurons: 540\n",
            "After pruning:\n",
            "loss: 0.07377997040748596 - accuracy: 0.9757142663002014 - val_loss: 0.2857966423034668 - val_accuracy: 0.9038888812065125 - penalty: 1e-05\n",
            "hidden layer sizes: [28, 42, 24, 55], total neurons: 149\n",
            "##########################################################\n",
            "Epoch 21/40\n",
            "Before growing:\n",
            "loss: 0.07377997040748596 - accuracy: 0.9757142663002014 - val_loss: 0.2857966423034668 - val_accuracy: 0.9038888812065125 - penalty: 1e-05\n",
            "hidden layer sizes: [28, 42, 24, 55], total neurons: 149\n",
            "After growing:\n",
            "loss: 0.07377999275922775 - accuracy: 0.9757142663002014 - val_loss: 0.2857966423034668 - val_accuracy: 0.9038888812065125 - penalty: 1e-05\n",
            "hidden layer sizes: [128, 142, 124, 155], total neurons: 549\n",
            "Before pruning:\n",
            "loss: 0.06605780869722366 - accuracy: 0.9798809289932251 - val_loss: 0.291938453912735 - val_accuracy: 0.9047222137451172 - penalty: 1e-05\n",
            "hidden layer sizes: [128, 142, 124, 155], total neurons: 549\n",
            "After pruning:\n",
            "loss: 0.06592321395874023 - accuracy: 0.9797618985176086 - val_loss: 0.2928047776222229 - val_accuracy: 0.9044444561004639 - penalty: 1e-05\n",
            "hidden layer sizes: [30, 43, 21, 36], total neurons: 130\n",
            "##########################################################\n",
            "Epoch 22/40\n",
            "Before growing:\n",
            "loss: 0.06592321395874023 - accuracy: 0.9797618985176086 - val_loss: 0.2928047776222229 - val_accuracy: 0.9044444561004639 - penalty: 1e-05\n",
            "hidden layer sizes: [30, 43, 21, 36], total neurons: 130\n",
            "After growing:\n",
            "loss: 0.06592321395874023 - accuracy: 0.9797618985176086 - val_loss: 0.2928048074245453 - val_accuracy: 0.9044444561004639 - penalty: 1e-05\n",
            "hidden layer sizes: [130, 143, 121, 136], total neurons: 530\n",
            "Before pruning:\n",
            "loss: 0.06199348717927933 - accuracy: 0.9815475940704346 - val_loss: 0.26511478424072266 - val_accuracy: 0.9116666913032532 - penalty: 1e-05\n",
            "hidden layer sizes: [130, 143, 121, 136], total neurons: 530\n",
            "After pruning:\n",
            "loss: 0.06200122833251953 - accuracy: 0.9816666841506958 - val_loss: 0.26468393206596375 - val_accuracy: 0.9116666913032532 - penalty: 1e-05\n",
            "hidden layer sizes: [51, 55, 21, 126], total neurons: 253\n",
            "##########################################################\n",
            "Epoch 23/40\n",
            "Before growing:\n",
            "loss: 0.06200122833251953 - accuracy: 0.9816666841506958 - val_loss: 0.26468393206596375 - val_accuracy: 0.9116666913032532 - penalty: 1e-05\n",
            "hidden layer sizes: [51, 55, 21, 126], total neurons: 253\n",
            "After growing:\n",
            "loss: 0.06200123950839043 - accuracy: 0.9816666841506958 - val_loss: 0.2646839916706085 - val_accuracy: 0.9116666913032532 - penalty: 1e-05\n",
            "hidden layer sizes: [151, 155, 121, 226], total neurons: 653\n",
            "Before pruning:\n",
            "loss: 0.07537352293729782 - accuracy: 0.9770237803459167 - val_loss: 0.28083619475364685 - val_accuracy: 0.8994444608688354 - penalty: 1e-05\n",
            "hidden layer sizes: [151, 155, 121, 226], total neurons: 653\n",
            "After pruning:\n",
            "loss: 0.0758088231086731 - accuracy: 0.9769047498703003 - val_loss: 0.2803553640842438 - val_accuracy: 0.8994444608688354 - penalty: 1e-05\n",
            "hidden layer sizes: [32, 41, 20, 105], total neurons: 198\n",
            "##########################################################\n",
            "Epoch 24/40\n",
            "Before growing:\n",
            "loss: 0.0758088231086731 - accuracy: 0.9769047498703003 - val_loss: 0.2803553640842438 - val_accuracy: 0.8994444608688354 - penalty: 1e-05\n",
            "hidden layer sizes: [32, 41, 20, 105], total neurons: 198\n",
            "After growing:\n",
            "loss: 0.07580885291099548 - accuracy: 0.9769047498703003 - val_loss: 0.2803553640842438 - val_accuracy: 0.8994444608688354 - penalty: 1e-05\n",
            "hidden layer sizes: [132, 141, 120, 205], total neurons: 598\n",
            "Before pruning:\n",
            "loss: 0.06915639340877533 - accuracy: 0.978690505027771 - val_loss: 0.28533294796943665 - val_accuracy: 0.9036111235618591 - penalty: 1e-05\n",
            "hidden layer sizes: [132, 141, 120, 205], total neurons: 598\n",
            "After pruning:\n",
            "loss: 0.0692301020026207 - accuracy: 0.9785714149475098 - val_loss: 0.2850106954574585 - val_accuracy: 0.9036111235618591 - penalty: 1e-05\n",
            "hidden layer sizes: [26, 50, 17, 33], total neurons: 126\n",
            "##########################################################\n",
            "Epoch 25/40\n",
            "Before growing:\n",
            "loss: 0.0692301020026207 - accuracy: 0.9785714149475098 - val_loss: 0.2850106954574585 - val_accuracy: 0.9036111235618591 - penalty: 1e-05\n",
            "hidden layer sizes: [26, 50, 17, 33], total neurons: 126\n",
            "After growing:\n",
            "loss: 0.06923011690378189 - accuracy: 0.9785714149475098 - val_loss: 0.28501057624816895 - val_accuracy: 0.9036111235618591 - penalty: 1e-05\n",
            "hidden layer sizes: [126, 150, 117, 133], total neurons: 526\n",
            "Before pruning:\n",
            "loss: 0.05088426172733307 - accuracy: 0.9869047403335571 - val_loss: 0.27761122584342957 - val_accuracy: 0.9111111164093018 - penalty: 1e-05\n",
            "hidden layer sizes: [126, 150, 117, 133], total neurons: 526\n",
            "After pruning:\n",
            "loss: 0.05132190138101578 - accuracy: 0.9870238304138184 - val_loss: 0.2784992754459381 - val_accuracy: 0.9100000262260437 - penalty: 1e-05\n",
            "hidden layer sizes: [22, 44, 17, 33], total neurons: 116\n",
            "##########################################################\n",
            "Epoch 26/40\n",
            "Before growing:\n",
            "loss: 0.05132190138101578 - accuracy: 0.9870238304138184 - val_loss: 0.2784992754459381 - val_accuracy: 0.9100000262260437 - penalty: 1e-05\n",
            "hidden layer sizes: [22, 44, 17, 33], total neurons: 116\n",
            "After growing:\n",
            "loss: 0.051321934908628464 - accuracy: 0.9870238304138184 - val_loss: 0.2784992754459381 - val_accuracy: 0.9100000262260437 - penalty: 1e-05\n",
            "hidden layer sizes: [122, 144, 117, 133], total neurons: 516\n",
            "Before pruning:\n",
            "loss: 0.06340575963258743 - accuracy: 0.9797618985176086 - val_loss: 0.297721803188324 - val_accuracy: 0.8999999761581421 - penalty: 1e-05\n",
            "hidden layer sizes: [122, 144, 117, 133], total neurons: 516\n",
            "After pruning:\n",
            "loss: 0.0638546422123909 - accuracy: 0.9794047474861145 - val_loss: 0.29903313517570496 - val_accuracy: 0.8997222185134888 - penalty: 1e-05\n",
            "hidden layer sizes: [20, 41, 17, 37], total neurons: 115\n",
            "##########################################################\n",
            "Epoch 27/40\n",
            "Before growing:\n",
            "loss: 0.0638546422123909 - accuracy: 0.9794047474861145 - val_loss: 0.29903313517570496 - val_accuracy: 0.8997222185134888 - penalty: 1e-05\n",
            "hidden layer sizes: [20, 41, 17, 37], total neurons: 115\n",
            "After growing:\n",
            "loss: 0.0638546496629715 - accuracy: 0.9794047474861145 - val_loss: 0.29903313517570496 - val_accuracy: 0.8997222185134888 - penalty: 1e-05\n",
            "hidden layer sizes: [120, 141, 117, 137], total neurons: 515\n",
            "Before pruning:\n",
            "loss: 0.06223023310303688 - accuracy: 0.9802380800247192 - val_loss: 0.3104024827480316 - val_accuracy: 0.9030555486679077 - penalty: 1e-05\n",
            "hidden layer sizes: [120, 141, 117, 137], total neurons: 515\n",
            "After pruning:\n",
            "loss: 0.06237534433603287 - accuracy: 0.9802380800247192 - val_loss: 0.3109969198703766 - val_accuracy: 0.903333306312561 - penalty: 1e-05\n",
            "hidden layer sizes: [19, 39, 17, 32], total neurons: 107\n",
            "##########################################################\n",
            "Epoch 28/40\n",
            "Before growing:\n",
            "loss: 0.06237534433603287 - accuracy: 0.9802380800247192 - val_loss: 0.3109969198703766 - val_accuracy: 0.903333306312561 - penalty: 1e-05\n",
            "hidden layer sizes: [19, 39, 17, 32], total neurons: 107\n",
            "After growing:\n",
            "loss: 0.062375377863645554 - accuracy: 0.9802380800247192 - val_loss: 0.3109968602657318 - val_accuracy: 0.903333306312561 - penalty: 1e-05\n",
            "hidden layer sizes: [119, 139, 117, 132], total neurons: 507\n",
            "Before pruning:\n",
            "loss: 0.05621547996997833 - accuracy: 0.9821428656578064 - val_loss: 0.308035284280777 - val_accuracy: 0.9100000262260437 - penalty: 1e-05\n",
            "hidden layer sizes: [119, 139, 117, 132], total neurons: 507\n",
            "After pruning:\n",
            "loss: 0.05630529671907425 - accuracy: 0.9820238351821899 - val_loss: 0.30817824602127075 - val_accuracy: 0.9097222089767456 - penalty: 1e-05\n",
            "hidden layer sizes: [21, 35, 17, 107], total neurons: 180\n",
            "##########################################################\n",
            "Epoch 29/40\n",
            "Before growing:\n",
            "loss: 0.05630529671907425 - accuracy: 0.9820238351821899 - val_loss: 0.30817824602127075 - val_accuracy: 0.9097222089767456 - penalty: 1e-05\n",
            "hidden layer sizes: [21, 35, 17, 107], total neurons: 180\n",
            "After growing:\n",
            "loss: 0.056305259466171265 - accuracy: 0.9820238351821899 - val_loss: 0.3081781268119812 - val_accuracy: 0.9097222089767456 - penalty: 1e-05\n",
            "hidden layer sizes: [121, 135, 117, 207], total neurons: 580\n",
            "Before pruning:\n",
            "loss: 0.053067393600940704 - accuracy: 0.9839285612106323 - val_loss: 0.30584314465522766 - val_accuracy: 0.9061111211776733 - penalty: 1e-05\n",
            "hidden layer sizes: [121, 135, 117, 207], total neurons: 580\n",
            "After pruning:\n",
            "loss: 0.05311987176537514 - accuracy: 0.9838095307350159 - val_loss: 0.30596044659614563 - val_accuracy: 0.9058333039283752 - penalty: 1e-05\n",
            "hidden layer sizes: [27, 36, 16, 30], total neurons: 109\n",
            "##########################################################\n",
            "Epoch 30/40\n",
            "Before growing:\n",
            "loss: 0.05311987176537514 - accuracy: 0.9838095307350159 - val_loss: 0.30596044659614563 - val_accuracy: 0.9058333039283752 - penalty: 1e-05\n",
            "hidden layer sizes: [27, 36, 16, 30], total neurons: 109\n",
            "After growing:\n",
            "loss: 0.05311983823776245 - accuracy: 0.9838095307350159 - val_loss: 0.30596035718917847 - val_accuracy: 0.9058333039283752 - penalty: 1e-05\n",
            "hidden layer sizes: [127, 136, 116, 130], total neurons: 509\n",
            "Before pruning:\n",
            "loss: 0.056110989302396774 - accuracy: 0.9819047451019287 - val_loss: 0.2927769720554352 - val_accuracy: 0.9058333039283752 - penalty: 1e-05\n",
            "hidden layer sizes: [127, 136, 116, 130], total neurons: 509\n",
            "After pruning:\n",
            "loss: 0.05632294714450836 - accuracy: 0.9816666841506958 - val_loss: 0.2925439476966858 - val_accuracy: 0.9069444537162781 - penalty: 1e-05\n",
            "hidden layer sizes: [29, 35, 15, 32], total neurons: 111\n",
            "##########################################################\n",
            "Epoch 31/40\n",
            "Before growing:\n",
            "loss: 0.05632294714450836 - accuracy: 0.9816666841506958 - val_loss: 0.2925439476966858 - val_accuracy: 0.9069444537162781 - penalty: 1e-05\n",
            "hidden layer sizes: [29, 35, 15, 32], total neurons: 111\n",
            "After growing:\n",
            "loss: 0.05632295832037926 - accuracy: 0.9816666841506958 - val_loss: 0.2925439476966858 - val_accuracy: 0.9069444537162781 - penalty: 1e-05\n",
            "hidden layer sizes: [129, 135, 115, 132], total neurons: 511\n",
            "Before pruning:\n",
            "loss: 0.047296106815338135 - accuracy: 0.9873809814453125 - val_loss: 0.3010064959526062 - val_accuracy: 0.9013888835906982 - penalty: 1e-05\n",
            "hidden layer sizes: [129, 135, 115, 132], total neurons: 511\n",
            "After pruning:\n",
            "loss: 0.047485075891017914 - accuracy: 0.986547589302063 - val_loss: 0.301449716091156 - val_accuracy: 0.9013888835906982 - penalty: 1e-05\n",
            "hidden layer sizes: [19, 37, 15, 51], total neurons: 122\n",
            "##########################################################\n",
            "Epoch 32/40\n",
            "Before growing:\n",
            "loss: 0.047485075891017914 - accuracy: 0.986547589302063 - val_loss: 0.301449716091156 - val_accuracy: 0.9013888835906982 - penalty: 1e-05\n",
            "hidden layer sizes: [19, 37, 15, 51], total neurons: 122\n",
            "After growing:\n",
            "loss: 0.04748506844043732 - accuracy: 0.986547589302063 - val_loss: 0.3014497756958008 - val_accuracy: 0.9013888835906982 - penalty: 1e-05\n",
            "hidden layer sizes: [119, 137, 115, 151], total neurons: 522\n",
            "Before pruning:\n",
            "loss: 0.05598343908786774 - accuracy: 0.9823809266090393 - val_loss: 0.31957507133483887 - val_accuracy: 0.9052777886390686 - penalty: 1e-05\n",
            "hidden layer sizes: [119, 137, 115, 151], total neurons: 522\n",
            "After pruning:\n",
            "loss: 0.05614699423313141 - accuracy: 0.9822618961334229 - val_loss: 0.3199199140071869 - val_accuracy: 0.9055555462837219 - penalty: 1e-05\n",
            "hidden layer sizes: [25, 32, 15, 28], total neurons: 100\n",
            "##########################################################\n",
            "Epoch 33/40\n",
            "Before growing:\n",
            "loss: 0.05614699423313141 - accuracy: 0.9822618961334229 - val_loss: 0.3199199140071869 - val_accuracy: 0.9055555462837219 - penalty: 1e-05\n",
            "hidden layer sizes: [25, 32, 15, 28], total neurons: 100\n",
            "After growing:\n",
            "loss: 0.056146975606679916 - accuracy: 0.9822618961334229 - val_loss: 0.3199199140071869 - val_accuracy: 0.9055555462837219 - penalty: 1e-05\n",
            "hidden layer sizes: [125, 132, 115, 128], total neurons: 500\n",
            "Before pruning:\n",
            "loss: 0.049032874405384064 - accuracy: 0.9840475916862488 - val_loss: 0.30521371960639954 - val_accuracy: 0.9055555462837219 - penalty: 1e-05\n",
            "hidden layer sizes: [125, 132, 115, 128], total neurons: 500\n",
            "After pruning:\n",
            "loss: 0.04910814017057419 - accuracy: 0.9839285612106323 - val_loss: 0.3055258095264435 - val_accuracy: 0.9061111211776733 - penalty: 1e-05\n",
            "hidden layer sizes: [25, 31, 15, 29], total neurons: 100\n",
            "##########################################################\n",
            "Epoch 34/40\n",
            "Before growing:\n",
            "loss: 0.04910814017057419 - accuracy: 0.9839285612106323 - val_loss: 0.3055258095264435 - val_accuracy: 0.9061111211776733 - penalty: 1e-05\n",
            "hidden layer sizes: [25, 31, 15, 29], total neurons: 100\n",
            "After growing:\n",
            "loss: 0.04910813644528389 - accuracy: 0.9839285612106323 - val_loss: 0.3055258095264435 - val_accuracy: 0.9061111211776733 - penalty: 1e-05\n",
            "hidden layer sizes: [125, 131, 115, 129], total neurons: 500\n",
            "Before pruning:\n",
            "loss: 0.04241514205932617 - accuracy: 0.9869047403335571 - val_loss: 0.3080086410045624 - val_accuracy: 0.9100000262260437 - penalty: 1e-05\n",
            "hidden layer sizes: [125, 131, 115, 129], total neurons: 500\n",
            "After pruning:\n",
            "loss: 0.04241554066538811 - accuracy: 0.986547589302063 - val_loss: 0.3080689013004303 - val_accuracy: 0.9097222089767456 - penalty: 1e-05\n",
            "hidden layer sizes: [19, 27, 15, 29], total neurons: 90\n",
            "##########################################################\n",
            "Epoch 35/40\n",
            "Before growing:\n",
            "loss: 0.04241554066538811 - accuracy: 0.986547589302063 - val_loss: 0.3080689013004303 - val_accuracy: 0.9097222089767456 - penalty: 1e-05\n",
            "hidden layer sizes: [19, 27, 15, 29], total neurons: 90\n",
            "After growing:\n",
            "loss: 0.042415548115968704 - accuracy: 0.986547589302063 - val_loss: 0.3080688714981079 - val_accuracy: 0.9097222089767456 - penalty: 1e-05\n",
            "hidden layer sizes: [119, 127, 115, 129], total neurons: 490\n",
            "Before pruning:\n",
            "loss: 0.04484880715608597 - accuracy: 0.9867857098579407 - val_loss: 0.3089557886123657 - val_accuracy: 0.9066666960716248 - penalty: 1e-05\n",
            "hidden layer sizes: [119, 127, 115, 129], total neurons: 490\n",
            "After pruning:\n",
            "loss: 0.04511436074972153 - accuracy: 0.9866666793823242 - val_loss: 0.3093438744544983 - val_accuracy: 0.9066666960716248 - penalty: 1e-05\n",
            "hidden layer sizes: [23, 30, 17, 37], total neurons: 107\n",
            "##########################################################\n",
            "Epoch 36/40\n",
            "Before growing:\n",
            "loss: 0.04511436074972153 - accuracy: 0.9866666793823242 - val_loss: 0.3093438744544983 - val_accuracy: 0.9066666960716248 - penalty: 1e-05\n",
            "hidden layer sizes: [23, 30, 17, 37], total neurons: 107\n",
            "After growing:\n",
            "loss: 0.045114342123270035 - accuracy: 0.9866666793823242 - val_loss: 0.3093438148498535 - val_accuracy: 0.9066666960716248 - penalty: 1e-05\n",
            "hidden layer sizes: [123, 130, 117, 137], total neurons: 507\n",
            "Before pruning:\n",
            "loss: 0.04833442345261574 - accuracy: 0.9847618937492371 - val_loss: 0.3170040547847748 - val_accuracy: 0.9083333611488342 - penalty: 1e-05\n",
            "hidden layer sizes: [123, 130, 117, 137], total neurons: 507\n",
            "After pruning:\n",
            "loss: 0.04828617349267006 - accuracy: 0.9850000143051147 - val_loss: 0.31685543060302734 - val_accuracy: 0.9080555438995361 - penalty: 1e-05\n",
            "hidden layer sizes: [26, 27, 14, 45], total neurons: 112\n",
            "##########################################################\n",
            "Epoch 37/40\n",
            "Before growing:\n",
            "loss: 0.04828617349267006 - accuracy: 0.9850000143051147 - val_loss: 0.31685543060302734 - val_accuracy: 0.9080555438995361 - penalty: 1e-05\n",
            "hidden layer sizes: [26, 27, 14, 45], total neurons: 112\n",
            "After growing:\n",
            "loss: 0.04828622564673424 - accuracy: 0.9850000143051147 - val_loss: 0.3168555796146393 - val_accuracy: 0.9080555438995361 - penalty: 1e-05\n",
            "hidden layer sizes: [126, 127, 114, 145], total neurons: 512\n",
            "Before pruning:\n",
            "loss: 0.04827258735895157 - accuracy: 0.9847618937492371 - val_loss: 0.307534396648407 - val_accuracy: 0.909166693687439 - penalty: 1e-05\n",
            "hidden layer sizes: [126, 127, 114, 145], total neurons: 512\n",
            "After pruning:\n",
            "loss: 0.04827379435300827 - accuracy: 0.9846428632736206 - val_loss: 0.3078135848045349 - val_accuracy: 0.909166693687439 - penalty: 1e-05\n",
            "hidden layer sizes: [23, 27, 14, 50], total neurons: 114\n",
            "##########################################################\n",
            "Epoch 38/40\n",
            "Before growing:\n",
            "loss: 0.04827379435300827 - accuracy: 0.9846428632736206 - val_loss: 0.3078135848045349 - val_accuracy: 0.909166693687439 - penalty: 1e-05\n",
            "hidden layer sizes: [23, 27, 14, 50], total neurons: 114\n",
            "After growing:\n",
            "loss: 0.04827377200126648 - accuracy: 0.9846428632736206 - val_loss: 0.30781349539756775 - val_accuracy: 0.909166693687439 - penalty: 1e-05\n",
            "hidden layer sizes: [123, 127, 114, 150], total neurons: 514\n",
            "Before pruning:\n",
            "loss: 0.0509292371571064 - accuracy: 0.9828571677207947 - val_loss: 0.319825142621994 - val_accuracy: 0.9075000286102295 - penalty: 1e-05\n",
            "hidden layer sizes: [123, 127, 114, 150], total neurons: 514\n",
            "After pruning:\n",
            "loss: 0.05020860582590103 - accuracy: 0.983214259147644 - val_loss: 0.3191058933734894 - val_accuracy: 0.9080555438995361 - penalty: 1e-05\n",
            "hidden layer sizes: [22, 29, 14, 26], total neurons: 91\n",
            "##########################################################\n",
            "Epoch 39/40\n",
            "Before growing:\n",
            "loss: 0.05020860582590103 - accuracy: 0.983214259147644 - val_loss: 0.3191058933734894 - val_accuracy: 0.9080555438995361 - penalty: 1e-05\n",
            "hidden layer sizes: [22, 29, 14, 26], total neurons: 91\n",
            "After growing:\n",
            "loss: 0.05020861700177193 - accuracy: 0.983214259147644 - val_loss: 0.31910598278045654 - val_accuracy: 0.9080555438995361 - penalty: 1e-05\n",
            "hidden layer sizes: [122, 129, 114, 126], total neurons: 491\n",
            "Before pruning:\n",
            "loss: 0.04737849161028862 - accuracy: 0.9842857122421265 - val_loss: 0.3309377431869507 - val_accuracy: 0.9047222137451172 - penalty: 1e-05\n",
            "hidden layer sizes: [122, 129, 114, 126], total neurons: 491\n",
            "After pruning:\n",
            "loss: 0.04765888676047325 - accuracy: 0.9838095307350159 - val_loss: 0.33104267716407776 - val_accuracy: 0.9044444561004639 - penalty: 1e-05\n",
            "hidden layer sizes: [29, 32, 13, 59], total neurons: 133\n",
            "##########################################################\n",
            "Epoch 40/40\n",
            "Before growing:\n",
            "loss: 0.04765888676047325 - accuracy: 0.9838095307350159 - val_loss: 0.33104267716407776 - val_accuracy: 0.9044444561004639 - penalty: 1e-05\n",
            "hidden layer sizes: [29, 32, 13, 59], total neurons: 133\n",
            "After growing:\n",
            "loss: 0.04765887185931206 - accuracy: 0.9838095307350159 - val_loss: 0.33104270696640015 - val_accuracy: 0.9044444561004639 - penalty: 1e-05\n",
            "hidden layer sizes: [129, 132, 113, 159], total neurons: 533\n",
            "Before pruning:\n",
            "loss: 0.04021686315536499 - accuracy: 0.9884523749351501 - val_loss: 0.32102343440055847 - val_accuracy: 0.9072222113609314 - penalty: 1e-05\n",
            "hidden layer sizes: [129, 132, 113, 159], total neurons: 533\n",
            "After pruning:\n",
            "loss: 0.04013022780418396 - accuracy: 0.988095223903656 - val_loss: 0.3203713595867157 - val_accuracy: 0.9080555438995361 - penalty: 1e-05\n",
            "hidden layer sizes: [30, 33, 13, 42], total neurons: 118\n",
            "CPU times: user 2min 36s, sys: 2.03 s, total: 2min 39s\n",
            "Wall time: 2min 38s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCJOKll6UeEC",
        "outputId": "41c6add3-cfd3-4bea-c9d8-90c515a64a1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(112 + 114 + 91 + 133 + 118) / 5"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "113.6"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nxw4lZFcT4E1",
        "outputId": "580059bd-fa6c-43b4-dd70-124fc6d49832",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "epochs = 5\n",
        "self_scaling_epochs = 5\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##########################################################\n",
            "Epoch 1/5\n",
            "Before growing:\n",
            "loss: 12.513557434082031 - accuracy: 0.19273999333381653 - val_loss: 12.51563549041748 - val_accuracy: 0.1932000070810318 - penalty: 1e-05\n",
            "hidden layer sizes: [30, 33, 13, 42], total neurons: 118\n",
            "After growing:\n",
            "loss: 12.51356029510498 - accuracy: 0.19273999333381653 - val_loss: 12.515637397766113 - val_accuracy: 0.1932000070810318 - penalty: 1e-05\n",
            "hidden layer sizes: [130, 133, 113, 142], total neurons: 518\n",
            "Before pruning:\n",
            "loss: 1.7758828401565552 - accuracy: 0.32624000310897827 - val_loss: 1.7807749509811401 - val_accuracy: 0.3278000056743622 - penalty: 1e-05\n",
            "hidden layer sizes: [130, 133, 113, 142], total neurons: 518\n",
            "After pruning:\n",
            "loss: 1.776384949684143 - accuracy: 0.32627999782562256 - val_loss: 1.7815121412277222 - val_accuracy: 0.32679998874664307 - penalty: 1e-05\n",
            "hidden layer sizes: [34, 132, 97, 131], total neurons: 394\n",
            "##########################################################\n",
            "Epoch 2/5\n",
            "Before growing:\n",
            "loss: 1.776384949684143 - accuracy: 0.32627999782562256 - val_loss: 1.7815121412277222 - val_accuracy: 0.32679998874664307 - penalty: 1e-05\n",
            "hidden layer sizes: [34, 132, 97, 131], total neurons: 394\n",
            "After growing:\n",
            "loss: 1.7763853073120117 - accuracy: 0.32627999782562256 - val_loss: 1.7815124988555908 - val_accuracy: 0.32679998874664307 - penalty: 1e-05\n",
            "hidden layer sizes: [134, 232, 197, 231], total neurons: 794\n",
            "Before pruning:\n",
            "loss: 1.6303637027740479 - accuracy: 0.4011400043964386 - val_loss: 1.6348861455917358 - val_accuracy: 0.3971000015735626 - penalty: 1e-05\n",
            "hidden layer sizes: [134, 232, 197, 231], total neurons: 794\n",
            "After pruning:\n",
            "loss: 1.6299527883529663 - accuracy: 0.40143999457359314 - val_loss: 1.6344599723815918 - val_accuracy: 0.39739999175071716 - penalty: 1e-05\n",
            "hidden layer sizes: [27, 110, 58, 105], total neurons: 300\n",
            "##########################################################\n",
            "Epoch 3/5\n",
            "Before growing:\n",
            "loss: 1.6299527883529663 - accuracy: 0.40143999457359314 - val_loss: 1.6344599723815918 - val_accuracy: 0.39739999175071716 - penalty: 1e-05\n",
            "hidden layer sizes: [27, 110, 58, 105], total neurons: 300\n",
            "After growing:\n",
            "loss: 1.6299527883529663 - accuracy: 0.40143999457359314 - val_loss: 1.6344599723815918 - val_accuracy: 0.39739999175071716 - penalty: 1e-05\n",
            "hidden layer sizes: [127, 210, 158, 205], total neurons: 700\n",
            "Before pruning:\n",
            "loss: 1.5553159713745117 - accuracy: 0.43248000741004944 - val_loss: 1.5709236860275269 - val_accuracy: 0.4275999963283539 - penalty: 1e-05\n",
            "hidden layer sizes: [127, 210, 158, 205], total neurons: 700\n",
            "After pruning:\n",
            "loss: 1.555314064025879 - accuracy: 0.4325000047683716 - val_loss: 1.5709097385406494 - val_accuracy: 0.42809998989105225 - penalty: 1e-05\n",
            "hidden layer sizes: [27, 92, 48, 95], total neurons: 262\n",
            "##########################################################\n",
            "Epoch 4/5\n",
            "Before growing:\n",
            "loss: 1.555314064025879 - accuracy: 0.4325000047683716 - val_loss: 1.5709097385406494 - val_accuracy: 0.42809998989105225 - penalty: 1e-05\n",
            "hidden layer sizes: [27, 92, 48, 95], total neurons: 262\n",
            "After growing:\n",
            "loss: 1.5553144216537476 - accuracy: 0.4325000047683716 - val_loss: 1.5709099769592285 - val_accuracy: 0.42809998989105225 - penalty: 1e-05\n",
            "hidden layer sizes: [127, 192, 148, 195], total neurons: 662\n",
            "Before pruning:\n",
            "loss: 1.517547845840454 - accuracy: 0.44624000787734985 - val_loss: 1.545390248298645 - val_accuracy: 0.4392000138759613 - penalty: 1e-05\n",
            "hidden layer sizes: [127, 192, 148, 195], total neurons: 662\n",
            "After pruning:\n",
            "loss: 1.517514705657959 - accuracy: 0.44642001390457153 - val_loss: 1.5453683137893677 - val_accuracy: 0.4390999972820282 - penalty: 1e-05\n",
            "hidden layer sizes: [26, 80, 41, 89], total neurons: 236\n",
            "##########################################################\n",
            "Epoch 5/5\n",
            "Before growing:\n",
            "loss: 1.517514705657959 - accuracy: 0.44642001390457153 - val_loss: 1.5453683137893677 - val_accuracy: 0.4390999972820282 - penalty: 1e-05\n",
            "hidden layer sizes: [26, 80, 41, 89], total neurons: 236\n",
            "After growing:\n",
            "loss: 1.5175145864486694 - accuracy: 0.44642001390457153 - val_loss: 1.5453680753707886 - val_accuracy: 0.4390999972820282 - penalty: 1e-05\n",
            "hidden layer sizes: [126, 180, 141, 189], total neurons: 636\n",
            "Before pruning:\n",
            "loss: 1.4875918626785278 - accuracy: 0.4587799906730652 - val_loss: 1.52324378490448 - val_accuracy: 0.445499986410141 - penalty: 1e-05\n",
            "hidden layer sizes: [126, 180, 141, 189], total neurons: 636\n",
            "After pruning:\n",
            "loss: 1.4876476526260376 - accuracy: 0.458979994058609 - val_loss: 1.5232874155044556 - val_accuracy: 0.44589999318122864 - penalty: 1e-05\n",
            "hidden layer sizes: [24, 72, 37, 96], total neurons: 229\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.32627999782562256,\n",
              "  0.40143999457359314,\n",
              "  0.4325000047683716,\n",
              "  0.44642001390457153,\n",
              "  0.458979994058609],\n",
              " 'loss': [1.776384949684143,\n",
              "  1.6299527883529663,\n",
              "  1.555314064025879,\n",
              "  1.517514705657959,\n",
              "  1.4876476526260376],\n",
              " 'val_accuracy': [0.32679998874664307,\n",
              "  0.39739999175071716,\n",
              "  0.42809998989105225,\n",
              "  0.4390999972820282,\n",
              "  0.44589999318122864],\n",
              " 'val_loss': [1.7815121412277222,\n",
              "  1.6344599723815918,\n",
              "  1.5709097385406494,\n",
              "  1.5453683137893677,\n",
              "  1.5232874155044556]}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiQZ8JxwUJM3",
        "outputId": "232e40e0-c260-4241-efcf-8277d14fe2d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "epochs = 5\n",
        "self_scaling_epochs = 5\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##########################################################\n",
            "Epoch 1/5\n",
            "Before growing:\n",
            "loss: 1.4876476526260376 - accuracy: 0.458979994058609 - val_loss: 1.5232874155044556 - val_accuracy: 0.44589999318122864 - penalty: 1e-05\n",
            "hidden layer sizes: [24, 72, 37, 96], total neurons: 229\n",
            "After growing:\n",
            "loss: 1.4876477718353271 - accuracy: 0.458979994058609 - val_loss: 1.523287296295166 - val_accuracy: 0.44589999318122864 - penalty: 1e-05\n",
            "hidden layer sizes: [124, 172, 137, 196], total neurons: 629\n",
            "Before pruning:\n",
            "loss: 1.4724597930908203 - accuracy: 0.4686799943447113 - val_loss: 1.5190184116363525 - val_accuracy: 0.4507000148296356 - penalty: 1e-05\n",
            "hidden layer sizes: [124, 172, 137, 196], total neurons: 629\n",
            "After pruning:\n",
            "loss: 1.4726018905639648 - accuracy: 0.4686200022697449 - val_loss: 1.5191874504089355 - val_accuracy: 0.4503999948501587 - penalty: 1e-05\n",
            "hidden layer sizes: [31, 68, 35, 93], total neurons: 227\n",
            "##########################################################\n",
            "Epoch 2/5\n",
            "Before growing:\n",
            "loss: 1.4726018905639648 - accuracy: 0.4686200022697449 - val_loss: 1.5191874504089355 - val_accuracy: 0.4503999948501587 - penalty: 1e-05\n",
            "hidden layer sizes: [31, 68, 35, 93], total neurons: 227\n",
            "After growing:\n",
            "loss: 1.472601294517517 - accuracy: 0.46860000491142273 - val_loss: 1.5191869735717773 - val_accuracy: 0.4503999948501587 - penalty: 1e-05\n",
            "hidden layer sizes: [131, 168, 135, 193], total neurons: 627\n",
            "Before pruning:\n",
            "loss: 1.4466887712478638 - accuracy: 0.47909998893737793 - val_loss: 1.5029066801071167 - val_accuracy: 0.45159998536109924 - penalty: 1e-05\n",
            "hidden layer sizes: [131, 168, 135, 193], total neurons: 627\n",
            "After pruning:\n",
            "loss: 1.446529746055603 - accuracy: 0.4791800081729889 - val_loss: 1.502846598625183 - val_accuracy: 0.45179998874664307 - penalty: 1e-05\n",
            "hidden layer sizes: [22, 64, 30, 86], total neurons: 202\n",
            "##########################################################\n",
            "Epoch 3/5\n",
            "Before growing:\n",
            "loss: 1.446529746055603 - accuracy: 0.4791800081729889 - val_loss: 1.502846598625183 - val_accuracy: 0.45179998874664307 - penalty: 1e-05\n",
            "hidden layer sizes: [22, 64, 30, 86], total neurons: 202\n",
            "After growing:\n",
            "loss: 1.446529746055603 - accuracy: 0.4791800081729889 - val_loss: 1.5028467178344727 - val_accuracy: 0.45179998874664307 - penalty: 1e-05\n",
            "hidden layer sizes: [122, 164, 130, 186], total neurons: 602\n",
            "Before pruning:\n",
            "loss: 1.435104489326477 - accuracy: 0.48142001032829285 - val_loss: 1.4982284307479858 - val_accuracy: 0.45719999074935913 - penalty: 1e-05\n",
            "hidden layer sizes: [122, 164, 130, 186], total neurons: 602\n",
            "After pruning:\n",
            "loss: 1.4349040985107422 - accuracy: 0.4816800057888031 - val_loss: 1.4980697631835938 - val_accuracy: 0.4577000141143799 - penalty: 1e-05\n",
            "hidden layer sizes: [25, 63, 29, 84], total neurons: 201\n",
            "##########################################################\n",
            "Epoch 4/5\n",
            "Before growing:\n",
            "loss: 1.4349040985107422 - accuracy: 0.4816800057888031 - val_loss: 1.4980697631835938 - val_accuracy: 0.4577000141143799 - penalty: 1e-05\n",
            "hidden layer sizes: [25, 63, 29, 84], total neurons: 201\n",
            "After growing:\n",
            "loss: 1.4349042177200317 - accuracy: 0.4816800057888031 - val_loss: 1.4980697631835938 - val_accuracy: 0.4577000141143799 - penalty: 1e-05\n",
            "hidden layer sizes: [125, 163, 129, 184], total neurons: 601\n",
            "Before pruning:\n",
            "loss: 1.4204931259155273 - accuracy: 0.4877600073814392 - val_loss: 1.4919434785842896 - val_accuracy: 0.4546000063419342 - penalty: 1e-05\n",
            "hidden layer sizes: [125, 163, 129, 184], total neurons: 601\n",
            "After pruning:\n",
            "loss: 1.4203665256500244 - accuracy: 0.48774001002311707 - val_loss: 1.491937279701233 - val_accuracy: 0.454800009727478 - penalty: 1e-05\n",
            "hidden layer sizes: [23, 62, 33, 89], total neurons: 207\n",
            "##########################################################\n",
            "Epoch 5/5\n",
            "Before growing:\n",
            "loss: 1.4203665256500244 - accuracy: 0.48774001002311707 - val_loss: 1.491937279701233 - val_accuracy: 0.454800009727478 - penalty: 1e-05\n",
            "hidden layer sizes: [23, 62, 33, 89], total neurons: 207\n",
            "After growing:\n",
            "loss: 1.4203665256500244 - accuracy: 0.48774001002311707 - val_loss: 1.491937518119812 - val_accuracy: 0.454800009727478 - penalty: 1e-05\n",
            "hidden layer sizes: [123, 162, 133, 189], total neurons: 607\n",
            "Before pruning:\n",
            "loss: 1.4120324850082397 - accuracy: 0.48969998955726624 - val_loss: 1.4868528842926025 - val_accuracy: 0.45840001106262207 - penalty: 1e-05\n",
            "hidden layer sizes: [123, 162, 133, 189], total neurons: 607\n",
            "After pruning:\n",
            "loss: 1.4123131036758423 - accuracy: 0.4894599914550781 - val_loss: 1.487076997756958 - val_accuracy: 0.45829999446868896 - penalty: 1e-05\n",
            "hidden layer sizes: [20, 59, 28, 90], total neurons: 197\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.4686200022697449,\n",
              "  0.4791800081729889,\n",
              "  0.4816800057888031,\n",
              "  0.48774001002311707,\n",
              "  0.4894599914550781],\n",
              " 'loss': [1.4726018905639648,\n",
              "  1.446529746055603,\n",
              "  1.4349040985107422,\n",
              "  1.4203665256500244,\n",
              "  1.4123131036758423],\n",
              " 'val_accuracy': [0.4503999948501587,\n",
              "  0.45179998874664307,\n",
              "  0.4577000141143799,\n",
              "  0.454800009727478,\n",
              "  0.45829999446868896],\n",
              " 'val_loss': [1.5191874504089355,\n",
              "  1.502846598625183,\n",
              "  1.4980697631835938,\n",
              "  1.491937279701233,\n",
              "  1.487076997756958]}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG4Rb8C7aWuc"
      },
      "source": [
        "epochs = 20\n",
        "self_scaling_epochs = 20\n",
        "batch_size = 32\n",
        "min_new_neurons = 100"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkO7ZdKgadp3",
        "outputId": "fbadc630-45b5-4019-ad50-946a8ceda165",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model = SSModel(layer_sizes=[3072, 4000, 4000, 4000, 4000, 10], activation='selu', regularization_penalty=0.0000001, \n",
        "                regularization_method='weighted_l1', kernel_initializer='lecun_normal')\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_norm_automobiles_dogs_train, y_automobiles_dogs_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_norm_automobiles_dogs_test, y_automobiles_dogs_test))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "Before growing:\n",
            "loss: 2.711106538772583 - accuracy: 0.09107142686843872 - val_loss: 2.7317590713500977 - val_accuracy: 0.09361111372709274 - penalty: 1e-07\n",
            "hidden layer sizes: [4000, 4000, 4000, 4000], total neurons: 16000\n",
            "After growing:\n",
            "loss: 2.711106777191162 - accuracy: 0.09107142686843872 - val_loss: 2.7317588329315186 - val_accuracy: 0.09361111372709274 - penalty: 1e-07\n",
            "hidden layer sizes: [4800, 4800, 4800, 4800], total neurons: 19200\n",
            "Before pruning:\n",
            "loss: 0.34226396679878235 - accuracy: 0.8897619247436523 - val_loss: 0.44591420888900757 - val_accuracy: 0.8700000047683716 - penalty: 1e-07\n",
            "hidden layer sizes: [4800, 4800, 4800, 4800], total neurons: 19200\n",
            "After pruning:\n",
            "loss: 0.34194567799568176 - accuracy: 0.8899999856948853 - val_loss: 0.44576242566108704 - val_accuracy: 0.8711110949516296 - penalty: 1e-07\n",
            "hidden layer sizes: [4000, 4000, 4015, 4008], total neurons: 16023\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "Before growing:\n",
            "loss: 0.34194567799568176 - accuracy: 0.8899999856948853 - val_loss: 0.44576242566108704 - val_accuracy: 0.8711110949516296 - penalty: 1e-07\n",
            "hidden layer sizes: [4000, 4000, 4015, 4008], total neurons: 16023\n",
            "After growing:\n",
            "loss: 0.34194567799568176 - accuracy: 0.8899999856948853 - val_loss: 0.4457624852657318 - val_accuracy: 0.8711110949516296 - penalty: 1e-07\n",
            "hidden layer sizes: [4800, 4800, 4818, 4809], total neurons: 19227\n",
            "Before pruning:\n",
            "loss: 0.26667335629463196 - accuracy: 0.8948809504508972 - val_loss: 0.31894269585609436 - val_accuracy: 0.8713889122009277 - penalty: 1e-07\n",
            "hidden layer sizes: [4800, 4800, 4818, 4809], total neurons: 19227\n",
            "After pruning:\n",
            "loss: 0.26667657494544983 - accuracy: 0.8949999809265137 - val_loss: 0.319049209356308 - val_accuracy: 0.8711110949516296 - penalty: 1e-07\n",
            "hidden layer sizes: [3956, 3820, 3987, 3856], total neurons: 15619\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "Before growing:\n",
            "loss: 0.26667657494544983 - accuracy: 0.8949999809265137 - val_loss: 0.319049209356308 - val_accuracy: 0.8711110949516296 - penalty: 1e-07\n",
            "hidden layer sizes: [3956, 3820, 3987, 3856], total neurons: 15619\n",
            "After growing:\n",
            "loss: 0.26667657494544983 - accuracy: 0.8949999809265137 - val_loss: 0.319049209356308 - val_accuracy: 0.8711110949516296 - penalty: 1e-07\n",
            "hidden layer sizes: [4747, 4584, 4784, 4627], total neurons: 18742\n",
            "Before pruning:\n",
            "loss: 0.2675943374633789 - accuracy: 0.8894047737121582 - val_loss: 0.31834879517555237 - val_accuracy: 0.8725000023841858 - penalty: 1e-07\n",
            "hidden layer sizes: [4747, 4584, 4784, 4627], total neurons: 18742\n",
            "After pruning:\n",
            "loss: 0.26740124821662903 - accuracy: 0.8896428346633911 - val_loss: 0.3177524507045746 - val_accuracy: 0.8725000023841858 - penalty: 1e-07\n",
            "hidden layer sizes: [2081, 1884, 2507, 3076], total neurons: 9548\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "Before growing:\n",
            "loss: 0.26740124821662903 - accuracy: 0.8896428346633911 - val_loss: 0.3177524507045746 - val_accuracy: 0.8725000023841858 - penalty: 1e-07\n",
            "hidden layer sizes: [2081, 1884, 2507, 3076], total neurons: 9548\n",
            "After growing:\n",
            "loss: 0.26740124821662903 - accuracy: 0.8896428346633911 - val_loss: 0.3177524507045746 - val_accuracy: 0.8725000023841858 - penalty: 1e-07\n",
            "hidden layer sizes: [2497, 2260, 3008, 3691], total neurons: 11456\n",
            "Before pruning:\n",
            "loss: 0.23015987873077393 - accuracy: 0.9075000286102295 - val_loss: 0.2957915961742401 - val_accuracy: 0.879444420337677 - penalty: 1e-07\n",
            "hidden layer sizes: [2497, 2260, 3008, 3691], total neurons: 11456\n",
            "After pruning:\n",
            "loss: 0.23011352121829987 - accuracy: 0.9075000286102295 - val_loss: 0.29584673047065735 - val_accuracy: 0.878333330154419 - penalty: 1e-07\n",
            "hidden layer sizes: [836, 1038, 1079, 1638], total neurons: 4591\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "Before growing:\n",
            "loss: 0.23011352121829987 - accuracy: 0.9075000286102295 - val_loss: 0.29584673047065735 - val_accuracy: 0.878333330154419 - penalty: 1e-07\n",
            "hidden layer sizes: [836, 1038, 1079, 1638], total neurons: 4591\n",
            "After growing:\n",
            "loss: 0.23011352121829987 - accuracy: 0.9075000286102295 - val_loss: 0.29584673047065735 - val_accuracy: 0.878333330154419 - penalty: 1e-07\n",
            "hidden layer sizes: [1003, 1245, 1294, 1965], total neurons: 5507\n",
            "Before pruning:\n",
            "loss: 0.1877242773771286 - accuracy: 0.9264285564422607 - val_loss: 0.2808976471424103 - val_accuracy: 0.8899999856948853 - penalty: 1e-07\n",
            "hidden layer sizes: [1003, 1245, 1294, 1965], total neurons: 5507\n",
            "After pruning:\n",
            "loss: 0.18761566281318665 - accuracy: 0.9264285564422607 - val_loss: 0.280710905790329 - val_accuracy: 0.8899999856948853 - penalty: 1e-07\n",
            "hidden layer sizes: [585, 989, 710, 1179], total neurons: 3463\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "Before growing:\n",
            "loss: 0.18761566281318665 - accuracy: 0.9264285564422607 - val_loss: 0.280710905790329 - val_accuracy: 0.8899999856948853 - penalty: 1e-07\n",
            "hidden layer sizes: [585, 989, 710, 1179], total neurons: 3463\n",
            "After growing:\n",
            "loss: 0.18761567771434784 - accuracy: 0.9264285564422607 - val_loss: 0.280710905790329 - val_accuracy: 0.8899999856948853 - penalty: 1e-07\n",
            "hidden layer sizes: [702, 1186, 852, 1414], total neurons: 4154\n",
            "Before pruning:\n",
            "loss: 0.1682083010673523 - accuracy: 0.9354761838912964 - val_loss: 0.25056108832359314 - val_accuracy: 0.9027777910232544 - penalty: 1e-07\n",
            "hidden layer sizes: [702, 1186, 852, 1414], total neurons: 4154\n",
            "After pruning:\n",
            "loss: 0.16857461631298065 - accuracy: 0.9348809719085693 - val_loss: 0.25089454650878906 - val_accuracy: 0.9030555486679077 - penalty: 1e-07\n",
            "hidden layer sizes: [413, 772, 578, 928], total neurons: 2691\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "Before growing:\n",
            "loss: 0.16857461631298065 - accuracy: 0.9348809719085693 - val_loss: 0.25089454650878906 - val_accuracy: 0.9030555486679077 - penalty: 1e-07\n",
            "hidden layer sizes: [413, 772, 578, 928], total neurons: 2691\n",
            "After growing:\n",
            "loss: 0.16857460141181946 - accuracy: 0.9348809719085693 - val_loss: 0.25089454650878906 - val_accuracy: 0.9030555486679077 - penalty: 1e-07\n",
            "hidden layer sizes: [513, 926, 693, 1113], total neurons: 3245\n",
            "Before pruning:\n",
            "loss: 0.1475975662469864 - accuracy: 0.9485714435577393 - val_loss: 0.2476041167974472 - val_accuracy: 0.8974999785423279 - penalty: 1e-07\n",
            "hidden layer sizes: [513, 926, 693, 1113], total neurons: 3245\n",
            "After pruning:\n",
            "loss: 0.1475650817155838 - accuracy: 0.948452353477478 - val_loss: 0.2475200593471527 - val_accuracy: 0.897777795791626 - penalty: 1e-07\n",
            "hidden layer sizes: [357, 852, 499, 716], total neurons: 2424\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "Before growing:\n",
            "loss: 0.1475650817155838 - accuracy: 0.948452353477478 - val_loss: 0.2475200593471527 - val_accuracy: 0.897777795791626 - penalty: 1e-07\n",
            "hidden layer sizes: [357, 852, 499, 716], total neurons: 2424\n",
            "After growing:\n",
            "loss: 0.1475650519132614 - accuracy: 0.948452353477478 - val_loss: 0.24751999974250793 - val_accuracy: 0.897777795791626 - penalty: 1e-07\n",
            "hidden layer sizes: [457, 1022, 599, 859], total neurons: 2937\n",
            "Before pruning:\n",
            "loss: 0.13216139376163483 - accuracy: 0.950952410697937 - val_loss: 0.2730575203895569 - val_accuracy: 0.8994444608688354 - penalty: 1e-07\n",
            "hidden layer sizes: [457, 1022, 599, 859], total neurons: 2937\n",
            "After pruning:\n",
            "loss: 0.13215483725070953 - accuracy: 0.9510714411735535 - val_loss: 0.27305179834365845 - val_accuracy: 0.8991666436195374 - penalty: 1e-07\n",
            "hidden layer sizes: [327, 601, 411, 638], total neurons: 1977\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "Before growing:\n",
            "loss: 0.13215483725070953 - accuracy: 0.9510714411735535 - val_loss: 0.27305179834365845 - val_accuracy: 0.8991666436195374 - penalty: 1e-07\n",
            "hidden layer sizes: [327, 601, 411, 638], total neurons: 1977\n",
            "After growing:\n",
            "loss: 0.13215488195419312 - accuracy: 0.9510714411735535 - val_loss: 0.2730517089366913 - val_accuracy: 0.8991666436195374 - penalty: 1e-07\n",
            "hidden layer sizes: [427, 721, 511, 765], total neurons: 2424\n",
            "Before pruning:\n",
            "loss: 0.11029554158449173 - accuracy: 0.9602380990982056 - val_loss: 0.27501726150512695 - val_accuracy: 0.9069444537162781 - penalty: 1e-07\n",
            "hidden layer sizes: [427, 721, 511, 765], total neurons: 2424\n",
            "After pruning:\n",
            "loss: 0.11029436439275742 - accuracy: 0.9602380990982056 - val_loss: 0.27498820424079895 - val_accuracy: 0.9069444537162781 - penalty: 1e-07\n",
            "hidden layer sizes: [405, 715, 508, 681], total neurons: 2309\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "Before growing:\n",
            "loss: 0.11029436439275742 - accuracy: 0.9602380990982056 - val_loss: 0.27498820424079895 - val_accuracy: 0.9069444537162781 - penalty: 1e-07\n",
            "hidden layer sizes: [405, 715, 508, 681], total neurons: 2309\n",
            "After growing:\n",
            "loss: 0.11029435694217682 - accuracy: 0.9602380990982056 - val_loss: 0.27498820424079895 - val_accuracy: 0.9069444537162781 - penalty: 1e-07\n",
            "hidden layer sizes: [505, 858, 609, 817], total neurons: 2789\n",
            "Before pruning:\n",
            "loss: 0.10268112272024155 - accuracy: 0.9634523987770081 - val_loss: 0.23362022638320923 - val_accuracy: 0.9119444489479065 - penalty: 1e-07\n",
            "hidden layer sizes: [505, 858, 609, 817], total neurons: 2789\n",
            "After pruning:\n",
            "loss: 0.10267391800880432 - accuracy: 0.9634523987770081 - val_loss: 0.23362402617931366 - val_accuracy: 0.9119444489479065 - penalty: 1e-07\n",
            "hidden layer sizes: [320, 583, 432, 628], total neurons: 1963\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "Before growing:\n",
            "loss: 0.10267391800880432 - accuracy: 0.9634523987770081 - val_loss: 0.23362402617931366 - val_accuracy: 0.9119444489479065 - penalty: 1e-07\n",
            "hidden layer sizes: [320, 583, 432, 628], total neurons: 1963\n",
            "After growing:\n",
            "loss: 0.10267391800880432 - accuracy: 0.9634523987770081 - val_loss: 0.23362398147583008 - val_accuracy: 0.9119444489479065 - penalty: 1e-07\n",
            "hidden layer sizes: [420, 699, 532, 753], total neurons: 2404\n",
            "Before pruning:\n",
            "loss: 0.09360021352767944 - accuracy: 0.9680952429771423 - val_loss: 0.2562810182571411 - val_accuracy: 0.9094444513320923 - penalty: 1e-07\n",
            "hidden layer sizes: [420, 699, 532, 753], total neurons: 2404\n",
            "After pruning:\n",
            "loss: 0.09358330070972443 - accuracy: 0.9679762125015259 - val_loss: 0.25613337755203247 - val_accuracy: 0.9094444513320923 - penalty: 1e-07\n",
            "hidden layer sizes: [314, 605, 325, 481], total neurons: 1725\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "Before growing:\n",
            "loss: 0.09358330070972443 - accuracy: 0.9679762125015259 - val_loss: 0.25613337755203247 - val_accuracy: 0.9094444513320923 - penalty: 1e-07\n",
            "hidden layer sizes: [314, 605, 325, 481], total neurons: 1725\n",
            "After growing:\n",
            "loss: 0.09358330070972443 - accuracy: 0.9679762125015259 - val_loss: 0.2561333477497101 - val_accuracy: 0.9094444513320923 - penalty: 1e-07\n",
            "hidden layer sizes: [414, 726, 425, 581], total neurons: 2146\n",
            "Before pruning:\n",
            "loss: 0.07671479135751724 - accuracy: 0.9748809337615967 - val_loss: 0.2573225796222687 - val_accuracy: 0.9108333587646484 - penalty: 1e-07\n",
            "hidden layer sizes: [414, 726, 425, 581], total neurons: 2146\n",
            "After pruning:\n",
            "loss: 0.07676566392183304 - accuracy: 0.9748809337615967 - val_loss: 0.25733742117881775 - val_accuracy: 0.9108333587646484 - penalty: 1e-07\n",
            "hidden layer sizes: [290, 521, 274, 356], total neurons: 1441\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "Before growing:\n",
            "loss: 0.07676566392183304 - accuracy: 0.9748809337615967 - val_loss: 0.25733742117881775 - val_accuracy: 0.9108333587646484 - penalty: 1e-07\n",
            "hidden layer sizes: [290, 521, 274, 356], total neurons: 1441\n",
            "After growing:\n",
            "loss: 0.07676564902067184 - accuracy: 0.9748809337615967 - val_loss: 0.25733745098114014 - val_accuracy: 0.9108333587646484 - penalty: 1e-07\n",
            "hidden layer sizes: [390, 625, 374, 456], total neurons: 1845\n",
            "Before pruning:\n",
            "loss: 0.09149594604969025 - accuracy: 0.9647619128227234 - val_loss: 0.30458709597587585 - val_accuracy: 0.9005555510520935 - penalty: 1e-07\n",
            "hidden layer sizes: [390, 625, 374, 456], total neurons: 1845\n",
            "After pruning:\n",
            "loss: 0.0914701521396637 - accuracy: 0.9647619128227234 - val_loss: 0.304567813873291 - val_accuracy: 0.9008333086967468 - penalty: 1e-07\n",
            "hidden layer sizes: [325, 623, 373, 456], total neurons: 1777\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "Before growing:\n",
            "loss: 0.0914701521396637 - accuracy: 0.9647619128227234 - val_loss: 0.304567813873291 - val_accuracy: 0.9008333086967468 - penalty: 1e-07\n",
            "hidden layer sizes: [325, 623, 373, 456], total neurons: 1777\n",
            "After growing:\n",
            "loss: 0.0914701446890831 - accuracy: 0.9647619128227234 - val_loss: 0.3045678734779358 - val_accuracy: 0.9008333086967468 - penalty: 1e-07\n",
            "hidden layer sizes: [425, 747, 473, 556], total neurons: 2201\n",
            "Before pruning:\n",
            "loss: 0.0681850016117096 - accuracy: 0.9769047498703003 - val_loss: 0.2972075641155243 - val_accuracy: 0.9122222065925598 - penalty: 1e-07\n",
            "hidden layer sizes: [425, 747, 473, 556], total neurons: 2201\n",
            "After pruning:\n",
            "loss: 0.0681818351149559 - accuracy: 0.9769047498703003 - val_loss: 0.2971939444541931 - val_accuracy: 0.9122222065925598 - penalty: 1e-07\n",
            "hidden layer sizes: [283, 683, 312, 434], total neurons: 1712\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "Before growing:\n",
            "loss: 0.0681818351149559 - accuracy: 0.9769047498703003 - val_loss: 0.2971939444541931 - val_accuracy: 0.9122222065925598 - penalty: 1e-07\n",
            "hidden layer sizes: [283, 683, 312, 434], total neurons: 1712\n",
            "After growing:\n",
            "loss: 0.0681818351149559 - accuracy: 0.9769047498703003 - val_loss: 0.2971939742565155 - val_accuracy: 0.9122222065925598 - penalty: 1e-07\n",
            "hidden layer sizes: [383, 819, 412, 534], total neurons: 2148\n",
            "Before pruning:\n",
            "loss: 0.05148258060216904 - accuracy: 0.9839285612106323 - val_loss: 0.27574068307876587 - val_accuracy: 0.918055534362793 - penalty: 1e-07\n",
            "hidden layer sizes: [383, 819, 412, 534], total neurons: 2148\n",
            "After pruning:\n",
            "loss: 0.051500141620635986 - accuracy: 0.9839285612106323 - val_loss: 0.275739848613739 - val_accuracy: 0.918055534362793 - penalty: 1e-07\n",
            "hidden layer sizes: [321, 591, 319, 407], total neurons: 1638\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "Before growing:\n",
            "loss: 0.051500141620635986 - accuracy: 0.9839285612106323 - val_loss: 0.275739848613739 - val_accuracy: 0.918055534362793 - penalty: 1e-07\n",
            "hidden layer sizes: [321, 591, 319, 407], total neurons: 1638\n",
            "After growing:\n",
            "loss: 0.05150013044476509 - accuracy: 0.9839285612106323 - val_loss: 0.27573999762535095 - val_accuracy: 0.918055534362793 - penalty: 1e-07\n",
            "hidden layer sizes: [421, 709, 419, 507], total neurons: 2056\n",
            "Before pruning:\n",
            "loss: 0.039661306887865067 - accuracy: 0.9870238304138184 - val_loss: 0.30375197529792786 - val_accuracy: 0.9144444465637207 - penalty: 1e-07\n",
            "hidden layer sizes: [421, 709, 419, 507], total neurons: 2056\n",
            "After pruning:\n",
            "loss: 0.03966761380434036 - accuracy: 0.9870238304138184 - val_loss: 0.30370619893074036 - val_accuracy: 0.9144444465637207 - penalty: 1e-07\n",
            "hidden layer sizes: [332, 571, 240, 364], total neurons: 1507\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "Before growing:\n",
            "loss: 0.03966761380434036 - accuracy: 0.9870238304138184 - val_loss: 0.30370619893074036 - val_accuracy: 0.9144444465637207 - penalty: 1e-07\n",
            "hidden layer sizes: [332, 571, 240, 364], total neurons: 1507\n",
            "After growing:\n",
            "loss: 0.03966762125492096 - accuracy: 0.9870238304138184 - val_loss: 0.30370616912841797 - val_accuracy: 0.9144444465637207 - penalty: 1e-07\n",
            "hidden layer sizes: [432, 685, 340, 464], total neurons: 1921\n",
            "Before pruning:\n",
            "loss: 0.05630123242735863 - accuracy: 0.9794047474861145 - val_loss: 0.3252764642238617 - val_accuracy: 0.9088888764381409 - penalty: 1e-07\n",
            "hidden layer sizes: [432, 685, 340, 464], total neurons: 1921\n",
            "After pruning:\n",
            "loss: 0.05628971755504608 - accuracy: 0.9795238375663757 - val_loss: 0.3252435028553009 - val_accuracy: 0.9088888764381409 - penalty: 1e-07\n",
            "hidden layer sizes: [328, 677, 340, 442], total neurons: 1787\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "Before growing:\n",
            "loss: 0.05628971755504608 - accuracy: 0.9795238375663757 - val_loss: 0.3252435028553009 - val_accuracy: 0.9088888764381409 - penalty: 1e-07\n",
            "hidden layer sizes: [328, 677, 340, 442], total neurons: 1787\n",
            "After growing:\n",
            "loss: 0.05628974363207817 - accuracy: 0.9795238375663757 - val_loss: 0.3252437114715576 - val_accuracy: 0.9088888764381409 - penalty: 1e-07\n",
            "hidden layer sizes: [428, 812, 440, 542], total neurons: 2222\n",
            "Before pruning:\n",
            "loss: 0.03970155119895935 - accuracy: 0.9859523773193359 - val_loss: 0.3384503424167633 - val_accuracy: 0.913611114025116 - penalty: 1e-07\n",
            "hidden layer sizes: [428, 812, 440, 542], total neurons: 2222\n",
            "After pruning:\n",
            "loss: 0.03966792672872543 - accuracy: 0.9859523773193359 - val_loss: 0.33850210905075073 - val_accuracy: 0.913611114025116 - penalty: 1e-07\n",
            "hidden layer sizes: [336, 498, 310, 361], total neurons: 1505\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "Before growing:\n",
            "loss: 0.03966792672872543 - accuracy: 0.9859523773193359 - val_loss: 0.33850210905075073 - val_accuracy: 0.913611114025116 - penalty: 1e-07\n",
            "hidden layer sizes: [336, 498, 310, 361], total neurons: 1505\n",
            "After growing:\n",
            "loss: 0.039667919278144836 - accuracy: 0.9859523773193359 - val_loss: 0.33850204944610596 - val_accuracy: 0.913611114025116 - penalty: 1e-07\n",
            "hidden layer sizes: [436, 598, 410, 461], total neurons: 1905\n",
            "Before pruning:\n",
            "loss: 0.03454030305147171 - accuracy: 0.9894047379493713 - val_loss: 0.3250926733016968 - val_accuracy: 0.9169444441795349 - penalty: 1e-07\n",
            "hidden layer sizes: [436, 598, 410, 461], total neurons: 1905\n",
            "After pruning:\n",
            "loss: 0.03458134084939957 - accuracy: 0.9894047379493713 - val_loss: 0.32511287927627563 - val_accuracy: 0.9172222018241882 - penalty: 1e-07\n",
            "hidden layer sizes: [262, 595, 375, 417], total neurons: 1649\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "Before growing:\n",
            "loss: 0.03458134084939957 - accuracy: 0.9894047379493713 - val_loss: 0.32511287927627563 - val_accuracy: 0.9172222018241882 - penalty: 1e-07\n",
            "hidden layer sizes: [262, 595, 375, 417], total neurons: 1649\n",
            "After growing:\n",
            "loss: 0.03458134084939957 - accuracy: 0.9894047379493713 - val_loss: 0.32511281967163086 - val_accuracy: 0.9172222018241882 - penalty: 1e-07\n",
            "hidden layer sizes: [362, 714, 475, 517], total neurons: 2068\n",
            "Before pruning:\n",
            "loss: 0.02911137416958809 - accuracy: 0.9908333420753479 - val_loss: 0.33136630058288574 - val_accuracy: 0.914722204208374 - penalty: 1e-07\n",
            "hidden layer sizes: [362, 714, 475, 517], total neurons: 2068\n",
            "After pruning:\n",
            "loss: 0.02912493422627449 - accuracy: 0.9908333420753479 - val_loss: 0.33138027787208557 - val_accuracy: 0.9144444465637207 - penalty: 1e-07\n",
            "hidden layer sizes: [303, 581, 302, 470], total neurons: 1656\n",
            "CPU times: user 1min 20s, sys: 1.25 s, total: 1min 21s\n",
            "Wall time: 1min 31s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js_vLZw3bLWQ",
        "outputId": "b477527f-4adc-4407-9241-09d99f0f3f0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "epochs = 5\n",
        "self_scaling_epochs = 5\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##########################################################\n",
            "Epoch 1/5\n",
            "Before growing:\n",
            "loss: 20.738924026489258 - accuracy: 0.19359999895095825 - val_loss: 20.696252822875977 - val_accuracy: 0.19349999725818634 - penalty: 1e-07\n",
            "hidden layer sizes: [303, 581, 302, 470], total neurons: 1656\n",
            "After growing:\n",
            "loss: 20.73892593383789 - accuracy: 0.19359999895095825 - val_loss: 20.69625473022461 - val_accuracy: 0.19349999725818634 - penalty: 1e-07\n",
            "hidden layer sizes: [403, 697, 402, 570], total neurons: 2072\n",
            "Before pruning:\n",
            "loss: 1.4864871501922607 - accuracy: 0.45423999428749084 - val_loss: 1.5066421031951904 - val_accuracy: 0.4424000084400177 - penalty: 1e-07\n",
            "hidden layer sizes: [403, 697, 402, 570], total neurons: 2072\n",
            "After pruning:\n",
            "loss: 1.486430287361145 - accuracy: 0.454259991645813 - val_loss: 1.5065820217132568 - val_accuracy: 0.4426000118255615 - penalty: 1e-07\n",
            "hidden layer sizes: [335, 697, 402, 536], total neurons: 1970\n",
            "##########################################################\n",
            "Epoch 2/5\n",
            "Before growing:\n",
            "loss: 1.486430287361145 - accuracy: 0.454259991645813 - val_loss: 1.5065820217132568 - val_accuracy: 0.4426000118255615 - penalty: 1e-07\n",
            "hidden layer sizes: [335, 697, 402, 536], total neurons: 1970\n",
            "After growing:\n",
            "loss: 1.486430287361145 - accuracy: 0.454259991645813 - val_loss: 1.5065820217132568 - val_accuracy: 0.4426000118255615 - penalty: 1e-07\n",
            "hidden layer sizes: [435, 836, 502, 643], total neurons: 2416\n",
            "Before pruning:\n",
            "loss: 1.3303452730178833 - accuracy: 0.520039975643158 - val_loss: 1.387462854385376 - val_accuracy: 0.5029000043869019 - penalty: 1e-07\n",
            "hidden layer sizes: [435, 836, 502, 643], total neurons: 2416\n",
            "After pruning:\n",
            "loss: 1.3302218914031982 - accuracy: 0.5199599862098694 - val_loss: 1.3873450756072998 - val_accuracy: 0.5031999945640564 - penalty: 1e-07\n",
            "hidden layer sizes: [419, 716, 416, 558], total neurons: 2109\n",
            "##########################################################\n",
            "Epoch 3/5\n",
            "Before growing:\n",
            "loss: 1.3302218914031982 - accuracy: 0.5199599862098694 - val_loss: 1.3873450756072998 - val_accuracy: 0.5031999945640564 - penalty: 1e-07\n",
            "hidden layer sizes: [419, 716, 416, 558], total neurons: 2109\n",
            "After growing:\n",
            "loss: 1.3302220106124878 - accuracy: 0.5199599862098694 - val_loss: 1.3873450756072998 - val_accuracy: 0.5031999945640564 - penalty: 1e-07\n",
            "hidden layer sizes: [519, 859, 516, 669], total neurons: 2563\n",
            "Before pruning:\n",
            "loss: 1.2867131233215332 - accuracy: 0.5285199880599976 - val_loss: 1.3824881315231323 - val_accuracy: 0.4984000027179718 - penalty: 1e-07\n",
            "hidden layer sizes: [519, 859, 516, 669], total neurons: 2563\n",
            "After pruning:\n",
            "loss: 1.2860933542251587 - accuracy: 0.5288800001144409 - val_loss: 1.381866693496704 - val_accuracy: 0.4982999861240387 - penalty: 1e-07\n",
            "hidden layer sizes: [508, 765, 466, 598], total neurons: 2337\n",
            "##########################################################\n",
            "Epoch 4/5\n",
            "Before growing:\n",
            "loss: 1.2860933542251587 - accuracy: 0.5288800001144409 - val_loss: 1.381866693496704 - val_accuracy: 0.4982999861240387 - penalty: 1e-07\n",
            "hidden layer sizes: [508, 765, 466, 598], total neurons: 2337\n",
            "After growing:\n",
            "loss: 1.2860933542251587 - accuracy: 0.5288800001144409 - val_loss: 1.381866693496704 - val_accuracy: 0.4982999861240387 - penalty: 1e-07\n",
            "hidden layer sizes: [609, 918, 566, 717], total neurons: 2810\n",
            "Before pruning:\n",
            "loss: 1.2454296350479126 - accuracy: 0.5463799834251404 - val_loss: 1.382521390914917 - val_accuracy: 0.5019999742507935 - penalty: 1e-07\n",
            "hidden layer sizes: [609, 918, 566, 717], total neurons: 2810\n",
            "After pruning:\n",
            "loss: 1.245113492012024 - accuracy: 0.5464199781417847 - val_loss: 1.382185697555542 - val_accuracy: 0.5023000240325928 - penalty: 1e-07\n",
            "hidden layer sizes: [577, 809, 482, 568], total neurons: 2436\n",
            "##########################################################\n",
            "Epoch 5/5\n",
            "Before growing:\n",
            "loss: 1.245113492012024 - accuracy: 0.5464199781417847 - val_loss: 1.382185697555542 - val_accuracy: 0.5023000240325928 - penalty: 1e-07\n",
            "hidden layer sizes: [577, 809, 482, 568], total neurons: 2436\n",
            "After growing:\n",
            "loss: 1.245113492012024 - accuracy: 0.5464199781417847 - val_loss: 1.3821855783462524 - val_accuracy: 0.5023000240325928 - penalty: 1e-07\n",
            "hidden layer sizes: [692, 970, 582, 681], total neurons: 2925\n",
            "Before pruning:\n",
            "loss: 1.1299822330474854 - accuracy: 0.5976600050926208 - val_loss: 1.2924996614456177 - val_accuracy: 0.5357999801635742 - penalty: 1e-07\n",
            "hidden layer sizes: [692, 970, 582, 681], total neurons: 2925\n",
            "After pruning:\n",
            "loss: 1.129961609840393 - accuracy: 0.5976600050926208 - val_loss: 1.2924774885177612 - val_accuracy: 0.5358999967575073 - penalty: 1e-07\n",
            "hidden layer sizes: [667, 861, 547, 466], total neurons: 2541\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.454259991645813,\n",
              "  0.5199599862098694,\n",
              "  0.5288800001144409,\n",
              "  0.5464199781417847,\n",
              "  0.5976600050926208],\n",
              " 'loss': [1.486430287361145,\n",
              "  1.3302218914031982,\n",
              "  1.2860933542251587,\n",
              "  1.245113492012024,\n",
              "  1.129961609840393],\n",
              " 'val_accuracy': [0.4426000118255615,\n",
              "  0.5031999945640564,\n",
              "  0.4982999861240387,\n",
              "  0.5023000240325928,\n",
              "  0.5358999967575073],\n",
              " 'val_loss': [1.5065820217132568,\n",
              "  1.3873450756072998,\n",
              "  1.381866693496704,\n",
              "  1.382185697555542,\n",
              "  1.2924774885177612]}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9upZn7BbMbJ",
        "outputId": "88c723e8-7958-4ce8-cce7-92cc184dffff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "epochs = 5\n",
        "self_scaling_epochs = 5\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##########################################################\n",
            "Epoch 1/5\n",
            "Before growing:\n",
            "loss: 1.129961609840393 - accuracy: 0.5976600050926208 - val_loss: 1.2924774885177612 - val_accuracy: 0.5358999967575073 - penalty: 1e-07\n",
            "hidden layer sizes: [667, 861, 547, 466], total neurons: 2541\n",
            "After growing:\n",
            "loss: 1.129961609840393 - accuracy: 0.5976600050926208 - val_loss: 1.2924774885177612 - val_accuracy: 0.5358999967575073 - penalty: 1e-07\n",
            "hidden layer sizes: [800, 1033, 656, 566], total neurons: 3055\n",
            "Before pruning:\n",
            "loss: 1.0870468616485596 - accuracy: 0.6112599968910217 - val_loss: 1.283087134361267 - val_accuracy: 0.5410000085830688 - penalty: 1e-07\n",
            "hidden layer sizes: [800, 1033, 656, 566], total neurons: 3055\n",
            "After pruning:\n",
            "loss: 1.0870997905731201 - accuracy: 0.611020028591156 - val_loss: 1.2830854654312134 - val_accuracy: 0.5408999919891357 - penalty: 1e-07\n",
            "hidden layer sizes: [728, 952, 583, 503], total neurons: 2766\n",
            "##########################################################\n",
            "Epoch 2/5\n",
            "Before growing:\n",
            "loss: 1.0870997905731201 - accuracy: 0.611020028591156 - val_loss: 1.2830854654312134 - val_accuracy: 0.5408999919891357 - penalty: 1e-07\n",
            "hidden layer sizes: [728, 952, 583, 503], total neurons: 2766\n",
            "After growing:\n",
            "loss: 1.0870997905731201 - accuracy: 0.611020028591156 - val_loss: 1.283085584640503 - val_accuracy: 0.5408999919891357 - penalty: 1e-07\n",
            "hidden layer sizes: [873, 1142, 699, 603], total neurons: 3317\n",
            "Before pruning:\n",
            "loss: 1.0354501008987427 - accuracy: 0.6274999976158142 - val_loss: 1.2824939489364624 - val_accuracy: 0.5412999987602234 - penalty: 1e-07\n",
            "hidden layer sizes: [873, 1142, 699, 603], total neurons: 3317\n",
            "After pruning:\n",
            "loss: 1.0354007482528687 - accuracy: 0.627560019493103 - val_loss: 1.2823516130447388 - val_accuracy: 0.541700005531311 - penalty: 1e-07\n",
            "hidden layer sizes: [718, 1015, 632, 450], total neurons: 2815\n",
            "##########################################################\n",
            "Epoch 3/5\n",
            "Before growing:\n",
            "loss: 1.0354007482528687 - accuracy: 0.627560019493103 - val_loss: 1.2823516130447388 - val_accuracy: 0.541700005531311 - penalty: 1e-07\n",
            "hidden layer sizes: [718, 1015, 632, 450], total neurons: 2815\n",
            "After growing:\n",
            "loss: 1.0354007482528687 - accuracy: 0.627560019493103 - val_loss: 1.2823516130447388 - val_accuracy: 0.541700005531311 - penalty: 1e-07\n",
            "hidden layer sizes: [861, 1218, 758, 550], total neurons: 3387\n",
            "Before pruning:\n",
            "loss: 1.0331538915634155 - accuracy: 0.6267799735069275 - val_loss: 1.314587950706482 - val_accuracy: 0.5351999998092651 - penalty: 1e-07\n",
            "hidden layer sizes: [861, 1218, 758, 550], total neurons: 3387\n",
            "After pruning:\n",
            "loss: 1.0331312417984009 - accuracy: 0.6269199848175049 - val_loss: 1.3145761489868164 - val_accuracy: 0.534600019454956 - penalty: 1e-07\n",
            "hidden layer sizes: [793, 1108, 722, 431], total neurons: 3054\n",
            "##########################################################\n",
            "Epoch 4/5\n",
            "Before growing:\n",
            "loss: 1.0331312417984009 - accuracy: 0.6269199848175049 - val_loss: 1.3145761489868164 - val_accuracy: 0.534600019454956 - penalty: 1e-07\n",
            "hidden layer sizes: [793, 1108, 722, 431], total neurons: 3054\n",
            "After growing:\n",
            "loss: 1.0331313610076904 - accuracy: 0.6269199848175049 - val_loss: 1.3145761489868164 - val_accuracy: 0.534600019454956 - penalty: 1e-07\n",
            "hidden layer sizes: [951, 1329, 866, 531], total neurons: 3677\n",
            "Before pruning:\n",
            "loss: 0.9817095398902893 - accuracy: 0.6486799716949463 - val_loss: 1.2891310453414917 - val_accuracy: 0.5472000241279602 - penalty: 1e-07\n",
            "hidden layer sizes: [951, 1329, 866, 531], total neurons: 3677\n",
            "After pruning:\n",
            "loss: 0.9818136096000671 - accuracy: 0.6485000252723694 - val_loss: 1.2891998291015625 - val_accuracy: 0.5472999811172485 - penalty: 1e-07\n",
            "hidden layer sizes: [811, 1267, 826, 391], total neurons: 3295\n",
            "##########################################################\n",
            "Epoch 5/5\n",
            "Before growing:\n",
            "loss: 0.9818136096000671 - accuracy: 0.6485000252723694 - val_loss: 1.2891998291015625 - val_accuracy: 0.5472999811172485 - penalty: 1e-07\n",
            "hidden layer sizes: [811, 1267, 826, 391], total neurons: 3295\n",
            "After growing:\n",
            "loss: 0.9818136096000671 - accuracy: 0.6485000252723694 - val_loss: 1.2891998291015625 - val_accuracy: 0.5472999811172485 - penalty: 1e-07\n",
            "hidden layer sizes: [973, 1520, 991, 491], total neurons: 3975\n",
            "Before pruning:\n",
            "loss: 0.94199138879776 - accuracy: 0.6656200289726257 - val_loss: 1.3003532886505127 - val_accuracy: 0.5486000180244446 - penalty: 1e-07\n",
            "hidden layer sizes: [973, 1520, 991, 491], total neurons: 3975\n",
            "After pruning:\n",
            "loss: 0.9419556260108948 - accuracy: 0.6655799746513367 - val_loss: 1.3002042770385742 - val_accuracy: 0.5486999750137329 - penalty: 1e-07\n",
            "hidden layer sizes: [841, 1389, 911, 385], total neurons: 3526\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.611020028591156,\n",
              "  0.627560019493103,\n",
              "  0.6269199848175049,\n",
              "  0.6485000252723694,\n",
              "  0.6655799746513367],\n",
              " 'loss': [1.0870997905731201,\n",
              "  1.0354007482528687,\n",
              "  1.0331312417984009,\n",
              "  0.9818136096000671,\n",
              "  0.9419556260108948],\n",
              " 'val_accuracy': [0.5408999919891357,\n",
              "  0.541700005531311,\n",
              "  0.534600019454956,\n",
              "  0.5472999811172485,\n",
              "  0.5486999750137329],\n",
              " 'val_loss': [1.2830854654312134,\n",
              "  1.2823516130447388,\n",
              "  1.3145761489868164,\n",
              "  1.2891998291015625,\n",
              "  1.3002042770385742]}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NfNqyAXYcok"
      },
      "source": [
        "### Group sparsity regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUwlAn7iXxpv"
      },
      "source": [
        "epochs = 20\n",
        "self_scaling_epochs = 20\n",
        "batch_size = 32\n",
        "min_new_neurons = 100"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR4hNj0MX49q",
        "outputId": "537586d3-37c8-4c2d-cd95-73c9b9366d57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model = SSModel(layer_sizes=[3072, 300, 300, 300, 300, 10], activation='selu', regularization_penalty=0.01, \n",
        "                regularization_method='group_sparsity', kernel_initializer='lecun_normal')\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_norm_automobiles_dogs_train, y_automobiles_dogs_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_norm_automobiles_dogs_test, y_automobiles_dogs_test))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "Before growing:\n",
            "loss: 2.7622008323669434 - accuracy: 0.14464285969734192 - val_loss: 2.7266921997070312 - val_accuracy: 0.14527778327465057 - penalty: 0.01\n",
            "hidden layer sizes: [300, 300, 300, 300], total neurons: 1200\n",
            "After growing:\n",
            "loss: 2.7622008323669434 - accuracy: 0.14464285969734192 - val_loss: 2.7266921997070312 - val_accuracy: 0.14527778327465057 - penalty: 0.01\n",
            "hidden layer sizes: [400, 400, 400, 400], total neurons: 1600\n",
            "Before pruning:\n",
            "loss: 0.22202880680561066 - accuracy: 0.9163095355033875 - val_loss: 0.3070373237133026 - val_accuracy: 0.8811110854148865 - penalty: 0.01\n",
            "hidden layer sizes: [400, 400, 400, 400], total neurons: 1600\n",
            "After pruning:\n",
            "loss: 0.22240205109119415 - accuracy: 0.9153571724891663 - val_loss: 0.3074040710926056 - val_accuracy: 0.8816666603088379 - penalty: 0.01\n",
            "hidden layer sizes: [300, 300, 301, 300], total neurons: 1201\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "Before growing:\n",
            "loss: 0.22240205109119415 - accuracy: 0.9153571724891663 - val_loss: 0.3074040710926056 - val_accuracy: 0.8816666603088379 - penalty: 0.01\n",
            "hidden layer sizes: [300, 300, 301, 300], total neurons: 1201\n",
            "After growing:\n",
            "loss: 0.22240206599235535 - accuracy: 0.9153571724891663 - val_loss: 0.307404100894928 - val_accuracy: 0.8816666603088379 - penalty: 0.01\n",
            "hidden layer sizes: [400, 400, 401, 400], total neurons: 1601\n",
            "Before pruning:\n",
            "loss: 0.2065180242061615 - accuracy: 0.9214285612106323 - val_loss: 0.2896224856376648 - val_accuracy: 0.883055567741394 - penalty: 0.01\n",
            "hidden layer sizes: [400, 400, 401, 400], total neurons: 1601\n",
            "After pruning:\n",
            "loss: 0.20645202696323395 - accuracy: 0.92166668176651 - val_loss: 0.2897859811782837 - val_accuracy: 0.883055567741394 - penalty: 0.01\n",
            "hidden layer sizes: [301, 300, 300, 286], total neurons: 1187\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "Before growing:\n",
            "loss: 0.20645202696323395 - accuracy: 0.92166668176651 - val_loss: 0.2897859811782837 - val_accuracy: 0.883055567741394 - penalty: 0.01\n",
            "hidden layer sizes: [301, 300, 300, 286], total neurons: 1187\n",
            "After growing:\n",
            "loss: 0.20645204186439514 - accuracy: 0.92166668176651 - val_loss: 0.2897859811782837 - val_accuracy: 0.883055567741394 - penalty: 0.01\n",
            "hidden layer sizes: [401, 400, 400, 386], total neurons: 1587\n",
            "Before pruning:\n",
            "loss: 0.2466094046831131 - accuracy: 0.9022619128227234 - val_loss: 0.3055397868156433 - val_accuracy: 0.8738889098167419 - penalty: 0.01\n",
            "hidden layer sizes: [401, 400, 400, 386], total neurons: 1587\n",
            "After pruning:\n",
            "loss: 0.24412034451961517 - accuracy: 0.9036904573440552 - val_loss: 0.3029809296131134 - val_accuracy: 0.8755555748939514 - penalty: 0.01\n",
            "hidden layer sizes: [197, 294, 296, 226], total neurons: 1013\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "Before growing:\n",
            "loss: 0.24412034451961517 - accuracy: 0.9036904573440552 - val_loss: 0.3029809296131134 - val_accuracy: 0.8755555748939514 - penalty: 0.01\n",
            "hidden layer sizes: [197, 294, 296, 226], total neurons: 1013\n",
            "After growing:\n",
            "loss: 0.24412037432193756 - accuracy: 0.9036904573440552 - val_loss: 0.3029809594154358 - val_accuracy: 0.8755555748939514 - penalty: 0.01\n",
            "hidden layer sizes: [297, 394, 396, 326], total neurons: 1413\n",
            "Before pruning:\n",
            "loss: 0.20944581925868988 - accuracy: 0.9239285588264465 - val_loss: 0.27727845311164856 - val_accuracy: 0.894444465637207 - penalty: 0.01\n",
            "hidden layer sizes: [297, 394, 396, 326], total neurons: 1413\n",
            "After pruning:\n",
            "loss: 0.2086365669965744 - accuracy: 0.9253571629524231 - val_loss: 0.27715033292770386 - val_accuracy: 0.8955555558204651 - penalty: 0.01\n",
            "hidden layer sizes: [49, 104, 69, 137], total neurons: 359\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "Before growing:\n",
            "loss: 0.2086365669965744 - accuracy: 0.9253571629524231 - val_loss: 0.27715033292770386 - val_accuracy: 0.8955555558204651 - penalty: 0.01\n",
            "hidden layer sizes: [49, 104, 69, 137], total neurons: 359\n",
            "After growing:\n",
            "loss: 0.2086365967988968 - accuracy: 0.9253571629524231 - val_loss: 0.27715036273002625 - val_accuracy: 0.8955555558204651 - penalty: 0.01\n",
            "hidden layer sizes: [149, 204, 169, 237], total neurons: 759\n",
            "Before pruning:\n",
            "loss: 0.2042963206768036 - accuracy: 0.928928554058075 - val_loss: 0.27228328585624695 - val_accuracy: 0.89083331823349 - penalty: 0.01\n",
            "hidden layer sizes: [149, 204, 169, 237], total neurons: 759\n",
            "After pruning:\n",
            "loss: 0.20483726263046265 - accuracy: 0.9288095235824585 - val_loss: 0.2724878489971161 - val_accuracy: 0.8905555605888367 - penalty: 0.01\n",
            "hidden layer sizes: [30, 55, 36, 100], total neurons: 221\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "Before growing:\n",
            "loss: 0.20483726263046265 - accuracy: 0.9288095235824585 - val_loss: 0.2724878489971161 - val_accuracy: 0.8905555605888367 - penalty: 0.01\n",
            "hidden layer sizes: [30, 55, 36, 100], total neurons: 221\n",
            "After growing:\n",
            "loss: 0.20483718812465668 - accuracy: 0.9288095235824585 - val_loss: 0.2724878191947937 - val_accuracy: 0.8905555605888367 - penalty: 0.01\n",
            "hidden layer sizes: [130, 155, 136, 200], total neurons: 621\n",
            "Before pruning:\n",
            "loss: 0.1766515076160431 - accuracy: 0.9397618770599365 - val_loss: 0.25643929839134216 - val_accuracy: 0.9024999737739563 - penalty: 0.01\n",
            "hidden layer sizes: [130, 155, 136, 200], total neurons: 621\n",
            "After pruning:\n",
            "loss: 0.1766577959060669 - accuracy: 0.9398809671401978 - val_loss: 0.256439745426178 - val_accuracy: 0.9019444584846497 - penalty: 0.01\n",
            "hidden layer sizes: [25, 44, 22, 85], total neurons: 176\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "Before growing:\n",
            "loss: 0.1766577959060669 - accuracy: 0.9398809671401978 - val_loss: 0.256439745426178 - val_accuracy: 0.9019444584846497 - penalty: 0.01\n",
            "hidden layer sizes: [25, 44, 22, 85], total neurons: 176\n",
            "After growing:\n",
            "loss: 0.1766577959060669 - accuracy: 0.9398809671401978 - val_loss: 0.25643977522850037 - val_accuracy: 0.9019444584846497 - penalty: 0.01\n",
            "hidden layer sizes: [125, 144, 122, 185], total neurons: 576\n",
            "Before pruning:\n",
            "loss: 0.17712149024009705 - accuracy: 0.9363095164299011 - val_loss: 0.2608802020549774 - val_accuracy: 0.8986111283302307 - penalty: 0.01\n",
            "hidden layer sizes: [125, 144, 122, 185], total neurons: 576\n",
            "After pruning:\n",
            "loss: 0.1777963787317276 - accuracy: 0.9367856979370117 - val_loss: 0.2613069713115692 - val_accuracy: 0.8991666436195374 - penalty: 0.01\n",
            "hidden layer sizes: [21, 31, 14, 69], total neurons: 135\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "Before growing:\n",
            "loss: 0.1777963787317276 - accuracy: 0.9367856979370117 - val_loss: 0.2613069713115692 - val_accuracy: 0.8991666436195374 - penalty: 0.01\n",
            "hidden layer sizes: [21, 31, 14, 69], total neurons: 135\n",
            "After growing:\n",
            "loss: 0.17779633402824402 - accuracy: 0.9367856979370117 - val_loss: 0.261307030916214 - val_accuracy: 0.8991666436195374 - penalty: 0.01\n",
            "hidden layer sizes: [121, 131, 114, 169], total neurons: 535\n",
            "Before pruning:\n",
            "loss: 0.15451829135417938 - accuracy: 0.9473809599876404 - val_loss: 0.24201136827468872 - val_accuracy: 0.9016666412353516 - penalty: 0.01\n",
            "hidden layer sizes: [121, 131, 114, 169], total neurons: 535\n",
            "After pruning:\n",
            "loss: 0.15460793673992157 - accuracy: 0.9471428394317627 - val_loss: 0.24201643466949463 - val_accuracy: 0.9019444584846497 - penalty: 0.01\n",
            "hidden layer sizes: [71, 28, 10, 69], total neurons: 178\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "Before growing:\n",
            "loss: 0.15460793673992157 - accuracy: 0.9471428394317627 - val_loss: 0.24201643466949463 - val_accuracy: 0.9019444584846497 - penalty: 0.01\n",
            "hidden layer sizes: [71, 28, 10, 69], total neurons: 178\n",
            "After growing:\n",
            "loss: 0.15460793673992157 - accuracy: 0.9471428394317627 - val_loss: 0.24201644957065582 - val_accuracy: 0.9019444584846497 - penalty: 0.01\n",
            "hidden layer sizes: [171, 128, 110, 169], total neurons: 578\n",
            "Before pruning:\n",
            "loss: 0.15290644764900208 - accuracy: 0.9452381134033203 - val_loss: 0.24778886139392853 - val_accuracy: 0.903333306312561 - penalty: 0.01\n",
            "hidden layer sizes: [171, 128, 110, 169], total neurons: 578\n",
            "After pruning:\n",
            "loss: 0.1530337929725647 - accuracy: 0.9453571438789368 - val_loss: 0.247825488448143 - val_accuracy: 0.9038888812065125 - penalty: 0.01\n",
            "hidden layer sizes: [14, 21, 10, 67], total neurons: 112\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "Before growing:\n",
            "loss: 0.1530337929725647 - accuracy: 0.9453571438789368 - val_loss: 0.247825488448143 - val_accuracy: 0.9038888812065125 - penalty: 0.01\n",
            "hidden layer sizes: [14, 21, 10, 67], total neurons: 112\n",
            "After growing:\n",
            "loss: 0.15303385257720947 - accuracy: 0.9453571438789368 - val_loss: 0.247825488448143 - val_accuracy: 0.9038888812065125 - penalty: 0.01\n",
            "hidden layer sizes: [114, 121, 110, 167], total neurons: 512\n",
            "Before pruning:\n",
            "loss: 0.15025106072425842 - accuracy: 0.9488095045089722 - val_loss: 0.2581351697444916 - val_accuracy: 0.8999999761581421 - penalty: 0.01\n",
            "hidden layer sizes: [114, 121, 110, 167], total neurons: 512\n",
            "After pruning:\n",
            "loss: 0.15059904754161835 - accuracy: 0.9483333230018616 - val_loss: 0.2586231827735901 - val_accuracy: 0.8997222185134888 - penalty: 0.01\n",
            "hidden layer sizes: [34, 18, 9, 64], total neurons: 125\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "Before growing:\n",
            "loss: 0.15059904754161835 - accuracy: 0.9483333230018616 - val_loss: 0.2586231827735901 - val_accuracy: 0.8997222185134888 - penalty: 0.01\n",
            "hidden layer sizes: [34, 18, 9, 64], total neurons: 125\n",
            "After growing:\n",
            "loss: 0.15059901773929596 - accuracy: 0.9483333230018616 - val_loss: 0.2586232125759125 - val_accuracy: 0.8997222185134888 - penalty: 0.01\n",
            "hidden layer sizes: [134, 118, 109, 164], total neurons: 525\n",
            "Before pruning:\n",
            "loss: 0.1435967981815338 - accuracy: 0.9504761695861816 - val_loss: 0.2547459900379181 - val_accuracy: 0.8983333110809326 - penalty: 0.01\n",
            "hidden layer sizes: [134, 118, 109, 164], total neurons: 525\n",
            "After pruning:\n",
            "loss: 0.14458014070987701 - accuracy: 0.9492856860160828 - val_loss: 0.2555382251739502 - val_accuracy: 0.8974999785423279 - penalty: 0.01\n",
            "hidden layer sizes: [26, 17, 7, 63], total neurons: 113\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "Before growing:\n",
            "loss: 0.14458014070987701 - accuracy: 0.9492856860160828 - val_loss: 0.2555382251739502 - val_accuracy: 0.8974999785423279 - penalty: 0.01\n",
            "hidden layer sizes: [26, 17, 7, 63], total neurons: 113\n",
            "After growing:\n",
            "loss: 0.14458011090755463 - accuracy: 0.9492856860160828 - val_loss: 0.2555381655693054 - val_accuracy: 0.8974999785423279 - penalty: 0.01\n",
            "hidden layer sizes: [126, 117, 107, 163], total neurons: 513\n",
            "Before pruning:\n",
            "loss: 0.14885157346725464 - accuracy: 0.9446428418159485 - val_loss: 0.26199594140052795 - val_accuracy: 0.9013888835906982 - penalty: 0.01\n",
            "hidden layer sizes: [126, 117, 107, 163], total neurons: 513\n",
            "After pruning:\n",
            "loss: 0.1495526134967804 - accuracy: 0.9441666603088379 - val_loss: 0.2627192735671997 - val_accuracy: 0.9016666412353516 - penalty: 0.01\n",
            "hidden layer sizes: [12, 13, 6, 57], total neurons: 88\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "Before growing:\n",
            "loss: 0.1495526134967804 - accuracy: 0.9441666603088379 - val_loss: 0.2627192735671997 - val_accuracy: 0.9016666412353516 - penalty: 0.01\n",
            "hidden layer sizes: [12, 13, 6, 57], total neurons: 88\n",
            "After growing:\n",
            "loss: 0.14955264329910278 - accuracy: 0.9441666603088379 - val_loss: 0.2627192735671997 - val_accuracy: 0.9016666412353516 - penalty: 0.01\n",
            "hidden layer sizes: [112, 113, 106, 157], total neurons: 488\n",
            "Before pruning:\n",
            "loss: 0.14250801503658295 - accuracy: 0.9479761719703674 - val_loss: 0.2558925151824951 - val_accuracy: 0.9019444584846497 - penalty: 0.01\n",
            "hidden layer sizes: [112, 113, 106, 157], total neurons: 488\n",
            "After pruning:\n",
            "loss: 0.14248348772525787 - accuracy: 0.9477381110191345 - val_loss: 0.25589025020599365 - val_accuracy: 0.902222216129303 - penalty: 0.01\n",
            "hidden layer sizes: [32, 13, 5, 54], total neurons: 104\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "Before growing:\n",
            "loss: 0.14248348772525787 - accuracy: 0.9477381110191345 - val_loss: 0.25589025020599365 - val_accuracy: 0.902222216129303 - penalty: 0.01\n",
            "hidden layer sizes: [32, 13, 5, 54], total neurons: 104\n",
            "After growing:\n",
            "loss: 0.14248350262641907 - accuracy: 0.9477381110191345 - val_loss: 0.25589028000831604 - val_accuracy: 0.902222216129303 - penalty: 0.01\n",
            "hidden layer sizes: [132, 113, 105, 154], total neurons: 504\n",
            "Before pruning:\n",
            "loss: 0.13288728892803192 - accuracy: 0.9553571343421936 - val_loss: 0.2516627609729767 - val_accuracy: 0.9030555486679077 - penalty: 0.01\n",
            "hidden layer sizes: [132, 113, 105, 154], total neurons: 504\n",
            "After pruning:\n",
            "loss: 0.13307462632656097 - accuracy: 0.9549999833106995 - val_loss: 0.2520010471343994 - val_accuracy: 0.9027777910232544 - penalty: 0.01\n",
            "hidden layer sizes: [59, 12, 5, 52], total neurons: 128\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "Before growing:\n",
            "loss: 0.13307462632656097 - accuracy: 0.9549999833106995 - val_loss: 0.2520010471343994 - val_accuracy: 0.9027777910232544 - penalty: 0.01\n",
            "hidden layer sizes: [59, 12, 5, 52], total neurons: 128\n",
            "After growing:\n",
            "loss: 0.133074551820755 - accuracy: 0.9549999833106995 - val_loss: 0.2520010471343994 - val_accuracy: 0.9027777910232544 - penalty: 0.01\n",
            "hidden layer sizes: [159, 112, 105, 152], total neurons: 528\n",
            "Before pruning:\n",
            "loss: 0.12738117575645447 - accuracy: 0.9557142853736877 - val_loss: 0.2650347650051117 - val_accuracy: 0.9030555486679077 - penalty: 0.01\n",
            "hidden layer sizes: [159, 112, 105, 152], total neurons: 528\n",
            "After pruning:\n",
            "loss: 0.1273517608642578 - accuracy: 0.9557142853736877 - val_loss: 0.26491105556488037 - val_accuracy: 0.9027777910232544 - penalty: 0.01\n",
            "hidden layer sizes: [38, 11, 4, 48], total neurons: 101\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "Before growing:\n",
            "loss: 0.1273517608642578 - accuracy: 0.9557142853736877 - val_loss: 0.26491105556488037 - val_accuracy: 0.9027777910232544 - penalty: 0.01\n",
            "hidden layer sizes: [38, 11, 4, 48], total neurons: 101\n",
            "After growing:\n",
            "loss: 0.1273517906665802 - accuracy: 0.9557142853736877 - val_loss: 0.26491105556488037 - val_accuracy: 0.9027777910232544 - penalty: 0.01\n",
            "hidden layer sizes: [138, 111, 104, 148], total neurons: 501\n",
            "Before pruning:\n",
            "loss: 0.11491638422012329 - accuracy: 0.9620237946510315 - val_loss: 0.24424545466899872 - val_accuracy: 0.9088888764381409 - penalty: 0.01\n",
            "hidden layer sizes: [138, 111, 104, 148], total neurons: 501\n",
            "After pruning:\n",
            "loss: 0.11505655944347382 - accuracy: 0.9617857336997986 - val_loss: 0.2442069947719574 - val_accuracy: 0.9094444513320923 - penalty: 0.01\n",
            "hidden layer sizes: [49, 21, 4, 47], total neurons: 121\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "Before growing:\n",
            "loss: 0.11505655944347382 - accuracy: 0.9617857336997986 - val_loss: 0.2442069947719574 - val_accuracy: 0.9094444513320923 - penalty: 0.01\n",
            "hidden layer sizes: [49, 21, 4, 47], total neurons: 121\n",
            "After growing:\n",
            "loss: 0.1150565892457962 - accuracy: 0.9617857336997986 - val_loss: 0.244206964969635 - val_accuracy: 0.9094444513320923 - penalty: 0.01\n",
            "hidden layer sizes: [149, 121, 104, 147], total neurons: 521\n",
            "Before pruning:\n",
            "loss: 0.11843448132276535 - accuracy: 0.9594047665596008 - val_loss: 0.25585028529167175 - val_accuracy: 0.9038888812065125 - penalty: 0.01\n",
            "hidden layer sizes: [149, 121, 104, 147], total neurons: 521\n",
            "After pruning:\n",
            "loss: 0.1183294728398323 - accuracy: 0.9595237970352173 - val_loss: 0.25569382309913635 - val_accuracy: 0.9038888812065125 - penalty: 0.01\n",
            "hidden layer sizes: [32, 10, 4, 42], total neurons: 88\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "Before growing:\n",
            "loss: 0.1183294728398323 - accuracy: 0.9595237970352173 - val_loss: 0.25569382309913635 - val_accuracy: 0.9038888812065125 - penalty: 0.01\n",
            "hidden layer sizes: [32, 10, 4, 42], total neurons: 88\n",
            "After growing:\n",
            "loss: 0.1183294877409935 - accuracy: 0.9595237970352173 - val_loss: 0.25569382309913635 - val_accuracy: 0.9038888812065125 - penalty: 0.01\n",
            "hidden layer sizes: [132, 110, 104, 142], total neurons: 488\n",
            "Before pruning:\n",
            "loss: 0.12350478768348694 - accuracy: 0.9579761624336243 - val_loss: 0.2490958720445633 - val_accuracy: 0.9077777862548828 - penalty: 0.01\n",
            "hidden layer sizes: [132, 110, 104, 142], total neurons: 488\n",
            "After pruning:\n",
            "loss: 0.12355535477399826 - accuracy: 0.9579761624336243 - val_loss: 0.24909719824790955 - val_accuracy: 0.9072222113609314 - penalty: 0.01\n",
            "hidden layer sizes: [17, 9, 4, 40], total neurons: 70\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "Before growing:\n",
            "loss: 0.12355535477399826 - accuracy: 0.9579761624336243 - val_loss: 0.24909719824790955 - val_accuracy: 0.9072222113609314 - penalty: 0.01\n",
            "hidden layer sizes: [17, 9, 4, 40], total neurons: 70\n",
            "After growing:\n",
            "loss: 0.12355531007051468 - accuracy: 0.9579761624336243 - val_loss: 0.24909713864326477 - val_accuracy: 0.9072222113609314 - penalty: 0.01\n",
            "hidden layer sizes: [117, 109, 104, 140], total neurons: 470\n",
            "Before pruning:\n",
            "loss: 0.11460010707378387 - accuracy: 0.9611904621124268 - val_loss: 0.25411364436149597 - val_accuracy: 0.9036111235618591 - penalty: 0.01\n",
            "hidden layer sizes: [117, 109, 104, 140], total neurons: 470\n",
            "After pruning:\n",
            "loss: 0.11545268446207047 - accuracy: 0.9609524011611938 - val_loss: 0.2546720802783966 - val_accuracy: 0.9038888812065125 - penalty: 0.01\n",
            "hidden layer sizes: [17, 9, 4, 39], total neurons: 69\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "Before growing:\n",
            "loss: 0.11545268446207047 - accuracy: 0.9609524011611938 - val_loss: 0.2546720802783966 - val_accuracy: 0.9038888812065125 - penalty: 0.01\n",
            "hidden layer sizes: [17, 9, 4, 39], total neurons: 69\n",
            "After growing:\n",
            "loss: 0.11545266211032867 - accuracy: 0.9609524011611938 - val_loss: 0.2546720802783966 - val_accuracy: 0.9038888812065125 - penalty: 0.01\n",
            "hidden layer sizes: [117, 109, 104, 139], total neurons: 469\n",
            "Before pruning:\n",
            "loss: 0.11079717427492142 - accuracy: 0.9644047617912292 - val_loss: 0.24541541934013367 - val_accuracy: 0.9077777862548828 - penalty: 0.01\n",
            "hidden layer sizes: [117, 109, 104, 139], total neurons: 469\n",
            "After pruning:\n",
            "loss: 0.11104068160057068 - accuracy: 0.9642857313156128 - val_loss: 0.2455434650182724 - val_accuracy: 0.9075000286102295 - penalty: 0.01\n",
            "hidden layer sizes: [37, 8, 3, 39], total neurons: 87\n",
            "CPU times: user 1min 26s, sys: 1.17 s, total: 1min 27s\n",
            "Wall time: 1min 26s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i931f3BYi5n",
        "outputId": "20717853-a1f8-4fb5-c80b-07eb772fe5e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "epochs = 5\n",
        "self_scaling_epochs = 5\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##########################################################\n",
            "Epoch 1/5\n",
            "Before growing:\n",
            "loss: 7.067015647888184 - accuracy: 0.18945999443531036 - val_loss: 7.076200008392334 - val_accuracy: 0.18940000236034393 - penalty: 0.01\n",
            "hidden layer sizes: [37, 8, 3, 39], total neurons: 87\n",
            "After growing:\n",
            "loss: 7.067009449005127 - accuracy: 0.18945999443531036 - val_loss: 7.076193809509277 - val_accuracy: 0.18940000236034393 - penalty: 0.01\n",
            "hidden layer sizes: [137, 108, 103, 139], total neurons: 487\n",
            "Before pruning:\n",
            "loss: 1.8373908996582031 - accuracy: 0.2900800108909607 - val_loss: 1.8446769714355469 - val_accuracy: 0.2863999903202057 - penalty: 0.01\n",
            "hidden layer sizes: [137, 108, 103, 139], total neurons: 487\n",
            "After pruning:\n",
            "loss: 1.8373355865478516 - accuracy: 0.2902800142765045 - val_loss: 1.8447535037994385 - val_accuracy: 0.287200003862381 - penalty: 0.01\n",
            "hidden layer sizes: [29, 45, 29, 99], total neurons: 202\n",
            "##########################################################\n",
            "Epoch 2/5\n",
            "Before growing:\n",
            "loss: 1.8373355865478516 - accuracy: 0.2902800142765045 - val_loss: 1.8447535037994385 - val_accuracy: 0.287200003862381 - penalty: 0.01\n",
            "hidden layer sizes: [29, 45, 29, 99], total neurons: 202\n",
            "After growing:\n",
            "loss: 1.8373359441757202 - accuracy: 0.2902800142765045 - val_loss: 1.8447535037994385 - val_accuracy: 0.287200003862381 - penalty: 0.01\n",
            "hidden layer sizes: [129, 145, 129, 199], total neurons: 602\n",
            "Before pruning:\n",
            "loss: 1.7930521965026855 - accuracy: 0.30970001220703125 - val_loss: 1.8054386377334595 - val_accuracy: 0.30730000138282776 - penalty: 0.01\n",
            "hidden layer sizes: [129, 145, 129, 199], total neurons: 602\n",
            "After pruning:\n",
            "loss: 1.793487787246704 - accuracy: 0.3094800114631653 - val_loss: 1.8058598041534424 - val_accuracy: 0.30649998784065247 - penalty: 0.01\n",
            "hidden layer sizes: [34, 26, 15, 99], total neurons: 174\n",
            "##########################################################\n",
            "Epoch 3/5\n",
            "Before growing:\n",
            "loss: 1.793487787246704 - accuracy: 0.3094800114631653 - val_loss: 1.8058598041534424 - val_accuracy: 0.30649998784065247 - penalty: 0.01\n",
            "hidden layer sizes: [34, 26, 15, 99], total neurons: 174\n",
            "After growing:\n",
            "loss: 1.793487548828125 - accuracy: 0.3094800114631653 - val_loss: 1.8058593273162842 - val_accuracy: 0.30649998784065247 - penalty: 0.01\n",
            "hidden layer sizes: [134, 126, 115, 199], total neurons: 574\n",
            "Before pruning:\n",
            "loss: 1.7748874425888062 - accuracy: 0.33191999793052673 - val_loss: 1.7880898714065552 - val_accuracy: 0.329800009727478 - penalty: 0.01\n",
            "hidden layer sizes: [134, 126, 115, 199], total neurons: 574\n",
            "After pruning:\n",
            "loss: 1.7749556303024292 - accuracy: 0.33263999223709106 - val_loss: 1.7882664203643799 - val_accuracy: 0.33070001006126404 - penalty: 0.01\n",
            "hidden layer sizes: [55, 19, 13, 93], total neurons: 180\n",
            "##########################################################\n",
            "Epoch 4/5\n",
            "Before growing:\n",
            "loss: 1.7749556303024292 - accuracy: 0.33263999223709106 - val_loss: 1.7882664203643799 - val_accuracy: 0.33070001006126404 - penalty: 0.01\n",
            "hidden layer sizes: [55, 19, 13, 93], total neurons: 180\n",
            "After growing:\n",
            "loss: 1.7749555110931396 - accuracy: 0.33263999223709106 - val_loss: 1.7882664203643799 - val_accuracy: 0.33070001006126404 - penalty: 0.01\n",
            "hidden layer sizes: [155, 119, 113, 193], total neurons: 580\n",
            "Before pruning:\n",
            "loss: 1.7587653398513794 - accuracy: 0.33682000637054443 - val_loss: 1.7736560106277466 - val_accuracy: 0.33410000801086426 - penalty: 0.01\n",
            "hidden layer sizes: [155, 119, 113, 193], total neurons: 580\n",
            "After pruning:\n",
            "loss: 1.7585344314575195 - accuracy: 0.3366200029850006 - val_loss: 1.7735812664031982 - val_accuracy: 0.33480000495910645 - penalty: 0.01\n",
            "hidden layer sizes: [16, 19, 13, 91], total neurons: 139\n",
            "##########################################################\n",
            "Epoch 5/5\n",
            "Before growing:\n",
            "loss: 1.7585344314575195 - accuracy: 0.3366200029850006 - val_loss: 1.7735812664031982 - val_accuracy: 0.33480000495910645 - penalty: 0.01\n",
            "hidden layer sizes: [16, 19, 13, 91], total neurons: 139\n",
            "After growing:\n",
            "loss: 1.7585340738296509 - accuracy: 0.3366200029850006 - val_loss: 1.7735809087753296 - val_accuracy: 0.33480000495910645 - penalty: 0.01\n",
            "hidden layer sizes: [116, 119, 113, 191], total neurons: 539\n",
            "Before pruning:\n",
            "loss: 1.7467790842056274 - accuracy: 0.3519800007343292 - val_loss: 1.7635797262191772 - val_accuracy: 0.3474000096321106 - penalty: 0.01\n",
            "hidden layer sizes: [116, 119, 113, 191], total neurons: 539\n",
            "After pruning:\n",
            "loss: 1.7463375329971313 - accuracy: 0.3519800007343292 - val_loss: 1.7631163597106934 - val_accuracy: 0.34790000319480896 - penalty: 0.01\n",
            "hidden layer sizes: [57, 19, 12, 88], total neurons: 176\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.2902800142765045,\n",
              "  0.3094800114631653,\n",
              "  0.33263999223709106,\n",
              "  0.3366200029850006,\n",
              "  0.3519800007343292],\n",
              " 'loss': [1.8373355865478516,\n",
              "  1.793487787246704,\n",
              "  1.7749556303024292,\n",
              "  1.7585344314575195,\n",
              "  1.7463375329971313],\n",
              " 'val_accuracy': [0.287200003862381,\n",
              "  0.30649998784065247,\n",
              "  0.33070001006126404,\n",
              "  0.33480000495910645,\n",
              "  0.34790000319480896],\n",
              " 'val_loss': [1.8447535037994385,\n",
              "  1.8058598041534424,\n",
              "  1.7882664203643799,\n",
              "  1.7735812664031982,\n",
              "  1.7631163597106934]}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6bugvFiYmoC",
        "outputId": "5dc150c2-05ee-4845-c826-533f6066cc8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "epochs = 5\n",
        "self_scaling_epochs = 5\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##########################################################\n",
            "Epoch 1/5\n",
            "Before growing:\n",
            "loss: 1.7463375329971313 - accuracy: 0.3519800007343292 - val_loss: 1.7631163597106934 - val_accuracy: 0.34790000319480896 - penalty: 0.01\n",
            "hidden layer sizes: [57, 19, 12, 88], total neurons: 176\n",
            "After growing:\n",
            "loss: 1.7463372945785522 - accuracy: 0.3519800007343292 - val_loss: 1.7631162405014038 - val_accuracy: 0.34790000319480896 - penalty: 0.01\n",
            "hidden layer sizes: [157, 119, 112, 188], total neurons: 576\n",
            "Before pruning:\n",
            "loss: 1.7129186391830444 - accuracy: 0.370959997177124 - val_loss: 1.7313566207885742 - val_accuracy: 0.3686999976634979 - penalty: 0.01\n",
            "hidden layer sizes: [157, 119, 112, 188], total neurons: 576\n",
            "After pruning:\n",
            "loss: 1.7132741212844849 - accuracy: 0.37031999230384827 - val_loss: 1.7316983938217163 - val_accuracy: 0.3682999908924103 - penalty: 0.01\n",
            "hidden layer sizes: [21, 17, 10, 88], total neurons: 136\n",
            "##########################################################\n",
            "Epoch 2/5\n",
            "Before growing:\n",
            "loss: 1.7132741212844849 - accuracy: 0.37031999230384827 - val_loss: 1.7316983938217163 - val_accuracy: 0.3682999908924103 - penalty: 0.01\n",
            "hidden layer sizes: [21, 17, 10, 88], total neurons: 136\n",
            "After growing:\n",
            "loss: 1.7132737636566162 - accuracy: 0.37031999230384827 - val_loss: 1.7316982746124268 - val_accuracy: 0.3682999908924103 - penalty: 0.01\n",
            "hidden layer sizes: [121, 117, 110, 188], total neurons: 536\n",
            "Before pruning:\n",
            "loss: 1.689890742301941 - accuracy: 0.3740200102329254 - val_loss: 1.7124007940292358 - val_accuracy: 0.3741999864578247 - penalty: 0.01\n",
            "hidden layer sizes: [121, 117, 110, 188], total neurons: 536\n",
            "After pruning:\n",
            "loss: 1.690038800239563 - accuracy: 0.3739599883556366 - val_loss: 1.7125375270843506 - val_accuracy: 0.37389999628067017 - penalty: 0.01\n",
            "hidden layer sizes: [20, 16, 10, 88], total neurons: 134\n",
            "##########################################################\n",
            "Epoch 3/5\n",
            "Before growing:\n",
            "loss: 1.690038800239563 - accuracy: 0.3739599883556366 - val_loss: 1.7125375270843506 - val_accuracy: 0.37389999628067017 - penalty: 0.01\n",
            "hidden layer sizes: [20, 16, 10, 88], total neurons: 134\n",
            "After growing:\n",
            "loss: 1.690038800239563 - accuracy: 0.3739599883556366 - val_loss: 1.7125375270843506 - val_accuracy: 0.37389999628067017 - penalty: 0.01\n",
            "hidden layer sizes: [120, 116, 110, 188], total neurons: 534\n",
            "Before pruning:\n",
            "loss: 1.684503436088562 - accuracy: 0.38095998764038086 - val_loss: 1.7062327861785889 - val_accuracy: 0.37779998779296875 - penalty: 0.01\n",
            "hidden layer sizes: [120, 116, 110, 188], total neurons: 534\n",
            "After pruning:\n",
            "loss: 1.6849206686019897 - accuracy: 0.38067999482154846 - val_loss: 1.7064882516860962 - val_accuracy: 0.3776000142097473 - penalty: 0.01\n",
            "hidden layer sizes: [30, 14, 9, 80], total neurons: 133\n",
            "##########################################################\n",
            "Epoch 4/5\n",
            "Before growing:\n",
            "loss: 1.6849206686019897 - accuracy: 0.38067999482154846 - val_loss: 1.7064882516860962 - val_accuracy: 0.3776000142097473 - penalty: 0.01\n",
            "hidden layer sizes: [30, 14, 9, 80], total neurons: 133\n",
            "After growing:\n",
            "loss: 1.6849206686019897 - accuracy: 0.38067999482154846 - val_loss: 1.7064882516860962 - val_accuracy: 0.3776000142097473 - penalty: 0.01\n",
            "hidden layer sizes: [130, 114, 109, 180], total neurons: 533\n",
            "Before pruning:\n",
            "loss: 1.6700459718704224 - accuracy: 0.3882400095462799 - val_loss: 1.6979864835739136 - val_accuracy: 0.38260000944137573 - penalty: 0.01\n",
            "hidden layer sizes: [130, 114, 109, 180], total neurons: 533\n",
            "After pruning:\n",
            "loss: 1.6698124408721924 - accuracy: 0.3883399963378906 - val_loss: 1.6978199481964111 - val_accuracy: 0.38260000944137573 - penalty: 0.01\n",
            "hidden layer sizes: [17, 12, 8, 80], total neurons: 117\n",
            "##########################################################\n",
            "Epoch 5/5\n",
            "Before growing:\n",
            "loss: 1.6698124408721924 - accuracy: 0.3883399963378906 - val_loss: 1.6978199481964111 - val_accuracy: 0.38260000944137573 - penalty: 0.01\n",
            "hidden layer sizes: [17, 12, 8, 80], total neurons: 117\n",
            "After growing:\n",
            "loss: 1.6698126792907715 - accuracy: 0.3883399963378906 - val_loss: 1.6978199481964111 - val_accuracy: 0.38260000944137573 - penalty: 0.01\n",
            "hidden layer sizes: [117, 112, 108, 180], total neurons: 517\n",
            "Before pruning:\n",
            "loss: 1.671547532081604 - accuracy: 0.3860599994659424 - val_loss: 1.699623465538025 - val_accuracy: 0.3785000145435333 - penalty: 0.01\n",
            "hidden layer sizes: [117, 112, 108, 180], total neurons: 517\n",
            "After pruning:\n",
            "loss: 1.671156883239746 - accuracy: 0.38618001341819763 - val_loss: 1.6991358995437622 - val_accuracy: 0.37940001487731934 - penalty: 0.01\n",
            "hidden layer sizes: [52, 12, 8, 79], total neurons: 151\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.37031999230384827,\n",
              "  0.3739599883556366,\n",
              "  0.38067999482154846,\n",
              "  0.3883399963378906,\n",
              "  0.38618001341819763],\n",
              " 'loss': [1.7132741212844849,\n",
              "  1.690038800239563,\n",
              "  1.6849206686019897,\n",
              "  1.6698124408721924,\n",
              "  1.671156883239746],\n",
              " 'val_accuracy': [0.3682999908924103,\n",
              "  0.37389999628067017,\n",
              "  0.3776000142097473,\n",
              "  0.38260000944137573,\n",
              "  0.37940001487731934],\n",
              " 'val_loss': [1.7316983938217163,\n",
              "  1.7125375270843506,\n",
              "  1.7064882516860962,\n",
              "  1.6978199481964111,\n",
              "  1.6991358995437622]}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHaQdAD-T5O-"
      },
      "source": [
        "## Corresponding static models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXPoc8Thngun"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(3072, activation='selu', kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dense(232, activation='selu', kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dense(231, activation='selu', kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dense(66, activation='selu', kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dense(74, activation='selu', kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax', kernel_initializer='lecun_normal'),\n",
        "])"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpowWVNNpi1_"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002), metrics=['accuracy'])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJKf14Y2pkO6",
        "outputId": "e0e848a2-b165-4a1c-bc01-49c1ada72de3"
      },
      "source": [
        "%%time\n",
        "\n",
        "model.fit(X_norm_automobiles_dogs_train, y_automobiles_dogs_train, epochs=40, validation_data=(X_norm_automobiles_dogs_test, y_automobiles_dogs_test))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.4433 - accuracy: 0.8440 - val_loss: 0.3395 - val_accuracy: 0.8653\n",
            "Epoch 2/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.2331 - accuracy: 0.9064 - val_loss: 0.3213 - val_accuracy: 0.8756\n",
            "Epoch 3/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.1692 - accuracy: 0.9364 - val_loss: 0.2886 - val_accuracy: 0.8933\n",
            "Epoch 4/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.1227 - accuracy: 0.9533 - val_loss: 0.2679 - val_accuracy: 0.9011\n",
            "Epoch 5/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.1042 - accuracy: 0.9599 - val_loss: 0.2661 - val_accuracy: 0.9106\n",
            "Epoch 6/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0840 - accuracy: 0.9687 - val_loss: 0.3718 - val_accuracy: 0.8914\n",
            "Epoch 7/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0808 - accuracy: 0.9700 - val_loss: 0.3197 - val_accuracy: 0.9094\n",
            "Epoch 8/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0613 - accuracy: 0.9767 - val_loss: 0.3507 - val_accuracy: 0.9036\n",
            "Epoch 9/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0479 - accuracy: 0.9826 - val_loss: 0.3459 - val_accuracy: 0.9103\n",
            "Epoch 10/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0456 - accuracy: 0.9836 - val_loss: 0.3416 - val_accuracy: 0.9047\n",
            "Epoch 11/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0569 - accuracy: 0.9798 - val_loss: 0.4098 - val_accuracy: 0.9014\n",
            "Epoch 12/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0760 - accuracy: 0.9740 - val_loss: 0.3546 - val_accuracy: 0.9017\n",
            "Epoch 13/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0426 - accuracy: 0.9845 - val_loss: 0.3471 - val_accuracy: 0.9103\n",
            "Epoch 14/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0322 - accuracy: 0.9889 - val_loss: 0.3849 - val_accuracy: 0.9111\n",
            "Epoch 15/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0220 - accuracy: 0.9919 - val_loss: 0.4635 - val_accuracy: 0.8903\n",
            "Epoch 16/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0532 - accuracy: 0.9824 - val_loss: 0.4988 - val_accuracy: 0.8881\n",
            "Epoch 17/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0460 - accuracy: 0.9848 - val_loss: 0.3983 - val_accuracy: 0.9089\n",
            "Epoch 18/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0354 - accuracy: 0.9876 - val_loss: 0.4473 - val_accuracy: 0.9061\n",
            "Epoch 19/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0352 - accuracy: 0.9868 - val_loss: 0.4367 - val_accuracy: 0.9103\n",
            "Epoch 20/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0238 - accuracy: 0.9921 - val_loss: 0.4156 - val_accuracy: 0.9131\n",
            "Epoch 21/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0411 - accuracy: 0.9861 - val_loss: 0.4883 - val_accuracy: 0.8997\n",
            "Epoch 22/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0363 - accuracy: 0.9861 - val_loss: 0.4564 - val_accuracy: 0.9103\n",
            "Epoch 23/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0296 - accuracy: 0.9900 - val_loss: 0.4764 - val_accuracy: 0.9053\n",
            "Epoch 24/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 0.4303 - val_accuracy: 0.9133\n",
            "Epoch 25/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.4405 - val_accuracy: 0.9178\n",
            "Epoch 26/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0251 - accuracy: 0.9918 - val_loss: 0.5156 - val_accuracy: 0.9069\n",
            "Epoch 27/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0567 - accuracy: 0.9823 - val_loss: 0.4394 - val_accuracy: 0.9094\n",
            "Epoch 28/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0305 - accuracy: 0.9906 - val_loss: 0.4965 - val_accuracy: 0.9042\n",
            "Epoch 29/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0146 - accuracy: 0.9943 - val_loss: 0.5148 - val_accuracy: 0.9153\n",
            "Epoch 30/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0210 - accuracy: 0.9925 - val_loss: 0.4736 - val_accuracy: 0.9161\n",
            "Epoch 31/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.4742 - val_accuracy: 0.9186\n",
            "Epoch 32/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0245 - accuracy: 0.9917 - val_loss: 0.5310 - val_accuracy: 0.9097\n",
            "Epoch 33/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0202 - accuracy: 0.9939 - val_loss: 0.5398 - val_accuracy: 0.9175\n",
            "Epoch 34/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0297 - accuracy: 0.9900 - val_loss: 0.5505 - val_accuracy: 0.9131\n",
            "Epoch 35/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0456 - accuracy: 0.9854 - val_loss: 0.5185 - val_accuracy: 0.9042\n",
            "Epoch 36/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0280 - accuracy: 0.9896 - val_loss: 0.4850 - val_accuracy: 0.9167\n",
            "Epoch 37/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.4736 - val_accuracy: 0.9208\n",
            "Epoch 38/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 4.5755e-04 - accuracy: 0.9999 - val_loss: 0.4702 - val_accuracy: 0.9253\n",
            "Epoch 39/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 1.1582e-04 - accuracy: 1.0000 - val_loss: 0.4747 - val_accuracy: 0.9256\n",
            "Epoch 40/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 8.2775e-05 - accuracy: 1.0000 - val_loss: 0.4798 - val_accuracy: 0.9250\n",
            "CPU times: user 43 s, sys: 3.9 s, total: 46.9 s\n",
            "Wall time: 41.4 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdf517c1f50>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4O9L7ffQWPr",
        "outputId": "25fb07c1-9398-4021-8eea-c32c3757a1f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model.fit(X_train_norm, y_train, epochs=5, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7528 - accuracy: 0.3855 - val_loss: 1.5240 - val_accuracy: 0.4500\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4355 - accuracy: 0.4812 - val_loss: 1.4249 - val_accuracy: 0.4891\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2993 - accuracy: 0.5315 - val_loss: 1.3902 - val_accuracy: 0.5023\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1908 - accuracy: 0.5702 - val_loss: 1.3810 - val_accuracy: 0.5161\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0991 - accuracy: 0.6038 - val_loss: 1.3643 - val_accuracy: 0.5230\n",
            "CPU times: user 28.2 s, sys: 2.24 s, total: 30.4 s\n",
            "Wall time: 25.7 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdf515d4710>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--9Q0_GqQ2RB",
        "outputId": "ce5020ac-ee49-41dc-9a55-c2be4eeddf3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model.fit(X_train_norm, y_train, epochs=5, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0068 - accuracy: 0.6396 - val_loss: 1.4075 - val_accuracy: 0.5247\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9191 - accuracy: 0.6701 - val_loss: 1.4108 - val_accuracy: 0.5321\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8325 - accuracy: 0.7009 - val_loss: 1.4371 - val_accuracy: 0.5372\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7532 - accuracy: 0.7305 - val_loss: 1.5081 - val_accuracy: 0.5286\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6743 - accuracy: 0.7606 - val_loss: 1.5969 - val_accuracy: 0.5287\n",
            "CPU times: user 28.3 s, sys: 2.31 s, total: 30.6 s\n",
            "Wall time: 41.3 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdf515a86d0>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJ252SBrrEcn"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(3072, activation='selu', kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dense(30, activation='selu', kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dense(33, activation='selu', kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dense(13, activation='selu', kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dense(42, activation='selu', kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax', kernel_initializer='lecun_normal'),\n",
        "])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9t4DCWZVrKp"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002), metrics=['accuracy'])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZROKqZUVtOT",
        "outputId": "149078d5-471f-4458-c1f2-206c81eed092",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model.fit(X_norm_automobiles_dogs_train, y_automobiles_dogs_train, epochs=40, validation_data=(X_norm_automobiles_dogs_test, y_automobiles_dogs_test))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.6208 - accuracy: 0.8281 - val_loss: 0.4214 - val_accuracy: 0.8481\n",
            "Epoch 2/40\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.2711 - accuracy: 0.8979 - val_loss: 0.3255 - val_accuracy: 0.8822\n",
            "Epoch 3/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.1972 - accuracy: 0.9251 - val_loss: 0.3301 - val_accuracy: 0.8833\n",
            "Epoch 4/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.1634 - accuracy: 0.9371 - val_loss: 0.3182 - val_accuracy: 0.8853\n",
            "Epoch 5/40\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.1356 - accuracy: 0.9474 - val_loss: 0.3045 - val_accuracy: 0.8928\n",
            "Epoch 6/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.1069 - accuracy: 0.9582 - val_loss: 0.3300 - val_accuracy: 0.8997\n",
            "Epoch 7/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0951 - accuracy: 0.9638 - val_loss: 0.3463 - val_accuracy: 0.8908\n",
            "Epoch 8/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0758 - accuracy: 0.9719 - val_loss: 0.3824 - val_accuracy: 0.8917\n",
            "Epoch 9/40\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.0863 - accuracy: 0.9708 - val_loss: 0.3311 - val_accuracy: 0.9017\n",
            "Epoch 10/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0661 - accuracy: 0.9788 - val_loss: 0.3394 - val_accuracy: 0.9031\n",
            "Epoch 11/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0532 - accuracy: 0.9807 - val_loss: 0.4035 - val_accuracy: 0.8989\n",
            "Epoch 12/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0609 - accuracy: 0.9773 - val_loss: 0.4049 - val_accuracy: 0.8964\n",
            "Epoch 13/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0470 - accuracy: 0.9826 - val_loss: 0.4502 - val_accuracy: 0.9042\n",
            "Epoch 14/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0452 - accuracy: 0.9849 - val_loss: 0.4272 - val_accuracy: 0.9044\n",
            "Epoch 15/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0430 - accuracy: 0.9860 - val_loss: 0.4642 - val_accuracy: 0.8981\n",
            "Epoch 16/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0472 - accuracy: 0.9829 - val_loss: 0.4541 - val_accuracy: 0.9050\n",
            "Epoch 17/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0289 - accuracy: 0.9900 - val_loss: 0.4729 - val_accuracy: 0.9033\n",
            "Epoch 18/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0425 - accuracy: 0.9860 - val_loss: 0.5173 - val_accuracy: 0.9000\n",
            "Epoch 19/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0296 - accuracy: 0.9890 - val_loss: 0.4598 - val_accuracy: 0.9100\n",
            "Epoch 20/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0222 - accuracy: 0.9924 - val_loss: 0.4976 - val_accuracy: 0.9083\n",
            "Epoch 21/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0148 - accuracy: 0.9944 - val_loss: 0.5605 - val_accuracy: 0.8989\n",
            "Epoch 22/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0351 - accuracy: 0.9882 - val_loss: 0.6056 - val_accuracy: 0.9000\n",
            "Epoch 23/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0767 - accuracy: 0.9760 - val_loss: 0.4807 - val_accuracy: 0.9022\n",
            "Epoch 24/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0149 - accuracy: 0.9952 - val_loss: 0.4370 - val_accuracy: 0.9106\n",
            "Epoch 25/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.4697 - val_accuracy: 0.9144\n",
            "Epoch 26/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.4464 - val_accuracy: 0.9203\n",
            "Epoch 27/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 9.7181e-04 - accuracy: 0.9999 - val_loss: 0.4630 - val_accuracy: 0.9186\n",
            "Epoch 28/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 6.0659e-04 - accuracy: 0.9999 - val_loss: 0.4729 - val_accuracy: 0.9183\n",
            "Epoch 29/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 4.5354e-04 - accuracy: 0.9999 - val_loss: 0.4807 - val_accuracy: 0.9186\n",
            "Epoch 30/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 3.5714e-04 - accuracy: 0.9999 - val_loss: 0.4882 - val_accuracy: 0.9192\n",
            "Epoch 31/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 2.8864e-04 - accuracy: 1.0000 - val_loss: 0.4962 - val_accuracy: 0.9200\n",
            "Epoch 32/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 2.2965e-04 - accuracy: 1.0000 - val_loss: 0.5033 - val_accuracy: 0.9192\n",
            "Epoch 33/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 1.8324e-04 - accuracy: 1.0000 - val_loss: 0.5097 - val_accuracy: 0.9200\n",
            "Epoch 34/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 1.4519e-04 - accuracy: 1.0000 - val_loss: 0.5194 - val_accuracy: 0.9194\n",
            "Epoch 35/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 1.1807e-04 - accuracy: 1.0000 - val_loss: 0.5239 - val_accuracy: 0.9200\n",
            "Epoch 36/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 9.5125e-05 - accuracy: 1.0000 - val_loss: 0.5338 - val_accuracy: 0.9200\n",
            "Epoch 37/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 8.1743e-05 - accuracy: 1.0000 - val_loss: 0.5412 - val_accuracy: 0.9194\n",
            "Epoch 38/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 6.5340e-05 - accuracy: 1.0000 - val_loss: 0.5466 - val_accuracy: 0.9206\n",
            "Epoch 39/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 5.5018e-05 - accuracy: 1.0000 - val_loss: 0.5526 - val_accuracy: 0.9200\n",
            "Epoch 40/40\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 4.6702e-05 - accuracy: 1.0000 - val_loss: 0.5594 - val_accuracy: 0.9200\n",
            "CPU times: user 42.3 s, sys: 4.28 s, total: 46.6 s\n",
            "Wall time: 40.9 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdf6809f990>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ck7OaNpWzHw",
        "outputId": "dc772f4f-e43a-4ff3-f53c-8a298905cb4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model.fit(X_train_norm, y_train, epochs=5, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.0058 - accuracy: 0.3147 - val_loss: 1.7041 - val_accuracy: 0.3896\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6476 - accuracy: 0.4086 - val_loss: 1.5962 - val_accuracy: 0.4338\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5286 - accuracy: 0.4524 - val_loss: 1.5452 - val_accuracy: 0.4515\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4472 - accuracy: 0.4833 - val_loss: 1.4902 - val_accuracy: 0.4664\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3784 - accuracy: 0.5090 - val_loss: 1.4683 - val_accuracy: 0.4760\n",
            "CPU times: user 27.7 s, sys: 2.29 s, total: 30 s\n",
            "Wall time: 25.2 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdf513e5690>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1airAHDVvcd",
        "outputId": "f96bd0b1-a23b-47c0-b4d6-62b5b01857fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model.fit(X_train_norm, y_train, epochs=5, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3215 - accuracy: 0.5312 - val_loss: 1.4451 - val_accuracy: 0.4929\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2606 - accuracy: 0.5512 - val_loss: 1.4518 - val_accuracy: 0.4940\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2125 - accuracy: 0.5691 - val_loss: 1.4392 - val_accuracy: 0.4933\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1631 - accuracy: 0.5879 - val_loss: 1.4150 - val_accuracy: 0.5102\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1137 - accuracy: 0.6081 - val_loss: 1.4505 - val_accuracy: 0.5021\n",
            "CPU times: user 27.8 s, sys: 2.53 s, total: 30.3 s\n",
            "Wall time: 41.3 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdf513b8dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFBf2ATDcUNn"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(3072, activation='selu', kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dense(303, activation='selu', kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dense(581, activation='selu', kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dense(302, activation='selu', kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dense(470, activation='selu', kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax', kernel_initializer='lecun_normal'),\n",
        "])"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnDa59KPcZGx"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002), metrics=['accuracy'])"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tN-gdO3HcZKA",
        "outputId": "d9a50429-fb76-4f8e-d688-8ad944f0dd1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model.fit(X_norm_automobiles_dogs_train, y_automobiles_dogs_train, epochs=20, validation_data=(X_norm_automobiles_dogs_test, y_automobiles_dogs_test))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "263/263 [==============================] - 2s 5ms/step - loss: 0.4272 - accuracy: 0.8489 - val_loss: 0.4906 - val_accuracy: 0.8211\n",
            "Epoch 2/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.2549 - accuracy: 0.9038 - val_loss: 0.3394 - val_accuracy: 0.8764\n",
            "Epoch 3/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.1766 - accuracy: 0.9346 - val_loss: 0.3973 - val_accuracy: 0.8786\n",
            "Epoch 4/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.1579 - accuracy: 0.9404 - val_loss: 0.3036 - val_accuracy: 0.8969\n",
            "Epoch 5/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.1307 - accuracy: 0.9502 - val_loss: 0.2618 - val_accuracy: 0.9025\n",
            "Epoch 6/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.1096 - accuracy: 0.9590 - val_loss: 0.3325 - val_accuracy: 0.8981\n",
            "Epoch 7/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0865 - accuracy: 0.9675 - val_loss: 0.3568 - val_accuracy: 0.8997\n",
            "Epoch 8/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0774 - accuracy: 0.9693 - val_loss: 0.3284 - val_accuracy: 0.9119\n",
            "Epoch 9/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0622 - accuracy: 0.9776 - val_loss: 0.3688 - val_accuracy: 0.9061\n",
            "Epoch 10/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0704 - accuracy: 0.9751 - val_loss: 0.3466 - val_accuracy: 0.9119\n",
            "Epoch 11/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0499 - accuracy: 0.9820 - val_loss: 0.3875 - val_accuracy: 0.9047\n",
            "Epoch 12/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0751 - accuracy: 0.9739 - val_loss: 0.4055 - val_accuracy: 0.9094\n",
            "Epoch 13/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0495 - accuracy: 0.9823 - val_loss: 0.4603 - val_accuracy: 0.8967\n",
            "Epoch 14/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0553 - accuracy: 0.9814 - val_loss: 0.3813 - val_accuracy: 0.9122\n",
            "Epoch 15/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0462 - accuracy: 0.9832 - val_loss: 0.4125 - val_accuracy: 0.9119\n",
            "Epoch 16/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0444 - accuracy: 0.9869 - val_loss: 0.3784 - val_accuracy: 0.9142\n",
            "Epoch 17/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0238 - accuracy: 0.9904 - val_loss: 0.4464 - val_accuracy: 0.9183\n",
            "Epoch 18/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0516 - accuracy: 0.9831 - val_loss: 0.3600 - val_accuracy: 0.9194\n",
            "Epoch 19/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0553 - accuracy: 0.9845 - val_loss: 0.3780 - val_accuracy: 0.9169\n",
            "Epoch 20/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.4062 - val_accuracy: 0.9194\n",
            "CPU times: user 22.3 s, sys: 1.86 s, total: 24.2 s\n",
            "Wall time: 41.4 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdfa012e510>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRza9GagcgIl",
        "outputId": "8f5e75c7-0094-4ef8-e6bc-333a0a89e699",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model.fit(X_train_norm, y_train, epochs=5, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6646 - accuracy: 0.4190 - val_loss: 1.4674 - val_accuracy: 0.4732\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3542 - accuracy: 0.5149 - val_loss: 1.3896 - val_accuracy: 0.4985\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2212 - accuracy: 0.5610 - val_loss: 1.3538 - val_accuracy: 0.5252\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1002 - accuracy: 0.6073 - val_loss: 1.3512 - val_accuracy: 0.5380\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9830 - accuracy: 0.6492 - val_loss: 1.3677 - val_accuracy: 0.5363\n",
            "CPU times: user 28.8 s, sys: 2.25 s, total: 31 s\n",
            "Wall time: 26.5 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdf510540d0>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3OaKMWzcjuf",
        "outputId": "f1f458c1-98a4-4277-c9ff-d98c936a812d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model.fit(X_train_norm, y_train, epochs=5, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8640 - accuracy: 0.6903 - val_loss: 1.4064 - val_accuracy: 0.5447\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7470 - accuracy: 0.7304 - val_loss: 1.4696 - val_accuracy: 0.5411\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6342 - accuracy: 0.7736 - val_loss: 1.5467 - val_accuracy: 0.5447\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5278 - accuracy: 0.8119 - val_loss: 1.7095 - val_accuracy: 0.5401\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4468 - accuracy: 0.8391 - val_loss: 1.9176 - val_accuracy: 0.5266\n",
            "CPU times: user 28.8 s, sys: 2.55 s, total: 31.3 s\n",
            "Wall time: 27 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdf51025c10>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbyAxn8RZzZJ"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(3072, activation='selu', kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dense(117, activation='selu', kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dense(109, activation='selu', kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dense(104, activation='selu', kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dense(139, activation='selu', kernel_initializer='lecun_normal'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax', kernel_initializer='lecun_normal'),\n",
        "])"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JDpPwkrZ2xx"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002), metrics=['accuracy'])"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l2I_etAZ4is",
        "outputId": "de994e1b-e913-4c25-9457-55e4d725f2ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model.fit(X_norm_automobiles_dogs_train, y_automobiles_dogs_train, epochs=20, validation_data=(X_norm_automobiles_dogs_test, y_automobiles_dogs_test))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.4151 - accuracy: 0.8404 - val_loss: 0.3217 - val_accuracy: 0.8722\n",
            "Epoch 2/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.2258 - accuracy: 0.9095 - val_loss: 0.2861 - val_accuracy: 0.8914\n",
            "Epoch 3/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.1857 - accuracy: 0.9270 - val_loss: 0.2878 - val_accuracy: 0.8933\n",
            "Epoch 4/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.1265 - accuracy: 0.9476 - val_loss: 0.2857 - val_accuracy: 0.8989\n",
            "Epoch 5/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0938 - accuracy: 0.9640 - val_loss: 0.2879 - val_accuracy: 0.9103\n",
            "Epoch 6/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0858 - accuracy: 0.9680 - val_loss: 0.3245 - val_accuracy: 0.9025\n",
            "Epoch 7/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0887 - accuracy: 0.9683 - val_loss: 0.3448 - val_accuracy: 0.8972\n",
            "Epoch 8/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0607 - accuracy: 0.9782 - val_loss: 0.3225 - val_accuracy: 0.9106\n",
            "Epoch 9/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0666 - accuracy: 0.9754 - val_loss: 0.3264 - val_accuracy: 0.9108\n",
            "Epoch 10/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0671 - accuracy: 0.9746 - val_loss: 0.4087 - val_accuracy: 0.8989\n",
            "Epoch 11/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0510 - accuracy: 0.9824 - val_loss: 0.4092 - val_accuracy: 0.9019\n",
            "Epoch 12/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0449 - accuracy: 0.9842 - val_loss: 0.3984 - val_accuracy: 0.9078\n",
            "Epoch 13/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0445 - accuracy: 0.9840 - val_loss: 0.3977 - val_accuracy: 0.9083\n",
            "Epoch 14/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0357 - accuracy: 0.9868 - val_loss: 0.3933 - val_accuracy: 0.9164\n",
            "Epoch 15/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0260 - accuracy: 0.9905 - val_loss: 0.4204 - val_accuracy: 0.9083\n",
            "Epoch 16/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0748 - accuracy: 0.9767 - val_loss: 0.4453 - val_accuracy: 0.8967\n",
            "Epoch 17/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0558 - accuracy: 0.9813 - val_loss: 0.3681 - val_accuracy: 0.9131\n",
            "Epoch 18/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0160 - accuracy: 0.9942 - val_loss: 0.4286 - val_accuracy: 0.9156\n",
            "Epoch 19/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0249 - accuracy: 0.9906 - val_loss: 0.4434 - val_accuracy: 0.9092\n",
            "Epoch 20/20\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0282 - accuracy: 0.9911 - val_loss: 0.4694 - val_accuracy: 0.9075\n",
            "CPU times: user 21.8 s, sys: 1.79 s, total: 23.6 s\n",
            "Wall time: 41.4 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdf5146af10>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQZ0WeecZ8BO",
        "outputId": "a03520b7-7ebc-4993-f84f-1a3274373c87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model.fit(X_train_norm, y_train, epochs=5, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7722 - accuracy: 0.3908 - val_loss: 1.5381 - val_accuracy: 0.4579\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4426 - accuracy: 0.4809 - val_loss: 1.4417 - val_accuracy: 0.4888\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3321 - accuracy: 0.5202 - val_loss: 1.4054 - val_accuracy: 0.5008\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2423 - accuracy: 0.5539 - val_loss: 1.4132 - val_accuracy: 0.5043\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1557 - accuracy: 0.5877 - val_loss: 1.3845 - val_accuracy: 0.5243\n",
            "CPU times: user 28.1 s, sys: 2.29 s, total: 30.4 s\n",
            "Wall time: 41.3 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdf511fc110>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-ETLVDwZ9ef",
        "outputId": "730f3389-cd16-4ebe-9cdd-6b829d4520de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model.fit(X_train_norm, y_train, epochs=5, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0836 - accuracy: 0.6128 - val_loss: 1.3936 - val_accuracy: 0.5191\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0094 - accuracy: 0.6387 - val_loss: 1.3940 - val_accuracy: 0.5306\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9357 - accuracy: 0.6674 - val_loss: 1.4378 - val_accuracy: 0.5296\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8717 - accuracy: 0.6888 - val_loss: 1.4701 - val_accuracy: 0.5333\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8024 - accuracy: 0.7142 - val_loss: 1.4702 - val_accuracy: 0.5293\n",
            "CPU times: user 27.9 s, sys: 2.48 s, total: 30.4 s\n",
            "Wall time: 25.5 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdf511cbc90>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_BvNnozaO0-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}