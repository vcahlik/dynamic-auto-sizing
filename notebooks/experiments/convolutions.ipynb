{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_multi_layer_ssnet_inverse.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_deAUKlniFk",
        "outputId": "c589ef1a-bfcf-4c13-895e-c1d4915f88bd"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Sep 30 08:40:37 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKwUwV_NneIo"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOoXBq05neIt"
      },
      "source": [
        "dtype = 'float32'\n",
        "tf.keras.backend.set_floatx(dtype)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BrJPdkBneIv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de358dca-4561-43c8-c1cc-4f021858ab9c"
      },
      "source": [
        "cifar10 = tf.keras.datasets.cifar10\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "X_train = X_train.astype(dtype) / 255.0\n",
        "y_train = y_train.astype(dtype)\n",
        "X_test = X_test.astype(dtype)  / 255.0\n",
        "y_test = y_test.astype(dtype)\n",
        "\n",
        "X_train = np.reshape(X_train, (-1, 3072))\n",
        "X_test = np.reshape(X_test, (-1, 3072))\n",
        "\n",
        "X = np.concatenate((X_train, X_test), axis=0)\n",
        "y = np.concatenate((y_train, y_test), axis=0)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "170508288/170498071 [==============================] - 4s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5uTvu5kxF-b"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_norm = scaler.transform(X)\n",
        "X_train_norm = scaler.transform(X_train)\n",
        "X_test_norm = scaler.transform(X_test)\n",
        "\n",
        "X_train_norm = np.reshape(X_train_norm, (-1, 32, 32, 3))\n",
        "X_test_norm = np.reshape(X_test_norm, (-1, 32, 32, 3))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTZq4KMpneIv"
      },
      "source": [
        "class Regularizer(tf.keras.regularizers.Regularizer):\n",
        "    def __init__(self, regularization_penalty, regularization_method):\n",
        "        self.regularization_penalty = regularization_penalty\n",
        "        self.regularization_method = regularization_method\n",
        "\n",
        "    def __call__(self, x):\n",
        "        if self.regularization_method == 'weighted_l1':\n",
        "            return self.weighted_l1(x)\n",
        "        elif self.regularization_method == 'group_sparsity':\n",
        "            return self.group_sparsity(x)\n",
        "        else:\n",
        "            raise NotImplementedError(f\"Unknown regularization method {self.regularization_method}\")\n",
        "    \n",
        "    def weighted_l1(self, x):\n",
        "        # I.e. for a parameter matrix of 4 input and 10 output neurons:\n",
        "        #\n",
        "        # [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]\n",
        "        #\n",
        "        # the scaling tensor, as well as the resulting weighted values, could be:\n",
        "        #\n",
        "        # [[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
        "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
        "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
        "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]\n",
        "        #\n",
        "        # Therefore every additional output neuron is regularized more.\n",
        "\n",
        "        scaling_tensor = tf.cumsum(tf.constant(self.regularization_penalty, shape=x.shape, dtype=dtype), axis=-1)\n",
        "        weighted_values = scaling_tensor * tf.abs(x)\n",
        "        return tf.reduce_sum(weighted_values)\n",
        "    \n",
        "    def group_sparsity(self, x):\n",
        "        # I.e. for a parameter matrix of 3 input and 5 output neurons:\n",
        "        #\n",
        "        # [[1., 1., 1., 1., 1.],\n",
        "        #  [1., 2., 2., 1., 2.],\n",
        "        #  [2., 2., 3., 1., 3.]]\n",
        "        #\n",
        "        # The resulting vector of group norms is [2., 2., 3., 1., 3.], therefore for\n",
        "        # every output neuron, its incoming connections form a group.\n",
        "\n",
        "        # TODO implement for Conv2D layers\n",
        "        group_norms = tf.norm(x, ord=2, axis=0)\n",
        "        # assert group_norms.shape[0] == x.shape[1]\n",
        "        return self.regularization_penalty * tf.reduce_sum(group_norms)\n",
        "\n",
        "    def get_config(self):\n",
        "        return {'regularization_penalty': float(self.regularization_penalty)}\n",
        "\n",
        "\n",
        "class ModelReference:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "\n",
        "class CustomLayer(tf.keras.Model):\n",
        "    def __init__(self, input_shape):\n",
        "        super().__init__()\n",
        "\n",
        "        self.inpt_shp = input_shape\n",
        "    \n",
        "    def configure(self, model):\n",
        "        self.mr = ModelReference(model)\n",
        "    \n",
        "    def get_input_shape(self):\n",
        "        if self.inpt_shp is not None:\n",
        "            return self.inpt_shp\n",
        "        \n",
        "        return self.mr.model.get_layer_input_shape(self)\n",
        "    \n",
        "    def get_output_shape(self):\n",
        "        return self.mr.model.get_layer_output_shape(self)\n",
        "\n",
        "\n",
        "class Dense(CustomLayer):\n",
        "    def __init__(self, units, activation, regularization_penalty=0.01, \n",
        "                 regularization_method='weighted_l1', kernel_initializer='glorot_uniform', \n",
        "                 bias_initializer='zeros', input_shape=None, fixed_size=False):\n",
        "        super().__init__(input_shape)\n",
        "\n",
        "        self.units = units\n",
        "        self.activation = activation\n",
        "        self.regularization_penalty = regularization_penalty\n",
        "        self.regularization_method = regularization_method\n",
        "        self.kernel_initializer = kernel_initializer\n",
        "        self.bias_initializer = bias_initializer\n",
        "        self.fixed_size = fixed_size\n",
        "        \n",
        "        self.A = tf.keras.activations.get(activation)\n",
        "        self.W_init = tf.keras.initializers.get(kernel_initializer)\n",
        "        self.b_init = tf.keras.initializers.get(bias_initializer)\n",
        "        self.regularizer = Regularizer(self.regularization_penalty, self.regularization_method)\n",
        "    \n",
        "    def configure(self, model):\n",
        "        super().configure(model)\n",
        "\n",
        "        input_units = self.get_input_units_count()\n",
        "\n",
        "        self.W = tf.Variable(\n",
        "            name='W',\n",
        "            initial_value=self.W_init(shape=(input_units, self.units), dtype=dtype),\n",
        "            trainable=True)\n",
        "        \n",
        "        self.b = tf.Variable(\n",
        "            name='b',\n",
        "            initial_value=self.b_init(shape=(self.units,), dtype=dtype),\n",
        "            trainable=True)\n",
        "        \n",
        "        if self.regularization_method is not None:\n",
        "            self.add_loss(lambda: self.regularizer(tf.concat([self.W, tf.reshape(self.b, (1, -1))], axis=0)))\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        return self.A(tf.matmul(inputs, self.W) + self.b)\n",
        "    \n",
        "    def copy_without_regularization(self):\n",
        "        # TODO fix\n",
        "        copy = Dense(\n",
        "            self.input_units, \n",
        "            self.units, \n",
        "            self.activation, \n",
        "            regularization_penalty=self.regularization_penalty, \n",
        "            regularization_method=None, \n",
        "            kernel_initializer=self.kernel_initializer, \n",
        "            bias_initializer=self.bias_initializer\n",
        "        )\n",
        "        copy.W = self.W\n",
        "        copy.b = self.b\n",
        "        return copy\n",
        "    \n",
        "    def get_input_units_count(self):\n",
        "        input_shape = self.get_input_shape()\n",
        "        if len(input_shape) != 1:\n",
        "            raise Exception(f\"Invalid input shape {input_shape}.\")\n",
        "        return input_shape[0]\n",
        "    \n",
        "    def get_size(self):\n",
        "        return self.get_input_units_count(), self.W.shape[1]\n",
        "    \n",
        "    def prune(self, threshold, active_input_units_indices):\n",
        "        # Remove connections from pruned units in previous layer\n",
        "        new_W = tf.gather(self.W.value(), active_input_units_indices, axis=0)\n",
        "\n",
        "        if self.fixed_size:\n",
        "            active_output_neurons_indices = list(range(new_W.shape[1]))\n",
        "        else:\n",
        "            # Prune units in this layer\n",
        "            weights_with_biases = tf.concat([new_W, tf.reshape(self.b.value(), (1, -1))], axis=0)\n",
        "            neurons_are_active = tf.math.reduce_max(tf.abs(weights_with_biases), axis=0) >= threshold\n",
        "            active_output_neurons_indices = tf.reshape(tf.where(neurons_are_active), (-1,))\n",
        "            \n",
        "            new_W = tf.gather(new_W, active_output_neurons_indices, axis=1)\n",
        "            new_b = tf.gather(self.b.value(), active_output_neurons_indices, axis=0)\n",
        "\n",
        "            self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
        "\n",
        "        self.W = tf.Variable(name='W', initial_value=new_W, trainable=True)\n",
        "\n",
        "        return active_output_neurons_indices\n",
        "    \n",
        "    def grow(self, n_new_input_units, percentage, min_new_units, scaling_factor):\n",
        "        if n_new_input_units > 0:\n",
        "            # Add connections to grown units in previous layer\n",
        "            W_growth = self.W_init(shape=(self.W.shape[0] + n_new_input_units, self.W.shape[1]), dtype=dtype)[-n_new_input_units:, :] * scaling_factor  # TODO is it better to be multiplying here by scaling_factor? It does help with not increasing the max weights of existing neurons when new neurons are added.\n",
        "            new_W = tf.concat([self.W.value(), W_growth], axis=0)\n",
        "        else:\n",
        "            new_W = self.W.value()\n",
        "\n",
        "        if self.fixed_size:\n",
        "            n_new_output_units = 0\n",
        "        else:\n",
        "            # Grow new units in this layer\n",
        "            n_new_output_units = max(min_new_units, int(new_W.shape[1] * percentage))\n",
        "            W_growth = self.W_init(shape=(new_W.shape[0], new_W.shape[1] + n_new_output_units), dtype=dtype)[:, -n_new_output_units:] * scaling_factor\n",
        "            b_growth = self.b_init(shape=(n_new_output_units,), dtype=dtype)  # TODO for all possible bias initializers to work properly, the whole bias vector should be initialized at once\n",
        "            new_W = tf.concat([new_W, W_growth], axis=1)\n",
        "            new_b = tf.concat([self.b.value(), b_growth], axis=0)\n",
        "\n",
        "            self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
        "\n",
        "        self.W = tf.Variable(name='W', initial_value=new_W, trainable=True)\n",
        "\n",
        "        return n_new_output_units\n",
        "    \n",
        "    def get_param_string():\n",
        "        param_string = \"\"\n",
        "        weights_with_bias = tf.concat([self.W, tf.reshape(self.b, (1, -1))], axis=0)\n",
        "        max_parameters = tf.math.reduce_max(tf.abs(weights_with_bias), axis=0).numpy()\n",
        "        magnitudes = np.floor(np.log10(max_parameters))\n",
        "        for m in magnitudes:\n",
        "            if m > 0:\n",
        "                m = 0\n",
        "            param_string += str(int(-m))\n",
        "        return param_string\n",
        "\n",
        "\n",
        "class Conv2D(CustomLayer):\n",
        "    def __init__(self, filters, filter_size, activation, strides=(1, 1), \n",
        "                 padding='SAME', regularization_penalty=0.01, \n",
        "                 regularization_method='weighted_l1', kernel_initializer='glorot_uniform',\n",
        "                 bias_initializer='zeros', input_shape=None, fixed_size=False):\n",
        "        super().__init__(input_shape)\n",
        "    \n",
        "        self.filters = filters\n",
        "        self.filter_size = filter_size\n",
        "        self.activation = activation\n",
        "        self.strides = strides\n",
        "        self.padding = padding\n",
        "        self.regularization_penalty = regularization_penalty\n",
        "        self.regularization_method = regularization_method\n",
        "        self.kernel_initializer = kernel_initializer\n",
        "        self.bias_initializer = bias_initializer\n",
        "        self.fixed_size = fixed_size\n",
        "        \n",
        "        self.A = tf.keras.activations.get(activation)\n",
        "        self.F_init = tf.keras.initializers.get(kernel_initializer)\n",
        "        self.b_init = tf.keras.initializers.get(bias_initializer)\n",
        "        self.regularizer = Regularizer(self.regularization_penalty, self.regularization_method)\n",
        "    \n",
        "    def configure(self, model):\n",
        "        super().configure(model)\n",
        "\n",
        "        input_filters = self.get_input_filters_count()\n",
        "\n",
        "        self.F = tf.Variable(\n",
        "            name='F',\n",
        "            initial_value=self.F_init(\n",
        "                shape=(self.filter_size[0], self.filter_size[1], input_filters, self.filters), dtype=dtype\n",
        "            ),\n",
        "            trainable=True)\n",
        "        \n",
        "        self.b = tf.Variable(\n",
        "            name='b',\n",
        "            initial_value=self.b_init(shape=(self.filters,), dtype=dtype),\n",
        "            trainable=True)\n",
        "\n",
        "        if self.regularization_method is not None:\n",
        "            self.add_loss(lambda: self.regularizer(tf.concat([tf.reshape(self.F, (-1, self.F.shape[-1])), tf.reshape(self.b, (1, -1))], axis=0)))\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        y = tf.nn.conv2d(inputs, self.F, strides=self.strides, padding=self.padding)\n",
        "        y = tf.nn.bias_add(y, self.b)\n",
        "        y = self.A(y)\n",
        "        return y\n",
        "    \n",
        "    def copy_without_regularization(self):\n",
        "        # TODO fix\n",
        "        copy = Conv2D(\n",
        "            self.input_filters,\n",
        "            self.filters,\n",
        "            self.filter_size,\n",
        "            self.activation, \n",
        "            strides=self.strides, \n",
        "            padding=self.padding, \n",
        "            kernel_initializer=self.kernel_initializer, \n",
        "            bias_initializer=self.bias_initializer \n",
        "        )\n",
        "        copy.F = self.F\n",
        "        copy.b = self.b\n",
        "        return copy\n",
        "    \n",
        "    def get_input_filters_count(self):\n",
        "        input_shape = self.get_input_shape()\n",
        "        return input_shape[-1]\n",
        "    \n",
        "    def get_size(self):\n",
        "        return self.get_input_filters_count(), self.F.shape[-1]\n",
        "    \n",
        "    def prune(self, threshold, active_input_units_indices):\n",
        "        # Remove connections from pruned units in previous layer\n",
        "        new_F = tf.gather(self.F.value(), active_input_units_indices, axis=-2)\n",
        "\n",
        "        if self.fixed_size:\n",
        "            active_output_filters_indices = list(range(new_F.shape[-1]))\n",
        "        else:\n",
        "            # Prune units in this layer\n",
        "            F_reduced_max = tf.reshape(tf.math.reduce_max(tf.abs(new_F), axis=(0, 1, 2)), (1, -1))\n",
        "            F_reduced_max_with_biases = tf.concat([F_reduced_max, tf.reshape(self.b.value(), (1, -1))], axis=0)\n",
        "            filters_are_active = tf.math.reduce_max(tf.abs(F_reduced_max_with_biases), axis=0) >= threshold\n",
        "            active_output_filters_indices = tf.reshape(tf.where(filters_are_active), (-1,))\n",
        "            \n",
        "            new_F = tf.gather(new_F, active_output_filters_indices, axis=-1)\n",
        "            new_b = tf.gather(self.b.value(), active_output_filters_indices, axis=0)\n",
        "\n",
        "            self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
        "\n",
        "        self.F = tf.Variable(name='F', initial_value=new_F, trainable=True)\n",
        "\n",
        "        return active_output_filters_indices\n",
        "\n",
        "    def grow(self, n_new_input_units, percentage, min_new_units, scaling_factor):\n",
        "        if n_new_input_units > 0:\n",
        "            # Add connections to grown units in previous layer\n",
        "            F_growth = self.F_init(shape=(self.F.shape[0], self.F.shape[1], self.F.shape[2] + n_new_input_units, self.F.shape[3]), dtype=dtype)[:, :, -n_new_input_units:, :] * scaling_factor  # TODO is it better to be multiplying here by scaling_factor? It does help with not increasing the max weights of existing neurons when new neurons are added.\n",
        "            new_F = tf.concat([self.F.value(), F_growth], axis=-2)\n",
        "        else:\n",
        "            new_F = self.F.value()\n",
        "\n",
        "        if self.fixed_size:\n",
        "            n_new_output_units = 0\n",
        "        else:\n",
        "            # Grow new units in this layer\n",
        "            n_new_output_units = max(min_new_units, int(new_F.shape[-1] * percentage))\n",
        "            F_growth = self.F_init(shape=(new_F.shape[0], new_F.shape[1], new_F.shape[2], new_F.shape[3] + n_new_output_units), dtype=dtype)[:, :, :, -n_new_output_units:] * scaling_factor\n",
        "            b_growth = self.b_init(shape=(n_new_output_units,), dtype=dtype)  # TODO for all possible bias initializers to work properly, the whole bias vector should be initialized at once\n",
        "            new_F = tf.concat([new_F, F_growth], axis=-1)\n",
        "            new_b = tf.concat([self.b.value(), b_growth], axis=0)\n",
        "\n",
        "            self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
        "\n",
        "        self.F = tf.Variable(name='F', initial_value=new_F, trainable=True)\n",
        "\n",
        "        return n_new_output_units\n",
        "\n",
        "    def get_param_string():\n",
        "        param_string = \"\"\n",
        "        # TODO\n",
        "        return param_string\n",
        "\n",
        "\n",
        "class Flatten(tf.keras.Model):\n",
        "    def call(self, inputs):\n",
        "        return tf.reshape(tf.transpose(inputs, perm=[0, 3, 1, 2]), (inputs.shape[0], -1))\n",
        "\n",
        "\n",
        "class Sequential(tf.keras.Model):\n",
        "    def __init__(self, layers, activation=None):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.lrs = list()\n",
        "        for layer in layers:\n",
        "            self.lrs.append(layer)\n",
        "            if isinstance(layer, CustomLayer):\n",
        "                layer.configure(self)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs\n",
        "        for layer in self.lrs:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "    \n",
        "    def get_layer_input_shape(self, target_layer):\n",
        "        input = np.random.normal(size=(1,) + self.lrs[0].inpt_shp)\n",
        "        for layer in self.lrs:\n",
        "            if layer is target_layer:\n",
        "                return tuple(input.shape[1:])\n",
        "            input = layer(input)\n",
        "        raise Exception(\"Layer not found in the model.\")\n",
        "\n",
        "    def get_layer_output_shape(self, target_layer):\n",
        "        input = np.random.normal(size=(1,) + self.lrs[0].inpt_shp)\n",
        "        for layer in self.lrs:\n",
        "            output = layer(input)\n",
        "            if layer is target_layer:\n",
        "                return tuple(output.shape[1:])\n",
        "            input = output\n",
        "        raise Exception(\"Layer not found in the model.\")\n",
        "    \n",
        "    def get_layer_sizes(self):\n",
        "        \"\"\"\n",
        "        Returns the sizes of all layers in the model, including the input and output layer.\n",
        "        \"\"\"\n",
        "        layer_sizes = list()\n",
        "        first_layer = True\n",
        "        for l in range(len(self.lrs)):\n",
        "            layer = self.lrs[l]\n",
        "            if isinstance(layer, CustomLayer):\n",
        "                layer_size = layer.get_size()\n",
        "                if first_layer:\n",
        "                    layer_sizes.append(layer_size[0])\n",
        "                    first_layer = False\n",
        "                layer_sizes.append(layer_size[1])\n",
        "        return layer_sizes\n",
        "    \n",
        "    def get_hidden_layer_sizes(self):\n",
        "        return self.get_layer_sizes()[1:-1]\n",
        "    \n",
        "    def remove_regularization(self):\n",
        "        # for l in range(len(self.lrs)):\n",
        "        #     layer = self.lrs[l]\n",
        "        #     if isinstance(layer, CustomLayer):\n",
        "        #         self.lrs[l] = layer.copy_without_regularization()\n",
        "        self.set_regularization_penalty(0.)\n",
        "    \n",
        "    def get_regularization_penalty(self):\n",
        "        return self.lrs[-2].regularizer.regularization_penalty\n",
        "    \n",
        "    def set_regularization_penalty(self, regularization_penalty):\n",
        "        for layer in self.lrs:\n",
        "            if isinstance(layer, CustomLayer) and not layer.fixed_size:\n",
        "                layer.regularizer.regularization_penalty = regularization_penalty\n",
        "    \n",
        "    def prune(self, threshold=0.001):\n",
        "        # for l in range(len(self.lrs) - 1):\n",
        "        #     layer1 = self.lrs[l]\n",
        "        #     layer2 = self.lrs[l + 1]\n",
        "            \n",
        "        #     W1 = layer1.W.value()\n",
        "        #     b1 = layer1.b.value()\n",
        "        #     W2 = layer2.W.value()\n",
        "\n",
        "        #     weights_with_biases = tf.concat([W1, tf.reshape(b1, (1, -1))], axis=0)\n",
        "        #     neurons_are_active = tf.math.reduce_max(tf.abs(weights_with_biases), axis=0) >= threshold\n",
        "        #     active_neurons_indices = tf.reshape(tf.where(neurons_are_active), (-1,))\n",
        "            \n",
        "        #     new_W1 = tf.gather(W1, active_neurons_indices, axis=1)\n",
        "        #     new_b1 = tf.gather(b1, active_neurons_indices, axis=0)\n",
        "        #     new_W2 = tf.gather(W2, active_neurons_indices, axis=0)\n",
        "\n",
        "        #     layer1.W = tf.Variable(name='W', initial_value=new_W1, trainable=True)\n",
        "        #     layer1.b = tf.Variable(name='b', initial_value=new_b1, trainable=True)\n",
        "        #     layer2.W = tf.Variable(name='W', initial_value=new_W2, trainable=True)\n",
        "        input_shape = self.lrs[0].get_input_shape()\n",
        "        n_input_units = input_shape[-1]\n",
        "        active_units_indices = list(range(n_input_units))\n",
        "\n",
        "        last_custom_layer = None\n",
        "        for layer in self.lrs:\n",
        "            if isinstance(layer, CustomLayer):\n",
        "                if last_custom_layer is not None and type(last_custom_layer) != type(layer):\n",
        "                    if type(last_custom_layer) == Conv2D and type(layer) == Dense:\n",
        "                        convolutional_shape = last_custom_layer.get_output_shape()\n",
        "                        active_units_indices = self.convert_channel_indices_to_flattened_indices(active_units_indices, convolutional_shape)\n",
        "                    else:\n",
        "                        raise Exception(\"Incorrect order of custom layer types.\")\n",
        "                active_units_indices = layer.prune(threshold, active_units_indices)\n",
        "                last_custom_layer = layer\n",
        "    \n",
        "    def grow(self, percentage, min_new_neurons=5, scaling_factor=0.001):   \n",
        "        # for l in range(len(self.lrs) - 1):\n",
        "        #     layer1 = self.lrs[l]\n",
        "        #     layer2 = self.lrs[l + 1]\n",
        "       \n",
        "        #     W1 = layer1.W.value()\n",
        "        #     b1 = layer1.b.value()\n",
        "        #     W2 = layer2.W.value()\n",
        "\n",
        "        #     n_new_neurons = max(min_new_neurons, int(W1.shape[1] * percentage))\n",
        "\n",
        "        #     W1_growth = layer1.W_init(shape=(W1.shape[0], W1.shape[1] + n_new_neurons), dtype=dtype)[:, -n_new_neurons:] * scaling_factor\n",
        "        #     b1_growth = layer1.b_init(shape=(n_new_neurons,), dtype=dtype)\n",
        "        #     W2_growth = layer2.W_init(shape=(W2.shape[0] + n_new_neurons, W2.shape[1]), dtype=dtype)[-n_new_neurons:, :] * scaling_factor  # TODO is it better to be multiplying here by scaling_factor? It does help with not increasing the max weights of existing neurons when new neurons are added.\n",
        "\n",
        "        #     new_W1 = tf.concat([W1, W1_growth], axis=1)\n",
        "        #     new_b1 = tf.concat([b1, b1_growth], axis=0)\n",
        "        #     new_W2 = tf.concat([W2, W2_growth], axis=0)\n",
        "\n",
        "        #     layer1.W = tf.Variable(name='W1', initial_value=new_W1, trainable=True)\n",
        "        #     layer1.b = tf.Variable(name='b1', initial_value=new_b1, trainable=True)\n",
        "        #     layer2.W = tf.Variable(name='W2', initial_value=new_W2, trainable=True)\n",
        "        n_new_units = 0\n",
        "\n",
        "        last_custom_layer = None\n",
        "        for layer in self.lrs:\n",
        "            if isinstance(layer, CustomLayer):\n",
        "                if last_custom_layer is not None and type(last_custom_layer) != type(layer):\n",
        "                    if type(last_custom_layer) == Conv2D and type(layer) == Dense:\n",
        "                        convolutional_shape = last_custom_layer.get_output_shape()\n",
        "                        n_new_units = n_new_units * convolutional_shape[0] * convolutional_shape[1]\n",
        "                    else:\n",
        "                        raise Exception(\"Incorrect order of custom layer types.\")\n",
        "                n_new_units = layer.grow(n_new_units, percentage, min_new_units=min_new_neurons, scaling_factor=scaling_factor)\n",
        "                last_custom_layer = layer\n",
        "    \n",
        "    @staticmethod\n",
        "    def convert_channel_indices_to_flattened_indices(channel_indices, convolutional_shape):\n",
        "        dense_indices = list()\n",
        "        units_per_channel = convolutional_shape[0] * convolutional_shape[1]\n",
        "        for channel_index in channel_indices:\n",
        "            for iter in range(units_per_channel):\n",
        "                dense_indices.append(channel_index * units_per_channel + iter)\n",
        "        return dense_indices\n",
        "    \n",
        "    def print_neurons(self):\n",
        "        for layer in self.lrs[:-1]:\n",
        "            print(layer.get_param_string())\n",
        "    \n",
        "    def evaluate(self, x, y, summed_training_loss, summed_training_accuracy, val_dataset):\n",
        "        # Calculate training loss and accuracy\n",
        "        if summed_training_loss is not None:\n",
        "            loss = summed_training_loss / x.shape[0]\n",
        "        else:\n",
        "            loss = None\n",
        "        \n",
        "        if summed_training_accuracy is not None:\n",
        "            accuracy = summed_training_accuracy / x.shape[0]\n",
        "        else:\n",
        "            accuracy = None\n",
        "        \n",
        "        # Calculate val loss and accuracy\n",
        "        summed_val_loss = 0\n",
        "        summed_val_accuracy = 0\n",
        "        n_val_instances = 0\n",
        "        \n",
        "        for step, (x_batch, y_batch) in enumerate(val_dataset):\n",
        "            y_pred = self(x_batch)\n",
        "            summed_val_loss += tf.reduce_sum(tf.keras.losses.sparse_categorical_crossentropy(y_batch, y_pred))\n",
        "            summed_val_accuracy += float(tf.reduce_sum(tf.keras.metrics.sparse_categorical_accuracy(y_batch, y_pred)))\n",
        "            n_val_instances += x_batch.shape[0]\n",
        "        \n",
        "        val_loss = summed_val_loss / n_val_instances\n",
        "        val_accuracy = summed_val_accuracy / n_val_instances\n",
        "\n",
        "        return loss, accuracy, val_loss, val_accuracy\n",
        "    \n",
        "    def print_epoch_statistics(self, x, y, summed_training_loss, summed_training_accuracy, val_dataset, print_neurons):\n",
        "        loss, accuracy, val_loss, val_accuracy = self.evaluate(x, y, summed_training_loss, summed_training_accuracy, val_dataset)\n",
        "        print(f\"loss: {loss} - accuracy: {accuracy} - val_loss: {val_loss} - val_accuracy: {val_accuracy} - penalty: {model.get_regularization_penalty()}\")\n",
        "        hidden_layer_sizes = self.get_hidden_layer_sizes()\n",
        "        print(f\"hidden layer sizes: {hidden_layer_sizes}, total units: {sum(hidden_layer_sizes)}\")\n",
        "        if print_neurons:\n",
        "            self.print_neurons()\n",
        "    \n",
        "    def update_history(self, x, y, summed_loss, summed_accuracy, val_dataset, history):\n",
        "        loss, accuracy, val_loss, val_accuracy = self.evaluate(x, y, summed_loss, summed_accuracy, val_dataset)\n",
        "        history['loss'].append(loss)\n",
        "        history['accuracy'].append(accuracy)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_accuracy'].append(val_accuracy)\n",
        "\n",
        "    def fit(self, x, y, optimizer, epochs, self_scaling_epochs, batch_size, min_new_neurons, validation_data, pruning_threshold=0.001, \n",
        "            regularization_penalty_multiplier=1., stall_coefficient=1, growth_percentage=0.2, mini_epochs_per_epoch=1, verbose=True, print_neurons=False):\n",
        "        train_dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "        train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "        val_dataset = tf.data.Dataset.from_tensor_slices(validation_data).batch(batch_size)\n",
        "\n",
        "        history = {\n",
        "            'loss': list(),\n",
        "            'accuracy': list(),\n",
        "            'val_loss': list(),\n",
        "            'val_accuracy': list(),\n",
        "        }\n",
        "\n",
        "        best_val_loss = np.inf\n",
        "        training_stalled = False\n",
        "        for epoch in range(epochs):\n",
        "            summed_loss = 0\n",
        "            summed_accuracy = 0\n",
        "\n",
        "            if verbose:\n",
        "                print(\"##########################################################\")\n",
        "                print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "            if epoch < self_scaling_epochs:\n",
        "                if verbose:\n",
        "                    print(\"Before growing:\")\n",
        "                    self.print_epoch_statistics(x, y, None, None, val_dataset, print_neurons)\n",
        "\n",
        "                loss, accuracy, val_loss, val_accuracy = self.evaluate(x, y, summed_loss, summed_accuracy, val_dataset)\n",
        "                if regularization_penalty_multiplier != 1. and val_loss >= best_val_loss * stall_coefficient:\n",
        "                    if not training_stalled:\n",
        "                        penalty = self.get_regularization_penalty() * regularization_penalty_multiplier\n",
        "                        print(\"Changing penalty...\")\n",
        "                        # TODO this must be modified, penalty can differ for each layer\n",
        "                        self.set_regularization_penalty(penalty)\n",
        "                        training_stalled = True\n",
        "                else:\n",
        "                    best_val_loss = val_loss\n",
        "                    training_stalled = False\n",
        "\n",
        "                self.grow(percentage=growth_percentage, min_new_neurons=min_new_neurons, scaling_factor=pruning_threshold)\n",
        "                if verbose:\n",
        "                    print(\"After growing:\")\n",
        "                    self.print_epoch_statistics(x, y, None, None, val_dataset, print_neurons)\n",
        "            \n",
        "            if epoch == self_scaling_epochs:\n",
        "                self.remove_regularization()\n",
        "\n",
        "            for mini_epoch in range(mini_epochs_per_epoch):\n",
        "                for step, (x_batch, y_batch) in enumerate(train_dataset):\n",
        "                    with tf.GradientTape() as tape:\n",
        "                        y_pred = self(x_batch, training=True)\n",
        "                        raw_loss = tf.keras.losses.sparse_categorical_crossentropy(y_batch, y_pred)\n",
        "                        loss_value = tf.reduce_mean(raw_loss)\n",
        "                        loss_value += sum(self.losses)  # Add losses registered by model.add_loss\n",
        "\n",
        "                        summed_loss += tf.reduce_sum(raw_loss)\n",
        "                        summed_accuracy += float(tf.reduce_sum(tf.keras.metrics.sparse_categorical_accuracy(y_batch, y_pred)))\n",
        "\n",
        "                    grads = tape.gradient(loss_value, self.trainable_variables)\n",
        "                    optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
        "            \n",
        "            if epoch < self_scaling_epochs:\n",
        "                if verbose:\n",
        "                    print(\"Before pruning:\")\n",
        "                    self.print_epoch_statistics(x, y, summed_loss, summed_accuracy, val_dataset, print_neurons)\n",
        "                self.prune(threshold=pruning_threshold)\n",
        "                if verbose:\n",
        "                    print(\"After pruning:\")\n",
        "                    self.print_epoch_statistics(x, y, None, None, val_dataset, print_neurons)\n",
        "            else:\n",
        "                if verbose:\n",
        "                    self.print_epoch_statistics(x, y, summed_loss, summed_accuracy, val_dataset, print_neurons)\n",
        "            \n",
        "            self.update_history(x, y, summed_loss, summed_accuracy, val_dataset, history)\n",
        "\n",
        "        return history"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1MrQXUTFwOe"
      },
      "source": [
        "# Convolutions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByLRkOAPoGcc"
      },
      "source": [
        "epochs = 20\n",
        "self_scaling_epochs = 20\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "382QHGlZvyl9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "337ec911-97e2-447f-867d-a77870803f61"
      },
      "source": [
        "model = Sequential([\n",
        "        Dense(20, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal', input_shape=X_train_norm[0, :].shape),\n",
        "        Dense(20, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        Dense(20, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        Dense(20, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None, fixed_size=True),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.847022533416748 - val_accuracy: 0.0938 - penalty: 1e-06\n",
            "hidden layer sizes: [20, 20, 20, 20], total units: 80\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.84702205657959 - val_accuracy: 0.0938 - penalty: 1e-06\n",
            "hidden layer sizes: [40, 40, 40, 40], total units: 160\n",
            "Before pruning:\n",
            "loss: 1.9452203512191772 - accuracy: 0.32256 - val_loss: 1.7487735748291016 - val_accuracy: 0.3872 - penalty: 1e-06\n",
            "hidden layer sizes: [40, 40, 40, 40], total units: 160\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.7487735748291016 - val_accuracy: 0.3872 - penalty: 1e-06\n",
            "hidden layer sizes: [40, 40, 40, 40], total units: 160\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.7487735748291016 - val_accuracy: 0.3872 - penalty: 1e-06\n",
            "hidden layer sizes: [40, 40, 40, 40], total units: 160\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.7487735748291016 - val_accuracy: 0.3872 - penalty: 1e-06\n",
            "hidden layer sizes: [60, 60, 60, 60], total units: 240\n",
            "Before pruning:\n",
            "loss: 1.6932038068771362 - accuracy: 0.40406 - val_loss: 1.617717981338501 - val_accuracy: 0.432 - penalty: 1e-06\n",
            "hidden layer sizes: [60, 60, 60, 60], total units: 240\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.617717981338501 - val_accuracy: 0.432 - penalty: 1e-06\n",
            "hidden layer sizes: [60, 60, 60, 60], total units: 240\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.617717981338501 - val_accuracy: 0.432 - penalty: 1e-06\n",
            "hidden layer sizes: [60, 60, 60, 60], total units: 240\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.617717981338501 - val_accuracy: 0.432 - penalty: 1e-06\n",
            "hidden layer sizes: [80, 80, 80, 80], total units: 320\n",
            "Before pruning:\n",
            "loss: 1.5950701236724854 - accuracy: 0.43732 - val_loss: 1.5567930936813354 - val_accuracy: 0.4541 - penalty: 1e-06\n",
            "hidden layer sizes: [80, 80, 80, 80], total units: 320\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.5567940473556519 - val_accuracy: 0.4542 - penalty: 1e-06\n",
            "hidden layer sizes: [78, 80, 80, 80], total units: 318\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.5567940473556519 - val_accuracy: 0.4542 - penalty: 1e-06\n",
            "hidden layer sizes: [78, 80, 80, 80], total units: 318\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.5567940473556519 - val_accuracy: 0.4542 - penalty: 1e-06\n",
            "hidden layer sizes: [98, 100, 100, 100], total units: 398\n",
            "Before pruning:\n",
            "loss: 1.531063437461853 - accuracy: 0.46044 - val_loss: 1.5098843574523926 - val_accuracy: 0.4652 - penalty: 1e-06\n",
            "hidden layer sizes: [98, 100, 100, 100], total units: 398\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.509883165359497 - val_accuracy: 0.4651 - penalty: 1e-06\n",
            "hidden layer sizes: [98, 100, 92, 96], total units: 386\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.509883165359497 - val_accuracy: 0.4651 - penalty: 1e-06\n",
            "hidden layer sizes: [98, 100, 92, 96], total units: 386\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.5098830461502075 - val_accuracy: 0.4651 - penalty: 1e-06\n",
            "hidden layer sizes: [118, 120, 112, 116], total units: 466\n",
            "Before pruning:\n",
            "loss: 1.486151933670044 - accuracy: 0.47494 - val_loss: 1.4772998094558716 - val_accuracy: 0.48 - penalty: 1e-06\n",
            "hidden layer sizes: [118, 120, 112, 116], total units: 466\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4772988557815552 - val_accuracy: 0.48 - penalty: 1e-06\n",
            "hidden layer sizes: [114, 120, 103, 103], total units: 440\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4772988557815552 - val_accuracy: 0.48 - penalty: 1e-06\n",
            "hidden layer sizes: [114, 120, 103, 103], total units: 440\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4772988557815552 - val_accuracy: 0.48 - penalty: 1e-06\n",
            "hidden layer sizes: [136, 144, 123, 123], total units: 526\n",
            "Before pruning:\n",
            "loss: 1.4510244131088257 - accuracy: 0.48604 - val_loss: 1.4682587385177612 - val_accuracy: 0.4808 - penalty: 1e-06\n",
            "hidden layer sizes: [136, 144, 123, 123], total units: 526\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4682543277740479 - val_accuracy: 0.4807 - penalty: 1e-06\n",
            "hidden layer sizes: [132, 144, 114, 111], total units: 501\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4682543277740479 - val_accuracy: 0.4807 - penalty: 1e-06\n",
            "hidden layer sizes: [132, 144, 114, 111], total units: 501\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4682543277740479 - val_accuracy: 0.4807 - penalty: 1e-06\n",
            "hidden layer sizes: [158, 172, 136, 133], total units: 599\n",
            "Before pruning:\n",
            "loss: 1.4220269918441772 - accuracy: 0.49738 - val_loss: 1.4586914777755737 - val_accuracy: 0.4828 - penalty: 1e-06\n",
            "hidden layer sizes: [158, 172, 136, 133], total units: 599\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4587644338607788 - val_accuracy: 0.4828 - penalty: 1e-06\n",
            "hidden layer sizes: [148, 168, 122, 116], total units: 554\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4587644338607788 - val_accuracy: 0.4828 - penalty: 1e-06\n",
            "hidden layer sizes: [148, 168, 122, 116], total units: 554\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4587644338607788 - val_accuracy: 0.4828 - penalty: 1e-06\n",
            "hidden layer sizes: [177, 201, 146, 139], total units: 663\n",
            "Before pruning:\n",
            "loss: 1.3944101333618164 - accuracy: 0.50546 - val_loss: 1.4363137483596802 - val_accuracy: 0.4952 - penalty: 1e-06\n",
            "hidden layer sizes: [177, 201, 146, 139], total units: 663\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4362996816635132 - val_accuracy: 0.495 - penalty: 1e-06\n",
            "hidden layer sizes: [172, 196, 134, 110], total units: 612\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4362996816635132 - val_accuracy: 0.495 - penalty: 1e-06\n",
            "hidden layer sizes: [172, 196, 134, 110], total units: 612\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4362998008728027 - val_accuracy: 0.495 - penalty: 1e-06\n",
            "hidden layer sizes: [206, 235, 160, 132], total units: 733\n",
            "Before pruning:\n",
            "loss: 1.3739022016525269 - accuracy: 0.51368 - val_loss: 1.4447834491729736 - val_accuracy: 0.4908 - penalty: 1e-06\n",
            "hidden layer sizes: [206, 235, 160, 132], total units: 733\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4447710514068604 - val_accuracy: 0.4908 - penalty: 1e-06\n",
            "hidden layer sizes: [194, 218, 131, 118], total units: 661\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4447710514068604 - val_accuracy: 0.4908 - penalty: 1e-06\n",
            "hidden layer sizes: [194, 218, 131, 118], total units: 661\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.44477117061615 - val_accuracy: 0.4908 - penalty: 1e-06\n",
            "hidden layer sizes: [232, 261, 157, 141], total units: 791\n",
            "Before pruning:\n",
            "loss: 1.3534380197525024 - accuracy: 0.51908 - val_loss: 1.426801085472107 - val_accuracy: 0.4967 - penalty: 1e-06\n",
            "hidden layer sizes: [232, 261, 157, 141], total units: 791\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4268704652786255 - val_accuracy: 0.4968 - penalty: 1e-06\n",
            "hidden layer sizes: [203, 217, 125, 119], total units: 664\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4268704652786255 - val_accuracy: 0.4968 - penalty: 1e-06\n",
            "hidden layer sizes: [203, 217, 125, 119], total units: 664\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.426870584487915 - val_accuracy: 0.4968 - penalty: 1e-06\n",
            "hidden layer sizes: [243, 260, 150, 142], total units: 795\n",
            "Before pruning:\n",
            "loss: 1.3362910747528076 - accuracy: 0.52698 - val_loss: 1.4262040853500366 - val_accuracy: 0.4949 - penalty: 1e-06\n",
            "hidden layer sizes: [243, 260, 150, 142], total units: 795\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4262185096740723 - val_accuracy: 0.4946 - penalty: 1e-06\n",
            "hidden layer sizes: [228, 210, 132, 128], total units: 698\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4262185096740723 - val_accuracy: 0.4946 - penalty: 1e-06\n",
            "hidden layer sizes: [228, 210, 132, 128], total units: 698\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4262185096740723 - val_accuracy: 0.4946 - penalty: 1e-06\n",
            "hidden layer sizes: [273, 252, 158, 153], total units: 836\n",
            "Before pruning:\n",
            "loss: 1.3206266164779663 - accuracy: 0.53322 - val_loss: 1.4255939722061157 - val_accuracy: 0.4931 - penalty: 1e-06\n",
            "hidden layer sizes: [273, 252, 158, 153], total units: 836\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4254165887832642 - val_accuracy: 0.4928 - penalty: 1e-06\n",
            "hidden layer sizes: [212, 229, 120, 130], total units: 691\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4254165887832642 - val_accuracy: 0.4928 - penalty: 1e-06\n",
            "hidden layer sizes: [212, 229, 120, 130], total units: 691\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4254164695739746 - val_accuracy: 0.4928 - penalty: 1e-06\n",
            "hidden layer sizes: [254, 274, 144, 156], total units: 828\n",
            "Before pruning:\n",
            "loss: 1.305312156677246 - accuracy: 0.53872 - val_loss: 1.4191508293151855 - val_accuracy: 0.5 - penalty: 1e-06\n",
            "hidden layer sizes: [254, 274, 144, 156], total units: 828\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4190995693206787 - val_accuracy: 0.4999 - penalty: 1e-06\n",
            "hidden layer sizes: [238, 263, 121, 129], total units: 751\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4190995693206787 - val_accuracy: 0.4999 - penalty: 1e-06\n",
            "hidden layer sizes: [238, 263, 121, 129], total units: 751\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4190994501113892 - val_accuracy: 0.4999 - penalty: 1e-06\n",
            "hidden layer sizes: [285, 315, 145, 154], total units: 899\n",
            "Before pruning:\n",
            "loss: 1.2916194200515747 - accuracy: 0.54382 - val_loss: 1.417806625366211 - val_accuracy: 0.4987 - penalty: 1e-06\n",
            "hidden layer sizes: [285, 315, 145, 154], total units: 899\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.417663335800171 - val_accuracy: 0.4989 - penalty: 1e-06\n",
            "hidden layer sizes: [241, 293, 121, 140], total units: 795\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.417663335800171 - val_accuracy: 0.4989 - penalty: 1e-06\n",
            "hidden layer sizes: [241, 293, 121, 140], total units: 795\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4176632165908813 - val_accuracy: 0.4989 - penalty: 1e-06\n",
            "hidden layer sizes: [289, 351, 145, 168], total units: 953\n",
            "Before pruning:\n",
            "loss: 1.27534019947052 - accuracy: 0.55034 - val_loss: 1.413841962814331 - val_accuracy: 0.4989 - penalty: 1e-06\n",
            "hidden layer sizes: [289, 351, 145, 168], total units: 953\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4138699769973755 - val_accuracy: 0.4987 - penalty: 1e-06\n",
            "hidden layer sizes: [267, 288, 115, 139], total units: 809\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4138699769973755 - val_accuracy: 0.4987 - penalty: 1e-06\n",
            "hidden layer sizes: [267, 288, 115, 139], total units: 809\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4138699769973755 - val_accuracy: 0.4987 - penalty: 1e-06\n",
            "hidden layer sizes: [320, 345, 138, 166], total units: 969\n",
            "Before pruning:\n",
            "loss: 1.260942816734314 - accuracy: 0.55546 - val_loss: 1.4225391149520874 - val_accuracy: 0.4966 - penalty: 1e-06\n",
            "hidden layer sizes: [320, 345, 138, 166], total units: 969\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4219051599502563 - val_accuracy: 0.4971 - penalty: 1e-06\n",
            "hidden layer sizes: [268, 299, 131, 158], total units: 856\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4219051599502563 - val_accuracy: 0.4971 - penalty: 1e-06\n",
            "hidden layer sizes: [268, 299, 131, 158], total units: 856\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4219053983688354 - val_accuracy: 0.4971 - penalty: 1e-06\n",
            "hidden layer sizes: [321, 358, 157, 189], total units: 1025\n",
            "Before pruning:\n",
            "loss: 1.2511773109436035 - accuracy: 0.55652 - val_loss: 1.413221836090088 - val_accuracy: 0.4987 - penalty: 1e-06\n",
            "hidden layer sizes: [321, 358, 157, 189], total units: 1025\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4132758378982544 - val_accuracy: 0.4986 - penalty: 1e-06\n",
            "hidden layer sizes: [298, 316, 143, 161], total units: 918\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4132758378982544 - val_accuracy: 0.4986 - penalty: 1e-06\n",
            "hidden layer sizes: [298, 316, 143, 161], total units: 918\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4132758378982544 - val_accuracy: 0.4986 - penalty: 1e-06\n",
            "hidden layer sizes: [357, 379, 171, 193], total units: 1100\n",
            "Before pruning:\n",
            "loss: 1.2374706268310547 - accuracy: 0.5622 - val_loss: 1.4080685377120972 - val_accuracy: 0.4979 - penalty: 1e-06\n",
            "hidden layer sizes: [357, 379, 171, 193], total units: 1100\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4082773923873901 - val_accuracy: 0.4976 - penalty: 1e-06\n",
            "hidden layer sizes: [250, 323, 141, 174], total units: 888\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4082773923873901 - val_accuracy: 0.4976 - penalty: 1e-06\n",
            "hidden layer sizes: [250, 323, 141, 174], total units: 888\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4082773923873901 - val_accuracy: 0.4976 - penalty: 1e-06\n",
            "hidden layer sizes: [300, 387, 169, 208], total units: 1064\n",
            "Before pruning:\n",
            "loss: 1.2334518432617188 - accuracy: 0.56502 - val_loss: 1.4120644330978394 - val_accuracy: 0.4982 - penalty: 1e-06\n",
            "hidden layer sizes: [300, 387, 169, 208], total units: 1064\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4121218919754028 - val_accuracy: 0.498 - penalty: 1e-06\n",
            "hidden layer sizes: [262, 311, 146, 156], total units: 875\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4121218919754028 - val_accuracy: 0.498 - penalty: 1e-06\n",
            "hidden layer sizes: [262, 311, 146, 156], total units: 875\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4121216535568237 - val_accuracy: 0.498 - penalty: 1e-06\n",
            "hidden layer sizes: [314, 373, 175, 187], total units: 1049\n",
            "Before pruning:\n",
            "loss: 1.2193961143493652 - accuracy: 0.56912 - val_loss: 1.4202760457992554 - val_accuracy: 0.4993 - penalty: 1e-06\n",
            "hidden layer sizes: [314, 373, 175, 187], total units: 1049\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4200063943862915 - val_accuracy: 0.4996 - penalty: 1e-06\n",
            "hidden layer sizes: [274, 319, 153, 152], total units: 898\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.32256,\n",
              "  0.40406,\n",
              "  0.43732,\n",
              "  0.46044,\n",
              "  0.47494,\n",
              "  0.48604,\n",
              "  0.49738,\n",
              "  0.50546,\n",
              "  0.51368,\n",
              "  0.51908,\n",
              "  0.52698,\n",
              "  0.53322,\n",
              "  0.53872,\n",
              "  0.54382,\n",
              "  0.55034,\n",
              "  0.55546,\n",
              "  0.55652,\n",
              "  0.5622,\n",
              "  0.56502,\n",
              "  0.56912],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.9452204>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.6932038>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.5950701>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.5310634>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4861519>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4510244>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.422027>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3944101>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3739022>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.353438>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3362911>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3206266>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3053122>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2916194>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2753402>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2609428>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2511773>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2374706>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2334518>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2193961>],\n",
              " 'val_accuracy': [0.3872,\n",
              "  0.432,\n",
              "  0.4542,\n",
              "  0.4651,\n",
              "  0.48,\n",
              "  0.4807,\n",
              "  0.4828,\n",
              "  0.495,\n",
              "  0.4908,\n",
              "  0.4968,\n",
              "  0.4946,\n",
              "  0.4928,\n",
              "  0.4999,\n",
              "  0.4989,\n",
              "  0.4987,\n",
              "  0.4971,\n",
              "  0.4986,\n",
              "  0.4976,\n",
              "  0.498,\n",
              "  0.4996],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.7487736>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.617718>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.556794>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.5098832>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4772989>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4682543>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4587644>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4362997>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.444771>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4268705>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4262185>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4254166>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4190996>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4176633>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.41387>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4219052>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4132758>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4082774>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4121219>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4200064>]}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C3tMuzb7m2s"
      },
      "source": [
        "model = Sequential([\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        # tf.keras.layers.Flatten(),\n",
        "        Dense(256, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None, fixed_size=True),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-suYTV264gm"
      },
      "source": [
        "# 74.5 % vs 71.5 % accuracy in the following two models - 3 % boost! (output lost)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6J2bR2B9Zam"
      },
      "source": [
        "## Dynamic models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68VYqDLJ969f"
      },
      "source": [
        "epochs = 20\n",
        "self_scaling_epochs = 20\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQnJaU_Ray-V",
        "outputId": "9d5e40e3-5223-4fe1-c01a-a267f89be8bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential([\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None, fixed_size=True),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.963027238845825 - val_accuracy: 0.0795 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.963027238845825 - val_accuracy: 0.0795 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.8671212196350098 - accuracy: 0.38654 - val_loss: 1.3841943740844727 - val_accuracy: 0.5051 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.3840810060501099 - val_accuracy: 0.5043 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 257], total units: 1025\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.3840810060501099 - val_accuracy: 0.5043 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 257], total units: 1025\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.3840810060501099 - val_accuracy: 0.5043 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 308], total units: 1228\n",
            "Before pruning:\n",
            "loss: 1.5167487859725952 - accuracy: 0.45996 - val_loss: 1.304641842842102 - val_accuracy: 0.5286 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 308], total units: 1228\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.304631233215332 - val_accuracy: 0.5282 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 199, 256], total units: 1031\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.304631233215332 - val_accuracy: 0.5282 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 199, 256], total units: 1031\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.304631233215332 - val_accuracy: 0.5282 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 238, 307], total units: 1235\n",
            "Before pruning:\n",
            "loss: 1.3350378274917603 - accuracy: 0.5233 - val_loss: 1.1858943700790405 - val_accuracy: 0.5726 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 238, 307], total units: 1235\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1857129335403442 - val_accuracy: 0.5728 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 193, 259], total units: 1028\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1857129335403442 - val_accuracy: 0.5728 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 193, 259], total units: 1028\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1857129335403442 - val_accuracy: 0.5728 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 231, 310], total units: 1231\n",
            "Before pruning:\n",
            "loss: 1.2161905765533447 - accuracy: 0.56528 - val_loss: 1.1129087209701538 - val_accuracy: 0.5999 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 231, 310], total units: 1231\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1126041412353516 - val_accuracy: 0.6004 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 180, 182, 192, 258], total units: 1004\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1126041412353516 - val_accuracy: 0.6004 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 180, 182, 192, 258], total units: 1004\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1126041412353516 - val_accuracy: 0.6004 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 216, 218, 230, 309], total units: 1203\n",
            "Before pruning:\n",
            "loss: 1.1187293529510498 - accuracy: 0.60158 - val_loss: 1.0171185731887817 - val_accuracy: 0.6407 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 216, 218, 230, 309], total units: 1203\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0162806510925293 - val_accuracy: 0.6403 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 131, 165, 194, 285], total units: 967\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0162806510925293 - val_accuracy: 0.6403 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 131, 165, 194, 285], total units: 967\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0162804126739502 - val_accuracy: 0.6403 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 157, 198, 232, 342], total units: 1159\n",
            "Before pruning:\n",
            "loss: 1.0229793787002563 - accuracy: 0.6377 - val_loss: 0.947227954864502 - val_accuracy: 0.6621 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 157, 198, 232, 342], total units: 1159\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9468349814414978 - val_accuracy: 0.663 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 94, 156, 199, 268], total units: 909\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9468349814414978 - val_accuracy: 0.663 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 94, 156, 199, 268], total units: 909\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9468348622322083 - val_accuracy: 0.663 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 114, 187, 238, 321], total units: 1090\n",
            "Before pruning:\n",
            "loss: 0.9530110359191895 - accuracy: 0.66296 - val_loss: 0.8898763656616211 - val_accuracy: 0.6846 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 114, 187, 238, 321], total units: 1090\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8898091912269592 - val_accuracy: 0.6844 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 86, 139, 208, 275], total units: 900\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8898091912269592 - val_accuracy: 0.6844 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 86, 139, 208, 275], total units: 900\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8898091912269592 - val_accuracy: 0.6844 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 106, 166, 249, 330], total units: 1081\n",
            "Before pruning:\n",
            "loss: 0.8919062614440918 - accuracy: 0.68452 - val_loss: 0.8546335101127625 - val_accuracy: 0.6997 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 106, 166, 249, 330], total units: 1081\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8546062707901001 - val_accuracy: 0.6996 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 75, 124, 225, 291], total units: 907\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8546062707901001 - val_accuracy: 0.6996 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 75, 124, 225, 291], total units: 907\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8546061515808105 - val_accuracy: 0.6996 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 95, 148, 270, 349], total units: 1092\n",
            "Before pruning:\n",
            "loss: 0.8516693115234375 - accuracy: 0.69782 - val_loss: 0.8437287211418152 - val_accuracy: 0.7068 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 95, 148, 270, 349], total units: 1092\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8436052799224854 - val_accuracy: 0.7069 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 71, 115, 241, 328], total units: 946\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8436052799224854 - val_accuracy: 0.7069 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 71, 115, 241, 328], total units: 946\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8436052799224854 - val_accuracy: 0.7069 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 91, 138, 289, 393], total units: 1140\n",
            "Before pruning:\n",
            "loss: 0.8148197531700134 - accuracy: 0.71044 - val_loss: 0.8297868967056274 - val_accuracy: 0.7061 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 91, 138, 289, 393], total units: 1140\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8295626044273376 - val_accuracy: 0.7058 - penalty: 1e-06\n",
            "hidden layer sizes: [187, 66, 104, 250, 352], total units: 959\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8295626044273376 - val_accuracy: 0.7058 - penalty: 1e-06\n",
            "hidden layer sizes: [187, 66, 104, 250, 352], total units: 959\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8295627236366272 - val_accuracy: 0.7057 - penalty: 1e-06\n",
            "hidden layer sizes: [224, 86, 124, 300, 422], total units: 1156\n",
            "Before pruning:\n",
            "loss: 0.7849943041801453 - accuracy: 0.72276 - val_loss: 0.8167417645454407 - val_accuracy: 0.7146 - penalty: 1e-06\n",
            "hidden layer sizes: [224, 86, 124, 300, 422], total units: 1156\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8165286183357239 - val_accuracy: 0.7148 - penalty: 1e-06\n",
            "hidden layer sizes: [184, 62, 93, 254, 369], total units: 962\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8165286183357239 - val_accuracy: 0.7148 - penalty: 1e-06\n",
            "hidden layer sizes: [184, 62, 93, 254, 369], total units: 962\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8165287375450134 - val_accuracy: 0.7148 - penalty: 1e-06\n",
            "hidden layer sizes: [220, 82, 113, 304, 442], total units: 1161\n",
            "Before pruning:\n",
            "loss: 0.7655342221260071 - accuracy: 0.72994 - val_loss: 0.7894124984741211 - val_accuracy: 0.7225 - penalty: 1e-06\n",
            "hidden layer sizes: [220, 82, 113, 304, 442], total units: 1161\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7893617153167725 - val_accuracy: 0.7225 - penalty: 1e-06\n",
            "hidden layer sizes: [179, 59, 91, 249, 381], total units: 959\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7893617153167725 - val_accuracy: 0.7225 - penalty: 1e-06\n",
            "hidden layer sizes: [179, 59, 91, 249, 381], total units: 959\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7893617153167725 - val_accuracy: 0.7225 - penalty: 1e-06\n",
            "hidden layer sizes: [214, 79, 111, 298, 457], total units: 1159\n",
            "Before pruning:\n",
            "loss: 0.7458457946777344 - accuracy: 0.73536 - val_loss: 0.7913826704025269 - val_accuracy: 0.7198 - penalty: 1e-06\n",
            "hidden layer sizes: [214, 79, 111, 298, 457], total units: 1159\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7913693189620972 - val_accuracy: 0.7198 - penalty: 1e-06\n",
            "hidden layer sizes: [173, 58, 89, 255, 398], total units: 973\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7913693189620972 - val_accuracy: 0.7198 - penalty: 1e-06\n",
            "hidden layer sizes: [173, 58, 89, 255, 398], total units: 973\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7913693189620972 - val_accuracy: 0.7198 - penalty: 1e-06\n",
            "hidden layer sizes: [207, 78, 109, 306, 477], total units: 1177\n",
            "Before pruning:\n",
            "loss: 0.7267219424247742 - accuracy: 0.74644 - val_loss: 0.7885811924934387 - val_accuracy: 0.7245 - penalty: 1e-06\n",
            "hidden layer sizes: [207, 78, 109, 306, 477], total units: 1177\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7886152267456055 - val_accuracy: 0.7244 - penalty: 1e-06\n",
            "hidden layer sizes: [169, 58, 81, 260, 360], total units: 928\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7886152267456055 - val_accuracy: 0.7244 - penalty: 1e-06\n",
            "hidden layer sizes: [169, 58, 81, 260, 360], total units: 928\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7886152863502502 - val_accuracy: 0.7244 - penalty: 1e-06\n",
            "hidden layer sizes: [202, 78, 101, 312, 432], total units: 1125\n",
            "Before pruning:\n",
            "loss: 0.7069907188415527 - accuracy: 0.75044 - val_loss: 0.7790190577507019 - val_accuracy: 0.726 - penalty: 1e-06\n",
            "hidden layer sizes: [202, 78, 101, 312, 432], total units: 1125\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7788867354393005 - val_accuracy: 0.7262 - penalty: 1e-06\n",
            "hidden layer sizes: [159, 55, 84, 273, 355], total units: 926\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7788867354393005 - val_accuracy: 0.7262 - penalty: 1e-06\n",
            "hidden layer sizes: [159, 55, 84, 273, 355], total units: 926\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7788867354393005 - val_accuracy: 0.7262 - penalty: 1e-06\n",
            "hidden layer sizes: [190, 75, 104, 327, 426], total units: 1122\n",
            "Before pruning:\n",
            "loss: 0.6895431280136108 - accuracy: 0.75626 - val_loss: 0.7799628376960754 - val_accuracy: 0.725 - penalty: 1e-06\n",
            "hidden layer sizes: [190, 75, 104, 327, 426], total units: 1122\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7800217270851135 - val_accuracy: 0.7249 - penalty: 1e-06\n",
            "hidden layer sizes: [152, 56, 78, 272, 362], total units: 920\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7800217270851135 - val_accuracy: 0.7249 - penalty: 1e-06\n",
            "hidden layer sizes: [152, 56, 78, 272, 362], total units: 920\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7800217270851135 - val_accuracy: 0.7249 - penalty: 1e-06\n",
            "hidden layer sizes: [182, 76, 98, 326, 434], total units: 1116\n",
            "Before pruning:\n",
            "loss: 0.6785920262336731 - accuracy: 0.75946 - val_loss: 0.7791489958763123 - val_accuracy: 0.733 - penalty: 1e-06\n",
            "hidden layer sizes: [182, 76, 98, 326, 434], total units: 1116\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7789269685745239 - val_accuracy: 0.7329 - penalty: 1e-06\n",
            "hidden layer sizes: [149, 63, 74, 272, 420], total units: 978\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7789269685745239 - val_accuracy: 0.7329 - penalty: 1e-06\n",
            "hidden layer sizes: [149, 63, 74, 272, 420], total units: 978\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7789270281791687 - val_accuracy: 0.7329 - penalty: 1e-06\n",
            "hidden layer sizes: [178, 83, 94, 326, 504], total units: 1185\n",
            "Before pruning:\n",
            "loss: 0.6671287417411804 - accuracy: 0.7638 - val_loss: 0.7715978622436523 - val_accuracy: 0.734 - penalty: 1e-06\n",
            "hidden layer sizes: [178, 83, 94, 326, 504], total units: 1185\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7713760137557983 - val_accuracy: 0.7337 - penalty: 1e-06\n",
            "hidden layer sizes: [146, 54, 85, 270, 470], total units: 1025\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7713760137557983 - val_accuracy: 0.7337 - penalty: 1e-06\n",
            "hidden layer sizes: [146, 54, 85, 270, 470], total units: 1025\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7713760137557983 - val_accuracy: 0.7337 - penalty: 1e-06\n",
            "hidden layer sizes: [175, 74, 105, 324, 564], total units: 1242\n",
            "Before pruning:\n",
            "loss: 0.6534648537635803 - accuracy: 0.76808 - val_loss: 0.7684080004692078 - val_accuracy: 0.731 - penalty: 1e-06\n",
            "hidden layer sizes: [175, 74, 105, 324, 564], total units: 1242\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7684280276298523 - val_accuracy: 0.7306 - penalty: 1e-06\n",
            "hidden layer sizes: [139, 56, 71, 268, 424], total units: 958\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7684280276298523 - val_accuracy: 0.7306 - penalty: 1e-06\n",
            "hidden layer sizes: [139, 56, 71, 268, 424], total units: 958\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7684279680252075 - val_accuracy: 0.7306 - penalty: 1e-06\n",
            "hidden layer sizes: [166, 76, 91, 321, 508], total units: 1162\n",
            "Before pruning:\n",
            "loss: 0.6403169631958008 - accuracy: 0.77302 - val_loss: 0.775848388671875 - val_accuracy: 0.7316 - penalty: 1e-06\n",
            "hidden layer sizes: [166, 76, 91, 321, 508], total units: 1162\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.775759220123291 - val_accuracy: 0.7313 - penalty: 1e-06\n",
            "hidden layer sizes: [131, 51, 72, 277, 438], total units: 969\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.38654,\n",
              "  0.45996,\n",
              "  0.5233,\n",
              "  0.56528,\n",
              "  0.60158,\n",
              "  0.6377,\n",
              "  0.66296,\n",
              "  0.68452,\n",
              "  0.69782,\n",
              "  0.71044,\n",
              "  0.72276,\n",
              "  0.72994,\n",
              "  0.73536,\n",
              "  0.74644,\n",
              "  0.75044,\n",
              "  0.75626,\n",
              "  0.75946,\n",
              "  0.7638,\n",
              "  0.76808,\n",
              "  0.77302],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.8671212>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.5167488>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3350378>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2161906>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1187294>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0229794>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.95301104>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.89190626>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8516693>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.81481975>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7849943>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7655342>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7458458>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.72672194>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7069907>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6895431>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.678592>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.66712874>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.65346485>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.64031696>],\n",
              " 'val_accuracy': [0.5043,\n",
              "  0.5282,\n",
              "  0.5728,\n",
              "  0.6004,\n",
              "  0.6403,\n",
              "  0.663,\n",
              "  0.6844,\n",
              "  0.6996,\n",
              "  0.7069,\n",
              "  0.7058,\n",
              "  0.7148,\n",
              "  0.7225,\n",
              "  0.7198,\n",
              "  0.7244,\n",
              "  0.7262,\n",
              "  0.7249,\n",
              "  0.7329,\n",
              "  0.7337,\n",
              "  0.7306,\n",
              "  0.7313],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.384081>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3046312>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1857129>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1126041>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0162807>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.946835>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8898092>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8546063>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8436053>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8295626>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8165286>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7893617>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7913693>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7886152>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.77888674>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7800217>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.77892697>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.771376>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.768428>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7757592>]}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0z5bWkr98dk",
        "outputId": "6b69fadc-acd4-4517-c8dc-e6469aac4ef2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential([\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None, fixed_size=True),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.965449810028076 - val_accuracy: 0.0943 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.9654500484466553 - val_accuracy: 0.0943 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.9078271389007568 - accuracy: 0.38218 - val_loss: 1.427015781402588 - val_accuracy: 0.4892 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.426162838935852 - val_accuracy: 0.4891 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 261], total units: 1029\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.426162838935852 - val_accuracy: 0.4891 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 261], total units: 1029\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4261629581451416 - val_accuracy: 0.4891 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 313], total units: 1233\n",
            "Before pruning:\n",
            "loss: 1.4895902872085571 - accuracy: 0.47094 - val_loss: 1.263016700744629 - val_accuracy: 0.5462 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 313], total units: 1233\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.2628270387649536 - val_accuracy: 0.546 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2628270387649536 - val_accuracy: 0.546 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2628271579742432 - val_accuracy: 0.546 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.3357962369918823 - accuracy: 0.52314 - val_loss: 1.1886502504348755 - val_accuracy: 0.5717 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.188405990600586 - val_accuracy: 0.5719 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.188405990600586 - val_accuracy: 0.5719 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.188405990600586 - val_accuracy: 0.5719 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.2331066131591797 - accuracy: 0.56054 - val_loss: 1.107539415359497 - val_accuracy: 0.6053 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1074802875518799 - val_accuracy: 0.6056 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 184, 189, 192, 265], total units: 1022\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1074802875518799 - val_accuracy: 0.6056 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 184, 189, 192, 265], total units: 1022\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1074801683425903 - val_accuracy: 0.6056 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 220, 226, 230, 318], total units: 1224\n",
            "Before pruning:\n",
            "loss: 1.1451588869094849 - accuracy: 0.591 - val_loss: 1.029172420501709 - val_accuracy: 0.6346 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 220, 226, 230, 318], total units: 1224\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0291587114334106 - val_accuracy: 0.6349 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 144, 175, 192, 269], total units: 972\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0291587114334106 - val_accuracy: 0.6349 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 144, 175, 192, 269], total units: 972\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0291587114334106 - val_accuracy: 0.6349 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 172, 210, 230, 322], total units: 1164\n",
            "Before pruning:\n",
            "loss: 1.0575878620147705 - accuracy: 0.6224 - val_loss: 0.9810765385627747 - val_accuracy: 0.653 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 172, 210, 230, 322], total units: 1164\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9812194108963013 - val_accuracy: 0.6526 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 100, 164, 197, 259], total units: 912\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9812194108963013 - val_accuracy: 0.6526 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 100, 164, 197, 259], total units: 912\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9812195301055908 - val_accuracy: 0.6526 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 120, 196, 236, 310], total units: 1092\n",
            "Before pruning:\n",
            "loss: 0.9986783862113953 - accuracy: 0.64552 - val_loss: 0.923439621925354 - val_accuracy: 0.6735 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 120, 196, 236, 310], total units: 1092\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9232416152954102 - val_accuracy: 0.6736 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 80, 158, 199, 263], total units: 892\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9232416152954102 - val_accuracy: 0.6736 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 80, 158, 199, 263], total units: 892\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9232416152954102 - val_accuracy: 0.6736 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 100, 189, 238, 315], total units: 1072\n",
            "Before pruning:\n",
            "loss: 0.9431843757629395 - accuracy: 0.66534 - val_loss: 0.8951692581176758 - val_accuracy: 0.6828 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 100, 189, 238, 315], total units: 1072\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8949394822120667 - val_accuracy: 0.6831 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 74, 139, 209, 268], total units: 882\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8949394822120667 - val_accuracy: 0.6831 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 74, 139, 209, 268], total units: 882\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8949394822120667 - val_accuracy: 0.6831 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 94, 166, 250, 321], total units: 1061\n",
            "Before pruning:\n",
            "loss: 0.8991597890853882 - accuracy: 0.68246 - val_loss: 0.8602918982505798 - val_accuracy: 0.6969 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 94, 166, 250, 321], total units: 1061\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8602458238601685 - val_accuracy: 0.6968 - penalty: 1e-06\n",
            "hidden layer sizes: [190, 66, 127, 212, 268], total units: 863\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8602458238601685 - val_accuracy: 0.6968 - penalty: 1e-06\n",
            "hidden layer sizes: [190, 66, 127, 212, 268], total units: 863\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8602458238601685 - val_accuracy: 0.6968 - penalty: 1e-06\n",
            "hidden layer sizes: [228, 86, 152, 254, 321], total units: 1041\n",
            "Before pruning:\n",
            "loss: 0.8475485444068909 - accuracy: 0.69776 - val_loss: 0.8503279089927673 - val_accuracy: 0.7027 - penalty: 1e-06\n",
            "hidden layer sizes: [228, 86, 152, 254, 321], total units: 1041\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8499798774719238 - val_accuracy: 0.7032 - penalty: 1e-06\n",
            "hidden layer sizes: [188, 63, 122, 219, 279], total units: 871\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8499798774719238 - val_accuracy: 0.7032 - penalty: 1e-06\n",
            "hidden layer sizes: [188, 63, 122, 219, 279], total units: 871\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8499798774719238 - val_accuracy: 0.7032 - penalty: 1e-06\n",
            "hidden layer sizes: [225, 83, 146, 262, 334], total units: 1050\n",
            "Before pruning:\n",
            "loss: 0.8216924071311951 - accuracy: 0.71072 - val_loss: 0.8132625818252563 - val_accuracy: 0.7194 - penalty: 1e-06\n",
            "hidden layer sizes: [225, 83, 146, 262, 334], total units: 1050\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8130559921264648 - val_accuracy: 0.7192 - penalty: 1e-06\n",
            "hidden layer sizes: [184, 51, 101, 222, 299], total units: 857\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8130559921264648 - val_accuracy: 0.7192 - penalty: 1e-06\n",
            "hidden layer sizes: [184, 51, 101, 222, 299], total units: 857\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8130559325218201 - val_accuracy: 0.7192 - penalty: 1e-06\n",
            "hidden layer sizes: [220, 71, 121, 266, 358], total units: 1036\n",
            "Before pruning:\n",
            "loss: 0.7910312414169312 - accuracy: 0.71876 - val_loss: 0.8092338442802429 - val_accuracy: 0.7172 - penalty: 1e-06\n",
            "hidden layer sizes: [220, 71, 121, 266, 358], total units: 1036\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8090081214904785 - val_accuracy: 0.7178 - penalty: 1e-06\n",
            "hidden layer sizes: [176, 56, 93, 234, 338], total units: 897\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8090081214904785 - val_accuracy: 0.7178 - penalty: 1e-06\n",
            "hidden layer sizes: [176, 56, 93, 234, 338], total units: 897\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8090081214904785 - val_accuracy: 0.7178 - penalty: 1e-06\n",
            "hidden layer sizes: [211, 76, 113, 280, 405], total units: 1085\n",
            "Before pruning:\n",
            "loss: 0.7626461982727051 - accuracy: 0.73006 - val_loss: 0.7829939723014832 - val_accuracy: 0.73 - penalty: 1e-06\n",
            "hidden layer sizes: [211, 76, 113, 280, 405], total units: 1085\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7829059362411499 - val_accuracy: 0.73 - penalty: 1e-06\n",
            "hidden layer sizes: [171, 59, 91, 236, 338], total units: 895\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7829059362411499 - val_accuracy: 0.73 - penalty: 1e-06\n",
            "hidden layer sizes: [171, 59, 91, 236, 338], total units: 895\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7829058766365051 - val_accuracy: 0.73 - penalty: 1e-06\n",
            "hidden layer sizes: [205, 79, 111, 283, 405], total units: 1083\n",
            "Before pruning:\n",
            "loss: 0.747941255569458 - accuracy: 0.73512 - val_loss: 0.788496732711792 - val_accuracy: 0.7303 - penalty: 1e-06\n",
            "hidden layer sizes: [205, 79, 111, 283, 405], total units: 1083\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.788341224193573 - val_accuracy: 0.7305 - penalty: 1e-06\n",
            "hidden layer sizes: [167, 55, 86, 234, 337], total units: 879\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.788341224193573 - val_accuracy: 0.7305 - penalty: 1e-06\n",
            "hidden layer sizes: [167, 55, 86, 234, 337], total units: 879\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7883412837982178 - val_accuracy: 0.7305 - penalty: 1e-06\n",
            "hidden layer sizes: [200, 75, 106, 280, 404], total units: 1065\n",
            "Before pruning:\n",
            "loss: 0.7217869758605957 - accuracy: 0.7463 - val_loss: 0.7700600624084473 - val_accuracy: 0.7306 - penalty: 1e-06\n",
            "hidden layer sizes: [200, 75, 106, 280, 404], total units: 1065\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7700117826461792 - val_accuracy: 0.7305 - penalty: 1e-06\n",
            "hidden layer sizes: [159, 47, 84, 236, 366], total units: 892\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7700117826461792 - val_accuracy: 0.7305 - penalty: 1e-06\n",
            "hidden layer sizes: [159, 47, 84, 236, 366], total units: 892\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.770011842250824 - val_accuracy: 0.7305 - penalty: 1e-06\n",
            "hidden layer sizes: [190, 67, 104, 283, 439], total units: 1083\n",
            "Before pruning:\n",
            "loss: 0.7126347422599792 - accuracy: 0.74762 - val_loss: 0.7778818607330322 - val_accuracy: 0.7315 - penalty: 1e-06\n",
            "hidden layer sizes: [190, 67, 104, 283, 439], total units: 1083\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7775612473487854 - val_accuracy: 0.7315 - penalty: 1e-06\n",
            "hidden layer sizes: [156, 49, 85, 239, 374], total units: 903\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7775612473487854 - val_accuracy: 0.7315 - penalty: 1e-06\n",
            "hidden layer sizes: [156, 49, 85, 239, 374], total units: 903\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7775613069534302 - val_accuracy: 0.7315 - penalty: 1e-06\n",
            "hidden layer sizes: [187, 69, 105, 286, 448], total units: 1095\n",
            "Before pruning:\n",
            "loss: 0.6926641464233398 - accuracy: 0.75674 - val_loss: 0.7840036153793335 - val_accuracy: 0.7295 - penalty: 1e-06\n",
            "hidden layer sizes: [187, 69, 105, 286, 448], total units: 1095\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7838205695152283 - val_accuracy: 0.7297 - penalty: 1e-06\n",
            "hidden layer sizes: [142, 44, 86, 242, 366], total units: 880\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7838205695152283 - val_accuracy: 0.7297 - penalty: 1e-06\n",
            "hidden layer sizes: [142, 44, 86, 242, 366], total units: 880\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7838205099105835 - val_accuracy: 0.7297 - penalty: 1e-06\n",
            "hidden layer sizes: [170, 64, 106, 290, 439], total units: 1069\n",
            "Before pruning:\n",
            "loss: 0.6821691393852234 - accuracy: 0.75832 - val_loss: 0.7603672742843628 - val_accuracy: 0.7394 - penalty: 1e-06\n",
            "hidden layer sizes: [170, 64, 106, 290, 439], total units: 1069\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7601619958877563 - val_accuracy: 0.7399 - penalty: 1e-06\n",
            "hidden layer sizes: [135, 46, 80, 242, 395], total units: 898\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7601619958877563 - val_accuracy: 0.7399 - penalty: 1e-06\n",
            "hidden layer sizes: [135, 46, 80, 242, 395], total units: 898\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7601619362831116 - val_accuracy: 0.7399 - penalty: 1e-06\n",
            "hidden layer sizes: [162, 66, 100, 290, 474], total units: 1092\n",
            "Before pruning:\n",
            "loss: 0.6606719493865967 - accuracy: 0.7673 - val_loss: 0.7607381343841553 - val_accuracy: 0.7379 - penalty: 1e-06\n",
            "hidden layer sizes: [162, 66, 100, 290, 474], total units: 1092\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7606223225593567 - val_accuracy: 0.7381 - penalty: 1e-06\n",
            "hidden layer sizes: [131, 45, 85, 241, 433], total units: 935\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7606223225593567 - val_accuracy: 0.7381 - penalty: 1e-06\n",
            "hidden layer sizes: [131, 45, 85, 241, 433], total units: 935\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7606223821640015 - val_accuracy: 0.7381 - penalty: 1e-06\n",
            "hidden layer sizes: [157, 65, 105, 289, 519], total units: 1135\n",
            "Before pruning:\n",
            "loss: 0.651715099811554 - accuracy: 0.76898 - val_loss: 0.7393239736557007 - val_accuracy: 0.7467 - penalty: 1e-06\n",
            "hidden layer sizes: [157, 65, 105, 289, 519], total units: 1135\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7391284108161926 - val_accuracy: 0.7462 - penalty: 1e-06\n",
            "hidden layer sizes: [130, 45, 88, 244, 434], total units: 941\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.38218,\n",
              "  0.47094,\n",
              "  0.52314,\n",
              "  0.56054,\n",
              "  0.591,\n",
              "  0.6224,\n",
              "  0.64552,\n",
              "  0.66534,\n",
              "  0.68246,\n",
              "  0.69776,\n",
              "  0.71072,\n",
              "  0.71876,\n",
              "  0.73006,\n",
              "  0.73512,\n",
              "  0.7463,\n",
              "  0.74762,\n",
              "  0.75674,\n",
              "  0.75832,\n",
              "  0.7673,\n",
              "  0.76898],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.9078271>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4895903>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3357962>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2331066>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1451589>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0575879>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9986784>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9431844>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8991598>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.84754854>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8216924>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.79103124>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7626462>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.74794126>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.721787>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.71263474>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.69266415>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.68216914>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.66067195>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6517151>],\n",
              " 'val_accuracy': [0.4891,\n",
              "  0.546,\n",
              "  0.5719,\n",
              "  0.6056,\n",
              "  0.6349,\n",
              "  0.6526,\n",
              "  0.6736,\n",
              "  0.6831,\n",
              "  0.6968,\n",
              "  0.7032,\n",
              "  0.7192,\n",
              "  0.7178,\n",
              "  0.73,\n",
              "  0.7305,\n",
              "  0.7305,\n",
              "  0.7315,\n",
              "  0.7297,\n",
              "  0.7399,\n",
              "  0.7381,\n",
              "  0.7462],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.4261628>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.262827>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.188406>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1074803>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0291587>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9812194>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9232416>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8949395>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8602458>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8499799>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.813056>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8090081>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.78290594>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7883412>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7700118>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.77756125>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.78382057>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.760162>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7606223>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7391284>]}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tBv3VFqCRVs",
        "outputId": "46674f2e-2f54-4201-c93c-ad179a9efd8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential([\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None, fixed_size=True),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.840655565261841 - val_accuracy: 0.1002 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.84065580368042 - val_accuracy: 0.1002 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.9883681535720825 - accuracy: 0.36158 - val_loss: 1.4862158298492432 - val_accuracy: 0.476 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4863176345825195 - val_accuracy: 0.4759 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4863176345825195 - val_accuracy: 0.4759 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4863176345825195 - val_accuracy: 0.4759 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.526109218597412 - accuracy: 0.4584 - val_loss: 1.3053607940673828 - val_accuracy: 0.5293 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.3052390813827515 - val_accuracy: 0.53 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.3052390813827515 - val_accuracy: 0.53 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.305239200592041 - val_accuracy: 0.53 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.341887354850769 - accuracy: 0.52154 - val_loss: 1.2112756967544556 - val_accuracy: 0.5627 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.2109817266464233 - val_accuracy: 0.5624 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2109817266464233 - val_accuracy: 0.5624 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2109817266464233 - val_accuracy: 0.5624 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.2322930097579956 - accuracy: 0.55994 - val_loss: 1.1409339904785156 - val_accuracy: 0.5877 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1409472227096558 - val_accuracy: 0.5877 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1409472227096558 - val_accuracy: 0.5877 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1409472227096558 - val_accuracy: 0.5877 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.1574097871780396 - accuracy: 0.58706 - val_loss: 1.0995608568191528 - val_accuracy: 0.6056 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0991530418395996 - val_accuracy: 0.6058 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 191, 192, 256], total units: 1023\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0991530418395996 - val_accuracy: 0.6058 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 191, 192, 256], total units: 1023\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0991530418395996 - val_accuracy: 0.6058 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 229, 230, 307], total units: 1226\n",
            "Before pruning:\n",
            "loss: 1.081053614616394 - accuracy: 0.61628 - val_loss: 1.0199790000915527 - val_accuracy: 0.6364 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 229, 230, 307], total units: 1226\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.019527792930603 - val_accuracy: 0.6365 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 169, 172, 192, 256], total units: 981\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.019527792930603 - val_accuracy: 0.6365 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 169, 172, 192, 256], total units: 981\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.019527554512024 - val_accuracy: 0.6365 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 202, 206, 230, 307], total units: 1175\n",
            "Before pruning:\n",
            "loss: 0.9990887641906738 - accuracy: 0.64598 - val_loss: 0.9820299744606018 - val_accuracy: 0.6491 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 202, 206, 230, 307], total units: 1175\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9819338917732239 - val_accuracy: 0.6489 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 137, 155, 191, 256], total units: 931\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9819338917732239 - val_accuracy: 0.6489 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 137, 155, 191, 256], total units: 931\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9819337725639343 - val_accuracy: 0.6489 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 164, 186, 229, 307], total units: 1116\n",
            "Before pruning:\n",
            "loss: 0.9280332922935486 - accuracy: 0.67044 - val_loss: 0.914259672164917 - val_accuracy: 0.6777 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 164, 186, 229, 307], total units: 1116\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9142920970916748 - val_accuracy: 0.6773 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 112, 140, 190, 256], total units: 890\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9142920970916748 - val_accuracy: 0.6773 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 112, 140, 190, 256], total units: 890\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9142920970916748 - val_accuracy: 0.6773 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 134, 168, 228, 307], total units: 1067\n",
            "Before pruning:\n",
            "loss: 0.8665342926979065 - accuracy: 0.69346 - val_loss: 0.877951979637146 - val_accuracy: 0.6883 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 134, 168, 228, 307], total units: 1067\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8776419162750244 - val_accuracy: 0.6883 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 100, 127, 192, 256], total units: 867\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8776419162750244 - val_accuracy: 0.6883 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 100, 127, 192, 256], total units: 867\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8776419758796692 - val_accuracy: 0.6883 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 120, 152, 230, 307], total units: 1039\n",
            "Before pruning:\n",
            "loss: 0.812792956829071 - accuracy: 0.7153 - val_loss: 0.8443649411201477 - val_accuracy: 0.7006 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 120, 152, 230, 307], total units: 1039\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8443865180015564 - val_accuracy: 0.7008 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 90, 119, 191, 260], total units: 852\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8443865180015564 - val_accuracy: 0.7008 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 90, 119, 191, 260], total units: 852\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8443865180015564 - val_accuracy: 0.7008 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 110, 142, 229, 312], total units: 1023\n",
            "Before pruning:\n",
            "loss: 0.7686486840248108 - accuracy: 0.72814 - val_loss: 0.824310839176178 - val_accuracy: 0.711 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 110, 142, 229, 312], total units: 1023\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8240812420845032 - val_accuracy: 0.7112 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 78, 109, 190, 266], total units: 835\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8240812420845032 - val_accuracy: 0.7112 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 78, 109, 190, 266], total units: 835\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8240812420845032 - val_accuracy: 0.7112 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 98, 130, 228, 319], total units: 1005\n",
            "Before pruning:\n",
            "loss: 0.7316874861717224 - accuracy: 0.7413 - val_loss: 0.8030737638473511 - val_accuracy: 0.718 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 98, 130, 228, 319], total units: 1005\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8030152916908264 - val_accuracy: 0.718 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 75, 103, 191, 261], total units: 822\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8030152916908264 - val_accuracy: 0.718 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 75, 103, 191, 261], total units: 822\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8030153512954712 - val_accuracy: 0.718 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 95, 123, 229, 313], total units: 990\n",
            "Before pruning:\n",
            "loss: 0.7004841566085815 - accuracy: 0.75176 - val_loss: 0.7907684445381165 - val_accuracy: 0.7236 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 95, 123, 229, 313], total units: 990\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7906835675239563 - val_accuracy: 0.7235 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 68, 96, 192, 262], total units: 810\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7906835675239563 - val_accuracy: 0.7235 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 68, 96, 192, 262], total units: 810\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7906835675239563 - val_accuracy: 0.7235 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 88, 116, 230, 314], total units: 978\n",
            "Before pruning:\n",
            "loss: 0.6733863949775696 - accuracy: 0.76094 - val_loss: 0.7818681597709656 - val_accuracy: 0.7237 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 88, 116, 230, 314], total units: 978\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7817997336387634 - val_accuracy: 0.7236 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 61, 90, 191, 266], total units: 800\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7817997336387634 - val_accuracy: 0.7236 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 61, 90, 191, 266], total units: 800\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7817997336387634 - val_accuracy: 0.7236 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 81, 110, 229, 319], total units: 969\n",
            "Before pruning:\n",
            "loss: 0.6478533744812012 - accuracy: 0.77142 - val_loss: 0.7860833406448364 - val_accuracy: 0.7273 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 81, 110, 229, 319], total units: 969\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.786094069480896 - val_accuracy: 0.7273 - penalty: 1e-06\n",
            "hidden layer sizes: [190, 61, 86, 193, 271], total units: 801\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.786094069480896 - val_accuracy: 0.7273 - penalty: 1e-06\n",
            "hidden layer sizes: [190, 61, 86, 193, 271], total units: 801\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7860941290855408 - val_accuracy: 0.7273 - penalty: 1e-06\n",
            "hidden layer sizes: [228, 81, 106, 231, 325], total units: 971\n",
            "Before pruning:\n",
            "loss: 0.6264689564704895 - accuracy: 0.77972 - val_loss: 0.7853912115097046 - val_accuracy: 0.7256 - penalty: 1e-06\n",
            "hidden layer sizes: [228, 81, 106, 231, 325], total units: 971\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7853613495826721 - val_accuracy: 0.7256 - penalty: 1e-06\n",
            "hidden layer sizes: [190, 62, 82, 191, 268], total units: 793\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7853613495826721 - val_accuracy: 0.7256 - penalty: 1e-06\n",
            "hidden layer sizes: [190, 62, 82, 191, 268], total units: 793\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7853613495826721 - val_accuracy: 0.7256 - penalty: 1e-06\n",
            "hidden layer sizes: [228, 82, 102, 229, 321], total units: 962\n",
            "Before pruning:\n",
            "loss: 0.6101464629173279 - accuracy: 0.78484 - val_loss: 0.780669629573822 - val_accuracy: 0.7258 - penalty: 1e-06\n",
            "hidden layer sizes: [228, 82, 102, 229, 321], total units: 962\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7803981304168701 - val_accuracy: 0.7259 - penalty: 1e-06\n",
            "hidden layer sizes: [188, 56, 81, 191, 268], total units: 784\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7803981304168701 - val_accuracy: 0.7259 - penalty: 1e-06\n",
            "hidden layer sizes: [188, 56, 81, 191, 268], total units: 784\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7803981304168701 - val_accuracy: 0.7259 - penalty: 1e-06\n",
            "hidden layer sizes: [225, 76, 101, 229, 321], total units: 952\n",
            "Before pruning:\n",
            "loss: 0.5904771685600281 - accuracy: 0.79202 - val_loss: 0.7718416452407837 - val_accuracy: 0.7303 - penalty: 1e-06\n",
            "hidden layer sizes: [225, 76, 101, 229, 321], total units: 952\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7717891931533813 - val_accuracy: 0.7302 - penalty: 1e-06\n",
            "hidden layer sizes: [182, 56, 79, 197, 280], total units: 794\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7717891931533813 - val_accuracy: 0.7302 - penalty: 1e-06\n",
            "hidden layer sizes: [182, 56, 79, 197, 280], total units: 794\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7717891335487366 - val_accuracy: 0.7302 - penalty: 1e-06\n",
            "hidden layer sizes: [218, 76, 99, 236, 336], total units: 965\n",
            "Before pruning:\n",
            "loss: 0.5727397799491882 - accuracy: 0.79806 - val_loss: 0.7796993255615234 - val_accuracy: 0.7292 - penalty: 1e-06\n",
            "hidden layer sizes: [218, 76, 99, 236, 336], total units: 965\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7791340947151184 - val_accuracy: 0.7287 - penalty: 1e-06\n",
            "hidden layer sizes: [177, 54, 73, 196, 274], total units: 774\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7791340947151184 - val_accuracy: 0.7287 - penalty: 1e-06\n",
            "hidden layer sizes: [177, 54, 73, 196, 274], total units: 774\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7791340947151184 - val_accuracy: 0.7287 - penalty: 1e-06\n",
            "hidden layer sizes: [212, 74, 93, 235, 328], total units: 942\n",
            "Before pruning:\n",
            "loss: 0.5618031024932861 - accuracy: 0.80034 - val_loss: 0.7752525210380554 - val_accuracy: 0.7357 - penalty: 1e-06\n",
            "hidden layer sizes: [212, 74, 93, 235, 328], total units: 942\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7751069068908691 - val_accuracy: 0.7361 - penalty: 1e-06\n",
            "hidden layer sizes: [174, 54, 71, 200, 279], total units: 778\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.36158,\n",
              "  0.4584,\n",
              "  0.52154,\n",
              "  0.55994,\n",
              "  0.58706,\n",
              "  0.61628,\n",
              "  0.64598,\n",
              "  0.67044,\n",
              "  0.69346,\n",
              "  0.7153,\n",
              "  0.72814,\n",
              "  0.7413,\n",
              "  0.75176,\n",
              "  0.76094,\n",
              "  0.77142,\n",
              "  0.77972,\n",
              "  0.78484,\n",
              "  0.79202,\n",
              "  0.79806,\n",
              "  0.80034],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.9883682>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.5261092>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3418874>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.232293>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1574098>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0810536>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.99908876>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9280333>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8665343>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.81279296>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7686487>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7316875>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.70048416>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6733864>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6478534>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.62646896>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.61014646>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.59047717>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5727398>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5618031>],\n",
              " 'val_accuracy': [0.4759,\n",
              "  0.53,\n",
              "  0.5624,\n",
              "  0.5877,\n",
              "  0.6058,\n",
              "  0.6365,\n",
              "  0.6489,\n",
              "  0.6773,\n",
              "  0.6883,\n",
              "  0.7008,\n",
              "  0.7112,\n",
              "  0.718,\n",
              "  0.7235,\n",
              "  0.7236,\n",
              "  0.7273,\n",
              "  0.7256,\n",
              "  0.7259,\n",
              "  0.7302,\n",
              "  0.7287,\n",
              "  0.7361],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.4863176>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3052391>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2109817>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1409472>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.099153>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0195278>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9819339>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9142921>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8776419>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8443865>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.82408124>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8030153>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.79068357>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.78179973>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.78609407>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.78536135>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.78039813>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7717892>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7791341>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7751069>]}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdlIlwQIFPaL",
        "outputId": "e07c8bfd-f6f1-471f-a7af-06d568e77ad4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7751069068908691 - val_accuracy: 0.7361 - penalty: 1e-06\n",
            "hidden layer sizes: [174, 54, 71, 200, 279], total units: 778\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7751069664955139 - val_accuracy: 0.7361 - penalty: 1e-06\n",
            "hidden layer sizes: [208, 74, 91, 240, 334], total units: 947\n",
            "Before pruning:\n",
            "loss: 0.5426346063613892 - accuracy: 0.80752 - val_loss: 0.7737799882888794 - val_accuracy: 0.7273 - penalty: 1e-06\n",
            "hidden layer sizes: [208, 74, 91, 240, 334], total units: 947\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7737587690353394 - val_accuracy: 0.7271 - penalty: 1e-06\n",
            "hidden layer sizes: [168, 52, 68, 196, 273], total units: 757\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7737587690353394 - val_accuracy: 0.7271 - penalty: 1e-06\n",
            "hidden layer sizes: [168, 52, 68, 196, 273], total units: 757\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7737588286399841 - val_accuracy: 0.7271 - penalty: 1e-06\n",
            "hidden layer sizes: [201, 72, 88, 235, 327], total units: 923\n",
            "Before pruning:\n",
            "loss: 0.5328280329704285 - accuracy: 0.80988 - val_loss: 0.7777541279792786 - val_accuracy: 0.734 - penalty: 1e-06\n",
            "hidden layer sizes: [201, 72, 88, 235, 327], total units: 923\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.777652382850647 - val_accuracy: 0.7343 - penalty: 1e-06\n",
            "hidden layer sizes: [164, 53, 68, 205, 301], total units: 791\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.777652382850647 - val_accuracy: 0.7343 - penalty: 1e-06\n",
            "hidden layer sizes: [164, 53, 68, 205, 301], total units: 791\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7776523232460022 - val_accuracy: 0.7343 - penalty: 1e-06\n",
            "hidden layer sizes: [196, 73, 88, 246, 361], total units: 964\n",
            "Before pruning:\n",
            "loss: 0.5252960920333862 - accuracy: 0.81346 - val_loss: 0.7779180407524109 - val_accuracy: 0.7349 - penalty: 1e-06\n",
            "hidden layer sizes: [196, 73, 88, 246, 361], total units: 964\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7780272364616394 - val_accuracy: 0.7349 - penalty: 1e-06\n",
            "hidden layer sizes: [163, 52, 67, 200, 288], total units: 770\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7780272364616394 - val_accuracy: 0.7349 - penalty: 1e-06\n",
            "hidden layer sizes: [163, 52, 67, 200, 288], total units: 770\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7780271768569946 - val_accuracy: 0.7349 - penalty: 1e-06\n",
            "hidden layer sizes: [195, 72, 87, 240, 345], total units: 939\n",
            "Before pruning:\n",
            "loss: 0.5142058730125427 - accuracy: 0.8191 - val_loss: 0.7818767428398132 - val_accuracy: 0.7315 - penalty: 1e-06\n",
            "hidden layer sizes: [195, 72, 87, 240, 345], total units: 939\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7818840146064758 - val_accuracy: 0.7315 - penalty: 1e-06\n",
            "hidden layer sizes: [161, 52, 65, 208, 301], total units: 787\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7818840146064758 - val_accuracy: 0.7315 - penalty: 1e-06\n",
            "hidden layer sizes: [161, 52, 65, 208, 301], total units: 787\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7818840742111206 - val_accuracy: 0.7315 - penalty: 1e-06\n",
            "hidden layer sizes: [193, 72, 85, 249, 361], total units: 960\n",
            "Before pruning:\n",
            "loss: 0.503919243812561 - accuracy: 0.82134 - val_loss: 0.7824618816375732 - val_accuracy: 0.7312 - penalty: 1e-06\n",
            "hidden layer sizes: [193, 72, 85, 249, 361], total units: 960\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7824063301086426 - val_accuracy: 0.7312 - penalty: 1e-06\n",
            "hidden layer sizes: [157, 51, 65, 212, 308], total units: 793\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7824063301086426 - val_accuracy: 0.7312 - penalty: 1e-06\n",
            "hidden layer sizes: [157, 51, 65, 212, 308], total units: 793\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7824063301086426 - val_accuracy: 0.7312 - penalty: 1e-06\n",
            "hidden layer sizes: [188, 71, 85, 254, 369], total units: 967\n",
            "Before pruning:\n",
            "loss: 0.4920761287212372 - accuracy: 0.8247 - val_loss: 0.7799797058105469 - val_accuracy: 0.7349 - penalty: 1e-06\n",
            "hidden layer sizes: [188, 71, 85, 254, 369], total units: 967\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7798812985420227 - val_accuracy: 0.7347 - penalty: 1e-06\n",
            "hidden layer sizes: [150, 51, 62, 212, 284], total units: 759\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7798812985420227 - val_accuracy: 0.7347 - penalty: 1e-06\n",
            "hidden layer sizes: [150, 51, 62, 212, 284], total units: 759\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7798811793327332 - val_accuracy: 0.7347 - penalty: 1e-06\n",
            "hidden layer sizes: [180, 71, 82, 254, 340], total units: 927\n",
            "Before pruning:\n",
            "loss: 0.48363596200942993 - accuracy: 0.82708 - val_loss: 0.7864531874656677 - val_accuracy: 0.7367 - penalty: 1e-06\n",
            "hidden layer sizes: [180, 71, 82, 254, 340], total units: 927\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7863690853118896 - val_accuracy: 0.7368 - penalty: 1e-06\n",
            "hidden layer sizes: [150, 52, 62, 212, 292], total units: 768\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7863690853118896 - val_accuracy: 0.7368 - penalty: 1e-06\n",
            "hidden layer sizes: [150, 52, 62, 212, 292], total units: 768\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7863691449165344 - val_accuracy: 0.7368 - penalty: 1e-06\n",
            "hidden layer sizes: [180, 72, 82, 254, 350], total units: 938\n",
            "Before pruning:\n",
            "loss: 0.47302472591400146 - accuracy: 0.83188 - val_loss: 0.7918798923492432 - val_accuracy: 0.7347 - penalty: 1e-06\n",
            "hidden layer sizes: [180, 72, 82, 254, 350], total units: 938\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7916135787963867 - val_accuracy: 0.7354 - penalty: 1e-06\n",
            "hidden layer sizes: [144, 54, 62, 205, 300], total units: 765\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7916135787963867 - val_accuracy: 0.7354 - penalty: 1e-06\n",
            "hidden layer sizes: [144, 54, 62, 205, 300], total units: 765\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7916135787963867 - val_accuracy: 0.7354 - penalty: 1e-06\n",
            "hidden layer sizes: [172, 74, 82, 246, 360], total units: 934\n",
            "Before pruning:\n",
            "loss: 0.4719679653644562 - accuracy: 0.83242 - val_loss: 0.7959504127502441 - val_accuracy: 0.735 - penalty: 1e-06\n",
            "hidden layer sizes: [172, 74, 82, 246, 360], total units: 934\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.795958936214447 - val_accuracy: 0.7346 - penalty: 1e-06\n",
            "hidden layer sizes: [140, 51, 61, 210, 310], total units: 772\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.795958936214447 - val_accuracy: 0.7346 - penalty: 1e-06\n",
            "hidden layer sizes: [140, 51, 61, 210, 310], total units: 772\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7959590554237366 - val_accuracy: 0.7346 - penalty: 1e-06\n",
            "hidden layer sizes: [168, 71, 81, 252, 372], total units: 944\n",
            "Before pruning:\n",
            "loss: 0.4619728922843933 - accuracy: 0.83558 - val_loss: 0.7854200601577759 - val_accuracy: 0.7372 - penalty: 1e-06\n",
            "hidden layer sizes: [168, 71, 81, 252, 372], total units: 944\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7852558493614197 - val_accuracy: 0.737 - penalty: 1e-06\n",
            "hidden layer sizes: [137, 53, 61, 216, 279], total units: 746\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7852558493614197 - val_accuracy: 0.737 - penalty: 1e-06\n",
            "hidden layer sizes: [137, 53, 61, 216, 279], total units: 746\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7852558493614197 - val_accuracy: 0.737 - penalty: 1e-06\n",
            "hidden layer sizes: [164, 73, 81, 259, 334], total units: 911\n",
            "Before pruning:\n",
            "loss: 0.45086032152175903 - accuracy: 0.83914 - val_loss: 0.7889162302017212 - val_accuracy: 0.7364 - penalty: 1e-06\n",
            "hidden layer sizes: [164, 73, 81, 259, 334], total units: 911\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7889137864112854 - val_accuracy: 0.7367 - penalty: 1e-06\n",
            "hidden layer sizes: [131, 50, 57, 208, 281], total units: 727\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7889137864112854 - val_accuracy: 0.7367 - penalty: 1e-06\n",
            "hidden layer sizes: [131, 50, 57, 208, 281], total units: 727\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7889138460159302 - val_accuracy: 0.7367 - penalty: 1e-06\n",
            "hidden layer sizes: [157, 70, 77, 249, 337], total units: 890\n",
            "Before pruning:\n",
            "loss: 0.4474680721759796 - accuracy: 0.84106 - val_loss: 0.789192795753479 - val_accuracy: 0.7345 - penalty: 1e-06\n",
            "hidden layer sizes: [157, 70, 77, 249, 337], total units: 890\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7891157269477844 - val_accuracy: 0.7344 - penalty: 1e-06\n",
            "hidden layer sizes: [128, 57, 57, 215, 310], total units: 767\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7891157269477844 - val_accuracy: 0.7344 - penalty: 1e-06\n",
            "hidden layer sizes: [128, 57, 57, 215, 310], total units: 767\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7891157865524292 - val_accuracy: 0.7344 - penalty: 1e-06\n",
            "hidden layer sizes: [153, 77, 77, 258, 372], total units: 937\n",
            "Before pruning:\n",
            "loss: 0.44540679454803467 - accuracy: 0.84198 - val_loss: 0.7925061583518982 - val_accuracy: 0.7376 - penalty: 1e-06\n",
            "hidden layer sizes: [153, 77, 77, 258, 372], total units: 937\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7924822568893433 - val_accuracy: 0.7377 - penalty: 1e-06\n",
            "hidden layer sizes: [125, 50, 61, 216, 331], total units: 783\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7924822568893433 - val_accuracy: 0.7377 - penalty: 1e-06\n",
            "hidden layer sizes: [125, 50, 61, 216, 331], total units: 783\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.792482316493988 - val_accuracy: 0.7377 - penalty: 1e-06\n",
            "hidden layer sizes: [150, 70, 81, 259, 397], total units: 957\n",
            "Before pruning:\n",
            "loss: 0.43666866421699524 - accuracy: 0.84404 - val_loss: 0.8057506084442139 - val_accuracy: 0.7326 - penalty: 1e-06\n",
            "hidden layer sizes: [150, 70, 81, 259, 397], total units: 957\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8053776621818542 - val_accuracy: 0.7328 - penalty: 1e-06\n",
            "hidden layer sizes: [124, 52, 58, 213, 330], total units: 777\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8053776621818542 - val_accuracy: 0.7328 - penalty: 1e-06\n",
            "hidden layer sizes: [124, 52, 58, 213, 330], total units: 777\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8053776621818542 - val_accuracy: 0.7328 - penalty: 1e-06\n",
            "hidden layer sizes: [148, 72, 78, 255, 396], total units: 949\n",
            "Before pruning:\n",
            "loss: 0.4306914508342743 - accuracy: 0.84692 - val_loss: 0.789804220199585 - val_accuracy: 0.7399 - penalty: 1e-06\n",
            "hidden layer sizes: [148, 72, 78, 255, 396], total units: 949\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7897264957427979 - val_accuracy: 0.7397 - penalty: 1e-06\n",
            "hidden layer sizes: [116, 54, 57, 210, 286], total units: 723\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7897264957427979 - val_accuracy: 0.7397 - penalty: 1e-06\n",
            "hidden layer sizes: [116, 54, 57, 210, 286], total units: 723\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7897264361381531 - val_accuracy: 0.7397 - penalty: 1e-06\n",
            "hidden layer sizes: [139, 74, 77, 252, 343], total units: 885\n",
            "Before pruning:\n",
            "loss: 0.4283207356929779 - accuracy: 0.84924 - val_loss: 0.805580198764801 - val_accuracy: 0.7356 - penalty: 1e-06\n",
            "hidden layer sizes: [139, 74, 77, 252, 343], total units: 885\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.805504560470581 - val_accuracy: 0.7356 - penalty: 1e-06\n",
            "hidden layer sizes: [116, 51, 59, 221, 316], total units: 763\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.805504560470581 - val_accuracy: 0.7356 - penalty: 1e-06\n",
            "hidden layer sizes: [116, 51, 59, 221, 316], total units: 763\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.805504560470581 - val_accuracy: 0.7356 - penalty: 1e-06\n",
            "hidden layer sizes: [139, 71, 79, 265, 379], total units: 933\n",
            "Before pruning:\n",
            "loss: 0.42126989364624023 - accuracy: 0.84984 - val_loss: 0.8015350699424744 - val_accuracy: 0.738 - penalty: 1e-06\n",
            "hidden layer sizes: [139, 71, 79, 265, 379], total units: 933\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8013960719108582 - val_accuracy: 0.7377 - penalty: 1e-06\n",
            "hidden layer sizes: [113, 52, 54, 220, 330], total units: 769\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8013960719108582 - val_accuracy: 0.7377 - penalty: 1e-06\n",
            "hidden layer sizes: [113, 52, 54, 220, 330], total units: 769\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8013960719108582 - val_accuracy: 0.7377 - penalty: 1e-06\n",
            "hidden layer sizes: [135, 72, 74, 264, 396], total units: 941\n",
            "Before pruning:\n",
            "loss: 0.41100624203681946 - accuracy: 0.85484 - val_loss: 0.800648033618927 - val_accuracy: 0.7427 - penalty: 1e-06\n",
            "hidden layer sizes: [135, 72, 74, 264, 396], total units: 941\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8006948828697205 - val_accuracy: 0.7424 - penalty: 1e-06\n",
            "hidden layer sizes: [110, 49, 52, 208, 317], total units: 736\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8006948828697205 - val_accuracy: 0.7424 - penalty: 1e-06\n",
            "hidden layer sizes: [110, 49, 52, 208, 317], total units: 736\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8006948232650757 - val_accuracy: 0.7424 - penalty: 1e-06\n",
            "hidden layer sizes: [132, 69, 72, 249, 380], total units: 902\n",
            "Before pruning:\n",
            "loss: 0.40971723198890686 - accuracy: 0.8535 - val_loss: 0.7981252074241638 - val_accuracy: 0.7404 - penalty: 1e-06\n",
            "hidden layer sizes: [132, 69, 72, 249, 380], total units: 902\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7980993390083313 - val_accuracy: 0.7402 - penalty: 1e-06\n",
            "hidden layer sizes: [110, 49, 52, 220, 344], total units: 775\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7980993390083313 - val_accuracy: 0.7402 - penalty: 1e-06\n",
            "hidden layer sizes: [110, 49, 52, 220, 344], total units: 775\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7980993390083313 - val_accuracy: 0.7402 - penalty: 1e-06\n",
            "hidden layer sizes: [132, 69, 72, 264, 412], total units: 949\n",
            "Before pruning:\n",
            "loss: 0.40532195568084717 - accuracy: 0.8566 - val_loss: 0.8091340661048889 - val_accuracy: 0.7397 - penalty: 1e-06\n",
            "hidden layer sizes: [132, 69, 72, 264, 412], total units: 949\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8090648651123047 - val_accuracy: 0.7397 - penalty: 1e-06\n",
            "hidden layer sizes: [107, 51, 58, 212, 310], total units: 738\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.80752,\n",
              "  0.80988,\n",
              "  0.81346,\n",
              "  0.8191,\n",
              "  0.82134,\n",
              "  0.8247,\n",
              "  0.82708,\n",
              "  0.83188,\n",
              "  0.83242,\n",
              "  0.83558,\n",
              "  0.83914,\n",
              "  0.84106,\n",
              "  0.84198,\n",
              "  0.84404,\n",
              "  0.84692,\n",
              "  0.84924,\n",
              "  0.84984,\n",
              "  0.85484,\n",
              "  0.8535,\n",
              "  0.8566],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=0.5426346>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.53282803>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5252961>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5142059>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.50391924>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.49207613>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.48363596>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.47302473>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.47196797>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.4619729>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.45086032>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.44746807>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.4454068>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.43666866>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.43069145>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.42832074>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.4212699>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.41100624>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.40971723>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.40532196>],\n",
              " 'val_accuracy': [0.7271,\n",
              "  0.7343,\n",
              "  0.7349,\n",
              "  0.7315,\n",
              "  0.7312,\n",
              "  0.7347,\n",
              "  0.7368,\n",
              "  0.7354,\n",
              "  0.7346,\n",
              "  0.737,\n",
              "  0.7367,\n",
              "  0.7344,\n",
              "  0.7377,\n",
              "  0.7328,\n",
              "  0.7397,\n",
              "  0.7356,\n",
              "  0.7377,\n",
              "  0.7424,\n",
              "  0.7402,\n",
              "  0.7397],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=0.77375877>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7776524>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.77802724>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.781884>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.78240633>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7798813>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7863691>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7916136>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.79595894>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.78525585>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7889138>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7891157>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.79248226>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.80537766>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7897265>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.80550456>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8013961>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8006949>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.79809934>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.80906487>]}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bdv3hFwfOmBM"
      },
      "source": [
        "epochs = 30\n",
        "self_scaling_epochs = 20\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPU9oQTSO02S",
        "outputId": "fcda428e-adbd-4c8d-e8c3-8a36ff80afee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential([\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None, fixed_size=True),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.9966039657592773 - val_accuracy: 0.095 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.9966037273406982 - val_accuracy: 0.095 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.9035162925720215 - accuracy: 0.38132 - val_loss: 1.4311473369598389 - val_accuracy: 0.4863 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4304295778274536 - val_accuracy: 0.488 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "##########################################################\n",
            "Epoch 2/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4304295778274536 - val_accuracy: 0.488 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4304296970367432 - val_accuracy: 0.488 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.4815970659255981 - accuracy: 0.47052 - val_loss: 1.2382206916809082 - val_accuracy: 0.5544 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.2381744384765625 - val_accuracy: 0.5544 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "##########################################################\n",
            "Epoch 3/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2381744384765625 - val_accuracy: 0.5544 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2381744384765625 - val_accuracy: 0.5544 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.2890013456344604 - accuracy: 0.53864 - val_loss: 1.1519461870193481 - val_accuracy: 0.5823 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1516029834747314 - val_accuracy: 0.5818 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 193, 256], total units: 1025\n",
            "##########################################################\n",
            "Epoch 4/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1516029834747314 - val_accuracy: 0.5818 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 193, 256], total units: 1025\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1516029834747314 - val_accuracy: 0.5818 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 231, 307], total units: 1228\n",
            "Before pruning:\n",
            "loss: 1.184485912322998 - accuracy: 0.57584 - val_loss: 1.0725525617599487 - val_accuracy: 0.6154 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 231, 307], total units: 1228\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0723928213119507 - val_accuracy: 0.6156 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 178, 189, 195, 258], total units: 1012\n",
            "##########################################################\n",
            "Epoch 5/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0723928213119507 - val_accuracy: 0.6156 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 178, 189, 195, 258], total units: 1012\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0723928213119507 - val_accuracy: 0.6156 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 213, 226, 234, 309], total units: 1212\n",
            "Before pruning:\n",
            "loss: 1.0812360048294067 - accuracy: 0.61424 - val_loss: 0.9862753748893738 - val_accuracy: 0.6524 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 213, 226, 234, 309], total units: 1212\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9857228398323059 - val_accuracy: 0.6527 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 124, 169, 202, 276], total units: 963\n",
            "##########################################################\n",
            "Epoch 6/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9857228398323059 - val_accuracy: 0.6527 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 124, 169, 202, 276], total units: 963\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9857228398323059 - val_accuracy: 0.6527 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 148, 202, 242, 331], total units: 1153\n",
            "Before pruning:\n",
            "loss: 0.9936506152153015 - accuracy: 0.64546 - val_loss: 0.9009475708007812 - val_accuracy: 0.6848 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 148, 202, 242, 331], total units: 1153\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9009442329406738 - val_accuracy: 0.6846 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 101, 153, 214, 297], total units: 957\n",
            "##########################################################\n",
            "Epoch 7/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9009442329406738 - val_accuracy: 0.6846 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 101, 153, 214, 297], total units: 957\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9009442329406738 - val_accuracy: 0.6846 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 121, 183, 256, 356], total units: 1146\n",
            "Before pruning:\n",
            "loss: 0.9322214126586914 - accuracy: 0.66984 - val_loss: 0.878605842590332 - val_accuracy: 0.6906 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 121, 183, 256, 356], total units: 1146\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8786243200302124 - val_accuracy: 0.6907 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 89, 138, 223, 270], total units: 912\n",
            "##########################################################\n",
            "Epoch 8/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8786243200302124 - val_accuracy: 0.6907 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 89, 138, 223, 270], total units: 912\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.878624439239502 - val_accuracy: 0.6907 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 109, 165, 267, 324], total units: 1095\n",
            "Before pruning:\n",
            "loss: 0.8767426013946533 - accuracy: 0.68944 - val_loss: 0.8341246843338013 - val_accuracy: 0.7084 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 109, 165, 267, 324], total units: 1095\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8341604471206665 - val_accuracy: 0.7083 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 75, 134, 227, 279], total units: 907\n",
            "##########################################################\n",
            "Epoch 9/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8341604471206665 - val_accuracy: 0.7083 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 75, 134, 227, 279], total units: 907\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8341604471206665 - val_accuracy: 0.7083 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 95, 160, 272, 334], total units: 1091\n",
            "Before pruning:\n",
            "loss: 0.8339406251907349 - accuracy: 0.70474 - val_loss: 0.8075234293937683 - val_accuracy: 0.7168 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 95, 160, 272, 334], total units: 1091\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8072875142097473 - val_accuracy: 0.7167 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 66, 122, 241, 282], total units: 902\n",
            "##########################################################\n",
            "Epoch 10/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8072875142097473 - val_accuracy: 0.7167 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 66, 122, 241, 282], total units: 902\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8072875142097473 - val_accuracy: 0.7167 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 86, 146, 289, 338], total units: 1088\n",
            "Before pruning:\n",
            "loss: 0.7909952402114868 - accuracy: 0.719 - val_loss: 0.8035134077072144 - val_accuracy: 0.7163 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 86, 146, 289, 338], total units: 1088\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8033929467201233 - val_accuracy: 0.7168 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 62, 109, 246, 316], total units: 924\n",
            "##########################################################\n",
            "Epoch 11/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8033929467201233 - val_accuracy: 0.7168 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 62, 109, 246, 316], total units: 924\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8033929467201233 - val_accuracy: 0.7168 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 82, 130, 295, 379], total units: 1115\n",
            "Before pruning:\n",
            "loss: 0.7663810849189758 - accuracy: 0.72956 - val_loss: 0.7877995371818542 - val_accuracy: 0.7237 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 82, 130, 295, 379], total units: 1115\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7873464822769165 - val_accuracy: 0.7235 - penalty: 1e-06\n",
            "hidden layer sizes: [188, 63, 109, 247, 311], total units: 918\n",
            "##########################################################\n",
            "Epoch 12/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7873464822769165 - val_accuracy: 0.7235 - penalty: 1e-06\n",
            "hidden layer sizes: [188, 63, 109, 247, 311], total units: 918\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7873464822769165 - val_accuracy: 0.7235 - penalty: 1e-06\n",
            "hidden layer sizes: [225, 83, 130, 296, 373], total units: 1107\n",
            "Before pruning:\n",
            "loss: 0.7398622632026672 - accuracy: 0.73654 - val_loss: 0.7899677157402039 - val_accuracy: 0.7259 - penalty: 1e-06\n",
            "hidden layer sizes: [225, 83, 130, 296, 373], total units: 1107\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7897037267684937 - val_accuracy: 0.7259 - penalty: 1e-06\n",
            "hidden layer sizes: [184, 58, 94, 254, 324], total units: 914\n",
            "##########################################################\n",
            "Epoch 13/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7897037267684937 - val_accuracy: 0.7259 - penalty: 1e-06\n",
            "hidden layer sizes: [184, 58, 94, 254, 324], total units: 914\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7897036075592041 - val_accuracy: 0.7259 - penalty: 1e-06\n",
            "hidden layer sizes: [220, 78, 114, 304, 388], total units: 1104\n",
            "Before pruning:\n",
            "loss: 0.7175453305244446 - accuracy: 0.74674 - val_loss: 0.7621151208877563 - val_accuracy: 0.7377 - penalty: 1e-06\n",
            "hidden layer sizes: [220, 78, 114, 304, 388], total units: 1104\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7620356678962708 - val_accuracy: 0.7373 - penalty: 1e-06\n",
            "hidden layer sizes: [180, 61, 91, 253, 348], total units: 933\n",
            "##########################################################\n",
            "Epoch 14/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7620356678962708 - val_accuracy: 0.7373 - penalty: 1e-06\n",
            "hidden layer sizes: [180, 61, 91, 253, 348], total units: 933\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7620358467102051 - val_accuracy: 0.7373 - penalty: 1e-06\n",
            "hidden layer sizes: [216, 81, 111, 303, 417], total units: 1128\n",
            "Before pruning:\n",
            "loss: 0.6981886625289917 - accuracy: 0.75508 - val_loss: 0.7666155099868774 - val_accuracy: 0.731 - penalty: 1e-06\n",
            "hidden layer sizes: [216, 81, 111, 303, 417], total units: 1128\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7664950489997864 - val_accuracy: 0.731 - penalty: 1e-06\n",
            "hidden layer sizes: [178, 62, 87, 264, 378], total units: 969\n",
            "##########################################################\n",
            "Epoch 15/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7664950489997864 - val_accuracy: 0.731 - penalty: 1e-06\n",
            "hidden layer sizes: [178, 62, 87, 264, 378], total units: 969\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7664950489997864 - val_accuracy: 0.731 - penalty: 1e-06\n",
            "hidden layer sizes: [213, 82, 107, 316, 453], total units: 1171\n",
            "Before pruning:\n",
            "loss: 0.6880046725273132 - accuracy: 0.75548 - val_loss: 0.7561757564544678 - val_accuracy: 0.7337 - penalty: 1e-06\n",
            "hidden layer sizes: [213, 82, 107, 316, 453], total units: 1171\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7562063932418823 - val_accuracy: 0.7336 - penalty: 1e-06\n",
            "hidden layer sizes: [171, 49, 82, 262, 364], total units: 928\n",
            "##########################################################\n",
            "Epoch 16/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7562063932418823 - val_accuracy: 0.7336 - penalty: 1e-06\n",
            "hidden layer sizes: [171, 49, 82, 262, 364], total units: 928\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7562063336372375 - val_accuracy: 0.7336 - penalty: 1e-06\n",
            "hidden layer sizes: [205, 69, 102, 314, 436], total units: 1126\n",
            "Before pruning:\n",
            "loss: 0.6694562435150146 - accuracy: 0.76352 - val_loss: 0.7817996144294739 - val_accuracy: 0.7274 - penalty: 1e-06\n",
            "hidden layer sizes: [205, 69, 102, 314, 436], total units: 1126\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7814444303512573 - val_accuracy: 0.7276 - penalty: 1e-06\n",
            "hidden layer sizes: [159, 50, 85, 258, 401], total units: 953\n",
            "##########################################################\n",
            "Epoch 17/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7814444303512573 - val_accuracy: 0.7276 - penalty: 1e-06\n",
            "hidden layer sizes: [159, 50, 85, 258, 401], total units: 953\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7814444303512573 - val_accuracy: 0.7276 - penalty: 1e-06\n",
            "hidden layer sizes: [190, 70, 105, 309, 481], total units: 1155\n",
            "Before pruning:\n",
            "loss: 0.6558962464332581 - accuracy: 0.76712 - val_loss: 0.7513936758041382 - val_accuracy: 0.7383 - penalty: 1e-06\n",
            "hidden layer sizes: [190, 70, 105, 309, 481], total units: 1155\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7513830065727234 - val_accuracy: 0.7383 - penalty: 1e-06\n",
            "hidden layer sizes: [153, 50, 74, 254, 397], total units: 928\n",
            "##########################################################\n",
            "Epoch 18/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7513830065727234 - val_accuracy: 0.7383 - penalty: 1e-06\n",
            "hidden layer sizes: [153, 50, 74, 254, 397], total units: 928\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7513830065727234 - val_accuracy: 0.7383 - penalty: 1e-06\n",
            "hidden layer sizes: [183, 70, 94, 304, 476], total units: 1127\n",
            "Before pruning:\n",
            "loss: 0.6457028388977051 - accuracy: 0.77214 - val_loss: 0.7543075680732727 - val_accuracy: 0.7383 - penalty: 1e-06\n",
            "hidden layer sizes: [183, 70, 94, 304, 476], total units: 1127\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7542768716812134 - val_accuracy: 0.7381 - penalty: 1e-06\n",
            "hidden layer sizes: [148, 44, 67, 253, 430], total units: 942\n",
            "##########################################################\n",
            "Epoch 19/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7542768716812134 - val_accuracy: 0.7381 - penalty: 1e-06\n",
            "hidden layer sizes: [148, 44, 67, 253, 430], total units: 942\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7542769312858582 - val_accuracy: 0.7381 - penalty: 1e-06\n",
            "hidden layer sizes: [177, 64, 87, 303, 516], total units: 1147\n",
            "Before pruning:\n",
            "loss: 0.6329159140586853 - accuracy: 0.77766 - val_loss: 0.7475136518478394 - val_accuracy: 0.7409 - penalty: 1e-06\n",
            "hidden layer sizes: [177, 64, 87, 303, 516], total units: 1147\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7475546598434448 - val_accuracy: 0.7409 - penalty: 1e-06\n",
            "hidden layer sizes: [141, 50, 76, 259, 404], total units: 930\n",
            "##########################################################\n",
            "Epoch 20/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7475546598434448 - val_accuracy: 0.7409 - penalty: 1e-06\n",
            "hidden layer sizes: [141, 50, 76, 259, 404], total units: 930\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7475546598434448 - val_accuracy: 0.7409 - penalty: 1e-06\n",
            "hidden layer sizes: [169, 70, 96, 310, 484], total units: 1129\n",
            "Before pruning:\n",
            "loss: 0.6243708729743958 - accuracy: 0.77822 - val_loss: 0.7408627867698669 - val_accuracy: 0.7426 - penalty: 1e-06\n",
            "hidden layer sizes: [169, 70, 96, 310, 484], total units: 1129\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7406055927276611 - val_accuracy: 0.7428 - penalty: 1e-06\n",
            "hidden layer sizes: [137, 50, 72, 253, 431], total units: 943\n",
            "##########################################################\n",
            "Epoch 21/30\n",
            "loss: 0.6657538414001465 - accuracy: 0.76752 - val_loss: 0.7742445468902588 - val_accuracy: 0.7296 - penalty: 0.0\n",
            "hidden layer sizes: [137, 50, 72, 253, 431], total units: 943\n",
            "##########################################################\n",
            "Epoch 22/30\n",
            "loss: 0.510741651058197 - accuracy: 0.81886 - val_loss: 0.7856537103652954 - val_accuracy: 0.7381 - penalty: 0.0\n",
            "hidden layer sizes: [137, 50, 72, 253, 431], total units: 943\n",
            "##########################################################\n",
            "Epoch 23/30\n",
            "loss: 0.42453768849372864 - accuracy: 0.84902 - val_loss: 0.7928207516670227 - val_accuracy: 0.7432 - penalty: 0.0\n",
            "hidden layer sizes: [137, 50, 72, 253, 431], total units: 943\n",
            "##########################################################\n",
            "Epoch 24/30\n",
            "loss: 0.35585126280784607 - accuracy: 0.87342 - val_loss: 0.8148535490036011 - val_accuracy: 0.7401 - penalty: 0.0\n",
            "hidden layer sizes: [137, 50, 72, 253, 431], total units: 943\n",
            "##########################################################\n",
            "Epoch 25/30\n",
            "loss: 0.2869917154312134 - accuracy: 0.89744 - val_loss: 0.8468588590621948 - val_accuracy: 0.7458 - penalty: 0.0\n",
            "hidden layer sizes: [137, 50, 72, 253, 431], total units: 943\n",
            "##########################################################\n",
            "Epoch 26/30\n",
            "loss: 0.24149714410305023 - accuracy: 0.91382 - val_loss: 0.869026243686676 - val_accuracy: 0.7466 - penalty: 0.0\n",
            "hidden layer sizes: [137, 50, 72, 253, 431], total units: 943\n",
            "##########################################################\n",
            "Epoch 27/30\n",
            "loss: 0.1891796886920929 - accuracy: 0.93306 - val_loss: 0.946753203868866 - val_accuracy: 0.7455 - penalty: 0.0\n",
            "hidden layer sizes: [137, 50, 72, 253, 431], total units: 943\n",
            "##########################################################\n",
            "Epoch 28/30\n",
            "loss: 0.15514622628688812 - accuracy: 0.94566 - val_loss: 0.9624152183532715 - val_accuracy: 0.7517 - penalty: 0.0\n",
            "hidden layer sizes: [137, 50, 72, 253, 431], total units: 943\n",
            "##########################################################\n",
            "Epoch 29/30\n",
            "loss: 0.12853001058101654 - accuracy: 0.95534 - val_loss: 1.004549264907837 - val_accuracy: 0.7492 - penalty: 0.0\n",
            "hidden layer sizes: [137, 50, 72, 253, 431], total units: 943\n",
            "##########################################################\n",
            "Epoch 30/30\n",
            "loss: 0.10986413061618805 - accuracy: 0.96172 - val_loss: 1.0249000787734985 - val_accuracy: 0.7561 - penalty: 0.0\n",
            "hidden layer sizes: [137, 50, 72, 253, 431], total units: 943\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.38132,\n",
              "  0.47052,\n",
              "  0.53864,\n",
              "  0.57584,\n",
              "  0.61424,\n",
              "  0.64546,\n",
              "  0.66984,\n",
              "  0.68944,\n",
              "  0.70474,\n",
              "  0.719,\n",
              "  0.72956,\n",
              "  0.73654,\n",
              "  0.74674,\n",
              "  0.75508,\n",
              "  0.75548,\n",
              "  0.76352,\n",
              "  0.76712,\n",
              "  0.77214,\n",
              "  0.77766,\n",
              "  0.77822,\n",
              "  0.76752,\n",
              "  0.81886,\n",
              "  0.84902,\n",
              "  0.87342,\n",
              "  0.89744,\n",
              "  0.91382,\n",
              "  0.93306,\n",
              "  0.94566,\n",
              "  0.95534,\n",
              "  0.96172],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.9035163>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4815971>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2890013>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1844859>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.081236>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9936506>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9322214>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8767426>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8339406>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.79099524>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7663811>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.73986226>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.71754533>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.69818866>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6880047>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.66945624>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.65589625>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.64570284>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6329159>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6243709>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.66575384>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.51074165>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.4245377>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.35585126>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.28699172>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.24149714>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.18917969>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.15514623>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.12853001>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.10986413>],\n",
              " 'val_accuracy': [0.488,\n",
              "  0.5544,\n",
              "  0.5818,\n",
              "  0.6156,\n",
              "  0.6527,\n",
              "  0.6846,\n",
              "  0.6907,\n",
              "  0.7083,\n",
              "  0.7167,\n",
              "  0.7168,\n",
              "  0.7235,\n",
              "  0.7259,\n",
              "  0.7373,\n",
              "  0.731,\n",
              "  0.7336,\n",
              "  0.7276,\n",
              "  0.7383,\n",
              "  0.7381,\n",
              "  0.7409,\n",
              "  0.7428,\n",
              "  0.7296,\n",
              "  0.7381,\n",
              "  0.7432,\n",
              "  0.7401,\n",
              "  0.7458,\n",
              "  0.7466,\n",
              "  0.7455,\n",
              "  0.7517,\n",
              "  0.7492,\n",
              "  0.7561],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.4304296>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2381744>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.151603>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0723928>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.98572284>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.90094423>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8786243>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.83416045>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8072875>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.80339295>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7873465>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7897037>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.76203567>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.76649505>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7562064>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.78144443>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.751383>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7542769>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.74755466>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7406056>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.77424455>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7856537>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.79282075>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.81485355>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.84685886>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.86902624>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9467532>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9624152>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0045493>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0249001>]}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrcVbyP7QYXg",
        "outputId": "cacab1da-2c06-43ed-c92c-723826eea8fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential([\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None, fixed_size=True),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.983743667602539 - val_accuracy: 0.1149 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.983743906021118 - val_accuracy: 0.1149 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.9288136959075928 - accuracy: 0.37844 - val_loss: 1.4544951915740967 - val_accuracy: 0.4809 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4529860019683838 - val_accuracy: 0.4821 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "##########################################################\n",
            "Epoch 2/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4529860019683838 - val_accuracy: 0.4821 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4529860019683838 - val_accuracy: 0.4821 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.5003464221954346 - accuracy: 0.46592 - val_loss: 1.273173451423645 - val_accuracy: 0.5368 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.2731773853302002 - val_accuracy: 0.5364 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "##########################################################\n",
            "Epoch 3/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2731773853302002 - val_accuracy: 0.5364 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2731773853302002 - val_accuracy: 0.5364 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.3108245134353638 - accuracy: 0.53098 - val_loss: 1.1865636110305786 - val_accuracy: 0.5708 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1864274740219116 - val_accuracy: 0.5706 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "##########################################################\n",
            "Epoch 4/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1864274740219116 - val_accuracy: 0.5706 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 256], total units: 1024\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.186427354812622 - val_accuracy: 0.5706 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "Before pruning:\n",
            "loss: 1.1894413232803345 - accuracy: 0.5748 - val_loss: 1.0617703199386597 - val_accuracy: 0.622 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 307], total units: 1227\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0615702867507935 - val_accuracy: 0.6217 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 166, 181, 191, 258], total units: 988\n",
            "##########################################################\n",
            "Epoch 5/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0615702867507935 - val_accuracy: 0.6217 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 166, 181, 191, 258], total units: 988\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.061570167541504 - val_accuracy: 0.6217 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 199, 217, 229, 309], total units: 1184\n",
            "Before pruning:\n",
            "loss: 1.0909630060195923 - accuracy: 0.60972 - val_loss: 1.001274585723877 - val_accuracy: 0.6471 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 199, 217, 229, 309], total units: 1184\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.001535177230835 - val_accuracy: 0.6468 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 117, 158, 197, 284], total units: 948\n",
            "##########################################################\n",
            "Epoch 6/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.001535177230835 - val_accuracy: 0.6468 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 117, 158, 197, 284], total units: 948\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.001535177230835 - val_accuracy: 0.6468 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 140, 189, 236, 340], total units: 1135\n",
            "Before pruning:\n",
            "loss: 1.0069819688796997 - accuracy: 0.6425 - val_loss: 0.9350489974021912 - val_accuracy: 0.67 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 140, 189, 236, 340], total units: 1135\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9349101781845093 - val_accuracy: 0.6701 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 96, 137, 197, 272], total units: 894\n",
            "##########################################################\n",
            "Epoch 7/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9349101781845093 - val_accuracy: 0.6701 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 96, 137, 197, 272], total units: 894\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9349101781845093 - val_accuracy: 0.6701 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 116, 164, 236, 326], total units: 1072\n",
            "Before pruning:\n",
            "loss: 0.9389311671257019 - accuracy: 0.66636 - val_loss: 0.8998627662658691 - val_accuracy: 0.6817 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 116, 164, 236, 326], total units: 1072\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8994801044464111 - val_accuracy: 0.682 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 85, 121, 208, 284], total units: 890\n",
            "##########################################################\n",
            "Epoch 8/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8994801044464111 - val_accuracy: 0.682 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 85, 121, 208, 284], total units: 890\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8994799852371216 - val_accuracy: 0.682 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 105, 145, 249, 340], total units: 1069\n",
            "Before pruning:\n",
            "loss: 0.8841295838356018 - accuracy: 0.68794 - val_loss: 0.8493033051490784 - val_accuracy: 0.705 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 105, 145, 249, 340], total units: 1069\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8491409420967102 - val_accuracy: 0.7056 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 75, 106, 215, 281], total units: 868\n",
            "##########################################################\n",
            "Epoch 9/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8491409420967102 - val_accuracy: 0.7056 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 75, 106, 215, 281], total units: 868\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.849141001701355 - val_accuracy: 0.7056 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 95, 127, 258, 337], total units: 1046\n",
            "Before pruning:\n",
            "loss: 0.8387278318405151 - accuracy: 0.70252 - val_loss: 0.8214557766914368 - val_accuracy: 0.7128 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 95, 127, 258, 337], total units: 1046\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.821336030960083 - val_accuracy: 0.713 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 73, 100, 231, 302], total units: 897\n",
            "##########################################################\n",
            "Epoch 10/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.821336030960083 - val_accuracy: 0.713 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 73, 100, 231, 302], total units: 897\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.821336030960083 - val_accuracy: 0.713 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 93, 120, 277, 362], total units: 1081\n",
            "Before pruning:\n",
            "loss: 0.8099547028541565 - accuracy: 0.71222 - val_loss: 0.8064177632331848 - val_accuracy: 0.7201 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 93, 120, 277, 362], total units: 1081\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8063188791275024 - val_accuracy: 0.7196 - penalty: 1e-06\n",
            "hidden layer sizes: [188, 70, 87, 242, 322], total units: 909\n",
            "##########################################################\n",
            "Epoch 11/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8063188791275024 - val_accuracy: 0.7196 - penalty: 1e-06\n",
            "hidden layer sizes: [188, 70, 87, 242, 322], total units: 909\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8063188791275024 - val_accuracy: 0.7196 - penalty: 1e-06\n",
            "hidden layer sizes: [225, 90, 107, 290, 386], total units: 1098\n",
            "Before pruning:\n",
            "loss: 0.7798410654067993 - accuracy: 0.72336 - val_loss: 0.8011629581451416 - val_accuracy: 0.7208 - penalty: 1e-06\n",
            "hidden layer sizes: [225, 90, 107, 290, 386], total units: 1098\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8010385036468506 - val_accuracy: 0.7212 - penalty: 1e-06\n",
            "hidden layer sizes: [187, 70, 83, 243, 332], total units: 915\n",
            "##########################################################\n",
            "Epoch 12/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8010385036468506 - val_accuracy: 0.7212 - penalty: 1e-06\n",
            "hidden layer sizes: [187, 70, 83, 243, 332], total units: 915\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8010385036468506 - val_accuracy: 0.7212 - penalty: 1e-06\n",
            "hidden layer sizes: [224, 90, 103, 291, 398], total units: 1106\n",
            "Before pruning:\n",
            "loss: 0.7496861219406128 - accuracy: 0.73368 - val_loss: 0.7774808406829834 - val_accuracy: 0.7272 - penalty: 1e-06\n",
            "hidden layer sizes: [224, 90, 103, 291, 398], total units: 1106\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.777439534664154 - val_accuracy: 0.7276 - penalty: 1e-06\n",
            "hidden layer sizes: [182, 61, 78, 249, 331], total units: 901\n",
            "##########################################################\n",
            "Epoch 13/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.777439534664154 - val_accuracy: 0.7276 - penalty: 1e-06\n",
            "hidden layer sizes: [182, 61, 78, 249, 331], total units: 901\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7774396538734436 - val_accuracy: 0.7276 - penalty: 1e-06\n",
            "hidden layer sizes: [218, 81, 98, 298, 397], total units: 1092\n",
            "Before pruning:\n",
            "loss: 0.7353717684745789 - accuracy: 0.73852 - val_loss: 0.7796745896339417 - val_accuracy: 0.7279 - penalty: 1e-06\n",
            "hidden layer sizes: [218, 81, 98, 298, 397], total units: 1092\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7796557545661926 - val_accuracy: 0.7282 - penalty: 1e-06\n",
            "hidden layer sizes: [170, 57, 77, 257, 322], total units: 883\n",
            "##########################################################\n",
            "Epoch 14/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7796557545661926 - val_accuracy: 0.7282 - penalty: 1e-06\n",
            "hidden layer sizes: [170, 57, 77, 257, 322], total units: 883\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7796558141708374 - val_accuracy: 0.7282 - penalty: 1e-06\n",
            "hidden layer sizes: [204, 77, 97, 308, 386], total units: 1072\n",
            "Before pruning:\n",
            "loss: 0.7121407985687256 - accuracy: 0.7498 - val_loss: 0.7689936757087708 - val_accuracy: 0.7289 - penalty: 1e-06\n",
            "hidden layer sizes: [204, 77, 97, 308, 386], total units: 1072\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7690028548240662 - val_accuracy: 0.7289 - penalty: 1e-06\n",
            "hidden layer sizes: [167, 57, 72, 257, 366], total units: 919\n",
            "##########################################################\n",
            "Epoch 15/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7690028548240662 - val_accuracy: 0.7289 - penalty: 1e-06\n",
            "hidden layer sizes: [167, 57, 72, 257, 366], total units: 919\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7690028548240662 - val_accuracy: 0.7289 - penalty: 1e-06\n",
            "hidden layer sizes: [200, 77, 92, 308, 439], total units: 1116\n",
            "Before pruning:\n",
            "loss: 0.6919641494750977 - accuracy: 0.75436 - val_loss: 0.7647964358329773 - val_accuracy: 0.7348 - penalty: 1e-06\n",
            "hidden layer sizes: [200, 77, 92, 308, 439], total units: 1116\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.764499306678772 - val_accuracy: 0.7351 - penalty: 1e-06\n",
            "hidden layer sizes: [160, 59, 72, 258, 383], total units: 932\n",
            "##########################################################\n",
            "Epoch 16/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.764499306678772 - val_accuracy: 0.7351 - penalty: 1e-06\n",
            "hidden layer sizes: [160, 59, 72, 258, 383], total units: 932\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.764499306678772 - val_accuracy: 0.7351 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 79, 92, 309, 459], total units: 1131\n",
            "Before pruning:\n",
            "loss: 0.6801711916923523 - accuracy: 0.76042 - val_loss: 0.7700462341308594 - val_accuracy: 0.7336 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 79, 92, 309, 459], total units: 1131\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7697965502738953 - val_accuracy: 0.7337 - penalty: 1e-06\n",
            "hidden layer sizes: [153, 54, 68, 259, 399], total units: 933\n",
            "##########################################################\n",
            "Epoch 17/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7697965502738953 - val_accuracy: 0.7337 - penalty: 1e-06\n",
            "hidden layer sizes: [153, 54, 68, 259, 399], total units: 933\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7697965502738953 - val_accuracy: 0.7337 - penalty: 1e-06\n",
            "hidden layer sizes: [183, 74, 88, 310, 478], total units: 1133\n",
            "Before pruning:\n",
            "loss: 0.6661350727081299 - accuracy: 0.7648 - val_loss: 0.7700350284576416 - val_accuracy: 0.7337 - penalty: 1e-06\n",
            "hidden layer sizes: [183, 74, 88, 310, 478], total units: 1133\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7698341012001038 - val_accuracy: 0.7334 - penalty: 1e-06\n",
            "hidden layer sizes: [146, 55, 70, 259, 441], total units: 971\n",
            "##########################################################\n",
            "Epoch 18/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7698341012001038 - val_accuracy: 0.7334 - penalty: 1e-06\n",
            "hidden layer sizes: [146, 55, 70, 259, 441], total units: 971\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7698341012001038 - val_accuracy: 0.7334 - penalty: 1e-06\n",
            "hidden layer sizes: [175, 75, 90, 310, 529], total units: 1179\n",
            "Before pruning:\n",
            "loss: 0.6538716554641724 - accuracy: 0.7687 - val_loss: 0.7591924071311951 - val_accuracy: 0.737 - penalty: 1e-06\n",
            "hidden layer sizes: [175, 75, 90, 310, 529], total units: 1179\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7590632438659668 - val_accuracy: 0.7373 - penalty: 1e-06\n",
            "hidden layer sizes: [141, 53, 68, 260, 428], total units: 950\n",
            "##########################################################\n",
            "Epoch 19/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7590632438659668 - val_accuracy: 0.7373 - penalty: 1e-06\n",
            "hidden layer sizes: [141, 53, 68, 260, 428], total units: 950\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7590632438659668 - val_accuracy: 0.7373 - penalty: 1e-06\n",
            "hidden layer sizes: [169, 73, 88, 312, 513], total units: 1155\n",
            "Before pruning:\n",
            "loss: 0.6393699049949646 - accuracy: 0.7746 - val_loss: 0.7619454860687256 - val_accuracy: 0.7368 - penalty: 1e-06\n",
            "hidden layer sizes: [169, 73, 88, 312, 513], total units: 1155\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7618334293365479 - val_accuracy: 0.7363 - penalty: 1e-06\n",
            "hidden layer sizes: [132, 55, 66, 259, 438], total units: 950\n",
            "##########################################################\n",
            "Epoch 20/30\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7618334293365479 - val_accuracy: 0.7363 - penalty: 1e-06\n",
            "hidden layer sizes: [132, 55, 66, 259, 438], total units: 950\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7618333697319031 - val_accuracy: 0.7363 - penalty: 1e-06\n",
            "hidden layer sizes: [158, 75, 86, 310, 525], total units: 1154\n",
            "Before pruning:\n",
            "loss: 0.6292902827262878 - accuracy: 0.7785 - val_loss: 0.7493035197257996 - val_accuracy: 0.7445 - penalty: 1e-06\n",
            "hidden layer sizes: [158, 75, 86, 310, 525], total units: 1154\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7494103908538818 - val_accuracy: 0.7442 - penalty: 1e-06\n",
            "hidden layer sizes: [128, 53, 73, 262, 489], total units: 1005\n",
            "##########################################################\n",
            "Epoch 21/30\n",
            "loss: 0.6712389588356018 - accuracy: 0.76604 - val_loss: 0.7921534180641174 - val_accuracy: 0.7277 - penalty: 0.0\n",
            "hidden layer sizes: [128, 53, 73, 262, 489], total units: 1005\n",
            "##########################################################\n",
            "Epoch 22/30\n",
            "loss: 0.5169544219970703 - accuracy: 0.815 - val_loss: 0.783096969127655 - val_accuracy: 0.7396 - penalty: 0.0\n",
            "hidden layer sizes: [128, 53, 73, 262, 489], total units: 1005\n",
            "##########################################################\n",
            "Epoch 23/30\n",
            "loss: 0.43144160509109497 - accuracy: 0.8464 - val_loss: 0.7942081093788147 - val_accuracy: 0.7405 - penalty: 0.0\n",
            "hidden layer sizes: [128, 53, 73, 262, 489], total units: 1005\n",
            "##########################################################\n",
            "Epoch 24/30\n",
            "loss: 0.3458555042743683 - accuracy: 0.8779 - val_loss: 0.8367624878883362 - val_accuracy: 0.7415 - penalty: 0.0\n",
            "hidden layer sizes: [128, 53, 73, 262, 489], total units: 1005\n",
            "##########################################################\n",
            "Epoch 25/30\n",
            "loss: 0.2707514762878418 - accuracy: 0.90406 - val_loss: 0.8694369196891785 - val_accuracy: 0.7461 - penalty: 0.0\n",
            "hidden layer sizes: [128, 53, 73, 262, 489], total units: 1005\n",
            "##########################################################\n",
            "Epoch 26/30\n",
            "loss: 0.21049128472805023 - accuracy: 0.92654 - val_loss: 0.9012873768806458 - val_accuracy: 0.7467 - penalty: 0.0\n",
            "hidden layer sizes: [128, 53, 73, 262, 489], total units: 1005\n",
            "##########################################################\n",
            "Epoch 27/30\n",
            "loss: 0.16451993584632874 - accuracy: 0.94354 - val_loss: 0.9772655963897705 - val_accuracy: 0.746 - penalty: 0.0\n",
            "hidden layer sizes: [128, 53, 73, 262, 489], total units: 1005\n",
            "##########################################################\n",
            "Epoch 28/30\n",
            "loss: 0.13301429152488708 - accuracy: 0.95464 - val_loss: 1.0230374336242676 - val_accuracy: 0.7463 - penalty: 0.0\n",
            "hidden layer sizes: [128, 53, 73, 262, 489], total units: 1005\n",
            "##########################################################\n",
            "Epoch 29/30\n",
            "loss: 0.11242907494306564 - accuracy: 0.96162 - val_loss: 1.0425822734832764 - val_accuracy: 0.7494 - penalty: 0.0\n",
            "hidden layer sizes: [128, 53, 73, 262, 489], total units: 1005\n",
            "##########################################################\n",
            "Epoch 30/30\n",
            "loss: 0.0937553122639656 - accuracy: 0.96782 - val_loss: 1.0605627298355103 - val_accuracy: 0.7491 - penalty: 0.0\n",
            "hidden layer sizes: [128, 53, 73, 262, 489], total units: 1005\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.37844,\n",
              "  0.46592,\n",
              "  0.53098,\n",
              "  0.5748,\n",
              "  0.60972,\n",
              "  0.6425,\n",
              "  0.66636,\n",
              "  0.68794,\n",
              "  0.70252,\n",
              "  0.71222,\n",
              "  0.72336,\n",
              "  0.73368,\n",
              "  0.73852,\n",
              "  0.7498,\n",
              "  0.75436,\n",
              "  0.76042,\n",
              "  0.7648,\n",
              "  0.7687,\n",
              "  0.7746,\n",
              "  0.7785,\n",
              "  0.76604,\n",
              "  0.815,\n",
              "  0.8464,\n",
              "  0.8779,\n",
              "  0.90406,\n",
              "  0.92654,\n",
              "  0.94354,\n",
              "  0.95464,\n",
              "  0.96162,\n",
              "  0.96782],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.9288137>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.5003464>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3108245>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1894413>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.090963>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.006982>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.93893117>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8841296>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.83872783>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8099547>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.77984107>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7496861>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.73537177>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7121408>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.69196415>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6801712>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6661351>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.65387166>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6393699>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6292903>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.67123896>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5169544>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.4314416>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.3458555>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.27075148>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.21049128>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.16451994>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.13301429>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.112429075>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.09375531>],\n",
              " 'val_accuracy': [0.4821,\n",
              "  0.5364,\n",
              "  0.5706,\n",
              "  0.6217,\n",
              "  0.6468,\n",
              "  0.6701,\n",
              "  0.682,\n",
              "  0.7056,\n",
              "  0.713,\n",
              "  0.7196,\n",
              "  0.7212,\n",
              "  0.7276,\n",
              "  0.7282,\n",
              "  0.7289,\n",
              "  0.7351,\n",
              "  0.7337,\n",
              "  0.7334,\n",
              "  0.7373,\n",
              "  0.7363,\n",
              "  0.7442,\n",
              "  0.7277,\n",
              "  0.7396,\n",
              "  0.7405,\n",
              "  0.7415,\n",
              "  0.7461,\n",
              "  0.7467,\n",
              "  0.746,\n",
              "  0.7463,\n",
              "  0.7494,\n",
              "  0.7491],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.452986>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2731774>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1864275>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0615703>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0015352>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9349102>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8994801>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.84914094>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.82133603>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8063189>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8010385>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.77743953>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.77965575>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.76900285>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7644993>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.76979655>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7698341>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.75906324>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7618334>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7494104>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7921534>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.78309697>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7942081>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8367625>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8694369>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9012874>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9772656>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0230374>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0425823>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0605627>]}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmgHRLNJ9cEM"
      },
      "source": [
        "## Static models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjsCq-6j7vI2"
      },
      "source": [
        "epochs = 20\n",
        "self_scaling_epochs = 0\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQrzS2PLHysw"
      },
      "source": [
        "# Final layer sizes of dynamic models\n",
        "[131, 51, 72, 277, 438]\n",
        "[130, 45, 88, 244, 434]\n",
        "[107, 51, 58, 212, 310]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zomuwg35LG6R"
      },
      "source": [
        "### Layer sizes set to the architecture discovered by auto-sizing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpeSlT3CLizZ",
        "outputId": "95b26d31-157b-429a-b539-da0427b50be0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model = Sequential([\n",
        "        Conv2D(130, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(50, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(80, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Conv2D(250, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(430, activation='selu', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "loss: 3.542296886444092 - accuracy: 0.10588 - val_loss: 2.349604606628418 - val_accuracy: 0.1 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "loss: 2.3350794315338135 - accuracy: 0.10072 - val_loss: 2.341313362121582 - val_accuracy: 0.1002 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "loss: 2.322622299194336 - accuracy: 0.11064 - val_loss: 2.151273727416992 - val_accuracy: 0.1587 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "loss: 2.028930187225342 - accuracy: 0.1828 - val_loss: 1.8920965194702148 - val_accuracy: 0.1908 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "loss: 1.7598954439163208 - accuracy: 0.29744 - val_loss: 1.567871332168579 - val_accuracy: 0.3852 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "loss: 1.4557782411575317 - accuracy: 0.44832 - val_loss: 1.3415145874023438 - val_accuracy: 0.5022 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "loss: 1.3105548620224 - accuracy: 0.51294 - val_loss: 1.3159866333007812 - val_accuracy: 0.5299 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "loss: 1.1933603286743164 - accuracy: 0.56258 - val_loss: 1.148223876953125 - val_accuracy: 0.5822 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "loss: 1.098826289176941 - accuracy: 0.5981 - val_loss: 1.0770899057388306 - val_accuracy: 0.6176 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "loss: 1.0256305932998657 - accuracy: 0.62944 - val_loss: 1.0650094747543335 - val_accuracy: 0.6292 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "loss: 0.9596800804138184 - accuracy: 0.66138 - val_loss: 0.9870801568031311 - val_accuracy: 0.6731 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "loss: 0.8893182873725891 - accuracy: 0.68966 - val_loss: 0.9066979289054871 - val_accuracy: 0.6982 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "loss: 0.844311535358429 - accuracy: 0.70426 - val_loss: 0.9533615112304688 - val_accuracy: 0.6851 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "loss: 0.7950552105903625 - accuracy: 0.72374 - val_loss: 0.9299074411392212 - val_accuracy: 0.6977 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "loss: 0.7652485966682434 - accuracy: 0.73516 - val_loss: 0.8921818137168884 - val_accuracy: 0.7132 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "loss: 0.7335625290870667 - accuracy: 0.74742 - val_loss: 0.8883573412895203 - val_accuracy: 0.7149 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "loss: 0.7036364078521729 - accuracy: 0.75782 - val_loss: 0.9330236315727234 - val_accuracy: 0.7075 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "loss: 0.6641353368759155 - accuracy: 0.77294 - val_loss: 0.8753843903541565 - val_accuracy: 0.7262 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "loss: 0.6394566297531128 - accuracy: 0.78166 - val_loss: 0.8594812750816345 - val_accuracy: 0.7327 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "loss: 0.6381580829620361 - accuracy: 0.78208 - val_loss: 0.9548560380935669 - val_accuracy: 0.7193 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "CPU times: user 2min 38s, sys: 3.28 s, total: 2min 41s\n",
            "Wall time: 3min 2s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2DBXrAtIEVw",
        "outputId": "b7c10081-b5b2-4e02-8be4-4efc9fed6d38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model = Sequential([\n",
        "        Conv2D(130, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(50, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(80, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Conv2D(250, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(430, activation='selu', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "loss: 2.307016611099243 - accuracy: 0.36996 - val_loss: 1.4811290502548218 - val_accuracy: 0.457 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "loss: 1.4038615226745605 - accuracy: 0.49278 - val_loss: 1.2863517999649048 - val_accuracy: 0.5352 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "loss: 1.2491425275802612 - accuracy: 0.55084 - val_loss: 1.1936345100402832 - val_accuracy: 0.5744 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "loss: 1.1316972970962524 - accuracy: 0.59534 - val_loss: 1.1694689989089966 - val_accuracy: 0.5793 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "loss: 1.019073486328125 - accuracy: 0.6355 - val_loss: 1.0789142847061157 - val_accuracy: 0.6232 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "loss: 0.9088562726974487 - accuracy: 0.67686 - val_loss: 1.0609148740768433 - val_accuracy: 0.6466 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "loss: 0.8106961846351624 - accuracy: 0.7126 - val_loss: 1.0519739389419556 - val_accuracy: 0.6571 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "loss: 0.7255057096481323 - accuracy: 0.7433 - val_loss: 1.0838028192520142 - val_accuracy: 0.6652 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "loss: 0.6549095511436462 - accuracy: 0.76922 - val_loss: 1.0932139158248901 - val_accuracy: 0.6736 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "loss: 0.5864938497543335 - accuracy: 0.79342 - val_loss: 1.1260793209075928 - val_accuracy: 0.6714 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "loss: 0.5393314361572266 - accuracy: 0.81242 - val_loss: 1.1495566368103027 - val_accuracy: 0.685 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "loss: 0.4936266541481018 - accuracy: 0.82566 - val_loss: 1.1411411762237549 - val_accuracy: 0.6876 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "loss: 0.44394850730895996 - accuracy: 0.84316 - val_loss: 1.132514238357544 - val_accuracy: 0.6931 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "loss: 0.4059078097343445 - accuracy: 0.8601 - val_loss: 1.1951543092727661 - val_accuracy: 0.6862 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "loss: 0.3730584681034088 - accuracy: 0.86916 - val_loss: 1.170699119567871 - val_accuracy: 0.6986 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "loss: 0.3675439953804016 - accuracy: 0.87296 - val_loss: 1.2077562808990479 - val_accuracy: 0.6927 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "loss: 0.33543598651885986 - accuracy: 0.88378 - val_loss: 1.3065261840820312 - val_accuracy: 0.6909 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "loss: 0.31193506717681885 - accuracy: 0.89282 - val_loss: 1.389482855796814 - val_accuracy: 0.6922 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "loss: 0.2900753319263458 - accuracy: 0.90106 - val_loss: 1.3118497133255005 - val_accuracy: 0.7009 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "loss: 0.2800607681274414 - accuracy: 0.90562 - val_loss: 1.3819533586502075 - val_accuracy: 0.6867 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "CPU times: user 2min 40s, sys: 3.63 s, total: 2min 44s\n",
            "Wall time: 3min 4s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHZO6wDRK5nE",
        "outputId": "b3a5e411-86f2-46b5-9da5-21c028febc02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model = Sequential([\n",
        "        Conv2D(130, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(50, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(80, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Conv2D(250, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(430, activation='selu', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "loss: 1.9652268886566162 - accuracy: 0.39594 - val_loss: 1.4078832864761353 - val_accuracy: 0.4997 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "loss: 1.3558696508407593 - accuracy: 0.51694 - val_loss: 1.286001443862915 - val_accuracy: 0.5464 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "loss: 1.2024716138839722 - accuracy: 0.57148 - val_loss: 1.1833745241165161 - val_accuracy: 0.5795 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "loss: 1.061343789100647 - accuracy: 0.6232 - val_loss: 1.1501379013061523 - val_accuracy: 0.5953 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "loss: 0.922852098941803 - accuracy: 0.67318 - val_loss: 1.1511390209197998 - val_accuracy: 0.6108 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "loss: 0.7912628650665283 - accuracy: 0.71992 - val_loss: 1.1361163854599 - val_accuracy: 0.6187 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "loss: 0.6588713526725769 - accuracy: 0.76658 - val_loss: 1.2003930807113647 - val_accuracy: 0.6344 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "loss: 0.5527268648147583 - accuracy: 0.8031 - val_loss: 1.2076102495193481 - val_accuracy: 0.6385 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "loss: 0.4640187919139862 - accuracy: 0.83704 - val_loss: 1.2885226011276245 - val_accuracy: 0.6339 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "loss: 0.37477973103523254 - accuracy: 0.86736 - val_loss: 1.3218116760253906 - val_accuracy: 0.6506 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "loss: 0.32981929183006287 - accuracy: 0.88506 - val_loss: 1.4347448348999023 - val_accuracy: 0.6471 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "loss: 0.28487178683280945 - accuracy: 0.9009 - val_loss: 1.4376320838928223 - val_accuracy: 0.6525 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "loss: 0.2514776289463043 - accuracy: 0.91248 - val_loss: 1.5086326599121094 - val_accuracy: 0.6481 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "loss: 0.22519056499004364 - accuracy: 0.9227 - val_loss: 1.5170361995697021 - val_accuracy: 0.6486 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "loss: 0.2004801630973816 - accuracy: 0.93098 - val_loss: 1.6709601879119873 - val_accuracy: 0.6472 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "loss: 0.1883498579263687 - accuracy: 0.93642 - val_loss: 1.7348310947418213 - val_accuracy: 0.661 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "loss: 0.17838351428508759 - accuracy: 0.93942 - val_loss: 1.7377312183380127 - val_accuracy: 0.6594 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "loss: 0.16687171161174774 - accuracy: 0.94378 - val_loss: 1.8090025186538696 - val_accuracy: 0.6717 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "loss: 0.15447545051574707 - accuracy: 0.94752 - val_loss: 1.7867709398269653 - val_accuracy: 0.6654 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "loss: 0.14759458601474762 - accuracy: 0.9517 - val_loss: 1.8556467294692993 - val_accuracy: 0.6664 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "CPU times: user 2min 38s, sys: 3.37 s, total: 2min 42s\n",
            "Wall time: 3min 2s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Vcban4zKEv1",
        "outputId": "fed09eb7-d77d-4bd8-8529-34ae53b75d72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model = Sequential([\n",
        "        Conv2D(130, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(50, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(80, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Conv2D(250, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(430, activation='selu', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "loss: 2.064971685409546 - accuracy: 0.3657 - val_loss: 1.4674673080444336 - val_accuracy: 0.477 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "loss: 1.4317291975021362 - accuracy: 0.49284 - val_loss: 1.3502579927444458 - val_accuracy: 0.5144 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "loss: 1.2809815406799316 - accuracy: 0.5453 - val_loss: 1.278853416442871 - val_accuracy: 0.5474 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "loss: 1.1600797176361084 - accuracy: 0.58854 - val_loss: 1.1908364295959473 - val_accuracy: 0.5767 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "loss: 1.0447736978530884 - accuracy: 0.63098 - val_loss: 1.156123161315918 - val_accuracy: 0.597 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "loss: 0.9252257943153381 - accuracy: 0.67272 - val_loss: 1.126400351524353 - val_accuracy: 0.6074 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "loss: 0.8046407103538513 - accuracy: 0.71718 - val_loss: 1.1198372840881348 - val_accuracy: 0.6179 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "loss: 0.6971640586853027 - accuracy: 0.75288 - val_loss: 1.1441832780838013 - val_accuracy: 0.6281 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "loss: 0.5893728137016296 - accuracy: 0.79322 - val_loss: 1.1488935947418213 - val_accuracy: 0.6311 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "loss: 0.4847254753112793 - accuracy: 0.82932 - val_loss: 1.2176817655563354 - val_accuracy: 0.6327 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "loss: 0.41446205973625183 - accuracy: 0.85586 - val_loss: 1.2500206232070923 - val_accuracy: 0.6369 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "loss: 0.33975690603256226 - accuracy: 0.88168 - val_loss: 1.282813549041748 - val_accuracy: 0.6346 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "loss: 0.2850266993045807 - accuracy: 0.8997 - val_loss: 1.3853214979171753 - val_accuracy: 0.6394 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "loss: 0.24025051295757294 - accuracy: 0.91662 - val_loss: 1.4497275352478027 - val_accuracy: 0.6414 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "loss: 0.20378732681274414 - accuracy: 0.93024 - val_loss: 1.4719005823135376 - val_accuracy: 0.6405 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "loss: 0.17931272089481354 - accuracy: 0.93778 - val_loss: 1.5043904781341553 - val_accuracy: 0.6432 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "loss: 0.15186503529548645 - accuracy: 0.94868 - val_loss: 1.5284686088562012 - val_accuracy: 0.6443 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "loss: 0.13846157491207123 - accuracy: 0.95188 - val_loss: 1.6347123384475708 - val_accuracy: 0.6408 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "loss: 0.13032525777816772 - accuracy: 0.95502 - val_loss: 1.633957028388977 - val_accuracy: 0.6389 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "loss: 0.10857569426298141 - accuracy: 0.96344 - val_loss: 1.7090785503387451 - val_accuracy: 0.6509 - penalty: 0.0\n",
            "hidden layer sizes: [130, 50, 80, 250, 430], total units: 940\n",
            "CPU times: user 2min 39s, sys: 3.53 s, total: 2min 43s\n",
            "Wall time: 3min 3s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGcN0_PqLRlV"
      },
      "source": [
        "### Layer sizes set manually"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoJydQX7bsmq",
        "scrolled": false,
        "outputId": "c83f7f79-7bf7-4370-e9b4-33dcfad8d311"
      },
      "source": [
        "%%time\n",
        "\n",
        "model = Sequential([\n",
        "        Conv2D(3, 96, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(96, 96, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(96, 192, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', kernel_initializer='lecun_normal'),\n",
        "        Conv2D(96, 192, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(12288, 256, activation='selu', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Dense(256, 10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/25\n",
            "loss: 2.1398861408233643 - accuracy: 0.39144 - val_loss: 1.3741620779037476 - val_accuracy: 0.5007 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 2/25\n",
            "loss: 1.3535252809524536 - accuracy: 0.51546 - val_loss: 1.268190860748291 - val_accuracy: 0.5486 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 3/25\n",
            "loss: 1.1914558410644531 - accuracy: 0.5725 - val_loss: 1.166611671447754 - val_accuracy: 0.5835 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 4/25\n",
            "loss: 1.0351282358169556 - accuracy: 0.63084 - val_loss: 1.087954044342041 - val_accuracy: 0.623 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 5/25\n",
            "loss: 0.9159864783287048 - accuracy: 0.67614 - val_loss: 0.9969214797019958 - val_accuracy: 0.6613 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 6/25\n",
            "loss: 0.8134353160858154 - accuracy: 0.7108 - val_loss: 1.0081638097763062 - val_accuracy: 0.6658 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 7/25\n",
            "loss: 0.7176882028579712 - accuracy: 0.74724 - val_loss: 0.9864904284477234 - val_accuracy: 0.675 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 8/25\n",
            "loss: 0.6499534249305725 - accuracy: 0.76928 - val_loss: 0.973360538482666 - val_accuracy: 0.6957 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 9/25\n",
            "loss: 0.5757144093513489 - accuracy: 0.79518 - val_loss: 1.0311030149459839 - val_accuracy: 0.6877 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 10/25\n",
            "loss: 0.5312620997428894 - accuracy: 0.8151 - val_loss: 1.0731127262115479 - val_accuracy: 0.6944 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 11/25\n",
            "loss: 0.49278587102890015 - accuracy: 0.82826 - val_loss: 1.1032124757766724 - val_accuracy: 0.6912 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 12/25\n",
            "loss: 0.45533832907676697 - accuracy: 0.83932 - val_loss: 1.1450512409210205 - val_accuracy: 0.6946 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 13/25\n",
            "loss: 0.417134165763855 - accuracy: 0.8523 - val_loss: 1.137213945388794 - val_accuracy: 0.6986 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 14/25\n",
            "loss: 0.39540520310401917 - accuracy: 0.8612 - val_loss: 1.1061996221542358 - val_accuracy: 0.7029 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 15/25\n",
            "loss: 0.37588027119636536 - accuracy: 0.87056 - val_loss: 1.133886694908142 - val_accuracy: 0.7044 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 16/25\n",
            "loss: 0.34373739361763 - accuracy: 0.88308 - val_loss: 1.1591758728027344 - val_accuracy: 0.7147 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 17/25\n",
            "loss: 0.3225548565387726 - accuracy: 0.88992 - val_loss: 1.190388560295105 - val_accuracy: 0.711 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 18/25\n",
            "loss: 0.3176613748073578 - accuracy: 0.89348 - val_loss: 1.1829746961593628 - val_accuracy: 0.7074 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 19/25\n",
            "loss: 0.28977060317993164 - accuracy: 0.90038 - val_loss: 1.396437168121338 - val_accuracy: 0.7148 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 20/25\n",
            "loss: 0.28722086548805237 - accuracy: 0.90372 - val_loss: 1.291654348373413 - val_accuracy: 0.7115 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 21/25\n",
            "loss: 0.26941731572151184 - accuracy: 0.90884 - val_loss: 1.4155263900756836 - val_accuracy: 0.7053 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 22/25\n",
            "loss: 0.26944756507873535 - accuracy: 0.90862 - val_loss: 1.2642757892608643 - val_accuracy: 0.7172 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 23/25\n",
            "loss: 0.2647763788700104 - accuracy: 0.91274 - val_loss: 1.3459445238113403 - val_accuracy: 0.6958 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 24/25\n",
            "loss: 0.2519494593143463 - accuracy: 0.91652 - val_loss: 1.2954438924789429 - val_accuracy: 0.7191 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 25/25\n",
            "loss: 0.23448781669139862 - accuracy: 0.92198 - val_loss: 1.3476343154907227 - val_accuracy: 0.7157 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "CPU times: user 4min 53s, sys: 4 s, total: 4min 57s\n",
            "Wall time: 6min 27s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mjBr84v6Ktk",
        "outputId": "21ea0c14-2b46-405d-fc56-371ee2d2856f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model = Sequential([\n",
        "        Conv2D(96, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(96, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='selu', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "loss: 2.116030216217041 - accuracy: 0.38428 - val_loss: 1.3876560926437378 - val_accuracy: 0.4998 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "loss: 1.360109567642212 - accuracy: 0.5092 - val_loss: 1.2392711639404297 - val_accuracy: 0.5579 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "loss: 1.202415108680725 - accuracy: 0.56706 - val_loss: 1.117976427078247 - val_accuracy: 0.5957 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "loss: 1.0698447227478027 - accuracy: 0.6183 - val_loss: 1.0646827220916748 - val_accuracy: 0.6295 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "loss: 0.9639225006103516 - accuracy: 0.65716 - val_loss: 0.9881615042686462 - val_accuracy: 0.6582 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "loss: 0.8609135746955872 - accuracy: 0.69368 - val_loss: 1.0106662511825562 - val_accuracy: 0.6663 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "loss: 0.7895837426185608 - accuracy: 0.72044 - val_loss: 0.9579691290855408 - val_accuracy: 0.6829 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "loss: 0.7255645394325256 - accuracy: 0.742 - val_loss: 0.9203139543533325 - val_accuracy: 0.6933 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "loss: 0.6741765737533569 - accuracy: 0.76052 - val_loss: 0.9133610129356384 - val_accuracy: 0.7121 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "loss: 0.6124322414398193 - accuracy: 0.78406 - val_loss: 0.9261025190353394 - val_accuracy: 0.7036 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "loss: 0.5763772130012512 - accuracy: 0.796 - val_loss: 0.9831997156143188 - val_accuracy: 0.7048 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "loss: 0.5292472839355469 - accuracy: 0.81348 - val_loss: 0.940315842628479 - val_accuracy: 0.7109 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "loss: 0.49868765473365784 - accuracy: 0.82296 - val_loss: 0.9559101462364197 - val_accuracy: 0.7194 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "loss: 0.46681809425354004 - accuracy: 0.8339 - val_loss: 0.9786410927772522 - val_accuracy: 0.7113 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "loss: 0.4455386698246002 - accuracy: 0.84384 - val_loss: 1.0370675325393677 - val_accuracy: 0.7156 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "loss: 0.431081086397171 - accuracy: 0.84874 - val_loss: 0.9598382115364075 - val_accuracy: 0.7327 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "loss: 0.39421042799949646 - accuracy: 0.86204 - val_loss: 0.9601312279701233 - val_accuracy: 0.7233 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "loss: 0.3889602720737457 - accuracy: 0.86446 - val_loss: 0.9993749260902405 - val_accuracy: 0.7196 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "loss: 0.3769107460975647 - accuracy: 0.86922 - val_loss: 1.0717551708221436 - val_accuracy: 0.7291 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "loss: 0.3443959653377533 - accuracy: 0.88068 - val_loss: 1.1164978742599487 - val_accuracy: 0.719 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "CPU times: user 2min 32s, sys: 4.41 s, total: 2min 37s\n",
            "Wall time: 3min 3s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFl0fNzo9tTT"
      },
      "source": [
        "### Lower learning rates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve0vEDGlNag4",
        "outputId": "b2d30051-3219-4c2d-ab7d-438ffffc5b95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model = Sequential([\n",
        "        Conv2D(96, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(96, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='selu', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "loss: 3.6364753246307373 - accuracy: 0.13834 - val_loss: 2.038997173309326 - val_accuracy: 0.1937 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "loss: 1.8863511085510254 - accuracy: 0.24728 - val_loss: 1.6929947137832642 - val_accuracy: 0.3369 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "loss: 1.5627237558364868 - accuracy: 0.40592 - val_loss: 1.4371005296707153 - val_accuracy: 0.4556 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "loss: 1.4159406423568726 - accuracy: 0.47122 - val_loss: 1.3222863674163818 - val_accuracy: 0.5077 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "loss: 1.2911038398742676 - accuracy: 0.52424 - val_loss: 1.2030831575393677 - val_accuracy: 0.5573 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "loss: 1.194854974746704 - accuracy: 0.56558 - val_loss: 1.162782907485962 - val_accuracy: 0.5652 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "loss: 1.1220676898956299 - accuracy: 0.59142 - val_loss: 1.115524172782898 - val_accuracy: 0.5981 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "loss: 1.0569331645965576 - accuracy: 0.61752 - val_loss: 1.0428560972213745 - val_accuracy: 0.6176 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "loss: 0.9967590570449829 - accuracy: 0.638 - val_loss: 1.0251280069351196 - val_accuracy: 0.6366 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "loss: 0.9514718651771545 - accuracy: 0.6595 - val_loss: 0.9853264689445496 - val_accuracy: 0.6495 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "loss: 0.8963597416877747 - accuracy: 0.67962 - val_loss: 0.9651879072189331 - val_accuracy: 0.6638 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "loss: 0.8530036211013794 - accuracy: 0.69698 - val_loss: 0.9137949347496033 - val_accuracy: 0.683 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "loss: 0.8059719800949097 - accuracy: 0.71514 - val_loss: 0.8971531987190247 - val_accuracy: 0.6994 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "loss: 0.7699702382087708 - accuracy: 0.73044 - val_loss: 0.9172139763832092 - val_accuracy: 0.6992 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "loss: 0.74892258644104 - accuracy: 0.7383 - val_loss: 0.9431652426719666 - val_accuracy: 0.6993 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "loss: 0.6957507729530334 - accuracy: 0.75576 - val_loss: 0.8777626752853394 - val_accuracy: 0.7111 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "loss: 0.696088969707489 - accuracy: 0.75654 - val_loss: 0.9330437779426575 - val_accuracy: 0.7144 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "loss: 0.6720901727676392 - accuracy: 0.76816 - val_loss: 0.9006590843200684 - val_accuracy: 0.7177 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "loss: 0.651520848274231 - accuracy: 0.77566 - val_loss: 0.8798283934593201 - val_accuracy: 0.7325 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "loss: 0.6420966982841492 - accuracy: 0.77946 - val_loss: 0.9747942090034485 - val_accuracy: 0.6975 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "CPU times: user 2min 32s, sys: 3 s, total: 2min 35s\n",
            "Wall time: 3min 1s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aduJ_eed85hy",
        "outputId": "86922ff3-dc1c-4f7a-dcee-4b132b2c5bcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model = Sequential([\n",
        "        Conv2D(96, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(96, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', \n",
        "            strides=(1, 1), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', \n",
        "            strides=(2, 2), padding='SAME', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='selu', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "loss: 1.9364395141601562 - accuracy: 0.37422 - val_loss: 1.4458012580871582 - val_accuracy: 0.485 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "loss: 1.4242712259292603 - accuracy: 0.49284 - val_loss: 1.3421002626419067 - val_accuracy: 0.5156 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "loss: 1.289955735206604 - accuracy: 0.54334 - val_loss: 1.2476561069488525 - val_accuracy: 0.5556 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "loss: 1.170866847038269 - accuracy: 0.58414 - val_loss: 1.1811169385910034 - val_accuracy: 0.5738 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "loss: 1.0659559965133667 - accuracy: 0.6197 - val_loss: 1.1238079071044922 - val_accuracy: 0.6009 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "loss: 0.9630758762359619 - accuracy: 0.65902 - val_loss: 1.1032953262329102 - val_accuracy: 0.6142 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "loss: 0.8649547100067139 - accuracy: 0.69482 - val_loss: 1.086409330368042 - val_accuracy: 0.6278 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "loss: 0.7637264728546143 - accuracy: 0.72968 - val_loss: 1.088549256324768 - val_accuracy: 0.6318 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "loss: 0.6691085696220398 - accuracy: 0.76486 - val_loss: 1.1164265871047974 - val_accuracy: 0.636 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "loss: 0.5807543992996216 - accuracy: 0.79298 - val_loss: 1.1370887756347656 - val_accuracy: 0.6419 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "loss: 0.5004003047943115 - accuracy: 0.82274 - val_loss: 1.1191058158874512 - val_accuracy: 0.6532 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "loss: 0.42416244745254517 - accuracy: 0.84982 - val_loss: 1.1677745580673218 - val_accuracy: 0.6552 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "loss: 0.3670492470264435 - accuracy: 0.87066 - val_loss: 1.2148022651672363 - val_accuracy: 0.6517 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "loss: 0.3215842843055725 - accuracy: 0.88494 - val_loss: 1.2641360759735107 - val_accuracy: 0.6618 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "loss: 0.2755711078643799 - accuracy: 0.90228 - val_loss: 1.2828997373580933 - val_accuracy: 0.6633 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "loss: 0.2423623651266098 - accuracy: 0.91376 - val_loss: 1.343477487564087 - val_accuracy: 0.6669 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "loss: 0.21431538462638855 - accuracy: 0.92396 - val_loss: 1.3868709802627563 - val_accuracy: 0.6588 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "loss: 0.18811562657356262 - accuracy: 0.93352 - val_loss: 1.4123141765594482 - val_accuracy: 0.6678 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "loss: 0.16785545647144318 - accuracy: 0.94086 - val_loss: 1.4013440608978271 - val_accuracy: 0.6716 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "loss: 0.15461832284927368 - accuracy: 0.9453 - val_loss: 1.5946664810180664 - val_accuracy: 0.6722 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 256], total units: 832\n",
            "CPU times: user 2min 30s, sys: 10.6 s, total: 2min 41s\n",
            "Wall time: 3min 6s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwNfV7WmWw-r"
      },
      "source": [
        "# Deeper architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9Gd_Iy4WzYa"
      },
      "source": [
        "epochs = 20\n",
        "self_scaling_epochs = 20\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42AZfDwfW3lB",
        "outputId": "fe71eb32-de9f-4067-9b24-f73bed8e3380",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential([\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Dense(256, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None, fixed_size=True),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.811230182647705 - val_accuracy: 0.0935 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 192, 256, 256], total units: 1472\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.811230182647705 - val_accuracy: 0.0935 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 307, 307], total units: 1764\n",
            "Before pruning:\n",
            "loss: 2.0089962482452393 - accuracy: 0.34114 - val_loss: 1.4994239807128906 - val_accuracy: 0.4688 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 307, 307], total units: 1764\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4994170665740967 - val_accuracy: 0.4687 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 192, 267, 288], total units: 1515\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4994170665740967 - val_accuracy: 0.4687 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 192, 267, 288], total units: 1515\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4994169473648071 - val_accuracy: 0.4687 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 320, 345], total units: 1815\n",
            "Before pruning:\n",
            "loss: 1.612258791923523 - accuracy: 0.42356 - val_loss: 1.3127188682556152 - val_accuracy: 0.525 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 320, 345], total units: 1815\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.3126733303070068 - val_accuracy: 0.5246 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 192, 261, 262], total units: 1483\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.3126733303070068 - val_accuracy: 0.5246 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 192, 261, 262], total units: 1483\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.3126733303070068 - val_accuracy: 0.5246 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 313, 314], total units: 1777\n",
            "Before pruning:\n",
            "loss: 1.409425973892212 - accuracy: 0.49296 - val_loss: 1.1963850259780884 - val_accuracy: 0.5684 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 313, 314], total units: 1777\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.196353554725647 - val_accuracy: 0.5684 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 192, 265, 256], total units: 1481\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.196353554725647 - val_accuracy: 0.5684 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 192, 265, 256], total units: 1481\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1963534355163574 - val_accuracy: 0.5684 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 318, 307], total units: 1775\n",
            "Before pruning:\n",
            "loss: 1.3170057535171509 - accuracy: 0.52344 - val_loss: 1.137181043624878 - val_accuracy: 0.5886 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 318, 307], total units: 1775\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1368311643600464 - val_accuracy: 0.5884 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 157, 170, 191, 192, 257, 256], total units: 1415\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1368311643600464 - val_accuracy: 0.5884 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 157, 170, 191, 192, 257, 256], total units: 1415\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1368311643600464 - val_accuracy: 0.5884 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 188, 204, 229, 230, 308, 307], total units: 1696\n",
            "Before pruning:\n",
            "loss: 1.2247231006622314 - accuracy: 0.56212 - val_loss: 1.0706379413604736 - val_accuracy: 0.6184 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 188, 204, 229, 230, 308, 307], total units: 1696\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0698719024658203 - val_accuracy: 0.6187 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 102, 151, 184, 192, 259, 256], total units: 1336\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0698719024658203 - val_accuracy: 0.6187 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 102, 151, 184, 192, 259, 256], total units: 1336\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0698719024658203 - val_accuracy: 0.6187 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 122, 181, 220, 230, 310, 307], total units: 1600\n",
            "Before pruning:\n",
            "loss: 1.1484946012496948 - accuracy: 0.58804 - val_loss: 1.0001367330551147 - val_accuracy: 0.6428 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 122, 181, 220, 230, 310, 307], total units: 1600\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9998205304145813 - val_accuracy: 0.6429 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 85, 139, 174, 192, 258, 257], total units: 1297\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9998205304145813 - val_accuracy: 0.6429 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 85, 139, 174, 192, 258, 257], total units: 1297\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9998205304145813 - val_accuracy: 0.6429 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 105, 166, 208, 230, 309, 308], total units: 1556\n",
            "Before pruning:\n",
            "loss: 1.0888670682907104 - accuracy: 0.6061 - val_loss: 0.9619160294532776 - val_accuracy: 0.6585 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 105, 166, 208, 230, 309, 308], total units: 1556\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9617174863815308 - val_accuracy: 0.6588 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 68, 128, 160, 191, 263, 269], total units: 1271\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9617174863815308 - val_accuracy: 0.6588 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 68, 128, 160, 191, 263, 269], total units: 1271\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9617174863815308 - val_accuracy: 0.6588 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 88, 153, 192, 229, 315, 322], total units: 1529\n",
            "Before pruning:\n",
            "loss: 1.0441266298294067 - accuracy: 0.62636 - val_loss: 0.9099509716033936 - val_accuracy: 0.6748 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 88, 153, 192, 229, 315, 322], total units: 1529\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9098342657089233 - val_accuracy: 0.6747 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 77, 106, 150, 190, 260, 259], total units: 1234\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9098342657089233 - val_accuracy: 0.6747 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 77, 106, 150, 190, 260, 259], total units: 1234\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9098342061042786 - val_accuracy: 0.6747 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 97, 127, 180, 228, 312, 310], total units: 1484\n",
            "Before pruning:\n",
            "loss: 1.013214111328125 - accuracy: 0.63776 - val_loss: 0.869118869304657 - val_accuracy: 0.6918 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 97, 127, 180, 228, 312, 310], total units: 1484\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8689793944358826 - val_accuracy: 0.6921 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 56, 102, 143, 186, 262, 259], total units: 1200\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8689793944358826 - val_accuracy: 0.6921 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 56, 102, 143, 186, 262, 259], total units: 1200\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8689793944358826 - val_accuracy: 0.6921 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 76, 122, 171, 223, 314, 310], total units: 1446\n",
            "Before pruning:\n",
            "loss: 0.97169429063797 - accuracy: 0.65238 - val_loss: 0.8336386680603027 - val_accuracy: 0.7022 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 76, 122, 171, 223, 314, 310], total units: 1446\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8336556553840637 - val_accuracy: 0.7027 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 52, 92, 136, 186, 264, 286], total units: 1207\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8336556553840637 - val_accuracy: 0.7027 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 52, 92, 136, 186, 264, 286], total units: 1207\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.833655595779419 - val_accuracy: 0.7027 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 72, 112, 163, 223, 316, 343], total units: 1458\n",
            "Before pruning:\n",
            "loss: 0.9481240510940552 - accuracy: 0.66166 - val_loss: 0.8369192481040955 - val_accuracy: 0.7028 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 72, 112, 163, 223, 316, 343], total units: 1458\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8368337154388428 - val_accuracy: 0.7025 - penalty: 1e-06\n",
            "hidden layer sizes: [189, 48, 87, 139, 185, 258, 287], total units: 1193\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8368337154388428 - val_accuracy: 0.7025 - penalty: 1e-06\n",
            "hidden layer sizes: [189, 48, 87, 139, 185, 258, 287], total units: 1193\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8368335962295532 - val_accuracy: 0.7025 - penalty: 1e-06\n",
            "hidden layer sizes: [226, 68, 107, 166, 222, 309, 344], total units: 1442\n",
            "Before pruning:\n",
            "loss: 0.9240742921829224 - accuracy: 0.67162 - val_loss: 0.8032433390617371 - val_accuracy: 0.7169 - penalty: 1e-06\n",
            "hidden layer sizes: [226, 68, 107, 166, 222, 309, 344], total units: 1442\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.803183376789093 - val_accuracy: 0.7171 - penalty: 1e-06\n",
            "hidden layer sizes: [186, 46, 76, 128, 185, 262, 267], total units: 1150\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.803183376789093 - val_accuracy: 0.7171 - penalty: 1e-06\n",
            "hidden layer sizes: [186, 46, 76, 128, 185, 262, 267], total units: 1150\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.803183376789093 - val_accuracy: 0.7171 - penalty: 1e-06\n",
            "hidden layer sizes: [223, 66, 96, 153, 222, 314, 320], total units: 1394\n",
            "Before pruning:\n",
            "loss: 0.9034700989723206 - accuracy: 0.67804 - val_loss: 0.7776550650596619 - val_accuracy: 0.7242 - penalty: 1e-06\n",
            "hidden layer sizes: [223, 66, 96, 153, 222, 314, 320], total units: 1394\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7774673104286194 - val_accuracy: 0.7244 - penalty: 1e-06\n",
            "hidden layer sizes: [180, 42, 75, 118, 185, 264, 278], total units: 1142\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7774673104286194 - val_accuracy: 0.7244 - penalty: 1e-06\n",
            "hidden layer sizes: [180, 42, 75, 118, 185, 264, 278], total units: 1142\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7774673104286194 - val_accuracy: 0.7244 - penalty: 1e-06\n",
            "hidden layer sizes: [216, 62, 95, 141, 222, 316, 333], total units: 1385\n",
            "Before pruning:\n",
            "loss: 0.8772387504577637 - accuracy: 0.68804 - val_loss: 0.7489398717880249 - val_accuracy: 0.7386 - penalty: 1e-06\n",
            "hidden layer sizes: [216, 62, 95, 141, 222, 316, 333], total units: 1385\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7489501237869263 - val_accuracy: 0.7387 - penalty: 1e-06\n",
            "hidden layer sizes: [177, 41, 70, 118, 182, 259, 282], total units: 1129\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7489501237869263 - val_accuracy: 0.7387 - penalty: 1e-06\n",
            "hidden layer sizes: [177, 41, 70, 118, 182, 259, 282], total units: 1129\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7489501237869263 - val_accuracy: 0.7387 - penalty: 1e-06\n",
            "hidden layer sizes: [212, 61, 90, 141, 218, 310, 338], total units: 1370\n",
            "Before pruning:\n",
            "loss: 0.8636115789413452 - accuracy: 0.6946 - val_loss: 0.7495485544204712 - val_accuracy: 0.7355 - penalty: 1e-06\n",
            "hidden layer sizes: [212, 61, 90, 141, 218, 310, 338], total units: 1370\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.749462366104126 - val_accuracy: 0.7358 - penalty: 1e-06\n",
            "hidden layer sizes: [174, 41, 63, 114, 180, 257, 267], total units: 1096\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.749462366104126 - val_accuracy: 0.7358 - penalty: 1e-06\n",
            "hidden layer sizes: [174, 41, 63, 114, 180, 257, 267], total units: 1096\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.749462366104126 - val_accuracy: 0.7358 - penalty: 1e-06\n",
            "hidden layer sizes: [208, 61, 83, 136, 216, 308, 320], total units: 1332\n",
            "Before pruning:\n",
            "loss: 0.8472725749015808 - accuracy: 0.69908 - val_loss: 0.7357000112533569 - val_accuracy: 0.7389 - penalty: 1e-06\n",
            "hidden layer sizes: [208, 61, 83, 136, 216, 308, 320], total units: 1332\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7356984615325928 - val_accuracy: 0.7389 - penalty: 1e-06\n",
            "hidden layer sizes: [168, 38, 61, 110, 179, 260, 272], total units: 1088\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7356984615325928 - val_accuracy: 0.7389 - penalty: 1e-06\n",
            "hidden layer sizes: [168, 38, 61, 110, 179, 260, 272], total units: 1088\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7356985211372375 - val_accuracy: 0.7389 - penalty: 1e-06\n",
            "hidden layer sizes: [201, 58, 81, 132, 214, 312, 326], total units: 1324\n",
            "Before pruning:\n",
            "loss: 0.8326897025108337 - accuracy: 0.70398 - val_loss: 0.7290319204330444 - val_accuracy: 0.7409 - penalty: 1e-06\n",
            "hidden layer sizes: [201, 58, 81, 132, 214, 312, 326], total units: 1324\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7290802001953125 - val_accuracy: 0.741 - penalty: 1e-06\n",
            "hidden layer sizes: [160, 35, 73, 111, 179, 260, 283], total units: 1101\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7290802001953125 - val_accuracy: 0.741 - penalty: 1e-06\n",
            "hidden layer sizes: [160, 35, 73, 111, 179, 260, 283], total units: 1101\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7290802001953125 - val_accuracy: 0.741 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 55, 93, 133, 214, 312, 339], total units: 1338\n",
            "Before pruning:\n",
            "loss: 0.8206173181533813 - accuracy: 0.7088 - val_loss: 0.7184113264083862 - val_accuracy: 0.7458 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 55, 93, 133, 214, 312, 339], total units: 1338\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7183603644371033 - val_accuracy: 0.746 - penalty: 1e-06\n",
            "hidden layer sizes: [150, 35, 60, 110, 177, 260, 286], total units: 1078\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7183603644371033 - val_accuracy: 0.746 - penalty: 1e-06\n",
            "hidden layer sizes: [150, 35, 60, 110, 177, 260, 286], total units: 1078\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7183603644371033 - val_accuracy: 0.746 - penalty: 1e-06\n",
            "hidden layer sizes: [180, 55, 80, 132, 212, 312, 343], total units: 1314\n",
            "Before pruning:\n",
            "loss: 0.8056330680847168 - accuracy: 0.71256 - val_loss: 0.7085071206092834 - val_accuracy: 0.7483 - penalty: 1e-06\n",
            "hidden layer sizes: [180, 55, 80, 132, 212, 312, 343], total units: 1314\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7085568308830261 - val_accuracy: 0.7484 - penalty: 1e-06\n",
            "hidden layer sizes: [146, 36, 60, 108, 176, 256, 273], total units: 1055\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7085568308830261 - val_accuracy: 0.7484 - penalty: 1e-06\n",
            "hidden layer sizes: [146, 36, 60, 108, 176, 256, 273], total units: 1055\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7085567116737366 - val_accuracy: 0.7484 - penalty: 1e-06\n",
            "hidden layer sizes: [175, 56, 80, 129, 211, 307, 327], total units: 1285\n",
            "Before pruning:\n",
            "loss: 0.8015623688697815 - accuracy: 0.71304 - val_loss: 0.6991947293281555 - val_accuracy: 0.7521 - penalty: 1e-06\n",
            "hidden layer sizes: [175, 56, 80, 129, 211, 307, 327], total units: 1285\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.6991751194000244 - val_accuracy: 0.7523 - penalty: 1e-06\n",
            "hidden layer sizes: [141, 33, 58, 110, 174, 259, 279], total units: 1054\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.34114,\n",
              "  0.42356,\n",
              "  0.49296,\n",
              "  0.52344,\n",
              "  0.56212,\n",
              "  0.58804,\n",
              "  0.6061,\n",
              "  0.62636,\n",
              "  0.63776,\n",
              "  0.65238,\n",
              "  0.66166,\n",
              "  0.67162,\n",
              "  0.67804,\n",
              "  0.68804,\n",
              "  0.6946,\n",
              "  0.69908,\n",
              "  0.70398,\n",
              "  0.7088,\n",
              "  0.71256,\n",
              "  0.71304],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=2.0089962>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.6122588>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.409426>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3170058>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2247231>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1484946>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0888671>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0441266>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0132141>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9716943>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.94812405>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9240743>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9034701>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.87723875>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8636116>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8472726>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8326897>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8206173>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.80563307>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.80156237>],\n",
              " 'val_accuracy': [0.4687,\n",
              "  0.5246,\n",
              "  0.5684,\n",
              "  0.5884,\n",
              "  0.6187,\n",
              "  0.6429,\n",
              "  0.6588,\n",
              "  0.6747,\n",
              "  0.6921,\n",
              "  0.7027,\n",
              "  0.7025,\n",
              "  0.7171,\n",
              "  0.7244,\n",
              "  0.7387,\n",
              "  0.7358,\n",
              "  0.7389,\n",
              "  0.741,\n",
              "  0.746,\n",
              "  0.7484,\n",
              "  0.7523],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.4994171>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3126733>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1963536>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1368312>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0698719>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.99982053>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9617175>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.90983427>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8689794>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.83365566>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8368337>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8031834>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7774673>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7489501>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.74946237>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.73569846>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7290802>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.71836036>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.70855683>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6991751>]}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSZZ2dUyZHCS"
      },
      "source": [
        "epochs = 15\n",
        "self_scaling_epochs = 5\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIQQanw_ZJWc",
        "outputId": "2064462c-4dbe-45a8-833d-1c841bc26e36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/15\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.6991751194000244 - val_accuracy: 0.7523 - penalty: 1e-06\n",
            "hidden layer sizes: [141, 33, 58, 110, 174, 259, 279], total units: 1054\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.699175238609314 - val_accuracy: 0.7523 - penalty: 1e-06\n",
            "hidden layer sizes: [169, 53, 78, 132, 208, 310, 334], total units: 1284\n",
            "Before pruning:\n",
            "loss: 0.7891672849655151 - accuracy: 0.72078 - val_loss: 0.6832705736160278 - val_accuracy: 0.7585 - penalty: 1e-06\n",
            "hidden layer sizes: [169, 53, 78, 132, 208, 310, 334], total units: 1284\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.6832776069641113 - val_accuracy: 0.7585 - penalty: 1e-06\n",
            "hidden layer sizes: [137, 33, 59, 104, 172, 259, 277], total units: 1041\n",
            "##########################################################\n",
            "Epoch 2/15\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.6832776069641113 - val_accuracy: 0.7585 - penalty: 1e-06\n",
            "hidden layer sizes: [137, 33, 59, 104, 172, 259, 277], total units: 1041\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.6832776069641113 - val_accuracy: 0.7585 - penalty: 1e-06\n",
            "hidden layer sizes: [164, 53, 79, 124, 206, 310, 332], total units: 1268\n",
            "Before pruning:\n",
            "loss: 0.7766771912574768 - accuracy: 0.7243 - val_loss: 0.6783956289291382 - val_accuracy: 0.7604 - penalty: 1e-06\n",
            "hidden layer sizes: [164, 53, 79, 124, 206, 310, 332], total units: 1268\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.6784159541130066 - val_accuracy: 0.7605 - penalty: 1e-06\n",
            "hidden layer sizes: [132, 40, 62, 106, 170, 264, 281], total units: 1055\n",
            "##########################################################\n",
            "Epoch 3/15\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.6784159541130066 - val_accuracy: 0.7605 - penalty: 1e-06\n",
            "hidden layer sizes: [132, 40, 62, 106, 170, 264, 281], total units: 1055\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.6784160733222961 - val_accuracy: 0.7605 - penalty: 1e-06\n",
            "hidden layer sizes: [158, 60, 82, 127, 204, 316, 337], total units: 1284\n",
            "Before pruning:\n",
            "loss: 0.7725674510002136 - accuracy: 0.72684 - val_loss: 0.6934359669685364 - val_accuracy: 0.7559 - penalty: 1e-06\n",
            "hidden layer sizes: [158, 60, 82, 127, 204, 316, 337], total units: 1284\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.6933403015136719 - val_accuracy: 0.7562 - penalty: 1e-06\n",
            "hidden layer sizes: [129, 30, 56, 103, 168, 257, 271], total units: 1014\n",
            "##########################################################\n",
            "Epoch 4/15\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.6933403015136719 - val_accuracy: 0.7562 - penalty: 1e-06\n",
            "hidden layer sizes: [129, 30, 56, 103, 168, 257, 271], total units: 1014\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.6933403015136719 - val_accuracy: 0.7562 - penalty: 1e-06\n",
            "hidden layer sizes: [154, 50, 76, 123, 201, 308, 325], total units: 1237\n",
            "Before pruning:\n",
            "loss: 0.7668255567550659 - accuracy: 0.72658 - val_loss: 0.6771217584609985 - val_accuracy: 0.7637 - penalty: 1e-06\n",
            "hidden layer sizes: [154, 50, 76, 123, 201, 308, 325], total units: 1237\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.6770637035369873 - val_accuracy: 0.7636 - penalty: 1e-06\n",
            "hidden layer sizes: [124, 32, 57, 113, 164, 257, 295], total units: 1042\n",
            "##########################################################\n",
            "Epoch 5/15\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.6770637035369873 - val_accuracy: 0.7636 - penalty: 1e-06\n",
            "hidden layer sizes: [124, 32, 57, 113, 164, 257, 295], total units: 1042\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.6770636439323425 - val_accuracy: 0.7636 - penalty: 1e-06\n",
            "hidden layer sizes: [148, 52, 77, 135, 196, 308, 354], total units: 1270\n",
            "Before pruning:\n",
            "loss: 0.759740948677063 - accuracy: 0.73046 - val_loss: 0.677257239818573 - val_accuracy: 0.7621 - penalty: 1e-06\n",
            "hidden layer sizes: [148, 52, 77, 135, 196, 308, 354], total units: 1270\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.6771854758262634 - val_accuracy: 0.7621 - penalty: 1e-06\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n",
            "##########################################################\n",
            "Epoch 6/15\n",
            "loss: 0.7706327438354492 - accuracy: 0.72782 - val_loss: 0.6531803011894226 - val_accuracy: 0.7702 - penalty: 0.0\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n",
            "##########################################################\n",
            "Epoch 7/15\n",
            "loss: 0.6665133833885193 - accuracy: 0.76208 - val_loss: 0.6348080039024353 - val_accuracy: 0.7746 - penalty: 0.0\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n",
            "##########################################################\n",
            "Epoch 8/15\n",
            "loss: 0.6215977668762207 - accuracy: 0.77934 - val_loss: 0.6211541295051575 - val_accuracy: 0.7833 - penalty: 0.0\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n",
            "##########################################################\n",
            "Epoch 9/15\n",
            "loss: 0.5899196267127991 - accuracy: 0.78992 - val_loss: 0.6109042763710022 - val_accuracy: 0.787 - penalty: 0.0\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n",
            "##########################################################\n",
            "Epoch 10/15\n",
            "loss: 0.5648033022880554 - accuracy: 0.79692 - val_loss: 0.6114565134048462 - val_accuracy: 0.785 - penalty: 0.0\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n",
            "##########################################################\n",
            "Epoch 11/15\n",
            "loss: 0.5411083102226257 - accuracy: 0.80594 - val_loss: 0.6017608046531677 - val_accuracy: 0.7917 - penalty: 0.0\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n",
            "##########################################################\n",
            "Epoch 12/15\n",
            "loss: 0.5241559147834778 - accuracy: 0.81288 - val_loss: 0.5970019102096558 - val_accuracy: 0.7926 - penalty: 0.0\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n",
            "##########################################################\n",
            "Epoch 13/15\n",
            "loss: 0.5056828260421753 - accuracy: 0.81928 - val_loss: 0.5944268107414246 - val_accuracy: 0.7944 - penalty: 0.0\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n",
            "##########################################################\n",
            "Epoch 14/15\n",
            "loss: 0.4884328842163086 - accuracy: 0.82528 - val_loss: 0.592613935470581 - val_accuracy: 0.7971 - penalty: 0.0\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n",
            "##########################################################\n",
            "Epoch 15/15\n",
            "loss: 0.4726400077342987 - accuracy: 0.82962 - val_loss: 0.5901088118553162 - val_accuracy: 0.7994 - penalty: 0.0\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.72078,\n",
              "  0.7243,\n",
              "  0.72684,\n",
              "  0.72658,\n",
              "  0.73046,\n",
              "  0.72782,\n",
              "  0.76208,\n",
              "  0.77934,\n",
              "  0.78992,\n",
              "  0.79692,\n",
              "  0.80594,\n",
              "  0.81288,\n",
              "  0.81928,\n",
              "  0.82528,\n",
              "  0.82962],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=0.7891673>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7766772>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.77256745>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.76682556>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.75974095>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.77063274>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6665134>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.62159777>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5899196>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5648033>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5411083>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5241559>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5056828>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.48843288>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.47264>],\n",
              " 'val_accuracy': [0.7585,\n",
              "  0.7605,\n",
              "  0.7562,\n",
              "  0.7636,\n",
              "  0.7621,\n",
              "  0.7702,\n",
              "  0.7746,\n",
              "  0.7833,\n",
              "  0.787,\n",
              "  0.785,\n",
              "  0.7917,\n",
              "  0.7926,\n",
              "  0.7944,\n",
              "  0.7971,\n",
              "  0.7994],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=0.6832776>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.67841595>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6933403>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6770637>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6771855>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6531803>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.634808>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6211541>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6109043>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6114565>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6017608>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5970019>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5944268>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.59261394>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5901088>]}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "If4nQnREaAFT"
      },
      "source": [
        "epochs = 5\n",
        "self_scaling_epochs = 0\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avuOu4GtaEdy",
        "outputId": "844805d4-588a-489e-efbf-77c0bd302893",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/5\n",
            "loss: 0.4571080803871155 - accuracy: 0.8337 - val_loss: 0.5971691608428955 - val_accuracy: 0.7968 - penalty: 0.0\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n",
            "##########################################################\n",
            "Epoch 2/5\n",
            "loss: 0.44272705912590027 - accuracy: 0.83764 - val_loss: 0.5940378904342651 - val_accuracy: 0.7997 - penalty: 0.0\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n",
            "##########################################################\n",
            "Epoch 3/5\n",
            "loss: 0.4271366000175476 - accuracy: 0.84598 - val_loss: 0.5995334982872009 - val_accuracy: 0.7945 - penalty: 0.0\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n",
            "##########################################################\n",
            "Epoch 4/5\n",
            "loss: 0.4159424602985382 - accuracy: 0.84966 - val_loss: 0.5943306684494019 - val_accuracy: 0.798 - penalty: 0.0\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n",
            "##########################################################\n",
            "Epoch 5/5\n",
            "loss: 0.40201738476753235 - accuracy: 0.85598 - val_loss: 0.5975359082221985 - val_accuracy: 0.7967 - penalty: 0.0\n",
            "hidden layer sizes: [121, 31, 54, 112, 160, 258, 285], total units: 1021\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.8337, 0.83764, 0.84598, 0.84966, 0.85598],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=0.45710808>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.44272706>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.4271366>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.41594246>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.40201738>],\n",
              " 'val_accuracy': [0.7968, 0.7997, 0.7945, 0.798, 0.7967],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=0.59716916>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5940379>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5995335>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.59433067>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5975359>]}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xasW23EaV9M"
      },
      "source": [
        "epochs = 25\n",
        "self_scaling_epochs = 25\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQW7p9k4acEM",
        "outputId": "effcd6cb-9913-4fb7-e7eb-32c5c96a570e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential([\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0.000005, regularization_method='weighted_l1', \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Dense(256, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Dense(256, activation='selu', regularization_penalty=0.000001, \n",
        "            regularization_method='weighted_l1', kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None, fixed_size=True),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.79923677444458 - val_accuracy: 0.1137 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 192, 192, 256, 256, 256], total units: 1920\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.799236297607422 - val_accuracy: 0.1137 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 230, 307, 307, 307], total units: 2301\n",
            "Before pruning:\n",
            "loss: 2.1290526390075684 - accuracy: 0.29672 - val_loss: 1.5416100025177002 - val_accuracy: 0.4397 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 230, 307, 307, 307], total units: 2301\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.541624665260315 - val_accuracy: 0.4397 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 192, 192, 256, 256, 307], total units: 1971\n",
            "##########################################################\n",
            "Epoch 2/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.541624665260315 - val_accuracy: 0.4397 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 192, 192, 256, 256, 307], total units: 1971\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.541624665260315 - val_accuracy: 0.4397 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 230, 307, 307, 368], total units: 2362\n",
            "Before pruning:\n",
            "loss: 1.7051478624343872 - accuracy: 0.38644 - val_loss: 1.3967374563217163 - val_accuracy: 0.4933 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 230, 307, 307, 368], total units: 2362\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.3967136144638062 - val_accuracy: 0.4932 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 192, 192, 256, 256, 286], total units: 1950\n",
            "##########################################################\n",
            "Epoch 3/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.3967136144638062 - val_accuracy: 0.4932 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 192, 192, 256, 256, 286], total units: 1950\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.3967136144638062 - val_accuracy: 0.4932 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 230, 307, 307, 343], total units: 2337\n",
            "Before pruning:\n",
            "loss: 1.5092018842697144 - accuracy: 0.45368 - val_loss: 1.260297417640686 - val_accuracy: 0.5449 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 230, 307, 307, 343], total units: 2337\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.2603567838668823 - val_accuracy: 0.5448 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 192, 192, 256, 256, 256], total units: 1920\n",
            "##########################################################\n",
            "Epoch 4/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2603567838668823 - val_accuracy: 0.5448 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 192, 192, 192, 192, 192, 256, 256, 256], total units: 1920\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2603567838668823 - val_accuracy: 0.5448 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 230, 307, 307, 307], total units: 2301\n",
            "Before pruning:\n",
            "loss: 1.3749382495880127 - accuracy: 0.50138 - val_loss: 1.1972721815109253 - val_accuracy: 0.5648 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 230, 230, 230, 230, 230, 307, 307, 307], total units: 2301\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1960912942886353 - val_accuracy: 0.565 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 164, 157, 191, 192, 192, 256, 256, 257], total units: 1857\n",
            "##########################################################\n",
            "Epoch 5/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1960912942886353 - val_accuracy: 0.565 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 164, 157, 191, 192, 192, 256, 256, 257], total units: 1857\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1960911750793457 - val_accuracy: 0.565 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 196, 188, 229, 230, 230, 307, 307, 308], total units: 2225\n",
            "Before pruning:\n",
            "loss: 1.276135802268982 - accuracy: 0.53902 - val_loss: 1.089812994003296 - val_accuracy: 0.6017 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 196, 188, 229, 230, 230, 307, 307, 308], total units: 2225\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0896503925323486 - val_accuracy: 0.6018 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 107, 131, 186, 192, 192, 256, 256, 261], total units: 1773\n",
            "##########################################################\n",
            "Epoch 6/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0896503925323486 - val_accuracy: 0.6018 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 107, 131, 186, 192, 192, 256, 256, 261], total units: 1773\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0896501541137695 - val_accuracy: 0.6018 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 128, 157, 223, 230, 230, 307, 307, 313], total units: 2125\n",
            "Before pruning:\n",
            "loss: 1.1796029806137085 - accuracy: 0.57974 - val_loss: 1.0209232568740845 - val_accuracy: 0.6357 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 128, 157, 223, 230, 230, 307, 307, 313], total units: 2125\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0206140279769897 - val_accuracy: 0.6363 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 88, 116, 175, 184, 192, 256, 256, 258], total units: 1717\n",
            "##########################################################\n",
            "Epoch 7/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0206140279769897 - val_accuracy: 0.6363 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 88, 116, 175, 184, 192, 256, 256, 258], total units: 1717\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0206140279769897 - val_accuracy: 0.6363 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 108, 139, 210, 220, 230, 307, 307, 309], total units: 2060\n",
            "Before pruning:\n",
            "loss: 1.10708749294281 - accuracy: 0.60538 - val_loss: 0.9520258903503418 - val_accuracy: 0.6628 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 108, 139, 210, 220, 230, 307, 307, 309], total units: 2060\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9518150687217712 - val_accuracy: 0.6631 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 69, 105, 173, 166, 191, 256, 256, 256], total units: 1664\n",
            "##########################################################\n",
            "Epoch 8/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9518150687217712 - val_accuracy: 0.6631 - penalty: 1e-06\n",
            "hidden layer sizes: [192, 69, 105, 173, 166, 191, 256, 256, 256], total units: 1664\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9518150687217712 - val_accuracy: 0.6631 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 89, 126, 207, 199, 229, 307, 307, 307], total units: 2001\n",
            "Before pruning:\n",
            "loss: 1.0561540126800537 - accuracy: 0.6235 - val_loss: 0.9148663878440857 - val_accuracy: 0.6802 - penalty: 1e-06\n",
            "hidden layer sizes: [230, 89, 126, 207, 199, 229, 307, 307, 307], total units: 2001\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9148054718971252 - val_accuracy: 0.6802 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 69, 90, 164, 145, 191, 256, 256, 256], total units: 1618\n",
            "##########################################################\n",
            "Epoch 9/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9148054718971252 - val_accuracy: 0.6802 - penalty: 1e-06\n",
            "hidden layer sizes: [191, 69, 90, 164, 145, 191, 256, 256, 256], total units: 1618\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9148053526878357 - val_accuracy: 0.6802 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 89, 110, 196, 174, 229, 307, 307, 307], total units: 1948\n",
            "Before pruning:\n",
            "loss: 1.0170271396636963 - accuracy: 0.6395 - val_loss: 0.879567563533783 - val_accuracy: 0.6913 - penalty: 1e-06\n",
            "hidden layer sizes: [229, 89, 110, 196, 174, 229, 307, 307, 307], total units: 1948\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8795211911201477 - val_accuracy: 0.6912 - penalty: 1e-06\n",
            "hidden layer sizes: [189, 59, 86, 155, 130, 188, 256, 256, 257], total units: 1576\n",
            "##########################################################\n",
            "Epoch 10/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8795211911201477 - val_accuracy: 0.6912 - penalty: 1e-06\n",
            "hidden layer sizes: [189, 59, 86, 155, 130, 188, 256, 256, 257], total units: 1576\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8795211911201477 - val_accuracy: 0.6912 - penalty: 1e-06\n",
            "hidden layer sizes: [226, 79, 106, 186, 156, 225, 307, 307, 308], total units: 1900\n",
            "Before pruning:\n",
            "loss: 0.983442485332489 - accuracy: 0.65214 - val_loss: 0.8580209016799927 - val_accuracy: 0.6959 - penalty: 1e-06\n",
            "hidden layer sizes: [226, 79, 106, 186, 156, 225, 307, 307, 308], total units: 1900\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8579892516136169 - val_accuracy: 0.6958 - penalty: 1e-06\n",
            "hidden layer sizes: [187, 55, 78, 150, 125, 185, 256, 256, 273], total units: 1565\n",
            "##########################################################\n",
            "Epoch 11/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8579892516136169 - val_accuracy: 0.6958 - penalty: 1e-06\n",
            "hidden layer sizes: [187, 55, 78, 150, 125, 185, 256, 256, 273], total units: 1565\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8579890727996826 - val_accuracy: 0.6958 - penalty: 1e-06\n",
            "hidden layer sizes: [224, 75, 98, 180, 150, 222, 307, 307, 327], total units: 1890\n",
            "Before pruning:\n",
            "loss: 0.9523352384567261 - accuracy: 0.6635 - val_loss: 0.8428192138671875 - val_accuracy: 0.7033 - penalty: 1e-06\n",
            "hidden layer sizes: [224, 75, 98, 180, 150, 222, 307, 307, 327], total units: 1890\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8427272439002991 - val_accuracy: 0.703 - penalty: 1e-06\n",
            "hidden layer sizes: [178, 55, 74, 150, 119, 183, 256, 256, 268], total units: 1539\n",
            "##########################################################\n",
            "Epoch 12/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8427272439002991 - val_accuracy: 0.703 - penalty: 1e-06\n",
            "hidden layer sizes: [178, 55, 74, 150, 119, 183, 256, 256, 268], total units: 1539\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8427272439002991 - val_accuracy: 0.703 - penalty: 1e-06\n",
            "hidden layer sizes: [213, 75, 94, 180, 142, 219, 307, 307, 321], total units: 1858\n",
            "Before pruning:\n",
            "loss: 0.9347068667411804 - accuracy: 0.66914 - val_loss: 0.8179975748062134 - val_accuracy: 0.7125 - penalty: 1e-06\n",
            "hidden layer sizes: [213, 75, 94, 180, 142, 219, 307, 307, 321], total units: 1858\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8179476857185364 - val_accuracy: 0.7124 - penalty: 1e-06\n",
            "hidden layer sizes: [172, 52, 67, 145, 106, 174, 255, 255, 255], total units: 1481\n",
            "##########################################################\n",
            "Epoch 13/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8179476857185364 - val_accuracy: 0.7124 - penalty: 1e-06\n",
            "hidden layer sizes: [172, 52, 67, 145, 106, 174, 255, 255, 255], total units: 1481\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8179476857185364 - val_accuracy: 0.7124 - penalty: 1e-06\n",
            "hidden layer sizes: [206, 72, 87, 174, 127, 208, 306, 306, 306], total units: 1792\n",
            "Before pruning:\n",
            "loss: 0.9060376286506653 - accuracy: 0.68018 - val_loss: 0.8045517802238464 - val_accuracy: 0.715 - penalty: 1e-06\n",
            "hidden layer sizes: [206, 72, 87, 174, 127, 208, 306, 306, 306], total units: 1792\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8044756054878235 - val_accuracy: 0.7149 - penalty: 1e-06\n",
            "hidden layer sizes: [166, 48, 67, 140, 100, 170, 248, 254, 257], total units: 1450\n",
            "##########################################################\n",
            "Epoch 14/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8044756054878235 - val_accuracy: 0.7149 - penalty: 1e-06\n",
            "hidden layer sizes: [166, 48, 67, 140, 100, 170, 248, 254, 257], total units: 1450\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8044756054878235 - val_accuracy: 0.7149 - penalty: 1e-06\n",
            "hidden layer sizes: [199, 68, 87, 168, 120, 204, 297, 304, 308], total units: 1755\n",
            "Before pruning:\n",
            "loss: 0.8920026421546936 - accuracy: 0.68618 - val_loss: 0.8184489607810974 - val_accuracy: 0.7113 - penalty: 1e-06\n",
            "hidden layer sizes: [199, 68, 87, 168, 120, 204, 297, 304, 308], total units: 1755\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8182895183563232 - val_accuracy: 0.7113 - penalty: 1e-06\n",
            "hidden layer sizes: [163, 45, 62, 139, 91, 169, 235, 252, 254], total units: 1410\n",
            "##########################################################\n",
            "Epoch 15/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8182895183563232 - val_accuracy: 0.7113 - penalty: 1e-06\n",
            "hidden layer sizes: [163, 45, 62, 139, 91, 169, 235, 252, 254], total units: 1410\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8182895183563232 - val_accuracy: 0.7113 - penalty: 1e-06\n",
            "hidden layer sizes: [195, 65, 82, 166, 111, 202, 282, 302, 304], total units: 1709\n",
            "Before pruning:\n",
            "loss: 0.8783363103866577 - accuracy: 0.69182 - val_loss: 0.7755981087684631 - val_accuracy: 0.726 - penalty: 1e-06\n",
            "hidden layer sizes: [195, 65, 82, 166, 111, 202, 282, 302, 304], total units: 1709\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7755541801452637 - val_accuracy: 0.7263 - penalty: 1e-06\n",
            "hidden layer sizes: [156, 44, 57, 139, 84, 161, 225, 245, 253], total units: 1364\n",
            "##########################################################\n",
            "Epoch 16/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7755541801452637 - val_accuracy: 0.7263 - penalty: 1e-06\n",
            "hidden layer sizes: [156, 44, 57, 139, 84, 161, 225, 245, 253], total units: 1364\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7755542993545532 - val_accuracy: 0.7263 - penalty: 1e-06\n",
            "hidden layer sizes: [187, 64, 77, 166, 104, 193, 270, 294, 303], total units: 1658\n",
            "Before pruning:\n",
            "loss: 0.8595612645149231 - accuracy: 0.69772 - val_loss: 0.7878279685974121 - val_accuracy: 0.7189 - penalty: 1e-06\n",
            "hidden layer sizes: [187, 64, 77, 166, 104, 193, 270, 294, 303], total units: 1658\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7878957986831665 - val_accuracy: 0.7189 - penalty: 1e-06\n",
            "hidden layer sizes: [150, 43, 57, 136, 88, 158, 215, 241, 258], total units: 1346\n",
            "##########################################################\n",
            "Epoch 17/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7878957986831665 - val_accuracy: 0.7189 - penalty: 1e-06\n",
            "hidden layer sizes: [150, 43, 57, 136, 88, 158, 215, 241, 258], total units: 1346\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7878957986831665 - val_accuracy: 0.7189 - penalty: 1e-06\n",
            "hidden layer sizes: [180, 63, 77, 163, 108, 189, 258, 289, 309], total units: 1636\n",
            "Before pruning:\n",
            "loss: 0.8419432044029236 - accuracy: 0.70522 - val_loss: 0.7699435949325562 - val_accuracy: 0.728 - penalty: 1e-06\n",
            "hidden layer sizes: [180, 63, 77, 163, 108, 189, 258, 289, 309], total units: 1636\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7699012160301208 - val_accuracy: 0.7284 - penalty: 1e-06\n",
            "hidden layer sizes: [151, 44, 54, 138, 93, 153, 205, 235, 275], total units: 1348\n",
            "##########################################################\n",
            "Epoch 18/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7699012160301208 - val_accuracy: 0.7284 - penalty: 1e-06\n",
            "hidden layer sizes: [151, 44, 54, 138, 93, 153, 205, 235, 275], total units: 1348\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7699012160301208 - val_accuracy: 0.7284 - penalty: 1e-06\n",
            "hidden layer sizes: [181, 64, 74, 165, 113, 183, 246, 282, 330], total units: 1638\n",
            "Before pruning:\n",
            "loss: 0.8274267911911011 - accuracy: 0.71006 - val_loss: 0.7582378387451172 - val_accuracy: 0.7332 - penalty: 1e-06\n",
            "hidden layer sizes: [181, 64, 74, 165, 113, 183, 246, 282, 330], total units: 1638\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7580767869949341 - val_accuracy: 0.7331 - penalty: 1e-06\n",
            "hidden layer sizes: [147, 43, 54, 136, 83, 150, 189, 228, 254], total units: 1284\n",
            "##########################################################\n",
            "Epoch 19/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7580767869949341 - val_accuracy: 0.7331 - penalty: 1e-06\n",
            "hidden layer sizes: [147, 43, 54, 136, 83, 150, 189, 228, 254], total units: 1284\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7580766677856445 - val_accuracy: 0.7331 - penalty: 1e-06\n",
            "hidden layer sizes: [176, 63, 74, 163, 103, 180, 226, 273, 304], total units: 1562\n",
            "Before pruning:\n",
            "loss: 0.8212050199508667 - accuracy: 0.71036 - val_loss: 0.7405781745910645 - val_accuracy: 0.7369 - penalty: 1e-06\n",
            "hidden layer sizes: [176, 63, 74, 163, 103, 180, 226, 273, 304], total units: 1562\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.740613579750061 - val_accuracy: 0.7367 - penalty: 1e-06\n",
            "hidden layer sizes: [143, 41, 57, 133, 78, 147, 180, 221, 250], total units: 1250\n",
            "##########################################################\n",
            "Epoch 20/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.740613579750061 - val_accuracy: 0.7367 - penalty: 1e-06\n",
            "hidden layer sizes: [143, 41, 57, 133, 78, 147, 180, 221, 250], total units: 1250\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.740613579750061 - val_accuracy: 0.7367 - penalty: 1e-06\n",
            "hidden layer sizes: [171, 61, 77, 159, 98, 176, 216, 265, 300], total units: 1523\n",
            "Before pruning:\n",
            "loss: 0.8128229975700378 - accuracy: 0.71452 - val_loss: 0.736884355545044 - val_accuracy: 0.7407 - penalty: 1e-06\n",
            "hidden layer sizes: [171, 61, 77, 159, 98, 176, 216, 265, 300], total units: 1523\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7368226647377014 - val_accuracy: 0.7409 - penalty: 1e-06\n",
            "hidden layer sizes: [140, 38, 54, 132, 82, 146, 174, 218, 219], total units: 1203\n",
            "##########################################################\n",
            "Epoch 21/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7368226647377014 - val_accuracy: 0.7409 - penalty: 1e-06\n",
            "hidden layer sizes: [140, 38, 54, 132, 82, 146, 174, 218, 219], total units: 1203\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7368226647377014 - val_accuracy: 0.7409 - penalty: 1e-06\n",
            "hidden layer sizes: [168, 58, 74, 158, 102, 175, 208, 261, 262], total units: 1466\n",
            "Before pruning:\n",
            "loss: 0.7998989224433899 - accuracy: 0.7186 - val_loss: 0.7281237840652466 - val_accuracy: 0.7442 - penalty: 1e-06\n",
            "hidden layer sizes: [168, 58, 74, 158, 102, 175, 208, 261, 262], total units: 1466\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7280671000480652 - val_accuracy: 0.7443 - penalty: 1e-06\n",
            "hidden layer sizes: [136, 38, 54, 129, 84, 142, 163, 209, 218], total units: 1173\n",
            "##########################################################\n",
            "Epoch 22/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7280671000480652 - val_accuracy: 0.7443 - penalty: 1e-06\n",
            "hidden layer sizes: [136, 38, 54, 129, 84, 142, 163, 209, 218], total units: 1173\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.72806715965271 - val_accuracy: 0.7443 - penalty: 1e-06\n",
            "hidden layer sizes: [163, 58, 74, 154, 104, 170, 195, 250, 261], total units: 1429\n",
            "Before pruning:\n",
            "loss: 0.7958008646965027 - accuracy: 0.72298 - val_loss: 0.7224709987640381 - val_accuracy: 0.75 - penalty: 1e-06\n",
            "hidden layer sizes: [163, 58, 74, 154, 104, 170, 195, 250, 261], total units: 1429\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7224716544151306 - val_accuracy: 0.7501 - penalty: 1e-06\n",
            "hidden layer sizes: [137, 42, 49, 136, 85, 142, 157, 203, 202], total units: 1153\n",
            "##########################################################\n",
            "Epoch 23/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7224716544151306 - val_accuracy: 0.7501 - penalty: 1e-06\n",
            "hidden layer sizes: [137, 42, 49, 136, 85, 142, 157, 203, 202], total units: 1153\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7224716544151306 - val_accuracy: 0.7501 - penalty: 1e-06\n",
            "hidden layer sizes: [164, 62, 69, 163, 105, 170, 188, 243, 242], total units: 1406\n",
            "Before pruning:\n",
            "loss: 0.7834238409996033 - accuracy: 0.72524 - val_loss: 0.7227911949157715 - val_accuracy: 0.7468 - penalty: 1e-06\n",
            "hidden layer sizes: [164, 62, 69, 163, 105, 170, 188, 243, 242], total units: 1406\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7227593064308167 - val_accuracy: 0.7469 - penalty: 1e-06\n",
            "hidden layer sizes: [131, 39, 50, 133, 81, 139, 156, 193, 229], total units: 1151\n",
            "##########################################################\n",
            "Epoch 24/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7227593064308167 - val_accuracy: 0.7469 - penalty: 1e-06\n",
            "hidden layer sizes: [131, 39, 50, 133, 81, 139, 156, 193, 229], total units: 1151\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7227591872215271 - val_accuracy: 0.7469 - penalty: 1e-06\n",
            "hidden layer sizes: [157, 59, 70, 159, 101, 166, 187, 231, 274], total units: 1404\n",
            "Before pruning:\n",
            "loss: 0.782342791557312 - accuracy: 0.7285 - val_loss: 0.7364693880081177 - val_accuracy: 0.7409 - penalty: 1e-06\n",
            "hidden layer sizes: [157, 59, 70, 159, 101, 166, 187, 231, 274], total units: 1404\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7363388538360596 - val_accuracy: 0.7409 - penalty: 1e-06\n",
            "hidden layer sizes: [126, 43, 48, 132, 78, 135, 153, 186, 210], total units: 1111\n",
            "##########################################################\n",
            "Epoch 25/25\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7363388538360596 - val_accuracy: 0.7409 - penalty: 1e-06\n",
            "hidden layer sizes: [126, 43, 48, 132, 78, 135, 153, 186, 210], total units: 1111\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.7363388538360596 - val_accuracy: 0.7409 - penalty: 1e-06\n",
            "hidden layer sizes: [151, 63, 68, 158, 98, 162, 183, 223, 252], total units: 1358\n",
            "Before pruning:\n",
            "loss: 0.7712135910987854 - accuracy: 0.7303 - val_loss: 0.7229657769203186 - val_accuracy: 0.7482 - penalty: 1e-06\n",
            "hidden layer sizes: [151, 63, 68, 158, 98, 162, 183, 223, 252], total units: 1358\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.7230144739151001 - val_accuracy: 0.7481 - penalty: 1e-06\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.29672,\n",
              "  0.38644,\n",
              "  0.45368,\n",
              "  0.50138,\n",
              "  0.53902,\n",
              "  0.57974,\n",
              "  0.60538,\n",
              "  0.6235,\n",
              "  0.6395,\n",
              "  0.65214,\n",
              "  0.6635,\n",
              "  0.66914,\n",
              "  0.68018,\n",
              "  0.68618,\n",
              "  0.69182,\n",
              "  0.69772,\n",
              "  0.70522,\n",
              "  0.71006,\n",
              "  0.71036,\n",
              "  0.71452,\n",
              "  0.7186,\n",
              "  0.72298,\n",
              "  0.72524,\n",
              "  0.7285,\n",
              "  0.7303],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=2.1290526>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.7051479>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.5092019>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3749382>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2761358>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.179603>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1070875>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.056154>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0170271>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9834425>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.95233524>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.93470687>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9060376>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.89200264>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8783363>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.85956126>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8419432>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8274268>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.821205>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.812823>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7998989>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.79580086>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.78342384>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7823428>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7712136>],\n",
              " 'val_accuracy': [0.4397,\n",
              "  0.4932,\n",
              "  0.5448,\n",
              "  0.565,\n",
              "  0.6018,\n",
              "  0.6363,\n",
              "  0.6631,\n",
              "  0.6802,\n",
              "  0.6912,\n",
              "  0.6958,\n",
              "  0.703,\n",
              "  0.7124,\n",
              "  0.7149,\n",
              "  0.7113,\n",
              "  0.7263,\n",
              "  0.7189,\n",
              "  0.7284,\n",
              "  0.7331,\n",
              "  0.7367,\n",
              "  0.7409,\n",
              "  0.7443,\n",
              "  0.7501,\n",
              "  0.7469,\n",
              "  0.7409,\n",
              "  0.7481],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.5416247>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3967136>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2603568>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1960913>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0896504>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.020614>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.95181507>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9148055>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8795212>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.85798925>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.84272724>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8179477>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8044756>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8182895>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7755542>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7878958>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7699012>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7580768>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7406136>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.73682266>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7280671>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.72247165>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7227593>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.73633885>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7230145>]}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVkEe121cwF-"
      },
      "source": [
        "epochs = 15\n",
        "self_scaling_epochs = 0\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXSU9LIvc0u4",
        "outputId": "7df21407-e1df-43c6-cfeb-5ca06a0dc2e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/15\n",
            "loss: 0.7808060646057129 - accuracy: 0.72632 - val_loss: 0.7153555750846863 - val_accuracy: 0.7517 - penalty: 0.0\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n",
            "##########################################################\n",
            "Epoch 2/15\n",
            "loss: 0.6949461102485657 - accuracy: 0.75636 - val_loss: 0.6902822256088257 - val_accuracy: 0.7567 - penalty: 0.0\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n",
            "##########################################################\n",
            "Epoch 3/15\n",
            "loss: 0.6561957597732544 - accuracy: 0.7704 - val_loss: 0.6762971878051758 - val_accuracy: 0.7636 - penalty: 0.0\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n",
            "##########################################################\n",
            "Epoch 4/15\n",
            "loss: 0.63089519739151 - accuracy: 0.78064 - val_loss: 0.6755340695381165 - val_accuracy: 0.7644 - penalty: 0.0\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n",
            "##########################################################\n",
            "Epoch 5/15\n",
            "loss: 0.6106624007225037 - accuracy: 0.78576 - val_loss: 0.6762180924415588 - val_accuracy: 0.766 - penalty: 0.0\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n",
            "##########################################################\n",
            "Epoch 6/15\n",
            "loss: 0.5878487229347229 - accuracy: 0.79436 - val_loss: 0.676163911819458 - val_accuracy: 0.7659 - penalty: 0.0\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n",
            "##########################################################\n",
            "Epoch 7/15\n",
            "loss: 0.5761703252792358 - accuracy: 0.79672 - val_loss: 0.6725249290466309 - val_accuracy: 0.7706 - penalty: 0.0\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n",
            "##########################################################\n",
            "Epoch 8/15\n",
            "loss: 0.5563377141952515 - accuracy: 0.80472 - val_loss: 0.6783761978149414 - val_accuracy: 0.7677 - penalty: 0.0\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n",
            "##########################################################\n",
            "Epoch 9/15\n",
            "loss: 0.5414478182792664 - accuracy: 0.81134 - val_loss: 0.6776442527770996 - val_accuracy: 0.7716 - penalty: 0.0\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n",
            "##########################################################\n",
            "Epoch 10/15\n",
            "loss: 0.532252311706543 - accuracy: 0.8133 - val_loss: 0.6709115505218506 - val_accuracy: 0.7726 - penalty: 0.0\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n",
            "##########################################################\n",
            "Epoch 11/15\n",
            "loss: 0.5087337493896484 - accuracy: 0.82136 - val_loss: 0.6741521954536438 - val_accuracy: 0.7707 - penalty: 0.0\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n",
            "##########################################################\n",
            "Epoch 12/15\n",
            "loss: 0.49994316697120667 - accuracy: 0.82398 - val_loss: 0.6821077466011047 - val_accuracy: 0.7748 - penalty: 0.0\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n",
            "##########################################################\n",
            "Epoch 13/15\n",
            "loss: 0.4876604378223419 - accuracy: 0.82932 - val_loss: 0.6888116002082825 - val_accuracy: 0.7735 - penalty: 0.0\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n",
            "##########################################################\n",
            "Epoch 14/15\n",
            "loss: 0.47158288955688477 - accuracy: 0.83464 - val_loss: 0.6917790174484253 - val_accuracy: 0.7754 - penalty: 0.0\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n",
            "##########################################################\n",
            "Epoch 15/15\n",
            "loss: 0.463847279548645 - accuracy: 0.83678 - val_loss: 0.6907138228416443 - val_accuracy: 0.772 - penalty: 0.0\n",
            "hidden layer sizes: [124, 40, 49, 135, 84, 132, 146, 183, 211], total units: 1104\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.72632,\n",
              "  0.75636,\n",
              "  0.7704,\n",
              "  0.78064,\n",
              "  0.78576,\n",
              "  0.79436,\n",
              "  0.79672,\n",
              "  0.80472,\n",
              "  0.81134,\n",
              "  0.8133,\n",
              "  0.82136,\n",
              "  0.82398,\n",
              "  0.82932,\n",
              "  0.83464,\n",
              "  0.83678],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=0.78080606>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6949461>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.65619576>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6308952>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6106624>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5878487>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5761703>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5563377>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5414478>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5322523>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.50873375>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.49994317>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.48766044>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.4715829>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.46384728>],\n",
              " 'val_accuracy': [0.7517,\n",
              "  0.7567,\n",
              "  0.7636,\n",
              "  0.7644,\n",
              "  0.766,\n",
              "  0.7659,\n",
              "  0.7706,\n",
              "  0.7677,\n",
              "  0.7716,\n",
              "  0.7726,\n",
              "  0.7707,\n",
              "  0.7748,\n",
              "  0.7735,\n",
              "  0.7754,\n",
              "  0.772],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=0.7153556>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6902822>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6762972>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.67553407>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6762181>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6761639>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6725249>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6783762>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.67764425>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.67091155>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6741522>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.68210775>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6888116>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.691779>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6907138>]}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X6oS2sRduEP"
      },
      "source": [
        "epochs = 25\n",
        "self_scaling_epochs = 0\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnxI6oiedsNS",
        "outputId": "e3e5f7b0-52f3-4027-c84a-eeae60072c02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential([\n",
        "        Conv2D(96, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(96, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(192, filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=0., regularization_method=None, \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='selu', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Dense(256, activation='selu', regularization_penalty=0., \n",
        "            regularization_method=None, kernel_initializer='lecun_normal'),\n",
        "        Dense(10, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None, fixed_size=True),\n",
        "    ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/25\n",
            "loss: 1.984422206878662 - accuracy: 0.34968 - val_loss: 1.4874681234359741 - val_accuracy: 0.4664 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 2/25\n",
            "loss: 1.534834861755371 - accuracy: 0.45358 - val_loss: 1.3034113645553589 - val_accuracy: 0.5236 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 3/25\n",
            "loss: 1.3513355255126953 - accuracy: 0.52156 - val_loss: 1.10728919506073 - val_accuracy: 0.5984 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 4/25\n",
            "loss: 1.1799495220184326 - accuracy: 0.5813 - val_loss: 1.0366899967193604 - val_accuracy: 0.6298 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 5/25\n",
            "loss: 1.0552955865859985 - accuracy: 0.62838 - val_loss: 0.9161049723625183 - val_accuracy: 0.6693 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 6/25\n",
            "loss: 0.9564655423164368 - accuracy: 0.66144 - val_loss: 0.8756198287010193 - val_accuracy: 0.6871 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 7/25\n",
            "loss: 0.8740798234939575 - accuracy: 0.69012 - val_loss: 0.8169200420379639 - val_accuracy: 0.7109 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 8/25\n",
            "loss: 0.8163473606109619 - accuracy: 0.71342 - val_loss: 0.7992860078811646 - val_accuracy: 0.7194 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 9/25\n",
            "loss: 0.7709840536117554 - accuracy: 0.729 - val_loss: 0.7689354419708252 - val_accuracy: 0.7309 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 10/25\n",
            "loss: 0.7252802848815918 - accuracy: 0.744 - val_loss: 0.7766849398612976 - val_accuracy: 0.7329 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 11/25\n",
            "loss: 0.6835195422172546 - accuracy: 0.75938 - val_loss: 0.7348169684410095 - val_accuracy: 0.7478 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 12/25\n",
            "loss: 0.6466548442840576 - accuracy: 0.77064 - val_loss: 0.7242235541343689 - val_accuracy: 0.7508 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 13/25\n",
            "loss: 0.6158807277679443 - accuracy: 0.78186 - val_loss: 0.7233321070671082 - val_accuracy: 0.7547 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 14/25\n",
            "loss: 0.5950009822845459 - accuracy: 0.78912 - val_loss: 0.6880744695663452 - val_accuracy: 0.7695 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 15/25\n",
            "loss: 0.5661211013793945 - accuracy: 0.79944 - val_loss: 0.7262626886367798 - val_accuracy: 0.754 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 16/25\n",
            "loss: 0.5497869253158569 - accuracy: 0.80594 - val_loss: 0.7028892636299133 - val_accuracy: 0.7621 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 17/25\n",
            "loss: 0.5240117311477661 - accuracy: 0.81474 - val_loss: 0.6905677318572998 - val_accuracy: 0.7726 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 18/25\n",
            "loss: 0.4997371733188629 - accuracy: 0.8237 - val_loss: 0.6828029155731201 - val_accuracy: 0.7726 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 19/25\n",
            "loss: 0.4856204390525818 - accuracy: 0.8286 - val_loss: 0.7016571164131165 - val_accuracy: 0.7706 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 20/25\n",
            "loss: 0.4724864065647125 - accuracy: 0.8348 - val_loss: 0.6981359124183655 - val_accuracy: 0.7696 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 21/25\n",
            "loss: 0.4563153088092804 - accuracy: 0.8404 - val_loss: 0.6709876656532288 - val_accuracy: 0.7836 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 22/25\n",
            "loss: 0.43065422773361206 - accuracy: 0.8476 - val_loss: 0.6945541501045227 - val_accuracy: 0.7817 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 23/25\n",
            "loss: 0.43342363834381104 - accuracy: 0.84858 - val_loss: 0.6721226572990417 - val_accuracy: 0.7836 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 24/25\n",
            "loss: 0.4119667708873749 - accuracy: 0.85546 - val_loss: 0.7576307058334351 - val_accuracy: 0.7687 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 25/25\n",
            "loss: 0.4089799225330353 - accuracy: 0.85678 - val_loss: 0.6862537264823914 - val_accuracy: 0.7867 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.34968,\n",
              "  0.45358,\n",
              "  0.52156,\n",
              "  0.5813,\n",
              "  0.62838,\n",
              "  0.66144,\n",
              "  0.69012,\n",
              "  0.71342,\n",
              "  0.729,\n",
              "  0.744,\n",
              "  0.75938,\n",
              "  0.77064,\n",
              "  0.78186,\n",
              "  0.78912,\n",
              "  0.79944,\n",
              "  0.80594,\n",
              "  0.81474,\n",
              "  0.8237,\n",
              "  0.8286,\n",
              "  0.8348,\n",
              "  0.8404,\n",
              "  0.8476,\n",
              "  0.84858,\n",
              "  0.85546,\n",
              "  0.85678],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.9844222>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.5348349>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3513355>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1799495>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0552956>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.95646554>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8740798>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.81634736>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.77098405>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7252803>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.68351954>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.64665484>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6158807>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.595001>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5661211>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.5497869>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.52401173>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.49973717>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.48562044>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.4724864>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.4563153>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.43065423>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.43342364>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.41196677>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.40897992>],\n",
              " 'val_accuracy': [0.4664,\n",
              "  0.5236,\n",
              "  0.5984,\n",
              "  0.6298,\n",
              "  0.6693,\n",
              "  0.6871,\n",
              "  0.7109,\n",
              "  0.7194,\n",
              "  0.7309,\n",
              "  0.7329,\n",
              "  0.7478,\n",
              "  0.7508,\n",
              "  0.7547,\n",
              "  0.7695,\n",
              "  0.754,\n",
              "  0.7621,\n",
              "  0.7726,\n",
              "  0.7726,\n",
              "  0.7706,\n",
              "  0.7696,\n",
              "  0.7836,\n",
              "  0.7817,\n",
              "  0.7836,\n",
              "  0.7687,\n",
              "  0.7867],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=1.4874681>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3034114>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1072892>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.03669>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.916105>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8756198>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.81692004>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.799286>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.76893544>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.77668494>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.73481697>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.72422355>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7233321>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.68807447>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7262627>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.70288926>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.69056773>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6828029>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7016571>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6981359>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.67098767>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.69455415>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.67212266>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7576307>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6862537>]}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9b072cEgaoG"
      },
      "source": [
        "epochs = 5\n",
        "self_scaling_epochs = 0\n",
        "batch_size = 256\n",
        "min_new_neurons = 20"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNoZd5Jqgdph",
        "outputId": "7cd267a6-7815-4d23-bb42-c32f1ebfbec3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/5\n",
            "loss: 0.39268678426742554 - accuracy: 0.86314 - val_loss: 0.6829092502593994 - val_accuracy: 0.7872 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 2/5\n",
            "loss: 0.38751205801963806 - accuracy: 0.86366 - val_loss: 0.6914719343185425 - val_accuracy: 0.786 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 3/5\n",
            "loss: 0.37477293610572815 - accuracy: 0.86886 - val_loss: 0.6710387468338013 - val_accuracy: 0.7846 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 4/5\n",
            "loss: 0.3605235517024994 - accuracy: 0.87322 - val_loss: 0.7064102292060852 - val_accuracy: 0.7836 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 5/5\n",
            "loss: 0.35460370779037476 - accuracy: 0.87496 - val_loss: 0.7092626690864563 - val_accuracy: 0.7858 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.86314, 0.86366, 0.86886, 0.87322, 0.87496],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=0.39268678>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.38751206>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.37477294>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.36052355>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.3546037>],\n",
              " 'val_accuracy': [0.7872, 0.786, 0.7846, 0.7836, 0.7858],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=0.68290925>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.69147193>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.67103875>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7064102>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.70926267>]}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBhhkeEagsEl",
        "outputId": "0d6ff290-64b3-4d3c-a9cf-bd3bf4469105",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/5\n",
            "loss: 0.33835598826408386 - accuracy: 0.88252 - val_loss: 0.714992105960846 - val_accuracy: 0.7874 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 2/5\n",
            "loss: 0.330736368894577 - accuracy: 0.8855 - val_loss: 0.6770148277282715 - val_accuracy: 0.7953 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 3/5\n",
            "loss: 0.32952749729156494 - accuracy: 0.88678 - val_loss: 0.6777744889259338 - val_accuracy: 0.7953 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 4/5\n",
            "loss: 0.3210453391075134 - accuracy: 0.88998 - val_loss: 0.7147794961929321 - val_accuracy: 0.7926 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 5/5\n",
            "loss: 0.30810704827308655 - accuracy: 0.89438 - val_loss: 0.6910793781280518 - val_accuracy: 0.7971 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.88252, 0.8855, 0.88678, 0.88998, 0.89438],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=0.338356>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.33073637>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.3295275>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.32104534>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.30810705>],\n",
              " 'val_accuracy': [0.7874, 0.7953, 0.7953, 0.7926, 0.7971],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=0.7149921>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6770148>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6777745>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7147795>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.6910794>]}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwJy2dDwg5dE",
        "outputId": "35c48950-df4e-4e56-c0cb-b3564ff30e2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "          min_new_neurons, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/5\n",
            "loss: 0.30340513586997986 - accuracy: 0.8947 - val_loss: 0.7206469774246216 - val_accuracy: 0.7952 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 2/5\n",
            "loss: 0.2996048331260681 - accuracy: 0.89638 - val_loss: 0.7327336668968201 - val_accuracy: 0.7948 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 3/5\n",
            "loss: 0.2871343195438385 - accuracy: 0.90196 - val_loss: 0.7004775404930115 - val_accuracy: 0.7965 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 4/5\n",
            "loss: 0.2848021686077118 - accuracy: 0.90296 - val_loss: 0.7234101295471191 - val_accuracy: 0.7971 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n",
            "##########################################################\n",
            "Epoch 5/5\n",
            "loss: 0.2826383113861084 - accuracy: 0.90142 - val_loss: 0.7366238832473755 - val_accuracy: 0.7957 - penalty: 0.0\n",
            "hidden layer sizes: [96, 96, 192, 192, 192, 256, 256], total units: 1280\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.8947, 0.89638, 0.90196, 0.90296, 0.90142],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=0.30340514>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.29960483>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.28713432>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.28480217>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.2826383>],\n",
              " 'val_accuracy': [0.7952, 0.7948, 0.7965, 0.7971, 0.7957],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=0.720647>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.73273367>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.70047754>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7234101>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.7366239>]}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZT88_cT9yej"
      },
      "source": [
        "# Misc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWOQuGEVq6Gj"
      },
      "source": [
        "# Temto model je na Cifar10 jiz pomerne vyladeny\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(input_shape=X_train_norm[0,:,:,:].shape, filters=96, kernel_size=(3,3), activation='selu', kernel_initializer='lecun_normal'))\n",
        "model.add(tf.keras.layers.Conv2D(filters=96, kernel_size=(3,3), strides=2, activation='selu', kernel_initializer='lecun_normal'))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Conv2D(filters=192, kernel_size=(3,3), activation='selu', kernel_initializer='lecun_normal'))\n",
        "model.add(tf.keras.layers.Conv2D(filters=192, kernel_size=(3,3), strides=2, activation='selu', kernel_initializer='lecun_normal'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256, activation='selu', kernel_initializer='lecun_normal'))\n",
        "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDMBpQB1zkdk"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4l2I_etAZ4is",
        "outputId": "7ea71652-9e59-4a95-838d-fb4d06ccab0b"
      },
      "source": [
        "%%time\n",
        "\n",
        "model.fit(X_train_norm, y_train, epochs=25, batch_size=256, validation_data=(X_test_norm, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "196/196 [==============================] - 9s 46ms/step - loss: 2.0276 - accuracy: 0.3617 - val_loss: 1.4487 - val_accuracy: 0.4768\n",
            "Epoch 2/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 1.4076 - accuracy: 0.4938 - val_loss: 1.3187 - val_accuracy: 0.5150\n",
            "Epoch 3/25\n",
            "196/196 [==============================] - 9s 46ms/step - loss: 1.2646 - accuracy: 0.5483 - val_loss: 1.1942 - val_accuracy: 0.5702\n",
            "Epoch 4/25\n",
            "196/196 [==============================] - 9s 46ms/step - loss: 1.1380 - accuracy: 0.5945 - val_loss: 1.1212 - val_accuracy: 0.5984\n",
            "Epoch 5/25\n",
            "196/196 [==============================] - 9s 46ms/step - loss: 1.0255 - accuracy: 0.6347 - val_loss: 1.0245 - val_accuracy: 0.6363\n",
            "Epoch 6/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 0.9390 - accuracy: 0.6672 - val_loss: 0.9999 - val_accuracy: 0.6479\n",
            "Epoch 7/25\n",
            "196/196 [==============================] - 9s 44ms/step - loss: 0.8667 - accuracy: 0.6939 - val_loss: 0.9372 - val_accuracy: 0.6731\n",
            "Epoch 8/25\n",
            "196/196 [==============================] - 9s 44ms/step - loss: 0.7990 - accuracy: 0.7169 - val_loss: 0.9421 - val_accuracy: 0.6771\n",
            "Epoch 9/25\n",
            "196/196 [==============================] - 9s 44ms/step - loss: 0.7508 - accuracy: 0.7351 - val_loss: 0.9119 - val_accuracy: 0.6902\n",
            "Epoch 10/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 0.6957 - accuracy: 0.7550 - val_loss: 0.8888 - val_accuracy: 0.7011\n",
            "Epoch 11/25\n",
            "196/196 [==============================] - 9s 44ms/step - loss: 0.6530 - accuracy: 0.7692 - val_loss: 0.8857 - val_accuracy: 0.7033\n",
            "Epoch 12/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 0.6118 - accuracy: 0.7842 - val_loss: 0.8710 - val_accuracy: 0.7076\n",
            "Epoch 13/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 0.5877 - accuracy: 0.7917 - val_loss: 0.9078 - val_accuracy: 0.7080\n",
            "Epoch 14/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 0.5419 - accuracy: 0.8086 - val_loss: 0.8814 - val_accuracy: 0.7109\n",
            "Epoch 15/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 0.5262 - accuracy: 0.8135 - val_loss: 0.9352 - val_accuracy: 0.7146\n",
            "Epoch 16/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 0.4963 - accuracy: 0.8243 - val_loss: 0.9018 - val_accuracy: 0.7223\n",
            "Epoch 17/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 0.4799 - accuracy: 0.8313 - val_loss: 0.9216 - val_accuracy: 0.7140\n",
            "Epoch 18/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 0.4564 - accuracy: 0.8392 - val_loss: 0.9259 - val_accuracy: 0.7286\n",
            "Epoch 19/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 0.4373 - accuracy: 0.8470 - val_loss: 0.9008 - val_accuracy: 0.7209\n",
            "Epoch 20/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 0.4227 - accuracy: 0.8521 - val_loss: 0.9384 - val_accuracy: 0.7263\n",
            "Epoch 21/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 0.3927 - accuracy: 0.8639 - val_loss: 0.9229 - val_accuracy: 0.7233\n",
            "Epoch 22/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 0.3971 - accuracy: 0.8618 - val_loss: 0.9479 - val_accuracy: 0.7231\n",
            "Epoch 23/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 0.3730 - accuracy: 0.8714 - val_loss: 0.9526 - val_accuracy: 0.7309\n",
            "Epoch 24/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 0.3650 - accuracy: 0.8750 - val_loss: 0.9737 - val_accuracy: 0.7286\n",
            "Epoch 25/25\n",
            "196/196 [==============================] - 9s 46ms/step - loss: 0.3604 - accuracy: 0.8747 - val_loss: 1.0245 - val_accuracy: 0.7315\n",
            "CPU times: user 3min 3s, sys: 6.67 s, total: 3min 9s\n",
            "Wall time: 3min 42s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc8d011d890>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_BvNnozaO0-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}