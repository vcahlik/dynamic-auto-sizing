{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_multi_layer_ssnet_inverse.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_deAUKlniFk",
        "outputId": "d5b0fdb1-d178-4390-c9ba-2a454d84da1d"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jan  8 17:10:50 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKwUwV_NneIo"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOoXBq05neIt"
      },
      "source": [
        "dtype = 'float32'\n",
        "tf.keras.backend.set_floatx(dtype)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BrJPdkBneIv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7febad41-03da-46b8-e1fa-e58fb7332ce9"
      },
      "source": [
        "cifar10 = tf.keras.datasets.cifar10\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "X_train = X_train.astype(dtype) / 255.0\n",
        "y_train = y_train.astype(dtype)\n",
        "X_test = X_test.astype(dtype)  / 255.0\n",
        "y_test = y_test.astype(dtype)\n",
        "\n",
        "X_train = np.reshape(X_train, (-1, 3072))\n",
        "X_test = np.reshape(X_test, (-1, 3072))\n",
        "\n",
        "X = np.concatenate((X_train, X_test), axis=0)\n",
        "y = np.concatenate((y_train, y_test), axis=0)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n",
            "170508288/170498071 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5uTvu5kxF-b"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)  # Scaling each feature independently\n",
        "\n",
        "X_norm = scaler.transform(X)\n",
        "X_train_norm = scaler.transform(X_train)\n",
        "X_test_norm = scaler.transform(X_test)\n",
        "\n",
        "X_norm = np.reshape(X_norm, (-1, 32, 32, 3))\n",
        "X_train_norm = np.reshape(X_train_norm, (-1, 32, 32, 3))\n",
        "X_test_norm = np.reshape(X_test_norm, (-1, 32, 32, 3))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTZq4KMpneIv"
      },
      "source": [
        "################################################################################\n",
        "# REGULARIZERS\n",
        "################################################################################\n",
        "\n",
        "\n",
        "class Regularizer(tf.keras.regularizers.Regularizer):\n",
        "    def __init__(self, regularization_penalty, regularization_method):\n",
        "        self.regularization_penalty = regularization_penalty\n",
        "        self.regularization_method = regularization_method\n",
        "        self.n_new_neurons = 0\n",
        "        self.scaling_tensor = None\n",
        "        if self.regularization_method == 'weighted_l1_reordered':\n",
        "            self.update_scaling_tensor = True\n",
        "        else:\n",
        "            self.update_scaling_tensor = None\n",
        "\n",
        "    def __call__(self, x):\n",
        "        if self.regularization_method == 'weighted_l1':\n",
        "            return self.weighted_l1(x)\n",
        "        elif self.regularization_method == 'weighted_l1_reordered':\n",
        "            return self.weighted_l1_reordered(x)\n",
        "        elif self.regularization_method == 'group_sparsity':\n",
        "            return self.group_sparsity(x)\n",
        "        else:\n",
        "            raise NotImplementedError(f\"Unknown regularization method {self.regularization_method}\")\n",
        "    \n",
        "    def weighted_l1(self, x):\n",
        "        # I.e. for a parameter matrix of 4 input and 10 output neurons:\n",
        "        #\n",
        "        # [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]\n",
        "        #\n",
        "        # the scaling tensor, as well as the resulting weighted values, could be:\n",
        "        #\n",
        "        # [[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
        "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
        "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
        "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]\n",
        "        #\n",
        "        # Therefore every additional output neuron is regularized more.\n",
        "\n",
        "        scaling_tensor = tf.cumsum(tf.constant(self.regularization_penalty, shape=x.shape, dtype=dtype), axis=-1)\n",
        "        weighted_values = scaling_tensor * tf.abs(x)\n",
        "        return tf.reduce_sum(weighted_values)\n",
        "    \n",
        "    def weighted_l1_reordered(self, x):\n",
        "        # I.e. for a parameter matrix of 4 input and 10 output neurons:\n",
        "        #\n",
        "        # [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]\n",
        "        #\n",
        "        # the scaling tensor, as well as the resulting weighted values, could be:\n",
        "        #\n",
        "        # [[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
        "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
        "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
        "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]\n",
        "        #\n",
        "        # Therefore every additional output neuron is regularized more.\n",
        "\n",
        "        if self.update_scaling_tensor:\n",
        "            scaling_tensor_raw = tf.cumsum(tf.constant(self.regularization_penalty, shape=x.shape, dtype=dtype), axis=-1)\n",
        "\n",
        "            scaling_tensor_old_neurons = scaling_tensor_raw[:, :-self.n_new_neurons]\n",
        "            scaling_tensor_new_neurons = scaling_tensor_raw[:, -self.n_new_neurons:]\n",
        "            scaling_tensor_old_neurons_shuffled = tf.transpose(tf.random.shuffle(tf.transpose(scaling_tensor_old_neurons)))\n",
        "            self.scaling_tensor = tf.concat([scaling_tensor_old_neurons_shuffled, scaling_tensor_new_neurons], axis=-1)\n",
        "            self.update_scaling_tensor = False\n",
        "\n",
        "        weighted_values = self.scaling_tensor * tf.abs(x)\n",
        "        return tf.reduce_sum(weighted_values)\n",
        "    \n",
        "    def group_sparsity(self, x):\n",
        "        # I.e. for a parameter matrix of 3 input and 5 output neurons:\n",
        "        #\n",
        "        # [[1., 1., 1., 1., 1.],\n",
        "        #  [1., 2., 2., 1., 2.],\n",
        "        #  [2., 2., 3., 1., 3.]]\n",
        "        #\n",
        "        # The resulting vector of group norms is [2., 2., 3., 1., 3.], therefore for\n",
        "        # every output neuron, its incoming connections form a group.\n",
        "\n",
        "        group_norms = tf.norm(x, ord=2, axis=0)\n",
        "        # assert group_norms.shape[0] == x.shape[1]\n",
        "        return self.regularization_penalty * tf.reduce_sum(group_norms)\n",
        "    \n",
        "    def prune(self):\n",
        "        pass\n",
        "    \n",
        "    def grow(self, n_new_neurons):\n",
        "        self.n_new_neurons = n_new_neurons\n",
        "        if self.regularization_method == 'weighted_l1_reordered':\n",
        "            self.update_scaling_tensor = True\n",
        "\n",
        "    def get_config(self):\n",
        "        return {'regularization_penalty': float(self.regularization_penalty)}\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# LAYERS\n",
        "################################################################################\n",
        "\n",
        "\n",
        "class CustomLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, input_shape):\n",
        "        super().__init__()\n",
        "\n",
        "        self.inpt_shp = input_shape\n",
        "\n",
        "\n",
        "class Dense(CustomLayer):\n",
        "    def __init__(self, units, activation, regularization_penalty=0.01, \n",
        "                 regularization_method='weighted_l1', kernel_initializer='glorot_uniform', \n",
        "                 bias_initializer='zeros', input_shape=None, fixed_size=False):\n",
        "        super().__init__(input_shape)\n",
        "\n",
        "        self.units = units\n",
        "        self.activation = activation\n",
        "        self.regularization_penalty = regularization_penalty\n",
        "        self.regularization_method = regularization_method\n",
        "        self.kernel_initializer = kernel_initializer\n",
        "        self.bias_initializer = bias_initializer\n",
        "        self.fixed_size = fixed_size\n",
        "        \n",
        "        self.A = tf.keras.activations.get(activation)\n",
        "        self.W_init = tf.keras.initializers.get(kernel_initializer)\n",
        "        self.b_init = tf.keras.initializers.get(bias_initializer)\n",
        "        self.regularizer = Regularizer(self.regularization_penalty, self.regularization_method)\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        input_units = input_shape[-1]\n",
        "\n",
        "        self.W = tf.Variable(\n",
        "            name='W',\n",
        "            initial_value=self.W_init(shape=(input_units, self.units), dtype=dtype),\n",
        "            trainable=True)\n",
        "        \n",
        "        self.b = tf.Variable(\n",
        "            name='b',\n",
        "            initial_value=self.b_init(shape=(self.units,), dtype=dtype),\n",
        "            trainable=True)\n",
        "        \n",
        "        if self.regularization_method is not None:\n",
        "            self.add_loss(lambda: self.regularizer(tf.concat([self.W, tf.reshape(self.b, (1, -1))], axis=0)))\n",
        "    \n",
        "    def call(self, inputs, training=None):\n",
        "        return self.A(tf.matmul(inputs, self.W) + self.b)\n",
        "\n",
        "    def get_size(self):\n",
        "        return self.W.shape[0], self.W.shape[1]\n",
        "    \n",
        "    def prune(self, threshold, active_input_units_indices):\n",
        "        # Remove connections from pruned units in previous layer\n",
        "        new_W = tf.gather(self.W.value(), active_input_units_indices, axis=0)\n",
        "\n",
        "        if self.fixed_size:\n",
        "            active_output_neurons_indices = list(range(new_W.shape[1]))\n",
        "        else:\n",
        "            # Prune units in this layer\n",
        "            weights_with_biases = tf.concat([new_W, tf.reshape(self.b.value(), (1, -1))], axis=0)\n",
        "            neurons_are_active = tf.math.reduce_max(tf.abs(weights_with_biases), axis=0) >= threshold\n",
        "            active_output_neurons_indices = tf.reshape(tf.where(neurons_are_active), (-1,))\n",
        "            \n",
        "            new_W = tf.gather(new_W, active_output_neurons_indices, axis=1)\n",
        "            new_b = tf.gather(self.b.value(), active_output_neurons_indices, axis=0)\n",
        "\n",
        "            self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
        "\n",
        "        self.W = tf.Variable(name='W', initial_value=new_W, trainable=True)\n",
        "\n",
        "        self.regularizer.prune()\n",
        "        return active_output_neurons_indices\n",
        "    \n",
        "    def grow(self, n_new_input_units, percentage, min_new_units, scaling_factor):\n",
        "        if n_new_input_units > 0:\n",
        "            # Add connections to grown units in previous layer\n",
        "            W_growth = self.W_init(shape=(self.W.shape[0] + n_new_input_units, self.W.shape[1]), dtype=dtype)[-n_new_input_units:, :] * scaling_factor  # TODO is it better to be multiplying here by scaling_factor? It does help with not increasing the max weights of existing neurons when new neurons are added.\n",
        "            new_W = tf.concat([self.W.value(), W_growth], axis=0)\n",
        "        else:\n",
        "            new_W = self.W.value()\n",
        "\n",
        "        if self.fixed_size:\n",
        "            n_new_output_units = 0\n",
        "        else:\n",
        "            # Grow new units in this layer\n",
        "            n_new_output_units = max(min_new_units, int(new_W.shape[1] * percentage))\n",
        "            W_growth = self.W_init(shape=(new_W.shape[0], new_W.shape[1] + n_new_output_units), dtype=dtype)[:, -n_new_output_units:] * scaling_factor\n",
        "            b_growth = self.b_init(shape=(n_new_output_units,), dtype=dtype)  # TODO for all possible bias initializers to work properly, the whole bias vector should be initialized at once\n",
        "            new_W = tf.concat([new_W, W_growth], axis=1)\n",
        "            new_b = tf.concat([self.b.value(), b_growth], axis=0)\n",
        "\n",
        "            self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
        "\n",
        "        self.W = tf.Variable(name='W', initial_value=new_W, trainable=True)\n",
        "\n",
        "        self.regularizer.grow(n_new_output_units)\n",
        "        return n_new_output_units\n",
        "    \n",
        "    def get_param_string():\n",
        "        param_string = \"\"\n",
        "        weights_with_bias = tf.concat([self.W, tf.reshape(self.b, (1, -1))], axis=0)\n",
        "        max_parameters = tf.math.reduce_max(tf.abs(weights_with_bias), axis=0).numpy()\n",
        "        magnitudes = np.floor(np.log10(max_parameters))\n",
        "        for m in magnitudes:\n",
        "            if m > 0:\n",
        "                m = 0\n",
        "            param_string += str(int(-m))\n",
        "        return param_string\n",
        "\n",
        "\n",
        "class Conv2D(CustomLayer):\n",
        "    def __init__(self, filters, filter_size, activation, strides=(1, 1), \n",
        "                 padding='SAME', regularization_penalty=0.01, \n",
        "                 regularization_method='weighted_l1', kernel_initializer='glorot_uniform',\n",
        "                 bias_initializer='zeros', input_shape=None, fixed_size=False):\n",
        "        super().__init__(input_shape)\n",
        "    \n",
        "        self.filters = filters\n",
        "        self.filter_size = filter_size\n",
        "        self.activation = activation\n",
        "        self.strides = strides\n",
        "        self.padding = padding\n",
        "        self.regularization_penalty = regularization_penalty\n",
        "        self.regularization_method = regularization_method\n",
        "        self.kernel_initializer = kernel_initializer\n",
        "        self.bias_initializer = bias_initializer\n",
        "        self.fixed_size = fixed_size\n",
        "        \n",
        "        self.A = tf.keras.activations.get(activation)\n",
        "        self.F_init = tf.keras.initializers.get(kernel_initializer)\n",
        "        self.b_init = tf.keras.initializers.get(bias_initializer)\n",
        "        self.regularizer = Regularizer(self.regularization_penalty, self.regularization_method)\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        input_filters = input_shape[-1]\n",
        "\n",
        "        self.F = tf.Variable(\n",
        "            name='F',\n",
        "            initial_value=self.F_init(\n",
        "                shape=(self.filter_size[0], self.filter_size[1], input_filters, self.filters), dtype=dtype\n",
        "            ),\n",
        "            trainable=True)\n",
        "        \n",
        "        self.b = tf.Variable(\n",
        "            name='b',\n",
        "            initial_value=self.b_init(shape=(self.filters,), dtype=dtype),\n",
        "            trainable=True)\n",
        "\n",
        "        if self.regularization_method is not None:\n",
        "            self.add_loss(lambda: self.regularizer(tf.concat([tf.reshape(self.F, (-1, self.F.shape[-1])), tf.reshape(self.b, (1, -1))], axis=0)))\n",
        "    \n",
        "    def call(self, inputs, training=None):\n",
        "        y = tf.nn.conv2d(inputs, self.F, strides=self.strides, padding=self.padding)\n",
        "        y = tf.nn.bias_add(y, self.b)\n",
        "        y = self.A(y)\n",
        "        return y\n",
        "    \n",
        "    def get_size(self):\n",
        "        return self.F.shape[-2], self.F.shape[-1]\n",
        "    \n",
        "    def prune(self, threshold, active_input_units_indices):\n",
        "        # Remove connections from pruned units in previous layer\n",
        "        new_F = tf.gather(self.F.value(), active_input_units_indices, axis=-2)\n",
        "\n",
        "        if self.fixed_size:\n",
        "            active_output_filters_indices = list(range(new_F.shape[-1]))\n",
        "        else:\n",
        "            # Prune units in this layer\n",
        "            F_reduced_max = tf.reshape(tf.math.reduce_max(tf.abs(new_F), axis=(0, 1, 2)), (1, -1))\n",
        "            F_reduced_max_with_biases = tf.concat([F_reduced_max, tf.reshape(self.b.value(), (1, -1))], axis=0)\n",
        "            filters_are_active = tf.math.reduce_max(tf.abs(F_reduced_max_with_biases), axis=0) >= threshold\n",
        "            active_output_filters_indices = tf.reshape(tf.where(filters_are_active), (-1,))\n",
        "            \n",
        "            new_F = tf.gather(new_F, active_output_filters_indices, axis=-1)\n",
        "            new_b = tf.gather(self.b.value(), active_output_filters_indices, axis=0)\n",
        "\n",
        "            self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
        "\n",
        "        self.F = tf.Variable(name='F', initial_value=new_F, trainable=True)\n",
        "\n",
        "        self.regularizer.prune()\n",
        "        return active_output_filters_indices\n",
        "\n",
        "    def grow(self, n_new_input_units, percentage, min_new_units, scaling_factor):\n",
        "        if n_new_input_units > 0:\n",
        "            # Add connections to grown units in previous layer\n",
        "            F_growth = self.F_init(shape=(self.F.shape[0], self.F.shape[1], self.F.shape[2] + n_new_input_units, self.F.shape[3]), dtype=dtype)[:, :, -n_new_input_units:, :] * scaling_factor  # TODO is it better to be multiplying here by scaling_factor? It does help with not increasing the max weights of existing neurons when new neurons are added.\n",
        "            new_F = tf.concat([self.F.value(), F_growth], axis=-2)\n",
        "        else:\n",
        "            new_F = self.F.value()\n",
        "\n",
        "        if self.fixed_size:\n",
        "            n_new_output_units = 0\n",
        "        else:\n",
        "            # Grow new units in this layer\n",
        "            n_new_output_units = max(min_new_units, int(new_F.shape[-1] * percentage))\n",
        "            F_growth = self.F_init(shape=(new_F.shape[0], new_F.shape[1], new_F.shape[2], new_F.shape[3] + n_new_output_units), dtype=dtype)[:, :, :, -n_new_output_units:] * scaling_factor\n",
        "            b_growth = self.b_init(shape=(n_new_output_units,), dtype=dtype)  # TODO for all possible bias initializers to work properly, the whole bias vector should be initialized at once\n",
        "            new_F = tf.concat([new_F, F_growth], axis=-1)\n",
        "            new_b = tf.concat([self.b.value(), b_growth], axis=0)\n",
        "\n",
        "            self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
        "\n",
        "        self.F = tf.Variable(name='F', initial_value=new_F, trainable=True)\n",
        "\n",
        "        self.regularizer.grow(n_new_output_units)\n",
        "        return n_new_output_units\n",
        "\n",
        "    def get_param_string():\n",
        "        param_string = \"\"\n",
        "        # TODO\n",
        "        return param_string\n",
        "\n",
        "\n",
        "class Flatten(tf.keras.Model):\n",
        "    def call(self, inputs, training=None):\n",
        "        return tf.reshape(tf.transpose(inputs, perm=[0, 3, 1, 2]), (inputs.shape[0], -1))\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# MODELS\n",
        "################################################################################\n",
        "\n",
        "\n",
        "class Sequential(tf.keras.Model):\n",
        "    def __init__(self, layers, activation=None):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.lrs = layers\n",
        "        \n",
        "    def call(self, inputs, training=None):\n",
        "        x = inputs\n",
        "        for layer in self.lrs:\n",
        "            x = layer(x, training=training)\n",
        "        return x\n",
        "    \n",
        "    def get_layer_input_shape(self, target_layer):\n",
        "        if target_layer.inpt_shp is not None:\n",
        "            return target_layer.inpt_shp\n",
        "\n",
        "        input = np.random.normal(size=(1,) + self.lrs[0].inpt_shp)\n",
        "        for layer in self.lrs:\n",
        "            if layer is target_layer:\n",
        "                return tuple(input.shape[1:])\n",
        "            input = layer(input)\n",
        "        raise Exception(\"Layer not found in the model.\")\n",
        "\n",
        "    def get_layer_output_shape(self, target_layer):\n",
        "        input = np.random.normal(size=(1,) + self.lrs[0].inpt_shp)\n",
        "        for layer in self.lrs:\n",
        "            output = layer(input)\n",
        "            if layer is target_layer:\n",
        "                return tuple(output.shape[1:])\n",
        "            input = output\n",
        "        raise Exception(\"Layer not found in the model.\")\n",
        "    \n",
        "    def get_layer_sizes(self):\n",
        "        \"\"\"\n",
        "        Returns the sizes of all layers in the model, including the input and output layer.\n",
        "        \"\"\"\n",
        "        layer_sizes = list()\n",
        "        first_layer = True\n",
        "        for l in range(len(self.lrs)):\n",
        "            layer = self.lrs[l]\n",
        "            if isinstance(layer, CustomLayer):\n",
        "                layer_size = layer.get_size()\n",
        "                if first_layer:\n",
        "                    layer_sizes.append(layer_size[0])\n",
        "                    first_layer = False\n",
        "                layer_sizes.append(layer_size[1])\n",
        "        return layer_sizes\n",
        "    \n",
        "    def get_hidden_layer_sizes(self):\n",
        "        return self.get_layer_sizes()[1:-1]\n",
        "    \n",
        "    def remove_regularization(self):\n",
        "        self.set_regularization_penalty(0.)\n",
        "    \n",
        "    def get_regularization_penalty(self):\n",
        "        #TODO improve\n",
        "        return self.lrs[-2].regularizer.regularization_penalty\n",
        "    \n",
        "    def set_regularization_penalty(self, regularization_penalty):\n",
        "        for layer in self.lrs:\n",
        "            if isinstance(layer, CustomLayer) and not layer.fixed_size:\n",
        "                layer.regularizer.regularization_penalty = regularization_penalty\n",
        "    \n",
        "    def prune(self, params):\n",
        "        input_shape = self.get_layer_input_shape(self.lrs[0])\n",
        "        n_input_units = input_shape[-1]\n",
        "        active_units_indices = list(range(n_input_units))\n",
        "\n",
        "        last_custom_layer = None\n",
        "        for layer in self.lrs:\n",
        "            if isinstance(layer, CustomLayer):\n",
        "                if last_custom_layer is not None and type(last_custom_layer) != type(layer):\n",
        "                    if type(last_custom_layer) == Conv2D and type(layer) == Dense:\n",
        "                        convolutional_shape = self.get_layer_output_shape(last_custom_layer)\n",
        "                        active_units_indices = self.convert_channel_indices_to_flattened_indices(active_units_indices, convolutional_shape)\n",
        "                    else:\n",
        "                        raise Exception(\"Incorrect order of custom layer types.\")\n",
        "                active_units_indices = layer.prune(params.pruning_threshold, active_units_indices)\n",
        "                last_custom_layer = layer\n",
        "    \n",
        "    def grow(self, params):   \n",
        "        n_new_units = 0\n",
        "\n",
        "        last_custom_layer = None\n",
        "        for layer in self.lrs:\n",
        "            if isinstance(layer, CustomLayer):\n",
        "                if last_custom_layer is not None and type(last_custom_layer) != type(layer):\n",
        "                    if type(last_custom_layer) == Conv2D and type(layer) == Dense:\n",
        "                        convolutional_shape = self.get_layer_output_shape(last_custom_layer)\n",
        "                        n_new_units = n_new_units * convolutional_shape[0] * convolutional_shape[1]\n",
        "                    else:\n",
        "                        raise Exception(\"Incorrect order of custom layer types.\")\n",
        "                n_new_units = layer.grow(n_new_units, params.growth_percentage, min_new_units=params.min_new_neurons, scaling_factor=params.pruning_threshold)\n",
        "                last_custom_layer = layer\n",
        "    \n",
        "    @staticmethod\n",
        "    def convert_channel_indices_to_flattened_indices(channel_indices, convolutional_shape):\n",
        "        dense_indices = list()\n",
        "        units_per_channel = convolutional_shape[0] * convolutional_shape[1]\n",
        "        for channel_index in channel_indices:\n",
        "            for iter in range(units_per_channel):\n",
        "                dense_indices.append(channel_index * units_per_channel + iter)\n",
        "        return dense_indices\n",
        "    \n",
        "    def print_neurons(self):\n",
        "        for layer in self.lrs[:-1]:\n",
        "            print(layer.get_param_string())\n",
        "    \n",
        "    def evaluate(self, params, summed_training_loss, summed_training_accuracy):\n",
        "        # Calculate training loss and accuracy\n",
        "        if summed_training_loss is not None:\n",
        "            loss = summed_training_loss / params.x.shape[0]\n",
        "        else:\n",
        "            loss = None\n",
        "        \n",
        "        if summed_training_accuracy is not None:\n",
        "            accuracy = summed_training_accuracy / params.x.shape[0]\n",
        "        else:\n",
        "            accuracy = None\n",
        "        \n",
        "        # Calculate val loss and accuracy\n",
        "        summed_val_loss = 0\n",
        "        summed_val_accuracy = 0\n",
        "        n_val_instances = 0\n",
        "        \n",
        "        for step, (x_batch, y_batch) in enumerate(params.val_dataset):\n",
        "            y_pred = self(x_batch, training=False)\n",
        "            summed_val_loss += tf.reduce_sum(tf.keras.losses.sparse_categorical_crossentropy(y_batch, y_pred))\n",
        "            summed_val_accuracy += float(tf.reduce_sum(tf.keras.metrics.sparse_categorical_accuracy(y_batch, y_pred)))\n",
        "            n_val_instances += x_batch.shape[0]\n",
        "        \n",
        "        val_loss = summed_val_loss / n_val_instances\n",
        "        val_accuracy = summed_val_accuracy / n_val_instances\n",
        "\n",
        "        return loss, accuracy, val_loss, val_accuracy\n",
        "    \n",
        "    def print_epoch_statistics(self, params, summed_training_loss, summed_training_accuracy, message=None, require_result=False):\n",
        "        if not params.verbose:\n",
        "            if require_result:\n",
        "                return self.evaluate(params, summed_training_loss, summed_training_accuracy)\n",
        "            else:\n",
        "                return\n",
        "        \n",
        "        loss, accuracy, val_loss, val_accuracy = self.evaluate(params, summed_training_loss, summed_training_accuracy)  \n",
        "\n",
        "        if message is not None:\n",
        "            print(message)\n",
        "        \n",
        "        print(f\"loss: {loss} - accuracy: {accuracy} - val_loss: {val_loss} - val_accuracy: {val_accuracy} - penalty: {self.get_regularization_penalty()}\")\n",
        "        hidden_layer_sizes = self.get_hidden_layer_sizes()\n",
        "        print(f\"hidden layer sizes: {hidden_layer_sizes}, total units: {sum(hidden_layer_sizes)}\")\n",
        "        if params.print_neurons:\n",
        "            self.print_neurons()\n",
        "        \n",
        "        if require_result:\n",
        "            return loss, accuracy, val_loss, val_accuracy\n",
        "    \n",
        "    def update_history(self, params, loss, accuracy, val_loss, val_accuracy):\n",
        "        params.history['loss'].append(loss)\n",
        "        params.history['accuracy'].append(accuracy)\n",
        "        params.history['val_loss'].append(val_loss)\n",
        "        params.history['val_accuracy'].append(val_accuracy)\n",
        "        params.history['hidden_layer_sizes'].append(self.get_hidden_layer_sizes())\n",
        "    \n",
        "    @staticmethod\n",
        "    def prepare_datasets(x, y, batch_size, validation_data):\n",
        "        train_dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "        train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "        val_dataset = tf.data.Dataset.from_tensor_slices(validation_data).batch(batch_size)\n",
        "        return train_dataset, val_dataset\n",
        "    \n",
        "    def manage_dynamic_regularization(self, params, val_loss):\n",
        "        if val_loss >= params.best_conditional_val_loss * params.stall_coefficient:\n",
        "            # Training is currently in stall\n",
        "            if not params.training_stalled:\n",
        "                penalty = self.get_regularization_penalty() * params.regularization_penalty_multiplier\n",
        "                print(\"Changing penalty...\")\n",
        "                # TODO this must be modified, penalty can differ for each layer\n",
        "                self.set_regularization_penalty(penalty)\n",
        "                params.training_stalled = True\n",
        "        else:\n",
        "            params.best_conditional_val_loss = val_loss\n",
        "            params.training_stalled = False\n",
        "    \n",
        "    def grow_wrapper(self, params):\n",
        "        dynamic_reqularization_active = params.regularization_penalty_multiplier != 1.\n",
        "        if dynamic_reqularization_active:\n",
        "            loss, accuracy, val_loss, val_accuracy = self.print_epoch_statistics(params, None, None, \"Before growing:\", require_result=True)\n",
        "            self.manage_dynamic_regularization(params, val_loss)\n",
        "        else:\n",
        "            self.print_epoch_statistics(params, None, None, \"Before growing:\")\n",
        "\n",
        "        self.grow(params)\n",
        "        self.print_epoch_statistics(params, None, None, \"After growing:\")\n",
        "    \n",
        "    def prune_wrapper(self, params, summed_loss, summed_accuracy):\n",
        "        loss, accuracy, _, _ = self.print_epoch_statistics(params, summed_loss, summed_accuracy, \"Before pruning:\", require_result=True)\n",
        "        self.prune(params)\n",
        "        _, _, val_loss, val_accuracy = self.print_epoch_statistics(params, None, None, \"After pruning:\", require_result=True)\n",
        "\n",
        "        self.update_history(params, loss, accuracy, val_loss, val_accuracy)\n",
        "    \n",
        "    class ParameterContainer:\n",
        "        def __init__(self, x, y, optimizer, epochs, self_scaling_epochs, batch_size, min_new_neurons, validation_data, pruning_threshold, \n",
        "                regularization_penalty_multiplier, stall_coefficient, growth_percentage, mini_epochs_per_epoch, verbose, print_neurons):\n",
        "            self.x = x\n",
        "            self.y = y\n",
        "            self.optimizer = optimizer\n",
        "            self.epochs = epochs\n",
        "            self.self_scaling_epochs = self_scaling_epochs\n",
        "            self.batch_size = batch_size\n",
        "            self.min_new_neurons = min_new_neurons\n",
        "            self.validation_data = validation_data\n",
        "            self.pruning_threshold = pruning_threshold\n",
        "            self.regularization_penalty_multiplier = regularization_penalty_multiplier\n",
        "            self.stall_coefficient = stall_coefficient\n",
        "            self.growth_percentage = growth_percentage\n",
        "            self.mini_epochs_per_epoch = mini_epochs_per_epoch\n",
        "            self.verbose = verbose\n",
        "            self.print_neurons = print_neurons\n",
        "\n",
        "            self.train_dataset, self.val_dataset = Sequential.prepare_datasets(x, y, batch_size, validation_data)\n",
        "            self.history = self.prepare_history()\n",
        "\n",
        "            self.best_conditional_val_loss = np.inf\n",
        "            self.training_stalled = False\n",
        "        \n",
        "        @staticmethod\n",
        "        def prepare_history():\n",
        "            history = {\n",
        "                'loss': list(),\n",
        "                'accuracy': list(),\n",
        "                'val_loss': list(),\n",
        "                'val_accuracy': list(),\n",
        "                'hidden_layer_sizes': list(),\n",
        "            }\n",
        "            return history\n",
        "    \n",
        "    def fit_single_epoch(self, params):       \n",
        "        summed_loss = 0\n",
        "        summed_accuracy = 0\n",
        "        \n",
        "        for mini_epoch in range(params.mini_epochs_per_epoch):\n",
        "            summed_loss = 0\n",
        "            summed_accuracy = 0\n",
        "\n",
        "            for step, (x_batch, y_batch) in enumerate(params.train_dataset):\n",
        "                with tf.GradientTape() as tape:\n",
        "                    y_pred = self(x_batch, training=True)\n",
        "                    raw_loss = tf.keras.losses.sparse_categorical_crossentropy(y_batch, y_pred)\n",
        "                    loss_value = tf.reduce_mean(raw_loss)\n",
        "                    loss_value += sum(self.losses)  # Add losses registered by model.add_loss\n",
        "\n",
        "                    summed_loss += tf.reduce_sum(raw_loss)\n",
        "                    summed_accuracy += float(tf.reduce_sum(tf.keras.metrics.sparse_categorical_accuracy(y_batch, y_pred)))\n",
        "\n",
        "                grads = tape.gradient(loss_value, self.trainable_variables)\n",
        "                params.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
        "        \n",
        "        return summed_loss, summed_accuracy\n",
        "\n",
        "    def fit(self, x, y, optimizer, epochs, self_scaling_epochs, batch_size, min_new_neurons, validation_data, pruning_threshold=0.001, \n",
        "            regularization_penalty_multiplier=1., stall_coefficient=1, growth_percentage=0.2, mini_epochs_per_epoch=1, pruning_only_epochs=0, verbose=True, print_neurons=False):\n",
        "        params = self.ParameterContainer(x, y, optimizer, epochs, self_scaling_epochs, batch_size, min_new_neurons, \n",
        "                                         validation_data, pruning_threshold, regularization_penalty_multiplier, stall_coefficient, \n",
        "                                         growth_percentage, mini_epochs_per_epoch, verbose, print_neurons)\n",
        "        self.build(x.shape)  # Necessary when verbose == False\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            if verbose:\n",
        "                print(\"##########################################################\")\n",
        "                print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "            if epoch < self_scaling_epochs - pruning_only_epochs:\n",
        "                self.grow_wrapper(params)\n",
        "            \n",
        "            if epoch == self_scaling_epochs:\n",
        "                self.remove_regularization()\n",
        "\n",
        "            summed_loss, summed_accuracy = self.fit_single_epoch(params)\n",
        "            \n",
        "            if epoch < self_scaling_epochs:\n",
        "                self.prune_wrapper(params, summed_loss, summed_accuracy)\n",
        "            else:\n",
        "                loss, accuracy, val_loss, val_accuracy = self.print_epoch_statistics(params, summed_loss, summed_accuracy, require_result=True)\n",
        "                self.update_history(params, loss, accuracy, val_loss, val_accuracy)\n",
        "\n",
        "        return params.history\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# HELPER FUNCTIONS\n",
        "################################################################################\n",
        "\n",
        "\n",
        "def get_statistics_from_history(history):\n",
        "    best_epoch_number = np.argmax(history['val_accuracy'])\n",
        "    best_val_accuracy = history['val_accuracy'][best_epoch_number]\n",
        "    best_hidden_layer_sizes = history['hidden_layer_sizes'][best_epoch_number]\n",
        "    return best_val_accuracy, best_hidden_layer_sizes\n",
        "\n",
        "\n",
        "def get_statistics_from_histories(histories):\n",
        "    best_val_accuracies = list()\n",
        "    all_best_hidden_layer_sizes = list()\n",
        "\n",
        "    for history in histories:\n",
        "        best_val_accuracy, best_hidden_layer_sizes = get_statistics_from_history(history)\n",
        "        best_val_accuracies.append(best_val_accuracy)\n",
        "        all_best_hidden_layer_sizes.append(best_hidden_layer_sizes)\n",
        "    \n",
        "    mean_best_val_accuracy = np.mean(best_val_accuracies)\n",
        "    mean_best_hidden_layer_sizes = [np.mean(layer) for layer in list(zip(*all_best_hidden_layer_sizes))]\n",
        "    \n",
        "    return mean_best_val_accuracy, mean_best_hidden_layer_sizes\n",
        "\n",
        "\n",
        "def cross_validate(train_fn, x, y, n_splits, random_state=42, *args, **kwargs):\n",
        "    from sklearn.model_selection import KFold\n",
        "\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "\n",
        "    histories = list()\n",
        "    for i, (train_index, test_index) in enumerate(kf.split(x)):\n",
        "        xtrain, xtest = x[train_index], x[test_index]\n",
        "        ytrain, ytest = y[train_index], y[test_index]\n",
        "\n",
        "        history = train_fn(*args, **kwargs)\n",
        "        histories.append(history)\n",
        "\n",
        "        best_val_accuracy, best_hidden_layer_sizes = get_statistics_from_history(history)\n",
        "        print(f\"Run {i} completed, best_val_accuracy: {best_val_accuracy}, best_hidden_layer_sizes: {best_hidden_layer_sizes}\")\n",
        "\n",
        "    mean_best_val_accuracy, mean_best_hidden_layer_sizes = get_statistics_from_histories(histories)\n",
        "    print(f'mean_best_val_accuracy: {mean_best_val_accuracy}')\n",
        "    print(f'mean_best_hidden_layer_sizes: {mean_best_hidden_layer_sizes}')\n",
        "\n",
        "    return histories\n",
        "\n",
        "\n",
        "def hyperparameter_search(train_fn, *args, **kwargs):\n",
        "    from itertools import product\n",
        "\n",
        "    all_params = [*args] + list(kwargs.values())\n",
        "    histories = list()\n",
        "\n",
        "    best_overall_val_accuracy = -np.inf\n",
        "    best_overall_combination = None\n",
        "\n",
        "    for combination in product(*all_params):\n",
        "        combination_args = combination[:len(args)]\n",
        "\n",
        "        combination_kwargs_values = combination[len(args):]\n",
        "        combination_kwargs = dict(zip(kwargs.keys(), combination_kwargs_values))\n",
        "\n",
        "        history = train_fn(*combination_args, **combination_kwargs)\n",
        "        history['parameters'] = combination\n",
        "        histories.append(history)\n",
        "\n",
        "        best_val_accuracy, best_hidden_layer_sizes = get_statistics_from_history(history)\n",
        "        print(f\"Run with parameters {combination} completed, best_val_accuracy: {best_val_accuracy}, best_hidden_layer_sizes sizes: {best_hidden_layer_sizes}\")\n",
        "\n",
        "        if best_val_accuracy > best_overall_val_accuracy:\n",
        "            best_overall_val_accuracy = best_val_accuracy\n",
        "            best_overall_combination = combination\n",
        "    \n",
        "    print(f'Best overall combination: {best_overall_combination}, val_accuracy: {best_overall_val_accuracy}')\n",
        "\n",
        "    return histories"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1MrQXUTFwOe"
      },
      "source": [
        "# Accuracy benchmark - FF and convolutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsivpauwveEK"
      },
      "source": [
        "## CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdBhEgOUHfLq"
      },
      "source": [
        "def get_convolutional_model(regularization_penalty, regularization_method, layer_sizes, output_neurons=10):\n",
        "    model = Sequential([\n",
        "        Conv2D(layer_sizes[0], filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=regularization_penalty, regularization_method=regularization_method, \n",
        "            kernel_initializer='lecun_normal', input_shape=X_train_norm[0,:,:,:].shape),\n",
        "        Conv2D(layer_sizes[1], filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=regularization_penalty, regularization_method=regularization_method, \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(layer_sizes[2], filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=regularization_penalty, regularization_method=regularization_method, \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        Conv2D(layer_sizes[3], filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=regularization_penalty, regularization_method=regularization_method, \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(layer_sizes[4], activation='selu', regularization_penalty=regularization_penalty, \n",
        "            regularization_method=regularization_method, kernel_initializer='lecun_normal'),\n",
        "        Dense(output_neurons, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None, fixed_size=True),\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_fn(learning_rate, regularization_penalty, regularization_method, self_scaling_epochs, layer_sizes, output_neurons=10, \n",
        "             epochs=40, pruning_only_epochs=0, min_new_neurons=20, growth_percentage=0.2, verbose=False):\n",
        "    batch_size = 128\n",
        "\n",
        "    model = get_convolutional_model(regularization_penalty, regularization_method, layer_sizes, output_neurons)\n",
        "    \n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    history = model.fit(X_train_norm, y_train, optimizer, epochs, self_scaling_epochs, batch_size, \n",
        "                        min_new_neurons, validation_data=(X_test_norm, y_test), pruning_only_epochs=pruning_only_epochs, \n",
        "                        growth_percentage=growth_percentage, verbose=verbose)\n",
        "    \n",
        "    return history"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "\n",
        "model = get_convolutional_model(regularization_penalty=0.00002, regularization_method='weighted_l1', layer_sizes=[100, 100, 100, 100, 100], output_neurons=10)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0006)\n",
        "\n",
        "history = model.fit(X_train_norm, y_train, optimizer, epochs=20, self_scaling_epochs=20, batch_size=batch_size, \n",
        "                    min_new_neurons=20, validation_data=(X_test_norm, y_test), pruning_only_epochs=0, \n",
        "                    growth_percentage=0.2, verbose=True)"
      ],
      "metadata": {
        "id": "T1dTftcZrXFh",
        "outputId": "41e279c6-605e-4310-d45c-212fc1a0790d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.0063858032226562 - val_accuracy: 0.0844 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.006385326385498 - val_accuracy: 0.0844 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "Before pruning:\n",
            "loss: 1.762871265411377 - accuracy: 0.39802 - val_loss: 1.4641473293304443 - val_accuracy: 0.4651 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4639816284179688 - val_accuracy: 0.4651 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 112], total units: 512\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4639816284179688 - val_accuracy: 0.4651 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 112], total units: 512\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4639816284179688 - val_accuracy: 0.4651 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 134], total units: 614\n",
            "Before pruning:\n",
            "loss: 1.588214635848999 - accuracy: 0.44086 - val_loss: 1.2987065315246582 - val_accuracy: 0.5283 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 134], total units: 614\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.2985821962356567 - val_accuracy: 0.5279 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 97, 101, 101, 132], total units: 531\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2985821962356567 - val_accuracy: 0.5279 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 97, 101, 101, 132], total units: 531\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.298582673072815 - val_accuracy: 0.5279 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 117, 121, 121, 158], total units: 637\n",
            "Before pruning:\n",
            "loss: 1.4011834859848022 - accuracy: 0.4934 - val_loss: 1.2440658807754517 - val_accuracy: 0.5498 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 117, 121, 121, 158], total units: 637\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.2445520162582397 - val_accuracy: 0.5495 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 56, 94, 80, 144], total units: 474\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2445520162582397 - val_accuracy: 0.5495 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 56, 94, 80, 144], total units: 474\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2445518970489502 - val_accuracy: 0.5495 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 76, 114, 100, 172], total units: 582\n",
            "Before pruning:\n",
            "loss: 1.3092278242111206 - accuracy: 0.52966 - val_loss: 1.1373684406280518 - val_accuracy: 0.5888 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 76, 114, 100, 172], total units: 582\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1373523473739624 - val_accuracy: 0.589 - penalty: 2e-05\n",
            "hidden layer sizes: [94, 41, 91, 60, 162], total units: 448\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1373523473739624 - val_accuracy: 0.589 - penalty: 2e-05\n",
            "hidden layer sizes: [94, 41, 91, 60, 162], total units: 448\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1373522281646729 - val_accuracy: 0.589 - penalty: 2e-05\n",
            "hidden layer sizes: [114, 61, 111, 80, 194], total units: 560\n",
            "Before pruning:\n",
            "loss: 1.2429461479187012 - accuracy: 0.55312 - val_loss: 1.0574992895126343 - val_accuracy: 0.6221 - penalty: 2e-05\n",
            "hidden layer sizes: [114, 61, 111, 80, 194], total units: 560\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0575121641159058 - val_accuracy: 0.6221 - penalty: 2e-05\n",
            "hidden layer sizes: [82, 33, 57, 61, 164], total units: 397\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0575121641159058 - val_accuracy: 0.6221 - penalty: 2e-05\n",
            "hidden layer sizes: [82, 33, 57, 61, 164], total units: 397\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0575121641159058 - val_accuracy: 0.6221 - penalty: 2e-05\n",
            "hidden layer sizes: [102, 53, 77, 81, 196], total units: 509\n",
            "Before pruning:\n",
            "loss: 1.1847989559173584 - accuracy: 0.5774 - val_loss: 1.0160642862319946 - val_accuracy: 0.6341 - penalty: 2e-05\n",
            "hidden layer sizes: [102, 53, 77, 81, 196], total units: 509\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0160325765609741 - val_accuracy: 0.6346 - penalty: 2e-05\n",
            "hidden layer sizes: [76, 30, 46, 59, 174], total units: 385\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0160325765609741 - val_accuracy: 0.6346 - penalty: 2e-05\n",
            "hidden layer sizes: [76, 30, 46, 59, 174], total units: 385\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0160325765609741 - val_accuracy: 0.6346 - penalty: 2e-05\n",
            "hidden layer sizes: [96, 50, 66, 79, 208], total units: 499\n",
            "Before pruning:\n",
            "loss: 1.1474229097366333 - accuracy: 0.5881 - val_loss: 0.9745102524757385 - val_accuracy: 0.6562 - penalty: 2e-05\n",
            "hidden layer sizes: [96, 50, 66, 79, 208], total units: 499\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9745498895645142 - val_accuracy: 0.6563 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 22, 35, 53, 179], total units: 349\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9745498895645142 - val_accuracy: 0.6563 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 22, 35, 53, 179], total units: 349\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9745500087738037 - val_accuracy: 0.6563 - penalty: 2e-05\n",
            "hidden layer sizes: [80, 42, 55, 73, 214], total units: 464\n",
            "Before pruning:\n",
            "loss: 1.1216723918914795 - accuracy: 0.59898 - val_loss: 0.9667522311210632 - val_accuracy: 0.6579 - penalty: 2e-05\n",
            "hidden layer sizes: [80, 42, 55, 73, 214], total units: 464\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9667598605155945 - val_accuracy: 0.6577 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 21, 36, 53, 213], total units: 380\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9667598605155945 - val_accuracy: 0.6577 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 21, 36, 53, 213], total units: 380\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9667598605155945 - val_accuracy: 0.6577 - penalty: 2e-05\n",
            "hidden layer sizes: [77, 41, 56, 73, 255], total units: 502\n",
            "Before pruning:\n",
            "loss: 1.091905117034912 - accuracy: 0.61164 - val_loss: 0.9380272626876831 - val_accuracy: 0.6667 - penalty: 2e-05\n",
            "hidden layer sizes: [77, 41, 56, 73, 255], total units: 502\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9379468560218811 - val_accuracy: 0.6671 - penalty: 2e-05\n",
            "hidden layer sizes: [54, 23, 42, 58, 233], total units: 410\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9379468560218811 - val_accuracy: 0.6671 - penalty: 2e-05\n",
            "hidden layer sizes: [54, 23, 42, 58, 233], total units: 410\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9379469752311707 - val_accuracy: 0.6671 - penalty: 2e-05\n",
            "hidden layer sizes: [74, 43, 62, 78, 279], total units: 536\n",
            "Before pruning:\n",
            "loss: 1.0707337856292725 - accuracy: 0.61774 - val_loss: 0.926649808883667 - val_accuracy: 0.6751 - penalty: 2e-05\n",
            "hidden layer sizes: [74, 43, 62, 78, 279], total units: 536\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9264616370201111 - val_accuracy: 0.6756 - penalty: 2e-05\n",
            "hidden layer sizes: [52, 18, 35, 58, 236], total units: 399\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9264616370201111 - val_accuracy: 0.6756 - penalty: 2e-05\n",
            "hidden layer sizes: [52, 18, 35, 58, 236], total units: 399\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9264616966247559 - val_accuracy: 0.6756 - penalty: 2e-05\n",
            "hidden layer sizes: [72, 38, 55, 78, 283], total units: 526\n",
            "Before pruning:\n",
            "loss: 1.0540820360183716 - accuracy: 0.62476 - val_loss: 0.9130798578262329 - val_accuracy: 0.6802 - penalty: 2e-05\n",
            "hidden layer sizes: [72, 38, 55, 78, 283], total units: 526\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9132159352302551 - val_accuracy: 0.6802 - penalty: 2e-05\n",
            "hidden layer sizes: [45, 19, 37, 55, 246], total units: 402\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9132159352302551 - val_accuracy: 0.6802 - penalty: 2e-05\n",
            "hidden layer sizes: [45, 19, 37, 55, 246], total units: 402\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9132158160209656 - val_accuracy: 0.6802 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 39, 57, 75, 295], total units: 531\n",
            "Before pruning:\n",
            "loss: 1.0365456342697144 - accuracy: 0.63078 - val_loss: 0.8871077299118042 - val_accuracy: 0.6884 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 39, 57, 75, 295], total units: 531\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8866878151893616 - val_accuracy: 0.6882 - penalty: 2e-05\n",
            "hidden layer sizes: [42, 17, 35, 56, 230], total units: 380\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8866878151893616 - val_accuracy: 0.6882 - penalty: 2e-05\n",
            "hidden layer sizes: [42, 17, 35, 56, 230], total units: 380\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8866878151893616 - val_accuracy: 0.6882 - penalty: 2e-05\n",
            "hidden layer sizes: [62, 37, 55, 76, 276], total units: 506\n",
            "Before pruning:\n",
            "loss: 1.0161739587783813 - accuracy: 0.63926 - val_loss: 0.8996338844299316 - val_accuracy: 0.6827 - penalty: 2e-05\n",
            "hidden layer sizes: [62, 37, 55, 76, 276], total units: 506\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8997265696525574 - val_accuracy: 0.6826 - penalty: 2e-05\n",
            "hidden layer sizes: [40, 17, 40, 60, 254], total units: 411\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8997265696525574 - val_accuracy: 0.6826 - penalty: 2e-05\n",
            "hidden layer sizes: [40, 17, 40, 60, 254], total units: 411\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8997265696525574 - val_accuracy: 0.6826 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 37, 60, 80, 304], total units: 541\n",
            "Before pruning:\n",
            "loss: 1.0051814317703247 - accuracy: 0.64454 - val_loss: 0.8733405470848083 - val_accuracy: 0.6966 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 37, 60, 80, 304], total units: 541\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.874220609664917 - val_accuracy: 0.6963 - penalty: 2e-05\n",
            "hidden layer sizes: [40, 17, 43, 62, 219], total units: 381\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.874220609664917 - val_accuracy: 0.6963 - penalty: 2e-05\n",
            "hidden layer sizes: [40, 17, 43, 62, 219], total units: 381\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8742204904556274 - val_accuracy: 0.6963 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 37, 63, 82, 262], total units: 504\n",
            "Before pruning:\n",
            "loss: 0.9923338890075684 - accuracy: 0.64988 - val_loss: 0.855217695236206 - val_accuracy: 0.7 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 37, 63, 82, 262], total units: 504\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8552069067955017 - val_accuracy: 0.6999 - penalty: 2e-05\n",
            "hidden layer sizes: [39, 17, 38, 60, 237], total units: 391\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8552069067955017 - val_accuracy: 0.6999 - penalty: 2e-05\n",
            "hidden layer sizes: [39, 17, 38, 60, 237], total units: 391\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8552070260047913 - val_accuracy: 0.6999 - penalty: 2e-05\n",
            "hidden layer sizes: [59, 37, 58, 80, 284], total units: 518\n",
            "Before pruning:\n",
            "loss: 0.9748952984809875 - accuracy: 0.65438 - val_loss: 0.8669872879981995 - val_accuracy: 0.7003 - penalty: 2e-05\n",
            "hidden layer sizes: [59, 37, 58, 80, 284], total units: 518\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8669258952140808 - val_accuracy: 0.7001 - penalty: 2e-05\n",
            "hidden layer sizes: [44, 17, 41, 61, 237], total units: 400\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8669258952140808 - val_accuracy: 0.7001 - penalty: 2e-05\n",
            "hidden layer sizes: [44, 17, 41, 61, 237], total units: 400\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8669259548187256 - val_accuracy: 0.7001 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 37, 61, 81, 284], total units: 527\n",
            "Before pruning:\n",
            "loss: 0.9688540697097778 - accuracy: 0.6572 - val_loss: 0.8404538035392761 - val_accuracy: 0.7055 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 37, 61, 81, 284], total units: 527\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8408623933792114 - val_accuracy: 0.705 - penalty: 2e-05\n",
            "hidden layer sizes: [40, 18, 35, 62, 225], total units: 380\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8408623933792114 - val_accuracy: 0.705 - penalty: 2e-05\n",
            "hidden layer sizes: [40, 18, 35, 62, 225], total units: 380\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8408622145652771 - val_accuracy: 0.705 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 38, 55, 82, 270], total units: 505\n",
            "Before pruning:\n",
            "loss: 0.9569295048713684 - accuracy: 0.66344 - val_loss: 0.8250074982643127 - val_accuracy: 0.7148 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 38, 55, 82, 270], total units: 505\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8250020742416382 - val_accuracy: 0.7149 - penalty: 2e-05\n",
            "hidden layer sizes: [38, 17, 36, 65, 268], total units: 424\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8250020742416382 - val_accuracy: 0.7149 - penalty: 2e-05\n",
            "hidden layer sizes: [38, 17, 36, 65, 268], total units: 424\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8250022530555725 - val_accuracy: 0.7149 - penalty: 2e-05\n",
            "hidden layer sizes: [58, 37, 56, 85, 321], total units: 557\n",
            "Before pruning:\n",
            "loss: 0.9523905515670776 - accuracy: 0.6648 - val_loss: 0.8342506885528564 - val_accuracy: 0.7065 - penalty: 2e-05\n",
            "hidden layer sizes: [58, 37, 56, 85, 321], total units: 557\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8341097831726074 - val_accuracy: 0.7063 - penalty: 2e-05\n",
            "hidden layer sizes: [34, 17, 35, 62, 284], total units: 432\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8341097831726074 - val_accuracy: 0.7063 - penalty: 2e-05\n",
            "hidden layer sizes: [34, 17, 35, 62, 284], total units: 432\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.8341097831726074 - val_accuracy: 0.7063 - penalty: 2e-05\n",
            "hidden layer sizes: [54, 37, 55, 82, 340], total units: 568\n",
            "Before pruning:\n",
            "loss: 0.9467862248420715 - accuracy: 0.66608 - val_loss: 0.8243851661682129 - val_accuracy: 0.7108 - penalty: 2e-05\n",
            "hidden layer sizes: [54, 37, 55, 82, 340], total units: 568\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.8243767619132996 - val_accuracy: 0.7105 - penalty: 2e-05\n",
            "hidden layer sizes: [35, 19, 44, 68, 285], total units: 451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "\n",
        "model = get_convolutional_model(regularization_penalty=0.00002, regularization_method='weighted_l1_reordered', layer_sizes=[100, 100, 100, 100, 100], output_neurons=10)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0006)\n",
        "\n",
        "history = model.fit(X_train_norm, y_train, optimizer, epochs=20, self_scaling_epochs=20, batch_size=batch_size, \n",
        "                    min_new_neurons=20, validation_data=(X_test_norm, y_test), pruning_only_epochs=0, \n",
        "                    growth_percentage=0.2, verbose=True)"
      ],
      "metadata": {
        "id": "yNZABZej0HVd",
        "outputId": "d5b485e3-ff9d-4adb-c40a-b010060f6f3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8939507007598877 - val_accuracy: 0.1005 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8939504623413086 - val_accuracy: 0.1005 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "Before pruning:\n",
            "loss: 1.7473422288894653 - accuracy: 0.39658 - val_loss: 1.4361164569854736 - val_accuracy: 0.4886 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.436206579208374 - val_accuracy: 0.4881 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 106], total units: 506\n",
            "##########################################################\n",
            "Epoch 2/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.436206579208374 - val_accuracy: 0.4881 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 106], total units: 506\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4362064599990845 - val_accuracy: 0.4881 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 127], total units: 607\n",
            "Before pruning:\n",
            "loss: 1.677731990814209 - accuracy: 0.40232 - val_loss: 1.4387489557266235 - val_accuracy: 0.4833 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 127], total units: 607\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.4385145902633667 - val_accuracy: 0.4839 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 99, 98, 96, 124], total units: 517\n",
            "##########################################################\n",
            "Epoch 3/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4385145902633667 - val_accuracy: 0.4839 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 99, 98, 96, 124], total units: 517\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.4385145902633667 - val_accuracy: 0.4839 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 119, 118, 116, 148], total units: 621\n",
            "Before pruning:\n",
            "loss: 1.5032627582550049 - accuracy: 0.45452 - val_loss: 1.3018602132797241 - val_accuracy: 0.5344 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 119, 118, 116, 148], total units: 621\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.3016899824142456 - val_accuracy: 0.5344 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 76, 76, 60, 126], total units: 438\n",
            "##########################################################\n",
            "Epoch 4/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.3016899824142456 - val_accuracy: 0.5344 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 76, 76, 60, 126], total units: 438\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.3016901016235352 - val_accuracy: 0.5344 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 96, 96, 80, 151], total units: 543\n",
            "Before pruning:\n",
            "loss: 1.3952487707138062 - accuracy: 0.4962 - val_loss: 1.220427393913269 - val_accuracy: 0.5601 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 96, 96, 80, 151], total units: 543\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.220436692237854 - val_accuracy: 0.56 - penalty: 2e-05\n",
            "hidden layer sizes: [97, 28, 47, 80, 134], total units: 386\n",
            "##########################################################\n",
            "Epoch 5/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.220436692237854 - val_accuracy: 0.56 - penalty: 2e-05\n",
            "hidden layer sizes: [97, 28, 47, 80, 134], total units: 386\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.2204365730285645 - val_accuracy: 0.56 - penalty: 2e-05\n",
            "hidden layer sizes: [117, 48, 67, 100, 160], total units: 492\n",
            "Before pruning:\n",
            "loss: 1.3192065954208374 - accuracy: 0.52716 - val_loss: 1.153975486755371 - val_accuracy: 0.5824 - penalty: 2e-05\n",
            "hidden layer sizes: [117, 48, 67, 100, 160], total units: 492\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1539466381072998 - val_accuracy: 0.5824 - penalty: 2e-05\n",
            "hidden layer sizes: [81, 18, 30, 50, 155], total units: 334\n",
            "##########################################################\n",
            "Epoch 6/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1539466381072998 - val_accuracy: 0.5824 - penalty: 2e-05\n",
            "hidden layer sizes: [81, 18, 30, 50, 155], total units: 334\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1539466381072998 - val_accuracy: 0.5824 - penalty: 2e-05\n",
            "hidden layer sizes: [101, 38, 50, 70, 186], total units: 445\n",
            "Before pruning:\n",
            "loss: 1.2823785543441772 - accuracy: 0.53958 - val_loss: 1.1207634210586548 - val_accuracy: 0.5982 - penalty: 2e-05\n",
            "hidden layer sizes: [101, 38, 50, 70, 186], total units: 445\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1207762956619263 - val_accuracy: 0.5986 - penalty: 2e-05\n",
            "hidden layer sizes: [73, 17, 26, 37, 170], total units: 323\n",
            "##########################################################\n",
            "Epoch 7/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1207762956619263 - val_accuracy: 0.5986 - penalty: 2e-05\n",
            "hidden layer sizes: [73, 17, 26, 37, 170], total units: 323\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1207762956619263 - val_accuracy: 0.5986 - penalty: 2e-05\n",
            "hidden layer sizes: [93, 37, 46, 57, 204], total units: 437\n",
            "Before pruning:\n",
            "loss: 1.2580077648162842 - accuracy: 0.549 - val_loss: 1.1123729944229126 - val_accuracy: 0.6108 - penalty: 2e-05\n",
            "hidden layer sizes: [93, 37, 46, 57, 204], total units: 437\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.1123605966567993 - val_accuracy: 0.6107 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 15, 25, 33, 192], total units: 330\n",
            "##########################################################\n",
            "Epoch 8/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1123605966567993 - val_accuracy: 0.6107 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 15, 25, 33, 192], total units: 330\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.1123605966567993 - val_accuracy: 0.6107 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 35, 45, 53, 230], total units: 448\n",
            "Before pruning:\n",
            "loss: 1.2325387001037598 - accuracy: 0.55746 - val_loss: 1.057499885559082 - val_accuracy: 0.6235 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 35, 45, 53, 230], total units: 448\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0574957132339478 - val_accuracy: 0.6236 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 15, 27, 53, 223], total units: 375\n",
            "##########################################################\n",
            "Epoch 9/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0574957132339478 - val_accuracy: 0.6236 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 15, 27, 53, 223], total units: 375\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0574957132339478 - val_accuracy: 0.6236 - penalty: 2e-05\n",
            "hidden layer sizes: [77, 35, 47, 73, 267], total units: 499\n",
            "Before pruning:\n",
            "loss: 1.206843614578247 - accuracy: 0.5693 - val_loss: 1.0597469806671143 - val_accuracy: 0.6176 - penalty: 2e-05\n",
            "hidden layer sizes: [77, 35, 47, 73, 267], total units: 499\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0596445798873901 - val_accuracy: 0.6179 - penalty: 2e-05\n",
            "hidden layer sizes: [51, 15, 30, 73, 249], total units: 418\n",
            "##########################################################\n",
            "Epoch 10/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0596445798873901 - val_accuracy: 0.6179 - penalty: 2e-05\n",
            "hidden layer sizes: [51, 15, 30, 73, 249], total units: 418\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0596445798873901 - val_accuracy: 0.6179 - penalty: 2e-05\n",
            "hidden layer sizes: [71, 35, 50, 93, 298], total units: 547\n",
            "Before pruning:\n",
            "loss: 1.185500979423523 - accuracy: 0.57732 - val_loss: 1.0105369091033936 - val_accuracy: 0.6453 - penalty: 2e-05\n",
            "hidden layer sizes: [71, 35, 50, 93, 298], total units: 547\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.010555386543274 - val_accuracy: 0.6452 - penalty: 2e-05\n",
            "hidden layer sizes: [48, 15, 26, 56, 265], total units: 410\n",
            "##########################################################\n",
            "Epoch 11/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.010555386543274 - val_accuracy: 0.6452 - penalty: 2e-05\n",
            "hidden layer sizes: [48, 15, 26, 56, 265], total units: 410\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.010555386543274 - val_accuracy: 0.6452 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 35, 46, 76, 318], total units: 543\n",
            "Before pruning:\n",
            "loss: 1.1761764287948608 - accuracy: 0.57728 - val_loss: 0.9887935519218445 - val_accuracy: 0.6441 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 35, 46, 76, 318], total units: 543\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9887959957122803 - val_accuracy: 0.644 - penalty: 2e-05\n",
            "hidden layer sizes: [46, 14, 32, 70, 271], total units: 433\n",
            "##########################################################\n",
            "Epoch 12/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9887959957122803 - val_accuracy: 0.644 - penalty: 2e-05\n",
            "hidden layer sizes: [46, 14, 32, 70, 271], total units: 433\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9887959957122803 - val_accuracy: 0.644 - penalty: 2e-05\n",
            "hidden layer sizes: [66, 34, 52, 90, 325], total units: 567\n",
            "Before pruning:\n",
            "loss: 1.1645961999893188 - accuracy: 0.58416 - val_loss: 1.0151164531707764 - val_accuracy: 0.6424 - penalty: 2e-05\n",
            "hidden layer sizes: [66, 34, 52, 90, 325], total units: 567\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 1.0147064924240112 - val_accuracy: 0.6428 - penalty: 2e-05\n",
            "hidden layer sizes: [39, 13, 31, 65, 233], total units: 381\n",
            "##########################################################\n",
            "Epoch 13/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0147064924240112 - val_accuracy: 0.6428 - penalty: 2e-05\n",
            "hidden layer sizes: [39, 13, 31, 65, 233], total units: 381\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 1.0147064924240112 - val_accuracy: 0.6428 - penalty: 2e-05\n",
            "hidden layer sizes: [59, 33, 51, 85, 279], total units: 507\n",
            "Before pruning:\n",
            "loss: 1.13856041431427 - accuracy: 0.59534 - val_loss: 0.9703090786933899 - val_accuracy: 0.658 - penalty: 2e-05\n",
            "hidden layer sizes: [59, 33, 51, 85, 279], total units: 507\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9702850580215454 - val_accuracy: 0.6582 - penalty: 2e-05\n",
            "hidden layer sizes: [37, 13, 25, 71, 207], total units: 353\n",
            "##########################################################\n",
            "Epoch 14/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9702850580215454 - val_accuracy: 0.6582 - penalty: 2e-05\n",
            "hidden layer sizes: [37, 13, 25, 71, 207], total units: 353\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.970285177230835 - val_accuracy: 0.6582 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 33, 45, 91, 248], total units: 474\n",
            "Before pruning:\n",
            "loss: 1.1257309913635254 - accuracy: 0.59814 - val_loss: 0.974070131778717 - val_accuracy: 0.6555 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 33, 45, 91, 248], total units: 474\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.974126935005188 - val_accuracy: 0.6559 - penalty: 2e-05\n",
            "hidden layer sizes: [38, 13, 26, 82, 214], total units: 373\n",
            "##########################################################\n",
            "Epoch 15/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.974126935005188 - val_accuracy: 0.6559 - penalty: 2e-05\n",
            "hidden layer sizes: [38, 13, 26, 82, 214], total units: 373\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9741270542144775 - val_accuracy: 0.6559 - penalty: 2e-05\n",
            "hidden layer sizes: [58, 33, 46, 102, 256], total units: 495\n",
            "Before pruning:\n",
            "loss: 1.1114637851715088 - accuracy: 0.60682 - val_loss: 0.9480355381965637 - val_accuracy: 0.6654 - penalty: 2e-05\n",
            "hidden layer sizes: [58, 33, 46, 102, 256], total units: 495\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9481191635131836 - val_accuracy: 0.6653 - penalty: 2e-05\n",
            "hidden layer sizes: [40, 13, 30, 102, 215], total units: 400\n",
            "##########################################################\n",
            "Epoch 16/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9481191635131836 - val_accuracy: 0.6653 - penalty: 2e-05\n",
            "hidden layer sizes: [40, 13, 30, 102, 215], total units: 400\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9481191635131836 - val_accuracy: 0.6653 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 33, 50, 122, 258], total units: 523\n",
            "Before pruning:\n",
            "loss: 1.1002287864685059 - accuracy: 0.6085 - val_loss: 0.9465226531028748 - val_accuracy: 0.6704 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 33, 50, 122, 258], total units: 523\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9466623067855835 - val_accuracy: 0.6704 - penalty: 2e-05\n",
            "hidden layer sizes: [39, 13, 28, 90, 240], total units: 410\n",
            "##########################################################\n",
            "Epoch 17/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9466623067855835 - val_accuracy: 0.6704 - penalty: 2e-05\n",
            "hidden layer sizes: [39, 13, 28, 90, 240], total units: 410\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.946662187576294 - val_accuracy: 0.6704 - penalty: 2e-05\n",
            "hidden layer sizes: [59, 33, 48, 110, 288], total units: 538\n",
            "Before pruning:\n",
            "loss: 1.0925538539886475 - accuracy: 0.61188 - val_loss: 0.9606273174285889 - val_accuracy: 0.6647 - penalty: 2e-05\n",
            "hidden layer sizes: [59, 33, 48, 110, 288], total units: 538\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9605926871299744 - val_accuracy: 0.6645 - penalty: 2e-05\n",
            "hidden layer sizes: [37, 13, 31, 84, 266], total units: 431\n",
            "##########################################################\n",
            "Epoch 18/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9605926871299744 - val_accuracy: 0.6645 - penalty: 2e-05\n",
            "hidden layer sizes: [37, 13, 31, 84, 266], total units: 431\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9605926871299744 - val_accuracy: 0.6645 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 33, 51, 104, 319], total units: 564\n",
            "Before pruning:\n",
            "loss: 1.0852175951004028 - accuracy: 0.61362 - val_loss: 0.920579195022583 - val_accuracy: 0.6731 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 33, 51, 104, 319], total units: 564\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9205239415168762 - val_accuracy: 0.6733 - penalty: 2e-05\n",
            "hidden layer sizes: [37, 13, 31, 89, 273], total units: 443\n",
            "##########################################################\n",
            "Epoch 19/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9205239415168762 - val_accuracy: 0.6733 - penalty: 2e-05\n",
            "hidden layer sizes: [37, 13, 31, 89, 273], total units: 443\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.920524001121521 - val_accuracy: 0.6733 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 33, 51, 109, 327], total units: 577\n",
            "Before pruning:\n",
            "loss: 1.077634572982788 - accuracy: 0.6164 - val_loss: 0.9266952872276306 - val_accuracy: 0.6774 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 33, 51, 109, 327], total units: 577\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9266478419303894 - val_accuracy: 0.6773 - penalty: 2e-05\n",
            "hidden layer sizes: [40, 13, 30, 100, 308], total units: 491\n",
            "##########################################################\n",
            "Epoch 20/20\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9266478419303894 - val_accuracy: 0.6773 - penalty: 2e-05\n",
            "hidden layer sizes: [40, 13, 30, 100, 308], total units: 491\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 0.9266478419303894 - val_accuracy: 0.6773 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 33, 50, 120, 369], total units: 632\n",
            "Before pruning:\n",
            "loss: 1.0724891424179077 - accuracy: 0.61908 - val_loss: 0.9140296578407288 - val_accuracy: 0.6811 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 33, 50, 120, 369], total units: 632\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 0.9139829874038696 - val_accuracy: 0.6815 - penalty: 2e-05\n",
            "hidden layer sizes: [37, 13, 34, 95, 318], total units: 497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "histories = cross_validate(train_fn, X_norm, y, n_splits=6, learning_rate=0.0006,\n",
        "                           regularization_penalty=0.00002, regularization_method='weighted_l1_reordered',\n",
        "                           self_scaling_epochs=20, layer_sizes=[100, 100, 100, 100, 100])"
      ],
      "metadata": {
        "id": "Hs6wXPoL4MFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Xjdr-TaRdui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84572bce-9e00-49f5-ccc3-3266ea8762e9"
      },
      "source": [
        "%%time\n",
        "\n",
        "histories = hyperparameter_search(train_fn, learning_rate=[0.00005, 0.0002, 0.0006], \n",
        "                                  regularization_penalty=[0.00002], regularization_method=['weighted_l1'], \n",
        "                                  self_scaling_epochs=[20], layer_sizes=[[100, 100, 100, 100, 100]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (5e-05, 2e-05, 'weighted_l1', 20, [100, 100, 100, 100, 100]) completed, best_val_accuracy: 0.7074, final_hidden_layer sizes: [100, 46, 47, 53, 71]\n",
            "Run with parameters (0.0002, 2e-05, 'weighted_l1', 20, [100, 100, 100, 100, 100]) completed, best_val_accuracy: 0.7496, final_hidden_layer sizes: [50, 25, 23, 60, 86]\n",
            "Run with parameters (0.0006, 2e-05, 'weighted_l1', 20, [100, 100, 100, 100, 100]) completed, best_val_accuracy: 0.7554, final_hidden_layer sizes: [36, 15, 30, 81, 266]\n",
            "Best overall combination: (0.0006, 2e-05, 'weighted_l1', 20, [100, 100, 100, 100, 100]), val_accuracy: 0.7554\n",
            "CPU times: user 27min 12s, sys: 31.1 s, total: 27min 43s\n",
            "Wall time: 27min 44s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlUE6-_XSirS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a86597f1-4912-4097-d1fd-fadd79b5391e"
      },
      "source": [
        "%%time\n",
        "\n",
        "histories = cross_validate(train_fn, X_norm, y, n_splits=6, learning_rate=0.0006,\n",
        "                           regularization_penalty=0.00002, regularization_method='weighted_l1',\n",
        "                           self_scaling_epochs=20, layer_sizes=[100, 100, 100, 100, 100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best_val_accuracy: 0.7661, final_hidden_layer sizes: [36, 16, 42, 81, 275]\n",
            "Run 1 completed, best_val_accuracy: 0.7548, final_hidden_layer sizes: [32, 17, 25, 93, 244]\n",
            "Run 2 completed, best_val_accuracy: 0.7611, final_hidden_layer sizes: [29, 17, 32, 80, 244]\n",
            "Run 3 completed, best_val_accuracy: 0.7671, final_hidden_layer sizes: [32, 17, 28, 61, 332]\n",
            "Run 4 completed, best_val_accuracy: 0.7603, final_hidden_layer sizes: [31, 18, 38, 72, 294]\n",
            "Run 5 completed, best_val_accuracy: 0.7689, final_hidden_layer sizes: [34, 16, 37, 71, 316]\n",
            "mean_best_val_accuracy: 0.7630500000000001\n",
            "mean_final_hidden_layer_sizes: [32.333333333333336, 16.833333333333332, 33.666666666666664, 76.33333333333333, 284.1666666666667]\n",
            "CPU times: user 54min 56s, sys: 1min 3s, total: 56min\n",
            "Wall time: 55min 15s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDegWc-xH-I0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3df413ac-8c66-4a07-da16-ece0795e67d2"
      },
      "source": [
        "histories = hyperparameter_search(train_fn, learning_rate=[0.0005, 0.002, 0.006], \n",
        "                                  regularization_penalty=[0.], regularization_method=[None], \n",
        "                                  self_scaling_epochs=[0], layer_sizes=[[32, 17, 34, 76, 284]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0005, 0.0, None, 0, [32, 17, 34, 76, 284]) completed, best_val_accuracy: 0.6696, final_hidden_layer sizes: [32, 17, 34, 76, 284]\n",
            "Run with parameters (0.002, 0.0, None, 0, [32, 17, 34, 76, 284]) completed, best_val_accuracy: 0.7203, final_hidden_layer sizes: [32, 17, 34, 76, 284]\n",
            "Run with parameters (0.006, 0.0, None, 0, [32, 17, 34, 76, 284]) completed, best_val_accuracy: 0.5657, final_hidden_layer sizes: [32, 17, 34, 76, 284]\n",
            "Best overall combination: (0.002, 0.0, None, 0, [32, 17, 34, 76, 284]), val_accuracy: 0.7203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6Tc8v-bI-Q5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c183254-9183-447f-d5ce-495f082b7fb3"
      },
      "source": [
        "histories = cross_validate(train_fn, X_norm, y, n_splits=6, learning_rate=0.002,\n",
        "                           regularization_penalty=0., regularization_method=None,\n",
        "                           self_scaling_epochs=0, layer_sizes=[32, 17, 34, 76, 284])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best_val_accuracy: 0.7183, final_hidden_layer sizes: [32, 17, 34, 76, 284]\n",
            "Run 1 completed, best_val_accuracy: 0.7177, final_hidden_layer sizes: [32, 17, 34, 76, 284]\n",
            "Run 2 completed, best_val_accuracy: 0.7154, final_hidden_layer sizes: [32, 17, 34, 76, 284]\n",
            "Run 3 completed, best_val_accuracy: 0.7285, final_hidden_layer sizes: [32, 17, 34, 76, 284]\n",
            "Run 4 completed, best_val_accuracy: 0.7061, final_hidden_layer sizes: [32, 17, 34, 76, 284]\n",
            "Run 5 completed, best_val_accuracy: 0.7166, final_hidden_layer sizes: [32, 17, 34, 76, 284]\n",
            "mean_best_val_accuracy: 0.7170999999999998\n",
            "mean_final_hidden_layer_sizes: [32.0, 17.0, 34.0, 76.0, 284.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ul-93OxJP8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c7d9384-14b3-41a2-c557-38b7c5be6d80"
      },
      "source": [
        "model = get_convolutional_model(regularization_penalty=0., regularization_method=None, layer_sizes=[32, 17, 34, 76, 284])\n",
        "model.build(X_norm.shape)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_36 (Conv2D)           multiple                  896       \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           multiple                  4913      \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           multiple                  5236      \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           multiple                  23332     \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             multiple                  1381660   \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             multiple                  2850      \n",
            "=================================================================\n",
            "Total params: 1,418,887\n",
            "Trainable params: 1,418,887\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8t_OOXohXj0h",
        "outputId": "5296d14e-e979-4b03-9df4-ead67c68448a"
      },
      "source": [
        "model = get_convolutional_model(regularization_penalty=0., regularization_method=None, layer_sizes=[71, 71, 71, 71, 284])\n",
        "model.build(X_norm.shape)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_68 (Conv2D)           multiple                  1988      \n",
            "_________________________________________________________________\n",
            "conv2d_69 (Conv2D)           multiple                  45440     \n",
            "_________________________________________________________________\n",
            "dropout_34 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv2d_70 (Conv2D)           multiple                  45440     \n",
            "_________________________________________________________________\n",
            "conv2d_71 (Conv2D)           multiple                  45440     \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten_17 (Flatten)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             multiple                  1290780   \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             multiple                  2850      \n",
            "=================================================================\n",
            "Total params: 1,431,938\n",
            "Trainable params: 1,431,938\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piss1dnQML-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0471852-2a0d-4f2f-8f73-2a371460a27f"
      },
      "source": [
        "%%time\n",
        "\n",
        "histories = hyperparameter_search(train_fn, learning_rate=[0.0005, 0.002, 0.006], \n",
        "                                  regularization_penalty=[0.], regularization_method=[None], \n",
        "                                  self_scaling_epochs=[0], layer_sizes=[[71, 71, 71, 71, 284]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0005, 0.0, None, 0, [71, 71, 71, 71, 284]) completed, best_val_accuracy: 0.7377, final_hidden_layer sizes: [71, 71, 71, 71, 284]\n",
            "Run with parameters (0.002, 0.0, None, 0, [71, 71, 71, 71, 284]) completed, best_val_accuracy: 0.7363, final_hidden_layer sizes: [71, 71, 71, 71, 284]\n",
            "Run with parameters (0.006, 0.0, None, 0, [71, 71, 71, 71, 284]) completed, best_val_accuracy: 0.1, final_hidden_layer sizes: [71, 71, 71, 71, 284]\n",
            "Best overall combination: (0.0005, 0.0, None, 0, [71, 71, 71, 71, 284]), val_accuracy: 0.7377\n",
            "CPU times: user 11min 50s, sys: 13 s, total: 12min 3s\n",
            "Wall time: 13min 22s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAFI6aIIYpry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87d9c092-d2fe-4da4-edd7-306135513ba5"
      },
      "source": [
        "%%time\n",
        "\n",
        "histories = cross_validate(train_fn, X_norm, y, n_splits=6, learning_rate=0.0005,\n",
        "                           regularization_penalty=0., regularization_method=None,\n",
        "                           self_scaling_epochs=0, layer_sizes=[71, 71, 71, 71, 284])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best_val_accuracy: 0.7418, final_hidden_layer sizes: [71, 71, 71, 71, 284]\n",
            "Run 1 completed, best_val_accuracy: 0.7336, final_hidden_layer sizes: [71, 71, 71, 71, 284]\n",
            "Run 2 completed, best_val_accuracy: 0.7415, final_hidden_layer sizes: [71, 71, 71, 71, 284]\n",
            "Run 3 completed, best_val_accuracy: 0.7389, final_hidden_layer sizes: [71, 71, 71, 71, 284]\n",
            "Run 4 completed, best_val_accuracy: 0.7345, final_hidden_layer sizes: [71, 71, 71, 71, 284]\n",
            "Run 5 completed, best_val_accuracy: 0.727, final_hidden_layer sizes: [71, 71, 71, 71, 284]\n",
            "mean_best_val_accuracy: 0.7362166666666666\n",
            "mean_final_hidden_layer_sizes: [71.0, 71.0, 71.0, 71.0, 284.0]\n",
            "CPU times: user 23min 38s, sys: 30.1 s, total: 24min 8s\n",
            "Wall time: 26min 44s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMXBfMaJdA5-"
      },
      "source": [
        "fashion_mnist = tf.keras.datasets.mnist\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "X_train = X_train.astype(dtype) / 255.0\n",
        "y_train = y_train.astype(dtype)\n",
        "X_test = X_test.astype(dtype)  / 255.0\n",
        "y_test = y_test.astype(dtype)\n",
        "\n",
        "X_train = np.reshape(X_train, (-1, 1))\n",
        "X_test = np.reshape(X_test, (-1, 1))\n",
        "\n",
        "X = np.concatenate((X_train, X_test), axis=0)\n",
        "y = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)  # Scaling all features together\n",
        "\n",
        "X_norm = scaler.transform(X)\n",
        "X_train_norm = scaler.transform(X_train)\n",
        "X_test_norm = scaler.transform(X_test)\n",
        "\n",
        "X_norm = np.reshape(X_norm, (-1, 28, 28))\n",
        "X_train_norm = np.reshape(X_train_norm, (-1, 28, 28))\n",
        "X_test_norm = np.reshape(X_test_norm, (-1, 28, 28))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nh4tkmCVvgrr"
      },
      "source": [
        "## Fashnion MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUjJ6WBbvhix"
      },
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "X_train = X_train.astype(dtype) / 255.0\n",
        "y_train = y_train.astype(dtype)\n",
        "X_test = X_test.astype(dtype)  / 255.0\n",
        "y_test = y_test.astype(dtype)\n",
        "\n",
        "X_train = np.reshape(X_train, (-1, 1))\n",
        "X_test = np.reshape(X_test, (-1, 1))\n",
        "\n",
        "X = np.concatenate((X_train, X_test), axis=0)\n",
        "y = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)  # Scaling all features together\n",
        "\n",
        "X_norm = scaler.transform(X)\n",
        "X_train_norm = scaler.transform(X_train)\n",
        "X_test_norm = scaler.transform(X_test)\n",
        "\n",
        "X_norm = np.reshape(X_norm, (-1, 28, 28, 1))\n",
        "X_train_norm = np.reshape(X_train_norm, (-1, 28, 28, 1))\n",
        "X_test_norm = np.reshape(X_test_norm, (-1, 28, 28, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Wd--pCev6uX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a2aa547-d134-4f27-f85f-67bd21b8abb7"
      },
      "source": [
        "%%time\n",
        "\n",
        "histories = hyperparameter_search(train_fn, learning_rate=[0.00005, 0.0002, 0.0006], \n",
        "                                  regularization_penalty=[0.00002], regularization_method=['weighted_l1'], \n",
        "                                  self_scaling_epochs=[20], layer_sizes=[[100, 100, 100, 100, 100]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (5e-05, 2e-05, 'weighted_l1', 20, [100, 100, 100, 100, 100]) completed, best_val_accuracy: 0.9158, final_hidden_layer sizes: [78, 21, 26, 43, 76]\n",
            "Run with parameters (0.0002, 2e-05, 'weighted_l1', 20, [100, 100, 100, 100, 100]) completed, best_val_accuracy: 0.9232, final_hidden_layer sizes: [42, 17, 16, 32, 46]\n",
            "Run with parameters (0.0006, 2e-05, 'weighted_l1', 20, [100, 100, 100, 100, 100]) completed, best_val_accuracy: 0.9306, final_hidden_layer sizes: [20, 13, 26, 51, 197]\n",
            "Best overall combination: (0.0006, 2e-05, 'weighted_l1', 20, [100, 100, 100, 100, 100]), val_accuracy: 0.9306\n",
            "CPU times: user 18min 26s, sys: 16.4 s, total: 18min 42s\n",
            "Wall time: 18min 57s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSDPL2ZqwIVX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a769191-78f3-4938-d819-c54cff1a95d6"
      },
      "source": [
        "%%time\n",
        "\n",
        "histories = cross_validate(train_fn, X_norm, y, n_splits=6, learning_rate=0.0006,\n",
        "                           regularization_penalty=0.00002, regularization_method='weighted_l1',\n",
        "                           self_scaling_epochs=20, layer_sizes=[100, 100, 100, 100, 100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best_val_accuracy: 0.9288, final_hidden_layer sizes: [17, 15, 22, 43, 168]\n",
            "Run 1 completed, best_val_accuracy: 0.9284, final_hidden_layer sizes: [19, 14, 20, 45, 196]\n",
            "Run 2 completed, best_val_accuracy: 0.9313, final_hidden_layer sizes: [20, 14, 24, 64, 198]\n",
            "Run 3 completed, best_val_accuracy: 0.9292, final_hidden_layer sizes: [28, 12, 25, 41, 181]\n",
            "Run 4 completed, best_val_accuracy: 0.9313, final_hidden_layer sizes: [23, 14, 27, 42, 172]\n",
            "Run 5 completed, best_val_accuracy: 0.9314, final_hidden_layer sizes: [23, 14, 23, 48, 186]\n",
            "mean_best_val_accuracy: 0.9300666666666667\n",
            "mean_final_hidden_layer_sizes: [21.666666666666668, 13.833333333333334, 23.5, 47.166666666666664, 183.5]\n",
            "CPU times: user 36min 47s, sys: 31.1 s, total: 37min 18s\n",
            "Wall time: 37min 18s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fD6d8MuL6H9w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8850789d-40e8-48e3-f12e-3f5893ef5b5d"
      },
      "source": [
        "%%time\n",
        "\n",
        "histories = hyperparameter_search(train_fn, learning_rate=[0.0005, 0.002, 0.006], \n",
        "                                  regularization_penalty=[0.], regularization_method=[None], \n",
        "                                  self_scaling_epochs=[0], layer_sizes=[[22, 14, 24, 47, 184]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0005, 0.0, None, 0, [22, 14, 24, 47, 184]) completed, best_val_accuracy: 0.9175, final_hidden_layer sizes: [22, 14, 24, 47, 184]\n",
            "Run with parameters (0.002, 0.0, None, 0, [22, 14, 24, 47, 184]) completed, best_val_accuracy: 0.9154, final_hidden_layer sizes: [22, 14, 24, 47, 184]\n",
            "Run with parameters (0.006, 0.0, None, 0, [22, 14, 24, 47, 184]) completed, best_val_accuracy: 0.8663, final_hidden_layer sizes: [22, 14, 24, 47, 184]\n",
            "Best overall combination: (0.0005, 0.0, None, 0, [22, 14, 24, 47, 184]), val_accuracy: 0.9175\n",
            "CPU times: user 11min 43s, sys: 9.79 s, total: 11min 53s\n",
            "Wall time: 11min 33s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnI5JZplC_DY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d38e1dcf-d829-457a-a5db-88d415d38a29"
      },
      "source": [
        "histories = cross_validate(train_fn, X_norm, y, n_splits=6, learning_rate=0.0005,\n",
        "                           regularization_penalty=0., regularization_method=None,\n",
        "                           self_scaling_epochs=0, layer_sizes=[22, 14, 24, 47, 184])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best_val_accuracy: 0.9207, final_hidden_layer sizes: [22, 14, 24, 47, 184]\n",
            "Run 1 completed, best_val_accuracy: 0.9216, final_hidden_layer sizes: [22, 14, 24, 47, 184]\n",
            "Run 2 completed, best_val_accuracy: 0.9195, final_hidden_layer sizes: [22, 14, 24, 47, 184]\n",
            "Run 3 completed, best_val_accuracy: 0.9179, final_hidden_layer sizes: [22, 14, 24, 47, 184]\n",
            "Run 4 completed, best_val_accuracy: 0.9158, final_hidden_layer sizes: [22, 14, 24, 47, 184]\n",
            "Run 5 completed, best_val_accuracy: 0.9152, final_hidden_layer sizes: [22, 14, 24, 47, 184]\n",
            "mean_best_val_accuracy: 0.91845\n",
            "mean_final_hidden_layer_sizes: [22.0, 14.0, 24.0, 47.0, 184.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYR_MWjeF0jn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de6b623-d6be-476e-f591-7102309346b8"
      },
      "source": [
        "model = get_convolutional_model(regularization_penalty=0., regularization_method=None, layer_sizes=[22, 14, 24, 47, 184])\n",
        "model.build(X_norm.shape)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_51\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_204 (Conv2D)          multiple                  220       \n",
            "_________________________________________________________________\n",
            "conv2d_205 (Conv2D)          multiple                  2786      \n",
            "_________________________________________________________________\n",
            "dropout_102 (Dropout)        multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv2d_206 (Conv2D)          multiple                  3048      \n",
            "_________________________________________________________________\n",
            "conv2d_207 (Conv2D)          multiple                  10199     \n",
            "_________________________________________________________________\n",
            "dropout_103 (Dropout)        multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten_51 (Flatten)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_102 (Dense)            multiple                  423936    \n",
            "_________________________________________________________________\n",
            "dense_103 (Dense)            multiple                  1850      \n",
            "=================================================================\n",
            "Total params: 442,039\n",
            "Trainable params: 442,039\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGVLULE7LfrG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2fbe56e-a475-4cc9-9c11-0ece35ea5bdf"
      },
      "source": [
        "model = get_convolutional_model(regularization_penalty=0., regularization_method=None, layer_sizes=[43, 43, 43, 43, 184])\n",
        "model.build(X_norm.shape)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_55\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_220 (Conv2D)          multiple                  430       \n",
            "_________________________________________________________________\n",
            "conv2d_221 (Conv2D)          multiple                  16684     \n",
            "_________________________________________________________________\n",
            "dropout_110 (Dropout)        multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv2d_222 (Conv2D)          multiple                  16684     \n",
            "_________________________________________________________________\n",
            "conv2d_223 (Conv2D)          multiple                  16684     \n",
            "_________________________________________________________________\n",
            "dropout_111 (Dropout)        multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten_55 (Flatten)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_110 (Dense)            multiple                  387872    \n",
            "_________________________________________________________________\n",
            "dense_111 (Dense)            multiple                  1850      \n",
            "=================================================================\n",
            "Total params: 440,204\n",
            "Trainable params: 440,204\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPFNNQVELj--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaf5e50c-c264-4aa0-f9b5-ea7dea68c16c"
      },
      "source": [
        "%%time\n",
        "\n",
        "histories = hyperparameter_search(train_fn, learning_rate=[0.0002, 0.0005, 0.002, 0.006], \n",
        "                                  regularization_penalty=[0.], regularization_method=[None], \n",
        "                                  self_scaling_epochs=[0], layer_sizes=[[43, 43, 43, 43, 184]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0002, 0.0, None, 0, [43, 43, 43, 43, 184]) completed, best_val_accuracy: 0.9236, final_hidden_layer sizes: [43, 43, 43, 43, 184]\n",
            "Run with parameters (0.0005, 0.0, None, 0, [43, 43, 43, 43, 184]) completed, best_val_accuracy: 0.9276, final_hidden_layer sizes: [43, 43, 43, 43, 184]\n",
            "Run with parameters (0.002, 0.0, None, 0, [43, 43, 43, 43, 184]) completed, best_val_accuracy: 0.9145, final_hidden_layer sizes: [43, 43, 43, 43, 184]\n",
            "Run with parameters (0.006, 0.0, None, 0, [43, 43, 43, 43, 184]) completed, best_val_accuracy: 0.8717, final_hidden_layer sizes: [43, 43, 43, 43, 184]\n",
            "Best overall combination: (0.0005, 0.0, None, 0, [43, 43, 43, 43, 184]), val_accuracy: 0.9276\n",
            "CPU times: user 15min 40s, sys: 13.4 s, total: 15min 53s\n",
            "Wall time: 15min 32s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOiBdQDXLzMv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae2aae8b-4a2a-4056-fc9e-8aa231bee25b"
      },
      "source": [
        "histories = cross_validate(train_fn, X_norm, y, n_splits=6, learning_rate=0.0005,\n",
        "                           regularization_penalty=0., regularization_method=None,\n",
        "                           self_scaling_epochs=0, layer_sizes=[43, 43, 43, 43, 184])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best_val_accuracy: 0.9243, final_hidden_layer sizes: [43, 43, 43, 43, 184]\n",
            "Run 1 completed, best_val_accuracy: 0.9249, final_hidden_layer sizes: [43, 43, 43, 43, 184]\n",
            "Run 2 completed, best_val_accuracy: 0.9244, final_hidden_layer sizes: [43, 43, 43, 43, 184]\n",
            "Run 3 completed, best_val_accuracy: 0.9287, final_hidden_layer sizes: [43, 43, 43, 43, 184]\n",
            "Run 4 completed, best_val_accuracy: 0.9232, final_hidden_layer sizes: [43, 43, 43, 43, 184]\n",
            "Run 5 completed, best_val_accuracy: 0.9239, final_hidden_layer sizes: [43, 43, 43, 43, 184]\n",
            "mean_best_val_accuracy: 0.9249\n",
            "mean_final_hidden_layer_sizes: [43.0, 43.0, 43.0, 43.0, 184.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wp_mqLzVS-LJ"
      },
      "source": [
        "# MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M38DSB38S_AY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da6eaa43-881f-4112-b86d-c22e5c74b25d"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.astype(dtype) / 255.0\n",
        "y_train = y_train.astype(dtype)\n",
        "X_test = X_test.astype(dtype)  / 255.0\n",
        "y_test = y_test.astype(dtype)\n",
        "\n",
        "X_train = np.reshape(X_train, (-1, 1))\n",
        "X_test = np.reshape(X_test, (-1, 1))\n",
        "\n",
        "X = np.concatenate((X_train, X_test), axis=0)\n",
        "y = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)  # Scaling all features together\n",
        "\n",
        "X_norm = scaler.transform(X)\n",
        "X_train_norm = scaler.transform(X_train)\n",
        "X_test_norm = scaler.transform(X_test)\n",
        "\n",
        "X_norm = np.reshape(X_norm, (-1, 28, 28, 1))\n",
        "X_train_norm = np.reshape(X_train_norm, (-1, 28, 28, 1))\n",
        "X_test_norm = np.reshape(X_test_norm, (-1, 28, 28, 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlhRX3IwZF6h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "050289d7-707a-45cb-d1fa-9cb423f63c02"
      },
      "source": [
        "%%time\n",
        "\n",
        "histories = hyperparameter_search(train_fn, learning_rate=[0.00005, 0.0002, 0.0006], \n",
        "                                  regularization_penalty=[0.00002], regularization_method=['weighted_l1'], \n",
        "                                  self_scaling_epochs=[20], layer_sizes=[[100, 100, 100, 100, 100]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (5e-05, 2e-05, 'weighted_l1', 20, [100, 100, 100, 100, 100]) completed, best_val_accuracy: 0.9918, final_hidden_layer sizes: [59, 22, 20, 42, 67]\n",
            "Run with parameters (0.0002, 2e-05, 'weighted_l1', 20, [100, 100, 100, 100, 100]) completed, best_val_accuracy: 0.9935, final_hidden_layer sizes: [19, 17, 16, 35, 50]\n",
            "Run with parameters (0.0006, 2e-05, 'weighted_l1', 20, [100, 100, 100, 100, 100]) completed, best_val_accuracy: 0.9933, final_hidden_layer sizes: [17, 14, 17, 41, 156]\n",
            "Best overall combination: (0.0002, 2e-05, 'weighted_l1', 20, [100, 100, 100, 100, 100]), val_accuracy: 0.9935\n",
            "CPU times: user 18min 24s, sys: 16.1 s, total: 18min 40s\n",
            "Wall time: 18min 52s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDCoiaf_ZnXd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6886f90f-14e8-49de-bebd-a10ab3b2caf4"
      },
      "source": [
        "%%time\n",
        "\n",
        "histories = cross_validate(train_fn, X_norm, y, n_splits=6, learning_rate=0.0002,\n",
        "                           regularization_penalty=0.00002, regularization_method='weighted_l1',\n",
        "                           self_scaling_epochs=20, layer_sizes=[100, 100, 100, 100, 100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best_val_accuracy: 0.9929, final_hidden_layer sizes: [19, 18, 12, 36, 54]\n",
            "Run 1 completed, best_val_accuracy: 0.9931, final_hidden_layer sizes: [21, 20, 13, 32, 43]\n",
            "Run 2 completed, best_val_accuracy: 0.9927, final_hidden_layer sizes: [23, 19, 14, 30, 47]\n",
            "Run 3 completed, best_val_accuracy: 0.9938, final_hidden_layer sizes: [19, 20, 15, 31, 53]\n",
            "Run 4 completed, best_val_accuracy: 0.9928, final_hidden_layer sizes: [24, 18, 10, 36, 46]\n",
            "Run 5 completed, best_val_accuracy: 0.9936, final_hidden_layer sizes: [22, 16, 13, 33, 38]\n",
            "mean_best_val_accuracy: 0.99315\n",
            "mean_final_hidden_layer_sizes: [21.333333333333332, 18.5, 12.833333333333334, 33.0, 46.833333333333336]\n",
            "CPU times: user 36min 33s, sys: 32.2 s, total: 37min 5s\n",
            "Wall time: 37min 13s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IawGXihJhVIL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd3fc2d6-1ca0-4f80-89fd-c8797ca412b8"
      },
      "source": [
        "%%time\n",
        "\n",
        "histories = hyperparameter_search(train_fn, learning_rate=[0.0002, 0.0005, 0.002, 0.006], \n",
        "                                  regularization_penalty=[0.], regularization_method=[None], \n",
        "                                  self_scaling_epochs=[0], layer_sizes=[[21, 19, 13, 33, 47]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0002, 0.0, None, 0, [21, 19, 13, 33, 47]) completed, best_val_accuracy: 0.9919, final_hidden_layer sizes: [21, 19, 13, 33, 47]\n",
            "Run with parameters (0.0005, 0.0, None, 0, [21, 19, 13, 33, 47]) completed, best_val_accuracy: 0.9937, final_hidden_layer sizes: [21, 19, 13, 33, 47]\n",
            "Run with parameters (0.002, 0.0, None, 0, [21, 19, 13, 33, 47]) completed, best_val_accuracy: 0.9913, final_hidden_layer sizes: [21, 19, 13, 33, 47]\n",
            "Run with parameters (0.006, 0.0, None, 0, [21, 19, 13, 33, 47]) completed, best_val_accuracy: 0.9818, final_hidden_layer sizes: [21, 19, 13, 33, 47]\n",
            "Best overall combination: (0.0005, 0.0, None, 0, [21, 19, 13, 33, 47]), val_accuracy: 0.9937\n",
            "CPU times: user 15min 31s, sys: 12.9 s, total: 15min 44s\n",
            "Wall time: 15min 18s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4sjFqDGrHbM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76ff7d84-7e4c-4e8d-ba2c-972236dbb7a6"
      },
      "source": [
        "%%time\n",
        "\n",
        "histories = cross_validate(train_fn, X_norm, y, n_splits=6, learning_rate=0.0005,\n",
        "                           regularization_penalty=0., regularization_method=None,\n",
        "                           self_scaling_epochs=0, layer_sizes=[21, 19, 13, 33, 47])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best_val_accuracy: 0.9934, final_hidden_layer sizes: [21, 19, 13, 33, 47]\n",
            "Run 1 completed, best_val_accuracy: 0.9913, final_hidden_layer sizes: [21, 19, 13, 33, 47]\n",
            "Run 2 completed, best_val_accuracy: 0.9928, final_hidden_layer sizes: [21, 19, 13, 33, 47]\n",
            "Run 3 completed, best_val_accuracy: 0.9927, final_hidden_layer sizes: [21, 19, 13, 33, 47]\n",
            "Run 4 completed, best_val_accuracy: 0.993, final_hidden_layer sizes: [21, 19, 13, 33, 47]\n",
            "Run 5 completed, best_val_accuracy: 0.993, final_hidden_layer sizes: [21, 19, 13, 33, 47]\n",
            "mean_best_val_accuracy: 0.9927000000000001\n",
            "mean_final_hidden_layer_sizes: [21.0, 19.0, 13.0, 33.0, 47.0]\n",
            "CPU times: user 23min 16s, sys: 21.4 s, total: 23min 38s\n",
            "Wall time: 23min 16s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-t1SWyk6v6Fa",
        "outputId": "95dbddfc-36db-4a7b-edbb-55be30633947"
      },
      "source": [
        "model = get_convolutional_model(regularization_penalty=0., regularization_method=None, layer_sizes=[21, 19, 13, 33, 47])\n",
        "model.build(X_norm.shape)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_24 (Conv2D)           multiple                  210       \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           multiple                  3610      \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           multiple                  2236      \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           multiple                  3894      \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             multiple                  76046     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             multiple                  480       \n",
            "=================================================================\n",
            "Total params: 86,476\n",
            "Trainable params: 86,476\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUdtUDeH3bo5",
        "outputId": "93fa53d7-8af2-4b41-8395-335e1aeab076"
      },
      "source": [
        "model = get_convolutional_model(regularization_penalty=0., regularization_method=None, layer_sizes=[28, 28, 28, 28, 47])\n",
        "model.build(X_norm.shape)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_32 (Conv2D)           multiple                  280       \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           multiple                  7084      \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           multiple                  7084      \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           multiple                  7084      \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             multiple                  64531     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             multiple                  480       \n",
            "=================================================================\n",
            "Total params: 86,543\n",
            "Trainable params: 86,543\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWUOnhN53pSR",
        "outputId": "354bdf82-c037-4d72-a6bd-08b1d5c1b42c"
      },
      "source": [
        "%%time\n",
        "\n",
        "histories = hyperparameter_search(train_fn, learning_rate=[0.0002, 0.0005, 0.002, 0.006], \n",
        "                                  regularization_penalty=[0.], regularization_method=[None], \n",
        "                                  self_scaling_epochs=[0], layer_sizes=[[28, 28, 28, 28, 47]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0002, 0.0, None, 0, [28, 28, 28, 28, 47]) completed, best_val_accuracy: 0.9925, final_hidden_layer sizes: [28, 28, 28, 28, 47]\n",
            "Run with parameters (0.0005, 0.0, None, 0, [28, 28, 28, 28, 47]) completed, best_val_accuracy: 0.992, final_hidden_layer sizes: [28, 28, 28, 28, 47]\n",
            "Run with parameters (0.002, 0.0, None, 0, [28, 28, 28, 28, 47]) completed, best_val_accuracy: 0.9914, final_hidden_layer sizes: [28, 28, 28, 28, 47]\n",
            "Run with parameters (0.006, 0.0, None, 0, [28, 28, 28, 28, 47]) completed, best_val_accuracy: 0.9812, final_hidden_layer sizes: [28, 28, 28, 28, 47]\n",
            "Best overall combination: (0.0002, 0.0, None, 0, [28, 28, 28, 28, 47]), val_accuracy: 0.9925\n",
            "CPU times: user 15min 18s, sys: 13.3 s, total: 15min 32s\n",
            "Wall time: 15min 6s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wPYFHGa33w-",
        "outputId": "0c7fb61a-d6fa-48e0-9d39-96dd35eaf57a"
      },
      "source": [
        "%%time\n",
        "\n",
        "histories = cross_validate(train_fn, X_norm, y, n_splits=6, learning_rate=0.0002,\n",
        "                           regularization_penalty=0., regularization_method=None,\n",
        "                           self_scaling_epochs=0, layer_sizes=[28, 28, 28, 28, 47])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best_val_accuracy: 0.9925, final_hidden_layer sizes: [28, 28, 28, 28, 47]\n",
            "Run 1 completed, best_val_accuracy: 0.9929, final_hidden_layer sizes: [28, 28, 28, 28, 47]\n",
            "Run 2 completed, best_val_accuracy: 0.9921, final_hidden_layer sizes: [28, 28, 28, 28, 47]\n",
            "Run 3 completed, best_val_accuracy: 0.9928, final_hidden_layer sizes: [28, 28, 28, 28, 47]\n",
            "Run 4 completed, best_val_accuracy: 0.9928, final_hidden_layer sizes: [28, 28, 28, 28, 47]\n",
            "Run 5 completed, best_val_accuracy: 0.9925, final_hidden_layer sizes: [28, 28, 28, 28, 47]\n",
            "mean_best_val_accuracy: 0.9925999999999999\n",
            "mean_final_hidden_layer_sizes: [28.0, 28.0, 28.0, 28.0, 47.0]\n",
            "CPU times: user 23min 4s, sys: 20.3 s, total: 23min 24s\n",
            "Wall time: 22min 46s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzMHztGzKpNG"
      },
      "source": [
        "## CIFAR100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4R2FQ1B76Or"
      },
      "source": [
        "cifar100 = tf.keras.datasets.cifar100\n",
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
        "\n",
        "X_train = X_train.astype(dtype) / 255.0\n",
        "y_train = y_train.astype(dtype)\n",
        "X_test = X_test.astype(dtype)  / 255.0\n",
        "y_test = y_test.astype(dtype)\n",
        "\n",
        "X_train = np.reshape(X_train, (-1, 3072))\n",
        "X_test = np.reshape(X_test, (-1, 3072))\n",
        "\n",
        "X = np.concatenate((X_train, X_test), axis=0)\n",
        "y = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)  # Scaling each feature independently\n",
        "\n",
        "X_norm = scaler.transform(X)\n",
        "X_train_norm = scaler.transform(X_train)\n",
        "X_test_norm = scaler.transform(X_test)\n",
        "\n",
        "X_norm = np.reshape(X_norm, (-1, 32, 32, 3))\n",
        "X_train_norm = np.reshape(X_train_norm, (-1, 32, 32, 3))\n",
        "X_test_norm = np.reshape(X_test_norm, (-1, 32, 32, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DpYmnqKKyb5",
        "outputId": "c7f7806e-4b69-4983-87fc-f47e97afbe23"
      },
      "source": [
        "%%time\n",
        "\n",
        "histories = hyperparameter_search(train_fn, learning_rate=[0.00005, 0.0002, 0.0006], \n",
        "                                  regularization_penalty=[0.00002], regularization_method=['weighted_l1'], \n",
        "                                  self_scaling_epochs=[20], layer_sizes=[[100, 100, 100, 100, 100]], output_neurons=[100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (5e-05, 2e-05, 'weighted_l1', 20, [100, 100, 100, 100, 100], 100) completed, best_val_accuracy: 0.4097, final_hidden_layer sizes: [100, 40, 48, 48, 100]\n",
            "Run with parameters (0.0002, 2e-05, 'weighted_l1', 20, [100, 100, 100, 100, 100], 100) completed, best_val_accuracy: 0.451, final_hidden_layer sizes: [69, 21, 33, 67, 193]\n",
            "Run with parameters (0.0006, 2e-05, 'weighted_l1', 20, [100, 100, 100, 100, 100], 100) completed, best_val_accuracy: 0.4063, final_hidden_layer sizes: [52, 21, 100, 124, 808]\n",
            "Best overall combination: (0.0002, 2e-05, 'weighted_l1', 20, [100, 100, 100, 100, 100], 100), val_accuracy: 0.451\n",
            "CPU times: user 18min 25s, sys: 19.1 s, total: 18min 45s\n",
            "Wall time: 20min 34s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuXxNaoFK9aw",
        "outputId": "fb62749c-0f12-475c-c02b-862fc8fb45c7"
      },
      "source": [
        "%%time\n",
        "\n",
        "histories = cross_validate(train_fn, X_norm, y, n_splits=6, learning_rate=0.0002,\n",
        "                           regularization_penalty=0.00002, regularization_method='weighted_l1',\n",
        "                           self_scaling_epochs=20, layer_sizes=[100, 100, 100, 100, 100], output_neurons=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best_val_accuracy: 0.4509, final_hidden_layer sizes: [65, 22, 30, 68, 200]\n",
            "Run 1 completed, best_val_accuracy: 0.4497, final_hidden_layer sizes: [63, 24, 31, 69, 206]\n",
            "Run 2 completed, best_val_accuracy: 0.4431, final_hidden_layer sizes: [63, 23, 28, 81, 189]\n",
            "Run 3 completed, best_val_accuracy: 0.4468, final_hidden_layer sizes: [65, 27, 32, 70, 206]\n",
            "Run 4 completed, best_val_accuracy: 0.459, final_hidden_layer sizes: [68, 19, 30, 69, 200]\n",
            "Run 5 completed, best_val_accuracy: 0.4536, final_hidden_layer sizes: [65, 24, 25, 75, 204]\n",
            "mean_best_val_accuracy: 0.4505166666666667\n",
            "mean_final_hidden_layer_sizes: [64.83333333333333, 23.166666666666668, 29.333333333333332, 72.0, 200.83333333333334]\n",
            "CPU times: user 36min 16s, sys: 35.5 s, total: 36min 52s\n",
            "Wall time: 39min 4s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRSh3YumfHYE",
        "outputId": "c53b344f-79db-44ba-c23a-20c942c92381"
      },
      "source": [
        "%%time\n",
        "\n",
        "histories = hyperparameter_search(train_fn, learning_rate=[0.0002, 0.0005, 0.002, 0.006], \n",
        "                                  regularization_penalty=[0.], regularization_method=[None], \n",
        "                                  self_scaling_epochs=[0], layer_sizes=[[65, 23, 29, 72, 201]], output_neurons=[100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0002, 0.0, None, 0, [65, 23, 29, 72, 201], 100) completed, best_val_accuracy: 0.3203, final_hidden_layer sizes: [65, 23, 29, 72, 201]\n",
            "Run with parameters (0.0005, 0.0, None, 0, [65, 23, 29, 72, 201], 100) completed, best_val_accuracy: 0.3173, final_hidden_layer sizes: [65, 23, 29, 72, 201]\n",
            "Run with parameters (0.002, 0.0, None, 0, [65, 23, 29, 72, 201], 100) completed, best_val_accuracy: 0.2612, final_hidden_layer sizes: [65, 23, 29, 72, 201]\n",
            "Run with parameters (0.006, 0.0, None, 0, [65, 23, 29, 72, 201], 100) completed, best_val_accuracy: 0.01, final_hidden_layer sizes: [65, 23, 29, 72, 201]\n",
            "Best overall combination: (0.0002, 0.0, None, 0, [65, 23, 29, 72, 201], 100), val_accuracy: 0.3203\n",
            "CPU times: user 15min 45s, sys: 28.4 s, total: 16min 13s\n",
            "Wall time: 15min 36s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRxerfK3ofRC",
        "outputId": "799ecfb2-a08b-434e-9432-2ed0858d0e09"
      },
      "source": [
        "%%time\n",
        "\n",
        "histories = hyperparameter_search(train_fn, learning_rate=[0.00005], \n",
        "                                  regularization_penalty=[0.], regularization_method=[None], \n",
        "                                  self_scaling_epochs=[0], layer_sizes=[[65, 23, 29, 72, 201]], output_neurons=[100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (5e-05, 0.0, None, 0, [65, 23, 29, 72, 201], 100) completed, best_val_accuracy: 0.3112, final_hidden_layer sizes: [65, 23, 29, 72, 201]\n",
            "Best overall combination: (5e-05, 0.0, None, 0, [65, 23, 29, 72, 201], 100), val_accuracy: 0.3112\n",
            "CPU times: user 3min 54s, sys: 6.71 s, total: 4min 1s\n",
            "Wall time: 3min 52s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTMd5Wy9sHz5",
        "outputId": "e1311cc5-86b2-43d7-b433-5b8c899cbb8b"
      },
      "source": [
        "%%time\n",
        "\n",
        "histories = cross_validate(train_fn, X_norm, y, n_splits=6, learning_rate=0.0002,\n",
        "                           regularization_penalty=0., regularization_method=None,\n",
        "                           self_scaling_epochs=0, layer_sizes=[65, 23, 29, 72, 201], output_neurons=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best_val_accuracy: 0.3274, final_hidden_layer sizes: [65, 23, 29, 72, 201]\n",
            "Run 1 completed, best_val_accuracy: 0.3229, final_hidden_layer sizes: [65, 23, 29, 72, 201]\n",
            "Run 2 completed, best_val_accuracy: 0.3256, final_hidden_layer sizes: [65, 23, 29, 72, 201]\n",
            "Run 3 completed, best_val_accuracy: 0.3191, final_hidden_layer sizes: [65, 23, 29, 72, 201]\n",
            "Run 4 completed, best_val_accuracy: 0.3226, final_hidden_layer sizes: [65, 23, 29, 72, 201]\n",
            "Run 5 completed, best_val_accuracy: 0.3247, final_hidden_layer sizes: [65, 23, 29, 72, 201]\n",
            "mean_best_val_accuracy: 0.3237166666666667\n",
            "mean_final_hidden_layer_sizes: [65.0, 23.0, 29.0, 72.0, 201.0]\n",
            "CPU times: user 23min 32s, sys: 21.1 s, total: 23min 53s\n",
            "Wall time: 22min 57s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upqkEH-Sv4YX",
        "outputId": "ec28ccd0-e5d6-4bac-e366-03566834cf76"
      },
      "source": [
        "model = get_convolutional_model(regularization_penalty=0., regularization_method=None, layer_sizes=[65, 23, 29, 72, 201], output_neurons=100)\n",
        "model.build(X_norm.shape)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_51\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_204 (Conv2D)          multiple                  1820      \n",
            "_________________________________________________________________\n",
            "conv2d_205 (Conv2D)          multiple                  13478     \n",
            "_________________________________________________________________\n",
            "dropout_102 (Dropout)        multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv2d_206 (Conv2D)          multiple                  6032      \n",
            "_________________________________________________________________\n",
            "conv2d_207 (Conv2D)          multiple                  18864     \n",
            "_________________________________________________________________\n",
            "dropout_103 (Dropout)        multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten_51 (Flatten)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_102 (Dense)            multiple                  926409    \n",
            "_________________________________________________________________\n",
            "dense_103 (Dense)            multiple                  20200     \n",
            "=================================================================\n",
            "Total params: 986,803\n",
            "Trainable params: 986,803\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQz5qYC03Qe2",
        "outputId": "428e3de1-3fbb-4ecf-b2ab-9e63dc99128d"
      },
      "source": [
        "model = get_convolutional_model(regularization_penalty=0., regularization_method=None, layer_sizes=[66, 66, 66, 66, 201], output_neurons=100)\n",
        "model.build(X_norm.shape)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_65\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_260 (Conv2D)          multiple                  1848      \n",
            "_________________________________________________________________\n",
            "conv2d_261 (Conv2D)          multiple                  39270     \n",
            "_________________________________________________________________\n",
            "dropout_130 (Dropout)        multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv2d_262 (Conv2D)          multiple                  39270     \n",
            "_________________________________________________________________\n",
            "conv2d_263 (Conv2D)          multiple                  39270     \n",
            "_________________________________________________________________\n",
            "dropout_131 (Dropout)        multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten_65 (Flatten)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_130 (Dense)            multiple                  849225    \n",
            "_________________________________________________________________\n",
            "dense_131 (Dense)            multiple                  20200     \n",
            "=================================================================\n",
            "Total params: 989,083\n",
            "Trainable params: 989,083\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zX3oQ5_s3Yfj",
        "outputId": "3aa7e7a8-7db8-49aa-c1f1-c934060149e2"
      },
      "source": [
        "%%time\n",
        "\n",
        "histories = hyperparameter_search(train_fn, learning_rate=[0.00005, 0.0002, 0.0005, 0.002, 0.006], \n",
        "                                  regularization_penalty=[0.], regularization_method=[None], \n",
        "                                  self_scaling_epochs=[0], layer_sizes=[[66, 66, 66, 66, 201]], output_neurons=[100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (5e-05, 0.0, None, 0, [66, 66, 66, 66, 201], 100) completed, best_val_accuracy: 0.3275, final_hidden_layer sizes: [66, 66, 66, 66, 201]\n",
            "Run with parameters (0.0002, 0.0, None, 0, [66, 66, 66, 66, 201], 100) completed, best_val_accuracy: 0.3547, final_hidden_layer sizes: [66, 66, 66, 66, 201]\n",
            "Run with parameters (0.0005, 0.0, None, 0, [66, 66, 66, 66, 201], 100) completed, best_val_accuracy: 0.3479, final_hidden_layer sizes: [66, 66, 66, 66, 201]\n",
            "Run with parameters (0.002, 0.0, None, 0, [66, 66, 66, 66, 201], 100) completed, best_val_accuracy: 0.3233, final_hidden_layer sizes: [66, 66, 66, 66, 201]\n",
            "Run with parameters (0.006, 0.0, None, 0, [66, 66, 66, 66, 201], 100) completed, best_val_accuracy: 0.01, final_hidden_layer sizes: [66, 66, 66, 66, 201]\n",
            "Best overall combination: (0.0002, 0.0, None, 0, [66, 66, 66, 66, 201], 100), val_accuracy: 0.3547\n",
            "CPU times: user 20min 10s, sys: 20.7 s, total: 20min 31s\n",
            "Wall time: 21min 51s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yx3V6b2v3kfV",
        "outputId": "4eef8045-8d7e-466d-97e4-41d24cdbdb19"
      },
      "source": [
        "%%time\n",
        "\n",
        "histories = cross_validate(train_fn, X_norm, y, n_splits=6, learning_rate=0.0002,\n",
        "                           regularization_penalty=0., regularization_method=None,\n",
        "                           self_scaling_epochs=0, layer_sizes=[66, 66, 66, 66, 201], output_neurons=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best_val_accuracy: 0.349, final_hidden_layer sizes: [66, 66, 66, 66, 201]\n",
            "Run 1 completed, best_val_accuracy: 0.372, final_hidden_layer sizes: [66, 66, 66, 66, 201]\n",
            "Run 2 completed, best_val_accuracy: 0.3374, final_hidden_layer sizes: [66, 66, 66, 66, 201]\n",
            "Run 3 completed, best_val_accuracy: 0.3614, final_hidden_layer sizes: [66, 66, 66, 66, 201]\n",
            "Run 4 completed, best_val_accuracy: 0.3378, final_hidden_layer sizes: [66, 66, 66, 66, 201]\n",
            "Run 5 completed, best_val_accuracy: 0.3616, final_hidden_layer sizes: [66, 66, 66, 66, 201]\n",
            "mean_best_val_accuracy: 0.3532\n",
            "mean_final_hidden_layer_sizes: [66.0, 66.0, 66.0, 66.0, 201.0]\n",
            "CPU times: user 24min 12s, sys: 24.8 s, total: 24min 37s\n",
            "Wall time: 26min 13s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBmtuVP-FdYG"
      },
      "source": [
        "## Street View House Numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-X11Iv29spy"
      },
      "source": [
        "from urllib.request import urlretrieve\n",
        "\n",
        "train_filename, _ = urlretrieve('http://ufldl.stanford.edu/housenumbers/train_32x32.mat')\n",
        "test_filename, _ = urlretrieve('http://ufldl.stanford.edu/housenumbers/test_32x32.mat')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEDjbGEGFiZW"
      },
      "source": [
        "from scipy import io\n",
        "\n",
        "X_train = io.loadmat(train_filename, variable_names='X').get('X')\n",
        "y_train = io.loadmat(train_filename, variable_names='y').get('y')\n",
        "X_test = io.loadmat(test_filename, variable_names='X').get('X')\n",
        "y_test = io.loadmat(test_filename, variable_names='y').get('y')\n",
        "\n",
        "X_train = np.moveaxis(X_train, -1, 0)\n",
        "y_train -= 1\n",
        "X_test = np.moveaxis(X_test, -1, 0)\n",
        "y_test -= 1\n",
        "\n",
        "X_train = X_train.astype(dtype) / 255.0\n",
        "y_train = y_train.astype(dtype)\n",
        "X_test = X_test.astype(dtype)  / 255.0\n",
        "y_test = y_test.astype(dtype)\n",
        "\n",
        "X_train = np.reshape(X_train, (-1, 3072))\n",
        "X_test = np.reshape(X_test, (-1, 3072))\n",
        "\n",
        "X = np.concatenate((X_train, X_test), axis=0)\n",
        "y = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)  # Scaling each feature independently\n",
        "\n",
        "X_norm = scaler.transform(X)\n",
        "X_train_norm = scaler.transform(X_train)\n",
        "X_test_norm = scaler.transform(X_test)\n",
        "\n",
        "X_norm = np.reshape(X_norm, (-1, 32, 32, 3))\n",
        "X_train_norm = np.reshape(X_train_norm, (-1, 32, 32, 3))\n",
        "X_test_norm = np.reshape(X_test_norm, (-1, 32, 32, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXWtQ5Q7IVsp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6875b727-f680-4c2d-9693-e5b5445401e1"
      },
      "source": [
        "%%time\n",
        "\n",
        "histories = hyperparameter_search(train_fn, learning_rate=[0.00005, 0.0002, 0.0006], \n",
        "                                  regularization_penalty=[0.00002], regularization_method=['weighted_l1'], \n",
        "                                  self_scaling_epochs=[20], layer_sizes=[[100, 100, 100, 100, 100]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (5e-05, 2e-05, 'weighted_l1', 20, [100, 100, 100, 100, 100]) completed, best_val_accuracy: 0.9157959434542102, best_hidden_layer_sizes sizes: [54, 28, 29, 52, 78]\n",
            "Run with parameters (0.0002, 2e-05, 'weighted_l1', 20, [100, 100, 100, 100, 100]) completed, best_val_accuracy: 0.9251306084818685, best_hidden_layer_sizes sizes: [24, 19, 17, 43, 67]\n",
            "Run with parameters (0.0006, 2e-05, 'weighted_l1', 20, [100, 100, 100, 100, 100]) completed, best_val_accuracy: 0.9240934234787953, best_hidden_layer_sizes sizes: [15, 17, 33, 55, 241]\n",
            "Best overall combination: (0.0002, 2e-05, 'weighted_l1', 20, [100, 100, 100, 100, 100]), val_accuracy: 0.9251306084818685\n",
            "CPU times: user 28min 8s, sys: 29.6 s, total: 28min 38s\n",
            "Wall time: 29min 6s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1GsAxliSDsl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22918833-7be2-4203-a050-093614ed3ebb"
      },
      "source": [
        "%%time\n",
        "\n",
        "histories = cross_validate(train_fn, X_norm, y, n_splits=6, learning_rate=0.0002,\n",
        "                           regularization_penalty=0.00002, regularization_method='weighted_l1',\n",
        "                           self_scaling_epochs=20, layer_sizes=[100, 100, 100, 100, 100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best_val_accuracy: 0.9232867240319607, best_hidden_layer_sizes: [22, 21, 18, 46, 61]\n",
            "Run 1 completed, best_val_accuracy: 0.9245928088506453, best_hidden_layer_sizes: [20, 18, 20, 39, 82]\n",
            "Run 2 completed, best_val_accuracy: 0.9235556238475722, best_hidden_layer_sizes: [26, 17, 17, 43, 77]\n",
            "Run 3 completed, best_val_accuracy: 0.926359864781807, best_hidden_layer_sizes: [25, 15, 17, 44, 79]\n",
            "Run 4 completed, best_val_accuracy: 0.9247464658881377, best_hidden_layer_sizes: [26, 18, 21, 47, 73]\n",
            "Run 5 completed, best_val_accuracy: 0.9237476951444377, best_hidden_layer_sizes: [25, 18, 21, 39, 74]\n",
            "mean_best_val_accuracy: 0.9243815304240934\n",
            "mean_best_hidden_layer_sizes: [24.0, 17.833333333333332, 19.0, 43.0, 74.33333333333333]\n",
            "CPU times: user 56min 3s, sys: 59.3 s, total: 57min 2s\n",
            "Wall time: 57min 16s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZnjumgLUWIe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74db026e-c2cf-479a-dbc9-08008a5180c9"
      },
      "source": [
        "%%time\n",
        "\n",
        "histories = hyperparameter_search(train_fn, learning_rate=[0.00005, 0.0002, 0.0005, 0.002], \n",
        "                                  regularization_penalty=[0.], regularization_method=[None], \n",
        "                                  self_scaling_epochs=[0], layer_sizes=[[24, 18, 19, 43, 74]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (5e-05, 0.0, None, 0, [24, 18, 19, 43, 74]) completed, best_val_accuracy: 0.8676628764597418, best_hidden_layer_sizes sizes: [24, 18, 19, 43, 74]\n",
            "Run with parameters (0.0002, 0.0, None, 0, [24, 18, 19, 43, 74]) completed, best_val_accuracy: 0.8984711124769514, best_hidden_layer_sizes sizes: [24, 18, 19, 43, 74]\n",
            "Run with parameters (0.0005, 0.0, None, 0, [24, 18, 19, 43, 74]) completed, best_val_accuracy: 0.9091502765826674, best_hidden_layer_sizes sizes: [24, 18, 19, 43, 74]\n",
            "Run with parameters (0.002, 0.0, None, 0, [24, 18, 19, 43, 74]) completed, best_val_accuracy: 0.9029655808236017, best_hidden_layer_sizes sizes: [24, 18, 19, 43, 74]\n",
            "Best overall combination: (0.0005, 0.0, None, 0, [24, 18, 19, 43, 74]), val_accuracy: 0.9091502765826674\n",
            "CPU times: user 25min, sys: 23.6 s, total: 25min 24s\n",
            "Wall time: 24min 22s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRkci_tcqKyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc3fbb71-4920-4b36-bb56-4823605d0814"
      },
      "source": [
        "model = get_convolutional_model(regularization_penalty=0., regularization_method=None, layer_sizes=[24, 18, 19, 43, 74])\n",
        "model.build(X_norm.shape)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_93\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_372 (Conv2D)          multiple                  672       \n",
            "_________________________________________________________________\n",
            "conv2d_373 (Conv2D)          multiple                  3906      \n",
            "_________________________________________________________________\n",
            "dropout_186 (Dropout)        multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv2d_374 (Conv2D)          multiple                  3097      \n",
            "_________________________________________________________________\n",
            "conv2d_375 (Conv2D)          multiple                  7396      \n",
            "_________________________________________________________________\n",
            "dropout_187 (Dropout)        multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten_93 (Flatten)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_186 (Dense)            multiple                  203722    \n",
            "_________________________________________________________________\n",
            "dense_187 (Dense)            multiple                  750       \n",
            "=================================================================\n",
            "Total params: 219,543\n",
            "Trainable params: 219,543\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GXmdMhGwkFg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf91a249-d86b-4daa-c8b9-496be91430bc"
      },
      "source": [
        "model = get_convolutional_model(regularization_penalty=0., regularization_method=None, layer_sizes=[38, 38, 38, 38, 74])\n",
        "model.build(X_norm.shape)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_94\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_376 (Conv2D)          multiple                  1064      \n",
            "_________________________________________________________________\n",
            "conv2d_377 (Conv2D)          multiple                  13034     \n",
            "_________________________________________________________________\n",
            "dropout_188 (Dropout)        multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv2d_378 (Conv2D)          multiple                  13034     \n",
            "_________________________________________________________________\n",
            "conv2d_379 (Conv2D)          multiple                  13034     \n",
            "_________________________________________________________________\n",
            "dropout_189 (Dropout)        multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten_94 (Flatten)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_188 (Dense)            multiple                  180042    \n",
            "_________________________________________________________________\n",
            "dense_189 (Dense)            multiple                  750       \n",
            "=================================================================\n",
            "Total params: 220,958\n",
            "Trainable params: 220,958\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9Lob8xqwm3o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e43365be-1ec6-4d56-93f6-9da9cd86ae52"
      },
      "source": [
        "%%time\n",
        "\n",
        "histories = hyperparameter_search(train_fn, learning_rate=[0.00005, 0.0002, 0.0005, 0.002], \n",
        "                                  regularization_penalty=[0.], regularization_method=[None], \n",
        "                                  self_scaling_epochs=[0], layer_sizes=[[38, 38, 38, 38, 74]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (5e-05, 0.0, None, 0, [38, 38, 38, 38, 74]) completed, best_val_accuracy: 0.8982406269207129, best_hidden_layer_sizes sizes: [38, 38, 38, 38, 74]\n",
            "Run with parameters (0.0002, 0.0, None, 0, [38, 38, 38, 38, 74]) completed, best_val_accuracy: 0.9143746158574063, best_hidden_layer_sizes sizes: [38, 38, 38, 38, 74]\n",
            "Run with parameters (0.0005, 0.0, None, 0, [38, 38, 38, 38, 74]) completed, best_val_accuracy: 0.9153733866011063, best_hidden_layer_sizes sizes: [38, 38, 38, 38, 74]\n",
            "Run with parameters (0.002, 0.0, None, 0, [38, 38, 38, 38, 74]) completed, best_val_accuracy: 0.9020436385986478, best_hidden_layer_sizes sizes: [38, 38, 38, 38, 74]\n",
            "Best overall combination: (0.0005, 0.0, None, 0, [38, 38, 38, 38, 74]), val_accuracy: 0.9153733866011063\n",
            "CPU times: user 24min 46s, sys: 23.3 s, total: 25min 9s\n",
            "Wall time: 24min 7s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQUBla3UMxyM"
      },
      "source": [
        "## Various numbers of added neurons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-77Y9i8M0zT",
        "outputId": "c4d9e99e-0259-4bdd-e57c-f6246910efbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cifar100 = tf.keras.datasets.cifar100\n",
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
        "\n",
        "X_train = X_train.astype(dtype) / 255.0\n",
        "y_train = y_train.astype(dtype)\n",
        "X_test = X_test.astype(dtype)  / 255.0\n",
        "y_test = y_test.astype(dtype)\n",
        "\n",
        "X_train = np.reshape(X_train, (-1, 3072))\n",
        "X_test = np.reshape(X_test, (-1, 3072))\n",
        "\n",
        "X = np.concatenate((X_train, X_test), axis=0)\n",
        "y = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)  # Scaling each feature independently\n",
        "\n",
        "X_norm = scaler.transform(X)\n",
        "X_train_norm = scaler.transform(X_train)\n",
        "X_test_norm = scaler.transform(X_test)\n",
        "\n",
        "X_norm = np.reshape(X_norm, (-1, 32, 32, 3))\n",
        "X_train_norm = np.reshape(X_train_norm, (-1, 32, 32, 3))\n",
        "X_test_norm = np.reshape(X_test_norm, (-1, 32, 32, 3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 4s 0us/step\n",
            "169017344/169001437 [==============================] - 4s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_OsKyD2NN3u",
        "outputId": "63c93e93-3e24-45d7-eea3-e68d861dbaa4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_fn(learning_rate=0.0002, regularization_penalty=0.00002, regularization_method='weighted_l1', self_scaling_epochs=25, \n",
        "         layer_sizes=[65, 23, 29, 72, 201], epochs=45, pruning_only_epochs=5, min_new_neurons=20, growth_percentage=0.2, output_neurons=100, verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.109777927398682 - val_accuracy: 0.0074 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.109777927398682 - val_accuracy: 0.0074 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 43, 49, 92, 241], total units: 510\n",
            "Before pruning:\n",
            "loss: 4.022263526916504 - accuracy: 0.10886 - val_loss: 3.635108709335327 - val_accuracy: 0.1627 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 43, 49, 92, 241], total units: 510\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.6351377964019775 - val_accuracy: 0.1627 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 28, 29, 72, 201], total units: 395\n",
            "##########################################################\n",
            "Epoch 2/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.6351377964019775 - val_accuracy: 0.1627 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 28, 29, 72, 201], total units: 395\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.6351377964019775 - val_accuracy: 0.1627 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 48, 49, 92, 241], total units: 515\n",
            "Before pruning:\n",
            "loss: 3.6177022457122803 - accuracy: 0.16018 - val_loss: 3.4651403427124023 - val_accuracy: 0.1855 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 48, 49, 92, 241], total units: 515\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.465297222137451 - val_accuracy: 0.1856 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 24, 29, 72, 201], total units: 391\n",
            "##########################################################\n",
            "Epoch 3/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.465297222137451 - val_accuracy: 0.1856 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 24, 29, 72, 201], total units: 391\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.465297222137451 - val_accuracy: 0.1856 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 44, 49, 92, 241], total units: 511\n",
            "Before pruning:\n",
            "loss: 3.4672012329101562 - accuracy: 0.18474 - val_loss: 3.2922606468200684 - val_accuracy: 0.2216 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 44, 49, 92, 241], total units: 511\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.292187452316284 - val_accuracy: 0.2212 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 4/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.292187452316284 - val_accuracy: 0.2212 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.292187452316284 - val_accuracy: 0.2212 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 43, 49, 92, 241], total units: 510\n",
            "Before pruning:\n",
            "loss: 3.2773165702819824 - accuracy: 0.21626 - val_loss: 3.0759551525115967 - val_accuracy: 0.2622 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 43, 49, 92, 241], total units: 510\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.076183319091797 - val_accuracy: 0.2618 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 5/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.076183319091797 - val_accuracy: 0.2618 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.076183319091797 - val_accuracy: 0.2618 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 43, 49, 92, 241], total units: 510\n",
            "Before pruning:\n",
            "loss: 3.124847173690796 - accuracy: 0.24354 - val_loss: 2.9380667209625244 - val_accuracy: 0.2878 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 43, 49, 92, 241], total units: 510\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.938014030456543 - val_accuracy: 0.2876 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 70, 204], total units: 391\n",
            "##########################################################\n",
            "Epoch 6/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.938014030456543 - val_accuracy: 0.2876 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 70, 204], total units: 391\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.938014268875122 - val_accuracy: 0.2876 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 43, 49, 90, 244], total units: 511\n",
            "Before pruning:\n",
            "loss: 3.0159494876861572 - accuracy: 0.26132 - val_loss: 2.8460605144500732 - val_accuracy: 0.2972 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 43, 49, 90, 244], total units: 511\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.846161127090454 - val_accuracy: 0.297 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 68, 204], total units: 389\n",
            "##########################################################\n",
            "Epoch 7/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.846161127090454 - val_accuracy: 0.297 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 68, 204], total units: 389\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.846161365509033 - val_accuracy: 0.297 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 43, 49, 88, 244], total units: 509\n",
            "Before pruning:\n",
            "loss: 2.92716646194458 - accuracy: 0.27734 - val_loss: 2.758147954940796 - val_accuracy: 0.3218 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 43, 49, 88, 244], total units: 509\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.75817608833313 - val_accuracy: 0.3213 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 66, 205], total units: 388\n",
            "##########################################################\n",
            "Epoch 8/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.75817608833313 - val_accuracy: 0.3213 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 66, 205], total units: 388\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.7581756114959717 - val_accuracy: 0.3213 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 43, 49, 86, 246], total units: 509\n",
            "Before pruning:\n",
            "loss: 2.845370054244995 - accuracy: 0.29562 - val_loss: 2.6965560913085938 - val_accuracy: 0.3353 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 43, 49, 86, 246], total units: 509\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.696613311767578 - val_accuracy: 0.3355 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 62, 209], total units: 388\n",
            "##########################################################\n",
            "Epoch 9/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.696613311767578 - val_accuracy: 0.3355 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 62, 209], total units: 388\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.696613311767578 - val_accuracy: 0.3355 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 43, 49, 82, 250], total units: 509\n",
            "Before pruning:\n",
            "loss: 2.7732748985290527 - accuracy: 0.30502 - val_loss: 2.6349270343780518 - val_accuracy: 0.3392 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 43, 49, 82, 250], total units: 509\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.634965419769287 - val_accuracy: 0.339 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 64, 207], total units: 388\n",
            "##########################################################\n",
            "Epoch 10/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.634965419769287 - val_accuracy: 0.339 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 64, 207], total units: 388\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.634965419769287 - val_accuracy: 0.339 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 43, 49, 84, 248], total units: 509\n",
            "Before pruning:\n",
            "loss: 2.7170283794403076 - accuracy: 0.31882 - val_loss: 2.5754876136779785 - val_accuracy: 0.3562 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 43, 49, 84, 248], total units: 509\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.5755274295806885 - val_accuracy: 0.3565 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 64, 210], total units: 391\n",
            "##########################################################\n",
            "Epoch 11/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.5755274295806885 - val_accuracy: 0.3565 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 64, 210], total units: 391\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.5755274295806885 - val_accuracy: 0.3565 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 43, 49, 84, 252], total units: 513\n",
            "Before pruning:\n",
            "loss: 2.6786599159240723 - accuracy: 0.32742 - val_loss: 2.5279603004455566 - val_accuracy: 0.3647 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 43, 49, 84, 252], total units: 513\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.528043270111084 - val_accuracy: 0.3648 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 68, 210], total units: 395\n",
            "##########################################################\n",
            "Epoch 12/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.528043270111084 - val_accuracy: 0.3648 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 68, 210], total units: 395\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.528043270111084 - val_accuracy: 0.3648 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 43, 49, 88, 252], total units: 517\n",
            "Before pruning:\n",
            "loss: 2.631152868270874 - accuracy: 0.33616 - val_loss: 2.507658004760742 - val_accuracy: 0.3679 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 43, 49, 88, 252], total units: 517\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.507761240005493 - val_accuracy: 0.3679 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 70, 210], total units: 397\n",
            "##########################################################\n",
            "Epoch 13/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.507761240005493 - val_accuracy: 0.3679 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 70, 210], total units: 397\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.507761240005493 - val_accuracy: 0.3679 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 43, 49, 90, 252], total units: 519\n",
            "Before pruning:\n",
            "loss: 2.589773178100586 - accuracy: 0.34476 - val_loss: 2.4651336669921875 - val_accuracy: 0.3717 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 43, 49, 90, 252], total units: 519\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.46522855758667 - val_accuracy: 0.3718 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 71, 210], total units: 398\n",
            "##########################################################\n",
            "Epoch 14/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.46522855758667 - val_accuracy: 0.3718 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 71, 210], total units: 398\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.465228796005249 - val_accuracy: 0.3718 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 43, 49, 91, 252], total units: 520\n",
            "Before pruning:\n",
            "loss: 2.55635929107666 - accuracy: 0.35048 - val_loss: 2.4334475994110107 - val_accuracy: 0.3781 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 43, 49, 91, 252], total units: 520\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.433443069458008 - val_accuracy: 0.3781 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 70, 211], total units: 398\n",
            "##########################################################\n",
            "Epoch 15/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.433443069458008 - val_accuracy: 0.3781 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 70, 211], total units: 398\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4334428310394287 - val_accuracy: 0.3781 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 43, 49, 90, 253], total units: 520\n",
            "Before pruning:\n",
            "loss: 2.520941734313965 - accuracy: 0.35752 - val_loss: 2.405914068222046 - val_accuracy: 0.3839 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 43, 49, 90, 253], total units: 520\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.4059665203094482 - val_accuracy: 0.3843 - penalty: 2e-05\n",
            "hidden layer sizes: [63, 23, 29, 73, 211], total units: 399\n",
            "##########################################################\n",
            "Epoch 16/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4059665203094482 - val_accuracy: 0.3843 - penalty: 2e-05\n",
            "hidden layer sizes: [63, 23, 29, 73, 211], total units: 399\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4059665203094482 - val_accuracy: 0.3843 - penalty: 2e-05\n",
            "hidden layer sizes: [83, 43, 49, 93, 253], total units: 521\n",
            "Before pruning:\n",
            "loss: 2.4988791942596436 - accuracy: 0.36154 - val_loss: 2.3806488513946533 - val_accuracy: 0.3874 - penalty: 2e-05\n",
            "hidden layer sizes: [83, 43, 49, 93, 253], total units: 521\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3806514739990234 - val_accuracy: 0.3872 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 23, 29, 70, 212], total units: 394\n",
            "##########################################################\n",
            "Epoch 17/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3806514739990234 - val_accuracy: 0.3872 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 23, 29, 70, 212], total units: 394\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3806514739990234 - val_accuracy: 0.3872 - penalty: 2e-05\n",
            "hidden layer sizes: [80, 43, 49, 90, 254], total units: 516\n",
            "Before pruning:\n",
            "loss: 2.4756734371185303 - accuracy: 0.36686 - val_loss: 2.3557324409484863 - val_accuracy: 0.3983 - penalty: 2e-05\n",
            "hidden layer sizes: [80, 43, 49, 90, 254], total units: 516\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3558006286621094 - val_accuracy: 0.3983 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 23, 29, 73, 213], total units: 398\n",
            "##########################################################\n",
            "Epoch 18/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3558006286621094 - val_accuracy: 0.3983 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 23, 29, 73, 213], total units: 398\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3558006286621094 - val_accuracy: 0.3983 - penalty: 2e-05\n",
            "hidden layer sizes: [80, 43, 49, 93, 255], total units: 520\n",
            "Before pruning:\n",
            "loss: 2.448415994644165 - accuracy: 0.37234 - val_loss: 2.328085422515869 - val_accuracy: 0.401 - penalty: 2e-05\n",
            "hidden layer sizes: [80, 43, 49, 93, 255], total units: 520\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3281314373016357 - val_accuracy: 0.4011 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 23, 29, 75, 213], total units: 400\n",
            "##########################################################\n",
            "Epoch 19/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3281314373016357 - val_accuracy: 0.4011 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 23, 29, 75, 213], total units: 400\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3281311988830566 - val_accuracy: 0.4011 - penalty: 2e-05\n",
            "hidden layer sizes: [80, 43, 49, 95, 255], total units: 522\n",
            "Before pruning:\n",
            "loss: 2.4328227043151855 - accuracy: 0.374 - val_loss: 2.3202455043792725 - val_accuracy: 0.3996 - penalty: 2e-05\n",
            "hidden layer sizes: [80, 43, 49, 95, 255], total units: 522\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.320279598236084 - val_accuracy: 0.3998 - penalty: 2e-05\n",
            "hidden layer sizes: [59, 23, 29, 72, 214], total units: 397\n",
            "##########################################################\n",
            "Epoch 20/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.320279598236084 - val_accuracy: 0.3998 - penalty: 2e-05\n",
            "hidden layer sizes: [59, 23, 29, 72, 214], total units: 397\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.320279598236084 - val_accuracy: 0.3998 - penalty: 2e-05\n",
            "hidden layer sizes: [79, 43, 49, 92, 256], total units: 519\n",
            "Before pruning:\n",
            "loss: 2.419759511947632 - accuracy: 0.3806 - val_loss: 2.311933755874634 - val_accuracy: 0.4014 - penalty: 2e-05\n",
            "hidden layer sizes: [79, 43, 49, 92, 256], total units: 519\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3119637966156006 - val_accuracy: 0.4013 - penalty: 2e-05\n",
            "hidden layer sizes: [59, 23, 29, 72, 213], total units: 396\n",
            "##########################################################\n",
            "Epoch 21/45\n",
            "Before pruning:\n",
            "loss: 2.404101610183716 - accuracy: 0.3809 - val_loss: 2.2982709407806396 - val_accuracy: 0.4018 - penalty: 2e-05\n",
            "hidden layer sizes: [59, 23, 29, 72, 213], total units: 396\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.2982583045959473 - val_accuracy: 0.4018 - penalty: 2e-05\n",
            "hidden layer sizes: [58, 23, 29, 71, 213], total units: 394\n",
            "##########################################################\n",
            "Epoch 22/45\n",
            "Before pruning:\n",
            "loss: 2.3920936584472656 - accuracy: 0.3828 - val_loss: 2.2849035263061523 - val_accuracy: 0.4045 - penalty: 2e-05\n",
            "hidden layer sizes: [58, 23, 29, 71, 213], total units: 394\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.284898281097412 - val_accuracy: 0.4045 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 23, 29, 71, 213], total units: 393\n",
            "##########################################################\n",
            "Epoch 23/45\n",
            "Before pruning:\n",
            "loss: 2.3734872341156006 - accuracy: 0.38544 - val_loss: 2.272979974746704 - val_accuracy: 0.412 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 23, 29, 71, 213], total units: 393\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.272963762283325 - val_accuracy: 0.412 - penalty: 2e-05\n",
            "hidden layer sizes: [53, 23, 29, 71, 213], total units: 389\n",
            "##########################################################\n",
            "Epoch 24/45\n",
            "Before pruning:\n",
            "loss: 2.3606293201446533 - accuracy: 0.39094 - val_loss: 2.2636990547180176 - val_accuracy: 0.4101 - penalty: 2e-05\n",
            "hidden layer sizes: [53, 23, 29, 71, 213], total units: 389\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.2636990547180176 - val_accuracy: 0.4101 - penalty: 2e-05\n",
            "hidden layer sizes: [53, 23, 29, 71, 213], total units: 389\n",
            "##########################################################\n",
            "Epoch 25/45\n",
            "Before pruning:\n",
            "loss: 2.3521735668182373 - accuracy: 0.39198 - val_loss: 2.2586469650268555 - val_accuracy: 0.419 - penalty: 2e-05\n",
            "hidden layer sizes: [53, 23, 29, 71, 213], total units: 389\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.2586467266082764 - val_accuracy: 0.419 - penalty: 2e-05\n",
            "hidden layer sizes: [52, 23, 29, 70, 213], total units: 387\n",
            "##########################################################\n",
            "Epoch 26/45\n",
            "loss: 2.407569408416748 - accuracy: 0.38374 - val_loss: 2.2284252643585205 - val_accuracy: 0.4223 - penalty: 0.0\n",
            "hidden layer sizes: [52, 23, 29, 70, 213], total units: 387\n",
            "##########################################################\n",
            "Epoch 27/45\n",
            "loss: 2.0913777351379395 - accuracy: 0.45196 - val_loss: 2.189464569091797 - val_accuracy: 0.4337 - penalty: 0.0\n",
            "hidden layer sizes: [52, 23, 29, 70, 213], total units: 387\n",
            "##########################################################\n",
            "Epoch 28/45\n",
            "loss: 1.975403904914856 - accuracy: 0.47614 - val_loss: 2.1684038639068604 - val_accuracy: 0.4371 - penalty: 0.0\n",
            "hidden layer sizes: [52, 23, 29, 70, 213], total units: 387\n",
            "##########################################################\n",
            "Epoch 29/45\n",
            "loss: 1.868670105934143 - accuracy: 0.503 - val_loss: 2.165107250213623 - val_accuracy: 0.4436 - penalty: 0.0\n",
            "hidden layer sizes: [52, 23, 29, 70, 213], total units: 387\n",
            "##########################################################\n",
            "Epoch 30/45\n",
            "loss: 1.7791662216186523 - accuracy: 0.52294 - val_loss: 2.1617255210876465 - val_accuracy: 0.4471 - penalty: 0.0\n",
            "hidden layer sizes: [52, 23, 29, 70, 213], total units: 387\n",
            "##########################################################\n",
            "Epoch 31/45\n",
            "loss: 1.6862874031066895 - accuracy: 0.5414 - val_loss: 2.1738274097442627 - val_accuracy: 0.4486 - penalty: 0.0\n",
            "hidden layer sizes: [52, 23, 29, 70, 213], total units: 387\n",
            "##########################################################\n",
            "Epoch 32/45\n",
            "loss: 1.6107622385025024 - accuracy: 0.56282 - val_loss: 2.187643527984619 - val_accuracy: 0.451 - penalty: 0.0\n",
            "hidden layer sizes: [52, 23, 29, 70, 213], total units: 387\n",
            "##########################################################\n",
            "Epoch 33/45\n",
            "loss: 1.5320042371749878 - accuracy: 0.581 - val_loss: 2.209425687789917 - val_accuracy: 0.4461 - penalty: 0.0\n",
            "hidden layer sizes: [52, 23, 29, 70, 213], total units: 387\n",
            "##########################################################\n",
            "Epoch 34/45\n",
            "loss: 1.4591937065124512 - accuracy: 0.59262 - val_loss: 2.224008083343506 - val_accuracy: 0.4487 - penalty: 0.0\n",
            "hidden layer sizes: [52, 23, 29, 70, 213], total units: 387\n",
            "##########################################################\n",
            "Epoch 35/45\n",
            "loss: 1.393343448638916 - accuracy: 0.61068 - val_loss: 2.254941940307617 - val_accuracy: 0.444 - penalty: 0.0\n",
            "hidden layer sizes: [52, 23, 29, 70, 213], total units: 387\n",
            "##########################################################\n",
            "Epoch 36/45\n",
            "loss: 1.3298110961914062 - accuracy: 0.62522 - val_loss: 2.2796950340270996 - val_accuracy: 0.4427 - penalty: 0.0\n",
            "hidden layer sizes: [52, 23, 29, 70, 213], total units: 387\n",
            "##########################################################\n",
            "Epoch 37/45\n",
            "loss: 1.2726632356643677 - accuracy: 0.63884 - val_loss: 2.299633502960205 - val_accuracy: 0.4513 - penalty: 0.0\n",
            "hidden layer sizes: [52, 23, 29, 70, 213], total units: 387\n",
            "##########################################################\n",
            "Epoch 38/45\n",
            "loss: 1.2160619497299194 - accuracy: 0.6493 - val_loss: 2.3318331241607666 - val_accuracy: 0.4466 - penalty: 0.0\n",
            "hidden layer sizes: [52, 23, 29, 70, 213], total units: 387\n",
            "##########################################################\n",
            "Epoch 39/45\n",
            "loss: 1.1667561531066895 - accuracy: 0.66408 - val_loss: 2.363743782043457 - val_accuracy: 0.448 - penalty: 0.0\n",
            "hidden layer sizes: [52, 23, 29, 70, 213], total units: 387\n",
            "##########################################################\n",
            "Epoch 40/45\n",
            "loss: 1.127554178237915 - accuracy: 0.6706 - val_loss: 2.3996565341949463 - val_accuracy: 0.4486 - penalty: 0.0\n",
            "hidden layer sizes: [52, 23, 29, 70, 213], total units: 387\n",
            "##########################################################\n",
            "Epoch 41/45\n",
            "loss: 1.0889320373535156 - accuracy: 0.6823 - val_loss: 2.399233102798462 - val_accuracy: 0.4475 - penalty: 0.0\n",
            "hidden layer sizes: [52, 23, 29, 70, 213], total units: 387\n",
            "##########################################################\n",
            "Epoch 42/45\n",
            "loss: 1.0416721105575562 - accuracy: 0.69084 - val_loss: 2.455592393875122 - val_accuracy: 0.4442 - penalty: 0.0\n",
            "hidden layer sizes: [52, 23, 29, 70, 213], total units: 387\n",
            "##########################################################\n",
            "Epoch 43/45\n",
            "loss: 1.0108258724212646 - accuracy: 0.69828 - val_loss: 2.4650685787200928 - val_accuracy: 0.4491 - penalty: 0.0\n",
            "hidden layer sizes: [52, 23, 29, 70, 213], total units: 387\n",
            "##########################################################\n",
            "Epoch 44/45\n",
            "loss: 0.973690927028656 - accuracy: 0.70974 - val_loss: 2.4996235370635986 - val_accuracy: 0.4453 - penalty: 0.0\n",
            "hidden layer sizes: [52, 23, 29, 70, 213], total units: 387\n",
            "##########################################################\n",
            "Epoch 45/45\n",
            "loss: 0.9395833015441895 - accuracy: 0.71898 - val_loss: 2.544058322906494 - val_accuracy: 0.442 - penalty: 0.0\n",
            "hidden layer sizes: [52, 23, 29, 70, 213], total units: 387\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.10886,\n",
              "  0.16018,\n",
              "  0.18474,\n",
              "  0.21626,\n",
              "  0.24354,\n",
              "  0.26132,\n",
              "  0.27734,\n",
              "  0.29562,\n",
              "  0.30502,\n",
              "  0.31882,\n",
              "  0.32742,\n",
              "  0.33616,\n",
              "  0.34476,\n",
              "  0.35048,\n",
              "  0.35752,\n",
              "  0.36154,\n",
              "  0.36686,\n",
              "  0.37234,\n",
              "  0.374,\n",
              "  0.3806,\n",
              "  0.3809,\n",
              "  0.3828,\n",
              "  0.38544,\n",
              "  0.39094,\n",
              "  0.39198,\n",
              "  0.38374,\n",
              "  0.45196,\n",
              "  0.47614,\n",
              "  0.503,\n",
              "  0.52294,\n",
              "  0.5414,\n",
              "  0.56282,\n",
              "  0.581,\n",
              "  0.59262,\n",
              "  0.61068,\n",
              "  0.62522,\n",
              "  0.63884,\n",
              "  0.6493,\n",
              "  0.66408,\n",
              "  0.6706,\n",
              "  0.6823,\n",
              "  0.69084,\n",
              "  0.69828,\n",
              "  0.70974,\n",
              "  0.71898],\n",
              " 'hidden_layer_sizes': [[65, 28, 29, 72, 201],\n",
              "  [65, 24, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 70, 204],\n",
              "  [65, 23, 29, 68, 204],\n",
              "  [65, 23, 29, 66, 205],\n",
              "  [65, 23, 29, 62, 209],\n",
              "  [65, 23, 29, 64, 207],\n",
              "  [65, 23, 29, 64, 210],\n",
              "  [65, 23, 29, 68, 210],\n",
              "  [65, 23, 29, 70, 210],\n",
              "  [65, 23, 29, 71, 210],\n",
              "  [65, 23, 29, 70, 211],\n",
              "  [63, 23, 29, 73, 211],\n",
              "  [60, 23, 29, 70, 212],\n",
              "  [60, 23, 29, 73, 213],\n",
              "  [60, 23, 29, 75, 213],\n",
              "  [59, 23, 29, 72, 214],\n",
              "  [59, 23, 29, 72, 213],\n",
              "  [58, 23, 29, 71, 213],\n",
              "  [57, 23, 29, 71, 213],\n",
              "  [53, 23, 29, 71, 213],\n",
              "  [53, 23, 29, 71, 213],\n",
              "  [52, 23, 29, 70, 213],\n",
              "  [52, 23, 29, 70, 213],\n",
              "  [52, 23, 29, 70, 213],\n",
              "  [52, 23, 29, 70, 213],\n",
              "  [52, 23, 29, 70, 213],\n",
              "  [52, 23, 29, 70, 213],\n",
              "  [52, 23, 29, 70, 213],\n",
              "  [52, 23, 29, 70, 213],\n",
              "  [52, 23, 29, 70, 213],\n",
              "  [52, 23, 29, 70, 213],\n",
              "  [52, 23, 29, 70, 213],\n",
              "  [52, 23, 29, 70, 213],\n",
              "  [52, 23, 29, 70, 213],\n",
              "  [52, 23, 29, 70, 213],\n",
              "  [52, 23, 29, 70, 213],\n",
              "  [52, 23, 29, 70, 213],\n",
              "  [52, 23, 29, 70, 213],\n",
              "  [52, 23, 29, 70, 213],\n",
              "  [52, 23, 29, 70, 213],\n",
              "  [52, 23, 29, 70, 213],\n",
              "  [52, 23, 29, 70, 213]],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=4.0222635>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.6177022>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.4672012>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.2773166>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.1248472>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.0159495>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.9271665>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.84537>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.773275>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.7170284>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.67866>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.6311529>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.5897732>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.5563593>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.5209417>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4988792>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4756734>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.448416>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4328227>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4197595>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4041016>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3920937>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3734872>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3606293>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3521736>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4075694>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.0913777>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.9754039>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.8686701>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.7791662>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.6862874>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.6107622>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.5320042>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4591937>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3933434>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3298111>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2726632>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.216062>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1667562>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1275542>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.088932>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0416721>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0108259>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9736909>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9395833>],\n",
              " 'val_accuracy': [0.1627,\n",
              "  0.1856,\n",
              "  0.2212,\n",
              "  0.2618,\n",
              "  0.2876,\n",
              "  0.297,\n",
              "  0.3213,\n",
              "  0.3355,\n",
              "  0.339,\n",
              "  0.3565,\n",
              "  0.3648,\n",
              "  0.3679,\n",
              "  0.3718,\n",
              "  0.3781,\n",
              "  0.3843,\n",
              "  0.3872,\n",
              "  0.3983,\n",
              "  0.4011,\n",
              "  0.3998,\n",
              "  0.4013,\n",
              "  0.4018,\n",
              "  0.4045,\n",
              "  0.412,\n",
              "  0.4101,\n",
              "  0.419,\n",
              "  0.4223,\n",
              "  0.4337,\n",
              "  0.4371,\n",
              "  0.4436,\n",
              "  0.4471,\n",
              "  0.4486,\n",
              "  0.451,\n",
              "  0.4461,\n",
              "  0.4487,\n",
              "  0.444,\n",
              "  0.4427,\n",
              "  0.4513,\n",
              "  0.4466,\n",
              "  0.448,\n",
              "  0.4486,\n",
              "  0.4475,\n",
              "  0.4442,\n",
              "  0.4491,\n",
              "  0.4453,\n",
              "  0.442],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=3.6351378>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.4652972>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.2921875>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.0761833>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.938014>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.8461611>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.758176>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.6966133>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.6349654>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.5755274>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.5280433>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.5077612>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4652286>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.433443>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4059665>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3806515>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3558006>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3281314>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3202796>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3119638>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.2982583>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.2848983>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.2729638>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.263699>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.2586467>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.2284253>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.1894646>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.1684039>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.1651073>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.1617255>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.1738274>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.1876435>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.2094257>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.224008>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.254942>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.279695>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.2996335>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3318331>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3637438>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3996565>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.399233>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4555924>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4650686>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4996235>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.5440583>]}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EirLrjUHOlNY",
        "outputId": "2c495162-ba22-4473-ffd5-fe794876698e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = train_fn(learning_rate=0.0002, regularization_penalty=0.00002, regularization_method='weighted_l1', self_scaling_epochs=25, \n",
        "         layer_sizes=[65, 23, 29, 72, 201], epochs=45, pruning_only_epochs=5, min_new_neurons=80, growth_percentage=0.8, output_neurons=100, verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.190567970275879 - val_accuracy: 0.0091 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.190567970275879 - val_accuracy: 0.0091 - penalty: 2e-05\n",
            "hidden layer sizes: [145, 103, 109, 152, 361], total units: 870\n",
            "Before pruning:\n",
            "loss: 4.023648262023926 - accuracy: 0.10894 - val_loss: 3.6310110092163086 - val_accuracy: 0.1578 - penalty: 2e-05\n",
            "hidden layer sizes: [145, 103, 109, 152, 361], total units: 870\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.63093638420105 - val_accuracy: 0.1578 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 24, 29, 72, 201], total units: 391\n",
            "##########################################################\n",
            "Epoch 2/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.63093638420105 - val_accuracy: 0.1578 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 24, 29, 72, 201], total units: 391\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.630936622619629 - val_accuracy: 0.1578 - penalty: 2e-05\n",
            "hidden layer sizes: [145, 104, 109, 152, 361], total units: 871\n",
            "Before pruning:\n",
            "loss: 3.616192102432251 - accuracy: 0.16046 - val_loss: 3.4674129486083984 - val_accuracy: 0.1861 - penalty: 2e-05\n",
            "hidden layer sizes: [145, 104, 109, 152, 361], total units: 871\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.4675464630126953 - val_accuracy: 0.1859 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 3/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.4675464630126953 - val_accuracy: 0.1859 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.4675464630126953 - val_accuracy: 0.1859 - penalty: 2e-05\n",
            "hidden layer sizes: [145, 103, 109, 152, 361], total units: 870\n",
            "Before pruning:\n",
            "loss: 3.4668538570404053 - accuracy: 0.18434 - val_loss: 3.304685592651367 - val_accuracy: 0.2172 - penalty: 2e-05\n",
            "hidden layer sizes: [145, 103, 109, 152, 361], total units: 870\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.304837942123413 - val_accuracy: 0.217 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 4/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.304837942123413 - val_accuracy: 0.217 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.304837942123413 - val_accuracy: 0.217 - penalty: 2e-05\n",
            "hidden layer sizes: [145, 103, 109, 152, 361], total units: 870\n",
            "Before pruning:\n",
            "loss: 3.295912265777588 - accuracy: 0.21426 - val_loss: 3.1376137733459473 - val_accuracy: 0.2467 - penalty: 2e-05\n",
            "hidden layer sizes: [145, 103, 109, 152, 361], total units: 870\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.137892484664917 - val_accuracy: 0.2466 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 5/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.137892484664917 - val_accuracy: 0.2466 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.137892484664917 - val_accuracy: 0.2466 - penalty: 2e-05\n",
            "hidden layer sizes: [145, 103, 109, 152, 361], total units: 870\n",
            "Before pruning:\n",
            "loss: 3.16068959236145 - accuracy: 0.2352 - val_loss: 2.9979307651519775 - val_accuracy: 0.2742 - penalty: 2e-05\n",
            "hidden layer sizes: [145, 103, 109, 152, 361], total units: 870\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.9982454776763916 - val_accuracy: 0.2736 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 6/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.9982454776763916 - val_accuracy: 0.2736 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.9982457160949707 - val_accuracy: 0.2736 - penalty: 2e-05\n",
            "hidden layer sizes: [145, 103, 109, 152, 361], total units: 870\n",
            "Before pruning:\n",
            "loss: 3.0397021770477295 - accuracy: 0.25852 - val_loss: 2.895643472671509 - val_accuracy: 0.2927 - penalty: 2e-05\n",
            "hidden layer sizes: [145, 103, 109, 152, 361], total units: 870\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.8959357738494873 - val_accuracy: 0.2932 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 71, 201], total units: 389\n",
            "##########################################################\n",
            "Epoch 7/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8959357738494873 - val_accuracy: 0.2932 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 71, 201], total units: 389\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8959357738494873 - val_accuracy: 0.2932 - penalty: 2e-05\n",
            "hidden layer sizes: [145, 103, 109, 151, 361], total units: 869\n",
            "Before pruning:\n",
            "loss: 2.935732126235962 - accuracy: 0.27794 - val_loss: 2.7893218994140625 - val_accuracy: 0.3142 - penalty: 2e-05\n",
            "hidden layer sizes: [145, 103, 109, 151, 361], total units: 869\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.789537191390991 - val_accuracy: 0.3145 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 69, 202], total units: 388\n",
            "##########################################################\n",
            "Epoch 8/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.789537191390991 - val_accuracy: 0.3145 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 69, 202], total units: 388\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.789537191390991 - val_accuracy: 0.3145 - penalty: 2e-05\n",
            "hidden layer sizes: [145, 103, 109, 149, 363], total units: 869\n",
            "Before pruning:\n",
            "loss: 2.8511762619018555 - accuracy: 0.29238 - val_loss: 2.7128145694732666 - val_accuracy: 0.3267 - penalty: 2e-05\n",
            "hidden layer sizes: [145, 103, 109, 149, 363], total units: 869\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.7129948139190674 - val_accuracy: 0.3262 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 67, 202], total units: 386\n",
            "##########################################################\n",
            "Epoch 9/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.7129948139190674 - val_accuracy: 0.3262 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 67, 202], total units: 386\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.7129948139190674 - val_accuracy: 0.3262 - penalty: 2e-05\n",
            "hidden layer sizes: [145, 103, 109, 147, 363], total units: 867\n",
            "Before pruning:\n",
            "loss: 2.77528715133667 - accuracy: 0.3088 - val_loss: 2.6449599266052246 - val_accuracy: 0.3372 - penalty: 2e-05\n",
            "hidden layer sizes: [145, 103, 109, 147, 363], total units: 867\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.6451377868652344 - val_accuracy: 0.3373 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 66, 203], total units: 386\n",
            "##########################################################\n",
            "Epoch 10/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.6451377868652344 - val_accuracy: 0.3373 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 66, 203], total units: 386\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.6451377868652344 - val_accuracy: 0.3373 - penalty: 2e-05\n",
            "hidden layer sizes: [145, 103, 109, 146, 365], total units: 868\n",
            "Before pruning:\n",
            "loss: 2.709084987640381 - accuracy: 0.3196 - val_loss: 2.575883388519287 - val_accuracy: 0.35 - penalty: 2e-05\n",
            "hidden layer sizes: [145, 103, 109, 146, 365], total units: 868\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.575981616973877 - val_accuracy: 0.3503 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 62, 202], total units: 381\n",
            "##########################################################\n",
            "Epoch 11/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.575981616973877 - val_accuracy: 0.3503 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 62, 202], total units: 381\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.575981616973877 - val_accuracy: 0.3503 - penalty: 2e-05\n",
            "hidden layer sizes: [145, 103, 109, 142, 363], total units: 862\n",
            "Before pruning:\n",
            "loss: 2.654310703277588 - accuracy: 0.3314 - val_loss: 2.5227935314178467 - val_accuracy: 0.3649 - penalty: 2e-05\n",
            "hidden layer sizes: [145, 103, 109, 142, 363], total units: 862\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.5229146480560303 - val_accuracy: 0.3653 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 63, 202], total units: 382\n",
            "##########################################################\n",
            "Epoch 12/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.5229146480560303 - val_accuracy: 0.3653 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 63, 202], total units: 382\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.5229148864746094 - val_accuracy: 0.3653 - penalty: 2e-05\n",
            "hidden layer sizes: [145, 103, 109, 143, 363], total units: 863\n",
            "Before pruning:\n",
            "loss: 2.605940818786621 - accuracy: 0.34072 - val_loss: 2.470484733581543 - val_accuracy: 0.3754 - penalty: 2e-05\n",
            "hidden layer sizes: [145, 103, 109, 143, 363], total units: 863\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.4708383083343506 - val_accuracy: 0.3752 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 23, 29, 64, 204], total units: 384\n",
            "##########################################################\n",
            "Epoch 13/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4708383083343506 - val_accuracy: 0.3752 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 23, 29, 64, 204], total units: 384\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4708383083343506 - val_accuracy: 0.3752 - penalty: 2e-05\n",
            "hidden layer sizes: [144, 103, 109, 144, 367], total units: 867\n",
            "Before pruning:\n",
            "loss: 2.5599427223205566 - accuracy: 0.34792 - val_loss: 2.4407553672790527 - val_accuracy: 0.3775 - penalty: 2e-05\n",
            "hidden layer sizes: [144, 103, 109, 144, 367], total units: 867\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.4409263134002686 - val_accuracy: 0.3776 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 23, 29, 65, 203], total units: 384\n",
            "##########################################################\n",
            "Epoch 14/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4409263134002686 - val_accuracy: 0.3776 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 23, 29, 65, 203], total units: 384\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4409265518188477 - val_accuracy: 0.3776 - penalty: 2e-05\n",
            "hidden layer sizes: [144, 103, 109, 145, 365], total units: 866\n",
            "Before pruning:\n",
            "loss: 2.5275864601135254 - accuracy: 0.35592 - val_loss: 2.415555953979492 - val_accuracy: 0.3803 - penalty: 2e-05\n",
            "hidden layer sizes: [144, 103, 109, 145, 365], total units: 866\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.415520429611206 - val_accuracy: 0.3799 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 23, 29, 62, 204], total units: 382\n",
            "##########################################################\n",
            "Epoch 15/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.415520429611206 - val_accuracy: 0.3799 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 23, 29, 62, 204], total units: 382\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.415520429611206 - val_accuracy: 0.3799 - penalty: 2e-05\n",
            "hidden layer sizes: [144, 103, 109, 142, 367], total units: 865\n",
            "Before pruning:\n",
            "loss: 2.500371217727661 - accuracy: 0.36036 - val_loss: 2.3842644691467285 - val_accuracy: 0.3907 - penalty: 2e-05\n",
            "hidden layer sizes: [144, 103, 109, 142, 367], total units: 865\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3842363357543945 - val_accuracy: 0.3912 - penalty: 2e-05\n",
            "hidden layer sizes: [63, 23, 29, 62, 205], total units: 382\n",
            "##########################################################\n",
            "Epoch 16/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3842363357543945 - val_accuracy: 0.3912 - penalty: 2e-05\n",
            "hidden layer sizes: [63, 23, 29, 62, 205], total units: 382\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3842363357543945 - val_accuracy: 0.3912 - penalty: 2e-05\n",
            "hidden layer sizes: [143, 103, 109, 142, 369], total units: 866\n",
            "Before pruning:\n",
            "loss: 2.4734206199645996 - accuracy: 0.36706 - val_loss: 2.3593695163726807 - val_accuracy: 0.3955 - penalty: 2e-05\n",
            "hidden layer sizes: [143, 103, 109, 142, 369], total units: 866\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.35945463180542 - val_accuracy: 0.3953 - penalty: 2e-05\n",
            "hidden layer sizes: [61, 23, 29, 66, 205], total units: 384\n",
            "##########################################################\n",
            "Epoch 17/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.35945463180542 - val_accuracy: 0.3953 - penalty: 2e-05\n",
            "hidden layer sizes: [61, 23, 29, 66, 205], total units: 384\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.359454393386841 - val_accuracy: 0.3953 - penalty: 2e-05\n",
            "hidden layer sizes: [141, 103, 109, 146, 369], total units: 868\n",
            "Before pruning:\n",
            "loss: 2.4532222747802734 - accuracy: 0.37134 - val_loss: 2.3517041206359863 - val_accuracy: 0.3954 - penalty: 2e-05\n",
            "hidden layer sizes: [141, 103, 109, 146, 369], total units: 868\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3517374992370605 - val_accuracy: 0.3954 - penalty: 2e-05\n",
            "hidden layer sizes: [61, 23, 30, 65, 205], total units: 384\n",
            "##########################################################\n",
            "Epoch 18/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3517374992370605 - val_accuracy: 0.3954 - penalty: 2e-05\n",
            "hidden layer sizes: [61, 23, 30, 65, 205], total units: 384\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3517377376556396 - val_accuracy: 0.3954 - penalty: 2e-05\n",
            "hidden layer sizes: [141, 103, 110, 145, 369], total units: 868\n",
            "Before pruning:\n",
            "loss: 2.4308910369873047 - accuracy: 0.37426 - val_loss: 2.3357949256896973 - val_accuracy: 0.3961 - penalty: 2e-05\n",
            "hidden layer sizes: [141, 103, 110, 145, 369], total units: 868\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.335839033126831 - val_accuracy: 0.3966 - penalty: 2e-05\n",
            "hidden layer sizes: [61, 23, 29, 68, 204], total units: 385\n",
            "##########################################################\n",
            "Epoch 19/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.335839033126831 - val_accuracy: 0.3966 - penalty: 2e-05\n",
            "hidden layer sizes: [61, 23, 29, 68, 204], total units: 385\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.335839033126831 - val_accuracy: 0.3966 - penalty: 2e-05\n",
            "hidden layer sizes: [141, 103, 109, 148, 367], total units: 868\n",
            "Before pruning:\n",
            "loss: 2.4189109802246094 - accuracy: 0.3763 - val_loss: 2.318397045135498 - val_accuracy: 0.3952 - penalty: 2e-05\n",
            "hidden layer sizes: [141, 103, 109, 148, 367], total units: 868\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3186628818511963 - val_accuracy: 0.3952 - penalty: 2e-05\n",
            "hidden layer sizes: [61, 23, 29, 67, 204], total units: 384\n",
            "##########################################################\n",
            "Epoch 20/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3186628818511963 - val_accuracy: 0.3952 - penalty: 2e-05\n",
            "hidden layer sizes: [61, 23, 29, 67, 204], total units: 384\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.318662643432617 - val_accuracy: 0.3952 - penalty: 2e-05\n",
            "hidden layer sizes: [141, 103, 109, 147, 367], total units: 867\n",
            "Before pruning:\n",
            "loss: 2.3926894664764404 - accuracy: 0.38428 - val_loss: 2.295712471008301 - val_accuracy: 0.4058 - penalty: 2e-05\n",
            "hidden layer sizes: [141, 103, 109, 147, 367], total units: 867\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.295665979385376 - val_accuracy: 0.4057 - penalty: 2e-05\n",
            "hidden layer sizes: [61, 23, 29, 66, 205], total units: 384\n",
            "##########################################################\n",
            "Epoch 21/45\n",
            "Before pruning:\n",
            "loss: 2.379488706588745 - accuracy: 0.3839 - val_loss: 2.285311222076416 - val_accuracy: 0.4046 - penalty: 2e-05\n",
            "hidden layer sizes: [61, 23, 29, 66, 205], total units: 384\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.2853286266326904 - val_accuracy: 0.4045 - penalty: 2e-05\n",
            "hidden layer sizes: [61, 22, 29, 64, 204], total units: 380\n",
            "##########################################################\n",
            "Epoch 22/45\n",
            "Before pruning:\n",
            "loss: 2.3658053874969482 - accuracy: 0.38658 - val_loss: 2.2755415439605713 - val_accuracy: 0.4109 - penalty: 2e-05\n",
            "hidden layer sizes: [61, 22, 29, 64, 204], total units: 380\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.2755417823791504 - val_accuracy: 0.4109 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 22, 29, 64, 204], total units: 379\n",
            "##########################################################\n",
            "Epoch 23/45\n",
            "Before pruning:\n",
            "loss: 2.348330020904541 - accuracy: 0.3926 - val_loss: 2.273946523666382 - val_accuracy: 0.4089 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 22, 29, 64, 204], total units: 379\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.2739462852478027 - val_accuracy: 0.4089 - penalty: 2e-05\n",
            "hidden layer sizes: [59, 22, 29, 64, 204], total units: 378\n",
            "##########################################################\n",
            "Epoch 24/45\n",
            "Before pruning:\n",
            "loss: 2.345569610595703 - accuracy: 0.393 - val_loss: 2.2546420097351074 - val_accuracy: 0.4171 - penalty: 2e-05\n",
            "hidden layer sizes: [59, 22, 29, 64, 204], total units: 378\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.2546350955963135 - val_accuracy: 0.417 - penalty: 2e-05\n",
            "hidden layer sizes: [58, 22, 29, 64, 204], total units: 377\n",
            "##########################################################\n",
            "Epoch 25/45\n",
            "Before pruning:\n",
            "loss: 2.3366568088531494 - accuracy: 0.39356 - val_loss: 2.2396860122680664 - val_accuracy: 0.4205 - penalty: 2e-05\n",
            "hidden layer sizes: [58, 22, 29, 64, 204], total units: 377\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.2396817207336426 - val_accuracy: 0.4204 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 22, 29, 64, 204], total units: 376\n",
            "##########################################################\n",
            "Epoch 26/45\n",
            "loss: 2.385002613067627 - accuracy: 0.38898 - val_loss: 2.210062265396118 - val_accuracy: 0.425 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 29, 64, 204], total units: 376\n",
            "##########################################################\n",
            "Epoch 27/45\n",
            "loss: 2.089370012283325 - accuracy: 0.45238 - val_loss: 2.1682889461517334 - val_accuracy: 0.4382 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 29, 64, 204], total units: 376\n",
            "##########################################################\n",
            "Epoch 28/45\n",
            "loss: 1.9705840349197388 - accuracy: 0.48042 - val_loss: 2.1451680660247803 - val_accuracy: 0.446 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 29, 64, 204], total units: 376\n",
            "##########################################################\n",
            "Epoch 29/45\n",
            "loss: 1.8686585426330566 - accuracy: 0.50202 - val_loss: 2.157724142074585 - val_accuracy: 0.4445 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 29, 64, 204], total units: 376\n",
            "##########################################################\n",
            "Epoch 30/45\n",
            "loss: 1.786967158317566 - accuracy: 0.5211 - val_loss: 2.1453182697296143 - val_accuracy: 0.4462 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 29, 64, 204], total units: 376\n",
            "##########################################################\n",
            "Epoch 31/45\n",
            "loss: 1.7011343240737915 - accuracy: 0.54176 - val_loss: 2.1533477306365967 - val_accuracy: 0.4504 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 29, 64, 204], total units: 376\n",
            "##########################################################\n",
            "Epoch 32/45\n",
            "loss: 1.6242337226867676 - accuracy: 0.55864 - val_loss: 2.164825677871704 - val_accuracy: 0.4494 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 29, 64, 204], total units: 376\n",
            "##########################################################\n",
            "Epoch 33/45\n",
            "loss: 1.5532824993133545 - accuracy: 0.57304 - val_loss: 2.18280029296875 - val_accuracy: 0.4524 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 29, 64, 204], total units: 376\n",
            "##########################################################\n",
            "Epoch 34/45\n",
            "loss: 1.4954371452331543 - accuracy: 0.58636 - val_loss: 2.2030532360076904 - val_accuracy: 0.4524 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 29, 64, 204], total units: 376\n",
            "##########################################################\n",
            "Epoch 35/45\n",
            "loss: 1.423751711845398 - accuracy: 0.607 - val_loss: 2.215294361114502 - val_accuracy: 0.4481 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 29, 64, 204], total units: 376\n",
            "##########################################################\n",
            "Epoch 36/45\n",
            "loss: 1.36325204372406 - accuracy: 0.61882 - val_loss: 2.2427141666412354 - val_accuracy: 0.4513 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 29, 64, 204], total units: 376\n",
            "##########################################################\n",
            "Epoch 37/45\n",
            "loss: 1.3242563009262085 - accuracy: 0.627 - val_loss: 2.2406697273254395 - val_accuracy: 0.4535 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 29, 64, 204], total units: 376\n",
            "##########################################################\n",
            "Epoch 38/45\n",
            "loss: 1.272985816001892 - accuracy: 0.63784 - val_loss: 2.2686078548431396 - val_accuracy: 0.4523 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 29, 64, 204], total units: 376\n",
            "##########################################################\n",
            "Epoch 39/45\n",
            "loss: 1.220207691192627 - accuracy: 0.65112 - val_loss: 2.2929863929748535 - val_accuracy: 0.4524 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 29, 64, 204], total units: 376\n",
            "##########################################################\n",
            "Epoch 40/45\n",
            "loss: 1.1769500970840454 - accuracy: 0.65976 - val_loss: 2.3055343627929688 - val_accuracy: 0.4516 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 29, 64, 204], total units: 376\n",
            "##########################################################\n",
            "Epoch 41/45\n",
            "loss: 1.1326669454574585 - accuracy: 0.67302 - val_loss: 2.338540554046631 - val_accuracy: 0.451 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 29, 64, 204], total units: 376\n",
            "##########################################################\n",
            "Epoch 42/45\n",
            "loss: 1.1013948917388916 - accuracy: 0.67668 - val_loss: 2.368018865585327 - val_accuracy: 0.4474 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 29, 64, 204], total units: 376\n",
            "##########################################################\n",
            "Epoch 43/45\n",
            "loss: 1.0630382299423218 - accuracy: 0.68756 - val_loss: 2.3940939903259277 - val_accuracy: 0.4504 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 29, 64, 204], total units: 376\n",
            "##########################################################\n",
            "Epoch 44/45\n",
            "loss: 1.0440117120742798 - accuracy: 0.69222 - val_loss: 2.413938045501709 - val_accuracy: 0.4487 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 29, 64, 204], total units: 376\n",
            "##########################################################\n",
            "Epoch 45/45\n",
            "loss: 1.0072343349456787 - accuracy: 0.70034 - val_loss: 2.4319400787353516 - val_accuracy: 0.4497 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 29, 64, 204], total units: 376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8nXGiMTUfrh",
        "outputId": "3d7b8d3f-44b6-4707-ead8-43bdfcc6f26d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_fn(learning_rate=0.0002, regularization_penalty=0.00002, regularization_method='weighted_l1', self_scaling_epochs=25, \n",
        "         layer_sizes=[65, 23, 29, 72, 201], epochs=45, pruning_only_epochs=5, min_new_neurons=3, growth_percentage=0.03, output_neurons=100, verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.087422847747803 - val_accuracy: 0.0114 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.087422847747803 - val_accuracy: 0.0114 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 26, 32, 75, 207], total units: 408\n",
            "Before pruning:\n",
            "loss: 4.023555755615234 - accuracy: 0.1083 - val_loss: 3.6138393878936768 - val_accuracy: 0.1695 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 26, 32, 75, 207], total units: 408\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.61383056640625 - val_accuracy: 0.1695 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 25, 29, 72, 201], total units: 392\n",
            "##########################################################\n",
            "Epoch 2/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.61383056640625 - val_accuracy: 0.1695 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 25, 29, 72, 201], total units: 392\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.613830804824829 - val_accuracy: 0.1695 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 28, 32, 75, 207], total units: 410\n",
            "Before pruning:\n",
            "loss: 3.6292481422424316 - accuracy: 0.159 - val_loss: 3.4726061820983887 - val_accuracy: 0.187 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 28, 32, 75, 207], total units: 410\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.4726274013519287 - val_accuracy: 0.1866 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 25, 29, 72, 201], total units: 392\n",
            "##########################################################\n",
            "Epoch 3/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.4726274013519287 - val_accuracy: 0.1866 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 25, 29, 72, 201], total units: 392\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.4726274013519287 - val_accuracy: 0.1866 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 28, 32, 75, 207], total units: 410\n",
            "Before pruning:\n",
            "loss: 3.4776196479797363 - accuracy: 0.18468 - val_loss: 3.3282723426818848 - val_accuracy: 0.2117 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 28, 32, 75, 207], total units: 410\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.3282227516174316 - val_accuracy: 0.2119 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 4/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.3282227516174316 - val_accuracy: 0.2119 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.3282227516174316 - val_accuracy: 0.2119 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 26, 32, 75, 207], total units: 408\n",
            "Before pruning:\n",
            "loss: 3.329526901245117 - accuracy: 0.20968 - val_loss: 3.1459033489227295 - val_accuracy: 0.2437 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 26, 32, 75, 207], total units: 408\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.1459450721740723 - val_accuracy: 0.2437 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 5/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.1459450721740723 - val_accuracy: 0.2437 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.1459450721740723 - val_accuracy: 0.2437 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 26, 32, 75, 207], total units: 408\n",
            "Before pruning:\n",
            "loss: 3.160399913787842 - accuracy: 0.2365 - val_loss: 2.969388484954834 - val_accuracy: 0.2774 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 26, 32, 75, 207], total units: 408\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.969395160675049 - val_accuracy: 0.2774 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 203], total units: 392\n",
            "##########################################################\n",
            "Epoch 6/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.969395160675049 - val_accuracy: 0.2774 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 203], total units: 392\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.9693946838378906 - val_accuracy: 0.2774 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 26, 32, 75, 209], total units: 410\n",
            "Before pruning:\n",
            "loss: 3.0353896617889404 - accuracy: 0.2597 - val_loss: 2.8661751747131348 - val_accuracy: 0.2947 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 26, 32, 75, 209], total units: 410\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.8662030696868896 - val_accuracy: 0.2948 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 205], total units: 394\n",
            "##########################################################\n",
            "Epoch 7/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8662030696868896 - val_accuracy: 0.2948 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 205], total units: 394\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8662030696868896 - val_accuracy: 0.2948 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 26, 32, 75, 211], total units: 412\n",
            "Before pruning:\n",
            "loss: 2.934731960296631 - accuracy: 0.27706 - val_loss: 2.7654354572296143 - val_accuracy: 0.3135 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 26, 32, 75, 211], total units: 412\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.7654383182525635 - val_accuracy: 0.3134 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 69, 202], total units: 388\n",
            "##########################################################\n",
            "Epoch 8/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.7654383182525635 - val_accuracy: 0.3134 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 69, 202], total units: 388\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.7654385566711426 - val_accuracy: 0.3134 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 26, 32, 72, 208], total units: 406\n",
            "Before pruning:\n",
            "loss: 2.8575849533081055 - accuracy: 0.29124 - val_loss: 2.7078301906585693 - val_accuracy: 0.3258 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 26, 32, 72, 208], total units: 406\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.7078332901000977 - val_accuracy: 0.3259 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 65, 202], total units: 384\n",
            "##########################################################\n",
            "Epoch 9/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.7078332901000977 - val_accuracy: 0.3259 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 65, 202], total units: 384\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.7078332901000977 - val_accuracy: 0.3259 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 26, 32, 68, 208], total units: 402\n",
            "Before pruning:\n",
            "loss: 2.793440103530884 - accuracy: 0.30326 - val_loss: 2.648170232772827 - val_accuracy: 0.3315 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 26, 32, 68, 208], total units: 402\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.6481783390045166 - val_accuracy: 0.3317 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 65, 202], total units: 384\n",
            "##########################################################\n",
            "Epoch 10/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.6481783390045166 - val_accuracy: 0.3317 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 65, 202], total units: 384\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.6481778621673584 - val_accuracy: 0.3317 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 26, 32, 68, 208], total units: 402\n",
            "Before pruning:\n",
            "loss: 2.739264965057373 - accuracy: 0.31482 - val_loss: 2.5894417762756348 - val_accuracy: 0.3476 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 26, 32, 68, 208], total units: 402\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.5894501209259033 - val_accuracy: 0.3476 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 65, 202], total units: 384\n",
            "##########################################################\n",
            "Epoch 11/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.5894501209259033 - val_accuracy: 0.3476 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 65, 202], total units: 384\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.5894501209259033 - val_accuracy: 0.3476 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 26, 32, 68, 208], total units: 402\n",
            "Before pruning:\n",
            "loss: 2.6808388233184814 - accuracy: 0.32476 - val_loss: 2.5756993293762207 - val_accuracy: 0.3511 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 26, 32, 68, 208], total units: 402\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.575709819793701 - val_accuracy: 0.3509 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 66, 202], total units: 385\n",
            "##########################################################\n",
            "Epoch 12/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.575709819793701 - val_accuracy: 0.3509 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 66, 202], total units: 385\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.5757100582122803 - val_accuracy: 0.3509 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 26, 32, 69, 208], total units: 403\n",
            "Before pruning:\n",
            "loss: 2.6506409645080566 - accuracy: 0.33048 - val_loss: 2.5265190601348877 - val_accuracy: 0.3584 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 26, 32, 69, 208], total units: 403\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.52652645111084 - val_accuracy: 0.3583 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 66, 202], total units: 385\n",
            "##########################################################\n",
            "Epoch 13/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.52652645111084 - val_accuracy: 0.3583 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 66, 202], total units: 385\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.526526689529419 - val_accuracy: 0.3583 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 26, 32, 69, 208], total units: 403\n",
            "Before pruning:\n",
            "loss: 2.6059165000915527 - accuracy: 0.33872 - val_loss: 2.48507022857666 - val_accuracy: 0.3656 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 26, 32, 69, 208], total units: 403\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.485069513320923 - val_accuracy: 0.3658 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 23, 29, 65, 202], total units: 383\n",
            "##########################################################\n",
            "Epoch 14/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.485069513320923 - val_accuracy: 0.3658 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 23, 29, 65, 202], total units: 383\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.485069513320923 - val_accuracy: 0.3658 - penalty: 2e-05\n",
            "hidden layer sizes: [67, 26, 32, 68, 208], total units: 401\n",
            "Before pruning:\n",
            "loss: 2.580200433731079 - accuracy: 0.34262 - val_loss: 2.44836688041687 - val_accuracy: 0.3778 - penalty: 2e-05\n",
            "hidden layer sizes: [67, 26, 32, 68, 208], total units: 401\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.4483892917633057 - val_accuracy: 0.3776 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 23, 29, 64, 202], total units: 382\n",
            "##########################################################\n",
            "Epoch 15/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4483892917633057 - val_accuracy: 0.3776 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 23, 29, 64, 202], total units: 382\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4483890533447266 - val_accuracy: 0.3776 - penalty: 2e-05\n",
            "hidden layer sizes: [67, 26, 32, 67, 208], total units: 400\n",
            "Before pruning:\n",
            "loss: 2.5501315593719482 - accuracy: 0.35102 - val_loss: 2.437520980834961 - val_accuracy: 0.3768 - penalty: 2e-05\n",
            "hidden layer sizes: [67, 26, 32, 67, 208], total units: 400\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.4375319480895996 - val_accuracy: 0.3767 - penalty: 2e-05\n",
            "hidden layer sizes: [63, 23, 29, 64, 202], total units: 381\n",
            "##########################################################\n",
            "Epoch 16/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4375319480895996 - val_accuracy: 0.3767 - penalty: 2e-05\n",
            "hidden layer sizes: [63, 23, 29, 64, 202], total units: 381\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4375319480895996 - val_accuracy: 0.3767 - penalty: 2e-05\n",
            "hidden layer sizes: [66, 26, 32, 67, 208], total units: 399\n",
            "Before pruning:\n",
            "loss: 2.5222718715667725 - accuracy: 0.35528 - val_loss: 2.413971185684204 - val_accuracy: 0.3815 - penalty: 2e-05\n",
            "hidden layer sizes: [66, 26, 32, 67, 208], total units: 399\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.4139795303344727 - val_accuracy: 0.3815 - penalty: 2e-05\n",
            "hidden layer sizes: [63, 23, 29, 65, 203], total units: 383\n",
            "##########################################################\n",
            "Epoch 17/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4139795303344727 - val_accuracy: 0.3815 - penalty: 2e-05\n",
            "hidden layer sizes: [63, 23, 29, 65, 203], total units: 383\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4139790534973145 - val_accuracy: 0.3815 - penalty: 2e-05\n",
            "hidden layer sizes: [66, 26, 32, 68, 209], total units: 401\n",
            "Before pruning:\n",
            "loss: 2.497480869293213 - accuracy: 0.36306 - val_loss: 2.3980228900909424 - val_accuracy: 0.3835 - penalty: 2e-05\n",
            "hidden layer sizes: [66, 26, 32, 68, 209], total units: 401\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3980088233947754 - val_accuracy: 0.3834 - penalty: 2e-05\n",
            "hidden layer sizes: [63, 23, 29, 65, 205], total units: 385\n",
            "##########################################################\n",
            "Epoch 18/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3980088233947754 - val_accuracy: 0.3834 - penalty: 2e-05\n",
            "hidden layer sizes: [63, 23, 29, 65, 205], total units: 385\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3980088233947754 - val_accuracy: 0.3834 - penalty: 2e-05\n",
            "hidden layer sizes: [66, 26, 32, 68, 211], total units: 403\n",
            "Before pruning:\n",
            "loss: 2.478321075439453 - accuracy: 0.36488 - val_loss: 2.385770797729492 - val_accuracy: 0.386 - penalty: 2e-05\n",
            "hidden layer sizes: [66, 26, 32, 68, 211], total units: 403\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3857877254486084 - val_accuracy: 0.3862 - penalty: 2e-05\n",
            "hidden layer sizes: [63, 23, 29, 65, 203], total units: 383\n",
            "##########################################################\n",
            "Epoch 19/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3857877254486084 - val_accuracy: 0.3862 - penalty: 2e-05\n",
            "hidden layer sizes: [63, 23, 29, 65, 203], total units: 383\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3857877254486084 - val_accuracy: 0.3862 - penalty: 2e-05\n",
            "hidden layer sizes: [66, 26, 32, 68, 209], total units: 401\n",
            "Before pruning:\n",
            "loss: 2.4641919136047363 - accuracy: 0.36598 - val_loss: 2.3593978881835938 - val_accuracy: 0.39 - penalty: 2e-05\n",
            "hidden layer sizes: [66, 26, 32, 68, 209], total units: 401\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3593976497650146 - val_accuracy: 0.3901 - penalty: 2e-05\n",
            "hidden layer sizes: [62, 23, 29, 66, 204], total units: 384\n",
            "##########################################################\n",
            "Epoch 20/45\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3593976497650146 - val_accuracy: 0.3901 - penalty: 2e-05\n",
            "hidden layer sizes: [62, 23, 29, 66, 204], total units: 384\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3593978881835938 - val_accuracy: 0.3901 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 26, 32, 69, 210], total units: 402\n",
            "Before pruning:\n",
            "loss: 2.4452664852142334 - accuracy: 0.37126 - val_loss: 2.348524332046509 - val_accuracy: 0.3911 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 26, 32, 69, 210], total units: 402\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3485236167907715 - val_accuracy: 0.3912 - penalty: 2e-05\n",
            "hidden layer sizes: [62, 23, 29, 66, 204], total units: 384\n",
            "##########################################################\n",
            "Epoch 21/45\n",
            "Before pruning:\n",
            "loss: 2.4284355640411377 - accuracy: 0.37652 - val_loss: 2.3363518714904785 - val_accuracy: 0.4001 - penalty: 2e-05\n",
            "hidden layer sizes: [62, 23, 29, 66, 204], total units: 384\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3363518714904785 - val_accuracy: 0.4001 - penalty: 2e-05\n",
            "hidden layer sizes: [62, 23, 29, 66, 204], total units: 384\n",
            "##########################################################\n",
            "Epoch 22/45\n",
            "Before pruning:\n",
            "loss: 2.4075450897216797 - accuracy: 0.37676 - val_loss: 2.3265321254730225 - val_accuracy: 0.3957 - penalty: 2e-05\n",
            "hidden layer sizes: [62, 23, 29, 66, 204], total units: 384\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3265371322631836 - val_accuracy: 0.3957 - penalty: 2e-05\n",
            "hidden layer sizes: [61, 23, 29, 66, 204], total units: 383\n",
            "##########################################################\n",
            "Epoch 23/45\n",
            "Before pruning:\n",
            "loss: 2.3968687057495117 - accuracy: 0.38052 - val_loss: 2.304795980453491 - val_accuracy: 0.4026 - penalty: 2e-05\n",
            "hidden layer sizes: [61, 23, 29, 66, 204], total units: 383\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.304795980453491 - val_accuracy: 0.4026 - penalty: 2e-05\n",
            "hidden layer sizes: [61, 23, 29, 66, 204], total units: 383\n",
            "##########################################################\n",
            "Epoch 24/45\n",
            "Before pruning:\n",
            "loss: 2.3771581649780273 - accuracy: 0.3851 - val_loss: 2.3065552711486816 - val_accuracy: 0.4002 - penalty: 2e-05\n",
            "hidden layer sizes: [61, 23, 29, 66, 204], total units: 383\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3065476417541504 - val_accuracy: 0.4002 - penalty: 2e-05\n",
            "hidden layer sizes: [58, 23, 29, 66, 204], total units: 380\n",
            "##########################################################\n",
            "Epoch 25/45\n",
            "Before pruning:\n",
            "loss: 2.3731000423431396 - accuracy: 0.38582 - val_loss: 2.297581195831299 - val_accuracy: 0.4047 - penalty: 2e-05\n",
            "hidden layer sizes: [58, 23, 29, 66, 204], total units: 380\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.297581195831299 - val_accuracy: 0.4047 - penalty: 2e-05\n",
            "hidden layer sizes: [58, 23, 29, 66, 204], total units: 380\n",
            "##########################################################\n",
            "Epoch 26/45\n",
            "loss: 2.4151949882507324 - accuracy: 0.37816 - val_loss: 2.249152183532715 - val_accuracy: 0.4181 - penalty: 0.0\n",
            "hidden layer sizes: [58, 23, 29, 66, 204], total units: 380\n",
            "##########################################################\n",
            "Epoch 27/45\n",
            "loss: 2.1201510429382324 - accuracy: 0.44222 - val_loss: 2.1981101036071777 - val_accuracy: 0.4329 - penalty: 0.0\n",
            "hidden layer sizes: [58, 23, 29, 66, 204], total units: 380\n",
            "##########################################################\n",
            "Epoch 28/45\n",
            "loss: 2.013026475906372 - accuracy: 0.47036 - val_loss: 2.1677186489105225 - val_accuracy: 0.4418 - penalty: 0.0\n",
            "hidden layer sizes: [58, 23, 29, 66, 204], total units: 380\n",
            "##########################################################\n",
            "Epoch 29/45\n",
            "loss: 1.905981421470642 - accuracy: 0.49168 - val_loss: 2.1643974781036377 - val_accuracy: 0.4447 - penalty: 0.0\n",
            "hidden layer sizes: [58, 23, 29, 66, 204], total units: 380\n",
            "##########################################################\n",
            "Epoch 30/45\n",
            "loss: 1.8179380893707275 - accuracy: 0.5112 - val_loss: 2.1726925373077393 - val_accuracy: 0.4476 - penalty: 0.0\n",
            "hidden layer sizes: [58, 23, 29, 66, 204], total units: 380\n",
            "##########################################################\n",
            "Epoch 31/45\n",
            "loss: 1.7305442094802856 - accuracy: 0.53198 - val_loss: 2.1693222522735596 - val_accuracy: 0.4464 - penalty: 0.0\n",
            "hidden layer sizes: [58, 23, 29, 66, 204], total units: 380\n",
            "##########################################################\n",
            "Epoch 32/45\n",
            "loss: 1.656730055809021 - accuracy: 0.54832 - val_loss: 2.18371319770813 - val_accuracy: 0.4505 - penalty: 0.0\n",
            "hidden layer sizes: [58, 23, 29, 66, 204], total units: 380\n",
            "##########################################################\n",
            "Epoch 33/45\n",
            "loss: 1.5858503580093384 - accuracy: 0.56712 - val_loss: 2.1915476322174072 - val_accuracy: 0.4513 - penalty: 0.0\n",
            "hidden layer sizes: [58, 23, 29, 66, 204], total units: 380\n",
            "##########################################################\n",
            "Epoch 34/45\n",
            "loss: 1.5102075338363647 - accuracy: 0.58414 - val_loss: 2.217080593109131 - val_accuracy: 0.4509 - penalty: 0.0\n",
            "hidden layer sizes: [58, 23, 29, 66, 204], total units: 380\n",
            "##########################################################\n",
            "Epoch 35/45\n",
            "loss: 1.4532350301742554 - accuracy: 0.59502 - val_loss: 2.2267682552337646 - val_accuracy: 0.4467 - penalty: 0.0\n",
            "hidden layer sizes: [58, 23, 29, 66, 204], total units: 380\n",
            "##########################################################\n",
            "Epoch 36/45\n",
            "loss: 1.3927836418151855 - accuracy: 0.60912 - val_loss: 2.2502732276916504 - val_accuracy: 0.4551 - penalty: 0.0\n",
            "hidden layer sizes: [58, 23, 29, 66, 204], total units: 380\n",
            "##########################################################\n",
            "Epoch 37/45\n",
            "loss: 1.346289038658142 - accuracy: 0.62166 - val_loss: 2.2672500610351562 - val_accuracy: 0.4511 - penalty: 0.0\n",
            "hidden layer sizes: [58, 23, 29, 66, 204], total units: 380\n",
            "##########################################################\n",
            "Epoch 38/45\n",
            "loss: 1.2892512083053589 - accuracy: 0.63244 - val_loss: 2.2893447875976562 - val_accuracy: 0.4476 - penalty: 0.0\n",
            "hidden layer sizes: [58, 23, 29, 66, 204], total units: 380\n",
            "##########################################################\n",
            "Epoch 39/45\n",
            "loss: 1.2460119724273682 - accuracy: 0.64212 - val_loss: 2.3301949501037598 - val_accuracy: 0.4481 - penalty: 0.0\n",
            "hidden layer sizes: [58, 23, 29, 66, 204], total units: 380\n",
            "##########################################################\n",
            "Epoch 40/45\n",
            "loss: 1.2008585929870605 - accuracy: 0.65272 - val_loss: 2.3571534156799316 - val_accuracy: 0.4443 - penalty: 0.0\n",
            "hidden layer sizes: [58, 23, 29, 66, 204], total units: 380\n",
            "##########################################################\n",
            "Epoch 41/45\n",
            "loss: 1.1614043712615967 - accuracy: 0.6631 - val_loss: 2.3685503005981445 - val_accuracy: 0.4484 - penalty: 0.0\n",
            "hidden layer sizes: [58, 23, 29, 66, 204], total units: 380\n",
            "##########################################################\n",
            "Epoch 42/45\n",
            "loss: 1.1157997846603394 - accuracy: 0.67496 - val_loss: 2.3984298706054688 - val_accuracy: 0.4483 - penalty: 0.0\n",
            "hidden layer sizes: [58, 23, 29, 66, 204], total units: 380\n",
            "##########################################################\n",
            "Epoch 43/45\n",
            "loss: 1.0950140953063965 - accuracy: 0.6782 - val_loss: 2.408940076828003 - val_accuracy: 0.444 - penalty: 0.0\n",
            "hidden layer sizes: [58, 23, 29, 66, 204], total units: 380\n",
            "##########################################################\n",
            "Epoch 44/45\n",
            "loss: 1.0573185682296753 - accuracy: 0.68672 - val_loss: 2.4557743072509766 - val_accuracy: 0.4433 - penalty: 0.0\n",
            "hidden layer sizes: [58, 23, 29, 66, 204], total units: 380\n",
            "##########################################################\n",
            "Epoch 45/45\n",
            "loss: 1.0207405090332031 - accuracy: 0.69862 - val_loss: 2.4588801860809326 - val_accuracy: 0.4435 - penalty: 0.0\n",
            "hidden layer sizes: [58, 23, 29, 66, 204], total units: 380\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.1083,\n",
              "  0.159,\n",
              "  0.18468,\n",
              "  0.20968,\n",
              "  0.2365,\n",
              "  0.2597,\n",
              "  0.27706,\n",
              "  0.29124,\n",
              "  0.30326,\n",
              "  0.31482,\n",
              "  0.32476,\n",
              "  0.33048,\n",
              "  0.33872,\n",
              "  0.34262,\n",
              "  0.35102,\n",
              "  0.35528,\n",
              "  0.36306,\n",
              "  0.36488,\n",
              "  0.36598,\n",
              "  0.37126,\n",
              "  0.37652,\n",
              "  0.37676,\n",
              "  0.38052,\n",
              "  0.3851,\n",
              "  0.38582,\n",
              "  0.37816,\n",
              "  0.44222,\n",
              "  0.47036,\n",
              "  0.49168,\n",
              "  0.5112,\n",
              "  0.53198,\n",
              "  0.54832,\n",
              "  0.56712,\n",
              "  0.58414,\n",
              "  0.59502,\n",
              "  0.60912,\n",
              "  0.62166,\n",
              "  0.63244,\n",
              "  0.64212,\n",
              "  0.65272,\n",
              "  0.6631,\n",
              "  0.67496,\n",
              "  0.6782,\n",
              "  0.68672,\n",
              "  0.69862],\n",
              " 'hidden_layer_sizes': [[65, 25, 29, 72, 201],\n",
              "  [65, 25, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 203],\n",
              "  [65, 23, 29, 72, 205],\n",
              "  [65, 23, 29, 69, 202],\n",
              "  [65, 23, 29, 65, 202],\n",
              "  [65, 23, 29, 65, 202],\n",
              "  [65, 23, 29, 65, 202],\n",
              "  [65, 23, 29, 66, 202],\n",
              "  [65, 23, 29, 66, 202],\n",
              "  [64, 23, 29, 65, 202],\n",
              "  [64, 23, 29, 64, 202],\n",
              "  [63, 23, 29, 64, 202],\n",
              "  [63, 23, 29, 65, 203],\n",
              "  [63, 23, 29, 65, 205],\n",
              "  [63, 23, 29, 65, 203],\n",
              "  [62, 23, 29, 66, 204],\n",
              "  [62, 23, 29, 66, 204],\n",
              "  [62, 23, 29, 66, 204],\n",
              "  [61, 23, 29, 66, 204],\n",
              "  [61, 23, 29, 66, 204],\n",
              "  [58, 23, 29, 66, 204],\n",
              "  [58, 23, 29, 66, 204],\n",
              "  [58, 23, 29, 66, 204],\n",
              "  [58, 23, 29, 66, 204],\n",
              "  [58, 23, 29, 66, 204],\n",
              "  [58, 23, 29, 66, 204],\n",
              "  [58, 23, 29, 66, 204],\n",
              "  [58, 23, 29, 66, 204],\n",
              "  [58, 23, 29, 66, 204],\n",
              "  [58, 23, 29, 66, 204],\n",
              "  [58, 23, 29, 66, 204],\n",
              "  [58, 23, 29, 66, 204],\n",
              "  [58, 23, 29, 66, 204],\n",
              "  [58, 23, 29, 66, 204],\n",
              "  [58, 23, 29, 66, 204],\n",
              "  [58, 23, 29, 66, 204],\n",
              "  [58, 23, 29, 66, 204],\n",
              "  [58, 23, 29, 66, 204],\n",
              "  [58, 23, 29, 66, 204],\n",
              "  [58, 23, 29, 66, 204],\n",
              "  [58, 23, 29, 66, 204],\n",
              "  [58, 23, 29, 66, 204]],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=4.0235558>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.6292481>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.4776196>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.329527>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.1604>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.0353897>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.934732>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.857585>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.79344>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.739265>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.6808388>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.650641>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.6059165>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.5802004>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.5501316>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.5222719>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4974809>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.478321>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.464192>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4452665>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4284356>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.407545>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3968687>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3771582>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3731>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.415195>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.120151>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.0130265>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.9059814>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.8179381>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.7305442>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.65673>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.5858504>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.5102075>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.453235>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3927836>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.346289>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2892512>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.246012>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2008586>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1614044>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1157998>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0950141>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0573186>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.0207405>],\n",
              " 'val_accuracy': [0.1695,\n",
              "  0.1866,\n",
              "  0.2119,\n",
              "  0.2437,\n",
              "  0.2774,\n",
              "  0.2948,\n",
              "  0.3134,\n",
              "  0.3259,\n",
              "  0.3317,\n",
              "  0.3476,\n",
              "  0.3509,\n",
              "  0.3583,\n",
              "  0.3658,\n",
              "  0.3776,\n",
              "  0.3767,\n",
              "  0.3815,\n",
              "  0.3834,\n",
              "  0.3862,\n",
              "  0.3901,\n",
              "  0.3912,\n",
              "  0.4001,\n",
              "  0.3957,\n",
              "  0.4026,\n",
              "  0.4002,\n",
              "  0.4047,\n",
              "  0.4181,\n",
              "  0.4329,\n",
              "  0.4418,\n",
              "  0.4447,\n",
              "  0.4476,\n",
              "  0.4464,\n",
              "  0.4505,\n",
              "  0.4513,\n",
              "  0.4509,\n",
              "  0.4467,\n",
              "  0.4551,\n",
              "  0.4511,\n",
              "  0.4476,\n",
              "  0.4481,\n",
              "  0.4443,\n",
              "  0.4484,\n",
              "  0.4483,\n",
              "  0.444,\n",
              "  0.4433,\n",
              "  0.4435],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=3.6138306>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.4726274>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.3282228>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.145945>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.9693952>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.866203>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.7654383>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.7078333>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.6481783>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.5894501>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.5757098>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.5265265>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4850695>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4483893>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.437532>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4139795>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3980088>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3857877>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3593976>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3485236>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3363519>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3265371>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.304796>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3065476>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.2975812>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.2491522>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.19811>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.1677186>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.1643975>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.1726925>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.1693223>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.1837132>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.1915476>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.2170806>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.2267683>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.2502732>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.26725>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.2893448>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.330195>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3571534>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3685503>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3984299>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.40894>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4557743>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4588802>]}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlziwCCzWiNT",
        "outputId": "8e206eda-b594-4635-bd72-c2a42b3b199c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_fn(learning_rate=0.0002, regularization_penalty=0.00002, regularization_method='weighted_l1', self_scaling_epochs=25, \n",
        "         layer_sizes=[65, 23, 29, 72, 201], epochs=45, pruning_only_epochs=25, min_new_neurons=1, growth_percentage=0., output_neurons=100, verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/45\n",
            "Before pruning:\n",
            "loss: 3.992975950241089 - accuracy: 0.11334 - val_loss: 3.6081390380859375 - val_accuracy: 0.1674 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.6081390380859375 - val_accuracy: 0.1674 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 2/45\n",
            "Before pruning:\n",
            "loss: 3.6014726161956787 - accuracy: 0.16406 - val_loss: 3.4407148361206055 - val_accuracy: 0.1902 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.4407148361206055 - val_accuracy: 0.1902 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 3/45\n",
            "Before pruning:\n",
            "loss: 3.4443089962005615 - accuracy: 0.18686 - val_loss: 3.3004307746887207 - val_accuracy: 0.2118 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.3004307746887207 - val_accuracy: 0.2118 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 4/45\n",
            "Before pruning:\n",
            "loss: 3.271906614303589 - accuracy: 0.21404 - val_loss: 3.1017374992370605 - val_accuracy: 0.2502 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.1017374992370605 - val_accuracy: 0.2502 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 5/45\n",
            "Before pruning:\n",
            "loss: 3.1333634853363037 - accuracy: 0.24042 - val_loss: 2.97485613822937 - val_accuracy: 0.2784 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.97485613822937 - val_accuracy: 0.2784 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 6/45\n",
            "Before pruning:\n",
            "loss: 3.0327186584472656 - accuracy: 0.26002 - val_loss: 2.8958210945129395 - val_accuracy: 0.2904 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.8958210945129395 - val_accuracy: 0.2904 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 71, 201], total units: 389\n",
            "##########################################################\n",
            "Epoch 7/45\n",
            "Before pruning:\n",
            "loss: 2.9452197551727295 - accuracy: 0.2753 - val_loss: 2.7922496795654297 - val_accuracy: 0.3118 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 71, 201], total units: 389\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.7922496795654297 - val_accuracy: 0.3118 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 71, 201], total units: 389\n",
            "##########################################################\n",
            "Epoch 8/45\n",
            "Before pruning:\n",
            "loss: 2.8727309703826904 - accuracy: 0.28964 - val_loss: 2.737419843673706 - val_accuracy: 0.323 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 71, 201], total units: 389\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.737419843673706 - val_accuracy: 0.323 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 71, 201], total units: 389\n",
            "##########################################################\n",
            "Epoch 9/45\n",
            "Before pruning:\n",
            "loss: 2.8100228309631348 - accuracy: 0.30378 - val_loss: 2.6826324462890625 - val_accuracy: 0.3372 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 71, 201], total units: 389\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.6826300621032715 - val_accuracy: 0.337 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 69, 201], total units: 387\n",
            "##########################################################\n",
            "Epoch 10/45\n",
            "Before pruning:\n",
            "loss: 2.760136842727661 - accuracy: 0.3089 - val_loss: 2.62060284614563 - val_accuracy: 0.343 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 69, 201], total units: 387\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.6205973625183105 - val_accuracy: 0.3429 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 67, 201], total units: 385\n",
            "##########################################################\n",
            "Epoch 11/45\n",
            "Before pruning:\n",
            "loss: 2.7081708908081055 - accuracy: 0.32214 - val_loss: 2.576409339904785 - val_accuracy: 0.3538 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 67, 201], total units: 385\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.5764079093933105 - val_accuracy: 0.3538 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 66, 201], total units: 384\n",
            "##########################################################\n",
            "Epoch 12/45\n",
            "Before pruning:\n",
            "loss: 2.6570894718170166 - accuracy: 0.33034 - val_loss: 2.539658784866333 - val_accuracy: 0.359 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 66, 201], total units: 384\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.5396549701690674 - val_accuracy: 0.359 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 65, 201], total units: 383\n",
            "##########################################################\n",
            "Epoch 13/45\n",
            "Before pruning:\n",
            "loss: 2.6219887733459473 - accuracy: 0.33752 - val_loss: 2.4995696544647217 - val_accuracy: 0.364 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 65, 201], total units: 383\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.4995696544647217 - val_accuracy: 0.364 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 64, 201], total units: 382\n",
            "##########################################################\n",
            "Epoch 14/45\n",
            "Before pruning:\n",
            "loss: 2.586764097213745 - accuracy: 0.3441 - val_loss: 2.4561448097229004 - val_accuracy: 0.3751 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 64, 201], total units: 382\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.456139326095581 - val_accuracy: 0.3751 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 23, 29, 64, 201], total units: 381\n",
            "##########################################################\n",
            "Epoch 15/45\n",
            "Before pruning:\n",
            "loss: 2.5503015518188477 - accuracy: 0.35336 - val_loss: 2.441009283065796 - val_accuracy: 0.3761 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 23, 29, 64, 201], total units: 381\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.441009283065796 - val_accuracy: 0.3761 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 23, 29, 64, 201], total units: 381\n",
            "##########################################################\n",
            "Epoch 16/45\n",
            "Before pruning:\n",
            "loss: 2.5243730545043945 - accuracy: 0.35844 - val_loss: 2.4120261669158936 - val_accuracy: 0.384 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 23, 29, 64, 201], total units: 381\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.412024736404419 - val_accuracy: 0.384 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 23, 29, 63, 201], total units: 380\n",
            "##########################################################\n",
            "Epoch 17/45\n",
            "Before pruning:\n",
            "loss: 2.5047683715820312 - accuracy: 0.3621 - val_loss: 2.3961527347564697 - val_accuracy: 0.3901 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 23, 29, 63, 201], total units: 380\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.396148681640625 - val_accuracy: 0.39 - penalty: 2e-05\n",
            "hidden layer sizes: [62, 23, 29, 63, 201], total units: 378\n",
            "##########################################################\n",
            "Epoch 18/45\n",
            "Before pruning:\n",
            "loss: 2.4871251583099365 - accuracy: 0.36476 - val_loss: 2.3635692596435547 - val_accuracy: 0.3914 - penalty: 2e-05\n",
            "hidden layer sizes: [62, 23, 29, 63, 201], total units: 378\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3635690212249756 - val_accuracy: 0.3914 - penalty: 2e-05\n",
            "hidden layer sizes: [61, 23, 29, 63, 201], total units: 377\n",
            "##########################################################\n",
            "Epoch 19/45\n",
            "Before pruning:\n",
            "loss: 2.4641010761260986 - accuracy: 0.36848 - val_loss: 2.348604679107666 - val_accuracy: 0.3969 - penalty: 2e-05\n",
            "hidden layer sizes: [61, 23, 29, 63, 201], total units: 377\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.348604679107666 - val_accuracy: 0.3969 - penalty: 2e-05\n",
            "hidden layer sizes: [61, 23, 29, 63, 201], total units: 377\n",
            "##########################################################\n",
            "Epoch 20/45\n",
            "Before pruning:\n",
            "loss: 2.449843168258667 - accuracy: 0.37152 - val_loss: 2.3420655727386475 - val_accuracy: 0.3958 - penalty: 2e-05\n",
            "hidden layer sizes: [61, 23, 29, 63, 201], total units: 377\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3420629501342773 - val_accuracy: 0.3958 - penalty: 2e-05\n",
            "hidden layer sizes: [59, 23, 29, 63, 201], total units: 375\n",
            "##########################################################\n",
            "Epoch 21/45\n",
            "Before pruning:\n",
            "loss: 2.429506540298462 - accuracy: 0.3756 - val_loss: 2.3308634757995605 - val_accuracy: 0.401 - penalty: 2e-05\n",
            "hidden layer sizes: [59, 23, 29, 63, 201], total units: 375\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3308634757995605 - val_accuracy: 0.401 - penalty: 2e-05\n",
            "hidden layer sizes: [59, 23, 29, 63, 201], total units: 375\n",
            "##########################################################\n",
            "Epoch 22/45\n",
            "Before pruning:\n",
            "loss: 2.4178545475006104 - accuracy: 0.37704 - val_loss: 2.303957939147949 - val_accuracy: 0.4076 - penalty: 2e-05\n",
            "hidden layer sizes: [59, 23, 29, 63, 201], total units: 375\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.303952932357788 - val_accuracy: 0.4076 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 23, 29, 63, 201], total units: 373\n",
            "##########################################################\n",
            "Epoch 23/45\n",
            "Before pruning:\n",
            "loss: 2.3966801166534424 - accuracy: 0.38282 - val_loss: 2.2909815311431885 - val_accuracy: 0.408 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 23, 29, 63, 201], total units: 373\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.2909815311431885 - val_accuracy: 0.408 - penalty: 2e-05\n",
            "hidden layer sizes: [55, 23, 29, 63, 201], total units: 371\n",
            "##########################################################\n",
            "Epoch 24/45\n",
            "Before pruning:\n",
            "loss: 2.3843722343444824 - accuracy: 0.38352 - val_loss: 2.2992022037506104 - val_accuracy: 0.4093 - penalty: 2e-05\n",
            "hidden layer sizes: [55, 23, 29, 63, 201], total units: 371\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.299194812774658 - val_accuracy: 0.4093 - penalty: 2e-05\n",
            "hidden layer sizes: [54, 23, 29, 63, 201], total units: 370\n",
            "##########################################################\n",
            "Epoch 25/45\n",
            "Before pruning:\n",
            "loss: 2.3734235763549805 - accuracy: 0.38778 - val_loss: 2.272921562194824 - val_accuracy: 0.4155 - penalty: 2e-05\n",
            "hidden layer sizes: [54, 23, 29, 63, 201], total units: 370\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.272913932800293 - val_accuracy: 0.4154 - penalty: 2e-05\n",
            "hidden layer sizes: [53, 23, 29, 63, 201], total units: 369\n",
            "##########################################################\n",
            "Epoch 26/45\n",
            "loss: 2.4148850440979004 - accuracy: 0.38028 - val_loss: 2.236391544342041 - val_accuracy: 0.4227 - penalty: 0.0\n",
            "hidden layer sizes: [53, 23, 29, 63, 201], total units: 369\n",
            "##########################################################\n",
            "Epoch 27/45\n",
            "loss: 2.1179697513580322 - accuracy: 0.4454 - val_loss: 2.1881356239318848 - val_accuracy: 0.4341 - penalty: 0.0\n",
            "hidden layer sizes: [53, 23, 29, 63, 201], total units: 369\n",
            "##########################################################\n",
            "Epoch 28/45\n",
            "loss: 2.004481792449951 - accuracy: 0.47324 - val_loss: 2.1780619621276855 - val_accuracy: 0.4374 - penalty: 0.0\n",
            "hidden layer sizes: [53, 23, 29, 63, 201], total units: 369\n",
            "##########################################################\n",
            "Epoch 29/45\n",
            "loss: 1.913128137588501 - accuracy: 0.49116 - val_loss: 2.1784884929656982 - val_accuracy: 0.4349 - penalty: 0.0\n",
            "hidden layer sizes: [53, 23, 29, 63, 201], total units: 369\n",
            "##########################################################\n",
            "Epoch 30/45\n",
            "loss: 1.8258756399154663 - accuracy: 0.51296 - val_loss: 2.182488203048706 - val_accuracy: 0.4402 - penalty: 0.0\n",
            "hidden layer sizes: [53, 23, 29, 63, 201], total units: 369\n",
            "##########################################################\n",
            "Epoch 31/45\n",
            "loss: 1.7481272220611572 - accuracy: 0.53066 - val_loss: 2.1753430366516113 - val_accuracy: 0.4421 - penalty: 0.0\n",
            "hidden layer sizes: [53, 23, 29, 63, 201], total units: 369\n",
            "##########################################################\n",
            "Epoch 32/45\n",
            "loss: 1.6770739555358887 - accuracy: 0.54682 - val_loss: 2.1804358959198 - val_accuracy: 0.4451 - penalty: 0.0\n",
            "hidden layer sizes: [53, 23, 29, 63, 201], total units: 369\n",
            "##########################################################\n",
            "Epoch 33/45\n",
            "loss: 1.6040563583374023 - accuracy: 0.56188 - val_loss: 2.1916744709014893 - val_accuracy: 0.448 - penalty: 0.0\n",
            "hidden layer sizes: [53, 23, 29, 63, 201], total units: 369\n",
            "##########################################################\n",
            "Epoch 34/45\n",
            "loss: 1.5495991706848145 - accuracy: 0.57644 - val_loss: 2.2077345848083496 - val_accuracy: 0.45 - penalty: 0.0\n",
            "hidden layer sizes: [53, 23, 29, 63, 201], total units: 369\n",
            "##########################################################\n",
            "Epoch 35/45\n",
            "loss: 1.4851268529891968 - accuracy: 0.59178 - val_loss: 2.218104600906372 - val_accuracy: 0.4534 - penalty: 0.0\n",
            "hidden layer sizes: [53, 23, 29, 63, 201], total units: 369\n",
            "##########################################################\n",
            "Epoch 36/45\n",
            "loss: 1.4248498678207397 - accuracy: 0.6036 - val_loss: 2.2310311794281006 - val_accuracy: 0.4515 - penalty: 0.0\n",
            "hidden layer sizes: [53, 23, 29, 63, 201], total units: 369\n",
            "##########################################################\n",
            "Epoch 37/45\n",
            "loss: 1.3794257640838623 - accuracy: 0.6134 - val_loss: 2.257868528366089 - val_accuracy: 0.4503 - penalty: 0.0\n",
            "hidden layer sizes: [53, 23, 29, 63, 201], total units: 369\n",
            "##########################################################\n",
            "Epoch 38/45\n",
            "loss: 1.3296386003494263 - accuracy: 0.62668 - val_loss: 2.2771694660186768 - val_accuracy: 0.4512 - penalty: 0.0\n",
            "hidden layer sizes: [53, 23, 29, 63, 201], total units: 369\n",
            "##########################################################\n",
            "Epoch 39/45\n",
            "loss: 1.2879384756088257 - accuracy: 0.63468 - val_loss: 2.2963449954986572 - val_accuracy: 0.4534 - penalty: 0.0\n",
            "hidden layer sizes: [53, 23, 29, 63, 201], total units: 369\n",
            "##########################################################\n",
            "Epoch 40/45\n",
            "loss: 1.2325202226638794 - accuracy: 0.6489 - val_loss: 2.310500383377075 - val_accuracy: 0.4518 - penalty: 0.0\n",
            "hidden layer sizes: [53, 23, 29, 63, 201], total units: 369\n",
            "##########################################################\n",
            "Epoch 41/45\n",
            "loss: 1.2035959959030151 - accuracy: 0.65284 - val_loss: 2.3350744247436523 - val_accuracy: 0.4529 - penalty: 0.0\n",
            "hidden layer sizes: [53, 23, 29, 63, 201], total units: 369\n",
            "##########################################################\n",
            "Epoch 42/45\n",
            "loss: 1.1740236282348633 - accuracy: 0.66126 - val_loss: 2.365853786468506 - val_accuracy: 0.45 - penalty: 0.0\n",
            "hidden layer sizes: [53, 23, 29, 63, 201], total units: 369\n",
            "##########################################################\n",
            "Epoch 43/45\n",
            "loss: 1.1307308673858643 - accuracy: 0.67116 - val_loss: 2.406327724456787 - val_accuracy: 0.4469 - penalty: 0.0\n",
            "hidden layer sizes: [53, 23, 29, 63, 201], total units: 369\n",
            "##########################################################\n",
            "Epoch 44/45\n",
            "loss: 1.1021195650100708 - accuracy: 0.67646 - val_loss: 2.4032537937164307 - val_accuracy: 0.4521 - penalty: 0.0\n",
            "hidden layer sizes: [53, 23, 29, 63, 201], total units: 369\n",
            "##########################################################\n",
            "Epoch 45/45\n",
            "loss: 1.0740859508514404 - accuracy: 0.68608 - val_loss: 2.4162983894348145 - val_accuracy: 0.4503 - penalty: 0.0\n",
            "hidden layer sizes: [53, 23, 29, 63, 201], total units: 369\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.11334,\n",
              "  0.16406,\n",
              "  0.18686,\n",
              "  0.21404,\n",
              "  0.24042,\n",
              "  0.26002,\n",
              "  0.2753,\n",
              "  0.28964,\n",
              "  0.30378,\n",
              "  0.3089,\n",
              "  0.32214,\n",
              "  0.33034,\n",
              "  0.33752,\n",
              "  0.3441,\n",
              "  0.35336,\n",
              "  0.35844,\n",
              "  0.3621,\n",
              "  0.36476,\n",
              "  0.36848,\n",
              "  0.37152,\n",
              "  0.3756,\n",
              "  0.37704,\n",
              "  0.38282,\n",
              "  0.38352,\n",
              "  0.38778,\n",
              "  0.38028,\n",
              "  0.4454,\n",
              "  0.47324,\n",
              "  0.49116,\n",
              "  0.51296,\n",
              "  0.53066,\n",
              "  0.54682,\n",
              "  0.56188,\n",
              "  0.57644,\n",
              "  0.59178,\n",
              "  0.6036,\n",
              "  0.6134,\n",
              "  0.62668,\n",
              "  0.63468,\n",
              "  0.6489,\n",
              "  0.65284,\n",
              "  0.66126,\n",
              "  0.67116,\n",
              "  0.67646,\n",
              "  0.68608],\n",
              " 'hidden_layer_sizes': [[65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 71, 201],\n",
              "  [65, 23, 29, 71, 201],\n",
              "  [65, 23, 29, 71, 201],\n",
              "  [65, 23, 29, 69, 201],\n",
              "  [65, 23, 29, 67, 201],\n",
              "  [65, 23, 29, 66, 201],\n",
              "  [65, 23, 29, 65, 201],\n",
              "  [65, 23, 29, 64, 201],\n",
              "  [64, 23, 29, 64, 201],\n",
              "  [64, 23, 29, 64, 201],\n",
              "  [64, 23, 29, 63, 201],\n",
              "  [62, 23, 29, 63, 201],\n",
              "  [61, 23, 29, 63, 201],\n",
              "  [61, 23, 29, 63, 201],\n",
              "  [59, 23, 29, 63, 201],\n",
              "  [59, 23, 29, 63, 201],\n",
              "  [57, 23, 29, 63, 201],\n",
              "  [55, 23, 29, 63, 201],\n",
              "  [54, 23, 29, 63, 201],\n",
              "  [53, 23, 29, 63, 201],\n",
              "  [53, 23, 29, 63, 201],\n",
              "  [53, 23, 29, 63, 201],\n",
              "  [53, 23, 29, 63, 201],\n",
              "  [53, 23, 29, 63, 201],\n",
              "  [53, 23, 29, 63, 201],\n",
              "  [53, 23, 29, 63, 201],\n",
              "  [53, 23, 29, 63, 201],\n",
              "  [53, 23, 29, 63, 201],\n",
              "  [53, 23, 29, 63, 201],\n",
              "  [53, 23, 29, 63, 201],\n",
              "  [53, 23, 29, 63, 201],\n",
              "  [53, 23, 29, 63, 201],\n",
              "  [53, 23, 29, 63, 201],\n",
              "  [53, 23, 29, 63, 201],\n",
              "  [53, 23, 29, 63, 201],\n",
              "  [53, 23, 29, 63, 201],\n",
              "  [53, 23, 29, 63, 201],\n",
              "  [53, 23, 29, 63, 201],\n",
              "  [53, 23, 29, 63, 201],\n",
              "  [53, 23, 29, 63, 201]],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=3.992976>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.6014726>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.444309>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.2719066>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.1333635>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.0327187>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.9452198>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.872731>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.8100228>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.7601368>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.708171>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.6570895>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.6219888>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.586764>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.5503016>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.524373>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.5047684>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4871252>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.464101>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4498432>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4295065>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4178545>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.39668>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3843722>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3734236>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.414885>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.1179698>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.0044818>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.9131281>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.8258756>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.7481272>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.677074>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.6040564>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.5495992>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4851269>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4248499>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3794258>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3296386>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2879385>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2325202>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.203596>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1740236>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1307309>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1021196>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.074086>],\n",
              " 'val_accuracy': [0.1674,\n",
              "  0.1902,\n",
              "  0.2118,\n",
              "  0.2502,\n",
              "  0.2784,\n",
              "  0.2904,\n",
              "  0.3118,\n",
              "  0.323,\n",
              "  0.337,\n",
              "  0.3429,\n",
              "  0.3538,\n",
              "  0.359,\n",
              "  0.364,\n",
              "  0.3751,\n",
              "  0.3761,\n",
              "  0.384,\n",
              "  0.39,\n",
              "  0.3914,\n",
              "  0.3969,\n",
              "  0.3958,\n",
              "  0.401,\n",
              "  0.4076,\n",
              "  0.408,\n",
              "  0.4093,\n",
              "  0.4154,\n",
              "  0.4227,\n",
              "  0.4341,\n",
              "  0.4374,\n",
              "  0.4349,\n",
              "  0.4402,\n",
              "  0.4421,\n",
              "  0.4451,\n",
              "  0.448,\n",
              "  0.45,\n",
              "  0.4534,\n",
              "  0.4515,\n",
              "  0.4503,\n",
              "  0.4512,\n",
              "  0.4534,\n",
              "  0.4518,\n",
              "  0.4529,\n",
              "  0.45,\n",
              "  0.4469,\n",
              "  0.4521,\n",
              "  0.4503],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=3.608139>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.4407148>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.3004308>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.1017375>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.9748561>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.895821>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.7922497>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.7374198>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.68263>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.6205974>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.576408>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.539655>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4995697>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4561393>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4410093>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4120247>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3961487>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.363569>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3486047>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.342063>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3308635>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.303953>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.2909815>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.2991948>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.272914>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.2363915>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.1881356>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.178062>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.1784885>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.1824882>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.175343>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.180436>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.1916745>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.2077346>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.2181046>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.2310312>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.2578685>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.2771695>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.296345>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3105004>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3350744>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3658538>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4063277>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4032538>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4162984>]}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RD-UZ8YbUUq",
        "outputId": "f0ef5b69-835f-4f91-edc7-a0d8a27ed3ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_fn(learning_rate=0.0002, regularization_penalty=0.00000002, regularization_method='weighted_l1', self_scaling_epochs=25, \n",
        "         layer_sizes=[65, 23, 29, 72, 201], epochs=45, pruning_only_epochs=25, min_new_neurons=1, growth_percentage=0., output_neurons=100, verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/45\n",
            "Before pruning:\n",
            "loss: 4.042459487915039 - accuracy: 0.10936 - val_loss: 3.5285441875457764 - val_accuracy: 0.1856 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.5285441875457764 - val_accuracy: 0.1856 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 2/45\n",
            "Before pruning:\n",
            "loss: 3.5535266399383545 - accuracy: 0.18092 - val_loss: 3.3058547973632812 - val_accuracy: 0.2268 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.3058547973632812 - val_accuracy: 0.2268 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 3/45\n",
            "Before pruning:\n",
            "loss: 3.3462257385253906 - accuracy: 0.21318 - val_loss: 3.1975536346435547 - val_accuracy: 0.2402 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.1975536346435547 - val_accuracy: 0.2402 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 4/45\n",
            "Before pruning:\n",
            "loss: 3.1798815727233887 - accuracy: 0.24234 - val_loss: 3.0950145721435547 - val_accuracy: 0.2606 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.0950145721435547 - val_accuracy: 0.2606 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 5/45\n",
            "Before pruning:\n",
            "loss: 3.038729667663574 - accuracy: 0.26524 - val_loss: 3.0237414836883545 - val_accuracy: 0.2681 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.0237414836883545 - val_accuracy: 0.2681 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 6/45\n",
            "Before pruning:\n",
            "loss: 2.9139277935028076 - accuracy: 0.29294 - val_loss: 2.9842183589935303 - val_accuracy: 0.2765 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.9842183589935303 - val_accuracy: 0.2765 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 7/45\n",
            "Before pruning:\n",
            "loss: 2.7899649143218994 - accuracy: 0.31004 - val_loss: 2.9260928630828857 - val_accuracy: 0.2895 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.9260928630828857 - val_accuracy: 0.2895 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 8/45\n",
            "Before pruning:\n",
            "loss: 2.6777243614196777 - accuracy: 0.33394 - val_loss: 2.90686297416687 - val_accuracy: 0.2932 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.90686297416687 - val_accuracy: 0.2932 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 9/45\n",
            "Before pruning:\n",
            "loss: 2.5844266414642334 - accuracy: 0.35352 - val_loss: 2.883277654647827 - val_accuracy: 0.299 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.883277654647827 - val_accuracy: 0.299 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 10/45\n",
            "Before pruning:\n",
            "loss: 2.5101821422576904 - accuracy: 0.3693 - val_loss: 2.8662941455841064 - val_accuracy: 0.3088 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.8662941455841064 - val_accuracy: 0.3088 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 11/45\n",
            "Before pruning:\n",
            "loss: 2.4337098598480225 - accuracy: 0.38136 - val_loss: 2.888511896133423 - val_accuracy: 0.3026 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.888511896133423 - val_accuracy: 0.3026 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 12/45\n",
            "Before pruning:\n",
            "loss: 2.3734333515167236 - accuracy: 0.3951 - val_loss: 2.8816874027252197 - val_accuracy: 0.3086 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.8816874027252197 - val_accuracy: 0.3086 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 13/45\n",
            "Before pruning:\n",
            "loss: 2.316176176071167 - accuracy: 0.40744 - val_loss: 2.8527793884277344 - val_accuracy: 0.3129 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.8527793884277344 - val_accuracy: 0.3129 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 14/45\n",
            "Before pruning:\n",
            "loss: 2.2734649181365967 - accuracy: 0.41642 - val_loss: 2.871575355529785 - val_accuracy: 0.3071 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.871575355529785 - val_accuracy: 0.3071 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 15/45\n",
            "Before pruning:\n",
            "loss: 2.209524393081665 - accuracy: 0.42992 - val_loss: 2.8454947471618652 - val_accuracy: 0.3144 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.8454947471618652 - val_accuracy: 0.3144 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 16/45\n",
            "Before pruning:\n",
            "loss: 2.1780128479003906 - accuracy: 0.43602 - val_loss: 2.8538973331451416 - val_accuracy: 0.3133 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.8538973331451416 - val_accuracy: 0.3133 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 17/45\n",
            "Before pruning:\n",
            "loss: 2.1347105503082275 - accuracy: 0.44686 - val_loss: 2.847166061401367 - val_accuracy: 0.3192 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.847166061401367 - val_accuracy: 0.3192 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 18/45\n",
            "Before pruning:\n",
            "loss: 2.1158955097198486 - accuracy: 0.44884 - val_loss: 2.878359794616699 - val_accuracy: 0.3152 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.878359794616699 - val_accuracy: 0.3152 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 19/45\n",
            "Before pruning:\n",
            "loss: 2.074249505996704 - accuracy: 0.46008 - val_loss: 2.869687795639038 - val_accuracy: 0.3082 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.869687795639038 - val_accuracy: 0.3082 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 20/45\n",
            "Before pruning:\n",
            "loss: 2.0425658226013184 - accuracy: 0.4672 - val_loss: 2.898437023162842 - val_accuracy: 0.3054 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.898437023162842 - val_accuracy: 0.3054 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 21/45\n",
            "Before pruning:\n",
            "loss: 2.0140151977539062 - accuracy: 0.47128 - val_loss: 2.887585401535034 - val_accuracy: 0.3113 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.887585401535034 - val_accuracy: 0.3113 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 22/45\n",
            "Before pruning:\n",
            "loss: 1.9956364631652832 - accuracy: 0.47426 - val_loss: 2.9151065349578857 - val_accuracy: 0.313 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.9151065349578857 - val_accuracy: 0.313 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 23/45\n",
            "Before pruning:\n",
            "loss: 1.975830316543579 - accuracy: 0.48148 - val_loss: 2.8828799724578857 - val_accuracy: 0.3181 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.8828799724578857 - val_accuracy: 0.3181 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 24/45\n",
            "Before pruning:\n",
            "loss: 1.9498529434204102 - accuracy: 0.48888 - val_loss: 2.886918306350708 - val_accuracy: 0.3135 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.886918306350708 - val_accuracy: 0.3135 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 25/45\n",
            "Before pruning:\n",
            "loss: 1.9308415651321411 - accuracy: 0.48862 - val_loss: 2.895139694213867 - val_accuracy: 0.3121 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.895139694213867 - val_accuracy: 0.3121 - penalty: 2e-08\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 26/45\n",
            "loss: 1.9115533828735352 - accuracy: 0.49608 - val_loss: 2.90698504447937 - val_accuracy: 0.3178 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 27/45\n",
            "loss: 1.713443398475647 - accuracy: 0.53858 - val_loss: 2.881135940551758 - val_accuracy: 0.3252 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 28/45\n",
            "loss: 1.6412012577056885 - accuracy: 0.55262 - val_loss: 2.874835252761841 - val_accuracy: 0.3298 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 29/45\n",
            "loss: 1.5842578411102295 - accuracy: 0.56618 - val_loss: 2.8851478099823 - val_accuracy: 0.3342 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 30/45\n",
            "loss: 1.5467734336853027 - accuracy: 0.57426 - val_loss: 2.896266460418701 - val_accuracy: 0.3293 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 31/45\n",
            "loss: 1.4976215362548828 - accuracy: 0.5866 - val_loss: 2.9097864627838135 - val_accuracy: 0.3308 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 32/45\n",
            "loss: 1.4750537872314453 - accuracy: 0.59066 - val_loss: 2.923567533493042 - val_accuracy: 0.3342 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 33/45\n",
            "loss: 1.440439224243164 - accuracy: 0.59672 - val_loss: 2.9405205249786377 - val_accuracy: 0.3345 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 34/45\n",
            "loss: 1.4168392419815063 - accuracy: 0.60234 - val_loss: 2.9537594318389893 - val_accuracy: 0.3325 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 35/45\n",
            "loss: 1.3855195045471191 - accuracy: 0.60832 - val_loss: 2.9517056941986084 - val_accuracy: 0.3374 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 36/45\n",
            "loss: 1.3655922412872314 - accuracy: 0.61264 - val_loss: 2.969187021255493 - val_accuracy: 0.3361 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 37/45\n",
            "loss: 1.3473726511001587 - accuracy: 0.61794 - val_loss: 2.997184991836548 - val_accuracy: 0.3362 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 38/45\n",
            "loss: 1.3282809257507324 - accuracy: 0.62048 - val_loss: 3.001107931137085 - val_accuracy: 0.3346 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 39/45\n",
            "loss: 1.2999637126922607 - accuracy: 0.6272 - val_loss: 3.0089170932769775 - val_accuracy: 0.3348 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 40/45\n",
            "loss: 1.2809234857559204 - accuracy: 0.63162 - val_loss: 3.034824848175049 - val_accuracy: 0.3328 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 41/45\n",
            "loss: 1.2625850439071655 - accuracy: 0.63598 - val_loss: 3.0515501499176025 - val_accuracy: 0.3309 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 42/45\n",
            "loss: 1.2466639280319214 - accuracy: 0.63818 - val_loss: 3.0613455772399902 - val_accuracy: 0.339 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 43/45\n",
            "loss: 1.2226017713546753 - accuracy: 0.64452 - val_loss: 3.0970466136932373 - val_accuracy: 0.3343 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 44/45\n",
            "loss: 1.21073579788208 - accuracy: 0.64776 - val_loss: 3.075427770614624 - val_accuracy: 0.3362 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 45/45\n",
            "loss: 1.1904921531677246 - accuracy: 0.6523 - val_loss: 3.1210501194000244 - val_accuracy: 0.3421 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.10936,\n",
              "  0.18092,\n",
              "  0.21318,\n",
              "  0.24234,\n",
              "  0.26524,\n",
              "  0.29294,\n",
              "  0.31004,\n",
              "  0.33394,\n",
              "  0.35352,\n",
              "  0.3693,\n",
              "  0.38136,\n",
              "  0.3951,\n",
              "  0.40744,\n",
              "  0.41642,\n",
              "  0.42992,\n",
              "  0.43602,\n",
              "  0.44686,\n",
              "  0.44884,\n",
              "  0.46008,\n",
              "  0.4672,\n",
              "  0.47128,\n",
              "  0.47426,\n",
              "  0.48148,\n",
              "  0.48888,\n",
              "  0.48862,\n",
              "  0.49608,\n",
              "  0.53858,\n",
              "  0.55262,\n",
              "  0.56618,\n",
              "  0.57426,\n",
              "  0.5866,\n",
              "  0.59066,\n",
              "  0.59672,\n",
              "  0.60234,\n",
              "  0.60832,\n",
              "  0.61264,\n",
              "  0.61794,\n",
              "  0.62048,\n",
              "  0.6272,\n",
              "  0.63162,\n",
              "  0.63598,\n",
              "  0.63818,\n",
              "  0.64452,\n",
              "  0.64776,\n",
              "  0.6523],\n",
              " 'hidden_layer_sizes': [[65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201]],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=4.0424595>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.5535266>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.3462257>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.1798816>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.0387297>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.9139278>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.789965>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.6777244>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.5844266>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.5101821>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4337099>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3734334>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3161762>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.273465>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.2095244>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.1780128>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.1347106>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.1158955>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.0742495>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.0425658>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.0140152>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.9956365>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.9758303>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.949853>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.9308416>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.9115534>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.7134434>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.6412013>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.5842578>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.5467734>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4976215>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4750538>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4404392>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4168392>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3855195>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3655922>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3473727>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3282809>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2999637>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2809235>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.262585>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2466639>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2226018>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2107358>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.1904922>],\n",
              " 'val_accuracy': [0.1856,\n",
              "  0.2268,\n",
              "  0.2402,\n",
              "  0.2606,\n",
              "  0.2681,\n",
              "  0.2765,\n",
              "  0.2895,\n",
              "  0.2932,\n",
              "  0.299,\n",
              "  0.3088,\n",
              "  0.3026,\n",
              "  0.3086,\n",
              "  0.3129,\n",
              "  0.3071,\n",
              "  0.3144,\n",
              "  0.3133,\n",
              "  0.3192,\n",
              "  0.3152,\n",
              "  0.3082,\n",
              "  0.3054,\n",
              "  0.3113,\n",
              "  0.313,\n",
              "  0.3181,\n",
              "  0.3135,\n",
              "  0.3121,\n",
              "  0.3178,\n",
              "  0.3252,\n",
              "  0.3298,\n",
              "  0.3342,\n",
              "  0.3293,\n",
              "  0.3308,\n",
              "  0.3342,\n",
              "  0.3345,\n",
              "  0.3325,\n",
              "  0.3374,\n",
              "  0.3361,\n",
              "  0.3362,\n",
              "  0.3346,\n",
              "  0.3348,\n",
              "  0.3328,\n",
              "  0.3309,\n",
              "  0.339,\n",
              "  0.3343,\n",
              "  0.3362,\n",
              "  0.3421],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=3.5285442>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.3058548>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.1975536>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.0950146>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.0237415>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.9842184>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.9260929>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.906863>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.8832777>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.8662941>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.888512>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.8816874>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.8527794>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.8715754>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.8454947>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.8538973>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.847166>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.8783598>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.8696878>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.898437>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.8875854>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.9151065>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.88288>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.8869183>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.8951397>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.906985>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.881136>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.8748353>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.8851478>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.8962665>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.9097865>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.9235675>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.9405205>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.9537594>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.9517057>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.969187>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.997185>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.001108>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.008917>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.0348248>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.0515501>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.0613456>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.0970466>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.0754278>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.1210501>]}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6tzOMJLYOC4",
        "outputId": "6388479b-4449-4e9d-be65-b01e1ca5d010",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_fn(learning_rate=0.0002, regularization_penalty=0., regularization_method=None, self_scaling_epochs=25, \n",
        "         layer_sizes=[65, 23, 29, 72, 201], epochs=45, pruning_only_epochs=25, min_new_neurons=1, growth_percentage=0., output_neurons=100, verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/45\n",
            "Before pruning:\n",
            "loss: 4.0540876388549805 - accuracy: 0.1073 - val_loss: 3.542466402053833 - val_accuracy: 0.1866 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.542466402053833 - val_accuracy: 0.1866 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 2/45\n",
            "Before pruning:\n",
            "loss: 3.587552785873413 - accuracy: 0.17374 - val_loss: 3.353174924850464 - val_accuracy: 0.2133 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.353174924850464 - val_accuracy: 0.2133 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 3/45\n",
            "Before pruning:\n",
            "loss: 3.377345085144043 - accuracy: 0.20884 - val_loss: 3.220838785171509 - val_accuracy: 0.2385 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.220838785171509 - val_accuracy: 0.2385 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 4/45\n",
            "Before pruning:\n",
            "loss: 3.2009196281433105 - accuracy: 0.24028 - val_loss: 3.1576807498931885 - val_accuracy: 0.2449 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.1576807498931885 - val_accuracy: 0.2449 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 5/45\n",
            "Before pruning:\n",
            "loss: 3.058767557144165 - accuracy: 0.26248 - val_loss: 3.1176974773406982 - val_accuracy: 0.26 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.1176974773406982 - val_accuracy: 0.26 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 6/45\n",
            "Before pruning:\n",
            "loss: 2.935821771621704 - accuracy: 0.2852 - val_loss: 2.995131492614746 - val_accuracy: 0.2748 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.995131492614746 - val_accuracy: 0.2748 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 7/45\n",
            "Before pruning:\n",
            "loss: 2.8236606121063232 - accuracy: 0.30876 - val_loss: 2.988842725753784 - val_accuracy: 0.2818 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.988842725753784 - val_accuracy: 0.2818 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 8/45\n",
            "Before pruning:\n",
            "loss: 2.7033767700195312 - accuracy: 0.3307 - val_loss: 2.9518942832946777 - val_accuracy: 0.2896 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.9518942832946777 - val_accuracy: 0.2896 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 9/45\n",
            "Before pruning:\n",
            "loss: 2.6192994117736816 - accuracy: 0.34718 - val_loss: 2.9190263748168945 - val_accuracy: 0.2897 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.9190263748168945 - val_accuracy: 0.2897 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 10/45\n",
            "Before pruning:\n",
            "loss: 2.5368716716766357 - accuracy: 0.36394 - val_loss: 2.8930115699768066 - val_accuracy: 0.3003 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.8930115699768066 - val_accuracy: 0.3003 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 11/45\n",
            "Before pruning:\n",
            "loss: 2.4622247219085693 - accuracy: 0.38012 - val_loss: 2.902677059173584 - val_accuracy: 0.2952 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.902677059173584 - val_accuracy: 0.2952 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 12/45\n",
            "Before pruning:\n",
            "loss: 2.407838821411133 - accuracy: 0.3876 - val_loss: 2.8815739154815674 - val_accuracy: 0.3036 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.8815739154815674 - val_accuracy: 0.3036 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 13/45\n",
            "Before pruning:\n",
            "loss: 2.336845874786377 - accuracy: 0.4052 - val_loss: 2.8848953247070312 - val_accuracy: 0.3036 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.8848953247070312 - val_accuracy: 0.3036 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 14/45\n",
            "Before pruning:\n",
            "loss: 2.28170108795166 - accuracy: 0.41532 - val_loss: 2.8729777336120605 - val_accuracy: 0.3085 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.8729777336120605 - val_accuracy: 0.3085 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 15/45\n",
            "Before pruning:\n",
            "loss: 2.2368953227996826 - accuracy: 0.42418 - val_loss: 2.883500576019287 - val_accuracy: 0.3034 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.883500576019287 - val_accuracy: 0.3034 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 16/45\n",
            "Before pruning:\n",
            "loss: 2.196025848388672 - accuracy: 0.43424 - val_loss: 2.880636692047119 - val_accuracy: 0.3093 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.880636692047119 - val_accuracy: 0.3093 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 17/45\n",
            "Before pruning:\n",
            "loss: 2.1621334552764893 - accuracy: 0.44196 - val_loss: 2.9215524196624756 - val_accuracy: 0.2998 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.9215524196624756 - val_accuracy: 0.2998 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 18/45\n",
            "Before pruning:\n",
            "loss: 2.126298666000366 - accuracy: 0.45062 - val_loss: 2.897921323776245 - val_accuracy: 0.3097 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.897921323776245 - val_accuracy: 0.3097 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 19/45\n",
            "Before pruning:\n",
            "loss: 2.106189250946045 - accuracy: 0.45308 - val_loss: 2.911043882369995 - val_accuracy: 0.3054 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.911043882369995 - val_accuracy: 0.3054 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 20/45\n",
            "Before pruning:\n",
            "loss: 2.076751947402954 - accuracy: 0.45912 - val_loss: 2.9059128761291504 - val_accuracy: 0.309 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.9059128761291504 - val_accuracy: 0.309 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 21/45\n",
            "Before pruning:\n",
            "loss: 2.0421559810638428 - accuracy: 0.46622 - val_loss: 2.9090750217437744 - val_accuracy: 0.3085 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.9090750217437744 - val_accuracy: 0.3085 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 22/45\n",
            "Before pruning:\n",
            "loss: 2.016474485397339 - accuracy: 0.47206 - val_loss: 2.923499584197998 - val_accuracy: 0.3025 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.923499584197998 - val_accuracy: 0.3025 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 23/45\n",
            "Before pruning:\n",
            "loss: 1.9925692081451416 - accuracy: 0.47812 - val_loss: 2.923081636428833 - val_accuracy: 0.3029 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.923081636428833 - val_accuracy: 0.3029 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 24/45\n",
            "Before pruning:\n",
            "loss: 1.963930606842041 - accuracy: 0.48374 - val_loss: 2.9120655059814453 - val_accuracy: 0.3081 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.9120655059814453 - val_accuracy: 0.3081 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 25/45\n",
            "Before pruning:\n",
            "loss: 1.957942008972168 - accuracy: 0.48298 - val_loss: 2.948591947555542 - val_accuracy: 0.2977 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.948591947555542 - val_accuracy: 0.2977 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 26/45\n",
            "loss: 1.9408643245697021 - accuracy: 0.48802 - val_loss: 2.945810079574585 - val_accuracy: 0.3026 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 27/45\n",
            "loss: 1.7328436374664307 - accuracy: 0.53452 - val_loss: 2.918233871459961 - val_accuracy: 0.3136 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 28/45\n",
            "loss: 1.65921950340271 - accuracy: 0.54826 - val_loss: 2.919031858444214 - val_accuracy: 0.3143 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 29/45\n",
            "loss: 1.605617642402649 - accuracy: 0.55998 - val_loss: 2.914625883102417 - val_accuracy: 0.3209 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 30/45\n",
            "loss: 1.5616425275802612 - accuracy: 0.57382 - val_loss: 2.9433846473693848 - val_accuracy: 0.3186 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 31/45\n",
            "loss: 1.5291471481323242 - accuracy: 0.57874 - val_loss: 2.9486889839172363 - val_accuracy: 0.3192 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 32/45\n",
            "loss: 1.4943259954452515 - accuracy: 0.58616 - val_loss: 2.947840452194214 - val_accuracy: 0.3237 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 33/45\n",
            "loss: 1.4714046716690063 - accuracy: 0.59152 - val_loss: 2.9494333267211914 - val_accuracy: 0.3239 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 34/45\n",
            "loss: 1.4470243453979492 - accuracy: 0.59558 - val_loss: 3.0016894340515137 - val_accuracy: 0.3189 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 35/45\n",
            "loss: 1.407473087310791 - accuracy: 0.6042 - val_loss: 2.9911553859710693 - val_accuracy: 0.3265 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 36/45\n",
            "loss: 1.3936562538146973 - accuracy: 0.60732 - val_loss: 2.9966742992401123 - val_accuracy: 0.3249 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 37/45\n",
            "loss: 1.359002947807312 - accuracy: 0.61616 - val_loss: 3.01505708694458 - val_accuracy: 0.3252 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 38/45\n",
            "loss: 1.3548407554626465 - accuracy: 0.61578 - val_loss: 3.02785587310791 - val_accuracy: 0.3233 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 39/45\n",
            "loss: 1.3200149536132812 - accuracy: 0.62308 - val_loss: 3.0493874549865723 - val_accuracy: 0.3254 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 40/45\n",
            "loss: 1.3073229789733887 - accuracy: 0.62656 - val_loss: 3.0502469539642334 - val_accuracy: 0.3257 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 41/45\n",
            "loss: 1.286985993385315 - accuracy: 0.63088 - val_loss: 3.0751266479492188 - val_accuracy: 0.3246 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 42/45\n",
            "loss: 1.2629451751708984 - accuracy: 0.63506 - val_loss: 3.0785365104675293 - val_accuracy: 0.3261 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 43/45\n",
            "loss: 1.2595831155776978 - accuracy: 0.63736 - val_loss: 3.108720541000366 - val_accuracy: 0.3237 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 44/45\n",
            "loss: 1.2240480184555054 - accuracy: 0.64502 - val_loss: 3.098193407058716 - val_accuracy: 0.3226 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 45/45\n",
            "loss: 1.222740650177002 - accuracy: 0.64388 - val_loss: 3.1740598678588867 - val_accuracy: 0.3228 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.1073,\n",
              "  0.17374,\n",
              "  0.20884,\n",
              "  0.24028,\n",
              "  0.26248,\n",
              "  0.2852,\n",
              "  0.30876,\n",
              "  0.3307,\n",
              "  0.34718,\n",
              "  0.36394,\n",
              "  0.38012,\n",
              "  0.3876,\n",
              "  0.4052,\n",
              "  0.41532,\n",
              "  0.42418,\n",
              "  0.43424,\n",
              "  0.44196,\n",
              "  0.45062,\n",
              "  0.45308,\n",
              "  0.45912,\n",
              "  0.46622,\n",
              "  0.47206,\n",
              "  0.47812,\n",
              "  0.48374,\n",
              "  0.48298,\n",
              "  0.48802,\n",
              "  0.53452,\n",
              "  0.54826,\n",
              "  0.55998,\n",
              "  0.57382,\n",
              "  0.57874,\n",
              "  0.58616,\n",
              "  0.59152,\n",
              "  0.59558,\n",
              "  0.6042,\n",
              "  0.60732,\n",
              "  0.61616,\n",
              "  0.61578,\n",
              "  0.62308,\n",
              "  0.62656,\n",
              "  0.63088,\n",
              "  0.63506,\n",
              "  0.63736,\n",
              "  0.64502,\n",
              "  0.64388],\n",
              " 'hidden_layer_sizes': [[65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201],\n",
              "  [65, 23, 29, 72, 201]],\n",
              " 'loss': [<tf.Tensor: shape=(), dtype=float32, numpy=4.0540876>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.5875528>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.377345>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.2009196>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.0587676>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.9358218>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.8236606>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.7033768>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.6192994>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.5368717>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4622247>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.4078388>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.3368459>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.281701>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.2368953>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.1960258>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.1621335>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.1262987>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.1061893>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.076752>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.042156>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.0164745>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.9925692>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.9639306>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.957942>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.9408643>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.7328436>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.6592195>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.6056176>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.5616425>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.5291471>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.494326>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4714047>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4470243>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.4074731>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3936563>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.359003>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.3548408>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.320015>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.307323>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.286986>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2629452>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2595831>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.224048>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=1.2227407>],\n",
              " 'val_accuracy': [0.1866,\n",
              "  0.2133,\n",
              "  0.2385,\n",
              "  0.2449,\n",
              "  0.26,\n",
              "  0.2748,\n",
              "  0.2818,\n",
              "  0.2896,\n",
              "  0.2897,\n",
              "  0.3003,\n",
              "  0.2952,\n",
              "  0.3036,\n",
              "  0.3036,\n",
              "  0.3085,\n",
              "  0.3034,\n",
              "  0.3093,\n",
              "  0.2998,\n",
              "  0.3097,\n",
              "  0.3054,\n",
              "  0.309,\n",
              "  0.3085,\n",
              "  0.3025,\n",
              "  0.3029,\n",
              "  0.3081,\n",
              "  0.2977,\n",
              "  0.3026,\n",
              "  0.3136,\n",
              "  0.3143,\n",
              "  0.3209,\n",
              "  0.3186,\n",
              "  0.3192,\n",
              "  0.3237,\n",
              "  0.3239,\n",
              "  0.3189,\n",
              "  0.3265,\n",
              "  0.3249,\n",
              "  0.3252,\n",
              "  0.3233,\n",
              "  0.3254,\n",
              "  0.3257,\n",
              "  0.3246,\n",
              "  0.3261,\n",
              "  0.3237,\n",
              "  0.3226,\n",
              "  0.3228],\n",
              " 'val_loss': [<tf.Tensor: shape=(), dtype=float32, numpy=3.5424664>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.353175>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.2208388>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.1576807>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.1176975>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.9951315>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.9888427>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.9518943>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.9190264>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.8930116>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.902677>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.881574>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.8848953>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.8729777>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.8835006>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.8806367>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.9215524>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.8979213>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.911044>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.9059129>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.909075>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.9234996>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.9230816>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.9120655>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.948592>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.94581>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.9182339>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.9190319>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.914626>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.9433846>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.948689>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.9478405>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.9494333>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.0016894>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.9911554>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.9966743>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.015057>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.0278559>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.0493875>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.050247>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.0751266>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.0785365>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.1087205>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.0981934>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=3.1740599>]}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBbX9M1TacAv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}