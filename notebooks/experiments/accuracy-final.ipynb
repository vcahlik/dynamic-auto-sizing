{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_multi_layer_ssnet_inverse.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "background_execution": "on",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_deAUKlniFk",
        "outputId": "5e2e10c2-5eee-4c6a-917e-3a6a2bbb1046"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jan 13 20:43:50 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    26W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKwUwV_NneIo"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from enum import Enum\n",
        "import imageio\n",
        "import os\n",
        "import hashlib\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "dtype = 'float32'\n",
        "tf.keras.backend.set_floatx(dtype)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTZq4KMpneIv"
      },
      "source": [
        "################################################################################\n",
        "# DATASETS\n",
        "################################################################################\n",
        "\n",
        "\n",
        "class Dataset:\n",
        "    def __init__(self, X_train, y_train, X_test, y_test, shape, shape_flattened):\n",
        "        X_train = X_train.astype(dtype) / 255.0\n",
        "        y_train = y_train.astype(dtype)\n",
        "        X_test = X_test.astype(dtype)  / 255.0\n",
        "        y_test = y_test.astype(dtype)\n",
        "\n",
        "        X_train = np.reshape(X_train, shape_flattened)\n",
        "        X_test = np.reshape(X_test, shape_flattened)\n",
        "\n",
        "        X = np.concatenate((X_train, X_test), axis=0)\n",
        "        y = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "        from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(X_train)  # Scaling each feature independently\n",
        "\n",
        "        X_norm = scaler.transform(X)\n",
        "        X_train_norm = scaler.transform(X_train)\n",
        "        X_test_norm = scaler.transform(X_test)\n",
        "\n",
        "        X_norm = np.reshape(X_norm, shape)\n",
        "        X_train_norm = np.reshape(X_train_norm, shape)\n",
        "        X_test_norm = np.reshape(X_test_norm, shape)\n",
        "\n",
        "        self.X_norm = X_norm\n",
        "        self.y = y\n",
        "        self.X_train_norm = X_train_norm\n",
        "        self.y_train = y_train\n",
        "        self.X_test_norm = X_test_norm\n",
        "        self.y_test = y_test\n",
        "\n",
        "\n",
        "def get_cifar_10_dataset():\n",
        "    cifar10 = tf.keras.datasets.cifar10\n",
        "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "    shape = (-1, 32, 32, 3)\n",
        "    shape_flattened = (-1, 3072)  # Scaling each feature independently\n",
        "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened)\n",
        "\n",
        "\n",
        "def get_cifar_100_dataset():\n",
        "    cifar100 = tf.keras.datasets.cifar100\n",
        "    (X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
        "    shape = (-1, 32, 32, 3)\n",
        "    shape_flattened = (-1, 3072)  # Scaling each feature independently\n",
        "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened)\n",
        "\n",
        "\n",
        "def get_svhn_dataset():\n",
        "    from urllib.request import urlretrieve\n",
        "    from scipy import io\n",
        "\n",
        "    train_filename, _ = urlretrieve('http://ufldl.stanford.edu/housenumbers/train_32x32.mat')\n",
        "    test_filename, _ = urlretrieve('http://ufldl.stanford.edu/housenumbers/test_32x32.mat')\n",
        "\n",
        "    X_train = io.loadmat(train_filename, variable_names='X').get('X')\n",
        "    y_train = io.loadmat(train_filename, variable_names='y').get('y')\n",
        "    X_test = io.loadmat(test_filename, variable_names='X').get('X')\n",
        "    y_test = io.loadmat(test_filename, variable_names='y').get('y')\n",
        "\n",
        "    X_train = np.moveaxis(X_train, -1, 0)\n",
        "    y_train -= 1\n",
        "    X_test = np.moveaxis(X_test, -1, 0)\n",
        "    y_test -= 1\n",
        "\n",
        "    shape = (-1, 32, 32, 3)\n",
        "    shape_flattened = (-1, 3072)  # Scaling each feature independently\n",
        "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened)\n",
        "\n",
        "\n",
        "def get_tiny_imagenet_dataset():\n",
        "    \"\"\"\n",
        "    Original source: https://github.com/sonugiri1043/Train_ResNet_On_Tiny_ImageNet/blob/master/Train_ResNet_On_Tiny_ImageNet.ipynb\n",
        "    Original author: sonugiri1043@gmail.com\n",
        "    \"\"\"\n",
        "\n",
        "    if not os.path.isdir('IMagenet'):\n",
        "        ! git clone https://github.com/seshuad/IMagenet\n",
        "\n",
        "    print(\"Processing the downloaded dataset...\")\n",
        "\n",
        "    path = 'IMagenet/tiny-imagenet-200/'\n",
        "\n",
        "    id_dict = {}\n",
        "    for i, line in enumerate(open(path + 'wnids.txt', 'r')):\n",
        "        id_dict[line.replace('\\n', '')] = i\n",
        "\n",
        "    train_data = list()\n",
        "    test_data = list()\n",
        "    train_labels = list()\n",
        "    test_labels = list()\n",
        "\n",
        "    for key, value in id_dict.items():\n",
        "        train_data += [imageio.imread(path + 'train/{}/images/{}_{}.JPEG'.format(key, key, str(i)), pilmode='RGB') for i in range(500)]\n",
        "        train_labels_ = np.array([[0]*200]*500)\n",
        "        train_labels_[:, value] = 1\n",
        "        train_labels += train_labels_.tolist()\n",
        "\n",
        "    for line in open(path + 'val/val_annotations.txt'):\n",
        "        img_name, class_id = line.split('\\t')[:2]\n",
        "        test_data.append(imageio.imread(path + 'val/images/{}'.format(img_name), pilmode='RGB'))\n",
        "        test_labels_ = np.array([[0]*200])\n",
        "        test_labels_[0, id_dict[class_id]] = 1\n",
        "        test_labels += test_labels_.tolist()\n",
        "\n",
        "    X_train = np.array(train_data)\n",
        "    y_train = np.argmax(np.array(train_labels), axis=1)\n",
        "    X_test = np.array(test_data)\n",
        "    y_test = np.argmax(np.array(test_labels), axis=1)\n",
        "\n",
        "    shape = (-1, 64, 64, 3)\n",
        "    shape_flattened = (-1, 12288)  # Scaling each feature independently\n",
        "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened)\n",
        "\n",
        "\n",
        "def get_mnist_dataset():\n",
        "    mnist = tf.keras.datasets.mnist\n",
        "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "    shape = (-1, 28, 28, 1)\n",
        "    shape_flattened = (-1, 1)  # Scaling all features together\n",
        "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened)\n",
        "\n",
        "\n",
        "def get_fashion_mnist_dataset():\n",
        "    fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "    (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "    shape = (-1, 28, 28, 1)\n",
        "    shape_flattened = (-1, 1)  # Scaling all features together\n",
        "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened)\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# REGULARIZERS\n",
        "################################################################################\n",
        "\n",
        "\n",
        "class Regularizer(tf.keras.regularizers.Regularizer):\n",
        "    def __init__(self):\n",
        "        self.n_new_neurons = 0\n",
        "        self.scaling_tensor = None\n",
        "        self.set_regularization_penalty(0.)\n",
        "        self.set_regularization_method(None)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        if self.regularization_method is None or self.regularization_penalty == 0:\n",
        "            return 0\n",
        "        elif self.regularization_method == 'weighted_l1':\n",
        "            return self.weighted_l1(x)\n",
        "        elif self.regularization_method == 'weighted_l1_reordered':\n",
        "            return self.weighted_l1_reordered(x)\n",
        "        elif self.regularization_method == 'group_sparsity':\n",
        "            return self.group_sparsity(x)\n",
        "        elif self.regularization_method == 'l1':\n",
        "            return self.l1(x)\n",
        "        else:\n",
        "            raise NotImplementedError(f\"Unknown regularization method {self.regularization_method}\")\n",
        "    \n",
        "    def weighted_l1(self, x):\n",
        "        # I.e. for a parameter matrix of 4 input and 10 output neurons:\n",
        "        #\n",
        "        # [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]\n",
        "        #\n",
        "        # the scaling tensor, as well as the resulting weighted values, could be:\n",
        "        #\n",
        "        # [[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
        "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
        "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
        "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]\n",
        "        #\n",
        "        # Therefore every additional output neuron is regularized more.\n",
        "\n",
        "        scaling_tensor = tf.cumsum(tf.constant(self.regularization_penalty, shape=x.shape, dtype=dtype), axis=-1)\n",
        "        weighted_values = scaling_tensor * tf.abs(x)\n",
        "        return tf.reduce_sum(weighted_values)\n",
        "    \n",
        "    def weighted_l1_reordered(self, x):\n",
        "        # I.e. for a parameter matrix of 4 input and 10 output neurons:\n",
        "        #\n",
        "        # [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]\n",
        "        #\n",
        "        # the scaling tensor, as well as the resulting weighted values, could be:\n",
        "        #\n",
        "        # [[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
        "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
        "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
        "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]\n",
        "        #\n",
        "        # Therefore every additional output neuron is regularized more.\n",
        "\n",
        "        if self.update_scaling_tensor:\n",
        "            scaling_tensor_raw = tf.cumsum(tf.constant(self.regularization_penalty, shape=x.shape, dtype=dtype), axis=-1)\n",
        "\n",
        "            scaling_tensor_old_neurons = scaling_tensor_raw[:, :-self.n_new_neurons]\n",
        "            scaling_tensor_new_neurons = scaling_tensor_raw[:, -self.n_new_neurons:]\n",
        "            scaling_tensor_old_neurons_shuffled = tf.transpose(tf.random.shuffle(tf.transpose(scaling_tensor_old_neurons)))\n",
        "            self.scaling_tensor = tf.concat([scaling_tensor_old_neurons_shuffled, scaling_tensor_new_neurons], axis=-1)\n",
        "            self.update_scaling_tensor = False\n",
        "\n",
        "        weighted_values = self.scaling_tensor * tf.abs(x)\n",
        "        return tf.reduce_sum(weighted_values)\n",
        "    \n",
        "    def group_sparsity(self, x):\n",
        "        # I.e. for a parameter matrix of 3 input and 5 output neurons:\n",
        "        #\n",
        "        # [[1., 1., 1., 1., 1.],\n",
        "        #  [1., 2., 2., 1., 2.],\n",
        "        #  [2., 2., 3., 1., 3.]]\n",
        "        #\n",
        "        # The resulting vector of group norms is [2., 2., 3., 1., 3.], therefore for\n",
        "        # every output neuron, its incoming connections form a group.\n",
        "\n",
        "        group_norms = tf.norm(x, ord=2, axis=0)\n",
        "        # assert group_norms.shape[0] == x.shape[1]\n",
        "        return self.regularization_penalty * tf.reduce_sum(group_norms)\n",
        "    \n",
        "    def l1(self, x):\n",
        "        weighted_values = self.regularization_penalty * tf.abs(x)\n",
        "        return tf.reduce_sum(weighted_values)\n",
        "    \n",
        "    def prune(self):\n",
        "        self.n_new_neurons = 0\n",
        "        if self.regularization_method == 'weighted_l1_reordered':\n",
        "            self.update_scaling_tensor = True\n",
        "    \n",
        "    def grow(self, n_new_neurons):\n",
        "        self.n_new_neurons = n_new_neurons\n",
        "        if self.regularization_method == 'weighted_l1_reordered':\n",
        "            self.update_scaling_tensor = True\n",
        "    \n",
        "    def set_regularization_penalty(self, regularization_penalty):\n",
        "        self.regularization_penalty = regularization_penalty\n",
        "    \n",
        "    def set_regularization_method(self, regularization_method):\n",
        "        self.regularization_method = regularization_method\n",
        "        if self.regularization_method == 'weighted_l1_reordered':\n",
        "            self.update_scaling_tensor = True\n",
        "        else:\n",
        "            self.update_scaling_tensor = None\n",
        "\n",
        "    def get_config(self):\n",
        "        return {'regularization_penalty': float(self.regularization_penalty)}\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# LAYERS\n",
        "################################################################################\n",
        "\n",
        "\n",
        "class CustomLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, input_shape):\n",
        "        super().__init__()\n",
        "\n",
        "        self.inpt_shp = input_shape\n",
        "\n",
        "\n",
        "class Dense(CustomLayer):\n",
        "    def __init__(self, units, activation, kernel_initializer='glorot_uniform', \n",
        "                 bias_initializer='zeros', input_shape=None, fixed_size=False):\n",
        "        super().__init__(input_shape)\n",
        "\n",
        "        self.units = units\n",
        "        self.activation = activation\n",
        "        self.kernel_initializer = kernel_initializer\n",
        "        self.bias_initializer = bias_initializer\n",
        "        self.fixed_size = fixed_size\n",
        "        \n",
        "        self.A = tf.keras.activations.get(activation)\n",
        "        self.W_init = tf.keras.initializers.get(kernel_initializer)\n",
        "        self.b_init = tf.keras.initializers.get(bias_initializer)\n",
        "        self.regularizer = Regularizer()\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        input_units = input_shape[-1]\n",
        "\n",
        "        self.W = tf.Variable(\n",
        "            name='W',\n",
        "            initial_value=self.W_init(shape=(input_units, self.units), dtype=dtype),\n",
        "            trainable=True)\n",
        "        \n",
        "        self.b = tf.Variable(\n",
        "            name='b',\n",
        "            initial_value=self.b_init(shape=(self.units,), dtype=dtype),\n",
        "            trainable=True)\n",
        "        \n",
        "        self.add_loss(lambda: self.regularizer(tf.concat([self.W, tf.reshape(self.b, (1, -1))], axis=0)))\n",
        "    \n",
        "    def call(self, inputs, training=None):\n",
        "        return self.A(tf.matmul(inputs, self.W) + self.b)\n",
        "\n",
        "    def get_size(self):\n",
        "        return self.W.shape[0], self.W.shape[1]\n",
        "    \n",
        "    def prune(self, threshold, active_input_units_indices):\n",
        "        # Remove connections from pruned units in previous layer\n",
        "        new_W = tf.gather(self.W.value(), active_input_units_indices, axis=0)\n",
        "\n",
        "        if self.fixed_size:\n",
        "            active_output_neurons_indices = list(range(new_W.shape[1]))\n",
        "        else:\n",
        "            # Prune units in this layer\n",
        "            weights_with_biases = tf.concat([new_W, tf.reshape(self.b.value(), (1, -1))], axis=0)\n",
        "            neurons_are_active = tf.math.reduce_max(tf.abs(weights_with_biases), axis=0) >= threshold\n",
        "            active_output_neurons_indices = tf.reshape(tf.where(neurons_are_active), (-1,))\n",
        "            \n",
        "            new_W = tf.gather(new_W, active_output_neurons_indices, axis=1)\n",
        "            new_b = tf.gather(self.b.value(), active_output_neurons_indices, axis=0)\n",
        "\n",
        "            self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
        "\n",
        "        self.W = tf.Variable(name='W', initial_value=new_W, trainable=True)\n",
        "\n",
        "        self.regularizer.prune()\n",
        "        return active_output_neurons_indices\n",
        "    \n",
        "    def grow(self, n_new_input_units, percentage, min_new_units, scaling_factor):\n",
        "        if n_new_input_units > 0:\n",
        "            # Add connections to grown units in previous layer\n",
        "            W_growth = self.W_init(shape=(self.W.shape[0] + n_new_input_units, self.W.shape[1]), dtype=dtype)[-n_new_input_units:, :] * scaling_factor  # TODO is it better to be multiplying here by scaling_factor? It does help with not increasing the max weights of existing neurons when new neurons are added.\n",
        "            new_W = tf.concat([self.W.value(), W_growth], axis=0)\n",
        "        else:\n",
        "            new_W = self.W.value()\n",
        "\n",
        "        if self.fixed_size:\n",
        "            n_new_output_units = 0\n",
        "        else:\n",
        "            # Grow new units in this layer\n",
        "            n_new_output_units = max(min_new_units, int(new_W.shape[1] * percentage))\n",
        "            if n_new_output_units > 0:\n",
        "                W_growth = self.W_init(shape=(new_W.shape[0], new_W.shape[1] + n_new_output_units), dtype=dtype)[:, -n_new_output_units:] * scaling_factor\n",
        "                b_growth = self.b_init(shape=(n_new_output_units,), dtype=dtype)  # TODO for all possible bias initializers to work properly, the whole bias vector should be initialized at once\n",
        "                new_W = tf.concat([new_W, W_growth], axis=1)\n",
        "                new_b = tf.concat([self.b.value(), b_growth], axis=0)\n",
        "\n",
        "                self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
        "\n",
        "        self.W = tf.Variable(name='W', initial_value=new_W, trainable=True)\n",
        "\n",
        "        self.regularizer.grow(n_new_output_units)\n",
        "        return n_new_output_units\n",
        "    \n",
        "    def set_regularization_penalty(self, regularization_penalty):\n",
        "        if not self.fixed_size:\n",
        "            self.regularizer.set_regularization_penalty(regularization_penalty)\n",
        "    \n",
        "    def set_regularization_method(self, regularization_method):\n",
        "        if not self.fixed_size:\n",
        "            self.regularizer.set_regularization_method(regularization_method)\n",
        "    \n",
        "    def get_param_string():\n",
        "        param_string = \"\"\n",
        "        weights_with_bias = tf.concat([self.W, tf.reshape(self.b, (1, -1))], axis=0)\n",
        "        max_parameters = tf.math.reduce_max(tf.abs(weights_with_bias), axis=0).numpy()\n",
        "        magnitudes = np.floor(np.log10(max_parameters))\n",
        "        for m in magnitudes:\n",
        "            if m > 0:\n",
        "                m = 0\n",
        "            param_string += str(int(-m))\n",
        "        return param_string\n",
        "\n",
        "\n",
        "class Conv2D(CustomLayer):\n",
        "    def __init__(self, filters, filter_size, activation, strides=(1, 1), \n",
        "                 padding='SAME', kernel_initializer='glorot_uniform',\n",
        "                 bias_initializer='zeros', input_shape=None, fixed_size=False):\n",
        "        super().__init__(input_shape)\n",
        "    \n",
        "        self.filters = filters\n",
        "        self.filter_size = filter_size\n",
        "        self.activation = activation\n",
        "        self.strides = strides\n",
        "        self.padding = padding\n",
        "        self.kernel_initializer = kernel_initializer\n",
        "        self.bias_initializer = bias_initializer\n",
        "        self.fixed_size = fixed_size\n",
        "        \n",
        "        self.A = tf.keras.activations.get(activation)\n",
        "        self.F_init = tf.keras.initializers.get(kernel_initializer)\n",
        "        self.b_init = tf.keras.initializers.get(bias_initializer)\n",
        "        self.regularizer = Regularizer()\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        input_filters = input_shape[-1]\n",
        "\n",
        "        self.F = tf.Variable(\n",
        "            name='F',\n",
        "            initial_value=self.F_init(\n",
        "                shape=(self.filter_size[0], self.filter_size[1], input_filters, self.filters), dtype=dtype\n",
        "            ),\n",
        "            trainable=True)\n",
        "        \n",
        "        self.b = tf.Variable(\n",
        "            name='b',\n",
        "            initial_value=self.b_init(shape=(self.filters,), dtype=dtype),\n",
        "            trainable=True)\n",
        "\n",
        "        self.add_loss(lambda: self.regularizer(tf.concat([tf.reshape(self.F, (-1, self.F.shape[-1])), tf.reshape(self.b, (1, -1))], axis=0)))\n",
        "    \n",
        "    def call(self, inputs, training=None):\n",
        "        y = tf.nn.conv2d(inputs, self.F, strides=self.strides, padding=self.padding)\n",
        "        y = tf.nn.bias_add(y, self.b)\n",
        "        y = self.A(y)\n",
        "        return y\n",
        "    \n",
        "    def get_size(self):\n",
        "        return self.F.shape[-2], self.F.shape[-1]\n",
        "    \n",
        "    def prune(self, threshold, active_input_units_indices):\n",
        "        # Remove connections from pruned units in previous layer\n",
        "        new_F = tf.gather(self.F.value(), active_input_units_indices, axis=-2)\n",
        "\n",
        "        if self.fixed_size:\n",
        "            active_output_filters_indices = list(range(new_F.shape[-1]))\n",
        "        else:\n",
        "            # Prune units in this layer\n",
        "            F_reduced_max = tf.reshape(tf.math.reduce_max(tf.abs(new_F), axis=(0, 1, 2)), (1, -1))\n",
        "            F_reduced_max_with_biases = tf.concat([F_reduced_max, tf.reshape(self.b.value(), (1, -1))], axis=0)\n",
        "            filters_are_active = tf.math.reduce_max(tf.abs(F_reduced_max_with_biases), axis=0) >= threshold\n",
        "            active_output_filters_indices = tf.reshape(tf.where(filters_are_active), (-1,))\n",
        "            \n",
        "            new_F = tf.gather(new_F, active_output_filters_indices, axis=-1)\n",
        "            new_b = tf.gather(self.b.value(), active_output_filters_indices, axis=0)\n",
        "\n",
        "            self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
        "\n",
        "        self.F = tf.Variable(name='F', initial_value=new_F, trainable=True)\n",
        "\n",
        "        self.regularizer.prune()\n",
        "        return active_output_filters_indices\n",
        "\n",
        "    def grow(self, n_new_input_units, percentage, min_new_units, scaling_factor):\n",
        "        if n_new_input_units > 0:\n",
        "            # Add connections to grown units in previous layer\n",
        "            F_growth = self.F_init(shape=(self.F.shape[0], self.F.shape[1], self.F.shape[2] + n_new_input_units, self.F.shape[3]), dtype=dtype)[:, :, -n_new_input_units:, :] * scaling_factor  # TODO is it better to be multiplying here by scaling_factor? It does help with not increasing the max weights of existing neurons when new neurons are added.\n",
        "            new_F = tf.concat([self.F.value(), F_growth], axis=-2)\n",
        "        else:\n",
        "            new_F = self.F.value()\n",
        "\n",
        "        if self.fixed_size:\n",
        "            n_new_output_units = 0\n",
        "        else:\n",
        "            # Grow new units in this layer\n",
        "            n_new_output_units = max(min_new_units, int(new_F.shape[-1] * percentage))\n",
        "            if n_new_output_units > 0:\n",
        "                F_growth = self.F_init(shape=(new_F.shape[0], new_F.shape[1], new_F.shape[2], new_F.shape[3] + n_new_output_units), dtype=dtype)[:, :, :, -n_new_output_units:] * scaling_factor\n",
        "                b_growth = self.b_init(shape=(n_new_output_units,), dtype=dtype)  # TODO for all possible bias initializers to work properly, the whole bias vector should be initialized at once\n",
        "                new_F = tf.concat([new_F, F_growth], axis=-1)\n",
        "                new_b = tf.concat([self.b.value(), b_growth], axis=0)\n",
        "\n",
        "                self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
        "\n",
        "        self.F = tf.Variable(name='F', initial_value=new_F, trainable=True)\n",
        "\n",
        "        self.regularizer.grow(n_new_output_units)\n",
        "        return n_new_output_units\n",
        "    \n",
        "    def set_regularization_penalty(self, regularization_penalty):\n",
        "        if not self.fixed_size:\n",
        "            self.regularizer.set_regularization_penalty(regularization_penalty)\n",
        "    \n",
        "    def set_regularization_method(self, regularization_method):\n",
        "        if not self.fixed_size:\n",
        "            self.regularizer.set_regularization_method(regularization_method)\n",
        "\n",
        "    def get_param_string():\n",
        "        param_string = \"\"\n",
        "        # TODO\n",
        "        return param_string\n",
        "\n",
        "\n",
        "class Flatten(tf.keras.Model):\n",
        "    def call(self, inputs, training=None):\n",
        "        return tf.reshape(tf.transpose(inputs, perm=[0, 3, 1, 2]), (inputs.shape[0], -1))\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# MODELS\n",
        "################################################################################\n",
        "\n",
        "\n",
        "class Epoch:\n",
        "    def __init__(self, grow, prune, regularization_penalty, regularization_method):\n",
        "        self.grow = grow\n",
        "        self.prune = prune\n",
        "        self.regularization_penalty = regularization_penalty\n",
        "        self.regularization_method = regularization_method\n",
        "    \n",
        "    def __str__(self):\n",
        "        return f'{int(self.grow)}{int(self.prune)}{self.regularization_penalty}{self.regularization_method}'\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return self.__str__()\n",
        "\n",
        "\n",
        "class DynamicEpoch(Epoch):\n",
        "    def __init__(self, regularization_penalty, regularization_method):\n",
        "        super().__init__(True, True, regularization_penalty, regularization_method)\n",
        "\n",
        "\n",
        "class StaticEpoch(Epoch):\n",
        "    def __init__(self, regularization_penalty, regularization_method):\n",
        "        super().__init__(False, False, regularization_penalty, regularization_method)\n",
        "\n",
        "\n",
        "class StaticEpochNoRegularization(StaticEpoch):\n",
        "    def __init__(self):\n",
        "        super().__init__(0., None)\n",
        "\n",
        "\n",
        "class Schedule:\n",
        "    def __init__(self, epochs):\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self.epochs.__iter__()\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.epochs)\n",
        "    \n",
        "    def __str__(self):\n",
        "        text = ''.join([str(epoch) for epoch in self.epochs])\n",
        "        return hashlib.sha1(text.encode('utf-8')).hexdigest()[:10]\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return self.__str__()\n",
        "\n",
        "\n",
        "class Sequential(tf.keras.Model):\n",
        "    def __init__(self, layers, activation=None):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.lrs = layers\n",
        "        \n",
        "    def call(self, inputs, training=None):\n",
        "        x = inputs\n",
        "        for layer in self.lrs:\n",
        "            x = layer(x, training=training)\n",
        "        return x\n",
        "    \n",
        "    def get_layer_input_shape(self, target_layer):\n",
        "        if target_layer.inpt_shp is not None:\n",
        "            return target_layer.inpt_shp\n",
        "\n",
        "        input = np.random.normal(size=(1,) + self.lrs[0].inpt_shp)\n",
        "        for layer in self.lrs:\n",
        "            if layer is target_layer:\n",
        "                return tuple(input.shape[1:])\n",
        "            input = layer(input)\n",
        "        raise Exception(\"Layer not found in the model.\")\n",
        "\n",
        "    def get_layer_output_shape(self, target_layer):\n",
        "        input = np.random.normal(size=(1,) + self.lrs[0].inpt_shp)\n",
        "        for layer in self.lrs:\n",
        "            output = layer(input)\n",
        "            if layer is target_layer:\n",
        "                return tuple(output.shape[1:])\n",
        "            input = output\n",
        "        raise Exception(\"Layer not found in the model.\")\n",
        "    \n",
        "    def get_layer_sizes(self):\n",
        "        \"\"\"\n",
        "        Returns the sizes of all layers in the model, including the input and output layer.\n",
        "        \"\"\"\n",
        "        layer_sizes = list()\n",
        "        first_layer = True\n",
        "        for l in range(len(self.lrs)):\n",
        "            layer = self.lrs[l]\n",
        "            if isinstance(layer, CustomLayer):\n",
        "                layer_size = layer.get_size()\n",
        "                if first_layer:\n",
        "                    layer_sizes.append(layer_size[0])\n",
        "                    first_layer = False\n",
        "                layer_sizes.append(layer_size[1])\n",
        "        return layer_sizes\n",
        "    \n",
        "    def get_hidden_layer_sizes(self):\n",
        "        return self.get_layer_sizes()[1:-1]\n",
        "    \n",
        "    def get_regularization_penalty(self):\n",
        "        #TODO improve\n",
        "        return self.lrs[-2].regularizer.regularization_penalty\n",
        "    \n",
        "    def set_regularization_penalty(self, regularization_penalty):\n",
        "        for layer in self.lrs:\n",
        "            if isinstance(layer, CustomLayer) and not layer.fixed_size:\n",
        "                layer.set_regularization_penalty(regularization_penalty)\n",
        "    \n",
        "    def set_regularization_method(self, regularization_method):\n",
        "        for layer in self.lrs:\n",
        "            if isinstance(layer, CustomLayer) and not layer.fixed_size:\n",
        "                layer.set_regularization_method(regularization_method)\n",
        "\n",
        "    def prune(self, params):\n",
        "        input_shape = self.get_layer_input_shape(self.lrs[0])\n",
        "        n_input_units = input_shape[-1]\n",
        "        active_units_indices = list(range(n_input_units))\n",
        "\n",
        "        last_custom_layer = None\n",
        "        for layer in self.lrs:\n",
        "            if isinstance(layer, CustomLayer):\n",
        "                if last_custom_layer is not None and type(last_custom_layer) != type(layer):\n",
        "                    if type(last_custom_layer) == Conv2D and type(layer) == Dense:\n",
        "                        convolutional_shape = self.get_layer_output_shape(last_custom_layer)\n",
        "                        active_units_indices = self.convert_channel_indices_to_flattened_indices(active_units_indices, convolutional_shape)\n",
        "                    else:\n",
        "                        raise Exception(\"Incorrect order of custom layer types.\")\n",
        "                active_units_indices = layer.prune(params.pruning_threshold, active_units_indices)\n",
        "                last_custom_layer = layer\n",
        "    \n",
        "    def grow(self, params):   \n",
        "        n_new_units = 0\n",
        "\n",
        "        last_custom_layer = None\n",
        "        for layer in self.lrs:\n",
        "            if isinstance(layer, CustomLayer):\n",
        "                if last_custom_layer is not None and type(last_custom_layer) != type(layer):\n",
        "                    if type(last_custom_layer) == Conv2D and type(layer) == Dense:\n",
        "                        convolutional_shape = self.get_layer_output_shape(last_custom_layer)\n",
        "                        n_new_units = n_new_units * convolutional_shape[0] * convolutional_shape[1]\n",
        "                    else:\n",
        "                        raise Exception(\"Incorrect order of custom layer types.\")\n",
        "                n_new_units = layer.grow(n_new_units, params.growth_percentage, min_new_units=params.min_new_neurons, scaling_factor=params.pruning_threshold)\n",
        "                last_custom_layer = layer\n",
        "    \n",
        "    @staticmethod\n",
        "    def convert_channel_indices_to_flattened_indices(channel_indices, convolutional_shape):\n",
        "        dense_indices = list()\n",
        "        units_per_channel = convolutional_shape[0] * convolutional_shape[1]\n",
        "        for channel_index in channel_indices:\n",
        "            for iter in range(units_per_channel):\n",
        "                dense_indices.append(channel_index * units_per_channel + iter)\n",
        "        return dense_indices\n",
        "    \n",
        "    def print_neurons(self):\n",
        "        for layer in self.lrs[:-1]:\n",
        "            print(layer.get_param_string())\n",
        "    \n",
        "    def evaluate(self, params, summed_training_loss, summed_training_accuracy):\n",
        "        # Calculate training loss and accuracy\n",
        "        if summed_training_loss is not None:\n",
        "            loss = summed_training_loss / params.x.shape[0]\n",
        "        else:\n",
        "            loss = None\n",
        "        \n",
        "        if summed_training_accuracy is not None:\n",
        "            accuracy = summed_training_accuracy / params.x.shape[0]\n",
        "        else:\n",
        "            accuracy = None\n",
        "        \n",
        "        # Calculate val loss and accuracy\n",
        "        summed_val_loss = 0\n",
        "        summed_val_accuracy = 0\n",
        "        n_val_instances = 0\n",
        "        \n",
        "        for step, (x_batch, y_batch) in enumerate(params.val_dataset):\n",
        "            y_pred = self(x_batch, training=False)\n",
        "            summed_val_loss += tf.reduce_sum(tf.keras.losses.sparse_categorical_crossentropy(y_batch, y_pred))\n",
        "            summed_val_accuracy += float(tf.reduce_sum(tf.keras.metrics.sparse_categorical_accuracy(y_batch, y_pred)))\n",
        "            n_val_instances += x_batch.shape[0]\n",
        "        \n",
        "        val_loss = summed_val_loss / n_val_instances\n",
        "        val_accuracy = summed_val_accuracy / n_val_instances\n",
        "\n",
        "        return loss, accuracy, val_loss, val_accuracy\n",
        "    \n",
        "    def print_epoch_statistics(self, params, summed_training_loss, summed_training_accuracy, message=None, require_result=False):\n",
        "        if not params.verbose:\n",
        "            if require_result:\n",
        "                return self.evaluate(params, summed_training_loss, summed_training_accuracy)\n",
        "            else:\n",
        "                return\n",
        "        \n",
        "        loss, accuracy, val_loss, val_accuracy = self.evaluate(params, summed_training_loss, summed_training_accuracy)  \n",
        "\n",
        "        if message is not None:\n",
        "            print(message)\n",
        "        \n",
        "        print(f\"loss: {loss} - accuracy: {accuracy} - val_loss: {val_loss} - val_accuracy: {val_accuracy} - penalty: {self.get_regularization_penalty()}\")\n",
        "        hidden_layer_sizes = self.get_hidden_layer_sizes()\n",
        "        print(f\"hidden layer sizes: {hidden_layer_sizes}, total units: {sum(hidden_layer_sizes)}\")\n",
        "        if params.print_neurons:\n",
        "            self.print_neurons()\n",
        "        \n",
        "        if require_result:\n",
        "            return loss, accuracy, val_loss, val_accuracy\n",
        "    \n",
        "    def update_history(self, params, loss, accuracy, val_loss, val_accuracy):\n",
        "        params.history['loss'].append(loss)\n",
        "        params.history['accuracy'].append(accuracy)\n",
        "        params.history['val_loss'].append(val_loss)\n",
        "        params.history['val_accuracy'].append(val_accuracy)\n",
        "        params.history['hidden_layer_sizes'].append(self.get_hidden_layer_sizes())\n",
        "    \n",
        "    @staticmethod\n",
        "    def prepare_datasets(x, y, batch_size, validation_data):\n",
        "        train_dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "        train_dataset = train_dataset.shuffle(buffer_size=20000).batch(batch_size)\n",
        "        val_dataset = tf.data.Dataset.from_tensor_slices(validation_data).batch(batch_size)\n",
        "        return train_dataset.prefetch(tf.data.AUTOTUNE), val_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    \n",
        "    def manage_dynamic_regularization(self, params, val_loss):\n",
        "        if val_loss >= params.best_conditional_val_loss * params.stall_coefficient:\n",
        "            # Training is currently in stall\n",
        "            if not params.training_stalled:\n",
        "                penalty = self.get_regularization_penalty() * params.regularization_penalty_multiplier\n",
        "                print(\"Changing penalty...\")\n",
        "                # TODO this must be modified, penalty can differ for each layer\n",
        "                self.set_regularization_penalty(penalty)\n",
        "                params.training_stalled = True\n",
        "        else:\n",
        "            params.best_conditional_val_loss = val_loss\n",
        "            params.training_stalled = False\n",
        "    \n",
        "    def grow_wrapper(self, params):\n",
        "        dynamic_reqularization_active = params.regularization_penalty_multiplier != 1.\n",
        "        if dynamic_reqularization_active:\n",
        "            loss, accuracy, val_loss, val_accuracy = self.print_epoch_statistics(params, None, None, \"Before growing:\", require_result=True)\n",
        "            self.manage_dynamic_regularization(params, val_loss)\n",
        "        else:\n",
        "            self.print_epoch_statistics(params, None, None, \"Before growing:\")\n",
        "\n",
        "        self.grow(params)\n",
        "        self.print_epoch_statistics(params, None, None, \"After growing:\")\n",
        "    \n",
        "    def prune_wrapper(self, params, summed_loss, summed_accuracy):\n",
        "        loss, accuracy, _, _ = self.print_epoch_statistics(params, summed_loss, summed_accuracy, \"Before pruning:\", require_result=True)\n",
        "        self.prune(params)\n",
        "        _, _, val_loss, val_accuracy = self.print_epoch_statistics(params, None, None, \"After pruning:\", require_result=True)\n",
        "\n",
        "        self.update_history(params, loss, accuracy, val_loss, val_accuracy)\n",
        "    \n",
        "    class ParameterContainer:\n",
        "        def __init__(self, x, y, optimizer, batch_size, min_new_neurons, validation_data, pruning_threshold, \n",
        "                regularization_penalty_multiplier, stall_coefficient, growth_percentage, mini_epochs_per_epoch, verbose, print_neurons, use_static_graph):\n",
        "            self.x = x\n",
        "            self.y = y\n",
        "            self.optimizer = optimizer\n",
        "            self.batch_size = batch_size\n",
        "            self.min_new_neurons = min_new_neurons\n",
        "            self.validation_data = validation_data\n",
        "            self.pruning_threshold = pruning_threshold\n",
        "            self.regularization_penalty_multiplier = regularization_penalty_multiplier\n",
        "            self.stall_coefficient = stall_coefficient\n",
        "            self.growth_percentage = growth_percentage\n",
        "            self.mini_epochs_per_epoch = mini_epochs_per_epoch\n",
        "            self.verbose = verbose\n",
        "            self.print_neurons = print_neurons\n",
        "            self.use_static_graph = use_static_graph\n",
        "\n",
        "            self.train_dataset, self.val_dataset = Sequential.prepare_datasets(x, y, batch_size, validation_data)\n",
        "            self.history = self.prepare_history()\n",
        "\n",
        "            self.best_conditional_val_loss = np.inf\n",
        "            self.training_stalled = False\n",
        "        \n",
        "        @staticmethod\n",
        "        def prepare_history():\n",
        "            history = {\n",
        "                'loss': list(),\n",
        "                'accuracy': list(),\n",
        "                'val_loss': list(),\n",
        "                'val_accuracy': list(),\n",
        "                'hidden_layer_sizes': list(),\n",
        "            }\n",
        "            return history\n",
        "    \n",
        "    def fit_single_step(self, params, x_batch, y_batch):\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x_batch, training=True)\n",
        "            raw_loss = tf.keras.losses.sparse_categorical_crossentropy(y_batch, y_pred)\n",
        "            loss_value = tf.reduce_mean(raw_loss)\n",
        "            loss_value += sum(self.losses)  # Add losses registered by model.add_loss\n",
        "\n",
        "            loss = tf.reduce_sum(raw_loss)\n",
        "            accuracy = float(tf.reduce_sum(tf.keras.metrics.sparse_categorical_accuracy(y_batch, y_pred)))\n",
        "\n",
        "        grads = tape.gradient(loss_value, self.trainable_variables)\n",
        "        params.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
        "\n",
        "        return loss, accuracy\n",
        "    \n",
        "    def fit_single_epoch(self, params):\n",
        "        summed_loss = 0\n",
        "        summed_accuracy = 0\n",
        "        \n",
        "        for mini_epoch in range(params.mini_epochs_per_epoch):\n",
        "            summed_loss = 0\n",
        "            summed_accuracy = 0\n",
        "\n",
        "            if params.use_static_graph:\n",
        "                fit_single_step_function = tf.function(self.fit_single_step)\n",
        "            else:\n",
        "                fit_single_step_function = self.fit_single_step\n",
        "            for step, (x_batch, y_batch) in enumerate(params.train_dataset):\n",
        "                loss, accuracy = fit_single_step_function(params, x_batch, y_batch)\n",
        "                summed_loss += loss\n",
        "                summed_accuracy += accuracy\n",
        "        \n",
        "        return summed_loss, summed_accuracy\n",
        "\n",
        "    def fit(self, x, y, optimizer, schedule, batch_size, min_new_neurons, validation_data, pruning_threshold=0.001, regularization_penalty_multiplier=1., \n",
        "            stall_coefficient=1, growth_percentage=0.2, mini_epochs_per_epoch=1, verbose=True, print_neurons=False, use_static_graph=True):\n",
        "        params = self.ParameterContainer(x=x, y=y, optimizer=optimizer, batch_size=batch_size, min_new_neurons=min_new_neurons, validation_data=validation_data, \n",
        "                                         pruning_threshold=pruning_threshold, regularization_penalty_multiplier=regularization_penalty_multiplier, stall_coefficient=stall_coefficient, \n",
        "                                         growth_percentage=growth_percentage, mini_epochs_per_epoch=mini_epochs_per_epoch, verbose=verbose, print_neurons=print_neurons, \n",
        "                                         use_static_graph=use_static_graph)\n",
        "        self.build(x.shape)  # Necessary when verbose == False\n",
        "\n",
        "        for epoch_no, epoch in enumerate(schedule):\n",
        "            if verbose:\n",
        "                print(\"##########################################################\")\n",
        "                print(f\"Epoch {epoch_no + 1}/{len(schedule)}\")\n",
        "            \n",
        "            self.set_regularization_penalty(epoch.regularization_penalty)\n",
        "            self.set_regularization_method(epoch.regularization_method)\n",
        "\n",
        "            if epoch.grow:\n",
        "                self.grow_wrapper(params)\n",
        "            \n",
        "            summed_loss, summed_accuracy = self.fit_single_epoch(params)\n",
        "\n",
        "            if epoch.prune:\n",
        "                self.prune_wrapper(params, summed_loss, summed_accuracy)\n",
        "            else:\n",
        "                loss, accuracy, val_loss, val_accuracy = self.print_epoch_statistics(params, summed_loss, summed_accuracy, require_result=True)\n",
        "                self.update_history(params, loss, accuracy, val_loss, val_accuracy)\n",
        "        \n",
        "        return params.history\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# HELPER FUNCTIONS\n",
        "################################################################################\n",
        "\n",
        "\n",
        "def get_statistics_from_history(history):\n",
        "    best_epoch_number = np.argmax(history['val_accuracy'])\n",
        "    best_val_accuracy = history['val_accuracy'][best_epoch_number]\n",
        "    best_hidden_layer_sizes = history['hidden_layer_sizes'][best_epoch_number]\n",
        "    return best_val_accuracy, best_hidden_layer_sizes\n",
        "\n",
        "\n",
        "def get_statistics_from_histories(histories):\n",
        "    best_val_accuracies = list()\n",
        "    all_best_hidden_layer_sizes = list()\n",
        "\n",
        "    for history in histories:\n",
        "        best_val_accuracy, best_hidden_layer_sizes = get_statistics_from_history(history)\n",
        "        best_val_accuracies.append(best_val_accuracy)\n",
        "        all_best_hidden_layer_sizes.append(best_hidden_layer_sizes)\n",
        "    \n",
        "    mean_best_val_accuracy = np.mean(best_val_accuracies)\n",
        "    mean_best_hidden_layer_sizes = [np.mean(layer) for layer in list(zip(*all_best_hidden_layer_sizes))]\n",
        "    \n",
        "    return mean_best_val_accuracy, mean_best_hidden_layer_sizes\n",
        "\n",
        "\n",
        "def cross_validate(train_fn, x, y, n_splits, random_state=42, *args, **kwargs):\n",
        "    from sklearn.model_selection import KFold\n",
        "\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "\n",
        "    histories = list()\n",
        "    for i, (train_index, test_index) in enumerate(kf.split(x)):\n",
        "        xtrain, xtest = x[train_index], x[test_index]\n",
        "        ytrain, ytest = y[train_index], y[test_index]\n",
        "\n",
        "        history = train_fn(xtrain, ytrain, validation_data=(xtest, ytest), *args, **kwargs)\n",
        "        histories.append(history)\n",
        "\n",
        "        best_val_accuracy, best_hidden_layer_sizes = get_statistics_from_history(history)\n",
        "        print(f\"Run {i} completed, best_val_accuracy: {best_val_accuracy}, best_hidden_layer_sizes: {best_hidden_layer_sizes}\")\n",
        "\n",
        "    mean_best_val_accuracy, mean_best_hidden_layer_sizes = get_statistics_from_histories(histories)\n",
        "    print(f'mean_best_val_accuracy: {mean_best_val_accuracy}')\n",
        "    print(f'mean_best_hidden_layer_sizes: {mean_best_hidden_layer_sizes}')\n",
        "\n",
        "    return histories, mean_best_hidden_layer_sizes\n",
        "\n",
        "\n",
        "def hyperparameter_search(train_fn, x, y, validation_data, *args, **kwargs):\n",
        "    from itertools import product\n",
        "\n",
        "    all_params = [*args] + list(kwargs.values())\n",
        "    histories = list()\n",
        "\n",
        "    best_overall_val_accuracy = -np.inf\n",
        "    best_overall_combination = None\n",
        "\n",
        "    for combination in product(*all_params):\n",
        "        combination_args = combination[:len(args)]\n",
        "\n",
        "        combination_kwargs_values = combination[len(args):]\n",
        "        combination_kwargs = dict(zip(kwargs.keys(), combination_kwargs_values))\n",
        "\n",
        "        history = train_fn(x, y, validation_data, *combination_args, **combination_kwargs)\n",
        "        history['parameters'] = combination\n",
        "        histories.append(history)\n",
        "\n",
        "        best_val_accuracy, best_hidden_layer_sizes = get_statistics_from_history(history)\n",
        "        print(f\"Run with parameters {combination} completed, best_val_accuracy: {best_val_accuracy}, best_hidden_layer_sizes sizes: {best_hidden_layer_sizes}\")\n",
        "\n",
        "        if best_val_accuracy > best_overall_val_accuracy:\n",
        "            best_overall_val_accuracy = best_val_accuracy\n",
        "            best_overall_combination = combination\n",
        "    \n",
        "    print(f'Best overall combination: {best_overall_combination}, val_accuracy: {best_overall_val_accuracy}')\n",
        "\n",
        "    return histories, best_overall_combination\n",
        "\n",
        "\n",
        "def get_convolutional_model(x, layer_sizes, output_neurons=10):\n",
        "    model = Sequential([\n",
        "        Conv2D(layer_sizes[0], filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', kernel_initializer='lecun_normal', input_shape=x[0,:,:,:].shape),\n",
        "        Conv2D(layer_sizes[1], filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(layer_sizes[2], filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', kernel_initializer='lecun_normal'),\n",
        "        Conv2D(layer_sizes[3], filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(layer_sizes[4], activation='selu', kernel_initializer='lecun_normal'),\n",
        "        Dense(output_neurons, activation='softmax', fixed_size=True),\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_fn(x, y, validation_data, learning_rate, schedule, layer_sizes, output_neurons=10, min_new_neurons=20, \n",
        "             growth_percentage=0.2, verbose=False, use_static_graph=True):\n",
        "    batch_size = 128\n",
        "\n",
        "    model = get_convolutional_model(x, layer_sizes, output_neurons)\n",
        "    \n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    history = model.fit(x=x, y=y, optimizer=optimizer, schedule=schedule, batch_size=batch_size, min_new_neurons=min_new_neurons, \n",
        "                        validation_data=validation_data, growth_percentage=growth_percentage, verbose=verbose, use_static_graph=use_static_graph)\n",
        "    \n",
        "    return history"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1MrQXUTFwOe"
      },
      "source": [
        "# Final accuracy tests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rates = [0.0001 * 2 ** i for i in range(7)]\n",
        "learning_rates"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSsLiNHjWU6q",
        "outputId": "f2a1eb05-dc45-4826-8d2a-5791b302e161"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0001, 0.0002, 0.0004, 0.0008, 0.0016, 0.0032, 0.0064]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CIFAR100"
      ],
      "metadata": {
        "id": "l4mmt4NUZPrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cifar100 = get_cifar_100_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzVe14JzL4ve",
        "outputId": "750bb85e-7330-45e5-a3d7-fd8d076d9ede"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 6s 0us/step\n",
            "169017344/169001437 [==============================] - 6s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([DynamicEpoch(0.00002, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20)\n",
        "histories, best_overall_combination = hyperparameter_search(train_fn, x=cifar100.X_train_norm, y=cifar100.y_train, validation_data=(cifar100.X_test_norm, cifar100.y_test), \n",
        "                                  learning_rate=[0.0001, 0.0002, 0.0004], schedule=[schedule], layer_sizes=[[100, 100, 100, 100, 100]], \n",
        "                                  output_neurons=[100], min_new_neurons=[20], growth_percentage=[0.2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "td7nnRPkOG0A",
        "outputId": "3fd61bd4-31a4-4ed8-b1cf-6c675379d0cc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0001, ec4ba8ef9e, [100, 100, 100, 100, 100], 100, 20, 0.2) completed, best_val_accuracy: 0.44, best_hidden_layer_sizes sizes: [90, 29, 38, 43, 100]\n",
            "Run with parameters (0.0002, ec4ba8ef9e, [100, 100, 100, 100, 100], 100, 20, 0.2) completed, best_val_accuracy: 0.4448, best_hidden_layer_sizes sizes: [67, 23, 27, 73, 195]\n",
            "Run with parameters (0.0004, ec4ba8ef9e, [100, 100, 100, 100, 100], 100, 20, 0.2) completed, best_val_accuracy: 0.4358, best_hidden_layer_sizes sizes: [60, 18, 55, 120, 452]\n",
            "Best overall combination: (0.0002, ec4ba8ef9e, [100, 100, 100, 100, 100], 100, 20, 0.2), val_accuracy: 0.4448\n",
            "CPU times: user 9min 57s, sys: 20.8 s, total: 10min 18s\n",
            "Wall time: 9min 3s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_learning_rate = best_overall_combination[0]\n",
        "best_learning_rate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--jg7yrcdMOM",
        "outputId": "6eaeea7a-ca79-4212-e51e-4973e6ef24f4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0002"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([DynamicEpoch(0.00002, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20)\n",
        "histories, mean_best_hidden_layer_sizes = cross_validate(\n",
        "    train_fn, cifar100.X_norm, cifar100.y, n_splits=6, learning_rate=best_learning_rate,\n",
        "    schedule=schedule, layer_sizes=[100, 100, 100, 100, 100], output_neurons=100, min_new_neurons=20, growth_percentage=0.2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WA3x6RkTlqt",
        "outputId": "ce80f1de-d326-4f44-bc37-03d906aedb13"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best_val_accuracy: 0.4428, best_hidden_layer_sizes: [68, 19, 33, 74, 191]\n",
            "Run 1 completed, best_val_accuracy: 0.4512, best_hidden_layer_sizes: [62, 22, 29, 61, 195]\n",
            "Run 2 completed, best_val_accuracy: 0.4484, best_hidden_layer_sizes: [67, 19, 30, 61, 200]\n",
            "Run 3 completed, best_val_accuracy: 0.4485, best_hidden_layer_sizes: [67, 18, 33, 63, 199]\n",
            "Run 4 completed, best_val_accuracy: 0.4577, best_hidden_layer_sizes: [62, 20, 27, 62, 190]\n",
            "Run 5 completed, best_val_accuracy: 0.457, best_hidden_layer_sizes: [69, 23, 28, 66, 192]\n",
            "mean_best_val_accuracy: 0.45093333333333335\n",
            "mean_best_hidden_layer_sizes: [65.83333333333333, 20.166666666666668, 30.0, 64.5, 194.5]\n",
            "CPU times: user 19min 26s, sys: 41.6 s, total: 20min 8s\n",
            "Wall time: 17min 17s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rounded_mean_best_hidden_layer_sizes = [round(x) for x in mean_best_hidden_layer_sizes]\n",
        "rounded_mean_best_hidden_layer_sizes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3T6G7caLTKUb",
        "outputId": "359e5813-8b3c-423f-8ca4-a109f7984264"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[66, 20, 30, 64, 194]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([StaticEpochNoRegularization()] * 40)\n",
        "histories, best_overall_combination = hyperparameter_search(train_fn, x=cifar100.X_train_norm, y=cifar100.y_train, validation_data=(cifar100.X_test_norm, cifar100.y_test), \n",
        "                                  learning_rate=[0.0001, 0.0002, 0.0004, 0.0008, 0.0016], schedule=[schedule], layer_sizes=[rounded_mean_best_hidden_layer_sizes], \n",
        "                                  output_neurons=[100], min_new_neurons=[20], growth_percentage=[0.2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vr-TsoVFaJbR",
        "outputId": "0453e6e8-733b-46ed-c90d-8314cfd5c88e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0001, 4a0f172746, [66, 20, 30, 64, 194], 100, 20, 0.2) completed, best_val_accuracy: 0.3397, best_hidden_layer_sizes sizes: [66, 20, 30, 64, 194]\n",
            "Run with parameters (0.0002, 4a0f172746, [66, 20, 30, 64, 194], 100, 20, 0.2) completed, best_val_accuracy: 0.3392, best_hidden_layer_sizes sizes: [66, 20, 30, 64, 194]\n",
            "Run with parameters (0.0004, 4a0f172746, [66, 20, 30, 64, 194], 100, 20, 0.2) completed, best_val_accuracy: 0.334, best_hidden_layer_sizes sizes: [66, 20, 30, 64, 194]\n",
            "Run with parameters (0.0008, 4a0f172746, [66, 20, 30, 64, 194], 100, 20, 0.2) completed, best_val_accuracy: 0.3272, best_hidden_layer_sizes sizes: [66, 20, 30, 64, 194]\n",
            "Run with parameters (0.0016, 4a0f172746, [66, 20, 30, 64, 194], 100, 20, 0.2) completed, best_val_accuracy: 0.3199, best_hidden_layer_sizes sizes: [66, 20, 30, 64, 194]\n",
            "Best overall combination: (0.0001, 4a0f172746, [66, 20, 30, 64, 194], 100, 20, 0.2), val_accuracy: 0.3397\n",
            "CPU times: user 11min 56s, sys: 29 s, total: 12min 25s\n",
            "Wall time: 9min 30s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_learning_rate = best_overall_combination[0]\n",
        "best_learning_rate"
      ],
      "metadata": {
        "id": "nZzqgA1nmd7S",
        "outputId": "a4e73b2c-3ad8-40da-83c6-7742e995cc3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0001"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([StaticEpochNoRegularization()] * 40)\n",
        "histories, mean_best_hidden_layer_sizes = cross_validate(\n",
        "    train_fn, cifar100.X_norm, cifar100.y, n_splits=6, learning_rate=best_learning_rate,\n",
        "    schedule=schedule, layer_sizes=rounded_mean_best_hidden_layer_sizes, output_neurons=100, min_new_neurons=20, growth_percentage=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "1RUzP8CXmgOI",
        "outputId": "82f33f74-804a-4bee-e87a-ed104da51e39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 0 completed, best_val_accuracy: 0.3183, best_hidden_layer_sizes: [66, 20, 30, 64, 194]\n",
            "Run 1 completed, best_val_accuracy: 0.3265, best_hidden_layer_sizes: [66, 20, 30, 64, 194]\n",
            "Run 2 completed, best_val_accuracy: 0.3134, best_hidden_layer_sizes: [66, 20, 30, 64, 194]\n",
            "Run 3 completed, best_val_accuracy: 0.3345, best_hidden_layer_sizes: [66, 20, 30, 64, 194]\n",
            "Run 4 completed, best_val_accuracy: 0.325, best_hidden_layer_sizes: [66, 20, 30, 64, 194]\n",
            "Run 5 completed, best_val_accuracy: 0.3234, best_hidden_layer_sizes: [66, 20, 30, 64, 194]\n",
            "mean_best_val_accuracy: 0.3235166666666667\n",
            "mean_best_hidden_layer_sizes: [66.0, 20.0, 30.0, 64.0, 194.0]\n",
            "CPU times: user 14min 32s, sys: 34.6 s, total: 15min 7s\n",
            "Wall time: 11min 33s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Street View House Numbers"
      ],
      "metadata": {
        "id": "edvD6CfRmy9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svhn = get_svhn_dataset()"
      ],
      "metadata": {
        "id": "agjNnmNYnJnM"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([DynamicEpoch(0.00002, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20)\n",
        "histories, best_overall_combination = hyperparameter_search(train_fn, x=svhn.X_train_norm, y=svhn.y_train, validation_data=(svhn.X_test_norm, svhn.y_test), \n",
        "                                  learning_rate=[0.0001, 0.0002, 0.0004], schedule=[schedule], layer_sizes=[[100, 100, 100, 100, 100]], \n",
        "                                  output_neurons=[10], min_new_neurons=[20], growth_percentage=[0.2])"
      ],
      "metadata": {
        "id": "RsEq_PP8nQKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_learning_rate = best_overall_combination[0]\n",
        "best_learning_rate"
      ],
      "metadata": {
        "id": "YnxsROtxpnkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([DynamicEpoch(0.00002, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20)\n",
        "histories, mean_best_hidden_layer_sizes = cross_validate(\n",
        "    train_fn, svhn.X_norm, svhn.y, n_splits=4, learning_rate=best_learning_rate,\n",
        "    schedule=schedule, layer_sizes=[100, 100, 100, 100, 100], output_neurons=10, min_new_neurons=20, growth_percentage=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "j3dIJMnGpsBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rounded_mean_best_hidden_layer_sizes = [round(x) for x in mean_best_hidden_layer_sizes]\n",
        "rounded_mean_best_hidden_layer_sizes"
      ],
      "metadata": {
        "id": "SZ5wlnWSpsGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([StaticEpochNoRegularization()] * 40)\n",
        "histories, best_overall_combination = hyperparameter_search(train_fn, x=svhn.X_train_norm, y=svhn.y_train, validation_data=(svhn.X_test_norm, svhn.y_test), \n",
        "                                  learning_rate=[0.0001, 0.0002, 0.0004, 0.0008, 0.0016], schedule=[schedule], layer_sizes=[rounded_mean_best_hidden_layer_sizes], \n",
        "                                  output_neurons=[10], min_new_neurons=[20], growth_percentage=[0.2])"
      ],
      "metadata": {
        "id": "KGHdm0iJpsNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_learning_rate = best_overall_combination[0]\n",
        "best_learning_rate"
      ],
      "metadata": {
        "id": "RfwjPtX7qNim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([StaticEpochNoRegularization()] * 40)\n",
        "histories, mean_best_hidden_layer_sizes = cross_validate(\n",
        "    train_fn, svhn.X_norm, svhn.y, n_splits=4, learning_rate=best_learning_rate,\n",
        "    schedule=schedule, layer_sizes=rounded_mean_best_hidden_layer_sizes, output_neurons=10, min_new_neurons=20, growth_percentage=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "_MePaSfwqPSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CIFAR10"
      ],
      "metadata": {
        "id": "M-FaQr8cro9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10 = get_cifar_10_dataset()"
      ],
      "metadata": {
        "id": "wAyVYQ5Brqnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([DynamicEpoch(0.00002, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20)\n",
        "histories, best_overall_combination = hyperparameter_search(train_fn, x=cifar10.X_train_norm, y=cifar10.y_train, validation_data=(cifar10.X_test_norm, cifar10.y_test), \n",
        "                                  learning_rate=[0.0001, 0.0002, 0.0004], schedule=[schedule], layer_sizes=[[100, 100, 100, 100, 100]], \n",
        "                                  output_neurons=[10], min_new_neurons=[20], growth_percentage=[0.2])"
      ],
      "metadata": {
        "id": "TcPnlUpKrqux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_learning_rate = best_overall_combination[0]\n",
        "best_learning_rate"
      ],
      "metadata": {
        "id": "1c_COXAgrqyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([DynamicEpoch(0.00002, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20)\n",
        "histories, mean_best_hidden_layer_sizes = cross_validate(\n",
        "    train_fn, cifar10.X_norm, cifar10.y, n_splits=6, learning_rate=best_learning_rate,\n",
        "    schedule=schedule, layer_sizes=[100, 100, 100, 100, 100], output_neurons=10, min_new_neurons=20, growth_percentage=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "7DQlPH90rq1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rounded_mean_best_hidden_layer_sizes = [round(x) for x in mean_best_hidden_layer_sizes]\n",
        "rounded_mean_best_hidden_layer_sizes"
      ],
      "metadata": {
        "id": "q_1Gql57rq4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([StaticEpochNoRegularization()] * 40)\n",
        "histories, best_overall_combination = hyperparameter_search(train_fn, x=cifar10.X_train_norm, y=cifar10.y_train, validation_data=(cifar10.X_test_norm, cifar10.y_test), \n",
        "                                  learning_rate=[0.0001, 0.0002, 0.0004, 0.0008, 0.0016], schedule=[schedule], layer_sizes=[rounded_mean_best_hidden_layer_sizes], \n",
        "                                  output_neurons=[10], min_new_neurons=[20], growth_percentage=[0.2])"
      ],
      "metadata": {
        "id": "O6BK6222sD1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_learning_rate = best_overall_combination[0]\n",
        "best_learning_rate"
      ],
      "metadata": {
        "id": "-LnzcDWasD4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([StaticEpochNoRegularization()] * 40)\n",
        "histories, mean_best_hidden_layer_sizes = cross_validate(\n",
        "    train_fn, cifar10.X_norm, cifar10.y, n_splits=6, learning_rate=best_learning_rate,\n",
        "    schedule=schedule, layer_sizes=rounded_mean_best_hidden_layer_sizes, output_neurons=10, min_new_neurons=20, growth_percentage=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "_TjO54M6sD7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fashion MNIST"
      ],
      "metadata": {
        "id": "vLDo_10YsgNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = get_fashion_mnist_dataset()"
      ],
      "metadata": {
        "id": "_ipVjRDqrq8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([DynamicEpoch(0.00002, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20)\n",
        "histories, best_overall_combination = hyperparameter_search(train_fn, x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test), \n",
        "                                  learning_rate=[0.0001, 0.0002, 0.0004], schedule=[schedule], layer_sizes=[[100, 100, 100, 100, 100]], \n",
        "                                  output_neurons=[10], min_new_neurons=[20], growth_percentage=[0.2])"
      ],
      "metadata": {
        "id": "g43wcgugsuIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_learning_rate = best_overall_combination[0]\n",
        "best_learning_rate"
      ],
      "metadata": {
        "id": "CnaZ5sW6svYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([DynamicEpoch(0.00002, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20)\n",
        "histories, mean_best_hidden_layer_sizes = cross_validate(\n",
        "    train_fn, fashion_mnist.X_norm, fashion_mnist.y, n_splits=7, learning_rate=best_learning_rate,\n",
        "    schedule=schedule, layer_sizes=[100, 100, 100, 100, 100], output_neurons=10, min_new_neurons=20, growth_percentage=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "xkOlyqQbsvbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rounded_mean_best_hidden_layer_sizes = [round(x) for x in mean_best_hidden_layer_sizes]\n",
        "rounded_mean_best_hidden_layer_sizes"
      ],
      "metadata": {
        "id": "Plo75e8lsvdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([StaticEpochNoRegularization()] * 40)\n",
        "histories, best_overall_combination = hyperparameter_search(train_fn, x=fashion_mnist.X_train_norm, y=fashion_mnist.y_train, validation_data=(fashion_mnist.X_test_norm, fashion_mnist.y_test), \n",
        "                                  learning_rate=[0.0001, 0.0002, 0.0004, 0.0008, 0.0016], schedule=[schedule], layer_sizes=[rounded_mean_best_hidden_layer_sizes], \n",
        "                                  output_neurons=[10], min_new_neurons=[20], growth_percentage=[0.2])"
      ],
      "metadata": {
        "id": "cPLGINjQsvgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_learning_rate = best_overall_combination[0]\n",
        "best_learning_rate"
      ],
      "metadata": {
        "id": "aBMFxM9VszsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([StaticEpochNoRegularization()] * 40)\n",
        "histories, mean_best_hidden_layer_sizes = cross_validate(\n",
        "    train_fn, fashion_mnist.X_norm, fashion_mnist.y, n_splits=7, learning_rate=best_learning_rate,\n",
        "    schedule=schedule, layer_sizes=rounded_mean_best_hidden_layer_sizes, output_neurons=10, min_new_neurons=20, growth_percentage=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "SVO0wAZUszx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MNIST"
      ],
      "metadata": {
        "id": "yq2h8XESsjwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = get_mnist_dataset()"
      ],
      "metadata": {
        "id": "U5lL2sS2slBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([DynamicEpoch(0.00002, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20)\n",
        "histories, best_overall_combination = hyperparameter_search(train_fn, x=mnist.X_train_norm, y=mnist.y_train, validation_data=(mnist.X_test_norm, mnist.y_test), \n",
        "                                  learning_rate=[0.0001, 0.0002, 0.0004], schedule=[schedule], layer_sizes=[[100, 100, 100, 100, 100]], \n",
        "                                  output_neurons=[10], min_new_neurons=[20], growth_percentage=[0.2])"
      ],
      "metadata": {
        "id": "nj58iVyUtVEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_learning_rate = best_overall_combination[0]\n",
        "best_learning_rate"
      ],
      "metadata": {
        "id": "ixVarQOxtVG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([DynamicEpoch(0.00002, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20)\n",
        "histories, mean_best_hidden_layer_sizes = cross_validate(\n",
        "    train_fn, mnist.X_norm, mnist.y, n_splits=7, learning_rate=best_learning_rate,\n",
        "    schedule=schedule, layer_sizes=[100, 100, 100, 100, 100], output_neurons=10, min_new_neurons=20, growth_percentage=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "8T-FpKMrtVJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rounded_mean_best_hidden_layer_sizes = [round(x) for x in mean_best_hidden_layer_sizes]\n",
        "rounded_mean_best_hidden_layer_sizes"
      ],
      "metadata": {
        "id": "kMDDfv8MtVMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([StaticEpochNoRegularization()] * 40)\n",
        "histories, best_overall_combination = hyperparameter_search(train_fn, x=mnist.X_train_norm, y=mnist.y_train, validation_data=(mnist.X_test_norm, mnist.y_test), \n",
        "                                  learning_rate=[0.0001, 0.0002, 0.0004, 0.0008, 0.0016], schedule=[schedule], layer_sizes=[rounded_mean_best_hidden_layer_sizes], \n",
        "                                  output_neurons=[10], min_new_neurons=[20], growth_percentage=[0.2])"
      ],
      "metadata": {
        "id": "SWRd6SvYtVOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_learning_rate = best_overall_combination[0]\n",
        "best_learning_rate"
      ],
      "metadata": {
        "id": "J-LTH8KftVQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([StaticEpochNoRegularization()] * 40)\n",
        "histories, mean_best_hidden_layer_sizes = cross_validate(\n",
        "    train_fn, mnist.X_norm, mnist.y, n_splits=7, learning_rate=best_learning_rate,\n",
        "    schedule=schedule, layer_sizes=rounded_mean_best_hidden_layer_sizes, output_neurons=10, min_new_neurons=20, growth_percentage=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "bxZEUlxytawY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tiny ImageNet"
      ],
      "metadata": {
        "id": "8nyE3FnKtzfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tiny_imagenet = get_tiny_imagenet_dataset()"
      ],
      "metadata": {
        "id": "a7f4aAUTuAwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([DynamicEpoch(0.00002, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20)\n",
        "histories, best_overall_combination = hyperparameter_search(train_fn, x=tiny_imagenet.X_train_norm, y=tiny_imagenet.y_train, validation_data=(tiny_imagenet.X_test_norm, tiny_imagenet.y_test), \n",
        "                                  learning_rate=[0.0001, 0.0002, 0.0004], schedule=[schedule], layer_sizes=[[100, 100, 100, 100, 100]], \n",
        "                                  output_neurons=[200], min_new_neurons=[20], growth_percentage=[0.2])"
      ],
      "metadata": {
        "id": "1If_JhQjuBVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_learning_rate = best_overall_combination[0]\n",
        "best_learning_rate"
      ],
      "metadata": {
        "id": "4J7PduGCuBYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([DynamicEpoch(0.00002, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20)\n",
        "histories, mean_best_hidden_layer_sizes = cross_validate(\n",
        "    train_fn, tiny_imagenet.X_norm, tiny_imagenet.y, n_splits=11, learning_rate=best_learning_rate,\n",
        "    schedule=schedule, layer_sizes=[100, 100, 100, 100, 100], output_neurons=200, min_new_neurons=20, growth_percentage=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "wQ6EeXZBuBbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rounded_mean_best_hidden_layer_sizes = [round(x) for x in mean_best_hidden_layer_sizes]\n",
        "rounded_mean_best_hidden_layer_sizes"
      ],
      "metadata": {
        "id": "Ug2Y9m3JuBdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([StaticEpochNoRegularization()] * 40)\n",
        "histories, best_overall_combination = hyperparameter_search(train_fn, x=tiny_imagenet.X_train_norm, y=tiny_imagenet.y_train, validation_data=(tiny_imagenet.X_test_norm, tiny_imagenet.y_test), \n",
        "                                  learning_rate=[0.0001, 0.0002, 0.0004, 0.0008, 0.0016], schedule=[schedule], layer_sizes=[rounded_mean_best_hidden_layer_sizes], \n",
        "                                  output_neurons=[200], min_new_neurons=[20], growth_percentage=[0.2])"
      ],
      "metadata": {
        "id": "TnoswIOWuSgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_learning_rate = best_overall_combination[0]\n",
        "best_learning_rate"
      ],
      "metadata": {
        "id": "QYtSsbjuuSi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([StaticEpochNoRegularization()] * 40)\n",
        "histories, mean_best_hidden_layer_sizes = cross_validate(\n",
        "    train_fn, tiny_imagenet.X_norm, tiny_imagenet.y, n_splits=11, learning_rate=best_learning_rate,\n",
        "    schedule=schedule, layer_sizes=rounded_mean_best_hidden_layer_sizes, output_neurons=200, min_new_neurons=20, growth_percentage=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "qGsq3IK9uSld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Legacy code"
      ],
      "metadata": {
        "id": "zDDY3V-oL26k"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsivpauwveEK"
      },
      "source": [
        "## CIFAR100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cifar100 = get_cifar_100_dataset()"
      ],
      "metadata": {
        "id": "SjJ2e9njMl04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2dca139-f254-4dbb-c3f7-c7728f593129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 6s 0us/step\n",
            "169017344/169001437 [==============================] - 6s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "model = get_convolutional_model(cifar100.X_train_norm, regularization_penalty=0.00002, regularization_method='weighted_l1', layer_sizes=[100, 100, 100, 100, 100], output_neurons=100)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "history = model.fit(cifar100.X_train_norm, cifar100.y_train, optimizer, epochs=40, self_scaling_epochs=20, batch_size=batch_size, \n",
        "                    min_new_neurons=20, validation_data=(cifar100.X_test_norm, cifar100.y_test), pruning_only_epochs=0, \n",
        "                    growth_percentage=0.2, verbose=True)"
      ],
      "metadata": {
        "id": "7934TYSFhFKN",
        "outputId": "bbd2acce-4228-4634-b3e7-20616475dff0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.9665093421936035 - val_accuracy: 0.0102 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.9665093421936035 - val_accuracy: 0.0102 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "Before pruning:\n",
            "loss: 4.0280256271362305 - accuracy: 0.1080000028014183 - val_loss: 3.6404457092285156 - val_accuracy: 0.1663 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.64062762260437 - val_accuracy: 0.1661 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 2/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.64062762260437 - val_accuracy: 0.1661 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.64062762260437 - val_accuracy: 0.1661 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "Before pruning:\n",
            "loss: 3.6307544708251953 - accuracy: 0.15977999567985535 - val_loss: 3.4752750396728516 - val_accuracy: 0.1883 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.475353240966797 - val_accuracy: 0.1886 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 106], total units: 506\n",
            "##########################################################\n",
            "Epoch 3/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.475353240966797 - val_accuracy: 0.1886 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 106], total units: 506\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.4753527641296387 - val_accuracy: 0.1886 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 127], total units: 607\n",
            "Before pruning:\n",
            "loss: 3.447922706604004 - accuracy: 0.18661999702453613 - val_loss: 3.241731882095337 - val_accuracy: 0.2306 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 127], total units: 607\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.241814374923706 - val_accuracy: 0.2302 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 98, 91, 91, 120], total units: 500\n",
            "##########################################################\n",
            "Epoch 4/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.241814374923706 - val_accuracy: 0.2302 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 98, 91, 91, 120], total units: 500\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.241814374923706 - val_accuracy: 0.2302 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 118, 111, 111, 144], total units: 604\n",
            "Before pruning:\n",
            "loss: 3.231048345565796 - accuracy: 0.22458000481128693 - val_loss: 3.0473365783691406 - val_accuracy: 0.261 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 118, 111, 111, 144], total units: 604\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.0472774505615234 - val_accuracy: 0.2609 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 60, 80, 78, 134], total units: 452\n",
            "##########################################################\n",
            "Epoch 5/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.0472774505615234 - val_accuracy: 0.2609 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 60, 80, 78, 134], total units: 452\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.0472774505615234 - val_accuracy: 0.2609 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 80, 100, 98, 160], total units: 558\n",
            "Before pruning:\n",
            "loss: 3.100306272506714 - accuracy: 0.24726000428199768 - val_loss: 2.9273619651794434 - val_accuracy: 0.2843 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 80, 100, 98, 160], total units: 558\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.9273147583007812 - val_accuracy: 0.2843 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 48, 76, 67, 156], total units: 447\n",
            "##########################################################\n",
            "Epoch 6/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.9273147583007812 - val_accuracy: 0.2843 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 48, 76, 67, 156], total units: 447\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.9273147583007812 - val_accuracy: 0.2843 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 68, 96, 87, 187], total units: 558\n",
            "Before pruning:\n",
            "loss: 3.0037763118743896 - accuracy: 0.26600000262260437 - val_loss: 2.8310389518737793 - val_accuracy: 0.3046 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 68, 96, 87, 187], total units: 558\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.831169605255127 - val_accuracy: 0.3046 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 38, 72, 60, 161], total units: 431\n",
            "##########################################################\n",
            "Epoch 7/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.831169605255127 - val_accuracy: 0.3046 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 38, 72, 60, 161], total units: 431\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.831169605255127 - val_accuracy: 0.3046 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 58, 92, 80, 193], total units: 543\n",
            "Before pruning:\n",
            "loss: 2.9358506202697754 - accuracy: 0.280239999294281 - val_loss: 2.748509407043457 - val_accuracy: 0.3227 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 58, 92, 80, 193], total units: 543\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.7486495971679688 - val_accuracy: 0.3233 - penalty: 2e-05\n",
            "hidden layer sizes: [99, 35, 72, 58, 170], total units: 434\n",
            "##########################################################\n",
            "Epoch 8/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.7486495971679688 - val_accuracy: 0.3233 - penalty: 2e-05\n",
            "hidden layer sizes: [99, 35, 72, 58, 170], total units: 434\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.7486495971679688 - val_accuracy: 0.3233 - penalty: 2e-05\n",
            "hidden layer sizes: [119, 55, 92, 78, 204], total units: 548\n",
            "Before pruning:\n",
            "loss: 2.873830556869507 - accuracy: 0.28804001212120056 - val_loss: 2.69982647895813 - val_accuracy: 0.3309 - penalty: 2e-05\n",
            "hidden layer sizes: [119, 55, 92, 78, 204], total units: 548\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.6998634338378906 - val_accuracy: 0.3306 - penalty: 2e-05\n",
            "hidden layer sizes: [95, 30, 62, 55, 179], total units: 421\n",
            "##########################################################\n",
            "Epoch 9/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.6998634338378906 - val_accuracy: 0.3306 - penalty: 2e-05\n",
            "hidden layer sizes: [95, 30, 62, 55, 179], total units: 421\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.6998634338378906 - val_accuracy: 0.3306 - penalty: 2e-05\n",
            "hidden layer sizes: [115, 50, 82, 75, 214], total units: 536\n",
            "Before pruning:\n",
            "loss: 2.817314624786377 - accuracy: 0.3005000054836273 - val_loss: 2.655538558959961 - val_accuracy: 0.3356 - penalty: 2e-05\n",
            "hidden layer sizes: [115, 50, 82, 75, 214], total units: 536\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.655611515045166 - val_accuracy: 0.3352 - penalty: 2e-05\n",
            "hidden layer sizes: [93, 29, 59, 52, 175], total units: 408\n",
            "##########################################################\n",
            "Epoch 10/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.655611515045166 - val_accuracy: 0.3352 - penalty: 2e-05\n",
            "hidden layer sizes: [93, 29, 59, 52, 175], total units: 408\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.655611991882324 - val_accuracy: 0.3352 - penalty: 2e-05\n",
            "hidden layer sizes: [113, 49, 79, 72, 210], total units: 523\n",
            "Before pruning:\n",
            "loss: 2.7702877521514893 - accuracy: 0.3056800067424774 - val_loss: 2.607609748840332 - val_accuracy: 0.3445 - penalty: 2e-05\n",
            "hidden layer sizes: [113, 49, 79, 72, 210], total units: 523\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.60766339302063 - val_accuracy: 0.3443 - penalty: 2e-05\n",
            "hidden layer sizes: [91, 26, 56, 53, 179], total units: 405\n",
            "##########################################################\n",
            "Epoch 11/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.60766339302063 - val_accuracy: 0.3443 - penalty: 2e-05\n",
            "hidden layer sizes: [91, 26, 56, 53, 179], total units: 405\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.60766339302063 - val_accuracy: 0.3443 - penalty: 2e-05\n",
            "hidden layer sizes: [111, 46, 76, 73, 214], total units: 520\n",
            "Before pruning:\n",
            "loss: 2.7229537963867188 - accuracy: 0.31727999448776245 - val_loss: 2.568338632583618 - val_accuracy: 0.3548 - penalty: 2e-05\n",
            "hidden layer sizes: [111, 46, 76, 73, 214], total units: 520\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.568450927734375 - val_accuracy: 0.3545 - penalty: 2e-05\n",
            "hidden layer sizes: [88, 25, 55, 52, 181], total units: 401\n",
            "##########################################################\n",
            "Epoch 12/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.568450927734375 - val_accuracy: 0.3545 - penalty: 2e-05\n",
            "hidden layer sizes: [88, 25, 55, 52, 181], total units: 401\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.568450927734375 - val_accuracy: 0.3545 - penalty: 2e-05\n",
            "hidden layer sizes: [108, 45, 75, 72, 217], total units: 517\n",
            "Before pruning:\n",
            "loss: 2.687681198120117 - accuracy: 0.32589998841285706 - val_loss: 2.5235960483551025 - val_accuracy: 0.3684 - penalty: 2e-05\n",
            "hidden layer sizes: [108, 45, 75, 72, 217], total units: 517\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.5236635208129883 - val_accuracy: 0.3677 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 25, 52, 56, 186], total units: 404\n",
            "##########################################################\n",
            "Epoch 13/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.5236635208129883 - val_accuracy: 0.3677 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 25, 52, 56, 186], total units: 404\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.5236637592315674 - val_accuracy: 0.3677 - penalty: 2e-05\n",
            "hidden layer sizes: [105, 45, 72, 76, 223], total units: 521\n",
            "Before pruning:\n",
            "loss: 2.654783010482788 - accuracy: 0.33118000626564026 - val_loss: 2.5015439987182617 - val_accuracy: 0.3698 - penalty: 2e-05\n",
            "hidden layer sizes: [105, 45, 72, 76, 223], total units: 521\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.5015714168548584 - val_accuracy: 0.3696 - penalty: 2e-05\n",
            "hidden layer sizes: [82, 24, 49, 54, 186], total units: 395\n",
            "##########################################################\n",
            "Epoch 14/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.5015714168548584 - val_accuracy: 0.3696 - penalty: 2e-05\n",
            "hidden layer sizes: [82, 24, 49, 54, 186], total units: 395\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.5015714168548584 - val_accuracy: 0.3696 - penalty: 2e-05\n",
            "hidden layer sizes: [102, 44, 69, 74, 223], total units: 512\n",
            "Before pruning:\n",
            "loss: 2.6212122440338135 - accuracy: 0.33643999695777893 - val_loss: 2.471114158630371 - val_accuracy: 0.3666 - penalty: 2e-05\n",
            "hidden layer sizes: [102, 44, 69, 74, 223], total units: 512\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.4711081981658936 - val_accuracy: 0.3659 - penalty: 2e-05\n",
            "hidden layer sizes: [79, 22, 44, 59, 187], total units: 391\n",
            "##########################################################\n",
            "Epoch 15/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4711081981658936 - val_accuracy: 0.3659 - penalty: 2e-05\n",
            "hidden layer sizes: [79, 22, 44, 59, 187], total units: 391\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4711081981658936 - val_accuracy: 0.3659 - penalty: 2e-05\n",
            "hidden layer sizes: [99, 42, 64, 79, 224], total units: 508\n",
            "Before pruning:\n",
            "loss: 2.5820822715759277 - accuracy: 0.3453199863433838 - val_loss: 2.451876640319824 - val_accuracy: 0.3776 - penalty: 2e-05\n",
            "hidden layer sizes: [99, 42, 64, 79, 224], total units: 508\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.45180344581604 - val_accuracy: 0.3774 - penalty: 2e-05\n",
            "hidden layer sizes: [76, 21, 39, 62, 188], total units: 386\n",
            "##########################################################\n",
            "Epoch 16/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.45180344581604 - val_accuracy: 0.3774 - penalty: 2e-05\n",
            "hidden layer sizes: [76, 21, 39, 62, 188], total units: 386\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4518039226531982 - val_accuracy: 0.3774 - penalty: 2e-05\n",
            "hidden layer sizes: [96, 41, 59, 82, 225], total units: 503\n",
            "Before pruning:\n",
            "loss: 2.5633888244628906 - accuracy: 0.3481200039386749 - val_loss: 2.418726682662964 - val_accuracy: 0.3866 - penalty: 2e-05\n",
            "hidden layer sizes: [96, 41, 59, 82, 225], total units: 503\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.418813943862915 - val_accuracy: 0.3868 - penalty: 2e-05\n",
            "hidden layer sizes: [73, 20, 37, 66, 189], total units: 385\n",
            "##########################################################\n",
            "Epoch 17/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.418813943862915 - val_accuracy: 0.3868 - penalty: 2e-05\n",
            "hidden layer sizes: [73, 20, 37, 66, 189], total units: 385\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.418813943862915 - val_accuracy: 0.3868 - penalty: 2e-05\n",
            "hidden layer sizes: [93, 40, 57, 86, 226], total units: 502\n",
            "Before pruning:\n",
            "loss: 2.536714792251587 - accuracy: 0.35109999775886536 - val_loss: 2.380084991455078 - val_accuracy: 0.395 - penalty: 2e-05\n",
            "hidden layer sizes: [93, 40, 57, 86, 226], total units: 502\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3800809383392334 - val_accuracy: 0.3948 - penalty: 2e-05\n",
            "hidden layer sizes: [70, 20, 37, 60, 190], total units: 377\n",
            "##########################################################\n",
            "Epoch 18/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3800809383392334 - val_accuracy: 0.3948 - penalty: 2e-05\n",
            "hidden layer sizes: [70, 20, 37, 60, 190], total units: 377\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3800809383392334 - val_accuracy: 0.3948 - penalty: 2e-05\n",
            "hidden layer sizes: [90, 40, 57, 80, 228], total units: 495\n",
            "Before pruning:\n",
            "loss: 2.5163424015045166 - accuracy: 0.3587999939918518 - val_loss: 2.3841278553009033 - val_accuracy: 0.3908 - penalty: 2e-05\n",
            "hidden layer sizes: [90, 40, 57, 80, 228], total units: 495\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3841354846954346 - val_accuracy: 0.3911 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 20, 33, 61, 194], total units: 376\n",
            "##########################################################\n",
            "Epoch 19/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3841354846954346 - val_accuracy: 0.3911 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 20, 33, 61, 194], total units: 376\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3841354846954346 - val_accuracy: 0.3911 - penalty: 2e-05\n",
            "hidden layer sizes: [88, 40, 53, 81, 232], total units: 494\n",
            "Before pruning:\n",
            "loss: 2.4894819259643555 - accuracy: 0.36188000440597534 - val_loss: 2.359753370285034 - val_accuracy: 0.3929 - penalty: 2e-05\n",
            "hidden layer sizes: [88, 40, 53, 81, 232], total units: 494\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.359687566757202 - val_accuracy: 0.3929 - penalty: 2e-05\n",
            "hidden layer sizes: [66, 20, 32, 63, 194], total units: 375\n",
            "##########################################################\n",
            "Epoch 20/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.359687566757202 - val_accuracy: 0.3929 - penalty: 2e-05\n",
            "hidden layer sizes: [66, 20, 32, 63, 194], total units: 375\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.359687328338623 - val_accuracy: 0.3929 - penalty: 2e-05\n",
            "hidden layer sizes: [86, 40, 52, 83, 232], total units: 493\n",
            "Before pruning:\n",
            "loss: 2.478177547454834 - accuracy: 0.36344000697135925 - val_loss: 2.3493340015411377 - val_accuracy: 0.3983 - penalty: 2e-05\n",
            "hidden layer sizes: [86, 40, 52, 83, 232], total units: 493\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3494250774383545 - val_accuracy: 0.3981 - penalty: 2e-05\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 21/40\n",
            "loss: 2.4997246265411377 - accuracy: 0.36320000886917114 - val_loss: 2.2836287021636963 - val_accuracy: 0.4075 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 22/40\n",
            "loss: 2.212423086166382 - accuracy: 0.42250001430511475 - val_loss: 2.251293659210205 - val_accuracy: 0.4182 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 23/40\n",
            "loss: 2.101757287979126 - accuracy: 0.4499000012874603 - val_loss: 2.2030065059661865 - val_accuracy: 0.4336 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 24/40\n",
            "loss: 2.0088319778442383 - accuracy: 0.4698199927806854 - val_loss: 2.189648151397705 - val_accuracy: 0.4373 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 25/40\n",
            "loss: 1.9249986410140991 - accuracy: 0.4891600012779236 - val_loss: 2.2084591388702393 - val_accuracy: 0.4328 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 26/40\n",
            "loss: 1.8579679727554321 - accuracy: 0.5050399899482727 - val_loss: 2.1898374557495117 - val_accuracy: 0.442 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 27/40\n",
            "loss: 1.7782809734344482 - accuracy: 0.5248000025749207 - val_loss: 2.1925439834594727 - val_accuracy: 0.4414 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 28/40\n",
            "loss: 1.7154521942138672 - accuracy: 0.5369200110435486 - val_loss: 2.1960043907165527 - val_accuracy: 0.4485 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 29/40\n",
            "loss: 1.6548138856887817 - accuracy: 0.5501000285148621 - val_loss: 2.191196918487549 - val_accuracy: 0.447 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 30/40\n",
            "loss: 1.6023191213607788 - accuracy: 0.561460018157959 - val_loss: 2.2147793769836426 - val_accuracy: 0.448 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 31/40\n",
            "loss: 1.552045464515686 - accuracy: 0.5742800235748291 - val_loss: 2.23360013961792 - val_accuracy: 0.4526 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 32/40\n",
            "loss: 1.5061599016189575 - accuracy: 0.5844799876213074 - val_loss: 2.23874568939209 - val_accuracy: 0.45 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 33/40\n",
            "loss: 1.45633065700531 - accuracy: 0.5946400165557861 - val_loss: 2.2481303215026855 - val_accuracy: 0.4481 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 34/40\n",
            "loss: 1.4107677936553955 - accuracy: 0.6059200167655945 - val_loss: 2.2804975509643555 - val_accuracy: 0.4479 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 35/40\n",
            "loss: 1.368695616722107 - accuracy: 0.6142399907112122 - val_loss: 2.275789260864258 - val_accuracy: 0.4519 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 36/40\n",
            "loss: 1.3367382287979126 - accuracy: 0.6235399842262268 - val_loss: 2.3016200065612793 - val_accuracy: 0.45 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 37/40\n",
            "loss: 1.29282808303833 - accuracy: 0.6343399882316589 - val_loss: 2.2924118041992188 - val_accuracy: 0.4496 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 38/40\n",
            "loss: 1.2675926685333252 - accuracy: 0.6386200189590454 - val_loss: 2.350851058959961 - val_accuracy: 0.4456 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 39/40\n",
            "loss: 1.2334692478179932 - accuracy: 0.6450600028038025 - val_loss: 2.3547112941741943 - val_accuracy: 0.4492 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 40/40\n",
            "loss: 1.2020186185836792 - accuracy: 0.6534799933433533 - val_loss: 2.3694541454315186 - val_accuracy: 0.4496 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "CPU times: user 3min 36s, sys: 8.33 s, total: 3min 45s\n",
            "Wall time: 3min 16s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "model = get_convolutional_model(cifar100.X_train_norm, regularization_penalty=0.00002, regularization_method='weighted_l1', layer_sizes=[100, 100, 100, 100, 100], output_neurons=100)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "history = model.fit(cifar100.X_train_norm, cifar100.y_train, optimizer, epochs=40, self_scaling_epochs=20, batch_size=batch_size, \n",
        "                    min_new_neurons=20, validation_data=(cifar100.X_test_norm, cifar100.y_test), pruning_only_epochs=0, \n",
        "                    growth_percentage=0.2, verbose=True)"
      ],
      "metadata": {
        "id": "TZjoY4LyiG7Z",
        "outputId": "5bef9841-66e8-40d6-90a6-161e97733677",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.954936504364014 - val_accuracy: 0.011 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.954936504364014 - val_accuracy: 0.011 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "Before pruning:\n",
            "loss: 3.9630274772644043 - accuracy: 0.11682000011205673 - val_loss: 3.6065542697906494 - val_accuracy: 0.166 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.6065804958343506 - val_accuracy: 0.166 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 107], total units: 507\n",
            "##########################################################\n",
            "Epoch 2/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.6065804958343506 - val_accuracy: 0.166 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 107], total units: 507\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.606580972671509 - val_accuracy: 0.166 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 128], total units: 608\n",
            "Before pruning:\n",
            "loss: 3.6110033988952637 - accuracy: 0.1626800000667572 - val_loss: 3.4388890266418457 - val_accuracy: 0.188 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 128], total units: 608\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.4389023780822754 - val_accuracy: 0.1878 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 99, 100, 100, 124], total units: 523\n",
            "##########################################################\n",
            "Epoch 3/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.4389023780822754 - val_accuracy: 0.1878 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 99, 100, 100, 124], total units: 523\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.4389023780822754 - val_accuracy: 0.1878 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 119, 120, 120, 148], total units: 627\n",
            "Before pruning:\n",
            "loss: 3.403515100479126 - accuracy: 0.19582000374794006 - val_loss: 3.1985278129577637 - val_accuracy: 0.2324 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 119, 120, 120, 148], total units: 627\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.1977641582489014 - val_accuracy: 0.2326 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 57, 93, 83, 148], total units: 481\n",
            "##########################################################\n",
            "Epoch 4/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.1977641582489014 - val_accuracy: 0.2326 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 57, 93, 83, 148], total units: 481\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.1977641582489014 - val_accuracy: 0.2326 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 77, 113, 103, 177], total units: 590\n",
            "Before pruning:\n",
            "loss: 3.1989669799804688 - accuracy: 0.22991999983787537 - val_loss: 3.001176357269287 - val_accuracy: 0.2702 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 77, 113, 103, 177], total units: 590\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.0010879039764404 - val_accuracy: 0.2708 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 43, 84, 75, 171], total units: 473\n",
            "##########################################################\n",
            "Epoch 5/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.0010879039764404 - val_accuracy: 0.2708 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 43, 84, 75, 171], total units: 473\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.0010876655578613 - val_accuracy: 0.2708 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 63, 104, 95, 205], total units: 587\n",
            "Before pruning:\n",
            "loss: 3.0719592571258545 - accuracy: 0.25064000487327576 - val_loss: 2.8911893367767334 - val_accuracy: 0.2947 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 63, 104, 95, 205], total units: 587\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.891228437423706 - val_accuracy: 0.2949 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 32, 70, 64, 194], total units: 460\n",
            "##########################################################\n",
            "Epoch 6/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.891228437423706 - val_accuracy: 0.2949 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 32, 70, 64, 194], total units: 460\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.891228437423706 - val_accuracy: 0.2949 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 52, 90, 84, 232], total units: 578\n",
            "Before pruning:\n",
            "loss: 2.9779112339019775 - accuracy: 0.268779993057251 - val_loss: 2.810983419418335 - val_accuracy: 0.3049 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 52, 90, 84, 232], total units: 578\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.8109703063964844 - val_accuracy: 0.305 - penalty: 2e-05\n",
            "hidden layer sizes: [98, 30, 66, 61, 209], total units: 464\n",
            "##########################################################\n",
            "Epoch 7/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8109703063964844 - val_accuracy: 0.305 - penalty: 2e-05\n",
            "hidden layer sizes: [98, 30, 66, 61, 209], total units: 464\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8109703063964844 - val_accuracy: 0.305 - penalty: 2e-05\n",
            "hidden layer sizes: [118, 50, 86, 81, 250], total units: 585\n",
            "Before pruning:\n",
            "loss: 2.909067153930664 - accuracy: 0.28181999921798706 - val_loss: 2.7352731227874756 - val_accuracy: 0.3175 - penalty: 2e-05\n",
            "hidden layer sizes: [118, 50, 86, 81, 250], total units: 585\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.7352294921875 - val_accuracy: 0.3176 - penalty: 2e-05\n",
            "hidden layer sizes: [93, 29, 64, 64, 214], total units: 464\n",
            "##########################################################\n",
            "Epoch 8/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.7352294921875 - val_accuracy: 0.3176 - penalty: 2e-05\n",
            "hidden layer sizes: [93, 29, 64, 64, 214], total units: 464\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.735229730606079 - val_accuracy: 0.3176 - penalty: 2e-05\n",
            "hidden layer sizes: [113, 49, 84, 84, 256], total units: 586\n",
            "Before pruning:\n",
            "loss: 2.8367090225219727 - accuracy: 0.2979399859905243 - val_loss: 2.6538636684417725 - val_accuracy: 0.3382 - penalty: 2e-05\n",
            "hidden layer sizes: [113, 49, 84, 84, 256], total units: 586\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.653963565826416 - val_accuracy: 0.338 - penalty: 2e-05\n",
            "hidden layer sizes: [89, 27, 59, 63, 214], total units: 452\n",
            "##########################################################\n",
            "Epoch 9/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.653963565826416 - val_accuracy: 0.338 - penalty: 2e-05\n",
            "hidden layer sizes: [89, 27, 59, 63, 214], total units: 452\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.653963565826416 - val_accuracy: 0.338 - penalty: 2e-05\n",
            "hidden layer sizes: [109, 47, 79, 83, 256], total units: 574\n",
            "Before pruning:\n",
            "loss: 2.7689056396484375 - accuracy: 0.3087800145149231 - val_loss: 2.599806308746338 - val_accuracy: 0.3454 - penalty: 2e-05\n",
            "hidden layer sizes: [109, 47, 79, 83, 256], total units: 574\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.5998740196228027 - val_accuracy: 0.3454 - penalty: 2e-05\n",
            "hidden layer sizes: [89, 27, 54, 65, 218], total units: 453\n",
            "##########################################################\n",
            "Epoch 10/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.5998740196228027 - val_accuracy: 0.3454 - penalty: 2e-05\n",
            "hidden layer sizes: [89, 27, 54, 65, 218], total units: 453\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.5998740196228027 - val_accuracy: 0.3454 - penalty: 2e-05\n",
            "hidden layer sizes: [109, 47, 74, 85, 261], total units: 576\n",
            "Before pruning:\n",
            "loss: 2.7054312229156494 - accuracy: 0.32058000564575195 - val_loss: 2.568729877471924 - val_accuracy: 0.3512 - penalty: 2e-05\n",
            "hidden layer sizes: [109, 47, 74, 85, 261], total units: 576\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.568925619125366 - val_accuracy: 0.3512 - penalty: 2e-05\n",
            "hidden layer sizes: [82, 27, 50, 66, 227], total units: 452\n",
            "##########################################################\n",
            "Epoch 11/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.568925619125366 - val_accuracy: 0.3512 - penalty: 2e-05\n",
            "hidden layer sizes: [82, 27, 50, 66, 227], total units: 452\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.568925619125366 - val_accuracy: 0.3512 - penalty: 2e-05\n",
            "hidden layer sizes: [102, 47, 70, 86, 272], total units: 577\n",
            "Before pruning:\n",
            "loss: 2.670111656188965 - accuracy: 0.32923999428749084 - val_loss: 2.506255626678467 - val_accuracy: 0.3626 - penalty: 2e-05\n",
            "hidden layer sizes: [102, 47, 70, 86, 272], total units: 577\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.5063090324401855 - val_accuracy: 0.3627 - penalty: 2e-05\n",
            "hidden layer sizes: [78, 27, 45, 63, 227], total units: 440\n",
            "##########################################################\n",
            "Epoch 12/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.5063090324401855 - val_accuracy: 0.3627 - penalty: 2e-05\n",
            "hidden layer sizes: [78, 27, 45, 63, 227], total units: 440\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.5063092708587646 - val_accuracy: 0.3627 - penalty: 2e-05\n",
            "hidden layer sizes: [98, 47, 65, 83, 272], total units: 565\n",
            "Before pruning:\n",
            "loss: 2.629441261291504 - accuracy: 0.3353399932384491 - val_loss: 2.46703839302063 - val_accuracy: 0.3713 - penalty: 2e-05\n",
            "hidden layer sizes: [98, 47, 65, 83, 272], total units: 565\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.4670207500457764 - val_accuracy: 0.3719 - penalty: 2e-05\n",
            "hidden layer sizes: [75, 26, 43, 60, 228], total units: 432\n",
            "##########################################################\n",
            "Epoch 13/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4670207500457764 - val_accuracy: 0.3719 - penalty: 2e-05\n",
            "hidden layer sizes: [75, 26, 43, 60, 228], total units: 432\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4670207500457764 - val_accuracy: 0.3719 - penalty: 2e-05\n",
            "hidden layer sizes: [95, 46, 63, 80, 273], total units: 557\n",
            "Before pruning:\n",
            "loss: 2.598825454711914 - accuracy: 0.3413200080394745 - val_loss: 2.436244487762451 - val_accuracy: 0.3804 - penalty: 2e-05\n",
            "hidden layer sizes: [95, 46, 63, 80, 273], total units: 557\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.4362549781799316 - val_accuracy: 0.3801 - penalty: 2e-05\n",
            "hidden layer sizes: [72, 26, 37, 63, 229], total units: 427\n",
            "##########################################################\n",
            "Epoch 14/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4362549781799316 - val_accuracy: 0.3801 - penalty: 2e-05\n",
            "hidden layer sizes: [72, 26, 37, 63, 229], total units: 427\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4362549781799316 - val_accuracy: 0.3801 - penalty: 2e-05\n",
            "hidden layer sizes: [92, 46, 57, 83, 274], total units: 552\n",
            "Before pruning:\n",
            "loss: 2.5661332607269287 - accuracy: 0.3470599949359894 - val_loss: 2.4128286838531494 - val_accuracy: 0.3834 - penalty: 2e-05\n",
            "hidden layer sizes: [92, 46, 57, 83, 274], total units: 552\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.4127368927001953 - val_accuracy: 0.3836 - penalty: 2e-05\n",
            "hidden layer sizes: [69, 24, 34, 64, 226], total units: 417\n",
            "##########################################################\n",
            "Epoch 15/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4127368927001953 - val_accuracy: 0.3836 - penalty: 2e-05\n",
            "hidden layer sizes: [69, 24, 34, 64, 226], total units: 417\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.412736654281616 - val_accuracy: 0.3836 - penalty: 2e-05\n",
            "hidden layer sizes: [89, 44, 54, 84, 271], total units: 542\n",
            "Before pruning:\n",
            "loss: 2.5488932132720947 - accuracy: 0.35076001286506653 - val_loss: 2.3928070068359375 - val_accuracy: 0.3845 - penalty: 2e-05\n",
            "hidden layer sizes: [89, 44, 54, 84, 271], total units: 542\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3928215503692627 - val_accuracy: 0.385 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 22, 32, 67, 231], total units: 417\n",
            "##########################################################\n",
            "Epoch 16/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3928215503692627 - val_accuracy: 0.385 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 22, 32, 67, 231], total units: 417\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3928215503692627 - val_accuracy: 0.385 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 42, 52, 87, 277], total units: 543\n",
            "Before pruning:\n",
            "loss: 2.522462844848633 - accuracy: 0.35580000281333923 - val_loss: 2.367138385772705 - val_accuracy: 0.3955 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 42, 52, 87, 277], total units: 543\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.367140769958496 - val_accuracy: 0.3949 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 22, 31, 69, 228], total units: 414\n",
            "##########################################################\n",
            "Epoch 17/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.367140769958496 - val_accuracy: 0.3949 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 22, 31, 69, 228], total units: 414\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.367140769958496 - val_accuracy: 0.3949 - penalty: 2e-05\n",
            "hidden layer sizes: [84, 42, 51, 89, 273], total units: 539\n",
            "Before pruning:\n",
            "loss: 2.5087778568267822 - accuracy: 0.35760000348091125 - val_loss: 2.35250186920166 - val_accuracy: 0.4018 - penalty: 2e-05\n",
            "hidden layer sizes: [84, 42, 51, 89, 273], total units: 539\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3525657653808594 - val_accuracy: 0.402 - penalty: 2e-05\n",
            "hidden layer sizes: [63, 22, 30, 67, 229], total units: 411\n",
            "##########################################################\n",
            "Epoch 18/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3525657653808594 - val_accuracy: 0.402 - penalty: 2e-05\n",
            "hidden layer sizes: [63, 22, 30, 67, 229], total units: 411\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3525655269622803 - val_accuracy: 0.402 - penalty: 2e-05\n",
            "hidden layer sizes: [83, 42, 50, 87, 274], total units: 536\n",
            "Before pruning:\n",
            "loss: 2.49056339263916 - accuracy: 0.36395999789237976 - val_loss: 2.335096597671509 - val_accuracy: 0.4071 - penalty: 2e-05\n",
            "hidden layer sizes: [83, 42, 50, 87, 274], total units: 536\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3351385593414307 - val_accuracy: 0.4074 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 22, 28, 68, 229], total units: 407\n",
            "##########################################################\n",
            "Epoch 19/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3351385593414307 - val_accuracy: 0.4074 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 22, 28, 68, 229], total units: 407\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3351387977600098 - val_accuracy: 0.4074 - penalty: 2e-05\n",
            "hidden layer sizes: [80, 42, 48, 88, 274], total units: 532\n",
            "Before pruning:\n",
            "loss: 2.474853754043579 - accuracy: 0.36434000730514526 - val_loss: 2.322746992111206 - val_accuracy: 0.4009 - penalty: 2e-05\n",
            "hidden layer sizes: [80, 42, 48, 88, 274], total units: 532\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.322770595550537 - val_accuracy: 0.4007 - penalty: 2e-05\n",
            "hidden layer sizes: [59, 22, 28, 66, 229], total units: 404\n",
            "##########################################################\n",
            "Epoch 20/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.322770595550537 - val_accuracy: 0.4007 - penalty: 2e-05\n",
            "hidden layer sizes: [59, 22, 28, 66, 229], total units: 404\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.322770595550537 - val_accuracy: 0.4007 - penalty: 2e-05\n",
            "hidden layer sizes: [79, 42, 48, 86, 274], total units: 529\n",
            "Before pruning:\n",
            "loss: 2.456420421600342 - accuracy: 0.3689599931240082 - val_loss: 2.323631525039673 - val_accuracy: 0.4012 - penalty: 2e-05\n",
            "hidden layer sizes: [79, 42, 48, 86, 274], total units: 529\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.323789119720459 - val_accuracy: 0.4013 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 21/40\n",
            "loss: 2.4838144779205322 - accuracy: 0.3684999942779541 - val_loss: 2.2542717456817627 - val_accuracy: 0.4208 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 22/40\n",
            "loss: 2.1958389282226562 - accuracy: 0.42838001251220703 - val_loss: 2.1808149814605713 - val_accuracy: 0.4331 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 23/40\n",
            "loss: 2.0788934230804443 - accuracy: 0.45767998695373535 - val_loss: 2.1656699180603027 - val_accuracy: 0.4434 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 24/40\n",
            "loss: 1.9762729406356812 - accuracy: 0.47863999009132385 - val_loss: 2.1576790809631348 - val_accuracy: 0.4434 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 25/40\n",
            "loss: 1.8821520805358887 - accuracy: 0.498879998922348 - val_loss: 2.1508190631866455 - val_accuracy: 0.4489 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 26/40\n",
            "loss: 1.784244418144226 - accuracy: 0.5199800133705139 - val_loss: 2.1646292209625244 - val_accuracy: 0.4508 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 27/40\n",
            "loss: 1.692240834236145 - accuracy: 0.5414999723434448 - val_loss: 2.170741558074951 - val_accuracy: 0.4492 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 28/40\n",
            "loss: 1.6143081188201904 - accuracy: 0.5579599738121033 - val_loss: 2.188553810119629 - val_accuracy: 0.4504 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 29/40\n",
            "loss: 1.5340301990509033 - accuracy: 0.5781199932098389 - val_loss: 2.195892095565796 - val_accuracy: 0.4511 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 30/40\n",
            "loss: 1.4521870613098145 - accuracy: 0.593779981136322 - val_loss: 2.223339319229126 - val_accuracy: 0.4492 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 31/40\n",
            "loss: 1.3904294967651367 - accuracy: 0.6098999977111816 - val_loss: 2.2660305500030518 - val_accuracy: 0.453 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 32/40\n",
            "loss: 1.3354294300079346 - accuracy: 0.622219979763031 - val_loss: 2.268756151199341 - val_accuracy: 0.4459 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 33/40\n",
            "loss: 1.2802320718765259 - accuracy: 0.6340600252151489 - val_loss: 2.2888760566711426 - val_accuracy: 0.4497 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 34/40\n",
            "loss: 1.226779580116272 - accuracy: 0.6456999778747559 - val_loss: 2.3313632011413574 - val_accuracy: 0.4481 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 35/40\n",
            "loss: 1.1743972301483154 - accuracy: 0.6586400270462036 - val_loss: 2.354907989501953 - val_accuracy: 0.4513 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 36/40\n",
            "loss: 1.1288738250732422 - accuracy: 0.6688600182533264 - val_loss: 2.370312213897705 - val_accuracy: 0.4536 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 37/40\n",
            "loss: 1.0819816589355469 - accuracy: 0.6825399994850159 - val_loss: 2.437800884246826 - val_accuracy: 0.4469 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 38/40\n",
            "loss: 1.0508049726486206 - accuracy: 0.6901599764823914 - val_loss: 2.437711238861084 - val_accuracy: 0.4499 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 39/40\n",
            "loss: 1.0040401220321655 - accuracy: 0.7031199932098389 - val_loss: 2.4660301208496094 - val_accuracy: 0.4479 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 40/40\n",
            "loss: 0.9733282327651978 - accuracy: 0.7082399725914001 - val_loss: 2.5028750896453857 - val_accuracy: 0.4489 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "CPU times: user 5min 18s, sys: 14.9 s, total: 5min 33s\n",
            "Wall time: 4min 37s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "histories = hyperparameter_search(train_fn, x=cifar100.X_train_norm, y=cifar100.y_train, validation_data=(cifar100.X_test_norm, cifar100.y_test), \n",
        "                                  learning_rate=[0.0002], regularization_penalty=[0.00002], regularization_method=['weighted_l1'], \n",
        "                                  self_scaling_epochs=[20], layer_sizes=[[65, 23, 29, 72, 201]], output_neurons=[100], min_new_neurons=[0, 1, 2, 4, 8, 16, 32], growth_percentage=[0.])"
      ],
      "metadata": {
        "id": "ShwjKpNOnXdM",
        "outputId": "5b3ac8e6-dca6-4673-d70c-37b0a6c04039",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0002, 2e-05, 'weighted_l1', 20, [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.4445, best_hidden_layer_sizes sizes: [59, 23, 29, 68, 201]\n",
            "Run with parameters (0.0002, 2e-05, 'weighted_l1', 20, [65, 23, 29, 72, 201], 100, 1, 0.0) completed, best_val_accuracy: 0.4427, best_hidden_layer_sizes sizes: [60, 23, 29, 70, 201]\n",
            "Run with parameters (0.0002, 2e-05, 'weighted_l1', 20, [65, 23, 29, 72, 201], 100, 2, 0.0) completed, best_val_accuracy: 0.4516, best_hidden_layer_sizes sizes: [62, 23, 29, 65, 203]\n",
            "Run with parameters (0.0002, 2e-05, 'weighted_l1', 20, [65, 23, 29, 72, 201], 100, 4, 0.0) completed, best_val_accuracy: 0.4449, best_hidden_layer_sizes sizes: [61, 23, 29, 72, 206]\n",
            "Run with parameters (0.0002, 2e-05, 'weighted_l1', 20, [65, 23, 29, 72, 201], 100, 8, 0.0) completed, best_val_accuracy: 0.4507, best_hidden_layer_sizes sizes: [59, 23, 29, 69, 210]\n",
            "Run with parameters (0.0002, 2e-05, 'weighted_l1', 20, [65, 23, 29, 72, 201], 100, 16, 0.0) completed, best_val_accuracy: 0.4421, best_hidden_layer_sizes sizes: [61, 23, 29, 70, 205]\n",
            "Run with parameters (0.0002, 2e-05, 'weighted_l1', 20, [65, 23, 29, 72, 201], 100, 32, 0.0) completed, best_val_accuracy: 0.4589, best_hidden_layer_sizes sizes: [58, 23, 29, 71, 207]\n",
            "Best overall combination: (0.0002, 2e-05, 'weighted_l1', 20, [65, 23, 29, 72, 201], 100, 32, 0.0), val_accuracy: 0.4589\n",
            "CPU times: user 21min 40s, sys: 50.7 s, total: 22min 30s\n",
            "Wall time: 18min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "histories = hyperparameter_search(train_fn, x=cifar100.X_train_norm, y=cifar100.y_train, validation_data=(cifar100.X_test_norm, cifar100.y_test), \n",
        "                                  learning_rate=[0.0002], regularization_penalty=[0.00002], regularization_method=[None, 'weighted_l1'], \n",
        "                                  self_scaling_epochs=[0], layer_sizes=[[65, 23, 29, 72, 201]], output_neurons=[100], min_new_neurons=[0], growth_percentage=[0.])"
      ],
      "metadata": {
        "id": "YaYpOv8c4eRx",
        "outputId": "55f6edcf-238e-4001-ee73-38c94817660f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0002, 2e-05, None, 0, [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.3236, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Run with parameters (0.0002, 2e-05, 'weighted_l1', 0, [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.3375, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Best overall combination: (0.0002, 2e-05, 'weighted_l1', 0, [65, 23, 29, 72, 201], 100, 0, 0.0), val_accuracy: 0.3375\n",
            "CPU times: user 4min 49s, sys: 12.2 s, total: 5min 1s\n",
            "Wall time: 3min 51s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "histories = hyperparameter_search(train_fn, x=cifar100.X_train_norm, y=cifar100.y_train, validation_data=(cifar100.X_test_norm, cifar100.y_test), \n",
        "                                  learning_rate=[0.0002], regularization_penalty=[0.00002], regularization_method=['weighted_l1'], \n",
        "                                  self_scaling_epochs=[20], layer_sizes=[[65, 23, 29, 72, 201]], output_neurons=[100], min_new_neurons=[0], growth_percentage=[0.])"
      ],
      "metadata": {
        "id": "l96IUzPz69YX",
        "outputId": "33ebcf9e-6ac6-4fc4-dc4f-5536467d4a0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0002, 2e-05, 'weighted_l1', 20, [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.4537, best_hidden_layer_sizes sizes: [60, 23, 29, 65, 201]\n",
            "Best overall combination: (0.0002, 2e-05, 'weighted_l1', 20, [65, 23, 29, 72, 201], 100, 0, 0.0), val_accuracy: 0.4537\n",
            "CPU times: user 3min 1s, sys: 7.44 s, total: 3min 9s\n",
            "Wall time: 2min 29s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "histories = hyperparameter_search(train_fn, x=cifar100.X_train_norm, y=cifar100.y_train, validation_data=(cifar100.X_test_norm, cifar100.y_test), \n",
        "                                  learning_rate=[0.0002], regularization_penalty=[0.00002], regularization_method=['weighted_l1'], \n",
        "                                  self_scaling_epochs=[0, 20], layer_sizes=[[65, 23, 29, 72, 201]], output_neurons=[100], min_new_neurons=[0], growth_percentage=[0.])"
      ],
      "metadata": {
        "id": "D8vf4fag9jkV",
        "outputId": "371cef82-2a07-402e-e354-10fcacecca31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0002, 2e-05, 'weighted_l1', 0, [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.3259, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Run with parameters (0.0002, 2e-05, 'weighted_l1', 20, [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.4573, best_hidden_layer_sizes sizes: [61, 23, 29, 62, 200]\n",
            "Best overall combination: (0.0002, 2e-05, 'weighted_l1', 20, [65, 23, 29, 72, 201], 100, 0, 0.0), val_accuracy: 0.4573\n",
            "CPU times: user 5min 35s, sys: 14 s, total: 5min 49s\n",
            "Wall time: 4min 33s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([EpochType.STATIC_WITH_REGULARIZATION] * 40)\n",
        "histories = hyperparameter_search(train_fn, x=cifar100.X_train_norm, y=cifar100.y_train, validation_data=(cifar100.X_test_norm, cifar100.y_test), \n",
        "                                  learning_rate=[0.0002], schedule=[schedule], regularization_penalty=[0.00002], regularization_method=[None, 'weighted_l1'], \n",
        "                                  layer_sizes=[[65, 23, 29, 72, 201]], output_neurons=[100], min_new_neurons=[0], growth_percentage=[0.])"
      ],
      "metadata": {
        "id": "6_BpUNyhsbHc",
        "outputId": "e4a2f7a0-2238-4c89-e80b-c9db41a15f75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 2e-05, None, [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.3213, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 2e-05, 'weighted_l1', [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.4173, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Best overall combination: (0.0002, 1111111111111111111111111111111111111111, 2e-05, 'weighted_l1', [65, 23, 29, 72, 201], 100, 0, 0.0), val_accuracy: 0.4173\n",
            "CPU times: user 5min 3s, sys: 13.3 s, total: 5min 16s\n",
            "Wall time: 4min 2s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([EpochType.STATIC_WITH_REGULARIZATION] * 20 + [EpochType.STATIC_NO_REGULARIZATION] * 20)\n",
        "histories = hyperparameter_search(train_fn, x=cifar100.X_train_norm, y=cifar100.y_train, validation_data=(cifar100.X_test_norm, cifar100.y_test), \n",
        "                                  learning_rate=[0.0002], schedule=[schedule], regularization_penalty=[0.00002], regularization_method=[None, 'weighted_l1'], \n",
        "                                  layer_sizes=[[65, 23, 29, 72, 201]], output_neurons=[100], min_new_neurons=[0], growth_percentage=[0.])"
      ],
      "metadata": {
        "id": "itosCeQJ1I1H",
        "outputId": "6a6a71e3-7d56-4a21-9aeb-233329844b76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0002, 1111111111111111111122222222222222222222, 2e-05, None, [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.3227, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Run with parameters (0.0002, 1111111111111111111122222222222222222222, 2e-05, 'weighted_l1', [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.4239, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Best overall combination: (0.0002, 1111111111111111111122222222222222222222, 2e-05, 'weighted_l1', [65, 23, 29, 72, 201], 100, 0, 0.0), val_accuracy: 0.4239\n",
            "CPU times: user 4min 56s, sys: 12.7 s, total: 5min 9s\n",
            "Wall time: 3min 56s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([EpochType.DYNAMIC] * 20 + [EpochType.STATIC_NO_REGULARIZATION] * 20)\n",
        "histories = hyperparameter_search(train_fn, x=cifar100.X_train_norm, y=cifar100.y_train, validation_data=(cifar100.X_test_norm, cifar100.y_test), \n",
        "                                  learning_rate=[0.0002], schedule=[schedule], regularization_penalty=[0.00002], regularization_method=[None, 'weighted_l1'], \n",
        "                                  layer_sizes=[[65, 23, 29, 72, 201]], output_neurons=[100], min_new_neurons=[0], growth_percentage=[0.])"
      ],
      "metadata": {
        "id": "aC_kttDS8SuN",
        "outputId": "63eaf670-7b0d-4748-f090-73e76907ca35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0002, 0000000000000000000022222222222222222222, 2e-05, None, [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.3333, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Run with parameters (0.0002, 0000000000000000000022222222222222222222, 2e-05, 'weighted_l1', [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.4584, best_hidden_layer_sizes sizes: [61, 23, 29, 60, 201]\n",
            "Best overall combination: (0.0002, 0000000000000000000022222222222222222222, 2e-05, 'weighted_l1', [65, 23, 29, 72, 201], 100, 0, 0.0), val_accuracy: 0.4584\n",
            "CPU times: user 5min 46s, sys: 13.7 s, total: 6min\n",
            "Wall time: 4min 43s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### L1 regularization"
      ],
      "metadata": {
        "id": "fWKv7M3RQ9q5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([EpochType.STATIC_WITH_REGULARIZATION] * 40)\n",
        "histories = hyperparameter_search(train_fn, x=cifar100.X_train_norm, y=cifar100.y_train, validation_data=(cifar100.X_test_norm, cifar100.y_test), \n",
        "                                  learning_rate=[0.0002], schedule=[schedule], regularization_penalty=[0., 0.00002, 0.0002, 0.002, 0.02], regularization_method=['l1'], \n",
        "                                  layer_sizes=[[65, 23, 29, 72, 201]], output_neurons=[100], min_new_neurons=[0], growth_percentage=[0.])"
      ],
      "metadata": {
        "id": "8DAHs2dAJQoe",
        "outputId": "8c8b874d-4f5e-4b88-f396-ec51f2cb19af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 0.0, 'l1', [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.3278, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 2e-05, 'l1', [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.3348, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 0.0002, 'l1', [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.4063, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 0.002, 'l1', [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.2332, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 0.02, 'l1', [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.0103, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Best overall combination: (0.0002, 1111111111111111111111111111111111111111, 0.0002, 'l1', [65, 23, 29, 72, 201], 100, 0, 0.0), val_accuracy: 0.4063\n",
            "CPU times: user 12min 58s, sys: 35.9 s, total: 13min 34s\n",
            "Wall time: 10min 24s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([EpochType.STATIC_WITH_REGULARIZATION] * 40)\n",
        "histories = hyperparameter_search(train_fn, x=cifar100.X_train_norm, y=cifar100.y_train, validation_data=(cifar100.X_test_norm, cifar100.y_test), \n",
        "                                  learning_rate=[0.0002], schedule=[schedule], regularization_penalty=[0.00005, 0.0001, 0.0002, 0.0004, 0.0008], regularization_method=['l1'], \n",
        "                                  layer_sizes=[[65, 23, 29, 72, 201]], output_neurons=[100], min_new_neurons=[0], growth_percentage=[0.])"
      ],
      "metadata": {
        "id": "8HBU2HJyNL46",
        "outputId": "d0a60ba4-ca1c-48fb-c7b4-1161abbe7b45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 5e-05, 'l1', [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.3447, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 0.0001, 'l1', [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.3606, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 0.0002, 'l1', [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.4194, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 0.0004, 'l1', [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.4177, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 0.0008, 'l1', [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.3714, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Best overall combination: (0.0002, 1111111111111111111111111111111111111111, 0.0002, 'l1', [65, 23, 29, 72, 201], 100, 0, 0.0), val_accuracy: 0.4194\n",
            "CPU times: user 12min 54s, sys: 36.2 s, total: 13min 30s\n",
            "Wall time: 10min 18s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([EpochType.STATIC_WITH_REGULARIZATION] * 40)\n",
        "histories = hyperparameter_search(train_fn, x=cifar100.X_train_norm, y=cifar100.y_train, validation_data=(cifar100.X_test_norm, cifar100.y_test), \n",
        "                                  learning_rate=[0.0002], schedule=[schedule], regularization_penalty=[0.0003], regularization_method=['l1'], \n",
        "                                  layer_sizes=[[65, 23, 29, 72, 201]], output_neurons=[100], min_new_neurons=[0], growth_percentage=[0.])"
      ],
      "metadata": {
        "id": "sdvVVnSIPsdA",
        "outputId": "fb596f80-2d2d-4fa1-e1bf-3b383093d0b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 0.0003, 'l1', [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.4293, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Best overall combination: (0.0002, 1111111111111111111111111111111111111111, 0.0003, 'l1', [65, 23, 29, 72, 201], 100, 0, 0.0), val_accuracy: 0.4293\n",
            "CPU times: user 2min 33s, sys: 7.19 s, total: 2min 40s\n",
            "Wall time: 2min 2s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([EpochType.STATIC_WITH_REGULARIZATION] * 40)\n",
        "histories = hyperparameter_search(train_fn, x=cifar100.X_train_norm, y=cifar100.y_train, validation_data=(cifar100.X_test_norm, cifar100.y_test), \n",
        "                                  learning_rate=[0.0002], schedule=[schedule], regularization_penalty=[0.0002, 0.0003, 0.0004], regularization_method=['l1'], \n",
        "                                  layer_sizes=[[66, 66, 66, 66, 201]], output_neurons=[100], min_new_neurons=[0], growth_percentage=[0.])"
      ],
      "metadata": {
        "id": "aqJHRNzZS0O9",
        "outputId": "c82747f0-e52b-49cc-c076-22821cbe00e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 0.0002, 'l1', [66, 66, 66, 66, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.4416, best_hidden_layer_sizes sizes: [66, 66, 66, 66, 201]\n",
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 0.0003, 'l1', [66, 66, 66, 66, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.4535, best_hidden_layer_sizes sizes: [66, 66, 66, 66, 201]\n",
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 0.0004, 'l1', [66, 66, 66, 66, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.441, best_hidden_layer_sizes sizes: [66, 66, 66, 66, 201]\n",
            "Best overall combination: (0.0002, 1111111111111111111111111111111111111111, 0.0003, 'l1', [66, 66, 66, 66, 201], 100, 0, 0.0), val_accuracy: 0.4535\n",
            "CPU times: user 8min, sys: 17.1 s, total: 8min 17s\n",
            "Wall time: 7min 14s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "model = get_convolutional_model(cifar100.X_train_norm, regularization_penalty=0.00002, regularization_method=None, layer_sizes=[65, 23, 29, 72, 201], output_neurons=100)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "history = model.fit(cifar100.X_train_norm, cifar100.y_train, optimizer, epochs=40, self_scaling_epochs=20, batch_size=batch_size, \n",
        "                    min_new_neurons=0, validation_data=(cifar100.X_test_norm, cifar100.y_test), pruning_only_epochs=0, \n",
        "                    growth_percentage=0., verbose=True)"
      ],
      "metadata": {
        "id": "lZrp9FkE7_5n",
        "outputId": "db5be5c6-9677-408f-fbd5-0e0bf177d81d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.157856464385986 - val_accuracy: 0.0083 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.157856464385986 - val_accuracy: 0.0083 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 4.065201759338379 - accuracy: 0.10670000314712524 - val_loss: 3.5247750282287598 - val_accuracy: 0.1916 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.5247750282287598 - val_accuracy: 0.1916 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 2/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.5247750282287598 - val_accuracy: 0.1916 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.5247750282287598 - val_accuracy: 0.1916 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 3.5729212760925293 - accuracy: 0.17825999855995178 - val_loss: 3.3440968990325928 - val_accuracy: 0.2164 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.3440968990325928 - val_accuracy: 0.2164 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 3/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.3440968990325928 - val_accuracy: 0.2164 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.3440968990325928 - val_accuracy: 0.2164 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 3.349431037902832 - accuracy: 0.21291999518871307 - val_loss: 3.198848247528076 - val_accuracy: 0.2406 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.198848247528076 - val_accuracy: 0.2406 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 4/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.198848247528076 - val_accuracy: 0.2406 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.198848247528076 - val_accuracy: 0.2406 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 3.187880039215088 - accuracy: 0.24267999827861786 - val_loss: 3.1080782413482666 - val_accuracy: 0.2564 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.1080782413482666 - val_accuracy: 0.2564 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 5/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.1080782413482666 - val_accuracy: 0.2564 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.1080782413482666 - val_accuracy: 0.2564 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 3.033339738845825 - accuracy: 0.2681399881839752 - val_loss: 3.058805465698242 - val_accuracy: 0.2718 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.058805465698242 - val_accuracy: 0.2718 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 6/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.058805465698242 - val_accuracy: 0.2718 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.058805465698242 - val_accuracy: 0.2718 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 2.9115965366363525 - accuracy: 0.2906799912452698 - val_loss: 2.978360414505005 - val_accuracy: 0.2797 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.978360414505005 - val_accuracy: 0.2797 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 7/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.978360414505005 - val_accuracy: 0.2797 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.978360414505005 - val_accuracy: 0.2797 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 2.796330213546753 - accuracy: 0.31130000948905945 - val_loss: 2.9387381076812744 - val_accuracy: 0.293 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.9387381076812744 - val_accuracy: 0.293 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 8/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.9387381076812744 - val_accuracy: 0.293 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.9387381076812744 - val_accuracy: 0.293 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 2.6931912899017334 - accuracy: 0.33215999603271484 - val_loss: 2.8953444957733154 - val_accuracy: 0.2977 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.8953444957733154 - val_accuracy: 0.2977 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 9/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8953444957733154 - val_accuracy: 0.2977 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8953444957733154 - val_accuracy: 0.2977 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 2.578977346420288 - accuracy: 0.35468000173568726 - val_loss: 2.886378765106201 - val_accuracy: 0.3036 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.886378765106201 - val_accuracy: 0.3036 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 10/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.886378765106201 - val_accuracy: 0.3036 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.886378765106201 - val_accuracy: 0.3036 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 2.487252950668335 - accuracy: 0.3716199994087219 - val_loss: 2.8758556842803955 - val_accuracy: 0.3082 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.8758556842803955 - val_accuracy: 0.3082 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 11/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8758556842803955 - val_accuracy: 0.3082 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8758556842803955 - val_accuracy: 0.3082 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 2.4155020713806152 - accuracy: 0.3852800130844116 - val_loss: 2.877117872238159 - val_accuracy: 0.3078 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.877117872238159 - val_accuracy: 0.3078 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 12/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.877117872238159 - val_accuracy: 0.3078 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.877117872238159 - val_accuracy: 0.3078 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 2.329409122467041 - accuracy: 0.402319997549057 - val_loss: 2.8944742679595947 - val_accuracy: 0.3127 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.8944742679595947 - val_accuracy: 0.3127 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 13/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8944742679595947 - val_accuracy: 0.3127 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8944742679595947 - val_accuracy: 0.3127 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 2.2553887367248535 - accuracy: 0.41822001338005066 - val_loss: 2.842076539993286 - val_accuracy: 0.3198 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.842076539993286 - val_accuracy: 0.3198 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 14/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.842076539993286 - val_accuracy: 0.3198 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.842076539993286 - val_accuracy: 0.3198 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 2.2035233974456787 - accuracy: 0.4280399978160858 - val_loss: 2.846912145614624 - val_accuracy: 0.3214 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.846912145614624 - val_accuracy: 0.3214 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 15/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.846912145614624 - val_accuracy: 0.3214 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.846912145614624 - val_accuracy: 0.3214 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 2.1467857360839844 - accuracy: 0.4435400068759918 - val_loss: 2.8552422523498535 - val_accuracy: 0.3189 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.8552422523498535 - val_accuracy: 0.3189 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 16/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8552422523498535 - val_accuracy: 0.3189 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8552422523498535 - val_accuracy: 0.3189 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 2.0946402549743652 - accuracy: 0.45155999064445496 - val_loss: 2.903836250305176 - val_accuracy: 0.3116 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.903836250305176 - val_accuracy: 0.3116 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 17/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.903836250305176 - val_accuracy: 0.3116 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.903836250305176 - val_accuracy: 0.3116 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 2.04494309425354 - accuracy: 0.4598200023174286 - val_loss: 2.9353861808776855 - val_accuracy: 0.3214 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.9353861808776855 - val_accuracy: 0.3214 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 18/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.9353861808776855 - val_accuracy: 0.3214 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.9353861808776855 - val_accuracy: 0.3214 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 2.009782552719116 - accuracy: 0.46658000349998474 - val_loss: 2.9045708179473877 - val_accuracy: 0.3198 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.9045708179473877 - val_accuracy: 0.3198 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 19/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.9045708179473877 - val_accuracy: 0.3198 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.9045708179473877 - val_accuracy: 0.3198 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 1.9685176610946655 - accuracy: 0.4777800142765045 - val_loss: 2.8966259956359863 - val_accuracy: 0.3257 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.8966259956359863 - val_accuracy: 0.3257 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 20/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8966259956359863 - val_accuracy: 0.3257 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8966259956359863 - val_accuracy: 0.3257 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 1.9309577941894531 - accuracy: 0.4853399991989136 - val_loss: 2.911456823348999 - val_accuracy: 0.3221 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.911456823348999 - val_accuracy: 0.3221 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 21/40\n",
            "loss: 1.895734190940857 - accuracy: 0.4927999973297119 - val_loss: 2.953035354614258 - val_accuracy: 0.323 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 22/40\n",
            "loss: 1.630110502243042 - accuracy: 0.5537400245666504 - val_loss: 2.9599382877349854 - val_accuracy: 0.3228 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 23/40\n",
            "loss: 1.5496588945388794 - accuracy: 0.5740000009536743 - val_loss: 2.960631847381592 - val_accuracy: 0.3258 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 24/40\n",
            "loss: 1.4891995191574097 - accuracy: 0.5875599980354309 - val_loss: 2.979832649230957 - val_accuracy: 0.3254 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 25/40\n",
            "loss: 1.456904649734497 - accuracy: 0.5933799743652344 - val_loss: 2.9904520511627197 - val_accuracy: 0.3281 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 26/40\n",
            "loss: 1.4324601888656616 - accuracy: 0.5974000096321106 - val_loss: 3.0426883697509766 - val_accuracy: 0.327 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 27/40\n",
            "loss: 1.385547161102295 - accuracy: 0.6122599840164185 - val_loss: 3.0661776065826416 - val_accuracy: 0.3266 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 28/40\n",
            "loss: 1.370500922203064 - accuracy: 0.6154400110244751 - val_loss: 3.084153413772583 - val_accuracy: 0.3302 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 29/40\n",
            "loss: 1.3446838855743408 - accuracy: 0.619379997253418 - val_loss: 3.058830738067627 - val_accuracy: 0.3281 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 30/40\n",
            "loss: 1.314578890800476 - accuracy: 0.6263399720191956 - val_loss: 3.11197829246521 - val_accuracy: 0.3288 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 31/40\n",
            "loss: 1.3052502870559692 - accuracy: 0.629859983921051 - val_loss: 3.16294527053833 - val_accuracy: 0.3263 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 32/40\n",
            "loss: 1.2803997993469238 - accuracy: 0.6313400268554688 - val_loss: 3.1292505264282227 - val_accuracy: 0.3315 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 33/40\n",
            "loss: 1.2594624757766724 - accuracy: 0.6357600092887878 - val_loss: 3.1777091026306152 - val_accuracy: 0.3275 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 34/40\n",
            "loss: 1.2384108304977417 - accuracy: 0.6413599848747253 - val_loss: 3.1524760723114014 - val_accuracy: 0.3294 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 35/40\n",
            "loss: 1.223309874534607 - accuracy: 0.6459599733352661 - val_loss: 3.2311999797821045 - val_accuracy: 0.3227 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 36/40\n",
            "loss: 1.2037484645843506 - accuracy: 0.6497799754142761 - val_loss: 3.1915900707244873 - val_accuracy: 0.3298 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 37/40\n",
            "loss: 1.200270414352417 - accuracy: 0.6505200266838074 - val_loss: 3.2524917125701904 - val_accuracy: 0.3253 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 38/40\n",
            "loss: 1.1940999031066895 - accuracy: 0.6520400047302246 - val_loss: 3.2098562717437744 - val_accuracy: 0.3284 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 39/40\n",
            "loss: 1.1589621305465698 - accuracy: 0.661080002784729 - val_loss: 3.237009048461914 - val_accuracy: 0.3242 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 40/40\n",
            "loss: 1.1579691171646118 - accuracy: 0.6603800058364868 - val_loss: 3.270716428756714 - val_accuracy: 0.3272 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "CPU times: user 3min 6s, sys: 7.57 s, total: 3min 14s\n",
            "Wall time: 2min 34s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test with new implementation"
      ],
      "metadata": {
        "id": "YNFhTkoFs3De"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "model = get_convolutional_model(cifar100.X_train_norm, layer_sizes=[100, 100, 100, 100, 100], output_neurons=100)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "schedule = Schedule([DynamicEpoch(0.00002, 'weighted_l1')] * 20 + [StaticEpochNoRegularization()] * 20)\n",
        "history = model.fit(cifar100.X_train_norm, cifar100.y_train, optimizer, schedule=schedule, batch_size=batch_size, min_new_neurons=20, \n",
        "                    validation_data=(cifar100.X_test_norm, cifar100.y_test), growth_percentage=0.2, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwzcNrZ8s52A",
        "outputId": "72fedd2d-285f-4bd1-f7be-30d22d9153ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.05519437789917 - val_accuracy: 0.0094 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.05519437789917 - val_accuracy: 0.0094 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "Before pruning:\n",
            "loss: 4.037003040313721 - accuracy: 0.10740000009536743 - val_loss: 3.615011215209961 - val_accuracy: 0.1709 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.615152359008789 - val_accuracy: 0.1707 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 2/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.615152359008789 - val_accuracy: 0.1707 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.615152359008789 - val_accuracy: 0.1707 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "Before pruning:\n",
            "loss: 3.6248016357421875 - accuracy: 0.16261999309062958 - val_loss: 3.460017681121826 - val_accuracy: 0.1921 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.4601054191589355 - val_accuracy: 0.1921 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 105], total units: 505\n",
            "##########################################################\n",
            "Epoch 3/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.4601054191589355 - val_accuracy: 0.1921 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 105], total units: 505\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.4601054191589355 - val_accuracy: 0.1921 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 126], total units: 606\n",
            "Before pruning:\n",
            "loss: 3.4335405826568604 - accuracy: 0.19006000459194183 - val_loss: 3.2430577278137207 - val_accuracy: 0.2273 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 126], total units: 606\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.2431211471557617 - val_accuracy: 0.2271 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 87, 95, 90, 123], total units: 495\n",
            "##########################################################\n",
            "Epoch 4/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.2431211471557617 - val_accuracy: 0.2271 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 87, 95, 90, 123], total units: 495\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.2431211471557617 - val_accuracy: 0.2271 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 107, 115, 110, 147], total units: 599\n",
            "Before pruning:\n",
            "loss: 3.249293327331543 - accuracy: 0.22015999257564545 - val_loss: 3.035372018814087 - val_accuracy: 0.2651 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 107, 115, 110, 147], total units: 599\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.034897565841675 - val_accuracy: 0.2651 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 58, 92, 74, 135], total units: 459\n",
            "##########################################################\n",
            "Epoch 5/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.034897565841675 - val_accuracy: 0.2651 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 58, 92, 74, 135], total units: 459\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.034897804260254 - val_accuracy: 0.2651 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 78, 112, 94, 162], total units: 566\n",
            "Before pruning:\n",
            "loss: 3.089345693588257 - accuracy: 0.24782000482082367 - val_loss: 2.901459217071533 - val_accuracy: 0.2922 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 78, 112, 94, 162], total units: 566\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.9014549255371094 - val_accuracy: 0.2924 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 49, 83, 62, 152], total units: 446\n",
            "##########################################################\n",
            "Epoch 6/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.9014549255371094 - val_accuracy: 0.2924 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 49, 83, 62, 152], total units: 446\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.9014549255371094 - val_accuracy: 0.2924 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 69, 103, 82, 182], total units: 556\n",
            "Before pruning:\n",
            "loss: 3.003218173980713 - accuracy: 0.26447999477386475 - val_loss: 2.819310188293457 - val_accuracy: 0.3121 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 69, 103, 82, 182], total units: 556\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.819310426712036 - val_accuracy: 0.3123 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 36, 71, 59, 165], total units: 431\n",
            "##########################################################\n",
            "Epoch 7/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.819310426712036 - val_accuracy: 0.3123 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 36, 71, 59, 165], total units: 431\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.819310426712036 - val_accuracy: 0.3123 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 56, 91, 79, 198], total units: 544\n",
            "Before pruning:\n",
            "loss: 2.927304267883301 - accuracy: 0.28088000416755676 - val_loss: 2.7459099292755127 - val_accuracy: 0.3172 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 56, 91, 79, 198], total units: 544\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.7460200786590576 - val_accuracy: 0.3174 - penalty: 2e-05\n",
            "hidden layer sizes: [97, 31, 69, 58, 166], total units: 421\n",
            "##########################################################\n",
            "Epoch 8/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.7460200786590576 - val_accuracy: 0.3174 - penalty: 2e-05\n",
            "hidden layer sizes: [97, 31, 69, 58, 166], total units: 421\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.7460198402404785 - val_accuracy: 0.3174 - penalty: 2e-05\n",
            "hidden layer sizes: [117, 51, 89, 78, 199], total units: 534\n",
            "Before pruning:\n",
            "loss: 2.859795093536377 - accuracy: 0.29396000504493713 - val_loss: 2.678797483444214 - val_accuracy: 0.3315 - penalty: 2e-05\n",
            "hidden layer sizes: [117, 51, 89, 78, 199], total units: 534\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.6789135932922363 - val_accuracy: 0.3317 - penalty: 2e-05\n",
            "hidden layer sizes: [95, 28, 64, 55, 175], total units: 417\n",
            "##########################################################\n",
            "Epoch 9/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.6789135932922363 - val_accuracy: 0.3317 - penalty: 2e-05\n",
            "hidden layer sizes: [95, 28, 64, 55, 175], total units: 417\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.6789135932922363 - val_accuracy: 0.3317 - penalty: 2e-05\n",
            "hidden layer sizes: [115, 48, 84, 75, 210], total units: 532\n",
            "Before pruning:\n",
            "loss: 2.804959774017334 - accuracy: 0.3011600077152252 - val_loss: 2.612635612487793 - val_accuracy: 0.3443 - penalty: 2e-05\n",
            "hidden layer sizes: [115, 48, 84, 75, 210], total units: 532\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.612727642059326 - val_accuracy: 0.3443 - penalty: 2e-05\n",
            "hidden layer sizes: [95, 28, 52, 57, 184], total units: 416\n",
            "##########################################################\n",
            "Epoch 10/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.612727642059326 - val_accuracy: 0.3443 - penalty: 2e-05\n",
            "hidden layer sizes: [95, 28, 52, 57, 184], total units: 416\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.612727642059326 - val_accuracy: 0.3443 - penalty: 2e-05\n",
            "hidden layer sizes: [115, 48, 72, 77, 220], total units: 532\n",
            "Before pruning:\n",
            "loss: 2.751696825027466 - accuracy: 0.3125999867916107 - val_loss: 2.586822509765625 - val_accuracy: 0.3548 - penalty: 2e-05\n",
            "hidden layer sizes: [115, 48, 72, 77, 220], total units: 532\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.5869405269622803 - val_accuracy: 0.3547 - penalty: 2e-05\n",
            "hidden layer sizes: [92, 27, 48, 57, 184], total units: 408\n",
            "##########################################################\n",
            "Epoch 11/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.5869405269622803 - val_accuracy: 0.3547 - penalty: 2e-05\n",
            "hidden layer sizes: [92, 27, 48, 57, 184], total units: 408\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.5869412422180176 - val_accuracy: 0.3547 - penalty: 2e-05\n",
            "hidden layer sizes: [112, 47, 68, 77, 220], total units: 524\n",
            "Before pruning:\n",
            "loss: 2.7111809253692627 - accuracy: 0.322160005569458 - val_loss: 2.550893545150757 - val_accuracy: 0.3551 - penalty: 2e-05\n",
            "hidden layer sizes: [112, 47, 68, 77, 220], total units: 524\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.550891876220703 - val_accuracy: 0.3552 - penalty: 2e-05\n",
            "hidden layer sizes: [86, 27, 46, 57, 185], total units: 401\n",
            "##########################################################\n",
            "Epoch 12/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.550891876220703 - val_accuracy: 0.3552 - penalty: 2e-05\n",
            "hidden layer sizes: [86, 27, 46, 57, 185], total units: 401\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.550891876220703 - val_accuracy: 0.3552 - penalty: 2e-05\n",
            "hidden layer sizes: [106, 47, 66, 77, 222], total units: 518\n",
            "Before pruning:\n",
            "loss: 2.683405637741089 - accuracy: 0.32572001218795776 - val_loss: 2.5115199089050293 - val_accuracy: 0.369 - penalty: 2e-05\n",
            "hidden layer sizes: [106, 47, 66, 77, 222], total units: 518\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.511550188064575 - val_accuracy: 0.3694 - penalty: 2e-05\n",
            "hidden layer sizes: [84, 26, 43, 58, 184], total units: 395\n",
            "##########################################################\n",
            "Epoch 13/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.511550188064575 - val_accuracy: 0.3694 - penalty: 2e-05\n",
            "hidden layer sizes: [84, 26, 43, 58, 184], total units: 395\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.511549949645996 - val_accuracy: 0.3694 - penalty: 2e-05\n",
            "hidden layer sizes: [104, 46, 63, 78, 220], total units: 511\n",
            "Before pruning:\n",
            "loss: 2.6466240882873535 - accuracy: 0.329120010137558 - val_loss: 2.4833881855010986 - val_accuracy: 0.3717 - penalty: 2e-05\n",
            "hidden layer sizes: [104, 46, 63, 78, 220], total units: 511\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.4834678173065186 - val_accuracy: 0.372 - penalty: 2e-05\n",
            "hidden layer sizes: [82, 25, 40, 61, 188], total units: 396\n",
            "##########################################################\n",
            "Epoch 14/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4834678173065186 - val_accuracy: 0.372 - penalty: 2e-05\n",
            "hidden layer sizes: [82, 25, 40, 61, 188], total units: 396\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4834678173065186 - val_accuracy: 0.372 - penalty: 2e-05\n",
            "hidden layer sizes: [102, 45, 60, 81, 225], total units: 513\n",
            "Before pruning:\n",
            "loss: 2.6142780780792236 - accuracy: 0.33781999349594116 - val_loss: 2.460160255432129 - val_accuracy: 0.3764 - penalty: 2e-05\n",
            "hidden layer sizes: [102, 45, 60, 81, 225], total units: 513\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.4601590633392334 - val_accuracy: 0.3765 - penalty: 2e-05\n",
            "hidden layer sizes: [80, 23, 39, 62, 186], total units: 390\n",
            "##########################################################\n",
            "Epoch 15/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4601590633392334 - val_accuracy: 0.3765 - penalty: 2e-05\n",
            "hidden layer sizes: [80, 23, 39, 62, 186], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4601593017578125 - val_accuracy: 0.3765 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 43, 59, 82, 223], total units: 507\n",
            "Before pruning:\n",
            "loss: 2.592832088470459 - accuracy: 0.34327998757362366 - val_loss: 2.437835693359375 - val_accuracy: 0.3786 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 43, 59, 82, 223], total units: 507\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.437974452972412 - val_accuracy: 0.3787 - penalty: 2e-05\n",
            "hidden layer sizes: [79, 22, 37, 59, 187], total units: 384\n",
            "##########################################################\n",
            "Epoch 16/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.437974452972412 - val_accuracy: 0.3787 - penalty: 2e-05\n",
            "hidden layer sizes: [79, 22, 37, 59, 187], total units: 384\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.437974452972412 - val_accuracy: 0.3787 - penalty: 2e-05\n",
            "hidden layer sizes: [99, 42, 57, 79, 224], total units: 501\n",
            "Before pruning:\n",
            "loss: 2.5666189193725586 - accuracy: 0.3474999964237213 - val_loss: 2.40576434135437 - val_accuracy: 0.3852 - penalty: 2e-05\n",
            "hidden layer sizes: [99, 42, 57, 79, 224], total units: 501\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.405787706375122 - val_accuracy: 0.3849 - penalty: 2e-05\n",
            "hidden layer sizes: [78, 22, 36, 60, 187], total units: 383\n",
            "##########################################################\n",
            "Epoch 17/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.405787706375122 - val_accuracy: 0.3849 - penalty: 2e-05\n",
            "hidden layer sizes: [78, 22, 36, 60, 187], total units: 383\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.405787467956543 - val_accuracy: 0.3849 - penalty: 2e-05\n",
            "hidden layer sizes: [98, 42, 56, 80, 224], total units: 500\n",
            "Before pruning:\n",
            "loss: 2.5431222915649414 - accuracy: 0.3517799973487854 - val_loss: 2.4085659980773926 - val_accuracy: 0.3833 - penalty: 2e-05\n",
            "hidden layer sizes: [98, 42, 56, 80, 224], total units: 500\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.408562660217285 - val_accuracy: 0.3835 - penalty: 2e-05\n",
            "hidden layer sizes: [75, 21, 35, 60, 187], total units: 378\n",
            "##########################################################\n",
            "Epoch 18/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.408562660217285 - val_accuracy: 0.3835 - penalty: 2e-05\n",
            "hidden layer sizes: [75, 21, 35, 60, 187], total units: 378\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.408562660217285 - val_accuracy: 0.3835 - penalty: 2e-05\n",
            "hidden layer sizes: [95, 41, 55, 80, 224], total units: 495\n",
            "Before pruning:\n",
            "loss: 2.523228168487549 - accuracy: 0.3554399907588959 - val_loss: 2.379987955093384 - val_accuracy: 0.3885 - penalty: 2e-05\n",
            "hidden layer sizes: [95, 41, 55, 80, 224], total units: 495\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3799939155578613 - val_accuracy: 0.3884 - penalty: 2e-05\n",
            "hidden layer sizes: [72, 21, 35, 62, 190], total units: 380\n",
            "##########################################################\n",
            "Epoch 19/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3799939155578613 - val_accuracy: 0.3884 - penalty: 2e-05\n",
            "hidden layer sizes: [72, 21, 35, 62, 190], total units: 380\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3799936771392822 - val_accuracy: 0.3884 - penalty: 2e-05\n",
            "hidden layer sizes: [92, 41, 55, 82, 228], total units: 498\n",
            "Before pruning:\n",
            "loss: 2.5035688877105713 - accuracy: 0.3608799874782562 - val_loss: 2.367837429046631 - val_accuracy: 0.3931 - penalty: 2e-05\n",
            "hidden layer sizes: [92, 41, 55, 82, 228], total units: 498\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3679003715515137 - val_accuracy: 0.3926 - penalty: 2e-05\n",
            "hidden layer sizes: [71, 19, 33, 64, 190], total units: 377\n",
            "##########################################################\n",
            "Epoch 20/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3679003715515137 - val_accuracy: 0.3926 - penalty: 2e-05\n",
            "hidden layer sizes: [71, 19, 33, 64, 190], total units: 377\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3679003715515137 - val_accuracy: 0.3926 - penalty: 2e-05\n",
            "hidden layer sizes: [91, 39, 53, 84, 228], total units: 495\n",
            "Before pruning:\n",
            "loss: 2.480381488800049 - accuracy: 0.36399999260902405 - val_loss: 2.3558216094970703 - val_accuracy: 0.3966 - penalty: 2e-05\n",
            "hidden layer sizes: [91, 39, 53, 84, 228], total units: 495\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.35581111907959 - val_accuracy: 0.397 - penalty: 2e-05\n",
            "hidden layer sizes: [67, 19, 33, 63, 192], total units: 374\n",
            "##########################################################\n",
            "Epoch 21/40\n",
            "loss: 2.5101146697998047 - accuracy: 0.3623200058937073 - val_loss: 2.2932052612304688 - val_accuracy: 0.4081 - penalty: 0.0\n",
            "hidden layer sizes: [67, 19, 33, 63, 192], total units: 374\n",
            "##########################################################\n",
            "Epoch 22/40\n",
            "loss: 2.2417519092559814 - accuracy: 0.4176799952983856 - val_loss: 2.24652099609375 - val_accuracy: 0.4191 - penalty: 0.0\n",
            "hidden layer sizes: [67, 19, 33, 63, 192], total units: 374\n",
            "##########################################################\n",
            "Epoch 23/40\n",
            "loss: 2.1229946613311768 - accuracy: 0.4456599950790405 - val_loss: 2.2346243858337402 - val_accuracy: 0.4272 - penalty: 0.0\n",
            "hidden layer sizes: [67, 19, 33, 63, 192], total units: 374\n",
            "##########################################################\n",
            "Epoch 24/40\n",
            "loss: 2.0389599800109863 - accuracy: 0.4651400148868561 - val_loss: 2.206825017929077 - val_accuracy: 0.4354 - penalty: 0.0\n",
            "hidden layer sizes: [67, 19, 33, 63, 192], total units: 374\n",
            "##########################################################\n",
            "Epoch 25/40\n",
            "loss: 1.9554073810577393 - accuracy: 0.48240000009536743 - val_loss: 2.219784736633301 - val_accuracy: 0.4366 - penalty: 0.0\n",
            "hidden layer sizes: [67, 19, 33, 63, 192], total units: 374\n",
            "##########################################################\n",
            "Epoch 26/40\n",
            "loss: 1.8829586505889893 - accuracy: 0.4977799952030182 - val_loss: 2.1988489627838135 - val_accuracy: 0.4374 - penalty: 0.0\n",
            "hidden layer sizes: [67, 19, 33, 63, 192], total units: 374\n",
            "##########################################################\n",
            "Epoch 27/40\n",
            "loss: 1.8065154552459717 - accuracy: 0.514460027217865 - val_loss: 2.2029411792755127 - val_accuracy: 0.4398 - penalty: 0.0\n",
            "hidden layer sizes: [67, 19, 33, 63, 192], total units: 374\n",
            "##########################################################\n",
            "Epoch 28/40\n",
            "loss: 1.7442501783370972 - accuracy: 0.5296000242233276 - val_loss: 2.2044661045074463 - val_accuracy: 0.4469 - penalty: 0.0\n",
            "hidden layer sizes: [67, 19, 33, 63, 192], total units: 374\n",
            "##########################################################\n",
            "Epoch 29/40\n",
            "loss: 1.6931864023208618 - accuracy: 0.5393400192260742 - val_loss: 2.2079403400421143 - val_accuracy: 0.4413 - penalty: 0.0\n",
            "hidden layer sizes: [67, 19, 33, 63, 192], total units: 374\n",
            "##########################################################\n",
            "Epoch 30/40\n",
            "loss: 1.6353719234466553 - accuracy: 0.5524799823760986 - val_loss: 2.2131571769714355 - val_accuracy: 0.4429 - penalty: 0.0\n",
            "hidden layer sizes: [67, 19, 33, 63, 192], total units: 374\n",
            "##########################################################\n",
            "Epoch 31/40\n",
            "loss: 1.5832101106643677 - accuracy: 0.5632200241088867 - val_loss: 2.2294435501098633 - val_accuracy: 0.4469 - penalty: 0.0\n",
            "hidden layer sizes: [67, 19, 33, 63, 192], total units: 374\n",
            "##########################################################\n",
            "Epoch 32/40\n",
            "loss: 1.532691240310669 - accuracy: 0.5778800249099731 - val_loss: 2.238565683364868 - val_accuracy: 0.4446 - penalty: 0.0\n",
            "hidden layer sizes: [67, 19, 33, 63, 192], total units: 374\n",
            "##########################################################\n",
            "Epoch 33/40\n",
            "loss: 1.4884145259857178 - accuracy: 0.5856199860572815 - val_loss: 2.257613182067871 - val_accuracy: 0.4472 - penalty: 0.0\n",
            "hidden layer sizes: [67, 19, 33, 63, 192], total units: 374\n",
            "##########################################################\n",
            "Epoch 34/40\n",
            "loss: 1.4464598894119263 - accuracy: 0.5948799848556519 - val_loss: 2.2750630378723145 - val_accuracy: 0.4452 - penalty: 0.0\n",
            "hidden layer sizes: [67, 19, 33, 63, 192], total units: 374\n",
            "##########################################################\n",
            "Epoch 35/40\n",
            "loss: 1.4070936441421509 - accuracy: 0.603659987449646 - val_loss: 2.287640333175659 - val_accuracy: 0.4506 - penalty: 0.0\n",
            "hidden layer sizes: [67, 19, 33, 63, 192], total units: 374\n",
            "##########################################################\n",
            "Epoch 36/40\n",
            "loss: 1.3669673204421997 - accuracy: 0.6153799891471863 - val_loss: 2.2972190380096436 - val_accuracy: 0.4498 - penalty: 0.0\n",
            "hidden layer sizes: [67, 19, 33, 63, 192], total units: 374\n",
            "##########################################################\n",
            "Epoch 37/40\n",
            "loss: 1.3195290565490723 - accuracy: 0.6241999864578247 - val_loss: 2.3099663257598877 - val_accuracy: 0.4491 - penalty: 0.0\n",
            "hidden layer sizes: [67, 19, 33, 63, 192], total units: 374\n",
            "##########################################################\n",
            "Epoch 38/40\n",
            "loss: 1.2996236085891724 - accuracy: 0.6271600127220154 - val_loss: 2.342262029647827 - val_accuracy: 0.4496 - penalty: 0.0\n",
            "hidden layer sizes: [67, 19, 33, 63, 192], total units: 374\n",
            "##########################################################\n",
            "Epoch 39/40\n",
            "loss: 1.2692670822143555 - accuracy: 0.6364200115203857 - val_loss: 2.3671762943267822 - val_accuracy: 0.4461 - penalty: 0.0\n",
            "hidden layer sizes: [67, 19, 33, 63, 192], total units: 374\n",
            "##########################################################\n",
            "Epoch 40/40\n",
            "loss: 1.2321586608886719 - accuracy: 0.6445199847221375 - val_loss: 2.37777042388916 - val_accuracy: 0.4456 - penalty: 0.0\n",
            "hidden layer sizes: [67, 19, 33, 63, 192], total units: 374\n",
            "CPU times: user 3min 38s, sys: 10.2 s, total: 3min 48s\n",
            "Wall time: 3min 19s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "model = get_convolutional_model(cifar100.X_train_norm, layer_sizes=[100, 100, 100, 100, 100], output_neurons=100)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "schedule = Schedule([StaticEpoch(0.0003, 'l1')] * 40)\n",
        "history = model.fit(cifar100.X_train_norm, cifar100.y_train, optimizer, schedule=schedule, batch_size=batch_size, min_new_neurons=20, \n",
        "                    validation_data=(cifar100.X_test_norm, cifar100.y_test), growth_percentage=0.2, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGf28iPzupVr",
        "outputId": "c438bbbb-a42a-4370-b73b-9fbc8a083293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/40\n",
            "loss: 4.071033000946045 - accuracy: 0.1052199974656105 - val_loss: 3.553272247314453 - val_accuracy: 0.183 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 2/40\n",
            "loss: 3.518968105316162 - accuracy: 0.18228000402450562 - val_loss: 3.396209716796875 - val_accuracy: 0.206 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 3/40\n",
            "loss: 3.3106374740600586 - accuracy: 0.21770000457763672 - val_loss: 3.2780559062957764 - val_accuracy: 0.2264 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 4/40\n",
            "loss: 3.1583590507507324 - accuracy: 0.24587999284267426 - val_loss: 3.13752818107605 - val_accuracy: 0.25 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 5/40\n",
            "loss: 3.0346078872680664 - accuracy: 0.2641800045967102 - val_loss: 3.0532619953155518 - val_accuracy: 0.267 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 6/40\n",
            "loss: 2.908710241317749 - accuracy: 0.2902199923992157 - val_loss: 2.9213547706604004 - val_accuracy: 0.2915 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 7/40\n",
            "loss: 2.801201343536377 - accuracy: 0.31279999017715454 - val_loss: 2.8582942485809326 - val_accuracy: 0.307 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 8/40\n",
            "loss: 2.719003438949585 - accuracy: 0.3266200125217438 - val_loss: 2.7766897678375244 - val_accuracy: 0.3205 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 9/40\n",
            "loss: 2.6402320861816406 - accuracy: 0.339819997549057 - val_loss: 2.706251382827759 - val_accuracy: 0.3303 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 10/40\n",
            "loss: 2.57295298576355 - accuracy: 0.3574199974536896 - val_loss: 2.660698890686035 - val_accuracy: 0.3413 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 11/40\n",
            "loss: 2.501272439956665 - accuracy: 0.36886000633239746 - val_loss: 2.6247684955596924 - val_accuracy: 0.3432 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 12/40\n",
            "loss: 2.442643165588379 - accuracy: 0.38166001439094543 - val_loss: 2.5751793384552 - val_accuracy: 0.3617 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 13/40\n",
            "loss: 2.383866310119629 - accuracy: 0.39302000403404236 - val_loss: 2.536834239959717 - val_accuracy: 0.3708 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 14/40\n",
            "loss: 2.3274741172790527 - accuracy: 0.40494000911712646 - val_loss: 2.480771780014038 - val_accuracy: 0.3825 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 15/40\n",
            "loss: 2.286496639251709 - accuracy: 0.41312000155448914 - val_loss: 2.463789939880371 - val_accuracy: 0.3844 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 16/40\n",
            "loss: 2.2363409996032715 - accuracy: 0.4251199960708618 - val_loss: 2.424389362335205 - val_accuracy: 0.3874 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 17/40\n",
            "loss: 2.1918132305145264 - accuracy: 0.43375998735427856 - val_loss: 2.405794382095337 - val_accuracy: 0.3968 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 18/40\n",
            "loss: 2.1478512287139893 - accuracy: 0.4424799978733063 - val_loss: 2.3559794425964355 - val_accuracy: 0.407 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 19/40\n",
            "loss: 2.108234167098999 - accuracy: 0.4510599970817566 - val_loss: 2.358304738998413 - val_accuracy: 0.405 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 20/40\n",
            "loss: 2.077047109603882 - accuracy: 0.4573799967765808 - val_loss: 2.316800117492676 - val_accuracy: 0.4162 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 21/40\n",
            "loss: 2.0365161895751953 - accuracy: 0.46658000349998474 - val_loss: 2.316678524017334 - val_accuracy: 0.416 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 22/40\n",
            "loss: 1.9989879131317139 - accuracy: 0.47297999262809753 - val_loss: 2.2923710346221924 - val_accuracy: 0.4184 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 23/40\n",
            "loss: 1.964857816696167 - accuracy: 0.4824399948120117 - val_loss: 2.281848192214966 - val_accuracy: 0.4245 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 24/40\n",
            "loss: 1.9355088472366333 - accuracy: 0.48871999979019165 - val_loss: 2.2623167037963867 - val_accuracy: 0.4241 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 25/40\n",
            "loss: 1.906049370765686 - accuracy: 0.49476000666618347 - val_loss: 2.2498297691345215 - val_accuracy: 0.4333 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 26/40\n",
            "loss: 1.8785537481307983 - accuracy: 0.5002599954605103 - val_loss: 2.244887113571167 - val_accuracy: 0.4294 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 27/40\n",
            "loss: 1.8562285900115967 - accuracy: 0.5053600072860718 - val_loss: 2.2310147285461426 - val_accuracy: 0.4324 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 28/40\n",
            "loss: 1.8266310691833496 - accuracy: 0.515500009059906 - val_loss: 2.236551284790039 - val_accuracy: 0.4349 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 29/40\n",
            "loss: 1.8073856830596924 - accuracy: 0.517300009727478 - val_loss: 2.2432727813720703 - val_accuracy: 0.4338 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 30/40\n",
            "loss: 1.7793145179748535 - accuracy: 0.5252400040626526 - val_loss: 2.224285364151001 - val_accuracy: 0.434 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 31/40\n",
            "loss: 1.7541224956512451 - accuracy: 0.5281000137329102 - val_loss: 2.244774580001831 - val_accuracy: 0.4368 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 32/40\n",
            "loss: 1.740288496017456 - accuracy: 0.5285199880599976 - val_loss: 2.2091290950775146 - val_accuracy: 0.4395 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 33/40\n",
            "loss: 1.7192367315292358 - accuracy: 0.5343800187110901 - val_loss: 2.197467565536499 - val_accuracy: 0.4459 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 34/40\n",
            "loss: 1.69728422164917 - accuracy: 0.54093998670578 - val_loss: 2.207422971725464 - val_accuracy: 0.4444 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 35/40\n",
            "loss: 1.686623454093933 - accuracy: 0.5417600274085999 - val_loss: 2.208491325378418 - val_accuracy: 0.4432 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 36/40\n",
            "loss: 1.6681064367294312 - accuracy: 0.5454800128936768 - val_loss: 2.184316873550415 - val_accuracy: 0.4488 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 37/40\n",
            "loss: 1.6466519832611084 - accuracy: 0.5486199855804443 - val_loss: 2.200468063354492 - val_accuracy: 0.4498 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 38/40\n",
            "loss: 1.6313741207122803 - accuracy: 0.5534200072288513 - val_loss: 2.176934003829956 - val_accuracy: 0.4531 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 39/40\n",
            "loss: 1.6199793815612793 - accuracy: 0.5560799837112427 - val_loss: 2.196065664291382 - val_accuracy: 0.4485 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 40/40\n",
            "loss: 1.5976577997207642 - accuracy: 0.559660017490387 - val_loss: 2.1980412006378174 - val_accuracy: 0.4508 - penalty: 0.0003\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "CPU times: user 2min 43s, sys: 6.9 s, total: 2min 50s\n",
            "Wall time: 3min 8s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "model = get_convolutional_model(cifar100.X_train_norm, layer_sizes=[100, 100, 100, 100, 100], output_neurons=100)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "schedule = Schedule([DynamicEpoch(0.00002, 'weighted_l1')] * 20 + [StaticEpoch(0.0003, 'l1')] * 20)\n",
        "history = model.fit(cifar100.X_train_norm, cifar100.y_train, optimizer, schedule=schedule, batch_size=batch_size, min_new_neurons=20, \n",
        "                    validation_data=(cifar100.X_test_norm, cifar100.y_test), growth_percentage=0.2, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ebr-8n7FvaGY",
        "outputId": "3ce4642a-7229-4cce-95b3-a151d022082d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.987770080566406 - val_accuracy: 0.0122 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.987770080566406 - val_accuracy: 0.0122 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "Before pruning:\n",
            "loss: 4.023364543914795 - accuracy: 0.10638000071048737 - val_loss: 3.644362211227417 - val_accuracy: 0.1689 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.64444637298584 - val_accuracy: 0.1693 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 2/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.64444637298584 - val_accuracy: 0.1693 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.644446849822998 - val_accuracy: 0.1693 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "Before pruning:\n",
            "loss: 3.618381977081299 - accuracy: 0.16308000683784485 - val_loss: 3.466158866882324 - val_accuracy: 0.1886 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.4663054943084717 - val_accuracy: 0.1877 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 105], total units: 505\n",
            "##########################################################\n",
            "Epoch 3/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.4663054943084717 - val_accuracy: 0.1877 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 105], total units: 505\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.4663054943084717 - val_accuracy: 0.1877 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 126], total units: 606\n",
            "Before pruning:\n",
            "loss: 3.4530599117279053 - accuracy: 0.18836000561714172 - val_loss: 3.2921671867370605 - val_accuracy: 0.2241 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 126], total units: 606\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.292043447494507 - val_accuracy: 0.2241 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 92, 81, 95, 122], total units: 490\n",
            "##########################################################\n",
            "Epoch 4/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.292043447494507 - val_accuracy: 0.2241 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 92, 81, 95, 122], total units: 490\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.292043685913086 - val_accuracy: 0.2241 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 112, 101, 115, 146], total units: 594\n",
            "Before pruning:\n",
            "loss: 3.2730484008789062 - accuracy: 0.21622000634670258 - val_loss: 3.094503164291382 - val_accuracy: 0.2575 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 112, 101, 115, 146], total units: 594\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.09443736076355 - val_accuracy: 0.2575 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 64, 72, 80, 136], total units: 452\n",
            "##########################################################\n",
            "Epoch 5/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.09443736076355 - val_accuracy: 0.2575 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 64, 72, 80, 136], total units: 452\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.09443736076355 - val_accuracy: 0.2575 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 84, 92, 100, 163], total units: 559\n",
            "Before pruning:\n",
            "loss: 3.101715326309204 - accuracy: 0.24738000333309174 - val_loss: 2.94486403465271 - val_accuracy: 0.2829 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 84, 92, 100, 163], total units: 559\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.9449334144592285 - val_accuracy: 0.2827 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 47, 66, 70, 148], total units: 431\n",
            "##########################################################\n",
            "Epoch 6/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.9449334144592285 - val_accuracy: 0.2827 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 47, 66, 70, 148], total units: 431\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.9449336528778076 - val_accuracy: 0.2827 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 67, 86, 90, 177], total units: 540\n",
            "Before pruning:\n",
            "loss: 2.994967460632324 - accuracy: 0.26864001154899597 - val_loss: 2.831048011779785 - val_accuracy: 0.3034 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 67, 86, 90, 177], total units: 540\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.831099271774292 - val_accuracy: 0.3033 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 42, 62, 62, 155], total units: 421\n",
            "##########################################################\n",
            "Epoch 7/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.831099271774292 - val_accuracy: 0.3033 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 42, 62, 62, 155], total units: 421\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.831099271774292 - val_accuracy: 0.3033 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 62, 82, 82, 186], total units: 532\n",
            "Before pruning:\n",
            "loss: 2.9095067977905273 - accuracy: 0.28534001111984253 - val_loss: 2.7435142993927 - val_accuracy: 0.3197 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 62, 82, 82, 186], total units: 532\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.743551254272461 - val_accuracy: 0.3197 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 38, 59, 67, 166], total units: 430\n",
            "##########################################################\n",
            "Epoch 8/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.743551254272461 - val_accuracy: 0.3197 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 38, 59, 67, 166], total units: 430\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.743551254272461 - val_accuracy: 0.3197 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 58, 79, 87, 199], total units: 543\n",
            "Before pruning:\n",
            "loss: 2.8300235271453857 - accuracy: 0.2973000109195709 - val_loss: 2.682271957397461 - val_accuracy: 0.3337 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 58, 79, 87, 199], total units: 543\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.6823511123657227 - val_accuracy: 0.3337 - penalty: 2e-05\n",
            "hidden layer sizes: [94, 36, 56, 66, 172], total units: 424\n",
            "##########################################################\n",
            "Epoch 9/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.6823511123657227 - val_accuracy: 0.3337 - penalty: 2e-05\n",
            "hidden layer sizes: [94, 36, 56, 66, 172], total units: 424\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.6823513507843018 - val_accuracy: 0.3337 - penalty: 2e-05\n",
            "hidden layer sizes: [114, 56, 76, 86, 206], total units: 538\n",
            "Before pruning:\n",
            "loss: 2.7649850845336914 - accuracy: 0.31025999784469604 - val_loss: 2.6347815990448 - val_accuracy: 0.3416 - penalty: 2e-05\n",
            "hidden layer sizes: [114, 56, 76, 86, 206], total units: 538\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.6348397731781006 - val_accuracy: 0.3414 - penalty: 2e-05\n",
            "hidden layer sizes: [91, 33, 53, 69, 174], total units: 420\n",
            "##########################################################\n",
            "Epoch 10/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.6348397731781006 - val_accuracy: 0.3414 - penalty: 2e-05\n",
            "hidden layer sizes: [91, 33, 53, 69, 174], total units: 420\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.6348397731781006 - val_accuracy: 0.3414 - penalty: 2e-05\n",
            "hidden layer sizes: [111, 53, 73, 89, 208], total units: 534\n",
            "Before pruning:\n",
            "loss: 2.710206985473633 - accuracy: 0.32335999608039856 - val_loss: 2.5629422664642334 - val_accuracy: 0.354 - penalty: 2e-05\n",
            "hidden layer sizes: [111, 53, 73, 89, 208], total units: 534\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.5630226135253906 - val_accuracy: 0.3538 - penalty: 2e-05\n",
            "hidden layer sizes: [88, 30, 49, 72, 175], total units: 414\n",
            "##########################################################\n",
            "Epoch 11/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.5630226135253906 - val_accuracy: 0.3538 - penalty: 2e-05\n",
            "hidden layer sizes: [88, 30, 49, 72, 175], total units: 414\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.5630226135253906 - val_accuracy: 0.3538 - penalty: 2e-05\n",
            "hidden layer sizes: [108, 50, 69, 92, 210], total units: 529\n",
            "Before pruning:\n",
            "loss: 2.6745922565460205 - accuracy: 0.32739999890327454 - val_loss: 2.5363001823425293 - val_accuracy: 0.3598 - penalty: 2e-05\n",
            "hidden layer sizes: [108, 50, 69, 92, 210], total units: 529\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.5363311767578125 - val_accuracy: 0.3598 - penalty: 2e-05\n",
            "hidden layer sizes: [82, 28, 44, 72, 178], total units: 404\n",
            "##########################################################\n",
            "Epoch 12/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.5363311767578125 - val_accuracy: 0.3598 - penalty: 2e-05\n",
            "hidden layer sizes: [82, 28, 44, 72, 178], total units: 404\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.5363314151763916 - val_accuracy: 0.3598 - penalty: 2e-05\n",
            "hidden layer sizes: [102, 48, 64, 92, 213], total units: 519\n",
            "Before pruning:\n",
            "loss: 2.634429693222046 - accuracy: 0.3358199894428253 - val_loss: 2.507314682006836 - val_accuracy: 0.3626 - penalty: 2e-05\n",
            "hidden layer sizes: [102, 48, 64, 92, 213], total units: 519\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.507383108139038 - val_accuracy: 0.3627 - penalty: 2e-05\n",
            "hidden layer sizes: [80, 28, 42, 73, 178], total units: 401\n",
            "##########################################################\n",
            "Epoch 13/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.507383108139038 - val_accuracy: 0.3627 - penalty: 2e-05\n",
            "hidden layer sizes: [80, 28, 42, 73, 178], total units: 401\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.507383108139038 - val_accuracy: 0.3627 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 48, 62, 93, 213], total units: 516\n",
            "Before pruning:\n",
            "loss: 2.6022844314575195 - accuracy: 0.3443399965763092 - val_loss: 2.4880776405334473 - val_accuracy: 0.3689 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 48, 62, 93, 213], total units: 516\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.488116502761841 - val_accuracy: 0.369 - penalty: 2e-05\n",
            "hidden layer sizes: [76, 26, 38, 74, 182], total units: 396\n",
            "##########################################################\n",
            "Epoch 14/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.488116502761841 - val_accuracy: 0.369 - penalty: 2e-05\n",
            "hidden layer sizes: [76, 26, 38, 74, 182], total units: 396\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.488116502761841 - val_accuracy: 0.369 - penalty: 2e-05\n",
            "hidden layer sizes: [96, 46, 58, 94, 218], total units: 512\n",
            "Before pruning:\n",
            "loss: 2.5715768337249756 - accuracy: 0.3483000099658966 - val_loss: 2.454090118408203 - val_accuracy: 0.3741 - penalty: 2e-05\n",
            "hidden layer sizes: [96, 46, 58, 94, 218], total units: 512\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.4542651176452637 - val_accuracy: 0.3742 - penalty: 2e-05\n",
            "hidden layer sizes: [72, 26, 34, 70, 188], total units: 390\n",
            "##########################################################\n",
            "Epoch 15/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4542651176452637 - val_accuracy: 0.3742 - penalty: 2e-05\n",
            "hidden layer sizes: [72, 26, 34, 70, 188], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4542653560638428 - val_accuracy: 0.3742 - penalty: 2e-05\n",
            "hidden layer sizes: [92, 46, 54, 90, 225], total units: 507\n",
            "Before pruning:\n",
            "loss: 2.546077013015747 - accuracy: 0.3521000146865845 - val_loss: 2.424926280975342 - val_accuracy: 0.3813 - penalty: 2e-05\n",
            "hidden layer sizes: [92, 46, 54, 90, 225], total units: 507\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.425039529800415 - val_accuracy: 0.381 - penalty: 2e-05\n",
            "hidden layer sizes: [71, 25, 34, 72, 190], total units: 392\n",
            "##########################################################\n",
            "Epoch 16/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.425039529800415 - val_accuracy: 0.381 - penalty: 2e-05\n",
            "hidden layer sizes: [71, 25, 34, 72, 190], total units: 392\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.425039529800415 - val_accuracy: 0.381 - penalty: 2e-05\n",
            "hidden layer sizes: [91, 45, 54, 92, 228], total units: 510\n",
            "Before pruning:\n",
            "loss: 2.519939422607422 - accuracy: 0.35833999514579773 - val_loss: 2.424110174179077 - val_accuracy: 0.3813 - penalty: 2e-05\n",
            "hidden layer sizes: [91, 45, 54, 92, 228], total units: 510\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.4242382049560547 - val_accuracy: 0.3807 - penalty: 2e-05\n",
            "hidden layer sizes: [69, 24, 32, 73, 190], total units: 388\n",
            "##########################################################\n",
            "Epoch 17/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4242382049560547 - val_accuracy: 0.3807 - penalty: 2e-05\n",
            "hidden layer sizes: [69, 24, 32, 73, 190], total units: 388\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4242382049560547 - val_accuracy: 0.3807 - penalty: 2e-05\n",
            "hidden layer sizes: [89, 44, 52, 93, 228], total units: 506\n",
            "Before pruning:\n",
            "loss: 2.4945499897003174 - accuracy: 0.36465999484062195 - val_loss: 2.3776206970214844 - val_accuracy: 0.394 - penalty: 2e-05\n",
            "hidden layer sizes: [89, 44, 52, 93, 228], total units: 506\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.377598762512207 - val_accuracy: 0.3943 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 22, 31, 73, 190], total units: 384\n",
            "##########################################################\n",
            "Epoch 18/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.377598762512207 - val_accuracy: 0.3943 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 22, 31, 73, 190], total units: 384\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.377598762512207 - val_accuracy: 0.3943 - penalty: 2e-05\n",
            "hidden layer sizes: [88, 42, 51, 93, 228], total units: 502\n",
            "Before pruning:\n",
            "loss: 2.4742727279663086 - accuracy: 0.36702001094818115 - val_loss: 2.3563246726989746 - val_accuracy: 0.3967 - penalty: 2e-05\n",
            "hidden layer sizes: [88, 42, 51, 93, 228], total units: 502\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3563735485076904 - val_accuracy: 0.397 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 22, 31, 74, 193], total units: 388\n",
            "##########################################################\n",
            "Epoch 19/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3563735485076904 - val_accuracy: 0.397 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 22, 31, 74, 193], total units: 388\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3563735485076904 - val_accuracy: 0.397 - penalty: 2e-05\n",
            "hidden layer sizes: [88, 42, 51, 94, 231], total units: 506\n",
            "Before pruning:\n",
            "loss: 2.4607784748077393 - accuracy: 0.36904001235961914 - val_loss: 2.340550422668457 - val_accuracy: 0.4024 - penalty: 2e-05\n",
            "hidden layer sizes: [88, 42, 51, 94, 231], total units: 506\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3405373096466064 - val_accuracy: 0.4023 - penalty: 2e-05\n",
            "hidden layer sizes: [66, 22, 31, 69, 191], total units: 379\n",
            "##########################################################\n",
            "Epoch 20/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3405373096466064 - val_accuracy: 0.4023 - penalty: 2e-05\n",
            "hidden layer sizes: [66, 22, 31, 69, 191], total units: 379\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3405373096466064 - val_accuracy: 0.4023 - penalty: 2e-05\n",
            "hidden layer sizes: [86, 42, 51, 89, 229], total units: 497\n",
            "Before pruning:\n",
            "loss: 2.443455457687378 - accuracy: 0.376120001077652 - val_loss: 2.324815034866333 - val_accuracy: 0.4007 - penalty: 2e-05\n",
            "hidden layer sizes: [86, 42, 51, 89, 229], total units: 497\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.324887990951538 - val_accuracy: 0.4006 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 22, 30, 69, 192], total units: 378\n",
            "##########################################################\n",
            "Epoch 21/40\n",
            "loss: 2.4351658821105957 - accuracy: 0.37571999430656433 - val_loss: 2.3070290088653564 - val_accuracy: 0.4082 - penalty: 0.0003\n",
            "hidden layer sizes: [65, 22, 30, 69, 192], total units: 378\n",
            "##########################################################\n",
            "Epoch 22/40\n",
            "loss: 2.247250556945801 - accuracy: 0.41819998621940613 - val_loss: 2.2516579627990723 - val_accuracy: 0.4208 - penalty: 0.0003\n",
            "hidden layer sizes: [65, 22, 30, 69, 192], total units: 378\n",
            "##########################################################\n",
            "Epoch 23/40\n",
            "loss: 2.204677104949951 - accuracy: 0.4281199872493744 - val_loss: 2.234187364578247 - val_accuracy: 0.4233 - penalty: 0.0003\n",
            "hidden layer sizes: [65, 22, 30, 69, 192], total units: 378\n",
            "##########################################################\n",
            "Epoch 24/40\n",
            "loss: 2.170292377471924 - accuracy: 0.43643999099731445 - val_loss: 2.2272331714630127 - val_accuracy: 0.4238 - penalty: 0.0003\n",
            "hidden layer sizes: [65, 22, 30, 69, 192], total units: 378\n",
            "##########################################################\n",
            "Epoch 25/40\n",
            "loss: 2.1434452533721924 - accuracy: 0.44168001413345337 - val_loss: 2.2272729873657227 - val_accuracy: 0.4318 - penalty: 0.0003\n",
            "hidden layer sizes: [65, 22, 30, 69, 192], total units: 378\n",
            "##########################################################\n",
            "Epoch 26/40\n",
            "loss: 2.130378484725952 - accuracy: 0.4436599910259247 - val_loss: 2.200345993041992 - val_accuracy: 0.4335 - penalty: 0.0003\n",
            "hidden layer sizes: [65, 22, 30, 69, 192], total units: 378\n",
            "##########################################################\n",
            "Epoch 27/40\n",
            "loss: 2.108189105987549 - accuracy: 0.44797998666763306 - val_loss: 2.187831163406372 - val_accuracy: 0.4356 - penalty: 0.0003\n",
            "hidden layer sizes: [65, 22, 30, 69, 192], total units: 378\n",
            "##########################################################\n",
            "Epoch 28/40\n",
            "loss: 2.0991203784942627 - accuracy: 0.45118001103401184 - val_loss: 2.195319414138794 - val_accuracy: 0.4351 - penalty: 0.0003\n",
            "hidden layer sizes: [65, 22, 30, 69, 192], total units: 378\n",
            "##########################################################\n",
            "Epoch 29/40\n",
            "loss: 2.0845422744750977 - accuracy: 0.4521400034427643 - val_loss: 2.181373357772827 - val_accuracy: 0.4396 - penalty: 0.0003\n",
            "hidden layer sizes: [65, 22, 30, 69, 192], total units: 378\n",
            "##########################################################\n",
            "Epoch 30/40\n",
            "loss: 2.0667076110839844 - accuracy: 0.4589200019836426 - val_loss: 2.179814338684082 - val_accuracy: 0.4341 - penalty: 0.0003\n",
            "hidden layer sizes: [65, 22, 30, 69, 192], total units: 378\n",
            "##########################################################\n",
            "Epoch 31/40\n",
            "loss: 2.057358503341675 - accuracy: 0.4603999853134155 - val_loss: 2.175199508666992 - val_accuracy: 0.439 - penalty: 0.0003\n",
            "hidden layer sizes: [65, 22, 30, 69, 192], total units: 378\n",
            "##########################################################\n",
            "Epoch 32/40\n",
            "loss: 2.0431642532348633 - accuracy: 0.46487998962402344 - val_loss: 2.1732680797576904 - val_accuracy: 0.4407 - penalty: 0.0003\n",
            "hidden layer sizes: [65, 22, 30, 69, 192], total units: 378\n",
            "##########################################################\n",
            "Epoch 33/40\n",
            "loss: 2.0341010093688965 - accuracy: 0.4668000042438507 - val_loss: 2.1670939922332764 - val_accuracy: 0.4392 - penalty: 0.0003\n",
            "hidden layer sizes: [65, 22, 30, 69, 192], total units: 378\n",
            "##########################################################\n",
            "Epoch 34/40\n",
            "loss: 2.02524995803833 - accuracy: 0.46724000573158264 - val_loss: 2.1590991020202637 - val_accuracy: 0.443 - penalty: 0.0003\n",
            "hidden layer sizes: [65, 22, 30, 69, 192], total units: 378\n",
            "##########################################################\n",
            "Epoch 35/40\n",
            "loss: 2.0163354873657227 - accuracy: 0.46772000193595886 - val_loss: 2.155287027359009 - val_accuracy: 0.4453 - penalty: 0.0003\n",
            "hidden layer sizes: [65, 22, 30, 69, 192], total units: 378\n",
            "##########################################################\n",
            "Epoch 36/40\n",
            "loss: 2.007478713989258 - accuracy: 0.47095999121665955 - val_loss: 2.153005361557007 - val_accuracy: 0.4433 - penalty: 0.0003\n",
            "hidden layer sizes: [65, 22, 30, 69, 192], total units: 378\n",
            "##########################################################\n",
            "Epoch 37/40\n",
            "loss: 1.992067813873291 - accuracy: 0.47516000270843506 - val_loss: 2.153569221496582 - val_accuracy: 0.4443 - penalty: 0.0003\n",
            "hidden layer sizes: [65, 22, 30, 69, 192], total units: 378\n",
            "##########################################################\n",
            "Epoch 38/40\n",
            "loss: 1.986749529838562 - accuracy: 0.47745999693870544 - val_loss: 2.155888557434082 - val_accuracy: 0.4408 - penalty: 0.0003\n",
            "hidden layer sizes: [65, 22, 30, 69, 192], total units: 378\n",
            "##########################################################\n",
            "Epoch 39/40\n",
            "loss: 1.9789592027664185 - accuracy: 0.47600001096725464 - val_loss: 2.1501967906951904 - val_accuracy: 0.4462 - penalty: 0.0003\n",
            "hidden layer sizes: [65, 22, 30, 69, 192], total units: 378\n",
            "##########################################################\n",
            "Epoch 40/40\n",
            "loss: 1.968506097793579 - accuracy: 0.4803600013256073 - val_loss: 2.136007308959961 - val_accuracy: 0.4473 - penalty: 0.0003\n",
            "hidden layer sizes: [65, 22, 30, 69, 192], total units: 378\n",
            "CPU times: user 3min 45s, sys: 10.7 s, total: 3min 56s\n",
            "Wall time: 3min 24s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "model = get_convolutional_model(cifar100.X_train_norm, layer_sizes=[100, 100, 100, 100, 100], output_neurons=100)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "schedule = Schedule([StaticEpochNoRegularization()] * 40)\n",
        "history = model.fit(cifar100.X_train_norm, cifar100.y_train, optimizer, schedule=schedule, batch_size=batch_size, min_new_neurons=20, \n",
        "                    validation_data=(cifar100.X_test_norm, cifar100.y_test), growth_percentage=0.2, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fX8ZVAKHvyAC",
        "outputId": "9e96a56a-0d83-44ca-e257-c0ce143653cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/40\n",
            "loss: 4.093144416809082 - accuracy: 0.10444000363349915 - val_loss: 3.5877597332000732 - val_accuracy: 0.1695 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 2/40\n",
            "loss: 3.5509471893310547 - accuracy: 0.17734000086784363 - val_loss: 3.3745546340942383 - val_accuracy: 0.2068 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 3/40\n",
            "loss: 3.3132200241088867 - accuracy: 0.2185399979352951 - val_loss: 3.230602502822876 - val_accuracy: 0.2343 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 4/40\n",
            "loss: 3.1267311573028564 - accuracy: 0.25209999084472656 - val_loss: 3.146618604660034 - val_accuracy: 0.2497 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 5/40\n",
            "loss: 2.9712767601013184 - accuracy: 0.2757200002670288 - val_loss: 3.06219744682312 - val_accuracy: 0.2724 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 6/40\n",
            "loss: 2.841517210006714 - accuracy: 0.30504000186920166 - val_loss: 3.0268003940582275 - val_accuracy: 0.2734 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 7/40\n",
            "loss: 2.7088096141815186 - accuracy: 0.3288800120353699 - val_loss: 2.9531710147857666 - val_accuracy: 0.2868 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 8/40\n",
            "loss: 2.602051019668579 - accuracy: 0.3500399887561798 - val_loss: 2.9328532218933105 - val_accuracy: 0.2996 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 9/40\n",
            "loss: 2.4761648178100586 - accuracy: 0.3745200037956238 - val_loss: 2.90521240234375 - val_accuracy: 0.2989 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 10/40\n",
            "loss: 2.378119707107544 - accuracy: 0.3929600119590759 - val_loss: 2.839526891708374 - val_accuracy: 0.3175 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 11/40\n",
            "loss: 2.2850866317749023 - accuracy: 0.41449999809265137 - val_loss: 2.8312931060791016 - val_accuracy: 0.3173 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 12/40\n",
            "loss: 2.2020294666290283 - accuracy: 0.43334001302719116 - val_loss: 2.8465628623962402 - val_accuracy: 0.3187 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 13/40\n",
            "loss: 2.1204612255096436 - accuracy: 0.44576001167297363 - val_loss: 2.8165605068206787 - val_accuracy: 0.3275 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 14/40\n",
            "loss: 2.045520544052124 - accuracy: 0.46525999903678894 - val_loss: 2.819701910018921 - val_accuracy: 0.3286 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 15/40\n",
            "loss: 1.9876747131347656 - accuracy: 0.4756399989128113 - val_loss: 2.8230762481689453 - val_accuracy: 0.3352 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 16/40\n",
            "loss: 1.9153075218200684 - accuracy: 0.4908199906349182 - val_loss: 2.8425395488739014 - val_accuracy: 0.3299 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 17/40\n",
            "loss: 1.8502057790756226 - accuracy: 0.5035600066184998 - val_loss: 2.8201370239257812 - val_accuracy: 0.3384 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 18/40\n",
            "loss: 1.7879220247268677 - accuracy: 0.5180799961090088 - val_loss: 2.820145606994629 - val_accuracy: 0.3451 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 19/40\n",
            "loss: 1.7453948259353638 - accuracy: 0.5268200039863586 - val_loss: 2.8134822845458984 - val_accuracy: 0.344 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 20/40\n",
            "loss: 1.6867417097091675 - accuracy: 0.5396400094032288 - val_loss: 2.8155558109283447 - val_accuracy: 0.3502 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 21/40\n",
            "loss: 1.6359061002731323 - accuracy: 0.550059974193573 - val_loss: 2.8411266803741455 - val_accuracy: 0.3483 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 22/40\n",
            "loss: 1.5832855701446533 - accuracy: 0.5589799880981445 - val_loss: 2.844855785369873 - val_accuracy: 0.3471 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 23/40\n",
            "loss: 1.5352048873901367 - accuracy: 0.573639988899231 - val_loss: 2.825165271759033 - val_accuracy: 0.3578 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 24/40\n",
            "loss: 1.4830501079559326 - accuracy: 0.5834199786186218 - val_loss: 2.8390281200408936 - val_accuracy: 0.3607 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 25/40\n",
            "loss: 1.4496864080429077 - accuracy: 0.5894399881362915 - val_loss: 2.8349716663360596 - val_accuracy: 0.3602 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 26/40\n",
            "loss: 1.3939177989959717 - accuracy: 0.6014400124549866 - val_loss: 2.857475519180298 - val_accuracy: 0.3626 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 27/40\n",
            "loss: 1.3662701845169067 - accuracy: 0.6104999780654907 - val_loss: 2.9178318977355957 - val_accuracy: 0.363 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 28/40\n",
            "loss: 1.3191035985946655 - accuracy: 0.6208599805831909 - val_loss: 2.8764665126800537 - val_accuracy: 0.369 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 29/40\n",
            "loss: 1.2922358512878418 - accuracy: 0.6262800097465515 - val_loss: 2.8860788345336914 - val_accuracy: 0.3701 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 30/40\n",
            "loss: 1.264326810836792 - accuracy: 0.6347000002861023 - val_loss: 2.867021083831787 - val_accuracy: 0.3772 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 31/40\n",
            "loss: 1.223596215248108 - accuracy: 0.6435400247573853 - val_loss: 2.9213898181915283 - val_accuracy: 0.3762 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 32/40\n",
            "loss: 1.1902698278427124 - accuracy: 0.6511600017547607 - val_loss: 2.913163900375366 - val_accuracy: 0.375 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 33/40\n",
            "loss: 1.1548553705215454 - accuracy: 0.6582199931144714 - val_loss: 2.940594434738159 - val_accuracy: 0.3767 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 34/40\n",
            "loss: 1.1319019794464111 - accuracy: 0.6647599935531616 - val_loss: 2.952223539352417 - val_accuracy: 0.378 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 35/40\n",
            "loss: 1.1065906286239624 - accuracy: 0.6715400218963623 - val_loss: 2.974762201309204 - val_accuracy: 0.3813 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 36/40\n",
            "loss: 1.0926940441131592 - accuracy: 0.672819972038269 - val_loss: 2.9820520877838135 - val_accuracy: 0.3887 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 37/40\n",
            "loss: 1.0657235383987427 - accuracy: 0.6804199814796448 - val_loss: 3.0015652179718018 - val_accuracy: 0.3831 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 38/40\n",
            "loss: 1.0420825481414795 - accuracy: 0.6860799789428711 - val_loss: 2.9807722568511963 - val_accuracy: 0.3846 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 39/40\n",
            "loss: 1.020012378692627 - accuracy: 0.6930400133132935 - val_loss: 3.032221794128418 - val_accuracy: 0.3824 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 40/40\n",
            "loss: 0.9985306859016418 - accuracy: 0.6991199851036072 - val_loss: 3.0326249599456787 - val_accuracy: 0.3863 - penalty: 0.0\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "CPU times: user 2min 31s, sys: 6.26 s, total: 2min 37s\n",
            "Wall time: 2min 57s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Group sparsity regularization"
      ],
      "metadata": {
        "id": "tUXTGVvy2ThE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "model = get_convolutional_model(cifar100.X_train_norm, layer_sizes=[100, 100, 100, 100, 100], output_neurons=100)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "schedule = Schedule([DynamicEpoch(0.02, 'group_sparsity')] * 20 + [StaticEpochNoRegularization()] * 20)\n",
        "history = model.fit(cifar100.X_train_norm, cifar100.y_train, optimizer, schedule=schedule, batch_size=batch_size, min_new_neurons=20, \n",
        "                    validation_data=(cifar100.X_test_norm, cifar100.y_test), growth_percentage=0.2, verbose=True)"
      ],
      "metadata": {
        "id": "azdWpqXj059X",
        "outputId": "184ace91-83f6-432f-bf90-058691fd39ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.003042221069336 - val_accuracy: 0.008 - penalty: 0.02\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.003042221069336 - val_accuracy: 0.008 - penalty: 0.02\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "Before pruning:\n",
            "loss: 4.029178142547607 - accuracy: 0.10970000177621841 - val_loss: 3.575300455093384 - val_accuracy: 0.1791 - penalty: 0.02\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.5744481086730957 - val_accuracy: 0.1788 - penalty: 0.02\n",
            "hidden layer sizes: [100, 101, 106, 120, 120], total units: 547\n",
            "##########################################################\n",
            "Epoch 2/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.5744481086730957 - val_accuracy: 0.1788 - penalty: 0.02\n",
            "hidden layer sizes: [100, 101, 106, 120, 120], total units: 547\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.5744481086730957 - val_accuracy: 0.1788 - penalty: 0.02\n",
            "hidden layer sizes: [120, 121, 127, 144, 144], total units: 656\n",
            "Before pruning:\n",
            "loss: 3.5850369930267334 - accuracy: 0.1715400069952011 - val_loss: 3.4246394634246826 - val_accuracy: 0.1982 - penalty: 0.02\n",
            "hidden layer sizes: [120, 121, 127, 144, 144], total units: 656\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.4245622158050537 - val_accuracy: 0.1982 - penalty: 0.02\n",
            "hidden layer sizes: [100, 100, 100, 108, 143], total units: 551\n",
            "##########################################################\n",
            "Epoch 3/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.4245622158050537 - val_accuracy: 0.1982 - penalty: 0.02\n",
            "hidden layer sizes: [100, 100, 100, 108, 143], total units: 551\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.4245622158050537 - val_accuracy: 0.1982 - penalty: 0.02\n",
            "hidden layer sizes: [120, 120, 120, 129, 171], total units: 660\n",
            "Before pruning:\n",
            "loss: 3.4887402057647705 - accuracy: 0.18400000035762787 - val_loss: 3.4328551292419434 - val_accuracy: 0.1904 - penalty: 0.02\n",
            "hidden layer sizes: [120, 120, 120, 129, 171], total units: 660\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.4326093196868896 - val_accuracy: 0.1906 - penalty: 0.02\n",
            "hidden layer sizes: [100, 58, 28, 95, 171], total units: 452\n",
            "##########################################################\n",
            "Epoch 4/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.4326093196868896 - val_accuracy: 0.1906 - penalty: 0.02\n",
            "hidden layer sizes: [100, 58, 28, 95, 171], total units: 452\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.4326093196868896 - val_accuracy: 0.1906 - penalty: 0.02\n",
            "hidden layer sizes: [120, 78, 48, 115, 205], total units: 566\n",
            "Before pruning:\n",
            "loss: 3.4836347103118896 - accuracy: 0.18422000110149384 - val_loss: 3.4172234535217285 - val_accuracy: 0.2014 - penalty: 0.02\n",
            "hidden layer sizes: [120, 78, 48, 115, 205], total units: 566\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.4172823429107666 - val_accuracy: 0.2015 - penalty: 0.02\n",
            "hidden layer sizes: [80, 25, 17, 52, 205], total units: 379\n",
            "##########################################################\n",
            "Epoch 5/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.4172823429107666 - val_accuracy: 0.2015 - penalty: 0.02\n",
            "hidden layer sizes: [80, 25, 17, 52, 205], total units: 379\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.4172823429107666 - val_accuracy: 0.2015 - penalty: 0.02\n",
            "hidden layer sizes: [100, 45, 37, 72, 246], total units: 500\n",
            "Before pruning:\n",
            "loss: 3.4614033699035645 - accuracy: 0.1864600032567978 - val_loss: 3.4009687900543213 - val_accuracy: 0.1976 - penalty: 0.02\n",
            "hidden layer sizes: [100, 45, 37, 72, 246], total units: 500\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.4009792804718018 - val_accuracy: 0.1976 - penalty: 0.02\n",
            "hidden layer sizes: [49, 18, 13, 30, 246], total units: 356\n",
            "##########################################################\n",
            "Epoch 6/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.4009792804718018 - val_accuracy: 0.1976 - penalty: 0.02\n",
            "hidden layer sizes: [49, 18, 13, 30, 246], total units: 356\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.4009792804718018 - val_accuracy: 0.1976 - penalty: 0.02\n",
            "hidden layer sizes: [69, 38, 33, 50, 295], total units: 485\n",
            "Before pruning:\n",
            "loss: 3.449936866760254 - accuracy: 0.185139998793602 - val_loss: 3.3801093101501465 - val_accuracy: 0.2065 - penalty: 0.02\n",
            "hidden layer sizes: [69, 38, 33, 50, 295], total units: 485\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.380061626434326 - val_accuracy: 0.2067 - penalty: 0.02\n",
            "hidden layer sizes: [35, 16, 11, 26, 295], total units: 383\n",
            "##########################################################\n",
            "Epoch 7/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.380061626434326 - val_accuracy: 0.2067 - penalty: 0.02\n",
            "hidden layer sizes: [35, 16, 11, 26, 295], total units: 383\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.380061388015747 - val_accuracy: 0.2067 - penalty: 0.02\n",
            "hidden layer sizes: [55, 36, 31, 46, 354], total units: 522\n",
            "Before pruning:\n",
            "loss: 3.431992769241333 - accuracy: 0.18775999546051025 - val_loss: 3.3612453937530518 - val_accuracy: 0.2069 - penalty: 0.02\n",
            "hidden layer sizes: [55, 36, 31, 46, 354], total units: 522\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.36124324798584 - val_accuracy: 0.2069 - penalty: 0.02\n",
            "hidden layer sizes: [24, 13, 10, 22, 354], total units: 423\n",
            "##########################################################\n",
            "Epoch 8/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.36124324798584 - val_accuracy: 0.2069 - penalty: 0.02\n",
            "hidden layer sizes: [24, 13, 10, 22, 354], total units: 423\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.3612430095672607 - val_accuracy: 0.2069 - penalty: 0.02\n",
            "hidden layer sizes: [44, 33, 30, 42, 424], total units: 573\n",
            "Before pruning:\n",
            "loss: 3.425278425216675 - accuracy: 0.19050000607967377 - val_loss: 3.3454983234405518 - val_accuracy: 0.2098 - penalty: 0.02\n",
            "hidden layer sizes: [44, 33, 30, 42, 424], total units: 573\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.3456497192382812 - val_accuracy: 0.21 - penalty: 0.02\n",
            "hidden layer sizes: [20, 11, 9, 18, 422], total units: 480\n",
            "##########################################################\n",
            "Epoch 9/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.3456497192382812 - val_accuracy: 0.21 - penalty: 0.02\n",
            "hidden layer sizes: [20, 11, 9, 18, 422], total units: 480\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.3456497192382812 - val_accuracy: 0.21 - penalty: 0.02\n",
            "hidden layer sizes: [40, 31, 29, 38, 506], total units: 644\n",
            "Before pruning:\n",
            "loss: 3.4167916774749756 - accuracy: 0.1903800070285797 - val_loss: 3.345370292663574 - val_accuracy: 0.2104 - penalty: 0.02\n",
            "hidden layer sizes: [40, 31, 29, 38, 506], total units: 644\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.3453409671783447 - val_accuracy: 0.2104 - penalty: 0.02\n",
            "hidden layer sizes: [14, 11, 8, 17, 506], total units: 556\n",
            "##########################################################\n",
            "Epoch 10/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.3453409671783447 - val_accuracy: 0.2104 - penalty: 0.02\n",
            "hidden layer sizes: [14, 11, 8, 17, 506], total units: 556\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.3453409671783447 - val_accuracy: 0.2104 - penalty: 0.02\n",
            "hidden layer sizes: [34, 31, 28, 37, 607], total units: 737\n",
            "Before pruning:\n",
            "loss: 3.4067890644073486 - accuracy: 0.1932400017976761 - val_loss: 3.328718662261963 - val_accuracy: 0.2145 - penalty: 0.02\n",
            "hidden layer sizes: [34, 31, 28, 37, 607], total units: 737\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.32871413230896 - val_accuracy: 0.2145 - penalty: 0.02\n",
            "hidden layer sizes: [13, 10, 8, 17, 607], total units: 655\n",
            "##########################################################\n",
            "Epoch 11/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.32871413230896 - val_accuracy: 0.2145 - penalty: 0.02\n",
            "hidden layer sizes: [13, 10, 8, 17, 607], total units: 655\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.32871413230896 - val_accuracy: 0.2145 - penalty: 0.02\n",
            "hidden layer sizes: [33, 30, 28, 37, 728], total units: 856\n",
            "Before pruning:\n",
            "loss: 3.401761293411255 - accuracy: 0.1926800012588501 - val_loss: 3.3219094276428223 - val_accuracy: 0.2153 - penalty: 0.02\n",
            "hidden layer sizes: [33, 30, 28, 37, 728], total units: 856\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.321908950805664 - val_accuracy: 0.2153 - penalty: 0.02\n",
            "hidden layer sizes: [11, 9, 8, 16, 726], total units: 770\n",
            "##########################################################\n",
            "Epoch 12/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.321908950805664 - val_accuracy: 0.2153 - penalty: 0.02\n",
            "hidden layer sizes: [11, 9, 8, 16, 726], total units: 770\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.321908712387085 - val_accuracy: 0.2153 - penalty: 0.02\n",
            "hidden layer sizes: [31, 29, 28, 36, 871], total units: 995\n",
            "Before pruning:\n",
            "loss: 3.390019655227661 - accuracy: 0.19516000151634216 - val_loss: 3.3048648834228516 - val_accuracy: 0.2222 - penalty: 0.02\n",
            "hidden layer sizes: [31, 29, 28, 36, 871], total units: 995\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.304837465286255 - val_accuracy: 0.2221 - penalty: 0.02\n",
            "hidden layer sizes: [9, 9, 8, 16, 864], total units: 906\n",
            "##########################################################\n",
            "Epoch 13/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.304837465286255 - val_accuracy: 0.2221 - penalty: 0.02\n",
            "hidden layer sizes: [9, 9, 8, 16, 864], total units: 906\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.304837465286255 - val_accuracy: 0.2221 - penalty: 0.02\n",
            "hidden layer sizes: [29, 29, 28, 36, 1036], total units: 1158\n",
            "Before pruning:\n",
            "loss: 3.3840134143829346 - accuracy: 0.19762000441551208 - val_loss: 3.301370620727539 - val_accuracy: 0.2179 - penalty: 0.02\n",
            "hidden layer sizes: [29, 29, 28, 36, 1036], total units: 1158\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.3011457920074463 - val_accuracy: 0.2183 - penalty: 0.02\n",
            "hidden layer sizes: [8, 9, 8, 16, 997], total units: 1038\n",
            "##########################################################\n",
            "Epoch 14/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.3011457920074463 - val_accuracy: 0.2183 - penalty: 0.02\n",
            "hidden layer sizes: [8, 9, 8, 16, 997], total units: 1038\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.3011457920074463 - val_accuracy: 0.2183 - penalty: 0.02\n",
            "hidden layer sizes: [28, 29, 28, 36, 1196], total units: 1317\n",
            "Before pruning:\n",
            "loss: 3.3801543712615967 - accuracy: 0.19565999507904053 - val_loss: 3.301340341567993 - val_accuracy: 0.2183 - penalty: 0.02\n",
            "hidden layer sizes: [28, 29, 28, 36, 1196], total units: 1317\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.30096173286438 - val_accuracy: 0.2184 - penalty: 0.02\n",
            "hidden layer sizes: [7, 9, 8, 16, 1111], total units: 1151\n",
            "##########################################################\n",
            "Epoch 15/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.30096173286438 - val_accuracy: 0.2184 - penalty: 0.02\n",
            "hidden layer sizes: [7, 9, 8, 16, 1111], total units: 1151\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.30096173286438 - val_accuracy: 0.2184 - penalty: 0.02\n",
            "hidden layer sizes: [27, 29, 28, 36, 1333], total units: 1453\n",
            "Before pruning:\n",
            "loss: 3.3718442916870117 - accuracy: 0.19779999554157257 - val_loss: 3.285907506942749 - val_accuracy: 0.2222 - penalty: 0.02\n",
            "hidden layer sizes: [27, 29, 28, 36, 1333], total units: 1453\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.2855024337768555 - val_accuracy: 0.2216 - penalty: 0.02\n",
            "hidden layer sizes: [7, 9, 7, 16, 1183], total units: 1222\n",
            "##########################################################\n",
            "Epoch 16/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.2855024337768555 - val_accuracy: 0.2216 - penalty: 0.02\n",
            "hidden layer sizes: [7, 9, 7, 16, 1183], total units: 1222\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.2855024337768555 - val_accuracy: 0.2216 - penalty: 0.02\n",
            "hidden layer sizes: [27, 29, 27, 36, 1419], total units: 1538\n",
            "Before pruning:\n",
            "loss: 3.369953155517578 - accuracy: 0.19750000536441803 - val_loss: 3.2843894958496094 - val_accuracy: 0.2213 - penalty: 0.02\n",
            "hidden layer sizes: [27, 29, 27, 36, 1419], total units: 1538\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.283541679382324 - val_accuracy: 0.2217 - penalty: 0.02\n",
            "hidden layer sizes: [7, 9, 7, 16, 1176], total units: 1215\n",
            "##########################################################\n",
            "Epoch 17/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.283541679382324 - val_accuracy: 0.2217 - penalty: 0.02\n",
            "hidden layer sizes: [7, 9, 7, 16, 1176], total units: 1215\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.283541679382324 - val_accuracy: 0.2217 - penalty: 0.02\n",
            "hidden layer sizes: [27, 29, 27, 36, 1411], total units: 1530\n",
            "Before pruning:\n",
            "loss: 3.35902738571167 - accuracy: 0.19981999695301056 - val_loss: 3.2694549560546875 - val_accuracy: 0.222 - penalty: 0.02\n",
            "hidden layer sizes: [27, 29, 27, 36, 1411], total units: 1530\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.268895387649536 - val_accuracy: 0.2229 - penalty: 0.02\n",
            "hidden layer sizes: [7, 9, 7, 17, 1208], total units: 1248\n",
            "##########################################################\n",
            "Epoch 18/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.268895387649536 - val_accuracy: 0.2229 - penalty: 0.02\n",
            "hidden layer sizes: [7, 9, 7, 17, 1208], total units: 1248\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.268895387649536 - val_accuracy: 0.2229 - penalty: 0.02\n",
            "hidden layer sizes: [27, 29, 27, 37, 1449], total units: 1569\n",
            "Before pruning:\n",
            "loss: 3.355689764022827 - accuracy: 0.20051999390125275 - val_loss: 3.2504632472991943 - val_accuracy: 0.2293 - penalty: 0.02\n",
            "hidden layer sizes: [27, 29, 27, 37, 1449], total units: 1569\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.2495620250701904 - val_accuracy: 0.2301 - penalty: 0.02\n",
            "hidden layer sizes: [7, 9, 7, 15, 1200], total units: 1238\n",
            "##########################################################\n",
            "Epoch 19/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.2495620250701904 - val_accuracy: 0.2301 - penalty: 0.02\n",
            "hidden layer sizes: [7, 9, 7, 15, 1200], total units: 1238\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.2495620250701904 - val_accuracy: 0.2301 - penalty: 0.02\n",
            "hidden layer sizes: [27, 29, 27, 35, 1440], total units: 1558\n",
            "Before pruning:\n",
            "loss: 3.347182512283325 - accuracy: 0.20362000167369843 - val_loss: 3.2521913051605225 - val_accuracy: 0.227 - penalty: 0.02\n",
            "hidden layer sizes: [27, 29, 27, 35, 1440], total units: 1558\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.2512619495391846 - val_accuracy: 0.2273 - penalty: 0.02\n",
            "hidden layer sizes: [7, 8, 7, 15, 1175], total units: 1212\n",
            "##########################################################\n",
            "Epoch 20/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.2512619495391846 - val_accuracy: 0.2273 - penalty: 0.02\n",
            "hidden layer sizes: [7, 8, 7, 15, 1175], total units: 1212\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.2512619495391846 - val_accuracy: 0.2273 - penalty: 0.02\n",
            "hidden layer sizes: [27, 28, 27, 35, 1410], total units: 1527\n",
            "Before pruning:\n",
            "loss: 3.3403244018554688 - accuracy: 0.2046400010585785 - val_loss: 3.252157688140869 - val_accuracy: 0.2269 - penalty: 0.02\n",
            "hidden layer sizes: [27, 28, 27, 35, 1410], total units: 1527\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.251176595687866 - val_accuracy: 0.2277 - penalty: 0.02\n",
            "hidden layer sizes: [7, 8, 7, 16, 1153], total units: 1191\n",
            "##########################################################\n",
            "Epoch 21/40\n",
            "loss: 3.3331093788146973 - accuracy: 0.20535999536514282 - val_loss: 3.167559862136841 - val_accuracy: 0.2393 - penalty: 0.0\n",
            "hidden layer sizes: [7, 8, 7, 16, 1153], total units: 1191\n",
            "##########################################################\n",
            "Epoch 22/40\n",
            "loss: 3.1809468269348145 - accuracy: 0.23615999519824982 - val_loss: 3.116870641708374 - val_accuracy: 0.2531 - penalty: 0.0\n",
            "hidden layer sizes: [7, 8, 7, 16, 1153], total units: 1191\n",
            "##########################################################\n",
            "Epoch 23/40\n",
            "loss: 3.129483699798584 - accuracy: 0.24583999812602997 - val_loss: 3.078681230545044 - val_accuracy: 0.2591 - penalty: 0.0\n",
            "hidden layer sizes: [7, 8, 7, 16, 1153], total units: 1191\n",
            "##########################################################\n",
            "Epoch 24/40\n",
            "loss: 3.0900700092315674 - accuracy: 0.2528199851512909 - val_loss: 3.056767463684082 - val_accuracy: 0.2675 - penalty: 0.0\n",
            "hidden layer sizes: [7, 8, 7, 16, 1153], total units: 1191\n",
            "##########################################################\n",
            "Epoch 25/40\n",
            "loss: 3.062069892883301 - accuracy: 0.25870001316070557 - val_loss: 3.038723945617676 - val_accuracy: 0.2689 - penalty: 0.0\n",
            "hidden layer sizes: [7, 8, 7, 16, 1153], total units: 1191\n",
            "##########################################################\n",
            "Epoch 26/40\n",
            "loss: 3.035173177719116 - accuracy: 0.26423999667167664 - val_loss: 3.0142202377319336 - val_accuracy: 0.2721 - penalty: 0.0\n",
            "hidden layer sizes: [7, 8, 7, 16, 1153], total units: 1191\n",
            "##########################################################\n",
            "Epoch 27/40\n",
            "loss: 3.0123510360717773 - accuracy: 0.26684001088142395 - val_loss: 2.9895713329315186 - val_accuracy: 0.2805 - penalty: 0.0\n",
            "hidden layer sizes: [7, 8, 7, 16, 1153], total units: 1191\n",
            "##########################################################\n",
            "Epoch 28/40\n",
            "loss: 2.987640380859375 - accuracy: 0.27035999298095703 - val_loss: 2.974994421005249 - val_accuracy: 0.2837 - penalty: 0.0\n",
            "hidden layer sizes: [7, 8, 7, 16, 1153], total units: 1191\n",
            "##########################################################\n",
            "Epoch 29/40\n",
            "loss: 2.9657249450683594 - accuracy: 0.2760399878025055 - val_loss: 2.9611363410949707 - val_accuracy: 0.2834 - penalty: 0.0\n",
            "hidden layer sizes: [7, 8, 7, 16, 1153], total units: 1191\n",
            "##########################################################\n",
            "Epoch 30/40\n",
            "loss: 2.939772844314575 - accuracy: 0.28242000937461853 - val_loss: 2.9413931369781494 - val_accuracy: 0.2903 - penalty: 0.0\n",
            "hidden layer sizes: [7, 8, 7, 16, 1153], total units: 1191\n",
            "##########################################################\n",
            "Epoch 31/40\n",
            "loss: 2.9221463203430176 - accuracy: 0.28446000814437866 - val_loss: 2.9296436309814453 - val_accuracy: 0.2941 - penalty: 0.0\n",
            "hidden layer sizes: [7, 8, 7, 16, 1153], total units: 1191\n",
            "##########################################################\n",
            "Epoch 32/40\n",
            "loss: 2.9108541011810303 - accuracy: 0.2865000069141388 - val_loss: 2.9205715656280518 - val_accuracy: 0.2891 - penalty: 0.0\n",
            "hidden layer sizes: [7, 8, 7, 16, 1153], total units: 1191\n",
            "##########################################################\n",
            "Epoch 33/40\n",
            "loss: 2.891430377960205 - accuracy: 0.2880200147628784 - val_loss: 2.904930591583252 - val_accuracy: 0.297 - penalty: 0.0\n",
            "hidden layer sizes: [7, 8, 7, 16, 1153], total units: 1191\n",
            "##########################################################\n",
            "Epoch 34/40\n",
            "loss: 2.876587152481079 - accuracy: 0.29396000504493713 - val_loss: 2.8850600719451904 - val_accuracy: 0.3001 - penalty: 0.0\n",
            "hidden layer sizes: [7, 8, 7, 16, 1153], total units: 1191\n",
            "##########################################################\n",
            "Epoch 35/40\n",
            "loss: 2.8626794815063477 - accuracy: 0.2955799996852875 - val_loss: 2.8764700889587402 - val_accuracy: 0.2994 - penalty: 0.0\n",
            "hidden layer sizes: [7, 8, 7, 16, 1153], total units: 1191\n",
            "##########################################################\n",
            "Epoch 36/40\n",
            "loss: 2.843937397003174 - accuracy: 0.3005000054836273 - val_loss: 2.8635787963867188 - val_accuracy: 0.3023 - penalty: 0.0\n",
            "hidden layer sizes: [7, 8, 7, 16, 1153], total units: 1191\n",
            "##########################################################\n",
            "Epoch 37/40\n",
            "loss: 2.826692819595337 - accuracy: 0.30278000235557556 - val_loss: 2.8468003273010254 - val_accuracy: 0.3058 - penalty: 0.0\n",
            "hidden layer sizes: [7, 8, 7, 16, 1153], total units: 1191\n",
            "##########################################################\n",
            "Epoch 38/40\n",
            "loss: 2.816483736038208 - accuracy: 0.30559998750686646 - val_loss: 2.836378812789917 - val_accuracy: 0.3087 - penalty: 0.0\n",
            "hidden layer sizes: [7, 8, 7, 16, 1153], total units: 1191\n",
            "##########################################################\n",
            "Epoch 39/40\n",
            "loss: 2.797224998474121 - accuracy: 0.3089199960231781 - val_loss: 2.823944091796875 - val_accuracy: 0.3072 - penalty: 0.0\n",
            "hidden layer sizes: [7, 8, 7, 16, 1153], total units: 1191\n",
            "##########################################################\n",
            "Epoch 40/40\n",
            "loss: 2.7863078117370605 - accuracy: 0.3087800145149231 - val_loss: 2.8140463829040527 - val_accuracy: 0.3159 - penalty: 0.0\n",
            "hidden layer sizes: [7, 8, 7, 16, 1153], total units: 1191\n",
            "CPU times: user 3min 29s, sys: 8.91 s, total: 3min 38s\n",
            "Wall time: 2min 59s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test - Tiny ImageNet"
      ],
      "metadata": {
        "id": "Vygd6mHvNv_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tiny_imagenet = get_tiny_imagenet_dataset()"
      ],
      "metadata": {
        "id": "1CAsBOpLNvZe",
        "outputId": "32d78ba1-f59a-4c57-aa20-e9e4b119000f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing the downloaded dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "model = get_convolutional_model(tiny_imagenet.X_train_norm, regularization_penalty=0.00002, regularization_method='weighted_l1', layer_sizes=[100, 100, 100, 100, 100], output_neurons=200)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "schedule = Schedule([EpochType.DYNAMIC] * 20 + [EpochType.STATIC_NO_REGULARIZATION] * 20)\n",
        "history = model.fit(tiny_imagenet.X_train_norm, tiny_imagenet.y_train, optimizer, schedule=schedule, batch_size=batch_size, min_new_neurons=20, \n",
        "                    validation_data=(tiny_imagenet.X_test_norm, tiny_imagenet.y_test), growth_percentage=0.2, verbose=True)"
      ],
      "metadata": {
        "id": "H80AY3X4N2DX",
        "outputId": "9ac29291-6331-4596-9107-197bcca57758",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-440bc3691363>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\nbatch_size = 64\\n\\nmodel = get_convolutional_model(tiny_imagenet.X_train_norm, regularization_penalty=0.01, regularization_method='weighted_l1', layer_sizes=[100, 100, 100, 100, 100], output_neurons=200)\\n\\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\\n\\nschedule = Schedule([EpochType.DYNAMIC] * 20 + [EpochType.STATIC_NO_REGULARIZATION] * 20)\\nhistory = model.fit(tiny_imagenet.X_train_norm, tiny_imagenet.y_train, optimizer, schedule=schedule, batch_size=batch_size, min_new_neurons=20, \\n                    validation_data=(tiny_imagenet.X_test_norm, tiny_imagenet.y_test), growth_percentage=0.2, verbose=True)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tiny_imagenet' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "model = get_convolutional_model(tiny_imagenet.X_train_norm, regularization_penalty=0.00002, regularization_method='weighted_l1', layer_sizes=[100, 100, 100, 100, 100, 100], output_neurons=200)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "schedule = Schedule([EpochType.DYNAMIC] * 20 + [EpochType.STATIC_NO_REGULARIZATION] * 20)\n",
        "history = model.fit(tiny_imagenet.X_train_norm, tiny_imagenet.y_train, optimizer, schedule=schedule, batch_size=batch_size, min_new_neurons=20, \n",
        "                    validation_data=(tiny_imagenet.X_test_norm, tiny_imagenet.y_test), growth_percentage=0.2, verbose=True)"
      ],
      "metadata": {
        "id": "yoG8HJqrQCGJ",
        "outputId": "fb54e119-e23a-4449-dd29-ec57c79d67fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.5959930419921875 - val_accuracy: 0.0045 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100, 100], total units: 600\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.595992565155029 - val_accuracy: 0.0045 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120, 120], total units: 720\n",
            "Before pruning:\n",
            "loss: 4.2364702224731445 - accuracy: 0.10057999938726425 - val_loss: 5.51335334777832 - val_accuracy: 0.0425 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120, 120], total units: 720\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 5.513298511505127 - val_accuracy: 0.0425 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100, 119], total units: 619\n",
            "##########################################################\n",
            "Epoch 2/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.513298511505127 - val_accuracy: 0.0425 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100, 119], total units: 619\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.513298511505127 - val_accuracy: 0.0425 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120, 142], total units: 742\n",
            "Before pruning:\n",
            "loss: 3.9836063385009766 - accuracy: 0.125 - val_loss: 5.222326755523682 - val_accuracy: 0.0508 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120, 142], total units: 742\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 5.2217488288879395 - val_accuracy: 0.0508 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 43, 47, 50, 61, 142], total units: 443\n",
            "##########################################################\n",
            "Epoch 3/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.2217488288879395 - val_accuracy: 0.0508 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 43, 47, 50, 61, 142], total units: 443\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.2217488288879395 - val_accuracy: 0.0508 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 63, 67, 70, 81, 170], total units: 571\n",
            "Before pruning:\n",
            "loss: 3.8026347160339355 - accuracy: 0.15259000658988953 - val_loss: 5.248560905456543 - val_accuracy: 0.0657 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 63, 67, 70, 81, 170], total units: 571\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 5.248408317565918 - val_accuracy: 0.0656 - penalty: 2e-05\n",
            "hidden layer sizes: [98, 28, 36, 36, 52, 170], total units: 420\n",
            "##########################################################\n",
            "Epoch 4/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.248408317565918 - val_accuracy: 0.0656 - penalty: 2e-05\n",
            "hidden layer sizes: [98, 28, 36, 36, 52, 170], total units: 420\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.248408317565918 - val_accuracy: 0.0656 - penalty: 2e-05\n",
            "hidden layer sizes: [118, 48, 56, 56, 72, 204], total units: 554\n",
            "Before pruning:\n",
            "loss: 3.6943037509918213 - accuracy: 0.17026999592781067 - val_loss: 5.177611351013184 - val_accuracy: 0.0727 - penalty: 2e-05\n",
            "hidden layer sizes: [118, 48, 56, 56, 72, 204], total units: 554\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 5.17764949798584 - val_accuracy: 0.0727 - penalty: 2e-05\n",
            "hidden layer sizes: [94, 19, 33, 33, 43, 202], total units: 424\n",
            "##########################################################\n",
            "Epoch 5/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.17764949798584 - val_accuracy: 0.0727 - penalty: 2e-05\n",
            "hidden layer sizes: [94, 19, 33, 33, 43, 202], total units: 424\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.17764949798584 - val_accuracy: 0.0727 - penalty: 2e-05\n",
            "hidden layer sizes: [114, 39, 53, 53, 63, 242], total units: 564\n",
            "Before pruning:\n",
            "loss: 3.588411569595337 - accuracy: 0.18467000126838684 - val_loss: 4.949895858764648 - val_accuracy: 0.086 - penalty: 2e-05\n",
            "hidden layer sizes: [114, 39, 53, 53, 63, 242], total units: 564\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.949367523193359 - val_accuracy: 0.0858 - penalty: 2e-05\n",
            "hidden layer sizes: [83, 17, 31, 32, 42, 230], total units: 435\n",
            "##########################################################\n",
            "Epoch 6/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.949367523193359 - val_accuracy: 0.0858 - penalty: 2e-05\n",
            "hidden layer sizes: [83, 17, 31, 32, 42, 230], total units: 435\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.949367523193359 - val_accuracy: 0.0858 - penalty: 2e-05\n",
            "hidden layer sizes: [103, 37, 51, 52, 62, 276], total units: 581\n",
            "Before pruning:\n",
            "loss: 3.4980480670928955 - accuracy: 0.20090000331401825 - val_loss: 4.8700995445251465 - val_accuracy: 0.0919 - penalty: 2e-05\n",
            "hidden layer sizes: [103, 37, 51, 52, 62, 276], total units: 581\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.870863914489746 - val_accuracy: 0.0917 - penalty: 2e-05\n",
            "hidden layer sizes: [78, 13, 30, 29, 43, 253], total units: 446\n",
            "##########################################################\n",
            "Epoch 7/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.870863914489746 - val_accuracy: 0.0917 - penalty: 2e-05\n",
            "hidden layer sizes: [78, 13, 30, 29, 43, 253], total units: 446\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.870863437652588 - val_accuracy: 0.0917 - penalty: 2e-05\n",
            "hidden layer sizes: [98, 33, 50, 49, 63, 303], total units: 596\n",
            "Before pruning:\n",
            "loss: 3.4179205894470215 - accuracy: 0.2171899974346161 - val_loss: 4.872628688812256 - val_accuracy: 0.0907 - penalty: 2e-05\n",
            "hidden layer sizes: [98, 33, 50, 49, 63, 303], total units: 596\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.877327919006348 - val_accuracy: 0.0905 - penalty: 2e-05\n",
            "hidden layer sizes: [76, 12, 29, 29, 44, 268], total units: 458\n",
            "##########################################################\n",
            "Epoch 8/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.877327919006348 - val_accuracy: 0.0905 - penalty: 2e-05\n",
            "hidden layer sizes: [76, 12, 29, 29, 44, 268], total units: 458\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.877327919006348 - val_accuracy: 0.0905 - penalty: 2e-05\n",
            "hidden layer sizes: [96, 32, 49, 49, 64, 321], total units: 611\n",
            "Before pruning:\n",
            "loss: 3.348052740097046 - accuracy: 0.2263299971818924 - val_loss: 4.677910804748535 - val_accuracy: 0.1057 - penalty: 2e-05\n",
            "hidden layer sizes: [96, 32, 49, 49, 64, 321], total units: 611\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.676393985748291 - val_accuracy: 0.1057 - penalty: 2e-05\n",
            "hidden layer sizes: [72, 12, 23, 29, 47, 275], total units: 458\n",
            "##########################################################\n",
            "Epoch 9/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.676393985748291 - val_accuracy: 0.1057 - penalty: 2e-05\n",
            "hidden layer sizes: [72, 12, 23, 29, 47, 275], total units: 458\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.676393032073975 - val_accuracy: 0.1057 - penalty: 2e-05\n",
            "hidden layer sizes: [92, 32, 43, 49, 67, 330], total units: 613\n",
            "Before pruning:\n",
            "loss: 3.305297613143921 - accuracy: 0.23485000431537628 - val_loss: 4.7039947509765625 - val_accuracy: 0.1085 - penalty: 2e-05\n",
            "hidden layer sizes: [92, 32, 43, 49, 67, 330], total units: 613\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.702571392059326 - val_accuracy: 0.108 - penalty: 2e-05\n",
            "hidden layer sizes: [69, 12, 23, 27, 48, 279], total units: 458\n",
            "##########################################################\n",
            "Epoch 10/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.702571392059326 - val_accuracy: 0.108 - penalty: 2e-05\n",
            "hidden layer sizes: [69, 12, 23, 27, 48, 279], total units: 458\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.702570915222168 - val_accuracy: 0.108 - penalty: 2e-05\n",
            "hidden layer sizes: [89, 32, 43, 47, 68, 334], total units: 613\n",
            "Before pruning:\n",
            "loss: 3.2751314640045166 - accuracy: 0.23899999260902405 - val_loss: 4.709865570068359 - val_accuracy: 0.1004 - penalty: 2e-05\n",
            "hidden layer sizes: [89, 32, 43, 47, 68, 334], total units: 613\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.713339805603027 - val_accuracy: 0.1001 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 12, 19, 26, 47, 280], total units: 449\n",
            "##########################################################\n",
            "Epoch 11/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.713339805603027 - val_accuracy: 0.1001 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 12, 19, 26, 47, 280], total units: 449\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.7133402824401855 - val_accuracy: 0.1001 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 32, 39, 46, 67, 336], total units: 605\n",
            "Before pruning:\n",
            "loss: 3.2538254261016846 - accuracy: 0.2426699995994568 - val_loss: 4.618536949157715 - val_accuracy: 0.1163 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 32, 39, 46, 67, 336], total units: 605\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.617951393127441 - val_accuracy: 0.1163 - penalty: 2e-05\n",
            "hidden layer sizes: [62, 12, 19, 24, 50, 282], total units: 449\n",
            "##########################################################\n",
            "Epoch 12/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.617951393127441 - val_accuracy: 0.1163 - penalty: 2e-05\n",
            "hidden layer sizes: [62, 12, 19, 24, 50, 282], total units: 449\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.6179518699646 - val_accuracy: 0.1163 - penalty: 2e-05\n",
            "hidden layer sizes: [82, 32, 39, 44, 70, 338], total units: 605\n",
            "Before pruning:\n",
            "loss: 3.2335433959960938 - accuracy: 0.24652999639511108 - val_loss: 4.62014627456665 - val_accuracy: 0.111 - penalty: 2e-05\n",
            "hidden layer sizes: [82, 32, 39, 44, 70, 338], total units: 605\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.61890983581543 - val_accuracy: 0.1111 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 12, 19, 23, 54, 285], total units: 453\n",
            "##########################################################\n",
            "Epoch 13/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.61890983581543 - val_accuracy: 0.1111 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 12, 19, 23, 54, 285], total units: 453\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.61890983581543 - val_accuracy: 0.1111 - penalty: 2e-05\n",
            "hidden layer sizes: [80, 32, 39, 43, 74, 342], total units: 610\n",
            "Before pruning:\n",
            "loss: 3.218733072280884 - accuracy: 0.24887000024318695 - val_loss: 4.599867820739746 - val_accuracy: 0.1137 - penalty: 2e-05\n",
            "hidden layer sizes: [80, 32, 39, 43, 74, 342], total units: 610\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.59977912902832 - val_accuracy: 0.1141 - penalty: 2e-05\n",
            "hidden layer sizes: [59, 12, 19, 23, 54, 288], total units: 455\n",
            "##########################################################\n",
            "Epoch 14/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.59977912902832 - val_accuracy: 0.1141 - penalty: 2e-05\n",
            "hidden layer sizes: [59, 12, 19, 23, 54, 288], total units: 455\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.599778652191162 - val_accuracy: 0.1141 - penalty: 2e-05\n",
            "hidden layer sizes: [79, 32, 39, 43, 74, 345], total units: 612\n",
            "Before pruning:\n",
            "loss: 3.1965866088867188 - accuracy: 0.25345999002456665 - val_loss: 4.605402946472168 - val_accuracy: 0.1158 - penalty: 2e-05\n",
            "hidden layer sizes: [79, 32, 39, 43, 74, 345], total units: 612\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.606936931610107 - val_accuracy: 0.1155 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 12, 18, 22, 62, 289], total units: 460\n",
            "##########################################################\n",
            "Epoch 15/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.606936931610107 - val_accuracy: 0.1155 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 12, 18, 22, 62, 289], total units: 460\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.60693883895874 - val_accuracy: 0.1155 - penalty: 2e-05\n",
            "hidden layer sizes: [77, 32, 38, 42, 82, 346], total units: 617\n",
            "Before pruning:\n",
            "loss: 3.1872897148132324 - accuracy: 0.2539600133895874 - val_loss: 4.585208892822266 - val_accuracy: 0.1295 - penalty: 2e-05\n",
            "hidden layer sizes: [77, 32, 38, 42, 82, 346], total units: 617\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.58690881729126 - val_accuracy: 0.1296 - penalty: 2e-05\n",
            "hidden layer sizes: [54, 12, 18, 20, 64, 289], total units: 457\n",
            "##########################################################\n",
            "Epoch 16/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.58690881729126 - val_accuracy: 0.1296 - penalty: 2e-05\n",
            "hidden layer sizes: [54, 12, 18, 20, 64, 289], total units: 457\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.58690881729126 - val_accuracy: 0.1296 - penalty: 2e-05\n",
            "hidden layer sizes: [74, 32, 38, 40, 84, 346], total units: 614\n",
            "Before pruning:\n",
            "loss: 3.1750500202178955 - accuracy: 0.2567000091075897 - val_loss: 4.663158893585205 - val_accuracy: 0.1113 - penalty: 2e-05\n",
            "hidden layer sizes: [74, 32, 38, 40, 84, 346], total units: 614\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.6615705490112305 - val_accuracy: 0.1114 - penalty: 2e-05\n",
            "hidden layer sizes: [53, 12, 18, 20, 65, 295], total units: 463\n",
            "##########################################################\n",
            "Epoch 17/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.6615705490112305 - val_accuracy: 0.1114 - penalty: 2e-05\n",
            "hidden layer sizes: [53, 12, 18, 20, 65, 295], total units: 463\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.6615705490112305 - val_accuracy: 0.1114 - penalty: 2e-05\n",
            "hidden layer sizes: [73, 32, 38, 40, 85, 354], total units: 622\n",
            "Before pruning:\n",
            "loss: 3.164978504180908 - accuracy: 0.2594200074672699 - val_loss: 4.54873514175415 - val_accuracy: 0.1128 - penalty: 2e-05\n",
            "hidden layer sizes: [73, 32, 38, 40, 85, 354], total units: 622\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.550144672393799 - val_accuracy: 0.1128 - penalty: 2e-05\n",
            "hidden layer sizes: [53, 12, 17, 20, 70, 294], total units: 466\n",
            "##########################################################\n",
            "Epoch 18/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.550144672393799 - val_accuracy: 0.1128 - penalty: 2e-05\n",
            "hidden layer sizes: [53, 12, 17, 20, 70, 294], total units: 466\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.550145149230957 - val_accuracy: 0.1128 - penalty: 2e-05\n",
            "hidden layer sizes: [73, 32, 37, 40, 90, 352], total units: 624\n",
            "Before pruning:\n",
            "loss: 3.1537792682647705 - accuracy: 0.26249000430107117 - val_loss: 4.470035552978516 - val_accuracy: 0.122 - penalty: 2e-05\n",
            "hidden layer sizes: [73, 32, 37, 40, 90, 352], total units: 624\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.469884872436523 - val_accuracy: 0.1218 - penalty: 2e-05\n",
            "hidden layer sizes: [52, 12, 17, 19, 75, 296], total units: 471\n",
            "##########################################################\n",
            "Epoch 19/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.469884872436523 - val_accuracy: 0.1218 - penalty: 2e-05\n",
            "hidden layer sizes: [52, 12, 17, 19, 75, 296], total units: 471\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.469882965087891 - val_accuracy: 0.1218 - penalty: 2e-05\n",
            "hidden layer sizes: [72, 32, 37, 39, 95, 355], total units: 630\n",
            "Before pruning:\n",
            "loss: 3.1405065059661865 - accuracy: 0.2605000138282776 - val_loss: 4.593721389770508 - val_accuracy: 0.1247 - penalty: 2e-05\n",
            "hidden layer sizes: [72, 32, 37, 39, 95, 355], total units: 630\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.592445373535156 - val_accuracy: 0.1245 - penalty: 2e-05\n",
            "hidden layer sizes: [51, 12, 17, 19, 80, 297], total units: 476\n",
            "##########################################################\n",
            "Epoch 20/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.592445373535156 - val_accuracy: 0.1245 - penalty: 2e-05\n",
            "hidden layer sizes: [51, 12, 17, 19, 80, 297], total units: 476\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.592445373535156 - val_accuracy: 0.1245 - penalty: 2e-05\n",
            "hidden layer sizes: [71, 32, 37, 39, 100, 356], total units: 635\n",
            "Before pruning:\n",
            "loss: 3.1361820697784424 - accuracy: 0.2635599970817566 - val_loss: 4.444351673126221 - val_accuracy: 0.1205 - penalty: 2e-05\n",
            "hidden layer sizes: [71, 32, 37, 39, 100, 356], total units: 635\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.448339939117432 - val_accuracy: 0.1207 - penalty: 2e-05\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 21/40\n",
            "loss: 3.2385036945343018 - accuracy: 0.25856998562812805 - val_loss: 4.675017833709717 - val_accuracy: 0.1341 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 22/40\n",
            "loss: 2.901371479034424 - accuracy: 0.31407999992370605 - val_loss: 4.477153301239014 - val_accuracy: 0.1406 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 23/40\n",
            "loss: 2.7937018871307373 - accuracy: 0.33491000533103943 - val_loss: 4.307125568389893 - val_accuracy: 0.1534 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 24/40\n",
            "loss: 2.7058706283569336 - accuracy: 0.35078999400138855 - val_loss: 4.195457935333252 - val_accuracy: 0.1592 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 25/40\n",
            "loss: 2.626380681991577 - accuracy: 0.36733999848365784 - val_loss: 4.189493179321289 - val_accuracy: 0.1655 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 26/40\n",
            "loss: 2.5610861778259277 - accuracy: 0.3808799982070923 - val_loss: 4.13769006729126 - val_accuracy: 0.166 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 27/40\n",
            "loss: 2.49271821975708 - accuracy: 0.39118000864982605 - val_loss: 4.070734977722168 - val_accuracy: 0.1794 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 28/40\n",
            "loss: 2.429917335510254 - accuracy: 0.4063299894332886 - val_loss: 4.240698337554932 - val_accuracy: 0.1679 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 29/40\n",
            "loss: 2.3660051822662354 - accuracy: 0.4180299937725067 - val_loss: 4.168391704559326 - val_accuracy: 0.1801 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 30/40\n",
            "loss: 2.3107657432556152 - accuracy: 0.4284299910068512 - val_loss: 4.167135715484619 - val_accuracy: 0.1876 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 31/40\n",
            "loss: 2.2578744888305664 - accuracy: 0.4378400146961212 - val_loss: 4.233453750610352 - val_accuracy: 0.1816 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 32/40\n",
            "loss: 2.2084429264068604 - accuracy: 0.4487900137901306 - val_loss: 4.278738498687744 - val_accuracy: 0.1769 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 33/40\n",
            "loss: 2.1649351119995117 - accuracy: 0.45598000288009644 - val_loss: 4.2091546058654785 - val_accuracy: 0.1806 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 34/40\n",
            "loss: 2.1106207370758057 - accuracy: 0.46682998538017273 - val_loss: 4.1878662109375 - val_accuracy: 0.1862 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 35/40\n",
            "loss: 2.068870782852173 - accuracy: 0.476500004529953 - val_loss: 4.354595184326172 - val_accuracy: 0.1839 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 36/40\n",
            "loss: 2.0263774394989014 - accuracy: 0.4835300147533417 - val_loss: 4.214017391204834 - val_accuracy: 0.1896 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 37/40\n",
            "loss: 1.987017035484314 - accuracy: 0.4923500120639801 - val_loss: 4.226319313049316 - val_accuracy: 0.192 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 38/40\n",
            "loss: 1.9549823999404907 - accuracy: 0.4997600018978119 - val_loss: 4.336300849914551 - val_accuracy: 0.191 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 39/40\n",
            "loss: 1.9157605171203613 - accuracy: 0.5044999718666077 - val_loss: 4.289840221405029 - val_accuracy: 0.1865 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 40/40\n",
            "loss: 1.8856204748153687 - accuracy: 0.5110700130462646 - val_loss: 4.220312118530273 - val_accuracy: 0.1977 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "CPU times: user 14min 56s, sys: 32.2 s, total: 15min 28s\n",
            "Wall time: 11min 52s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "model = get_convolutional_model(tiny_imagenet.X_train_norm, regularization_penalty=0.0002, regularization_method='l1', layer_sizes=[48, 12, 17, 19, 77, 296], output_neurons=200)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "schedule = Schedule([EpochType.STATIC_WITH_REGULARIZATION] * 40)\n",
        "history = model.fit(tiny_imagenet.X_train_norm, tiny_imagenet.y_train, optimizer, schedule=schedule, batch_size=batch_size, min_new_neurons=20, \n",
        "                    validation_data=(tiny_imagenet.X_test_norm, tiny_imagenet.y_test), growth_percentage=0.2, verbose=True)"
      ],
      "metadata": {
        "id": "hrAjQ6H-VWrl",
        "outputId": "16bf485b-f619-443e-bf4f-c57a302c3841",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/40\n",
            "loss: 4.289374828338623 - accuracy: 0.09640000015497208 - val_loss: 5.259166717529297 - val_accuracy: 0.0573 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 2/40\n",
            "loss: 3.8369767665863037 - accuracy: 0.15317000448703766 - val_loss: 5.067516803741455 - val_accuracy: 0.0667 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 3/40\n",
            "loss: 3.6995861530303955 - accuracy: 0.17618000507354736 - val_loss: 5.2216477394104 - val_accuracy: 0.0671 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 4/40\n",
            "loss: 3.60565185546875 - accuracy: 0.18990999460220337 - val_loss: 4.899083614349365 - val_accuracy: 0.0808 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 5/40\n",
            "loss: 3.5238840579986572 - accuracy: 0.20287999510765076 - val_loss: 4.834376335144043 - val_accuracy: 0.086 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 6/40\n",
            "loss: 3.459003210067749 - accuracy: 0.2132200002670288 - val_loss: 4.847607612609863 - val_accuracy: 0.0867 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 7/40\n",
            "loss: 3.402411460876465 - accuracy: 0.22452999651432037 - val_loss: 4.803019046783447 - val_accuracy: 0.0926 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 8/40\n",
            "loss: 3.3482375144958496 - accuracy: 0.23319999873638153 - val_loss: 4.777381896972656 - val_accuracy: 0.0977 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 9/40\n",
            "loss: 3.30110239982605 - accuracy: 0.24003000557422638 - val_loss: 4.626590728759766 - val_accuracy: 0.1006 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 10/40\n",
            "loss: 3.260195016860962 - accuracy: 0.2469100058078766 - val_loss: 4.699289798736572 - val_accuracy: 0.1005 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 11/40\n",
            "loss: 3.2248644828796387 - accuracy: 0.25492000579833984 - val_loss: 4.491023063659668 - val_accuracy: 0.1135 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 12/40\n",
            "loss: 3.1932740211486816 - accuracy: 0.2579199969768524 - val_loss: 4.5923919677734375 - val_accuracy: 0.1099 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 13/40\n",
            "loss: 3.1649274826049805 - accuracy: 0.26499998569488525 - val_loss: 4.645729064941406 - val_accuracy: 0.1101 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 14/40\n",
            "loss: 3.130465030670166 - accuracy: 0.2681800127029419 - val_loss: 4.574737548828125 - val_accuracy: 0.1122 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 15/40\n",
            "loss: 3.0999701023101807 - accuracy: 0.2746700048446655 - val_loss: 4.467548370361328 - val_accuracy: 0.1249 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 16/40\n",
            "loss: 3.074228525161743 - accuracy: 0.27970999479293823 - val_loss: 4.457192420959473 - val_accuracy: 0.1248 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 17/40\n",
            "loss: 3.045534133911133 - accuracy: 0.2812199890613556 - val_loss: 4.466061115264893 - val_accuracy: 0.1311 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 18/40\n",
            "loss: 3.019561290740967 - accuracy: 0.2888599932193756 - val_loss: 4.410892009735107 - val_accuracy: 0.1339 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 19/40\n",
            "loss: 2.998582601547241 - accuracy: 0.29322001338005066 - val_loss: 4.194242000579834 - val_accuracy: 0.1464 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 20/40\n",
            "loss: 2.9674808979034424 - accuracy: 0.29774001240730286 - val_loss: 4.367214679718018 - val_accuracy: 0.1365 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 21/40\n",
            "loss: 2.9520633220672607 - accuracy: 0.3009600043296814 - val_loss: 4.281967639923096 - val_accuracy: 0.1405 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 22/40\n",
            "loss: 2.9310302734375 - accuracy: 0.30351999402046204 - val_loss: 4.3452301025390625 - val_accuracy: 0.1348 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 23/40\n",
            "loss: 2.908107280731201 - accuracy: 0.3084999918937683 - val_loss: 4.2326812744140625 - val_accuracy: 0.1524 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 24/40\n",
            "loss: 2.8914859294891357 - accuracy: 0.31286999583244324 - val_loss: 4.2467522621154785 - val_accuracy: 0.1455 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 25/40\n",
            "loss: 2.8705663681030273 - accuracy: 0.31415000557899475 - val_loss: 4.385305404663086 - val_accuracy: 0.1429 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 26/40\n",
            "loss: 2.8557422161102295 - accuracy: 0.3197999894618988 - val_loss: 4.311227798461914 - val_accuracy: 0.139 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 27/40\n",
            "loss: 2.8361141681671143 - accuracy: 0.32315999269485474 - val_loss: 4.178327560424805 - val_accuracy: 0.1569 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 28/40\n",
            "loss: 2.8190102577209473 - accuracy: 0.3243899941444397 - val_loss: 4.193903923034668 - val_accuracy: 0.1533 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 29/40\n",
            "loss: 2.8055028915405273 - accuracy: 0.3278200030326843 - val_loss: 4.239876747131348 - val_accuracy: 0.1537 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 30/40\n",
            "loss: 2.7928719520568848 - accuracy: 0.3301999866962433 - val_loss: 3.9878180027008057 - val_accuracy: 0.1678 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 31/40\n",
            "loss: 2.7682790756225586 - accuracy: 0.335099995136261 - val_loss: 4.3836469650268555 - val_accuracy: 0.1458 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 32/40\n",
            "loss: 2.756039619445801 - accuracy: 0.3376399874687195 - val_loss: 4.302917003631592 - val_accuracy: 0.1493 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 33/40\n",
            "loss: 2.7415318489074707 - accuracy: 0.3402099907398224 - val_loss: 4.184179782867432 - val_accuracy: 0.1605 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 34/40\n",
            "loss: 2.7327420711517334 - accuracy: 0.3403100073337555 - val_loss: 4.139418601989746 - val_accuracy: 0.162 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 35/40\n",
            "loss: 2.7128171920776367 - accuracy: 0.34544000029563904 - val_loss: 4.196424961090088 - val_accuracy: 0.1646 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 36/40\n",
            "loss: 2.7044472694396973 - accuracy: 0.34810999035835266 - val_loss: 4.131458282470703 - val_accuracy: 0.1672 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 37/40\n",
            "loss: 2.687086820602417 - accuracy: 0.3508799970149994 - val_loss: 4.093888759613037 - val_accuracy: 0.1667 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 38/40\n",
            "loss: 2.680232286453247 - accuracy: 0.3506399989128113 - val_loss: 4.165778636932373 - val_accuracy: 0.1628 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 39/40\n",
            "loss: 2.66850209236145 - accuracy: 0.3550499975681305 - val_loss: 4.108555316925049 - val_accuracy: 0.1672 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 40/40\n",
            "loss: 2.6607143878936768 - accuracy: 0.35482001304626465 - val_loss: 4.253663063049316 - val_accuracy: 0.1547 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "CPU times: user 10min 27s, sys: 27.5 s, total: 10min 55s\n",
            "Wall time: 7min 51s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "model = get_convolutional_model(tiny_imagenet.X_train_norm, regularization_penalty=0.00002, regularization_method='weighted_l1', layer_sizes=[100, 100, 100, 100, 100, 100], output_neurons=200)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "schedule = Schedule([EpochType.DYNAMIC] * 30 + [EpochType.STATIC_NO_REGULARIZATION] * 30)\n",
        "history = model.fit(tiny_imagenet.X_train_norm, tiny_imagenet.y_train, optimizer, schedule=schedule, batch_size=batch_size, min_new_neurons=20, \n",
        "                    validation_data=(tiny_imagenet.X_test_norm, tiny_imagenet.y_test), growth_percentage=0.2, verbose=True)"
      ],
      "metadata": {
        "id": "8qmYxbHKYtU0",
        "outputId": "7b83133b-bb9d-4a5b-af97-7b8018e4dbb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.558587074279785 - val_accuracy: 0.0039 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100, 100], total units: 600\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.558587074279785 - val_accuracy: 0.0039 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120, 120], total units: 720\n",
            "Before pruning:\n",
            "loss: 4.259202003479004 - accuracy: 0.09923999756574631 - val_loss: 5.461585998535156 - val_accuracy: 0.0431 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120, 120], total units: 720\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 5.461586952209473 - val_accuracy: 0.0431 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100, 120], total units: 620\n",
            "##########################################################\n",
            "Epoch 2/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.461586952209473 - val_accuracy: 0.0431 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100, 120], total units: 620\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.461587429046631 - val_accuracy: 0.0431 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120, 144], total units: 744\n",
            "Before pruning:\n",
            "loss: 4.006210803985596 - accuracy: 0.12343999743461609 - val_loss: 5.379511833190918 - val_accuracy: 0.0494 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120, 144], total units: 744\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 5.379067420959473 - val_accuracy: 0.0497 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 39, 50, 59, 53, 144], total units: 445\n",
            "##########################################################\n",
            "Epoch 3/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.379067420959473 - val_accuracy: 0.0497 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 39, 50, 59, 53, 144], total units: 445\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.379067420959473 - val_accuracy: 0.0497 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 59, 70, 79, 73, 172], total units: 573\n",
            "Before pruning:\n",
            "loss: 3.8631763458251953 - accuracy: 0.14459000527858734 - val_loss: 5.364109516143799 - val_accuracy: 0.0652 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 59, 70, 79, 73, 172], total units: 573\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 5.363754749298096 - val_accuracy: 0.0651 - penalty: 2e-05\n",
            "hidden layer sizes: [94, 26, 37, 37, 41, 172], total units: 407\n",
            "##########################################################\n",
            "Epoch 4/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.363754749298096 - val_accuracy: 0.0651 - penalty: 2e-05\n",
            "hidden layer sizes: [94, 26, 37, 37, 41, 172], total units: 407\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.363755702972412 - val_accuracy: 0.0651 - penalty: 2e-05\n",
            "hidden layer sizes: [114, 46, 57, 57, 61, 206], total units: 541\n",
            "Before pruning:\n",
            "loss: 3.692729949951172 - accuracy: 0.17177000641822815 - val_loss: 5.078550338745117 - val_accuracy: 0.0753 - penalty: 2e-05\n",
            "hidden layer sizes: [114, 46, 57, 57, 61, 206], total units: 541\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 5.078652858734131 - val_accuracy: 0.0753 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 21, 32, 30, 36, 206], total units: 410\n",
            "##########################################################\n",
            "Epoch 5/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.078652858734131 - val_accuracy: 0.0753 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 21, 32, 30, 36, 206], total units: 410\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.078653335571289 - val_accuracy: 0.0753 - penalty: 2e-05\n",
            "hidden layer sizes: [105, 41, 52, 50, 56, 247], total units: 551\n",
            "Before pruning:\n",
            "loss: 3.5581905841827393 - accuracy: 0.19235999882221222 - val_loss: 4.81392240524292 - val_accuracy: 0.0862 - penalty: 2e-05\n",
            "hidden layer sizes: [105, 41, 52, 50, 56, 247], total units: 551\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.814635753631592 - val_accuracy: 0.0862 - penalty: 2e-05\n",
            "hidden layer sizes: [82, 16, 29, 28, 36, 244], total units: 435\n",
            "##########################################################\n",
            "Epoch 6/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.814635753631592 - val_accuracy: 0.0862 - penalty: 2e-05\n",
            "hidden layer sizes: [82, 16, 29, 28, 36, 244], total units: 435\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.814635753631592 - val_accuracy: 0.0862 - penalty: 2e-05\n",
            "hidden layer sizes: [102, 36, 49, 48, 56, 292], total units: 583\n",
            "Before pruning:\n",
            "loss: 3.47798490524292 - accuracy: 0.20427000522613525 - val_loss: 4.86498498916626 - val_accuracy: 0.0925 - penalty: 2e-05\n",
            "hidden layer sizes: [102, 36, 49, 48, 56, 292], total units: 583\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.866534233093262 - val_accuracy: 0.0921 - penalty: 2e-05\n",
            "hidden layer sizes: [81, 14, 28, 28, 38, 264], total units: 453\n",
            "##########################################################\n",
            "Epoch 7/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.866534233093262 - val_accuracy: 0.0921 - penalty: 2e-05\n",
            "hidden layer sizes: [81, 14, 28, 28, 38, 264], total units: 453\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.866535663604736 - val_accuracy: 0.0921 - penalty: 2e-05\n",
            "hidden layer sizes: [101, 34, 48, 48, 58, 316], total units: 605\n",
            "Before pruning:\n",
            "loss: 3.4082205295562744 - accuracy: 0.22022999823093414 - val_loss: 4.894439697265625 - val_accuracy: 0.0945 - penalty: 2e-05\n",
            "hidden layer sizes: [101, 34, 48, 48, 58, 316], total units: 605\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.8976945877075195 - val_accuracy: 0.0944 - penalty: 2e-05\n",
            "hidden layer sizes: [73, 12, 26, 28, 37, 269], total units: 445\n",
            "##########################################################\n",
            "Epoch 8/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.8976945877075195 - val_accuracy: 0.0944 - penalty: 2e-05\n",
            "hidden layer sizes: [73, 12, 26, 28, 37, 269], total units: 445\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.8976945877075195 - val_accuracy: 0.0944 - penalty: 2e-05\n",
            "hidden layer sizes: [93, 32, 46, 48, 57, 322], total units: 598\n",
            "Before pruning:\n",
            "loss: 3.365553855895996 - accuracy: 0.2243099957704544 - val_loss: 4.737705230712891 - val_accuracy: 0.0998 - penalty: 2e-05\n",
            "hidden layer sizes: [93, 32, 46, 48, 57, 322], total units: 598\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.742293357849121 - val_accuracy: 0.0991 - penalty: 2e-05\n",
            "hidden layer sizes: [70, 12, 25, 27, 38, 293], total units: 465\n",
            "##########################################################\n",
            "Epoch 9/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.742293357849121 - val_accuracy: 0.0991 - penalty: 2e-05\n",
            "hidden layer sizes: [70, 12, 25, 27, 38, 293], total units: 465\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.742292881011963 - val_accuracy: 0.0991 - penalty: 2e-05\n",
            "hidden layer sizes: [90, 32, 45, 47, 58, 351], total units: 623\n",
            "Before pruning:\n",
            "loss: 3.33231258392334 - accuracy: 0.2311200052499771 - val_loss: 4.76254415512085 - val_accuracy: 0.0977 - penalty: 2e-05\n",
            "hidden layer sizes: [90, 32, 45, 47, 58, 351], total units: 623\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.767833232879639 - val_accuracy: 0.0976 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 12, 24, 27, 41, 303], total units: 471\n",
            "##########################################################\n",
            "Epoch 10/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.767833232879639 - val_accuracy: 0.0976 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 12, 24, 27, 41, 303], total units: 471\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.7678327560424805 - val_accuracy: 0.0976 - penalty: 2e-05\n",
            "hidden layer sizes: [84, 32, 44, 47, 61, 363], total units: 631\n",
            "Before pruning:\n",
            "loss: 3.310650587081909 - accuracy: 0.23478999733924866 - val_loss: 4.630008697509766 - val_accuracy: 0.1082 - penalty: 2e-05\n",
            "hidden layer sizes: [84, 32, 44, 47, 61, 363], total units: 631\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.633068084716797 - val_accuracy: 0.1081 - penalty: 2e-05\n",
            "hidden layer sizes: [63, 12, 23, 26, 41, 303], total units: 468\n",
            "##########################################################\n",
            "Epoch 11/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.633068084716797 - val_accuracy: 0.1081 - penalty: 2e-05\n",
            "hidden layer sizes: [63, 12, 23, 26, 41, 303], total units: 468\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.6330671310424805 - val_accuracy: 0.1081 - penalty: 2e-05\n",
            "hidden layer sizes: [83, 32, 43, 46, 61, 363], total units: 628\n",
            "Before pruning:\n",
            "loss: 3.286367177963257 - accuracy: 0.23921999335289001 - val_loss: 4.6422576904296875 - val_accuracy: 0.1148 - penalty: 2e-05\n",
            "hidden layer sizes: [83, 32, 43, 46, 61, 363], total units: 628\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.643834590911865 - val_accuracy: 0.1147 - penalty: 2e-05\n",
            "hidden layer sizes: [58, 12, 22, 26, 38, 310], total units: 466\n",
            "##########################################################\n",
            "Epoch 12/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.643834590911865 - val_accuracy: 0.1147 - penalty: 2e-05\n",
            "hidden layer sizes: [58, 12, 22, 26, 38, 310], total units: 466\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.643834114074707 - val_accuracy: 0.1147 - penalty: 2e-05\n",
            "hidden layer sizes: [78, 32, 42, 46, 58, 372], total units: 628\n",
            "Before pruning:\n",
            "loss: 3.263369083404541 - accuracy: 0.24083000421524048 - val_loss: 4.669174671173096 - val_accuracy: 0.1121 - penalty: 2e-05\n",
            "hidden layer sizes: [78, 32, 42, 46, 58, 372], total units: 628\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.6701273918151855 - val_accuracy: 0.1124 - penalty: 2e-05\n",
            "hidden layer sizes: [55, 12, 22, 26, 37, 312], total units: 464\n",
            "##########################################################\n",
            "Epoch 13/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.6701273918151855 - val_accuracy: 0.1124 - penalty: 2e-05\n",
            "hidden layer sizes: [55, 12, 22, 26, 37, 312], total units: 464\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.6701273918151855 - val_accuracy: 0.1124 - penalty: 2e-05\n",
            "hidden layer sizes: [75, 32, 42, 46, 57, 374], total units: 626\n",
            "Before pruning:\n",
            "loss: 3.2436869144439697 - accuracy: 0.24498000741004944 - val_loss: 4.692123889923096 - val_accuracy: 0.1103 - penalty: 2e-05\n",
            "hidden layer sizes: [75, 32, 42, 46, 57, 374], total units: 626\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.697523593902588 - val_accuracy: 0.1102 - penalty: 2e-05\n",
            "hidden layer sizes: [54, 11, 20, 24, 43, 310], total units: 462\n",
            "##########################################################\n",
            "Epoch 14/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.697523593902588 - val_accuracy: 0.1102 - penalty: 2e-05\n",
            "hidden layer sizes: [54, 11, 20, 24, 43, 310], total units: 462\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.697523593902588 - val_accuracy: 0.1102 - penalty: 2e-05\n",
            "hidden layer sizes: [74, 31, 40, 44, 63, 372], total units: 624\n",
            "Before pruning:\n",
            "loss: 3.2276315689086914 - accuracy: 0.24922999739646912 - val_loss: 4.64387321472168 - val_accuracy: 0.1104 - penalty: 2e-05\n",
            "hidden layer sizes: [74, 31, 40, 44, 63, 372], total units: 624\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.643736839294434 - val_accuracy: 0.111 - penalty: 2e-05\n",
            "hidden layer sizes: [49, 11, 20, 24, 41, 311], total units: 456\n",
            "##########################################################\n",
            "Epoch 15/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.643736839294434 - val_accuracy: 0.111 - penalty: 2e-05\n",
            "hidden layer sizes: [49, 11, 20, 24, 41, 311], total units: 456\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.643735885620117 - val_accuracy: 0.111 - penalty: 2e-05\n",
            "hidden layer sizes: [69, 31, 40, 44, 61, 373], total units: 618\n",
            "Before pruning:\n",
            "loss: 3.21506404876709 - accuracy: 0.250110000371933 - val_loss: 4.574548244476318 - val_accuracy: 0.1112 - penalty: 2e-05\n",
            "hidden layer sizes: [69, 31, 40, 44, 61, 373], total units: 618\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.577556133270264 - val_accuracy: 0.1108 - penalty: 2e-05\n",
            "hidden layer sizes: [48, 11, 20, 24, 48, 313], total units: 464\n",
            "##########################################################\n",
            "Epoch 16/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.577556133270264 - val_accuracy: 0.1108 - penalty: 2e-05\n",
            "hidden layer sizes: [48, 11, 20, 24, 48, 313], total units: 464\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.577556610107422 - val_accuracy: 0.1108 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 31, 40, 44, 68, 375], total units: 626\n",
            "Before pruning:\n",
            "loss: 3.2011561393737793 - accuracy: 0.25146999955177307 - val_loss: 4.4906463623046875 - val_accuracy: 0.1111 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 31, 40, 44, 68, 375], total units: 626\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.49276876449585 - val_accuracy: 0.111 - penalty: 2e-05\n",
            "hidden layer sizes: [47, 11, 19, 23, 45, 311], total units: 456\n",
            "##########################################################\n",
            "Epoch 17/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.49276876449585 - val_accuracy: 0.111 - penalty: 2e-05\n",
            "hidden layer sizes: [47, 11, 19, 23, 45, 311], total units: 456\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.492769241333008 - val_accuracy: 0.111 - penalty: 2e-05\n",
            "hidden layer sizes: [67, 31, 39, 43, 65, 373], total units: 618\n",
            "Before pruning:\n",
            "loss: 3.1900646686553955 - accuracy: 0.25356999039649963 - val_loss: 4.582438945770264 - val_accuracy: 0.1138 - penalty: 2e-05\n",
            "hidden layer sizes: [67, 31, 39, 43, 65, 373], total units: 618\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.590993404388428 - val_accuracy: 0.114 - penalty: 2e-05\n",
            "hidden layer sizes: [46, 11, 19, 22, 47, 310], total units: 455\n",
            "##########################################################\n",
            "Epoch 18/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.590993404388428 - val_accuracy: 0.114 - penalty: 2e-05\n",
            "hidden layer sizes: [46, 11, 19, 22, 47, 310], total units: 455\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.5909929275512695 - val_accuracy: 0.114 - penalty: 2e-05\n",
            "hidden layer sizes: [66, 31, 39, 42, 67, 372], total units: 617\n",
            "Before pruning:\n",
            "loss: 3.1736769676208496 - accuracy: 0.2573400139808655 - val_loss: 4.658469200134277 - val_accuracy: 0.1158 - penalty: 2e-05\n",
            "hidden layer sizes: [66, 31, 39, 42, 67, 372], total units: 617\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.662522315979004 - val_accuracy: 0.1162 - penalty: 2e-05\n",
            "hidden layer sizes: [45, 11, 19, 21, 49, 310], total units: 455\n",
            "##########################################################\n",
            "Epoch 19/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.662522315979004 - val_accuracy: 0.1162 - penalty: 2e-05\n",
            "hidden layer sizes: [45, 11, 19, 21, 49, 310], total units: 455\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.662522315979004 - val_accuracy: 0.1162 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 31, 39, 41, 69, 372], total units: 617\n",
            "Before pruning:\n",
            "loss: 3.155961036682129 - accuracy: 0.26017001271247864 - val_loss: 4.634313583374023 - val_accuracy: 0.1186 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 31, 39, 41, 69, 372], total units: 617\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.637068748474121 - val_accuracy: 0.1185 - penalty: 2e-05\n",
            "hidden layer sizes: [45, 11, 19, 21, 52, 310], total units: 458\n",
            "##########################################################\n",
            "Epoch 20/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.637068748474121 - val_accuracy: 0.1185 - penalty: 2e-05\n",
            "hidden layer sizes: [45, 11, 19, 21, 52, 310], total units: 458\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.637068748474121 - val_accuracy: 0.1185 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 31, 39, 41, 72, 372], total units: 620\n",
            "Before pruning:\n",
            "loss: 3.1518542766571045 - accuracy: 0.2615399956703186 - val_loss: 4.631877422332764 - val_accuracy: 0.1127 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 31, 39, 41, 72, 372], total units: 620\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.631044387817383 - val_accuracy: 0.1125 - penalty: 2e-05\n",
            "hidden layer sizes: [45, 11, 19, 20, 53, 311], total units: 459\n",
            "##########################################################\n",
            "Epoch 21/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.631044387817383 - val_accuracy: 0.1125 - penalty: 2e-05\n",
            "hidden layer sizes: [45, 11, 19, 20, 53, 311], total units: 459\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.631043910980225 - val_accuracy: 0.1125 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 31, 39, 40, 73, 373], total units: 621\n",
            "Before pruning:\n",
            "loss: 3.1324663162231445 - accuracy: 0.2641499936580658 - val_loss: 4.635553359985352 - val_accuracy: 0.1119 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 31, 39, 40, 73, 373], total units: 621\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.6361799240112305 - val_accuracy: 0.1116 - penalty: 2e-05\n",
            "hidden layer sizes: [44, 11, 19, 20, 59, 310], total units: 463\n",
            "##########################################################\n",
            "Epoch 22/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.6361799240112305 - val_accuracy: 0.1116 - penalty: 2e-05\n",
            "hidden layer sizes: [44, 11, 19, 20, 59, 310], total units: 463\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.636180400848389 - val_accuracy: 0.1116 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 31, 39, 40, 79, 372], total units: 625\n",
            "Before pruning:\n",
            "loss: 3.1299192905426025 - accuracy: 0.26298999786376953 - val_loss: 4.561365127563477 - val_accuracy: 0.1167 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 31, 39, 40, 79, 372], total units: 625\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.561691761016846 - val_accuracy: 0.1165 - penalty: 2e-05\n",
            "hidden layer sizes: [44, 11, 19, 20, 57, 311], total units: 462\n",
            "##########################################################\n",
            "Epoch 23/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.561691761016846 - val_accuracy: 0.1165 - penalty: 2e-05\n",
            "hidden layer sizes: [44, 11, 19, 20, 57, 311], total units: 462\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.561690807342529 - val_accuracy: 0.1165 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 31, 39, 40, 77, 373], total units: 624\n",
            "Before pruning:\n",
            "loss: 3.1130590438842773 - accuracy: 0.2670300006866455 - val_loss: 4.419095516204834 - val_accuracy: 0.1283 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 31, 39, 40, 77, 373], total units: 624\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.418542385101318 - val_accuracy: 0.1284 - penalty: 2e-05\n",
            "hidden layer sizes: [44, 11, 19, 21, 58, 310], total units: 463\n",
            "##########################################################\n",
            "Epoch 24/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.418542385101318 - val_accuracy: 0.1284 - penalty: 2e-05\n",
            "hidden layer sizes: [44, 11, 19, 21, 58, 310], total units: 463\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.418542385101318 - val_accuracy: 0.1284 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 31, 39, 41, 78, 372], total units: 625\n",
            "Before pruning:\n",
            "loss: 3.110564708709717 - accuracy: 0.2662599980831146 - val_loss: 4.538193702697754 - val_accuracy: 0.1189 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 31, 39, 41, 78, 372], total units: 625\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.537871837615967 - val_accuracy: 0.119 - penalty: 2e-05\n",
            "hidden layer sizes: [42, 11, 19, 20, 70, 310], total units: 472\n",
            "##########################################################\n",
            "Epoch 25/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.537871837615967 - val_accuracy: 0.119 - penalty: 2e-05\n",
            "hidden layer sizes: [42, 11, 19, 20, 70, 310], total units: 472\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.537872314453125 - val_accuracy: 0.119 - penalty: 2e-05\n",
            "hidden layer sizes: [62, 31, 39, 40, 90, 372], total units: 634\n",
            "Before pruning:\n",
            "loss: 3.1038835048675537 - accuracy: 0.2688699960708618 - val_loss: 4.484906196594238 - val_accuracy: 0.1188 - penalty: 2e-05\n",
            "hidden layer sizes: [62, 31, 39, 40, 90, 372], total units: 634\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.485731601715088 - val_accuracy: 0.1184 - penalty: 2e-05\n",
            "hidden layer sizes: [40, 11, 19, 20, 69, 310], total units: 469\n",
            "##########################################################\n",
            "Epoch 26/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.485731601715088 - val_accuracy: 0.1184 - penalty: 2e-05\n",
            "hidden layer sizes: [40, 11, 19, 20, 69, 310], total units: 469\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.48573112487793 - val_accuracy: 0.1184 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 31, 39, 40, 89, 372], total units: 631\n",
            "Before pruning:\n",
            "loss: 3.0965993404388428 - accuracy: 0.26996999979019165 - val_loss: 4.733083724975586 - val_accuracy: 0.1106 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 31, 39, 40, 89, 372], total units: 631\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.734499931335449 - val_accuracy: 0.1108 - penalty: 2e-05\n",
            "hidden layer sizes: [39, 11, 19, 20, 69, 310], total units: 468\n",
            "##########################################################\n",
            "Epoch 27/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.734499931335449 - val_accuracy: 0.1108 - penalty: 2e-05\n",
            "hidden layer sizes: [39, 11, 19, 20, 69, 310], total units: 468\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.734496116638184 - val_accuracy: 0.1108 - penalty: 2e-05\n",
            "hidden layer sizes: [59, 31, 39, 40, 89, 372], total units: 630\n",
            "Before pruning:\n",
            "loss: 3.090688705444336 - accuracy: 0.2708300054073334 - val_loss: 4.537006378173828 - val_accuracy: 0.1185 - penalty: 2e-05\n",
            "hidden layer sizes: [59, 31, 39, 40, 89, 372], total units: 630\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.53663444519043 - val_accuracy: 0.1186 - penalty: 2e-05\n",
            "hidden layer sizes: [37, 11, 19, 21, 77, 310], total units: 475\n",
            "##########################################################\n",
            "Epoch 28/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.53663444519043 - val_accuracy: 0.1186 - penalty: 2e-05\n",
            "hidden layer sizes: [37, 11, 19, 21, 77, 310], total units: 475\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.536634922027588 - val_accuracy: 0.1186 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 31, 39, 41, 97, 372], total units: 637\n",
            "Before pruning:\n",
            "loss: 3.0844531059265137 - accuracy: 0.271340012550354 - val_loss: 4.629306793212891 - val_accuracy: 0.122 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 31, 39, 41, 97, 372], total units: 637\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.629480361938477 - val_accuracy: 0.122 - penalty: 2e-05\n",
            "hidden layer sizes: [37, 11, 19, 20, 80, 310], total units: 477\n",
            "##########################################################\n",
            "Epoch 29/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.629480361938477 - val_accuracy: 0.122 - penalty: 2e-05\n",
            "hidden layer sizes: [37, 11, 19, 20, 80, 310], total units: 477\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.629480838775635 - val_accuracy: 0.122 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 31, 39, 40, 100, 372], total units: 639\n",
            "Before pruning:\n",
            "loss: 3.0737996101379395 - accuracy: 0.2743400037288666 - val_loss: 4.715211868286133 - val_accuracy: 0.1143 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 31, 39, 40, 100, 372], total units: 639\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.716190338134766 - val_accuracy: 0.1142 - penalty: 2e-05\n",
            "hidden layer sizes: [37, 11, 19, 20, 84, 310], total units: 481\n",
            "##########################################################\n",
            "Epoch 30/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.716190338134766 - val_accuracy: 0.1142 - penalty: 2e-05\n",
            "hidden layer sizes: [37, 11, 19, 20, 84, 310], total units: 481\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.716190338134766 - val_accuracy: 0.1142 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 31, 39, 40, 104, 372], total units: 643\n",
            "Before pruning:\n",
            "loss: 3.0703158378601074 - accuracy: 0.2745800018310547 - val_loss: 4.6840081214904785 - val_accuracy: 0.122 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 31, 39, 40, 104, 372], total units: 643\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.683945178985596 - val_accuracy: 0.122 - penalty: 2e-05\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 31/60\n",
            "loss: 3.246882915496826 - accuracy: 0.2618100047111511 - val_loss: 4.479153156280518 - val_accuracy: 0.1352 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 32/60\n",
            "loss: 2.8623321056365967 - accuracy: 0.31922000646591187 - val_loss: 4.317714214324951 - val_accuracy: 0.146 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 33/60\n",
            "loss: 2.7526612281799316 - accuracy: 0.3427099883556366 - val_loss: 4.496099948883057 - val_accuracy: 0.145 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 34/60\n",
            "loss: 2.673252820968628 - accuracy: 0.35728999972343445 - val_loss: 4.141044616699219 - val_accuracy: 0.1593 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 35/60\n",
            "loss: 2.59960675239563 - accuracy: 0.37338000535964966 - val_loss: 4.354245185852051 - val_accuracy: 0.1604 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 36/60\n",
            "loss: 2.5359416007995605 - accuracy: 0.3843800127506256 - val_loss: 4.224964618682861 - val_accuracy: 0.1638 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 37/60\n",
            "loss: 2.474172592163086 - accuracy: 0.397379994392395 - val_loss: 4.361893177032471 - val_accuracy: 0.164 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 38/60\n",
            "loss: 2.420325994491577 - accuracy: 0.4077700078487396 - val_loss: 4.305993556976318 - val_accuracy: 0.1627 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 39/60\n",
            "loss: 2.357571601867676 - accuracy: 0.42118000984191895 - val_loss: 4.3974432945251465 - val_accuracy: 0.1579 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 40/60\n",
            "loss: 2.304961919784546 - accuracy: 0.4298900067806244 - val_loss: 4.188836097717285 - val_accuracy: 0.1749 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 41/60\n",
            "loss: 2.2541866302490234 - accuracy: 0.43904000520706177 - val_loss: 4.527584552764893 - val_accuracy: 0.1581 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 42/60\n",
            "loss: 2.215261697769165 - accuracy: 0.44749999046325684 - val_loss: 4.317127227783203 - val_accuracy: 0.1701 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 43/60\n",
            "loss: 2.1589598655700684 - accuracy: 0.45837000012397766 - val_loss: 4.334264755249023 - val_accuracy: 0.1722 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 44/60\n",
            "loss: 2.1167445182800293 - accuracy: 0.4648300111293793 - val_loss: 4.464268207550049 - val_accuracy: 0.1681 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 45/60\n",
            "loss: 2.0733606815338135 - accuracy: 0.4750699996948242 - val_loss: 4.329155921936035 - val_accuracy: 0.1731 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 46/60\n",
            "loss: 2.0307810306549072 - accuracy: 0.48107001185417175 - val_loss: 4.524293422698975 - val_accuracy: 0.169 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 47/60\n",
            "loss: 1.9967544078826904 - accuracy: 0.4906499981880188 - val_loss: 4.519810676574707 - val_accuracy: 0.1652 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 48/60\n",
            "loss: 1.9560863971710205 - accuracy: 0.49731001257896423 - val_loss: 4.475139141082764 - val_accuracy: 0.1689 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 49/60\n",
            "loss: 1.9167506694793701 - accuracy: 0.5062999725341797 - val_loss: 4.369975566864014 - val_accuracy: 0.1728 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 50/60\n",
            "loss: 1.8892220258712769 - accuracy: 0.5125200152397156 - val_loss: 4.365583896636963 - val_accuracy: 0.1838 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 51/60\n",
            "loss: 1.8505090475082397 - accuracy: 0.5185499787330627 - val_loss: 4.421718597412109 - val_accuracy: 0.1788 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 52/60\n",
            "loss: 1.8176560401916504 - accuracy: 0.5260499715805054 - val_loss: 4.528739929199219 - val_accuracy: 0.1744 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 53/60\n",
            "loss: 1.7850289344787598 - accuracy: 0.531279981136322 - val_loss: 4.515427589416504 - val_accuracy: 0.1801 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 54/60\n",
            "loss: 1.7551771402359009 - accuracy: 0.5374000072479248 - val_loss: 4.49268102645874 - val_accuracy: 0.1853 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 55/60\n",
            "loss: 1.7313982248306274 - accuracy: 0.5426200032234192 - val_loss: 4.473310947418213 - val_accuracy: 0.1866 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 56/60\n",
            "loss: 1.6980115175247192 - accuracy: 0.5502099990844727 - val_loss: 4.55034065246582 - val_accuracy: 0.1834 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 57/60\n",
            "loss: 1.6721645593643188 - accuracy: 0.5543500185012817 - val_loss: 4.683237552642822 - val_accuracy: 0.1814 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 58/60\n",
            "loss: 1.657073736190796 - accuracy: 0.5582000017166138 - val_loss: 4.43244743347168 - val_accuracy: 0.1908 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 59/60\n",
            "loss: 1.6225813627243042 - accuracy: 0.5651100277900696 - val_loss: 4.549902439117432 - val_accuracy: 0.1891 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 60/60\n",
            "loss: 1.6119625568389893 - accuracy: 0.5698000192642212 - val_loss: 4.643642425537109 - val_accuracy: 0.188 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "CPU times: user 20min 36s, sys: 42.8 s, total: 21min 18s\n",
            "Wall time: 16min 16s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "model = get_convolutional_model(tiny_imagenet.X_train_norm, regularization_penalty=0.0002, regularization_method='l1', layer_sizes=[37, 11, 19, 20, 86, 310], output_neurons=200)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "schedule = Schedule([EpochType.STATIC_WITH_REGULARIZATION] * 60)\n",
        "history = model.fit(tiny_imagenet.X_train_norm, tiny_imagenet.y_train, optimizer, schedule=schedule, batch_size=batch_size, min_new_neurons=20, \n",
        "                    validation_data=(tiny_imagenet.X_test_norm, tiny_imagenet.y_test), growth_percentage=0.2, verbose=True)"
      ],
      "metadata": {
        "id": "Mlgve6MyfCpf",
        "outputId": "50d8df8a-0ad1-4e2e-f65e-2c0a38ac9bc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/60\n",
            "loss: 4.257846355438232 - accuracy: 0.0994499996304512 - val_loss: 5.318850994110107 - val_accuracy: 0.0526 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 2/60\n",
            "loss: 3.785670518875122 - accuracy: 0.16226999461650848 - val_loss: 5.088986396789551 - val_accuracy: 0.0651 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 3/60\n",
            "loss: 3.666051149368286 - accuracy: 0.17880000174045563 - val_loss: 5.0565667152404785 - val_accuracy: 0.0699 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 4/60\n",
            "loss: 3.5895581245422363 - accuracy: 0.19134999811649323 - val_loss: 5.020029544830322 - val_accuracy: 0.0803 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 5/60\n",
            "loss: 3.5234525203704834 - accuracy: 0.2010599970817566 - val_loss: 4.941208362579346 - val_accuracy: 0.0799 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 6/60\n",
            "loss: 3.4741902351379395 - accuracy: 0.2097499966621399 - val_loss: 4.928002834320068 - val_accuracy: 0.0822 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 7/60\n",
            "loss: 3.433316946029663 - accuracy: 0.2162099927663803 - val_loss: 4.859347343444824 - val_accuracy: 0.0894 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 8/60\n",
            "loss: 3.391428232192993 - accuracy: 0.22296999394893646 - val_loss: 4.734714508056641 - val_accuracy: 0.0906 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 9/60\n",
            "loss: 3.356670618057251 - accuracy: 0.22806000709533691 - val_loss: 4.693403244018555 - val_accuracy: 0.0972 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 10/60\n",
            "loss: 3.3287136554718018 - accuracy: 0.2333499938249588 - val_loss: 4.714365005493164 - val_accuracy: 0.0965 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 11/60\n",
            "loss: 3.286480665206909 - accuracy: 0.24026000499725342 - val_loss: 4.663084983825684 - val_accuracy: 0.102 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 12/60\n",
            "loss: 3.2551074028015137 - accuracy: 0.24508999288082123 - val_loss: 4.688838481903076 - val_accuracy: 0.1015 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 13/60\n",
            "loss: 3.2203259468078613 - accuracy: 0.2515900135040283 - val_loss: 4.773599624633789 - val_accuracy: 0.1078 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 14/60\n",
            "loss: 3.185358762741089 - accuracy: 0.25617000460624695 - val_loss: 4.746317386627197 - val_accuracy: 0.1035 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 15/60\n",
            "loss: 3.1519758701324463 - accuracy: 0.2636600136756897 - val_loss: 4.623055934906006 - val_accuracy: 0.1134 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 16/60\n",
            "loss: 3.1274209022521973 - accuracy: 0.2685900032520294 - val_loss: 4.4388861656188965 - val_accuracy: 0.1183 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 17/60\n",
            "loss: 3.096492290496826 - accuracy: 0.2734900116920471 - val_loss: 4.481044292449951 - val_accuracy: 0.1231 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 18/60\n",
            "loss: 3.070535659790039 - accuracy: 0.2780900001525879 - val_loss: 4.486494541168213 - val_accuracy: 0.1248 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 19/60\n",
            "loss: 3.0439131259918213 - accuracy: 0.28404998779296875 - val_loss: 4.55245304107666 - val_accuracy: 0.1202 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 20/60\n",
            "loss: 3.0249149799346924 - accuracy: 0.28758999705314636 - val_loss: 4.341054916381836 - val_accuracy: 0.1287 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 21/60\n",
            "loss: 2.996307849884033 - accuracy: 0.2917200028896332 - val_loss: 4.346397399902344 - val_accuracy: 0.1349 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 22/60\n",
            "loss: 2.9699313640594482 - accuracy: 0.2968299984931946 - val_loss: 4.252047061920166 - val_accuracy: 0.1409 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 23/60\n",
            "loss: 2.941521644592285 - accuracy: 0.3017300069332123 - val_loss: 4.393033504486084 - val_accuracy: 0.1308 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 24/60\n",
            "loss: 2.9225990772247314 - accuracy: 0.3052099943161011 - val_loss: 4.283941745758057 - val_accuracy: 0.1391 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 25/60\n",
            "loss: 2.896031141281128 - accuracy: 0.30952998995780945 - val_loss: 4.322470188140869 - val_accuracy: 0.1368 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 26/60\n",
            "loss: 2.876189708709717 - accuracy: 0.3138900101184845 - val_loss: 4.1742939949035645 - val_accuracy: 0.1522 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 27/60\n",
            "loss: 2.8598687648773193 - accuracy: 0.3165600001811981 - val_loss: 4.080598831176758 - val_accuracy: 0.1606 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 28/60\n",
            "loss: 2.8425440788269043 - accuracy: 0.32062000036239624 - val_loss: 4.150353908538818 - val_accuracy: 0.1537 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 29/60\n",
            "loss: 2.8235578536987305 - accuracy: 0.32381999492645264 - val_loss: 4.258582592010498 - val_accuracy: 0.1485 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 30/60\n",
            "loss: 2.8095505237579346 - accuracy: 0.3274799883365631 - val_loss: 4.251204013824463 - val_accuracy: 0.1445 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 31/60\n",
            "loss: 2.7949438095092773 - accuracy: 0.3278999924659729 - val_loss: 4.206493854522705 - val_accuracy: 0.1521 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 32/60\n",
            "loss: 2.78406023979187 - accuracy: 0.33246999979019165 - val_loss: 4.233453750610352 - val_accuracy: 0.1487 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 33/60\n",
            "loss: 2.770413398742676 - accuracy: 0.3345800042152405 - val_loss: 4.045029163360596 - val_accuracy: 0.162 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 34/60\n",
            "loss: 2.7549400329589844 - accuracy: 0.33682000637054443 - val_loss: 4.149669647216797 - val_accuracy: 0.1615 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 35/60\n",
            "loss: 2.746790647506714 - accuracy: 0.3393099904060364 - val_loss: 4.149161338806152 - val_accuracy: 0.1617 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 36/60\n",
            "loss: 2.728705883026123 - accuracy: 0.3419699966907501 - val_loss: 4.044126033782959 - val_accuracy: 0.1679 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 37/60\n",
            "loss: 2.7194769382476807 - accuracy: 0.342960000038147 - val_loss: 4.092695236206055 - val_accuracy: 0.1624 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 38/60\n",
            "loss: 2.709078550338745 - accuracy: 0.3455899953842163 - val_loss: 4.111531734466553 - val_accuracy: 0.1671 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 39/60\n",
            "loss: 2.701646566390991 - accuracy: 0.3476099967956543 - val_loss: 4.044355392456055 - val_accuracy: 0.1677 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 40/60\n",
            "loss: 2.690676212310791 - accuracy: 0.35071998834609985 - val_loss: 4.106562614440918 - val_accuracy: 0.1634 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 41/60\n",
            "loss: 2.6797430515289307 - accuracy: 0.351500004529953 - val_loss: 4.0388689041137695 - val_accuracy: 0.1702 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 42/60\n",
            "loss: 2.666510820388794 - accuracy: 0.35471001267433167 - val_loss: 4.037220001220703 - val_accuracy: 0.1706 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 43/60\n",
            "loss: 2.6606011390686035 - accuracy: 0.3544999957084656 - val_loss: 4.099428653717041 - val_accuracy: 0.1668 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 44/60\n",
            "loss: 2.655705690383911 - accuracy: 0.3559199869632721 - val_loss: 3.9622836112976074 - val_accuracy: 0.1796 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 45/60\n",
            "loss: 2.6379761695861816 - accuracy: 0.3576500117778778 - val_loss: 4.0088791847229 - val_accuracy: 0.1741 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 46/60\n",
            "loss: 2.6346542835235596 - accuracy: 0.3592100143432617 - val_loss: 3.844907522201538 - val_accuracy: 0.1913 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 47/60\n",
            "loss: 2.6219100952148438 - accuracy: 0.36333999037742615 - val_loss: 3.930230140686035 - val_accuracy: 0.1819 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 48/60\n",
            "loss: 2.613410234451294 - accuracy: 0.3631899952888489 - val_loss: 4.082435131072998 - val_accuracy: 0.1699 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 49/60\n",
            "loss: 2.601804733276367 - accuracy: 0.36570000648498535 - val_loss: 3.9956445693969727 - val_accuracy: 0.176 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 50/60\n",
            "loss: 2.600696325302124 - accuracy: 0.3662799894809723 - val_loss: 4.12166166305542 - val_accuracy: 0.1669 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 51/60\n",
            "loss: 2.598646640777588 - accuracy: 0.3659699857234955 - val_loss: 4.071061134338379 - val_accuracy: 0.1731 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 52/60\n",
            "loss: 2.5841305255889893 - accuracy: 0.36897000670433044 - val_loss: 4.040156841278076 - val_accuracy: 0.1771 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 53/60\n",
            "loss: 2.5771636962890625 - accuracy: 0.3702400028705597 - val_loss: 3.9472649097442627 - val_accuracy: 0.1825 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 54/60\n",
            "loss: 2.5636343955993652 - accuracy: 0.37189000844955444 - val_loss: 3.9921252727508545 - val_accuracy: 0.1791 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 55/60\n",
            "loss: 2.558887243270874 - accuracy: 0.3744499981403351 - val_loss: 3.9890968799591064 - val_accuracy: 0.1805 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 56/60\n",
            "loss: 2.5504958629608154 - accuracy: 0.3749699890613556 - val_loss: 3.853379249572754 - val_accuracy: 0.1943 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 57/60\n",
            "loss: 2.5440421104431152 - accuracy: 0.3768500089645386 - val_loss: 3.9528605937957764 - val_accuracy: 0.1842 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 58/60\n",
            "loss: 2.5352625846862793 - accuracy: 0.37841999530792236 - val_loss: 4.087200164794922 - val_accuracy: 0.1749 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 59/60\n",
            "loss: 2.5295183658599854 - accuracy: 0.3795900046825409 - val_loss: 3.909482479095459 - val_accuracy: 0.189 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 60/60\n",
            "loss: 2.5280590057373047 - accuracy: 0.3806000053882599 - val_loss: 4.08701753616333 - val_accuracy: 0.1728 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "CPU times: user 14min 51s, sys: 42.9 s, total: 15min 34s\n",
            "Wall time: 11min 7s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bMrz149vtoST"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}