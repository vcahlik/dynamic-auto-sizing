{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_multi_layer_ssnet_inverse.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "background_execution": "on"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_deAUKlniFk",
        "outputId": "13270aa7-4b54-4170-c9f6-4751d1e58fbb"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jan 11 17:51:37 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    25W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKwUwV_NneIo"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from enum import Enum\n",
        "import imageio\n",
        "import os\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "dtype = 'float32'\n",
        "tf.keras.backend.set_floatx(dtype)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTZq4KMpneIv"
      },
      "source": [
        "################################################################################\n",
        "# DATASETS\n",
        "################################################################################\n",
        "\n",
        "\n",
        "class Dataset:\n",
        "    def __init__(self, X_train, y_train, X_test, y_test, shape, shape_flattened):\n",
        "        X_train = X_train.astype(dtype) / 255.0\n",
        "        y_train = y_train.astype(dtype)\n",
        "        X_test = X_test.astype(dtype)  / 255.0\n",
        "        y_test = y_test.astype(dtype)\n",
        "\n",
        "        X_train = np.reshape(X_train, shape_flattened)\n",
        "        X_test = np.reshape(X_test, shape_flattened)\n",
        "\n",
        "        X = np.concatenate((X_train, X_test), axis=0)\n",
        "        y = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "        from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(X_train)  # Scaling each feature independently\n",
        "\n",
        "        X_norm = scaler.transform(X)\n",
        "        X_train_norm = scaler.transform(X_train)\n",
        "        X_test_norm = scaler.transform(X_test)\n",
        "\n",
        "        X_norm = np.reshape(X_norm, shape)\n",
        "        X_train_norm = np.reshape(X_train_norm, shape)\n",
        "        X_test_norm = np.reshape(X_test_norm, shape)\n",
        "\n",
        "        self.X_norm = X_norm\n",
        "        self.y = y\n",
        "        self.X_train_norm = X_train_norm\n",
        "        self.y_train = y_train\n",
        "        self.X_test_norm = X_test_norm\n",
        "        self.y_test = y_test\n",
        "\n",
        "\n",
        "def get_cifar_10_dataset():\n",
        "    cifar10 = tf.keras.datasets.cifar10\n",
        "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "    shape = (-1, 32, 32, 3)\n",
        "    shape_flattened = (-1, 3072)  # Scaling each feature independently\n",
        "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened)\n",
        "\n",
        "\n",
        "def get_cifar_100_dataset():\n",
        "    cifar100 = tf.keras.datasets.cifar100\n",
        "    (X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
        "    shape = (-1, 32, 32, 3)\n",
        "    shape_flattened = (-1, 3072)  # Scaling each feature independently\n",
        "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened)\n",
        "\n",
        "\n",
        "def get_svhn_dataset():\n",
        "    from scipy import io\n",
        "\n",
        "    X_train = io.loadmat(train_filename, variable_names='X').get('X')\n",
        "    y_train = io.loadmat(train_filename, variable_names='y').get('y')\n",
        "    X_test = io.loadmat(test_filename, variable_names='X').get('X')\n",
        "    y_test = io.loadmat(test_filename, variable_names='y').get('y')\n",
        "\n",
        "    X_train = np.moveaxis(X_train, -1, 0)\n",
        "    y_train -= 1\n",
        "    X_test = np.moveaxis(X_test, -1, 0)\n",
        "    y_test -= 1\n",
        "\n",
        "    shape = (-1, 32, 32, 3)\n",
        "    shape_flattened = (-1, 3072)  # Scaling each feature independently\n",
        "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened)\n",
        "\n",
        "\n",
        "def get_tiny_imagenet_dataset():\n",
        "    \"\"\"\n",
        "    Original source: https://github.com/sonugiri1043/Train_ResNet_On_Tiny_ImageNet/blob/master/Train_ResNet_On_Tiny_ImageNet.ipynb\n",
        "    Original author: sonugiri1043@gmail.com\n",
        "    \"\"\"\n",
        "\n",
        "    if not os.path.isdir('IMagenet'):\n",
        "        ! git clone https://github.com/seshuad/IMagenet\n",
        "\n",
        "    print(\"Processing the downloaded dataset...\")\n",
        "\n",
        "    path = 'IMagenet/tiny-imagenet-200/'\n",
        "\n",
        "    id_dict = {}\n",
        "    for i, line in enumerate(open(path + 'wnids.txt', 'r')):\n",
        "        id_dict[line.replace('\\n', '')] = i\n",
        "\n",
        "    train_data = list()\n",
        "    test_data = list()\n",
        "    train_labels = list()\n",
        "    test_labels = list()\n",
        "\n",
        "    for key, value in id_dict.items():\n",
        "        train_data += [imageio.imread(path + 'train/{}/images/{}_{}.JPEG'.format(key, key, str(i)), pilmode='RGB') for i in range(500)]\n",
        "        train_labels_ = np.array([[0]*200]*500)\n",
        "        train_labels_[:, value] = 1\n",
        "        train_labels += train_labels_.tolist()\n",
        "\n",
        "    for line in open(path + 'val/val_annotations.txt'):\n",
        "        img_name, class_id = line.split('\\t')[:2]\n",
        "        test_data.append(imageio.imread(path + 'val/images/{}'.format(img_name), pilmode='RGB'))\n",
        "        test_labels_ = np.array([[0]*200])\n",
        "        test_labels_[0, id_dict[class_id]] = 1\n",
        "        test_labels += test_labels_.tolist()\n",
        "\n",
        "    X_train = np.array(train_data)\n",
        "    y_train = np.argmax(np.array(train_labels), axis=1)\n",
        "    X_test = np.array(test_data)\n",
        "    y_test = np.argmax(np.array(test_labels), axis=1)\n",
        "\n",
        "    shape = (-1, 64, 64, 3)\n",
        "    shape_flattened = (-1, 12288)  # Scaling each feature independently\n",
        "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened)\n",
        "\n",
        "\n",
        "def get_mnist_dataset():\n",
        "    mnist = tf.keras.datasets.mnist\n",
        "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "    shape = (-1, 28, 28, 1)\n",
        "    shape_flattened = (-1, 1)  # Scaling all features together\n",
        "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened)\n",
        "\n",
        "\n",
        "def get_fashion_mnist_dataset():\n",
        "    fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "    (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "    shape = (-1, 28, 28, 1)\n",
        "    shape_flattened = (-1, 1)  # Scaling all features together\n",
        "    return Dataset(X_train, y_train, X_test, y_test, shape=shape, shape_flattened=shape_flattened)\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# REGULARIZERS\n",
        "################################################################################\n",
        "\n",
        "\n",
        "class Regularizer(tf.keras.regularizers.Regularizer):\n",
        "    def __init__(self, regularization_penalty, regularization_method):\n",
        "        self.regularization_penalty = regularization_penalty\n",
        "        self.regularization_method = regularization_method\n",
        "        self.n_new_neurons = 0\n",
        "        self.scaling_tensor = None\n",
        "        if self.regularization_method == 'weighted_l1_reordered':\n",
        "            self.update_scaling_tensor = True\n",
        "        else:\n",
        "            self.update_scaling_tensor = None\n",
        "\n",
        "    def __call__(self, x):\n",
        "        if self.regularization_method == 'weighted_l1':\n",
        "            return self.weighted_l1(x)\n",
        "        elif self.regularization_method == 'weighted_l1_reordered':\n",
        "            return self.weighted_l1_reordered(x)\n",
        "        elif self.regularization_method == 'group_sparsity':\n",
        "            return self.group_sparsity(x)\n",
        "        elif self.regularization_method == 'l1':\n",
        "            return self.l1(x)\n",
        "        else:\n",
        "            raise NotImplementedError(f\"Unknown regularization method {self.regularization_method}\")\n",
        "    \n",
        "    def weighted_l1(self, x):\n",
        "        # I.e. for a parameter matrix of 4 input and 10 output neurons:\n",
        "        #\n",
        "        # [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]\n",
        "        #\n",
        "        # the scaling tensor, as well as the resulting weighted values, could be:\n",
        "        #\n",
        "        # [[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
        "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
        "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
        "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]\n",
        "        #\n",
        "        # Therefore every additional output neuron is regularized more.\n",
        "\n",
        "        scaling_tensor = tf.cumsum(tf.constant(self.regularization_penalty, shape=x.shape, dtype=dtype), axis=-1)\n",
        "        weighted_values = scaling_tensor * tf.abs(x)\n",
        "        return tf.reduce_sum(weighted_values)\n",
        "    \n",
        "    def weighted_l1_reordered(self, x):\n",
        "        # I.e. for a parameter matrix of 4 input and 10 output neurons:\n",
        "        #\n",
        "        # [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "        #  [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]\n",
        "        #\n",
        "        # the scaling tensor, as well as the resulting weighted values, could be:\n",
        "        #\n",
        "        # [[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
        "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
        "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
        "        #  [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]\n",
        "        #\n",
        "        # Therefore every additional output neuron is regularized more.\n",
        "\n",
        "        if self.update_scaling_tensor:\n",
        "            scaling_tensor_raw = tf.cumsum(tf.constant(self.regularization_penalty, shape=x.shape, dtype=dtype), axis=-1)\n",
        "\n",
        "            scaling_tensor_old_neurons = scaling_tensor_raw[:, :-self.n_new_neurons]\n",
        "            scaling_tensor_new_neurons = scaling_tensor_raw[:, -self.n_new_neurons:]\n",
        "            scaling_tensor_old_neurons_shuffled = tf.transpose(tf.random.shuffle(tf.transpose(scaling_tensor_old_neurons)))\n",
        "            self.scaling_tensor = tf.concat([scaling_tensor_old_neurons_shuffled, scaling_tensor_new_neurons], axis=-1)\n",
        "            self.update_scaling_tensor = False\n",
        "\n",
        "        weighted_values = self.scaling_tensor * tf.abs(x)\n",
        "        return tf.reduce_sum(weighted_values)\n",
        "    \n",
        "    def group_sparsity(self, x):\n",
        "        # I.e. for a parameter matrix of 3 input and 5 output neurons:\n",
        "        #\n",
        "        # [[1., 1., 1., 1., 1.],\n",
        "        #  [1., 2., 2., 1., 2.],\n",
        "        #  [2., 2., 3., 1., 3.]]\n",
        "        #\n",
        "        # The resulting vector of group norms is [2., 2., 3., 1., 3.], therefore for\n",
        "        # every output neuron, its incoming connections form a group.\n",
        "\n",
        "        group_norms = tf.norm(x, ord=2, axis=0)\n",
        "        # assert group_norms.shape[0] == x.shape[1]\n",
        "        return self.regularization_penalty * tf.reduce_sum(group_norms)\n",
        "    \n",
        "    def l1(self, x):\n",
        "        weighted_values = self.regularization_penalty * tf.abs(x)\n",
        "        return tf.reduce_sum(weighted_values)\n",
        "    \n",
        "    def prune(self):\n",
        "        self.n_new_neurons = 0\n",
        "        if self.regularization_method == 'weighted_l1_reordered':\n",
        "            self.update_scaling_tensor = True\n",
        "    \n",
        "    def grow(self, n_new_neurons):\n",
        "        self.n_new_neurons = n_new_neurons\n",
        "        if self.regularization_method == 'weighted_l1_reordered':\n",
        "            self.update_scaling_tensor = True\n",
        "\n",
        "    def get_config(self):\n",
        "        return {'regularization_penalty': float(self.regularization_penalty)}\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# LAYERS\n",
        "################################################################################\n",
        "\n",
        "\n",
        "class CustomLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, input_shape):\n",
        "        super().__init__()\n",
        "\n",
        "        self.inpt_shp = input_shape\n",
        "\n",
        "\n",
        "class Dense(CustomLayer):\n",
        "    def __init__(self, units, activation, regularization_penalty=0.01, \n",
        "                 regularization_method='weighted_l1', kernel_initializer='glorot_uniform', \n",
        "                 bias_initializer='zeros', input_shape=None, fixed_size=False):\n",
        "        super().__init__(input_shape)\n",
        "\n",
        "        self.units = units\n",
        "        self.activation = activation\n",
        "        self.regularization_penalty = regularization_penalty\n",
        "        self.regularization_method = regularization_method\n",
        "        self.kernel_initializer = kernel_initializer\n",
        "        self.bias_initializer = bias_initializer\n",
        "        self.fixed_size = fixed_size\n",
        "        \n",
        "        self.A = tf.keras.activations.get(activation)\n",
        "        self.W_init = tf.keras.initializers.get(kernel_initializer)\n",
        "        self.b_init = tf.keras.initializers.get(bias_initializer)\n",
        "        self.regularizer = Regularizer(self.regularization_penalty, self.regularization_method)\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        input_units = input_shape[-1]\n",
        "\n",
        "        self.W = tf.Variable(\n",
        "            name='W',\n",
        "            initial_value=self.W_init(shape=(input_units, self.units), dtype=dtype),\n",
        "            trainable=True)\n",
        "        \n",
        "        self.b = tf.Variable(\n",
        "            name='b',\n",
        "            initial_value=self.b_init(shape=(self.units,), dtype=dtype),\n",
        "            trainable=True)\n",
        "        \n",
        "        if self.regularization_method is not None:\n",
        "            self.add_loss(lambda: self.regularizer(tf.concat([self.W, tf.reshape(self.b, (1, -1))], axis=0)))\n",
        "    \n",
        "    def call(self, inputs, training=None):\n",
        "        return self.A(tf.matmul(inputs, self.W) + self.b)\n",
        "\n",
        "    def get_size(self):\n",
        "        return self.W.shape[0], self.W.shape[1]\n",
        "    \n",
        "    def prune(self, threshold, active_input_units_indices):\n",
        "        # Remove connections from pruned units in previous layer\n",
        "        new_W = tf.gather(self.W.value(), active_input_units_indices, axis=0)\n",
        "\n",
        "        if self.fixed_size:\n",
        "            active_output_neurons_indices = list(range(new_W.shape[1]))\n",
        "        else:\n",
        "            # Prune units in this layer\n",
        "            weights_with_biases = tf.concat([new_W, tf.reshape(self.b.value(), (1, -1))], axis=0)\n",
        "            neurons_are_active = tf.math.reduce_max(tf.abs(weights_with_biases), axis=0) >= threshold\n",
        "            active_output_neurons_indices = tf.reshape(tf.where(neurons_are_active), (-1,))\n",
        "            \n",
        "            new_W = tf.gather(new_W, active_output_neurons_indices, axis=1)\n",
        "            new_b = tf.gather(self.b.value(), active_output_neurons_indices, axis=0)\n",
        "\n",
        "            self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
        "\n",
        "        self.W = tf.Variable(name='W', initial_value=new_W, trainable=True)\n",
        "\n",
        "        self.regularizer.prune()\n",
        "        return active_output_neurons_indices\n",
        "    \n",
        "    def grow(self, n_new_input_units, percentage, min_new_units, scaling_factor):\n",
        "        if n_new_input_units > 0:\n",
        "            # Add connections to grown units in previous layer\n",
        "            W_growth = self.W_init(shape=(self.W.shape[0] + n_new_input_units, self.W.shape[1]), dtype=dtype)[-n_new_input_units:, :] * scaling_factor  # TODO is it better to be multiplying here by scaling_factor? It does help with not increasing the max weights of existing neurons when new neurons are added.\n",
        "            new_W = tf.concat([self.W.value(), W_growth], axis=0)\n",
        "        else:\n",
        "            new_W = self.W.value()\n",
        "\n",
        "        if self.fixed_size:\n",
        "            n_new_output_units = 0\n",
        "        else:\n",
        "            # Grow new units in this layer\n",
        "            n_new_output_units = max(min_new_units, int(new_W.shape[1] * percentage))\n",
        "            if n_new_output_units > 0:\n",
        "                W_growth = self.W_init(shape=(new_W.shape[0], new_W.shape[1] + n_new_output_units), dtype=dtype)[:, -n_new_output_units:] * scaling_factor\n",
        "                b_growth = self.b_init(shape=(n_new_output_units,), dtype=dtype)  # TODO for all possible bias initializers to work properly, the whole bias vector should be initialized at once\n",
        "                new_W = tf.concat([new_W, W_growth], axis=1)\n",
        "                new_b = tf.concat([self.b.value(), b_growth], axis=0)\n",
        "\n",
        "                self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
        "\n",
        "        self.W = tf.Variable(name='W', initial_value=new_W, trainable=True)\n",
        "\n",
        "        self.regularizer.grow(n_new_output_units)\n",
        "        return n_new_output_units\n",
        "    \n",
        "    def get_param_string():\n",
        "        param_string = \"\"\n",
        "        weights_with_bias = tf.concat([self.W, tf.reshape(self.b, (1, -1))], axis=0)\n",
        "        max_parameters = tf.math.reduce_max(tf.abs(weights_with_bias), axis=0).numpy()\n",
        "        magnitudes = np.floor(np.log10(max_parameters))\n",
        "        for m in magnitudes:\n",
        "            if m > 0:\n",
        "                m = 0\n",
        "            param_string += str(int(-m))\n",
        "        return param_string\n",
        "\n",
        "\n",
        "class Conv2D(CustomLayer):\n",
        "    def __init__(self, filters, filter_size, activation, strides=(1, 1), \n",
        "                 padding='SAME', regularization_penalty=0.01, \n",
        "                 regularization_method='weighted_l1', kernel_initializer='glorot_uniform',\n",
        "                 bias_initializer='zeros', input_shape=None, fixed_size=False):\n",
        "        super().__init__(input_shape)\n",
        "    \n",
        "        self.filters = filters\n",
        "        self.filter_size = filter_size\n",
        "        self.activation = activation\n",
        "        self.strides = strides\n",
        "        self.padding = padding\n",
        "        self.regularization_penalty = regularization_penalty\n",
        "        self.regularization_method = regularization_method\n",
        "        self.kernel_initializer = kernel_initializer\n",
        "        self.bias_initializer = bias_initializer\n",
        "        self.fixed_size = fixed_size\n",
        "        \n",
        "        self.A = tf.keras.activations.get(activation)\n",
        "        self.F_init = tf.keras.initializers.get(kernel_initializer)\n",
        "        self.b_init = tf.keras.initializers.get(bias_initializer)\n",
        "        self.regularizer = Regularizer(self.regularization_penalty, self.regularization_method)\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        input_filters = input_shape[-1]\n",
        "\n",
        "        self.F = tf.Variable(\n",
        "            name='F',\n",
        "            initial_value=self.F_init(\n",
        "                shape=(self.filter_size[0], self.filter_size[1], input_filters, self.filters), dtype=dtype\n",
        "            ),\n",
        "            trainable=True)\n",
        "        \n",
        "        self.b = tf.Variable(\n",
        "            name='b',\n",
        "            initial_value=self.b_init(shape=(self.filters,), dtype=dtype),\n",
        "            trainable=True)\n",
        "\n",
        "        if self.regularization_method is not None:\n",
        "            self.add_loss(lambda: self.regularizer(tf.concat([tf.reshape(self.F, (-1, self.F.shape[-1])), tf.reshape(self.b, (1, -1))], axis=0)))\n",
        "    \n",
        "    def call(self, inputs, training=None):\n",
        "        y = tf.nn.conv2d(inputs, self.F, strides=self.strides, padding=self.padding)\n",
        "        y = tf.nn.bias_add(y, self.b)\n",
        "        y = self.A(y)\n",
        "        return y\n",
        "    \n",
        "    def get_size(self):\n",
        "        return self.F.shape[-2], self.F.shape[-1]\n",
        "    \n",
        "    def prune(self, threshold, active_input_units_indices):\n",
        "        # Remove connections from pruned units in previous layer\n",
        "        new_F = tf.gather(self.F.value(), active_input_units_indices, axis=-2)\n",
        "\n",
        "        if self.fixed_size:\n",
        "            active_output_filters_indices = list(range(new_F.shape[-1]))\n",
        "        else:\n",
        "            # Prune units in this layer\n",
        "            F_reduced_max = tf.reshape(tf.math.reduce_max(tf.abs(new_F), axis=(0, 1, 2)), (1, -1))\n",
        "            F_reduced_max_with_biases = tf.concat([F_reduced_max, tf.reshape(self.b.value(), (1, -1))], axis=0)\n",
        "            filters_are_active = tf.math.reduce_max(tf.abs(F_reduced_max_with_biases), axis=0) >= threshold\n",
        "            active_output_filters_indices = tf.reshape(tf.where(filters_are_active), (-1,))\n",
        "            \n",
        "            new_F = tf.gather(new_F, active_output_filters_indices, axis=-1)\n",
        "            new_b = tf.gather(self.b.value(), active_output_filters_indices, axis=0)\n",
        "\n",
        "            self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
        "\n",
        "        self.F = tf.Variable(name='F', initial_value=new_F, trainable=True)\n",
        "\n",
        "        self.regularizer.prune()\n",
        "        return active_output_filters_indices\n",
        "\n",
        "    def grow(self, n_new_input_units, percentage, min_new_units, scaling_factor):\n",
        "        if n_new_input_units > 0:\n",
        "            # Add connections to grown units in previous layer\n",
        "            F_growth = self.F_init(shape=(self.F.shape[0], self.F.shape[1], self.F.shape[2] + n_new_input_units, self.F.shape[3]), dtype=dtype)[:, :, -n_new_input_units:, :] * scaling_factor  # TODO is it better to be multiplying here by scaling_factor? It does help with not increasing the max weights of existing neurons when new neurons are added.\n",
        "            new_F = tf.concat([self.F.value(), F_growth], axis=-2)\n",
        "        else:\n",
        "            new_F = self.F.value()\n",
        "\n",
        "        if self.fixed_size:\n",
        "            n_new_output_units = 0\n",
        "        else:\n",
        "            # Grow new units in this layer\n",
        "            n_new_output_units = max(min_new_units, int(new_F.shape[-1] * percentage))\n",
        "            if n_new_output_units > 0:\n",
        "                F_growth = self.F_init(shape=(new_F.shape[0], new_F.shape[1], new_F.shape[2], new_F.shape[3] + n_new_output_units), dtype=dtype)[:, :, :, -n_new_output_units:] * scaling_factor\n",
        "                b_growth = self.b_init(shape=(n_new_output_units,), dtype=dtype)  # TODO for all possible bias initializers to work properly, the whole bias vector should be initialized at once\n",
        "                new_F = tf.concat([new_F, F_growth], axis=-1)\n",
        "                new_b = tf.concat([self.b.value(), b_growth], axis=0)\n",
        "\n",
        "                self.b = tf.Variable(name='b', initial_value=new_b, trainable=True)\n",
        "\n",
        "        self.F = tf.Variable(name='F', initial_value=new_F, trainable=True)\n",
        "\n",
        "        self.regularizer.grow(n_new_output_units)\n",
        "        return n_new_output_units\n",
        "\n",
        "    def get_param_string():\n",
        "        param_string = \"\"\n",
        "        # TODO\n",
        "        return param_string\n",
        "\n",
        "\n",
        "class Flatten(tf.keras.Model):\n",
        "    def call(self, inputs, training=None):\n",
        "        return tf.reshape(tf.transpose(inputs, perm=[0, 3, 1, 2]), (inputs.shape[0], -1))\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# MODELS\n",
        "################################################################################\n",
        "\n",
        "\n",
        "class EpochType(Enum):\n",
        "    DYNAMIC = 0\n",
        "    STATIC_WITH_REGULARIZATION = 1\n",
        "    STATIC_NO_REGULARIZATION = 2\n",
        "    PRUNING_ONLY = 3\n",
        "    GROWTH_ONLY = 4\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.value)\n",
        "\n",
        "\n",
        "class Schedule:\n",
        "    def __init__(self, epoch_types):\n",
        "        self.epoch_types = epoch_types\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self.epoch_types.__iter__()\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.epoch_types)\n",
        "    \n",
        "    def __str__(self):\n",
        "        return ''.join([str(epoch_type.value) for epoch_type in self.epoch_types])\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return self.__str__()\n",
        "\n",
        "\n",
        "class Sequential(tf.keras.Model):\n",
        "    def __init__(self, layers, activation=None):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.lrs = layers\n",
        "        \n",
        "    def call(self, inputs, training=None):\n",
        "        x = inputs\n",
        "        for layer in self.lrs:\n",
        "            x = layer(x, training=training)\n",
        "        return x\n",
        "    \n",
        "    def get_layer_input_shape(self, target_layer):\n",
        "        if target_layer.inpt_shp is not None:\n",
        "            return target_layer.inpt_shp\n",
        "\n",
        "        input = np.random.normal(size=(1,) + self.lrs[0].inpt_shp)\n",
        "        for layer in self.lrs:\n",
        "            if layer is target_layer:\n",
        "                return tuple(input.shape[1:])\n",
        "            input = layer(input)\n",
        "        raise Exception(\"Layer not found in the model.\")\n",
        "\n",
        "    def get_layer_output_shape(self, target_layer):\n",
        "        input = np.random.normal(size=(1,) + self.lrs[0].inpt_shp)\n",
        "        for layer in self.lrs:\n",
        "            output = layer(input)\n",
        "            if layer is target_layer:\n",
        "                return tuple(output.shape[1:])\n",
        "            input = output\n",
        "        raise Exception(\"Layer not found in the model.\")\n",
        "    \n",
        "    def get_layer_sizes(self):\n",
        "        \"\"\"\n",
        "        Returns the sizes of all layers in the model, including the input and output layer.\n",
        "        \"\"\"\n",
        "        layer_sizes = list()\n",
        "        first_layer = True\n",
        "        for l in range(len(self.lrs)):\n",
        "            layer = self.lrs[l]\n",
        "            if isinstance(layer, CustomLayer):\n",
        "                layer_size = layer.get_size()\n",
        "                if first_layer:\n",
        "                    layer_sizes.append(layer_size[0])\n",
        "                    first_layer = False\n",
        "                layer_sizes.append(layer_size[1])\n",
        "        return layer_sizes\n",
        "    \n",
        "    def get_hidden_layer_sizes(self):\n",
        "        return self.get_layer_sizes()[1:-1]\n",
        "    \n",
        "    def get_regularization_penalty(self):\n",
        "        #TODO improve\n",
        "        return self.lrs[-2].regularizer.regularization_penalty\n",
        "    \n",
        "    def set_regularization_penalty(self, regularization_penalty):\n",
        "        for layer in self.lrs:\n",
        "            if isinstance(layer, CustomLayer) and not layer.fixed_size:\n",
        "                layer.regularizer.regularization_penalty = regularization_penalty\n",
        "    \n",
        "    def prune(self, params):\n",
        "        input_shape = self.get_layer_input_shape(self.lrs[0])\n",
        "        n_input_units = input_shape[-1]\n",
        "        active_units_indices = list(range(n_input_units))\n",
        "\n",
        "        last_custom_layer = None\n",
        "        for layer in self.lrs:\n",
        "            if isinstance(layer, CustomLayer):\n",
        "                if last_custom_layer is not None and type(last_custom_layer) != type(layer):\n",
        "                    if type(last_custom_layer) == Conv2D and type(layer) == Dense:\n",
        "                        convolutional_shape = self.get_layer_output_shape(last_custom_layer)\n",
        "                        active_units_indices = self.convert_channel_indices_to_flattened_indices(active_units_indices, convolutional_shape)\n",
        "                    else:\n",
        "                        raise Exception(\"Incorrect order of custom layer types.\")\n",
        "                active_units_indices = layer.prune(params.pruning_threshold, active_units_indices)\n",
        "                last_custom_layer = layer\n",
        "    \n",
        "    def grow(self, params):   \n",
        "        n_new_units = 0\n",
        "\n",
        "        last_custom_layer = None\n",
        "        for layer in self.lrs:\n",
        "            if isinstance(layer, CustomLayer):\n",
        "                if last_custom_layer is not None and type(last_custom_layer) != type(layer):\n",
        "                    if type(last_custom_layer) == Conv2D and type(layer) == Dense:\n",
        "                        convolutional_shape = self.get_layer_output_shape(last_custom_layer)\n",
        "                        n_new_units = n_new_units * convolutional_shape[0] * convolutional_shape[1]\n",
        "                    else:\n",
        "                        raise Exception(\"Incorrect order of custom layer types.\")\n",
        "                n_new_units = layer.grow(n_new_units, params.growth_percentage, min_new_units=params.min_new_neurons, scaling_factor=params.pruning_threshold)\n",
        "                last_custom_layer = layer\n",
        "    \n",
        "    @staticmethod\n",
        "    def convert_channel_indices_to_flattened_indices(channel_indices, convolutional_shape):\n",
        "        dense_indices = list()\n",
        "        units_per_channel = convolutional_shape[0] * convolutional_shape[1]\n",
        "        for channel_index in channel_indices:\n",
        "            for iter in range(units_per_channel):\n",
        "                dense_indices.append(channel_index * units_per_channel + iter)\n",
        "        return dense_indices\n",
        "    \n",
        "    def print_neurons(self):\n",
        "        for layer in self.lrs[:-1]:\n",
        "            print(layer.get_param_string())\n",
        "    \n",
        "    def evaluate(self, params, summed_training_loss, summed_training_accuracy):\n",
        "        # Calculate training loss and accuracy\n",
        "        if summed_training_loss is not None:\n",
        "            loss = summed_training_loss / params.x.shape[0]\n",
        "        else:\n",
        "            loss = None\n",
        "        \n",
        "        if summed_training_accuracy is not None:\n",
        "            accuracy = summed_training_accuracy / params.x.shape[0]\n",
        "        else:\n",
        "            accuracy = None\n",
        "        \n",
        "        # Calculate val loss and accuracy\n",
        "        summed_val_loss = 0\n",
        "        summed_val_accuracy = 0\n",
        "        n_val_instances = 0\n",
        "        \n",
        "        for step, (x_batch, y_batch) in enumerate(params.val_dataset):\n",
        "            y_pred = self(x_batch, training=False)\n",
        "            summed_val_loss += tf.reduce_sum(tf.keras.losses.sparse_categorical_crossentropy(y_batch, y_pred))\n",
        "            summed_val_accuracy += float(tf.reduce_sum(tf.keras.metrics.sparse_categorical_accuracy(y_batch, y_pred)))\n",
        "            n_val_instances += x_batch.shape[0]\n",
        "        \n",
        "        val_loss = summed_val_loss / n_val_instances\n",
        "        val_accuracy = summed_val_accuracy / n_val_instances\n",
        "\n",
        "        return loss, accuracy, val_loss, val_accuracy\n",
        "    \n",
        "    def print_epoch_statistics(self, params, summed_training_loss, summed_training_accuracy, message=None, require_result=False):\n",
        "        if not params.verbose:\n",
        "            if require_result:\n",
        "                return self.evaluate(params, summed_training_loss, summed_training_accuracy)\n",
        "            else:\n",
        "                return\n",
        "        \n",
        "        loss, accuracy, val_loss, val_accuracy = self.evaluate(params, summed_training_loss, summed_training_accuracy)  \n",
        "\n",
        "        if message is not None:\n",
        "            print(message)\n",
        "        \n",
        "        print(f\"loss: {loss} - accuracy: {accuracy} - val_loss: {val_loss} - val_accuracy: {val_accuracy} - penalty: {self.get_regularization_penalty()}\")\n",
        "        hidden_layer_sizes = self.get_hidden_layer_sizes()\n",
        "        print(f\"hidden layer sizes: {hidden_layer_sizes}, total units: {sum(hidden_layer_sizes)}\")\n",
        "        if params.print_neurons:\n",
        "            self.print_neurons()\n",
        "        \n",
        "        if require_result:\n",
        "            return loss, accuracy, val_loss, val_accuracy\n",
        "    \n",
        "    def update_history(self, params, loss, accuracy, val_loss, val_accuracy):\n",
        "        params.history['loss'].append(loss)\n",
        "        params.history['accuracy'].append(accuracy)\n",
        "        params.history['val_loss'].append(val_loss)\n",
        "        params.history['val_accuracy'].append(val_accuracy)\n",
        "        params.history['hidden_layer_sizes'].append(self.get_hidden_layer_sizes())\n",
        "    \n",
        "    @staticmethod\n",
        "    def prepare_datasets(x, y, batch_size, validation_data):\n",
        "        train_dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "        train_dataset = train_dataset.shuffle(buffer_size=20000).batch(batch_size)\n",
        "        val_dataset = tf.data.Dataset.from_tensor_slices(validation_data).batch(batch_size)\n",
        "        return train_dataset.prefetch(tf.data.AUTOTUNE), val_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    \n",
        "    def manage_dynamic_regularization(self, params, val_loss):\n",
        "        if val_loss >= params.best_conditional_val_loss * params.stall_coefficient:\n",
        "            # Training is currently in stall\n",
        "            if not params.training_stalled:\n",
        "                penalty = self.get_regularization_penalty() * params.regularization_penalty_multiplier\n",
        "                print(\"Changing penalty...\")\n",
        "                # TODO this must be modified, penalty can differ for each layer\n",
        "                self.set_regularization_penalty(penalty)\n",
        "                params.training_stalled = True\n",
        "        else:\n",
        "            params.best_conditional_val_loss = val_loss\n",
        "            params.training_stalled = False\n",
        "    \n",
        "    def grow_wrapper(self, params):\n",
        "        dynamic_reqularization_active = params.regularization_penalty_multiplier != 1.\n",
        "        if dynamic_reqularization_active:\n",
        "            loss, accuracy, val_loss, val_accuracy = self.print_epoch_statistics(params, None, None, \"Before growing:\", require_result=True)\n",
        "            self.manage_dynamic_regularization(params, val_loss)\n",
        "        else:\n",
        "            self.print_epoch_statistics(params, None, None, \"Before growing:\")\n",
        "\n",
        "        self.grow(params)\n",
        "        self.print_epoch_statistics(params, None, None, \"After growing:\")\n",
        "    \n",
        "    def prune_wrapper(self, params, summed_loss, summed_accuracy):\n",
        "        loss, accuracy, _, _ = self.print_epoch_statistics(params, summed_loss, summed_accuracy, \"Before pruning:\", require_result=True)\n",
        "        self.prune(params)\n",
        "        _, _, val_loss, val_accuracy = self.print_epoch_statistics(params, None, None, \"After pruning:\", require_result=True)\n",
        "\n",
        "        self.update_history(params, loss, accuracy, val_loss, val_accuracy)\n",
        "    \n",
        "    class ParameterContainer:\n",
        "        def __init__(self, x, y, optimizer, batch_size, min_new_neurons, validation_data, pruning_threshold, \n",
        "                regularization_penalty_multiplier, stall_coefficient, growth_percentage, mini_epochs_per_epoch, verbose, print_neurons, use_static_graph):\n",
        "            self.x = x\n",
        "            self.y = y\n",
        "            self.optimizer = optimizer\n",
        "            self.batch_size = batch_size\n",
        "            self.min_new_neurons = min_new_neurons\n",
        "            self.validation_data = validation_data\n",
        "            self.pruning_threshold = pruning_threshold\n",
        "            self.regularization_penalty_multiplier = regularization_penalty_multiplier\n",
        "            self.stall_coefficient = stall_coefficient\n",
        "            self.growth_percentage = growth_percentage\n",
        "            self.mini_epochs_per_epoch = mini_epochs_per_epoch\n",
        "            self.verbose = verbose\n",
        "            self.print_neurons = print_neurons\n",
        "            self.use_static_graph = use_static_graph\n",
        "\n",
        "            self.train_dataset, self.val_dataset = Sequential.prepare_datasets(x, y, batch_size, validation_data)\n",
        "            self.history = self.prepare_history()\n",
        "\n",
        "            self.best_conditional_val_loss = np.inf\n",
        "            self.training_stalled = False\n",
        "        \n",
        "        @staticmethod\n",
        "        def prepare_history():\n",
        "            history = {\n",
        "                'loss': list(),\n",
        "                'accuracy': list(),\n",
        "                'val_loss': list(),\n",
        "                'val_accuracy': list(),\n",
        "                'hidden_layer_sizes': list(),\n",
        "            }\n",
        "            return history\n",
        "    \n",
        "    def fit_single_step(self, params, x_batch, y_batch):\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x_batch, training=True)\n",
        "            raw_loss = tf.keras.losses.sparse_categorical_crossentropy(y_batch, y_pred)\n",
        "            loss_value = tf.reduce_mean(raw_loss)\n",
        "            loss_value += sum(self.losses)  # Add losses registered by model.add_loss\n",
        "\n",
        "            loss = tf.reduce_sum(raw_loss)\n",
        "            accuracy = float(tf.reduce_sum(tf.keras.metrics.sparse_categorical_accuracy(y_batch, y_pred)))\n",
        "\n",
        "        grads = tape.gradient(loss_value, self.trainable_variables)\n",
        "        params.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
        "\n",
        "        return loss, accuracy\n",
        "    \n",
        "    def fit_single_epoch(self, params):\n",
        "        summed_loss = 0\n",
        "        summed_accuracy = 0\n",
        "        \n",
        "        for mini_epoch in range(params.mini_epochs_per_epoch):\n",
        "            summed_loss = 0\n",
        "            summed_accuracy = 0\n",
        "\n",
        "            if params.use_static_graph:\n",
        "                fit_single_step_function = tf.function(self.fit_single_step)\n",
        "            else:\n",
        "                fit_single_step_function = self.fit_single_step\n",
        "            for step, (x_batch, y_batch) in enumerate(params.train_dataset):\n",
        "                loss, accuracy = fit_single_step_function(params, x_batch, y_batch)\n",
        "                summed_loss += loss\n",
        "                summed_accuracy += accuracy\n",
        "        \n",
        "        return summed_loss, summed_accuracy\n",
        "\n",
        "    def fit(self, x, y, optimizer, schedule, batch_size, min_new_neurons, validation_data, pruning_threshold=0.001, regularization_penalty_multiplier=1., \n",
        "            stall_coefficient=1, growth_percentage=0.2, mini_epochs_per_epoch=1, verbose=True, print_neurons=False, use_static_graph=True):\n",
        "        params = self.ParameterContainer(x=x, y=y, optimizer=optimizer, batch_size=batch_size, min_new_neurons=min_new_neurons, validation_data=validation_data, \n",
        "                                         pruning_threshold=pruning_threshold, regularization_penalty_multiplier=regularization_penalty_multiplier, stall_coefficient=stall_coefficient, \n",
        "                                         growth_percentage=growth_percentage, mini_epochs_per_epoch=mini_epochs_per_epoch, verbose=verbose, print_neurons=print_neurons, \n",
        "                                         use_static_graph=use_static_graph)\n",
        "        self.build(x.shape)  # Necessary when verbose == False\n",
        "\n",
        "        for epoch_no, epoch_type in enumerate(schedule):\n",
        "            if verbose:\n",
        "                print(\"##########################################################\")\n",
        "                print(f\"Epoch {epoch_no + 1}/{len(schedule)}\")\n",
        "\n",
        "            if epoch_type in (EpochType.DYNAMIC, EpochType.GROWTH_ONLY):\n",
        "                self.grow_wrapper(params)\n",
        "            \n",
        "            if epoch_type == EpochType.STATIC_NO_REGULARIZATION:\n",
        "                self.set_regularization_penalty(0.)\n",
        "            \n",
        "            summed_loss, summed_accuracy = self.fit_single_epoch(params)\n",
        "\n",
        "            if epoch_type in (EpochType.DYNAMIC, EpochType.PRUNING_ONLY):\n",
        "                self.prune_wrapper(params, summed_loss, summed_accuracy)\n",
        "            else:\n",
        "                loss, accuracy, val_loss, val_accuracy = self.print_epoch_statistics(params, summed_loss, summed_accuracy, require_result=True)\n",
        "                self.update_history(params, loss, accuracy, val_loss, val_accuracy)\n",
        "        \n",
        "        return params.history\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# HELPER FUNCTIONS\n",
        "################################################################################\n",
        "\n",
        "\n",
        "def get_statistics_from_history(history):\n",
        "    best_epoch_number = np.argmax(history['val_accuracy'])\n",
        "    best_val_accuracy = history['val_accuracy'][best_epoch_number]\n",
        "    best_hidden_layer_sizes = history['hidden_layer_sizes'][best_epoch_number]\n",
        "    return best_val_accuracy, best_hidden_layer_sizes\n",
        "\n",
        "\n",
        "def get_statistics_from_histories(histories):\n",
        "    best_val_accuracies = list()\n",
        "    all_best_hidden_layer_sizes = list()\n",
        "\n",
        "    for history in histories:\n",
        "        best_val_accuracy, best_hidden_layer_sizes = get_statistics_from_history(history)\n",
        "        best_val_accuracies.append(best_val_accuracy)\n",
        "        all_best_hidden_layer_sizes.append(best_hidden_layer_sizes)\n",
        "    \n",
        "    mean_best_val_accuracy = np.mean(best_val_accuracies)\n",
        "    mean_best_hidden_layer_sizes = [np.mean(layer) for layer in list(zip(*all_best_hidden_layer_sizes))]\n",
        "    \n",
        "    return mean_best_val_accuracy, mean_best_hidden_layer_sizes\n",
        "\n",
        "\n",
        "def cross_validate(train_fn, x, y, n_splits, random_state=42, *args, **kwargs):\n",
        "    from sklearn.model_selection import KFold\n",
        "\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "\n",
        "    histories = list()\n",
        "    for i, (train_index, test_index) in enumerate(kf.split(x)):\n",
        "        xtrain, xtest = x[train_index], x[test_index]\n",
        "        ytrain, ytest = y[train_index], y[test_index]\n",
        "\n",
        "        history = train_fn(xtrain, ytrain, validation_data=(xtest, ytest), *args, **kwargs)\n",
        "        histories.append(history)\n",
        "\n",
        "        best_val_accuracy, best_hidden_layer_sizes = get_statistics_from_history(history)\n",
        "        print(f\"Run {i} completed, best_val_accuracy: {best_val_accuracy}, best_hidden_layer_sizes: {best_hidden_layer_sizes}\")\n",
        "\n",
        "    mean_best_val_accuracy, mean_best_hidden_layer_sizes = get_statistics_from_histories(histories)\n",
        "    print(f'mean_best_val_accuracy: {mean_best_val_accuracy}')\n",
        "    print(f'mean_best_hidden_layer_sizes: {mean_best_hidden_layer_sizes}')\n",
        "\n",
        "    return histories\n",
        "\n",
        "\n",
        "def hyperparameter_search(train_fn, x, y, validation_data, *args, **kwargs):\n",
        "    from itertools import product\n",
        "\n",
        "    all_params = [*args] + list(kwargs.values())\n",
        "    histories = list()\n",
        "\n",
        "    best_overall_val_accuracy = -np.inf\n",
        "    best_overall_combination = None\n",
        "\n",
        "    for combination in product(*all_params):\n",
        "        combination_args = combination[:len(args)]\n",
        "\n",
        "        combination_kwargs_values = combination[len(args):]\n",
        "        combination_kwargs = dict(zip(kwargs.keys(), combination_kwargs_values))\n",
        "\n",
        "        history = train_fn(x, y, validation_data, *combination_args, **combination_kwargs)\n",
        "        history['parameters'] = combination\n",
        "        histories.append(history)\n",
        "\n",
        "        best_val_accuracy, best_hidden_layer_sizes = get_statistics_from_history(history)\n",
        "        print(f\"Run with parameters {combination} completed, best_val_accuracy: {best_val_accuracy}, best_hidden_layer_sizes sizes: {best_hidden_layer_sizes}\")\n",
        "\n",
        "        if best_val_accuracy > best_overall_val_accuracy:\n",
        "            best_overall_val_accuracy = best_val_accuracy\n",
        "            best_overall_combination = combination\n",
        "    \n",
        "    print(f'Best overall combination: {best_overall_combination}, val_accuracy: {best_overall_val_accuracy}')\n",
        "\n",
        "    return histories\n",
        "\n",
        "\n",
        "def get_convolutional_model(x, regularization_penalty, regularization_method, layer_sizes, output_neurons=10):\n",
        "    model = Sequential([\n",
        "        Conv2D(layer_sizes[0], filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=regularization_penalty, regularization_method=regularization_method, \n",
        "            kernel_initializer='lecun_normal', input_shape=x[0,:,:,:].shape),\n",
        "        Conv2D(layer_sizes[1], filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=regularization_penalty, regularization_method=regularization_method, \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        Conv2D(layer_sizes[2], filter_size=(3, 3), activation='selu', strides=(1, 1), padding='SAME', \n",
        "            regularization_penalty=regularization_penalty, regularization_method=regularization_method, \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        Conv2D(layer_sizes[3], filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=regularization_penalty, regularization_method=regularization_method, \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        Conv2D(layer_sizes[4], filter_size=(3, 3), activation='selu', strides=(2, 2), padding='SAME', \n",
        "            regularization_penalty=regularization_penalty, regularization_method=regularization_method, \n",
        "            kernel_initializer='lecun_normal'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(layer_sizes[5], activation='selu', regularization_penalty=regularization_penalty, \n",
        "            regularization_method=regularization_method, kernel_initializer='lecun_normal'),\n",
        "        Dense(output_neurons, activation='softmax', regularization_penalty=0., \n",
        "            regularization_method=None, fixed_size=True),\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_fn(x, y, validation_data, learning_rate, schedule, regularization_penalty, regularization_method, layer_sizes, \n",
        "             output_neurons=10, min_new_neurons=20, growth_percentage=0.2, verbose=False, use_static_graph=True):\n",
        "    batch_size = 128\n",
        "\n",
        "    model = get_convolutional_model(x, regularization_penalty, regularization_method, layer_sizes, output_neurons)\n",
        "    \n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    history = model.fit(x=x, y=y, optimizer=optimizer, schedule=schedule, batch_size=batch_size, min_new_neurons=min_new_neurons, \n",
        "                        validation_data=validation_data, growth_percentage=growth_percentage, verbose=verbose, use_static_graph=use_static_graph)\n",
        "    \n",
        "    return history"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1MrQXUTFwOe"
      },
      "source": [
        "# Accuracy benchmark - FF and convolutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsivpauwveEK"
      },
      "source": [
        "## CIFAR100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cifar100 = get_cifar_100_dataset()"
      ],
      "metadata": {
        "id": "SjJ2e9njMl04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "model = get_convolutional_model(cifar100.X_train_norm, regularization_penalty=0.00002, regularization_method='weighted_l1', layer_sizes=[100, 100, 100, 100, 100], output_neurons=100)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "history = model.fit(cifar100.X_train_norm, cifar100.y_train, optimizer, epochs=40, self_scaling_epochs=20, batch_size=batch_size, \n",
        "                    min_new_neurons=20, validation_data=(cifar100.X_test_norm, cifar100.y_test), pruning_only_epochs=0, \n",
        "                    growth_percentage=0.2, verbose=True)"
      ],
      "metadata": {
        "id": "7934TYSFhFKN",
        "outputId": "bbd2acce-4228-4634-b3e7-20616475dff0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.9665093421936035 - val_accuracy: 0.0102 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.9665093421936035 - val_accuracy: 0.0102 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "Before pruning:\n",
            "loss: 4.0280256271362305 - accuracy: 0.1080000028014183 - val_loss: 3.6404457092285156 - val_accuracy: 0.1663 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.64062762260437 - val_accuracy: 0.1661 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "##########################################################\n",
            "Epoch 2/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.64062762260437 - val_accuracy: 0.1661 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.64062762260437 - val_accuracy: 0.1661 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "Before pruning:\n",
            "loss: 3.6307544708251953 - accuracy: 0.15977999567985535 - val_loss: 3.4752750396728516 - val_accuracy: 0.1883 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.475353240966797 - val_accuracy: 0.1886 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 106], total units: 506\n",
            "##########################################################\n",
            "Epoch 3/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.475353240966797 - val_accuracy: 0.1886 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 106], total units: 506\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.4753527641296387 - val_accuracy: 0.1886 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 127], total units: 607\n",
            "Before pruning:\n",
            "loss: 3.447922706604004 - accuracy: 0.18661999702453613 - val_loss: 3.241731882095337 - val_accuracy: 0.2306 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 127], total units: 607\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.241814374923706 - val_accuracy: 0.2302 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 98, 91, 91, 120], total units: 500\n",
            "##########################################################\n",
            "Epoch 4/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.241814374923706 - val_accuracy: 0.2302 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 98, 91, 91, 120], total units: 500\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.241814374923706 - val_accuracy: 0.2302 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 118, 111, 111, 144], total units: 604\n",
            "Before pruning:\n",
            "loss: 3.231048345565796 - accuracy: 0.22458000481128693 - val_loss: 3.0473365783691406 - val_accuracy: 0.261 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 118, 111, 111, 144], total units: 604\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.0472774505615234 - val_accuracy: 0.2609 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 60, 80, 78, 134], total units: 452\n",
            "##########################################################\n",
            "Epoch 5/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.0472774505615234 - val_accuracy: 0.2609 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 60, 80, 78, 134], total units: 452\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.0472774505615234 - val_accuracy: 0.2609 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 80, 100, 98, 160], total units: 558\n",
            "Before pruning:\n",
            "loss: 3.100306272506714 - accuracy: 0.24726000428199768 - val_loss: 2.9273619651794434 - val_accuracy: 0.2843 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 80, 100, 98, 160], total units: 558\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.9273147583007812 - val_accuracy: 0.2843 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 48, 76, 67, 156], total units: 447\n",
            "##########################################################\n",
            "Epoch 6/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.9273147583007812 - val_accuracy: 0.2843 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 48, 76, 67, 156], total units: 447\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.9273147583007812 - val_accuracy: 0.2843 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 68, 96, 87, 187], total units: 558\n",
            "Before pruning:\n",
            "loss: 3.0037763118743896 - accuracy: 0.26600000262260437 - val_loss: 2.8310389518737793 - val_accuracy: 0.3046 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 68, 96, 87, 187], total units: 558\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.831169605255127 - val_accuracy: 0.3046 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 38, 72, 60, 161], total units: 431\n",
            "##########################################################\n",
            "Epoch 7/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.831169605255127 - val_accuracy: 0.3046 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 38, 72, 60, 161], total units: 431\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.831169605255127 - val_accuracy: 0.3046 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 58, 92, 80, 193], total units: 543\n",
            "Before pruning:\n",
            "loss: 2.9358506202697754 - accuracy: 0.280239999294281 - val_loss: 2.748509407043457 - val_accuracy: 0.3227 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 58, 92, 80, 193], total units: 543\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.7486495971679688 - val_accuracy: 0.3233 - penalty: 2e-05\n",
            "hidden layer sizes: [99, 35, 72, 58, 170], total units: 434\n",
            "##########################################################\n",
            "Epoch 8/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.7486495971679688 - val_accuracy: 0.3233 - penalty: 2e-05\n",
            "hidden layer sizes: [99, 35, 72, 58, 170], total units: 434\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.7486495971679688 - val_accuracy: 0.3233 - penalty: 2e-05\n",
            "hidden layer sizes: [119, 55, 92, 78, 204], total units: 548\n",
            "Before pruning:\n",
            "loss: 2.873830556869507 - accuracy: 0.28804001212120056 - val_loss: 2.69982647895813 - val_accuracy: 0.3309 - penalty: 2e-05\n",
            "hidden layer sizes: [119, 55, 92, 78, 204], total units: 548\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.6998634338378906 - val_accuracy: 0.3306 - penalty: 2e-05\n",
            "hidden layer sizes: [95, 30, 62, 55, 179], total units: 421\n",
            "##########################################################\n",
            "Epoch 9/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.6998634338378906 - val_accuracy: 0.3306 - penalty: 2e-05\n",
            "hidden layer sizes: [95, 30, 62, 55, 179], total units: 421\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.6998634338378906 - val_accuracy: 0.3306 - penalty: 2e-05\n",
            "hidden layer sizes: [115, 50, 82, 75, 214], total units: 536\n",
            "Before pruning:\n",
            "loss: 2.817314624786377 - accuracy: 0.3005000054836273 - val_loss: 2.655538558959961 - val_accuracy: 0.3356 - penalty: 2e-05\n",
            "hidden layer sizes: [115, 50, 82, 75, 214], total units: 536\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.655611515045166 - val_accuracy: 0.3352 - penalty: 2e-05\n",
            "hidden layer sizes: [93, 29, 59, 52, 175], total units: 408\n",
            "##########################################################\n",
            "Epoch 10/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.655611515045166 - val_accuracy: 0.3352 - penalty: 2e-05\n",
            "hidden layer sizes: [93, 29, 59, 52, 175], total units: 408\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.655611991882324 - val_accuracy: 0.3352 - penalty: 2e-05\n",
            "hidden layer sizes: [113, 49, 79, 72, 210], total units: 523\n",
            "Before pruning:\n",
            "loss: 2.7702877521514893 - accuracy: 0.3056800067424774 - val_loss: 2.607609748840332 - val_accuracy: 0.3445 - penalty: 2e-05\n",
            "hidden layer sizes: [113, 49, 79, 72, 210], total units: 523\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.60766339302063 - val_accuracy: 0.3443 - penalty: 2e-05\n",
            "hidden layer sizes: [91, 26, 56, 53, 179], total units: 405\n",
            "##########################################################\n",
            "Epoch 11/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.60766339302063 - val_accuracy: 0.3443 - penalty: 2e-05\n",
            "hidden layer sizes: [91, 26, 56, 53, 179], total units: 405\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.60766339302063 - val_accuracy: 0.3443 - penalty: 2e-05\n",
            "hidden layer sizes: [111, 46, 76, 73, 214], total units: 520\n",
            "Before pruning:\n",
            "loss: 2.7229537963867188 - accuracy: 0.31727999448776245 - val_loss: 2.568338632583618 - val_accuracy: 0.3548 - penalty: 2e-05\n",
            "hidden layer sizes: [111, 46, 76, 73, 214], total units: 520\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.568450927734375 - val_accuracy: 0.3545 - penalty: 2e-05\n",
            "hidden layer sizes: [88, 25, 55, 52, 181], total units: 401\n",
            "##########################################################\n",
            "Epoch 12/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.568450927734375 - val_accuracy: 0.3545 - penalty: 2e-05\n",
            "hidden layer sizes: [88, 25, 55, 52, 181], total units: 401\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.568450927734375 - val_accuracy: 0.3545 - penalty: 2e-05\n",
            "hidden layer sizes: [108, 45, 75, 72, 217], total units: 517\n",
            "Before pruning:\n",
            "loss: 2.687681198120117 - accuracy: 0.32589998841285706 - val_loss: 2.5235960483551025 - val_accuracy: 0.3684 - penalty: 2e-05\n",
            "hidden layer sizes: [108, 45, 75, 72, 217], total units: 517\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.5236635208129883 - val_accuracy: 0.3677 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 25, 52, 56, 186], total units: 404\n",
            "##########################################################\n",
            "Epoch 13/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.5236635208129883 - val_accuracy: 0.3677 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 25, 52, 56, 186], total units: 404\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.5236637592315674 - val_accuracy: 0.3677 - penalty: 2e-05\n",
            "hidden layer sizes: [105, 45, 72, 76, 223], total units: 521\n",
            "Before pruning:\n",
            "loss: 2.654783010482788 - accuracy: 0.33118000626564026 - val_loss: 2.5015439987182617 - val_accuracy: 0.3698 - penalty: 2e-05\n",
            "hidden layer sizes: [105, 45, 72, 76, 223], total units: 521\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.5015714168548584 - val_accuracy: 0.3696 - penalty: 2e-05\n",
            "hidden layer sizes: [82, 24, 49, 54, 186], total units: 395\n",
            "##########################################################\n",
            "Epoch 14/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.5015714168548584 - val_accuracy: 0.3696 - penalty: 2e-05\n",
            "hidden layer sizes: [82, 24, 49, 54, 186], total units: 395\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.5015714168548584 - val_accuracy: 0.3696 - penalty: 2e-05\n",
            "hidden layer sizes: [102, 44, 69, 74, 223], total units: 512\n",
            "Before pruning:\n",
            "loss: 2.6212122440338135 - accuracy: 0.33643999695777893 - val_loss: 2.471114158630371 - val_accuracy: 0.3666 - penalty: 2e-05\n",
            "hidden layer sizes: [102, 44, 69, 74, 223], total units: 512\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.4711081981658936 - val_accuracy: 0.3659 - penalty: 2e-05\n",
            "hidden layer sizes: [79, 22, 44, 59, 187], total units: 391\n",
            "##########################################################\n",
            "Epoch 15/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4711081981658936 - val_accuracy: 0.3659 - penalty: 2e-05\n",
            "hidden layer sizes: [79, 22, 44, 59, 187], total units: 391\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4711081981658936 - val_accuracy: 0.3659 - penalty: 2e-05\n",
            "hidden layer sizes: [99, 42, 64, 79, 224], total units: 508\n",
            "Before pruning:\n",
            "loss: 2.5820822715759277 - accuracy: 0.3453199863433838 - val_loss: 2.451876640319824 - val_accuracy: 0.3776 - penalty: 2e-05\n",
            "hidden layer sizes: [99, 42, 64, 79, 224], total units: 508\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.45180344581604 - val_accuracy: 0.3774 - penalty: 2e-05\n",
            "hidden layer sizes: [76, 21, 39, 62, 188], total units: 386\n",
            "##########################################################\n",
            "Epoch 16/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.45180344581604 - val_accuracy: 0.3774 - penalty: 2e-05\n",
            "hidden layer sizes: [76, 21, 39, 62, 188], total units: 386\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4518039226531982 - val_accuracy: 0.3774 - penalty: 2e-05\n",
            "hidden layer sizes: [96, 41, 59, 82, 225], total units: 503\n",
            "Before pruning:\n",
            "loss: 2.5633888244628906 - accuracy: 0.3481200039386749 - val_loss: 2.418726682662964 - val_accuracy: 0.3866 - penalty: 2e-05\n",
            "hidden layer sizes: [96, 41, 59, 82, 225], total units: 503\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.418813943862915 - val_accuracy: 0.3868 - penalty: 2e-05\n",
            "hidden layer sizes: [73, 20, 37, 66, 189], total units: 385\n",
            "##########################################################\n",
            "Epoch 17/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.418813943862915 - val_accuracy: 0.3868 - penalty: 2e-05\n",
            "hidden layer sizes: [73, 20, 37, 66, 189], total units: 385\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.418813943862915 - val_accuracy: 0.3868 - penalty: 2e-05\n",
            "hidden layer sizes: [93, 40, 57, 86, 226], total units: 502\n",
            "Before pruning:\n",
            "loss: 2.536714792251587 - accuracy: 0.35109999775886536 - val_loss: 2.380084991455078 - val_accuracy: 0.395 - penalty: 2e-05\n",
            "hidden layer sizes: [93, 40, 57, 86, 226], total units: 502\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3800809383392334 - val_accuracy: 0.3948 - penalty: 2e-05\n",
            "hidden layer sizes: [70, 20, 37, 60, 190], total units: 377\n",
            "##########################################################\n",
            "Epoch 18/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3800809383392334 - val_accuracy: 0.3948 - penalty: 2e-05\n",
            "hidden layer sizes: [70, 20, 37, 60, 190], total units: 377\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3800809383392334 - val_accuracy: 0.3948 - penalty: 2e-05\n",
            "hidden layer sizes: [90, 40, 57, 80, 228], total units: 495\n",
            "Before pruning:\n",
            "loss: 2.5163424015045166 - accuracy: 0.3587999939918518 - val_loss: 2.3841278553009033 - val_accuracy: 0.3908 - penalty: 2e-05\n",
            "hidden layer sizes: [90, 40, 57, 80, 228], total units: 495\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3841354846954346 - val_accuracy: 0.3911 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 20, 33, 61, 194], total units: 376\n",
            "##########################################################\n",
            "Epoch 19/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3841354846954346 - val_accuracy: 0.3911 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 20, 33, 61, 194], total units: 376\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3841354846954346 - val_accuracy: 0.3911 - penalty: 2e-05\n",
            "hidden layer sizes: [88, 40, 53, 81, 232], total units: 494\n",
            "Before pruning:\n",
            "loss: 2.4894819259643555 - accuracy: 0.36188000440597534 - val_loss: 2.359753370285034 - val_accuracy: 0.3929 - penalty: 2e-05\n",
            "hidden layer sizes: [88, 40, 53, 81, 232], total units: 494\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.359687566757202 - val_accuracy: 0.3929 - penalty: 2e-05\n",
            "hidden layer sizes: [66, 20, 32, 63, 194], total units: 375\n",
            "##########################################################\n",
            "Epoch 20/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.359687566757202 - val_accuracy: 0.3929 - penalty: 2e-05\n",
            "hidden layer sizes: [66, 20, 32, 63, 194], total units: 375\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.359687328338623 - val_accuracy: 0.3929 - penalty: 2e-05\n",
            "hidden layer sizes: [86, 40, 52, 83, 232], total units: 493\n",
            "Before pruning:\n",
            "loss: 2.478177547454834 - accuracy: 0.36344000697135925 - val_loss: 2.3493340015411377 - val_accuracy: 0.3983 - penalty: 2e-05\n",
            "hidden layer sizes: [86, 40, 52, 83, 232], total units: 493\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3494250774383545 - val_accuracy: 0.3981 - penalty: 2e-05\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 21/40\n",
            "loss: 2.4997246265411377 - accuracy: 0.36320000886917114 - val_loss: 2.2836287021636963 - val_accuracy: 0.4075 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 22/40\n",
            "loss: 2.212423086166382 - accuracy: 0.42250001430511475 - val_loss: 2.251293659210205 - val_accuracy: 0.4182 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 23/40\n",
            "loss: 2.101757287979126 - accuracy: 0.4499000012874603 - val_loss: 2.2030065059661865 - val_accuracy: 0.4336 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 24/40\n",
            "loss: 2.0088319778442383 - accuracy: 0.4698199927806854 - val_loss: 2.189648151397705 - val_accuracy: 0.4373 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 25/40\n",
            "loss: 1.9249986410140991 - accuracy: 0.4891600012779236 - val_loss: 2.2084591388702393 - val_accuracy: 0.4328 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 26/40\n",
            "loss: 1.8579679727554321 - accuracy: 0.5050399899482727 - val_loss: 2.1898374557495117 - val_accuracy: 0.442 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 27/40\n",
            "loss: 1.7782809734344482 - accuracy: 0.5248000025749207 - val_loss: 2.1925439834594727 - val_accuracy: 0.4414 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 28/40\n",
            "loss: 1.7154521942138672 - accuracy: 0.5369200110435486 - val_loss: 2.1960043907165527 - val_accuracy: 0.4485 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 29/40\n",
            "loss: 1.6548138856887817 - accuracy: 0.5501000285148621 - val_loss: 2.191196918487549 - val_accuracy: 0.447 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 30/40\n",
            "loss: 1.6023191213607788 - accuracy: 0.561460018157959 - val_loss: 2.2147793769836426 - val_accuracy: 0.448 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 31/40\n",
            "loss: 1.552045464515686 - accuracy: 0.5742800235748291 - val_loss: 2.23360013961792 - val_accuracy: 0.4526 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 32/40\n",
            "loss: 1.5061599016189575 - accuracy: 0.5844799876213074 - val_loss: 2.23874568939209 - val_accuracy: 0.45 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 33/40\n",
            "loss: 1.45633065700531 - accuracy: 0.5946400165557861 - val_loss: 2.2481303215026855 - val_accuracy: 0.4481 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 34/40\n",
            "loss: 1.4107677936553955 - accuracy: 0.6059200167655945 - val_loss: 2.2804975509643555 - val_accuracy: 0.4479 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 35/40\n",
            "loss: 1.368695616722107 - accuracy: 0.6142399907112122 - val_loss: 2.275789260864258 - val_accuracy: 0.4519 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 36/40\n",
            "loss: 1.3367382287979126 - accuracy: 0.6235399842262268 - val_loss: 2.3016200065612793 - val_accuracy: 0.45 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 37/40\n",
            "loss: 1.29282808303833 - accuracy: 0.6343399882316589 - val_loss: 2.2924118041992188 - val_accuracy: 0.4496 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 38/40\n",
            "loss: 1.2675926685333252 - accuracy: 0.6386200189590454 - val_loss: 2.350851058959961 - val_accuracy: 0.4456 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 39/40\n",
            "loss: 1.2334692478179932 - accuracy: 0.6450600028038025 - val_loss: 2.3547112941741943 - val_accuracy: 0.4492 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "##########################################################\n",
            "Epoch 40/40\n",
            "loss: 1.2020186185836792 - accuracy: 0.6534799933433533 - val_loss: 2.3694541454315186 - val_accuracy: 0.4496 - penalty: 0.0\n",
            "hidden layer sizes: [62, 17, 31, 65, 192], total units: 367\n",
            "CPU times: user 3min 36s, sys: 8.33 s, total: 3min 45s\n",
            "Wall time: 3min 16s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "model = get_convolutional_model(cifar100.X_train_norm, regularization_penalty=0.00002, regularization_method='weighted_l1', layer_sizes=[100, 100, 100, 100, 100], output_neurons=100)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "history = model.fit(cifar100.X_train_norm, cifar100.y_train, optimizer, epochs=40, self_scaling_epochs=20, batch_size=batch_size, \n",
        "                    min_new_neurons=20, validation_data=(cifar100.X_test_norm, cifar100.y_test), pruning_only_epochs=0, \n",
        "                    growth_percentage=0.2, verbose=True)"
      ],
      "metadata": {
        "id": "TZjoY4LyiG7Z",
        "outputId": "5bef9841-66e8-40d6-90a6-161e97733677",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.954936504364014 - val_accuracy: 0.011 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.954936504364014 - val_accuracy: 0.011 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "Before pruning:\n",
            "loss: 3.9630274772644043 - accuracy: 0.11682000011205673 - val_loss: 3.6065542697906494 - val_accuracy: 0.166 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.6065804958343506 - val_accuracy: 0.166 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 107], total units: 507\n",
            "##########################################################\n",
            "Epoch 2/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.6065804958343506 - val_accuracy: 0.166 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 107], total units: 507\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.606580972671509 - val_accuracy: 0.166 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 128], total units: 608\n",
            "Before pruning:\n",
            "loss: 3.6110033988952637 - accuracy: 0.1626800000667572 - val_loss: 3.4388890266418457 - val_accuracy: 0.188 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 128], total units: 608\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.4389023780822754 - val_accuracy: 0.1878 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 99, 100, 100, 124], total units: 523\n",
            "##########################################################\n",
            "Epoch 3/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.4389023780822754 - val_accuracy: 0.1878 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 99, 100, 100, 124], total units: 523\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.4389023780822754 - val_accuracy: 0.1878 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 119, 120, 120, 148], total units: 627\n",
            "Before pruning:\n",
            "loss: 3.403515100479126 - accuracy: 0.19582000374794006 - val_loss: 3.1985278129577637 - val_accuracy: 0.2324 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 119, 120, 120, 148], total units: 627\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.1977641582489014 - val_accuracy: 0.2326 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 57, 93, 83, 148], total units: 481\n",
            "##########################################################\n",
            "Epoch 4/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.1977641582489014 - val_accuracy: 0.2326 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 57, 93, 83, 148], total units: 481\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.1977641582489014 - val_accuracy: 0.2326 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 77, 113, 103, 177], total units: 590\n",
            "Before pruning:\n",
            "loss: 3.1989669799804688 - accuracy: 0.22991999983787537 - val_loss: 3.001176357269287 - val_accuracy: 0.2702 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 77, 113, 103, 177], total units: 590\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.0010879039764404 - val_accuracy: 0.2708 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 43, 84, 75, 171], total units: 473\n",
            "##########################################################\n",
            "Epoch 5/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.0010879039764404 - val_accuracy: 0.2708 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 43, 84, 75, 171], total units: 473\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.0010876655578613 - val_accuracy: 0.2708 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 63, 104, 95, 205], total units: 587\n",
            "Before pruning:\n",
            "loss: 3.0719592571258545 - accuracy: 0.25064000487327576 - val_loss: 2.8911893367767334 - val_accuracy: 0.2947 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 63, 104, 95, 205], total units: 587\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.891228437423706 - val_accuracy: 0.2949 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 32, 70, 64, 194], total units: 460\n",
            "##########################################################\n",
            "Epoch 6/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.891228437423706 - val_accuracy: 0.2949 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 32, 70, 64, 194], total units: 460\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.891228437423706 - val_accuracy: 0.2949 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 52, 90, 84, 232], total units: 578\n",
            "Before pruning:\n",
            "loss: 2.9779112339019775 - accuracy: 0.268779993057251 - val_loss: 2.810983419418335 - val_accuracy: 0.3049 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 52, 90, 84, 232], total units: 578\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.8109703063964844 - val_accuracy: 0.305 - penalty: 2e-05\n",
            "hidden layer sizes: [98, 30, 66, 61, 209], total units: 464\n",
            "##########################################################\n",
            "Epoch 7/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8109703063964844 - val_accuracy: 0.305 - penalty: 2e-05\n",
            "hidden layer sizes: [98, 30, 66, 61, 209], total units: 464\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8109703063964844 - val_accuracy: 0.305 - penalty: 2e-05\n",
            "hidden layer sizes: [118, 50, 86, 81, 250], total units: 585\n",
            "Before pruning:\n",
            "loss: 2.909067153930664 - accuracy: 0.28181999921798706 - val_loss: 2.7352731227874756 - val_accuracy: 0.3175 - penalty: 2e-05\n",
            "hidden layer sizes: [118, 50, 86, 81, 250], total units: 585\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.7352294921875 - val_accuracy: 0.3176 - penalty: 2e-05\n",
            "hidden layer sizes: [93, 29, 64, 64, 214], total units: 464\n",
            "##########################################################\n",
            "Epoch 8/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.7352294921875 - val_accuracy: 0.3176 - penalty: 2e-05\n",
            "hidden layer sizes: [93, 29, 64, 64, 214], total units: 464\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.735229730606079 - val_accuracy: 0.3176 - penalty: 2e-05\n",
            "hidden layer sizes: [113, 49, 84, 84, 256], total units: 586\n",
            "Before pruning:\n",
            "loss: 2.8367090225219727 - accuracy: 0.2979399859905243 - val_loss: 2.6538636684417725 - val_accuracy: 0.3382 - penalty: 2e-05\n",
            "hidden layer sizes: [113, 49, 84, 84, 256], total units: 586\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.653963565826416 - val_accuracy: 0.338 - penalty: 2e-05\n",
            "hidden layer sizes: [89, 27, 59, 63, 214], total units: 452\n",
            "##########################################################\n",
            "Epoch 9/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.653963565826416 - val_accuracy: 0.338 - penalty: 2e-05\n",
            "hidden layer sizes: [89, 27, 59, 63, 214], total units: 452\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.653963565826416 - val_accuracy: 0.338 - penalty: 2e-05\n",
            "hidden layer sizes: [109, 47, 79, 83, 256], total units: 574\n",
            "Before pruning:\n",
            "loss: 2.7689056396484375 - accuracy: 0.3087800145149231 - val_loss: 2.599806308746338 - val_accuracy: 0.3454 - penalty: 2e-05\n",
            "hidden layer sizes: [109, 47, 79, 83, 256], total units: 574\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.5998740196228027 - val_accuracy: 0.3454 - penalty: 2e-05\n",
            "hidden layer sizes: [89, 27, 54, 65, 218], total units: 453\n",
            "##########################################################\n",
            "Epoch 10/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.5998740196228027 - val_accuracy: 0.3454 - penalty: 2e-05\n",
            "hidden layer sizes: [89, 27, 54, 65, 218], total units: 453\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.5998740196228027 - val_accuracy: 0.3454 - penalty: 2e-05\n",
            "hidden layer sizes: [109, 47, 74, 85, 261], total units: 576\n",
            "Before pruning:\n",
            "loss: 2.7054312229156494 - accuracy: 0.32058000564575195 - val_loss: 2.568729877471924 - val_accuracy: 0.3512 - penalty: 2e-05\n",
            "hidden layer sizes: [109, 47, 74, 85, 261], total units: 576\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.568925619125366 - val_accuracy: 0.3512 - penalty: 2e-05\n",
            "hidden layer sizes: [82, 27, 50, 66, 227], total units: 452\n",
            "##########################################################\n",
            "Epoch 11/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.568925619125366 - val_accuracy: 0.3512 - penalty: 2e-05\n",
            "hidden layer sizes: [82, 27, 50, 66, 227], total units: 452\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.568925619125366 - val_accuracy: 0.3512 - penalty: 2e-05\n",
            "hidden layer sizes: [102, 47, 70, 86, 272], total units: 577\n",
            "Before pruning:\n",
            "loss: 2.670111656188965 - accuracy: 0.32923999428749084 - val_loss: 2.506255626678467 - val_accuracy: 0.3626 - penalty: 2e-05\n",
            "hidden layer sizes: [102, 47, 70, 86, 272], total units: 577\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.5063090324401855 - val_accuracy: 0.3627 - penalty: 2e-05\n",
            "hidden layer sizes: [78, 27, 45, 63, 227], total units: 440\n",
            "##########################################################\n",
            "Epoch 12/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.5063090324401855 - val_accuracy: 0.3627 - penalty: 2e-05\n",
            "hidden layer sizes: [78, 27, 45, 63, 227], total units: 440\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.5063092708587646 - val_accuracy: 0.3627 - penalty: 2e-05\n",
            "hidden layer sizes: [98, 47, 65, 83, 272], total units: 565\n",
            "Before pruning:\n",
            "loss: 2.629441261291504 - accuracy: 0.3353399932384491 - val_loss: 2.46703839302063 - val_accuracy: 0.3713 - penalty: 2e-05\n",
            "hidden layer sizes: [98, 47, 65, 83, 272], total units: 565\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.4670207500457764 - val_accuracy: 0.3719 - penalty: 2e-05\n",
            "hidden layer sizes: [75, 26, 43, 60, 228], total units: 432\n",
            "##########################################################\n",
            "Epoch 13/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4670207500457764 - val_accuracy: 0.3719 - penalty: 2e-05\n",
            "hidden layer sizes: [75, 26, 43, 60, 228], total units: 432\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4670207500457764 - val_accuracy: 0.3719 - penalty: 2e-05\n",
            "hidden layer sizes: [95, 46, 63, 80, 273], total units: 557\n",
            "Before pruning:\n",
            "loss: 2.598825454711914 - accuracy: 0.3413200080394745 - val_loss: 2.436244487762451 - val_accuracy: 0.3804 - penalty: 2e-05\n",
            "hidden layer sizes: [95, 46, 63, 80, 273], total units: 557\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.4362549781799316 - val_accuracy: 0.3801 - penalty: 2e-05\n",
            "hidden layer sizes: [72, 26, 37, 63, 229], total units: 427\n",
            "##########################################################\n",
            "Epoch 14/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4362549781799316 - val_accuracy: 0.3801 - penalty: 2e-05\n",
            "hidden layer sizes: [72, 26, 37, 63, 229], total units: 427\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4362549781799316 - val_accuracy: 0.3801 - penalty: 2e-05\n",
            "hidden layer sizes: [92, 46, 57, 83, 274], total units: 552\n",
            "Before pruning:\n",
            "loss: 2.5661332607269287 - accuracy: 0.3470599949359894 - val_loss: 2.4128286838531494 - val_accuracy: 0.3834 - penalty: 2e-05\n",
            "hidden layer sizes: [92, 46, 57, 83, 274], total units: 552\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.4127368927001953 - val_accuracy: 0.3836 - penalty: 2e-05\n",
            "hidden layer sizes: [69, 24, 34, 64, 226], total units: 417\n",
            "##########################################################\n",
            "Epoch 15/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.4127368927001953 - val_accuracy: 0.3836 - penalty: 2e-05\n",
            "hidden layer sizes: [69, 24, 34, 64, 226], total units: 417\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.412736654281616 - val_accuracy: 0.3836 - penalty: 2e-05\n",
            "hidden layer sizes: [89, 44, 54, 84, 271], total units: 542\n",
            "Before pruning:\n",
            "loss: 2.5488932132720947 - accuracy: 0.35076001286506653 - val_loss: 2.3928070068359375 - val_accuracy: 0.3845 - penalty: 2e-05\n",
            "hidden layer sizes: [89, 44, 54, 84, 271], total units: 542\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3928215503692627 - val_accuracy: 0.385 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 22, 32, 67, 231], total units: 417\n",
            "##########################################################\n",
            "Epoch 16/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3928215503692627 - val_accuracy: 0.385 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 22, 32, 67, 231], total units: 417\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3928215503692627 - val_accuracy: 0.385 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 42, 52, 87, 277], total units: 543\n",
            "Before pruning:\n",
            "loss: 2.522462844848633 - accuracy: 0.35580000281333923 - val_loss: 2.367138385772705 - val_accuracy: 0.3955 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 42, 52, 87, 277], total units: 543\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.367140769958496 - val_accuracy: 0.3949 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 22, 31, 69, 228], total units: 414\n",
            "##########################################################\n",
            "Epoch 17/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.367140769958496 - val_accuracy: 0.3949 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 22, 31, 69, 228], total units: 414\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.367140769958496 - val_accuracy: 0.3949 - penalty: 2e-05\n",
            "hidden layer sizes: [84, 42, 51, 89, 273], total units: 539\n",
            "Before pruning:\n",
            "loss: 2.5087778568267822 - accuracy: 0.35760000348091125 - val_loss: 2.35250186920166 - val_accuracy: 0.4018 - penalty: 2e-05\n",
            "hidden layer sizes: [84, 42, 51, 89, 273], total units: 539\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3525657653808594 - val_accuracy: 0.402 - penalty: 2e-05\n",
            "hidden layer sizes: [63, 22, 30, 67, 229], total units: 411\n",
            "##########################################################\n",
            "Epoch 18/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3525657653808594 - val_accuracy: 0.402 - penalty: 2e-05\n",
            "hidden layer sizes: [63, 22, 30, 67, 229], total units: 411\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3525655269622803 - val_accuracy: 0.402 - penalty: 2e-05\n",
            "hidden layer sizes: [83, 42, 50, 87, 274], total units: 536\n",
            "Before pruning:\n",
            "loss: 2.49056339263916 - accuracy: 0.36395999789237976 - val_loss: 2.335096597671509 - val_accuracy: 0.4071 - penalty: 2e-05\n",
            "hidden layer sizes: [83, 42, 50, 87, 274], total units: 536\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.3351385593414307 - val_accuracy: 0.4074 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 22, 28, 68, 229], total units: 407\n",
            "##########################################################\n",
            "Epoch 19/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3351385593414307 - val_accuracy: 0.4074 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 22, 28, 68, 229], total units: 407\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.3351387977600098 - val_accuracy: 0.4074 - penalty: 2e-05\n",
            "hidden layer sizes: [80, 42, 48, 88, 274], total units: 532\n",
            "Before pruning:\n",
            "loss: 2.474853754043579 - accuracy: 0.36434000730514526 - val_loss: 2.322746992111206 - val_accuracy: 0.4009 - penalty: 2e-05\n",
            "hidden layer sizes: [80, 42, 48, 88, 274], total units: 532\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.322770595550537 - val_accuracy: 0.4007 - penalty: 2e-05\n",
            "hidden layer sizes: [59, 22, 28, 66, 229], total units: 404\n",
            "##########################################################\n",
            "Epoch 20/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.322770595550537 - val_accuracy: 0.4007 - penalty: 2e-05\n",
            "hidden layer sizes: [59, 22, 28, 66, 229], total units: 404\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.322770595550537 - val_accuracy: 0.4007 - penalty: 2e-05\n",
            "hidden layer sizes: [79, 42, 48, 86, 274], total units: 529\n",
            "Before pruning:\n",
            "loss: 2.456420421600342 - accuracy: 0.3689599931240082 - val_loss: 2.323631525039673 - val_accuracy: 0.4012 - penalty: 2e-05\n",
            "hidden layer sizes: [79, 42, 48, 86, 274], total units: 529\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.323789119720459 - val_accuracy: 0.4013 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 21/40\n",
            "loss: 2.4838144779205322 - accuracy: 0.3684999942779541 - val_loss: 2.2542717456817627 - val_accuracy: 0.4208 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 22/40\n",
            "loss: 2.1958389282226562 - accuracy: 0.42838001251220703 - val_loss: 2.1808149814605713 - val_accuracy: 0.4331 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 23/40\n",
            "loss: 2.0788934230804443 - accuracy: 0.45767998695373535 - val_loss: 2.1656699180603027 - val_accuracy: 0.4434 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 24/40\n",
            "loss: 1.9762729406356812 - accuracy: 0.47863999009132385 - val_loss: 2.1576790809631348 - val_accuracy: 0.4434 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 25/40\n",
            "loss: 1.8821520805358887 - accuracy: 0.498879998922348 - val_loss: 2.1508190631866455 - val_accuracy: 0.4489 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 26/40\n",
            "loss: 1.784244418144226 - accuracy: 0.5199800133705139 - val_loss: 2.1646292209625244 - val_accuracy: 0.4508 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 27/40\n",
            "loss: 1.692240834236145 - accuracy: 0.5414999723434448 - val_loss: 2.170741558074951 - val_accuracy: 0.4492 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 28/40\n",
            "loss: 1.6143081188201904 - accuracy: 0.5579599738121033 - val_loss: 2.188553810119629 - val_accuracy: 0.4504 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 29/40\n",
            "loss: 1.5340301990509033 - accuracy: 0.5781199932098389 - val_loss: 2.195892095565796 - val_accuracy: 0.4511 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 30/40\n",
            "loss: 1.4521870613098145 - accuracy: 0.593779981136322 - val_loss: 2.223339319229126 - val_accuracy: 0.4492 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 31/40\n",
            "loss: 1.3904294967651367 - accuracy: 0.6098999977111816 - val_loss: 2.2660305500030518 - val_accuracy: 0.453 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 32/40\n",
            "loss: 1.3354294300079346 - accuracy: 0.622219979763031 - val_loss: 2.268756151199341 - val_accuracy: 0.4459 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 33/40\n",
            "loss: 1.2802320718765259 - accuracy: 0.6340600252151489 - val_loss: 2.2888760566711426 - val_accuracy: 0.4497 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 34/40\n",
            "loss: 1.226779580116272 - accuracy: 0.6456999778747559 - val_loss: 2.3313632011413574 - val_accuracy: 0.4481 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 35/40\n",
            "loss: 1.1743972301483154 - accuracy: 0.6586400270462036 - val_loss: 2.354907989501953 - val_accuracy: 0.4513 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 36/40\n",
            "loss: 1.1288738250732422 - accuracy: 0.6688600182533264 - val_loss: 2.370312213897705 - val_accuracy: 0.4536 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 37/40\n",
            "loss: 1.0819816589355469 - accuracy: 0.6825399994850159 - val_loss: 2.437800884246826 - val_accuracy: 0.4469 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 38/40\n",
            "loss: 1.0508049726486206 - accuracy: 0.6901599764823914 - val_loss: 2.437711238861084 - val_accuracy: 0.4499 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 39/40\n",
            "loss: 1.0040401220321655 - accuracy: 0.7031199932098389 - val_loss: 2.4660301208496094 - val_accuracy: 0.4479 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "##########################################################\n",
            "Epoch 40/40\n",
            "loss: 0.9733282327651978 - accuracy: 0.7082399725914001 - val_loss: 2.5028750896453857 - val_accuracy: 0.4489 - penalty: 0.0\n",
            "hidden layer sizes: [57, 22, 27, 69, 232], total units: 407\n",
            "CPU times: user 5min 18s, sys: 14.9 s, total: 5min 33s\n",
            "Wall time: 4min 37s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "histories = hyperparameter_search(train_fn, x=cifar100.X_train_norm, y=cifar100.y_train, validation_data=(cifar100.X_test_norm, cifar100.y_test), \n",
        "                                  learning_rate=[0.0002], regularization_penalty=[0.00002], regularization_method=['weighted_l1'], \n",
        "                                  self_scaling_epochs=[20], layer_sizes=[[65, 23, 29, 72, 201]], output_neurons=[100], min_new_neurons=[0, 1, 2, 4, 8, 16, 32], growth_percentage=[0.])"
      ],
      "metadata": {
        "id": "ShwjKpNOnXdM",
        "outputId": "5b3ac8e6-dca6-4673-d70c-37b0a6c04039",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0002, 2e-05, 'weighted_l1', 20, [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.4445, best_hidden_layer_sizes sizes: [59, 23, 29, 68, 201]\n",
            "Run with parameters (0.0002, 2e-05, 'weighted_l1', 20, [65, 23, 29, 72, 201], 100, 1, 0.0) completed, best_val_accuracy: 0.4427, best_hidden_layer_sizes sizes: [60, 23, 29, 70, 201]\n",
            "Run with parameters (0.0002, 2e-05, 'weighted_l1', 20, [65, 23, 29, 72, 201], 100, 2, 0.0) completed, best_val_accuracy: 0.4516, best_hidden_layer_sizes sizes: [62, 23, 29, 65, 203]\n",
            "Run with parameters (0.0002, 2e-05, 'weighted_l1', 20, [65, 23, 29, 72, 201], 100, 4, 0.0) completed, best_val_accuracy: 0.4449, best_hidden_layer_sizes sizes: [61, 23, 29, 72, 206]\n",
            "Run with parameters (0.0002, 2e-05, 'weighted_l1', 20, [65, 23, 29, 72, 201], 100, 8, 0.0) completed, best_val_accuracy: 0.4507, best_hidden_layer_sizes sizes: [59, 23, 29, 69, 210]\n",
            "Run with parameters (0.0002, 2e-05, 'weighted_l1', 20, [65, 23, 29, 72, 201], 100, 16, 0.0) completed, best_val_accuracy: 0.4421, best_hidden_layer_sizes sizes: [61, 23, 29, 70, 205]\n",
            "Run with parameters (0.0002, 2e-05, 'weighted_l1', 20, [65, 23, 29, 72, 201], 100, 32, 0.0) completed, best_val_accuracy: 0.4589, best_hidden_layer_sizes sizes: [58, 23, 29, 71, 207]\n",
            "Best overall combination: (0.0002, 2e-05, 'weighted_l1', 20, [65, 23, 29, 72, 201], 100, 32, 0.0), val_accuracy: 0.4589\n",
            "CPU times: user 21min 40s, sys: 50.7 s, total: 22min 30s\n",
            "Wall time: 18min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "histories = hyperparameter_search(train_fn, x=cifar100.X_train_norm, y=cifar100.y_train, validation_data=(cifar100.X_test_norm, cifar100.y_test), \n",
        "                                  learning_rate=[0.0002], regularization_penalty=[0.00002], regularization_method=[None, 'weighted_l1'], \n",
        "                                  self_scaling_epochs=[0], layer_sizes=[[65, 23, 29, 72, 201]], output_neurons=[100], min_new_neurons=[0], growth_percentage=[0.])"
      ],
      "metadata": {
        "id": "YaYpOv8c4eRx",
        "outputId": "55f6edcf-238e-4001-ee73-38c94817660f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0002, 2e-05, None, 0, [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.3236, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Run with parameters (0.0002, 2e-05, 'weighted_l1', 0, [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.3375, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Best overall combination: (0.0002, 2e-05, 'weighted_l1', 0, [65, 23, 29, 72, 201], 100, 0, 0.0), val_accuracy: 0.3375\n",
            "CPU times: user 4min 49s, sys: 12.2 s, total: 5min 1s\n",
            "Wall time: 3min 51s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "histories = hyperparameter_search(train_fn, x=cifar100.X_train_norm, y=cifar100.y_train, validation_data=(cifar100.X_test_norm, cifar100.y_test), \n",
        "                                  learning_rate=[0.0002], regularization_penalty=[0.00002], regularization_method=['weighted_l1'], \n",
        "                                  self_scaling_epochs=[20], layer_sizes=[[65, 23, 29, 72, 201]], output_neurons=[100], min_new_neurons=[0], growth_percentage=[0.])"
      ],
      "metadata": {
        "id": "l96IUzPz69YX",
        "outputId": "33ebcf9e-6ac6-4fc4-dc4f-5536467d4a0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0002, 2e-05, 'weighted_l1', 20, [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.4537, best_hidden_layer_sizes sizes: [60, 23, 29, 65, 201]\n",
            "Best overall combination: (0.0002, 2e-05, 'weighted_l1', 20, [65, 23, 29, 72, 201], 100, 0, 0.0), val_accuracy: 0.4537\n",
            "CPU times: user 3min 1s, sys: 7.44 s, total: 3min 9s\n",
            "Wall time: 2min 29s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "histories = hyperparameter_search(train_fn, x=cifar100.X_train_norm, y=cifar100.y_train, validation_data=(cifar100.X_test_norm, cifar100.y_test), \n",
        "                                  learning_rate=[0.0002], regularization_penalty=[0.00002], regularization_method=['weighted_l1'], \n",
        "                                  self_scaling_epochs=[0, 20], layer_sizes=[[65, 23, 29, 72, 201]], output_neurons=[100], min_new_neurons=[0], growth_percentage=[0.])"
      ],
      "metadata": {
        "id": "D8vf4fag9jkV",
        "outputId": "371cef82-2a07-402e-e354-10fcacecca31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0002, 2e-05, 'weighted_l1', 0, [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.3259, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Run with parameters (0.0002, 2e-05, 'weighted_l1', 20, [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.4573, best_hidden_layer_sizes sizes: [61, 23, 29, 62, 200]\n",
            "Best overall combination: (0.0002, 2e-05, 'weighted_l1', 20, [65, 23, 29, 72, 201], 100, 0, 0.0), val_accuracy: 0.4573\n",
            "CPU times: user 5min 35s, sys: 14 s, total: 5min 49s\n",
            "Wall time: 4min 33s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([EpochType.STATIC_WITH_REGULARIZATION] * 40)\n",
        "histories = hyperparameter_search(train_fn, x=cifar100.X_train_norm, y=cifar100.y_train, validation_data=(cifar100.X_test_norm, cifar100.y_test), \n",
        "                                  learning_rate=[0.0002], schedule=[schedule], regularization_penalty=[0.00002], regularization_method=[None, 'weighted_l1'], \n",
        "                                  layer_sizes=[[65, 23, 29, 72, 201]], output_neurons=[100], min_new_neurons=[0], growth_percentage=[0.])"
      ],
      "metadata": {
        "id": "6_BpUNyhsbHc",
        "outputId": "e4a2f7a0-2238-4c89-e80b-c9db41a15f75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 2e-05, None, [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.3213, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 2e-05, 'weighted_l1', [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.4173, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Best overall combination: (0.0002, 1111111111111111111111111111111111111111, 2e-05, 'weighted_l1', [65, 23, 29, 72, 201], 100, 0, 0.0), val_accuracy: 0.4173\n",
            "CPU times: user 5min 3s, sys: 13.3 s, total: 5min 16s\n",
            "Wall time: 4min 2s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([EpochType.STATIC_WITH_REGULARIZATION] * 20 + [EpochType.STATIC_NO_REGULARIZATION] * 20)\n",
        "histories = hyperparameter_search(train_fn, x=cifar100.X_train_norm, y=cifar100.y_train, validation_data=(cifar100.X_test_norm, cifar100.y_test), \n",
        "                                  learning_rate=[0.0002], schedule=[schedule], regularization_penalty=[0.00002], regularization_method=[None, 'weighted_l1'], \n",
        "                                  layer_sizes=[[65, 23, 29, 72, 201]], output_neurons=[100], min_new_neurons=[0], growth_percentage=[0.])"
      ],
      "metadata": {
        "id": "itosCeQJ1I1H",
        "outputId": "6a6a71e3-7d56-4a21-9aeb-233329844b76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0002, 1111111111111111111122222222222222222222, 2e-05, None, [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.3227, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Run with parameters (0.0002, 1111111111111111111122222222222222222222, 2e-05, 'weighted_l1', [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.4239, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Best overall combination: (0.0002, 1111111111111111111122222222222222222222, 2e-05, 'weighted_l1', [65, 23, 29, 72, 201], 100, 0, 0.0), val_accuracy: 0.4239\n",
            "CPU times: user 4min 56s, sys: 12.7 s, total: 5min 9s\n",
            "Wall time: 3min 56s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([EpochType.DYNAMIC] * 20 + [EpochType.STATIC_NO_REGULARIZATION] * 20)\n",
        "histories = hyperparameter_search(train_fn, x=cifar100.X_train_norm, y=cifar100.y_train, validation_data=(cifar100.X_test_norm, cifar100.y_test), \n",
        "                                  learning_rate=[0.0002], schedule=[schedule], regularization_penalty=[0.00002], regularization_method=[None, 'weighted_l1'], \n",
        "                                  layer_sizes=[[65, 23, 29, 72, 201]], output_neurons=[100], min_new_neurons=[0], growth_percentage=[0.])"
      ],
      "metadata": {
        "id": "aC_kttDS8SuN",
        "outputId": "63eaf670-7b0d-4748-f090-73e76907ca35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0002, 0000000000000000000022222222222222222222, 2e-05, None, [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.3333, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Run with parameters (0.0002, 0000000000000000000022222222222222222222, 2e-05, 'weighted_l1', [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.4584, best_hidden_layer_sizes sizes: [61, 23, 29, 60, 201]\n",
            "Best overall combination: (0.0002, 0000000000000000000022222222222222222222, 2e-05, 'weighted_l1', [65, 23, 29, 72, 201], 100, 0, 0.0), val_accuracy: 0.4584\n",
            "CPU times: user 5min 46s, sys: 13.7 s, total: 6min\n",
            "Wall time: 4min 43s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## L1 regularization"
      ],
      "metadata": {
        "id": "fWKv7M3RQ9q5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([EpochType.STATIC_WITH_REGULARIZATION] * 40)\n",
        "histories = hyperparameter_search(train_fn, x=cifar100.X_train_norm, y=cifar100.y_train, validation_data=(cifar100.X_test_norm, cifar100.y_test), \n",
        "                                  learning_rate=[0.0002], schedule=[schedule], regularization_penalty=[0., 0.00002, 0.0002, 0.002, 0.02], regularization_method=['l1'], \n",
        "                                  layer_sizes=[[65, 23, 29, 72, 201]], output_neurons=[100], min_new_neurons=[0], growth_percentage=[0.])"
      ],
      "metadata": {
        "id": "8DAHs2dAJQoe",
        "outputId": "8c8b874d-4f5e-4b88-f396-ec51f2cb19af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 0.0, 'l1', [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.3278, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 2e-05, 'l1', [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.3348, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 0.0002, 'l1', [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.4063, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 0.002, 'l1', [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.2332, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 0.02, 'l1', [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.0103, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Best overall combination: (0.0002, 1111111111111111111111111111111111111111, 0.0002, 'l1', [65, 23, 29, 72, 201], 100, 0, 0.0), val_accuracy: 0.4063\n",
            "CPU times: user 12min 58s, sys: 35.9 s, total: 13min 34s\n",
            "Wall time: 10min 24s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([EpochType.STATIC_WITH_REGULARIZATION] * 40)\n",
        "histories = hyperparameter_search(train_fn, x=cifar100.X_train_norm, y=cifar100.y_train, validation_data=(cifar100.X_test_norm, cifar100.y_test), \n",
        "                                  learning_rate=[0.0002], schedule=[schedule], regularization_penalty=[0.00005, 0.0001, 0.0002, 0.0004, 0.0008], regularization_method=['l1'], \n",
        "                                  layer_sizes=[[65, 23, 29, 72, 201]], output_neurons=[100], min_new_neurons=[0], growth_percentage=[0.])"
      ],
      "metadata": {
        "id": "8HBU2HJyNL46",
        "outputId": "d0a60ba4-ca1c-48fb-c7b4-1161abbe7b45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 5e-05, 'l1', [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.3447, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 0.0001, 'l1', [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.3606, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 0.0002, 'l1', [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.4194, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 0.0004, 'l1', [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.4177, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 0.0008, 'l1', [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.3714, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Best overall combination: (0.0002, 1111111111111111111111111111111111111111, 0.0002, 'l1', [65, 23, 29, 72, 201], 100, 0, 0.0), val_accuracy: 0.4194\n",
            "CPU times: user 12min 54s, sys: 36.2 s, total: 13min 30s\n",
            "Wall time: 10min 18s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([EpochType.STATIC_WITH_REGULARIZATION] * 40)\n",
        "histories = hyperparameter_search(train_fn, x=cifar100.X_train_norm, y=cifar100.y_train, validation_data=(cifar100.X_test_norm, cifar100.y_test), \n",
        "                                  learning_rate=[0.0002], schedule=[schedule], regularization_penalty=[0.0003], regularization_method=['l1'], \n",
        "                                  layer_sizes=[[65, 23, 29, 72, 201]], output_neurons=[100], min_new_neurons=[0], growth_percentage=[0.])"
      ],
      "metadata": {
        "id": "sdvVVnSIPsdA",
        "outputId": "fb596f80-2d2d-4fa1-e1bf-3b383093d0b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 0.0003, 'l1', [65, 23, 29, 72, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.4293, best_hidden_layer_sizes sizes: [65, 23, 29, 72, 201]\n",
            "Best overall combination: (0.0002, 1111111111111111111111111111111111111111, 0.0003, 'l1', [65, 23, 29, 72, 201], 100, 0, 0.0), val_accuracy: 0.4293\n",
            "CPU times: user 2min 33s, sys: 7.19 s, total: 2min 40s\n",
            "Wall time: 2min 2s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "schedule = Schedule([EpochType.STATIC_WITH_REGULARIZATION] * 40)\n",
        "histories = hyperparameter_search(train_fn, x=cifar100.X_train_norm, y=cifar100.y_train, validation_data=(cifar100.X_test_norm, cifar100.y_test), \n",
        "                                  learning_rate=[0.0002], schedule=[schedule], regularization_penalty=[0.0002, 0.0003, 0.0004], regularization_method=['l1'], \n",
        "                                  layer_sizes=[[66, 66, 66, 66, 201]], output_neurons=[100], min_new_neurons=[0], growth_percentage=[0.])"
      ],
      "metadata": {
        "id": "aqJHRNzZS0O9",
        "outputId": "c82747f0-e52b-49cc-c076-22821cbe00e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 0.0002, 'l1', [66, 66, 66, 66, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.4416, best_hidden_layer_sizes sizes: [66, 66, 66, 66, 201]\n",
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 0.0003, 'l1', [66, 66, 66, 66, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.4535, best_hidden_layer_sizes sizes: [66, 66, 66, 66, 201]\n",
            "Run with parameters (0.0002, 1111111111111111111111111111111111111111, 0.0004, 'l1', [66, 66, 66, 66, 201], 100, 0, 0.0) completed, best_val_accuracy: 0.441, best_hidden_layer_sizes sizes: [66, 66, 66, 66, 201]\n",
            "Best overall combination: (0.0002, 1111111111111111111111111111111111111111, 0.0003, 'l1', [66, 66, 66, 66, 201], 100, 0, 0.0), val_accuracy: 0.4535\n",
            "CPU times: user 8min, sys: 17.1 s, total: 8min 17s\n",
            "Wall time: 7min 14s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "model = get_convolutional_model(cifar100.X_train_norm, regularization_penalty=0.00002, regularization_method=None, layer_sizes=[65, 23, 29, 72, 201], output_neurons=100)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "history = model.fit(cifar100.X_train_norm, cifar100.y_train, optimizer, epochs=40, self_scaling_epochs=20, batch_size=batch_size, \n",
        "                    min_new_neurons=0, validation_data=(cifar100.X_test_norm, cifar100.y_test), pruning_only_epochs=0, \n",
        "                    growth_percentage=0., verbose=True)"
      ],
      "metadata": {
        "id": "lZrp9FkE7_5n",
        "outputId": "db5be5c6-9677-408f-fbd5-0e0bf177d81d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.157856464385986 - val_accuracy: 0.0083 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.157856464385986 - val_accuracy: 0.0083 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 4.065201759338379 - accuracy: 0.10670000314712524 - val_loss: 3.5247750282287598 - val_accuracy: 0.1916 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.5247750282287598 - val_accuracy: 0.1916 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 2/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.5247750282287598 - val_accuracy: 0.1916 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.5247750282287598 - val_accuracy: 0.1916 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 3.5729212760925293 - accuracy: 0.17825999855995178 - val_loss: 3.3440968990325928 - val_accuracy: 0.2164 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.3440968990325928 - val_accuracy: 0.2164 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 3/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.3440968990325928 - val_accuracy: 0.2164 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.3440968990325928 - val_accuracy: 0.2164 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 3.349431037902832 - accuracy: 0.21291999518871307 - val_loss: 3.198848247528076 - val_accuracy: 0.2406 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.198848247528076 - val_accuracy: 0.2406 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 4/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.198848247528076 - val_accuracy: 0.2406 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.198848247528076 - val_accuracy: 0.2406 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 3.187880039215088 - accuracy: 0.24267999827861786 - val_loss: 3.1080782413482666 - val_accuracy: 0.2564 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.1080782413482666 - val_accuracy: 0.2564 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 5/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.1080782413482666 - val_accuracy: 0.2564 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.1080782413482666 - val_accuracy: 0.2564 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 3.033339738845825 - accuracy: 0.2681399881839752 - val_loss: 3.058805465698242 - val_accuracy: 0.2718 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 3.058805465698242 - val_accuracy: 0.2718 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 6/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 3.058805465698242 - val_accuracy: 0.2718 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 3.058805465698242 - val_accuracy: 0.2718 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 2.9115965366363525 - accuracy: 0.2906799912452698 - val_loss: 2.978360414505005 - val_accuracy: 0.2797 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.978360414505005 - val_accuracy: 0.2797 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 7/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.978360414505005 - val_accuracy: 0.2797 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.978360414505005 - val_accuracy: 0.2797 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 2.796330213546753 - accuracy: 0.31130000948905945 - val_loss: 2.9387381076812744 - val_accuracy: 0.293 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.9387381076812744 - val_accuracy: 0.293 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 8/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.9387381076812744 - val_accuracy: 0.293 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.9387381076812744 - val_accuracy: 0.293 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 2.6931912899017334 - accuracy: 0.33215999603271484 - val_loss: 2.8953444957733154 - val_accuracy: 0.2977 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.8953444957733154 - val_accuracy: 0.2977 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 9/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8953444957733154 - val_accuracy: 0.2977 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8953444957733154 - val_accuracy: 0.2977 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 2.578977346420288 - accuracy: 0.35468000173568726 - val_loss: 2.886378765106201 - val_accuracy: 0.3036 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.886378765106201 - val_accuracy: 0.3036 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 10/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.886378765106201 - val_accuracy: 0.3036 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.886378765106201 - val_accuracy: 0.3036 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 2.487252950668335 - accuracy: 0.3716199994087219 - val_loss: 2.8758556842803955 - val_accuracy: 0.3082 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.8758556842803955 - val_accuracy: 0.3082 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 11/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8758556842803955 - val_accuracy: 0.3082 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8758556842803955 - val_accuracy: 0.3082 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 2.4155020713806152 - accuracy: 0.3852800130844116 - val_loss: 2.877117872238159 - val_accuracy: 0.3078 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.877117872238159 - val_accuracy: 0.3078 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 12/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.877117872238159 - val_accuracy: 0.3078 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.877117872238159 - val_accuracy: 0.3078 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 2.329409122467041 - accuracy: 0.402319997549057 - val_loss: 2.8944742679595947 - val_accuracy: 0.3127 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.8944742679595947 - val_accuracy: 0.3127 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 13/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8944742679595947 - val_accuracy: 0.3127 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8944742679595947 - val_accuracy: 0.3127 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 2.2553887367248535 - accuracy: 0.41822001338005066 - val_loss: 2.842076539993286 - val_accuracy: 0.3198 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.842076539993286 - val_accuracy: 0.3198 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 14/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.842076539993286 - val_accuracy: 0.3198 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.842076539993286 - val_accuracy: 0.3198 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 2.2035233974456787 - accuracy: 0.4280399978160858 - val_loss: 2.846912145614624 - val_accuracy: 0.3214 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.846912145614624 - val_accuracy: 0.3214 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 15/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.846912145614624 - val_accuracy: 0.3214 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.846912145614624 - val_accuracy: 0.3214 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 2.1467857360839844 - accuracy: 0.4435400068759918 - val_loss: 2.8552422523498535 - val_accuracy: 0.3189 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.8552422523498535 - val_accuracy: 0.3189 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 16/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8552422523498535 - val_accuracy: 0.3189 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8552422523498535 - val_accuracy: 0.3189 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 2.0946402549743652 - accuracy: 0.45155999064445496 - val_loss: 2.903836250305176 - val_accuracy: 0.3116 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.903836250305176 - val_accuracy: 0.3116 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 17/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.903836250305176 - val_accuracy: 0.3116 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.903836250305176 - val_accuracy: 0.3116 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 2.04494309425354 - accuracy: 0.4598200023174286 - val_loss: 2.9353861808776855 - val_accuracy: 0.3214 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.9353861808776855 - val_accuracy: 0.3214 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 18/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.9353861808776855 - val_accuracy: 0.3214 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.9353861808776855 - val_accuracy: 0.3214 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 2.009782552719116 - accuracy: 0.46658000349998474 - val_loss: 2.9045708179473877 - val_accuracy: 0.3198 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.9045708179473877 - val_accuracy: 0.3198 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 19/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.9045708179473877 - val_accuracy: 0.3198 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.9045708179473877 - val_accuracy: 0.3198 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 1.9685176610946655 - accuracy: 0.4777800142765045 - val_loss: 2.8966259956359863 - val_accuracy: 0.3257 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.8966259956359863 - val_accuracy: 0.3257 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 20/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8966259956359863 - val_accuracy: 0.3257 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 2.8966259956359863 - val_accuracy: 0.3257 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "Before pruning:\n",
            "loss: 1.9309577941894531 - accuracy: 0.4853399991989136 - val_loss: 2.911456823348999 - val_accuracy: 0.3221 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 2.911456823348999 - val_accuracy: 0.3221 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 21/40\n",
            "loss: 1.895734190940857 - accuracy: 0.4927999973297119 - val_loss: 2.953035354614258 - val_accuracy: 0.323 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 22/40\n",
            "loss: 1.630110502243042 - accuracy: 0.5537400245666504 - val_loss: 2.9599382877349854 - val_accuracy: 0.3228 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 23/40\n",
            "loss: 1.5496588945388794 - accuracy: 0.5740000009536743 - val_loss: 2.960631847381592 - val_accuracy: 0.3258 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 24/40\n",
            "loss: 1.4891995191574097 - accuracy: 0.5875599980354309 - val_loss: 2.979832649230957 - val_accuracy: 0.3254 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 25/40\n",
            "loss: 1.456904649734497 - accuracy: 0.5933799743652344 - val_loss: 2.9904520511627197 - val_accuracy: 0.3281 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 26/40\n",
            "loss: 1.4324601888656616 - accuracy: 0.5974000096321106 - val_loss: 3.0426883697509766 - val_accuracy: 0.327 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 27/40\n",
            "loss: 1.385547161102295 - accuracy: 0.6122599840164185 - val_loss: 3.0661776065826416 - val_accuracy: 0.3266 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 28/40\n",
            "loss: 1.370500922203064 - accuracy: 0.6154400110244751 - val_loss: 3.084153413772583 - val_accuracy: 0.3302 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 29/40\n",
            "loss: 1.3446838855743408 - accuracy: 0.619379997253418 - val_loss: 3.058830738067627 - val_accuracy: 0.3281 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 30/40\n",
            "loss: 1.314578890800476 - accuracy: 0.6263399720191956 - val_loss: 3.11197829246521 - val_accuracy: 0.3288 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 31/40\n",
            "loss: 1.3052502870559692 - accuracy: 0.629859983921051 - val_loss: 3.16294527053833 - val_accuracy: 0.3263 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 32/40\n",
            "loss: 1.2803997993469238 - accuracy: 0.6313400268554688 - val_loss: 3.1292505264282227 - val_accuracy: 0.3315 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 33/40\n",
            "loss: 1.2594624757766724 - accuracy: 0.6357600092887878 - val_loss: 3.1777091026306152 - val_accuracy: 0.3275 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 34/40\n",
            "loss: 1.2384108304977417 - accuracy: 0.6413599848747253 - val_loss: 3.1524760723114014 - val_accuracy: 0.3294 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 35/40\n",
            "loss: 1.223309874534607 - accuracy: 0.6459599733352661 - val_loss: 3.2311999797821045 - val_accuracy: 0.3227 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 36/40\n",
            "loss: 1.2037484645843506 - accuracy: 0.6497799754142761 - val_loss: 3.1915900707244873 - val_accuracy: 0.3298 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 37/40\n",
            "loss: 1.200270414352417 - accuracy: 0.6505200266838074 - val_loss: 3.2524917125701904 - val_accuracy: 0.3253 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 38/40\n",
            "loss: 1.1940999031066895 - accuracy: 0.6520400047302246 - val_loss: 3.2098562717437744 - val_accuracy: 0.3284 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 39/40\n",
            "loss: 1.1589621305465698 - accuracy: 0.661080002784729 - val_loss: 3.237009048461914 - val_accuracy: 0.3242 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "##########################################################\n",
            "Epoch 40/40\n",
            "loss: 1.1579691171646118 - accuracy: 0.6603800058364868 - val_loss: 3.270716428756714 - val_accuracy: 0.3272 - penalty: 0.0\n",
            "hidden layer sizes: [65, 23, 29, 72, 201], total units: 390\n",
            "CPU times: user 3min 6s, sys: 7.57 s, total: 3min 14s\n",
            "Wall time: 2min 34s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test - Tiny ImageNet"
      ],
      "metadata": {
        "id": "Vygd6mHvNv_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tiny_imagenet = get_tiny_imagenet_dataset()"
      ],
      "metadata": {
        "id": "1CAsBOpLNvZe",
        "outputId": "32d78ba1-f59a-4c57-aa20-e9e4b119000f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing the downloaded dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "model = get_convolutional_model(tiny_imagenet.X_train_norm, regularization_penalty=0.00002, regularization_method='weighted_l1', layer_sizes=[100, 100, 100, 100, 100], output_neurons=200)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "schedule = Schedule([EpochType.DYNAMIC] * 20 + [EpochType.STATIC_NO_REGULARIZATION] * 20)\n",
        "history = model.fit(tiny_imagenet.X_train_norm, tiny_imagenet.y_train, optimizer, schedule=schedule, batch_size=batch_size, min_new_neurons=20, \n",
        "                    validation_data=(tiny_imagenet.X_test_norm, tiny_imagenet.y_test), growth_percentage=0.2, verbose=True)"
      ],
      "metadata": {
        "id": "H80AY3X4N2DX",
        "outputId": "1c6152dc-9a33-4b90-c943-38f087024229",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.541385173797607 - val_accuracy: 0.0073 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100], total units: 500\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.541385173797607 - val_accuracy: 0.0073 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "Before pruning:\n",
            "loss: 4.205804824829102 - accuracy: 0.1064400002360344 - val_loss: 5.56486701965332 - val_accuracy: 0.0509 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120], total units: 600\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 5.564840793609619 - val_accuracy: 0.0509 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 98, 120], total units: 518\n",
            "##########################################################\n",
            "Epoch 2/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.564840793609619 - val_accuracy: 0.0509 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 98, 120], total units: 518\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.564841270446777 - val_accuracy: 0.0509 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 118, 144], total units: 622\n",
            "Before pruning:\n",
            "loss: 3.8965485095977783 - accuracy: 0.14381000399589539 - val_loss: 5.321378707885742 - val_accuracy: 0.0614 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 118, 144], total units: 622\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 5.321302890777588 - val_accuracy: 0.0612 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 68, 67, 52, 144], total units: 431\n",
            "##########################################################\n",
            "Epoch 3/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.321302890777588 - val_accuracy: 0.0612 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 68, 67, 52, 144], total units: 431\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.321302890777588 - val_accuracy: 0.0612 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 88, 87, 72, 172], total units: 539\n",
            "Before pruning:\n",
            "loss: 3.7714035511016846 - accuracy: 0.16011999547481537 - val_loss: 5.294824123382568 - val_accuracy: 0.0692 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 88, 87, 72, 172], total units: 539\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 5.294279098510742 - val_accuracy: 0.0692 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 32, 59, 37, 170], total units: 398\n",
            "##########################################################\n",
            "Epoch 4/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.294279098510742 - val_accuracy: 0.0692 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 32, 59, 37, 170], total units: 398\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.294279098510742 - val_accuracy: 0.0692 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 52, 79, 57, 204], total units: 512\n",
            "Before pruning:\n",
            "loss: 3.7037808895111084 - accuracy: 0.16954000294208527 - val_loss: 4.997419357299805 - val_accuracy: 0.0708 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 52, 79, 57, 204], total units: 512\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 5.004544258117676 - val_accuracy: 0.0708 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 28, 52, 31, 191], total units: 402\n",
            "##########################################################\n",
            "Epoch 5/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.004544258117676 - val_accuracy: 0.0708 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 28, 52, 31, 191], total units: 402\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.004544258117676 - val_accuracy: 0.0708 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 48, 72, 51, 229], total units: 520\n",
            "Before pruning:\n",
            "loss: 3.6499428749084473 - accuracy: 0.17728999257087708 - val_loss: 5.194529056549072 - val_accuracy: 0.072 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 48, 72, 51, 229], total units: 520\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 5.194575786590576 - val_accuracy: 0.0719 - penalty: 2e-05\n",
            "hidden layer sizes: [95, 24, 46, 31, 202], total units: 398\n",
            "##########################################################\n",
            "Epoch 6/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.194575786590576 - val_accuracy: 0.0719 - penalty: 2e-05\n",
            "hidden layer sizes: [95, 24, 46, 31, 202], total units: 398\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.194575786590576 - val_accuracy: 0.0719 - penalty: 2e-05\n",
            "hidden layer sizes: [115, 44, 66, 51, 242], total units: 518\n",
            "Before pruning:\n",
            "loss: 3.566897392272949 - accuracy: 0.19354000687599182 - val_loss: 4.994402885437012 - val_accuracy: 0.0862 - penalty: 2e-05\n",
            "hidden layer sizes: [115, 44, 66, 51, 242], total units: 518\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.996287822723389 - val_accuracy: 0.0863 - penalty: 2e-05\n",
            "hidden layer sizes: [91, 20, 43, 29, 208], total units: 391\n",
            "##########################################################\n",
            "Epoch 7/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.996287822723389 - val_accuracy: 0.0863 - penalty: 2e-05\n",
            "hidden layer sizes: [91, 20, 43, 29, 208], total units: 391\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.9962873458862305 - val_accuracy: 0.0863 - penalty: 2e-05\n",
            "hidden layer sizes: [111, 40, 63, 49, 249], total units: 512\n",
            "Before pruning:\n",
            "loss: 3.5002574920654297 - accuracy: 0.2057799994945526 - val_loss: 4.894510269165039 - val_accuracy: 0.0937 - penalty: 2e-05\n",
            "hidden layer sizes: [111, 40, 63, 49, 249], total units: 512\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.894584655761719 - val_accuracy: 0.0933 - penalty: 2e-05\n",
            "hidden layer sizes: [82, 17, 40, 33, 217], total units: 389\n",
            "##########################################################\n",
            "Epoch 8/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.894584655761719 - val_accuracy: 0.0933 - penalty: 2e-05\n",
            "hidden layer sizes: [82, 17, 40, 33, 217], total units: 389\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.894584655761719 - val_accuracy: 0.0933 - penalty: 2e-05\n",
            "hidden layer sizes: [102, 37, 60, 53, 260], total units: 512\n",
            "Before pruning:\n",
            "loss: 3.4470133781433105 - accuracy: 0.21307000517845154 - val_loss: 4.981642723083496 - val_accuracy: 0.0864 - penalty: 2e-05\n",
            "hidden layer sizes: [102, 37, 60, 53, 260], total units: 512\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 5.00131893157959 - val_accuracy: 0.0856 - penalty: 2e-05\n",
            "hidden layer sizes: [79, 17, 39, 32, 215], total units: 382\n",
            "##########################################################\n",
            "Epoch 9/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.00131893157959 - val_accuracy: 0.0856 - penalty: 2e-05\n",
            "hidden layer sizes: [79, 17, 39, 32, 215], total units: 382\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.00131893157959 - val_accuracy: 0.0856 - penalty: 2e-05\n",
            "hidden layer sizes: [99, 37, 59, 52, 258], total units: 505\n",
            "Before pruning:\n",
            "loss: 3.396408796310425 - accuracy: 0.223690003156662 - val_loss: 4.852090835571289 - val_accuracy: 0.0922 - penalty: 2e-05\n",
            "hidden layer sizes: [99, 37, 59, 52, 258], total units: 505\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.8550238609313965 - val_accuracy: 0.0922 - penalty: 2e-05\n",
            "hidden layer sizes: [75, 16, 35, 40, 223], total units: 389\n",
            "##########################################################\n",
            "Epoch 10/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.8550238609313965 - val_accuracy: 0.0922 - penalty: 2e-05\n",
            "hidden layer sizes: [75, 16, 35, 40, 223], total units: 389\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.855023384094238 - val_accuracy: 0.0922 - penalty: 2e-05\n",
            "hidden layer sizes: [95, 36, 55, 60, 267], total units: 513\n",
            "Before pruning:\n",
            "loss: 3.360323190689087 - accuracy: 0.22967000305652618 - val_loss: 4.973642349243164 - val_accuracy: 0.0927 - penalty: 2e-05\n",
            "hidden layer sizes: [95, 36, 55, 60, 267], total units: 513\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.978872776031494 - val_accuracy: 0.0924 - penalty: 2e-05\n",
            "hidden layer sizes: [74, 15, 33, 46, 222], total units: 390\n",
            "##########################################################\n",
            "Epoch 11/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.978872776031494 - val_accuracy: 0.0924 - penalty: 2e-05\n",
            "hidden layer sizes: [74, 15, 33, 46, 222], total units: 390\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.978871822357178 - val_accuracy: 0.0924 - penalty: 2e-05\n",
            "hidden layer sizes: [94, 35, 53, 66, 266], total units: 514\n",
            "Before pruning:\n",
            "loss: 3.3375494480133057 - accuracy: 0.2337300032377243 - val_loss: 4.709395885467529 - val_accuracy: 0.0976 - penalty: 2e-05\n",
            "hidden layer sizes: [94, 35, 53, 66, 266], total units: 514\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.710136890411377 - val_accuracy: 0.0974 - penalty: 2e-05\n",
            "hidden layer sizes: [71, 14, 32, 48, 228], total units: 393\n",
            "##########################################################\n",
            "Epoch 12/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.710136890411377 - val_accuracy: 0.0974 - penalty: 2e-05\n",
            "hidden layer sizes: [71, 14, 32, 48, 228], total units: 393\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.710136890411377 - val_accuracy: 0.0974 - penalty: 2e-05\n",
            "hidden layer sizes: [91, 34, 52, 68, 273], total units: 518\n",
            "Before pruning:\n",
            "loss: 3.31855845451355 - accuracy: 0.23645000159740448 - val_loss: 4.897375106811523 - val_accuracy: 0.1026 - penalty: 2e-05\n",
            "hidden layer sizes: [91, 34, 52, 68, 273], total units: 518\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.901175498962402 - val_accuracy: 0.1021 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 14, 32, 44, 229], total units: 387\n",
            "##########################################################\n",
            "Epoch 13/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.901175498962402 - val_accuracy: 0.1021 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 14, 32, 44, 229], total units: 387\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.9011759757995605 - val_accuracy: 0.1021 - penalty: 2e-05\n",
            "hidden layer sizes: [88, 34, 52, 64, 274], total units: 512\n",
            "Before pruning:\n",
            "loss: 3.295912504196167 - accuracy: 0.24014000594615936 - val_loss: 4.750245094299316 - val_accuracy: 0.1023 - penalty: 2e-05\n",
            "hidden layer sizes: [88, 34, 52, 64, 274], total units: 512\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.757006645202637 - val_accuracy: 0.1025 - penalty: 2e-05\n",
            "hidden layer sizes: [67, 13, 31, 43, 228], total units: 382\n",
            "##########################################################\n",
            "Epoch 14/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.757006645202637 - val_accuracy: 0.1025 - penalty: 2e-05\n",
            "hidden layer sizes: [67, 13, 31, 43, 228], total units: 382\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.757007122039795 - val_accuracy: 0.1025 - penalty: 2e-05\n",
            "hidden layer sizes: [87, 33, 51, 63, 273], total units: 507\n",
            "Before pruning:\n",
            "loss: 3.283747911453247 - accuracy: 0.23996999859809875 - val_loss: 4.84633731842041 - val_accuracy: 0.0973 - penalty: 2e-05\n",
            "hidden layer sizes: [87, 33, 51, 63, 273], total units: 507\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.842898845672607 - val_accuracy: 0.0975 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 13, 28, 46, 227], total units: 378\n",
            "##########################################################\n",
            "Epoch 15/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.842898845672607 - val_accuracy: 0.0975 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 13, 28, 46, 227], total units: 378\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.842897891998291 - val_accuracy: 0.0975 - penalty: 2e-05\n",
            "hidden layer sizes: [84, 33, 48, 66, 272], total units: 503\n",
            "Before pruning:\n",
            "loss: 3.276815414428711 - accuracy: 0.2414499968290329 - val_loss: 4.685425281524658 - val_accuracy: 0.1039 - penalty: 2e-05\n",
            "hidden layer sizes: [84, 33, 48, 66, 272], total units: 503\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.689558029174805 - val_accuracy: 0.1039 - penalty: 2e-05\n",
            "hidden layer sizes: [62, 13, 27, 42, 228], total units: 372\n",
            "##########################################################\n",
            "Epoch 16/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.689558029174805 - val_accuracy: 0.1039 - penalty: 2e-05\n",
            "hidden layer sizes: [62, 13, 27, 42, 228], total units: 372\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.689559459686279 - val_accuracy: 0.1039 - penalty: 2e-05\n",
            "hidden layer sizes: [82, 33, 47, 62, 273], total units: 497\n",
            "Before pruning:\n",
            "loss: 3.261875867843628 - accuracy: 0.24492000043392181 - val_loss: 4.759136199951172 - val_accuracy: 0.1067 - penalty: 2e-05\n",
            "hidden layer sizes: [82, 33, 47, 62, 273], total units: 497\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.765242099761963 - val_accuracy: 0.1064 - penalty: 2e-05\n",
            "hidden layer sizes: [61, 13, 27, 48, 230], total units: 379\n",
            "##########################################################\n",
            "Epoch 17/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.765242099761963 - val_accuracy: 0.1064 - penalty: 2e-05\n",
            "hidden layer sizes: [61, 13, 27, 48, 230], total units: 379\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.765242099761963 - val_accuracy: 0.1064 - penalty: 2e-05\n",
            "hidden layer sizes: [81, 33, 47, 68, 276], total units: 505\n",
            "Before pruning:\n",
            "loss: 3.2492456436157227 - accuracy: 0.2475000023841858 - val_loss: 4.6927490234375 - val_accuracy: 0.1153 - penalty: 2e-05\n",
            "hidden layer sizes: [81, 33, 47, 68, 276], total units: 505\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.690906524658203 - val_accuracy: 0.1156 - penalty: 2e-05\n",
            "hidden layer sizes: [58, 13, 27, 48, 231], total units: 377\n",
            "##########################################################\n",
            "Epoch 18/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.690906524658203 - val_accuracy: 0.1156 - penalty: 2e-05\n",
            "hidden layer sizes: [58, 13, 27, 48, 231], total units: 377\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.6909074783325195 - val_accuracy: 0.1156 - penalty: 2e-05\n",
            "hidden layer sizes: [78, 33, 47, 68, 277], total units: 503\n",
            "Before pruning:\n",
            "loss: 3.2382490634918213 - accuracy: 0.24684999883174896 - val_loss: 4.634526252746582 - val_accuracy: 0.1145 - penalty: 2e-05\n",
            "hidden layer sizes: [78, 33, 47, 68, 277], total units: 503\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.633401870727539 - val_accuracy: 0.1144 - penalty: 2e-05\n",
            "hidden layer sizes: [53, 13, 27, 48, 231], total units: 372\n",
            "##########################################################\n",
            "Epoch 19/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.633401870727539 - val_accuracy: 0.1144 - penalty: 2e-05\n",
            "hidden layer sizes: [53, 13, 27, 48, 231], total units: 372\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.633401393890381 - val_accuracy: 0.1144 - penalty: 2e-05\n",
            "hidden layer sizes: [73, 33, 47, 68, 277], total units: 498\n",
            "Before pruning:\n",
            "loss: 3.231672525405884 - accuracy: 0.2491600066423416 - val_loss: 4.820346832275391 - val_accuracy: 0.1071 - penalty: 2e-05\n",
            "hidden layer sizes: [73, 33, 47, 68, 277], total units: 498\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.835977077484131 - val_accuracy: 0.1071 - penalty: 2e-05\n",
            "hidden layer sizes: [51, 13, 31, 46, 228], total units: 369\n",
            "##########################################################\n",
            "Epoch 20/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.835977077484131 - val_accuracy: 0.1071 - penalty: 2e-05\n",
            "hidden layer sizes: [51, 13, 31, 46, 228], total units: 369\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.835976600646973 - val_accuracy: 0.1071 - penalty: 2e-05\n",
            "hidden layer sizes: [71, 33, 51, 66, 273], total units: 494\n",
            "Before pruning:\n",
            "loss: 3.225036859512329 - accuracy: 0.2508699893951416 - val_loss: 4.6464762687683105 - val_accuracy: 0.1197 - penalty: 2e-05\n",
            "hidden layer sizes: [71, 33, 51, 66, 273], total units: 494\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.655115127563477 - val_accuracy: 0.1192 - penalty: 2e-05\n",
            "hidden layer sizes: [51, 13, 29, 47, 228], total units: 368\n",
            "##########################################################\n",
            "Epoch 21/40\n",
            "loss: 3.3610804080963135 - accuracy: 0.2425999939441681 - val_loss: 4.579482555389404 - val_accuracy: 0.1247 - penalty: 0.0\n",
            "hidden layer sizes: [51, 13, 29, 47, 228], total units: 368\n",
            "##########################################################\n",
            "Epoch 22/40\n",
            "loss: 2.941493511199951 - accuracy: 0.30689001083374023 - val_loss: 4.419999122619629 - val_accuracy: 0.1384 - penalty: 0.0\n",
            "hidden layer sizes: [51, 13, 29, 47, 228], total units: 368\n",
            "##########################################################\n",
            "Epoch 23/40\n",
            "loss: 2.7995197772979736 - accuracy: 0.3349199891090393 - val_loss: 4.387439727783203 - val_accuracy: 0.141 - penalty: 0.0\n",
            "hidden layer sizes: [51, 13, 29, 47, 228], total units: 368\n",
            "##########################################################\n",
            "Epoch 24/40\n",
            "loss: 2.6672518253326416 - accuracy: 0.36039999127388 - val_loss: 4.462294578552246 - val_accuracy: 0.1452 - penalty: 0.0\n",
            "hidden layer sizes: [51, 13, 29, 47, 228], total units: 368\n",
            "##########################################################\n",
            "Epoch 25/40\n",
            "loss: 2.543436050415039 - accuracy: 0.38367000222206116 - val_loss: 4.653909206390381 - val_accuracy: 0.1419 - penalty: 0.0\n",
            "hidden layer sizes: [51, 13, 29, 47, 228], total units: 368\n",
            "##########################################################\n",
            "Epoch 26/40\n",
            "loss: 2.4357452392578125 - accuracy: 0.4075999855995178 - val_loss: 4.394029140472412 - val_accuracy: 0.1512 - penalty: 0.0\n",
            "hidden layer sizes: [51, 13, 29, 47, 228], total units: 368\n",
            "##########################################################\n",
            "Epoch 27/40\n",
            "loss: 2.3158071041107178 - accuracy: 0.42952999472618103 - val_loss: 4.538326740264893 - val_accuracy: 0.147 - penalty: 0.0\n",
            "hidden layer sizes: [51, 13, 29, 47, 228], total units: 368\n",
            "##########################################################\n",
            "Epoch 28/40\n",
            "loss: 2.2101857662200928 - accuracy: 0.4513700008392334 - val_loss: 4.663854122161865 - val_accuracy: 0.1435 - penalty: 0.0\n",
            "hidden layer sizes: [51, 13, 29, 47, 228], total units: 368\n",
            "##########################################################\n",
            "Epoch 29/40\n",
            "loss: 2.1085498332977295 - accuracy: 0.4704200029373169 - val_loss: 4.505544662475586 - val_accuracy: 0.1548 - penalty: 0.0\n",
            "hidden layer sizes: [51, 13, 29, 47, 228], total units: 368\n",
            "##########################################################\n",
            "Epoch 30/40\n",
            "loss: 2.0180747509002686 - accuracy: 0.48791998624801636 - val_loss: 4.598823070526123 - val_accuracy: 0.1493 - penalty: 0.0\n",
            "hidden layer sizes: [51, 13, 29, 47, 228], total units: 368\n",
            "##########################################################\n",
            "Epoch 31/40\n",
            "loss: 1.9212428331375122 - accuracy: 0.5092200040817261 - val_loss: 4.639727592468262 - val_accuracy: 0.1555 - penalty: 0.0\n",
            "hidden layer sizes: [51, 13, 29, 47, 228], total units: 368\n",
            "##########################################################\n",
            "Epoch 32/40\n",
            "loss: 1.8508129119873047 - accuracy: 0.5213000178337097 - val_loss: 4.841940879821777 - val_accuracy: 0.1513 - penalty: 0.0\n",
            "hidden layer sizes: [51, 13, 29, 47, 228], total units: 368\n",
            "##########################################################\n",
            "Epoch 33/40\n",
            "loss: 1.7754861116409302 - accuracy: 0.5378299951553345 - val_loss: 4.8370184898376465 - val_accuracy: 0.1508 - penalty: 0.0\n",
            "hidden layer sizes: [51, 13, 29, 47, 228], total units: 368\n",
            "##########################################################\n",
            "Epoch 34/40\n",
            "loss: 1.7070798873901367 - accuracy: 0.5515300035476685 - val_loss: 5.072152137756348 - val_accuracy: 0.1523 - penalty: 0.0\n",
            "hidden layer sizes: [51, 13, 29, 47, 228], total units: 368\n",
            "##########################################################\n",
            "Epoch 35/40\n",
            "loss: 1.6463285684585571 - accuracy: 0.5636799931526184 - val_loss: 4.968100547790527 - val_accuracy: 0.1535 - penalty: 0.0\n",
            "hidden layer sizes: [51, 13, 29, 47, 228], total units: 368\n",
            "##########################################################\n",
            "Epoch 36/40\n",
            "loss: 1.587555170059204 - accuracy: 0.5769299864768982 - val_loss: 4.9183220863342285 - val_accuracy: 0.1557 - penalty: 0.0\n",
            "hidden layer sizes: [51, 13, 29, 47, 228], total units: 368\n",
            "##########################################################\n",
            "Epoch 37/40\n",
            "loss: 1.5326390266418457 - accuracy: 0.5909500122070312 - val_loss: 5.003734588623047 - val_accuracy: 0.1576 - penalty: 0.0\n",
            "hidden layer sizes: [51, 13, 29, 47, 228], total units: 368\n",
            "##########################################################\n",
            "Epoch 38/40\n",
            "loss: 1.4939178228378296 - accuracy: 0.5972200036048889 - val_loss: 5.241466999053955 - val_accuracy: 0.1532 - penalty: 0.0\n",
            "hidden layer sizes: [51, 13, 29, 47, 228], total units: 368\n",
            "##########################################################\n",
            "Epoch 39/40\n",
            "loss: 1.4485026597976685 - accuracy: 0.6080399751663208 - val_loss: 5.247450828552246 - val_accuracy: 0.152 - penalty: 0.0\n",
            "hidden layer sizes: [51, 13, 29, 47, 228], total units: 368\n",
            "##########################################################\n",
            "Epoch 40/40\n",
            "loss: 1.4088449478149414 - accuracy: 0.6159899830818176 - val_loss: 5.327236175537109 - val_accuracy: 0.1487 - penalty: 0.0\n",
            "hidden layer sizes: [51, 13, 29, 47, 228], total units: 368\n",
            "CPU times: user 16min 5s, sys: 32.1 s, total: 16min 37s\n",
            "Wall time: 13min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "model = get_convolutional_model(tiny_imagenet.X_train_norm, regularization_penalty=0.00002, regularization_method='weighted_l1', layer_sizes=[100, 100, 100, 100, 100, 100], output_neurons=200)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "schedule = Schedule([EpochType.DYNAMIC] * 20 + [EpochType.STATIC_NO_REGULARIZATION] * 20)\n",
        "history = model.fit(tiny_imagenet.X_train_norm, tiny_imagenet.y_train, optimizer, schedule=schedule, batch_size=batch_size, min_new_neurons=20, \n",
        "                    validation_data=(tiny_imagenet.X_test_norm, tiny_imagenet.y_test), growth_percentage=0.2, verbose=True)"
      ],
      "metadata": {
        "id": "yoG8HJqrQCGJ",
        "outputId": "fb54e119-e23a-4449-dd29-ec57c79d67fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.5959930419921875 - val_accuracy: 0.0045 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100, 100], total units: 600\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.595992565155029 - val_accuracy: 0.0045 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120, 120], total units: 720\n",
            "Before pruning:\n",
            "loss: 4.2364702224731445 - accuracy: 0.10057999938726425 - val_loss: 5.51335334777832 - val_accuracy: 0.0425 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120, 120], total units: 720\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 5.513298511505127 - val_accuracy: 0.0425 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100, 119], total units: 619\n",
            "##########################################################\n",
            "Epoch 2/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.513298511505127 - val_accuracy: 0.0425 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100, 119], total units: 619\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.513298511505127 - val_accuracy: 0.0425 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120, 142], total units: 742\n",
            "Before pruning:\n",
            "loss: 3.9836063385009766 - accuracy: 0.125 - val_loss: 5.222326755523682 - val_accuracy: 0.0508 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120, 142], total units: 742\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 5.2217488288879395 - val_accuracy: 0.0508 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 43, 47, 50, 61, 142], total units: 443\n",
            "##########################################################\n",
            "Epoch 3/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.2217488288879395 - val_accuracy: 0.0508 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 43, 47, 50, 61, 142], total units: 443\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.2217488288879395 - val_accuracy: 0.0508 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 63, 67, 70, 81, 170], total units: 571\n",
            "Before pruning:\n",
            "loss: 3.8026347160339355 - accuracy: 0.15259000658988953 - val_loss: 5.248560905456543 - val_accuracy: 0.0657 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 63, 67, 70, 81, 170], total units: 571\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 5.248408317565918 - val_accuracy: 0.0656 - penalty: 2e-05\n",
            "hidden layer sizes: [98, 28, 36, 36, 52, 170], total units: 420\n",
            "##########################################################\n",
            "Epoch 4/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.248408317565918 - val_accuracy: 0.0656 - penalty: 2e-05\n",
            "hidden layer sizes: [98, 28, 36, 36, 52, 170], total units: 420\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.248408317565918 - val_accuracy: 0.0656 - penalty: 2e-05\n",
            "hidden layer sizes: [118, 48, 56, 56, 72, 204], total units: 554\n",
            "Before pruning:\n",
            "loss: 3.6943037509918213 - accuracy: 0.17026999592781067 - val_loss: 5.177611351013184 - val_accuracy: 0.0727 - penalty: 2e-05\n",
            "hidden layer sizes: [118, 48, 56, 56, 72, 204], total units: 554\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 5.17764949798584 - val_accuracy: 0.0727 - penalty: 2e-05\n",
            "hidden layer sizes: [94, 19, 33, 33, 43, 202], total units: 424\n",
            "##########################################################\n",
            "Epoch 5/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.17764949798584 - val_accuracy: 0.0727 - penalty: 2e-05\n",
            "hidden layer sizes: [94, 19, 33, 33, 43, 202], total units: 424\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.17764949798584 - val_accuracy: 0.0727 - penalty: 2e-05\n",
            "hidden layer sizes: [114, 39, 53, 53, 63, 242], total units: 564\n",
            "Before pruning:\n",
            "loss: 3.588411569595337 - accuracy: 0.18467000126838684 - val_loss: 4.949895858764648 - val_accuracy: 0.086 - penalty: 2e-05\n",
            "hidden layer sizes: [114, 39, 53, 53, 63, 242], total units: 564\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.949367523193359 - val_accuracy: 0.0858 - penalty: 2e-05\n",
            "hidden layer sizes: [83, 17, 31, 32, 42, 230], total units: 435\n",
            "##########################################################\n",
            "Epoch 6/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.949367523193359 - val_accuracy: 0.0858 - penalty: 2e-05\n",
            "hidden layer sizes: [83, 17, 31, 32, 42, 230], total units: 435\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.949367523193359 - val_accuracy: 0.0858 - penalty: 2e-05\n",
            "hidden layer sizes: [103, 37, 51, 52, 62, 276], total units: 581\n",
            "Before pruning:\n",
            "loss: 3.4980480670928955 - accuracy: 0.20090000331401825 - val_loss: 4.8700995445251465 - val_accuracy: 0.0919 - penalty: 2e-05\n",
            "hidden layer sizes: [103, 37, 51, 52, 62, 276], total units: 581\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.870863914489746 - val_accuracy: 0.0917 - penalty: 2e-05\n",
            "hidden layer sizes: [78, 13, 30, 29, 43, 253], total units: 446\n",
            "##########################################################\n",
            "Epoch 7/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.870863914489746 - val_accuracy: 0.0917 - penalty: 2e-05\n",
            "hidden layer sizes: [78, 13, 30, 29, 43, 253], total units: 446\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.870863437652588 - val_accuracy: 0.0917 - penalty: 2e-05\n",
            "hidden layer sizes: [98, 33, 50, 49, 63, 303], total units: 596\n",
            "Before pruning:\n",
            "loss: 3.4179205894470215 - accuracy: 0.2171899974346161 - val_loss: 4.872628688812256 - val_accuracy: 0.0907 - penalty: 2e-05\n",
            "hidden layer sizes: [98, 33, 50, 49, 63, 303], total units: 596\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.877327919006348 - val_accuracy: 0.0905 - penalty: 2e-05\n",
            "hidden layer sizes: [76, 12, 29, 29, 44, 268], total units: 458\n",
            "##########################################################\n",
            "Epoch 8/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.877327919006348 - val_accuracy: 0.0905 - penalty: 2e-05\n",
            "hidden layer sizes: [76, 12, 29, 29, 44, 268], total units: 458\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.877327919006348 - val_accuracy: 0.0905 - penalty: 2e-05\n",
            "hidden layer sizes: [96, 32, 49, 49, 64, 321], total units: 611\n",
            "Before pruning:\n",
            "loss: 3.348052740097046 - accuracy: 0.2263299971818924 - val_loss: 4.677910804748535 - val_accuracy: 0.1057 - penalty: 2e-05\n",
            "hidden layer sizes: [96, 32, 49, 49, 64, 321], total units: 611\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.676393985748291 - val_accuracy: 0.1057 - penalty: 2e-05\n",
            "hidden layer sizes: [72, 12, 23, 29, 47, 275], total units: 458\n",
            "##########################################################\n",
            "Epoch 9/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.676393985748291 - val_accuracy: 0.1057 - penalty: 2e-05\n",
            "hidden layer sizes: [72, 12, 23, 29, 47, 275], total units: 458\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.676393032073975 - val_accuracy: 0.1057 - penalty: 2e-05\n",
            "hidden layer sizes: [92, 32, 43, 49, 67, 330], total units: 613\n",
            "Before pruning:\n",
            "loss: 3.305297613143921 - accuracy: 0.23485000431537628 - val_loss: 4.7039947509765625 - val_accuracy: 0.1085 - penalty: 2e-05\n",
            "hidden layer sizes: [92, 32, 43, 49, 67, 330], total units: 613\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.702571392059326 - val_accuracy: 0.108 - penalty: 2e-05\n",
            "hidden layer sizes: [69, 12, 23, 27, 48, 279], total units: 458\n",
            "##########################################################\n",
            "Epoch 10/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.702571392059326 - val_accuracy: 0.108 - penalty: 2e-05\n",
            "hidden layer sizes: [69, 12, 23, 27, 48, 279], total units: 458\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.702570915222168 - val_accuracy: 0.108 - penalty: 2e-05\n",
            "hidden layer sizes: [89, 32, 43, 47, 68, 334], total units: 613\n",
            "Before pruning:\n",
            "loss: 3.2751314640045166 - accuracy: 0.23899999260902405 - val_loss: 4.709865570068359 - val_accuracy: 0.1004 - penalty: 2e-05\n",
            "hidden layer sizes: [89, 32, 43, 47, 68, 334], total units: 613\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.713339805603027 - val_accuracy: 0.1001 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 12, 19, 26, 47, 280], total units: 449\n",
            "##########################################################\n",
            "Epoch 11/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.713339805603027 - val_accuracy: 0.1001 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 12, 19, 26, 47, 280], total units: 449\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.7133402824401855 - val_accuracy: 0.1001 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 32, 39, 46, 67, 336], total units: 605\n",
            "Before pruning:\n",
            "loss: 3.2538254261016846 - accuracy: 0.2426699995994568 - val_loss: 4.618536949157715 - val_accuracy: 0.1163 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 32, 39, 46, 67, 336], total units: 605\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.617951393127441 - val_accuracy: 0.1163 - penalty: 2e-05\n",
            "hidden layer sizes: [62, 12, 19, 24, 50, 282], total units: 449\n",
            "##########################################################\n",
            "Epoch 12/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.617951393127441 - val_accuracy: 0.1163 - penalty: 2e-05\n",
            "hidden layer sizes: [62, 12, 19, 24, 50, 282], total units: 449\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.6179518699646 - val_accuracy: 0.1163 - penalty: 2e-05\n",
            "hidden layer sizes: [82, 32, 39, 44, 70, 338], total units: 605\n",
            "Before pruning:\n",
            "loss: 3.2335433959960938 - accuracy: 0.24652999639511108 - val_loss: 4.62014627456665 - val_accuracy: 0.111 - penalty: 2e-05\n",
            "hidden layer sizes: [82, 32, 39, 44, 70, 338], total units: 605\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.61890983581543 - val_accuracy: 0.1111 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 12, 19, 23, 54, 285], total units: 453\n",
            "##########################################################\n",
            "Epoch 13/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.61890983581543 - val_accuracy: 0.1111 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 12, 19, 23, 54, 285], total units: 453\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.61890983581543 - val_accuracy: 0.1111 - penalty: 2e-05\n",
            "hidden layer sizes: [80, 32, 39, 43, 74, 342], total units: 610\n",
            "Before pruning:\n",
            "loss: 3.218733072280884 - accuracy: 0.24887000024318695 - val_loss: 4.599867820739746 - val_accuracy: 0.1137 - penalty: 2e-05\n",
            "hidden layer sizes: [80, 32, 39, 43, 74, 342], total units: 610\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.59977912902832 - val_accuracy: 0.1141 - penalty: 2e-05\n",
            "hidden layer sizes: [59, 12, 19, 23, 54, 288], total units: 455\n",
            "##########################################################\n",
            "Epoch 14/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.59977912902832 - val_accuracy: 0.1141 - penalty: 2e-05\n",
            "hidden layer sizes: [59, 12, 19, 23, 54, 288], total units: 455\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.599778652191162 - val_accuracy: 0.1141 - penalty: 2e-05\n",
            "hidden layer sizes: [79, 32, 39, 43, 74, 345], total units: 612\n",
            "Before pruning:\n",
            "loss: 3.1965866088867188 - accuracy: 0.25345999002456665 - val_loss: 4.605402946472168 - val_accuracy: 0.1158 - penalty: 2e-05\n",
            "hidden layer sizes: [79, 32, 39, 43, 74, 345], total units: 612\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.606936931610107 - val_accuracy: 0.1155 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 12, 18, 22, 62, 289], total units: 460\n",
            "##########################################################\n",
            "Epoch 15/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.606936931610107 - val_accuracy: 0.1155 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 12, 18, 22, 62, 289], total units: 460\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.60693883895874 - val_accuracy: 0.1155 - penalty: 2e-05\n",
            "hidden layer sizes: [77, 32, 38, 42, 82, 346], total units: 617\n",
            "Before pruning:\n",
            "loss: 3.1872897148132324 - accuracy: 0.2539600133895874 - val_loss: 4.585208892822266 - val_accuracy: 0.1295 - penalty: 2e-05\n",
            "hidden layer sizes: [77, 32, 38, 42, 82, 346], total units: 617\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.58690881729126 - val_accuracy: 0.1296 - penalty: 2e-05\n",
            "hidden layer sizes: [54, 12, 18, 20, 64, 289], total units: 457\n",
            "##########################################################\n",
            "Epoch 16/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.58690881729126 - val_accuracy: 0.1296 - penalty: 2e-05\n",
            "hidden layer sizes: [54, 12, 18, 20, 64, 289], total units: 457\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.58690881729126 - val_accuracy: 0.1296 - penalty: 2e-05\n",
            "hidden layer sizes: [74, 32, 38, 40, 84, 346], total units: 614\n",
            "Before pruning:\n",
            "loss: 3.1750500202178955 - accuracy: 0.2567000091075897 - val_loss: 4.663158893585205 - val_accuracy: 0.1113 - penalty: 2e-05\n",
            "hidden layer sizes: [74, 32, 38, 40, 84, 346], total units: 614\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.6615705490112305 - val_accuracy: 0.1114 - penalty: 2e-05\n",
            "hidden layer sizes: [53, 12, 18, 20, 65, 295], total units: 463\n",
            "##########################################################\n",
            "Epoch 17/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.6615705490112305 - val_accuracy: 0.1114 - penalty: 2e-05\n",
            "hidden layer sizes: [53, 12, 18, 20, 65, 295], total units: 463\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.6615705490112305 - val_accuracy: 0.1114 - penalty: 2e-05\n",
            "hidden layer sizes: [73, 32, 38, 40, 85, 354], total units: 622\n",
            "Before pruning:\n",
            "loss: 3.164978504180908 - accuracy: 0.2594200074672699 - val_loss: 4.54873514175415 - val_accuracy: 0.1128 - penalty: 2e-05\n",
            "hidden layer sizes: [73, 32, 38, 40, 85, 354], total units: 622\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.550144672393799 - val_accuracy: 0.1128 - penalty: 2e-05\n",
            "hidden layer sizes: [53, 12, 17, 20, 70, 294], total units: 466\n",
            "##########################################################\n",
            "Epoch 18/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.550144672393799 - val_accuracy: 0.1128 - penalty: 2e-05\n",
            "hidden layer sizes: [53, 12, 17, 20, 70, 294], total units: 466\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.550145149230957 - val_accuracy: 0.1128 - penalty: 2e-05\n",
            "hidden layer sizes: [73, 32, 37, 40, 90, 352], total units: 624\n",
            "Before pruning:\n",
            "loss: 3.1537792682647705 - accuracy: 0.26249000430107117 - val_loss: 4.470035552978516 - val_accuracy: 0.122 - penalty: 2e-05\n",
            "hidden layer sizes: [73, 32, 37, 40, 90, 352], total units: 624\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.469884872436523 - val_accuracy: 0.1218 - penalty: 2e-05\n",
            "hidden layer sizes: [52, 12, 17, 19, 75, 296], total units: 471\n",
            "##########################################################\n",
            "Epoch 19/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.469884872436523 - val_accuracy: 0.1218 - penalty: 2e-05\n",
            "hidden layer sizes: [52, 12, 17, 19, 75, 296], total units: 471\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.469882965087891 - val_accuracy: 0.1218 - penalty: 2e-05\n",
            "hidden layer sizes: [72, 32, 37, 39, 95, 355], total units: 630\n",
            "Before pruning:\n",
            "loss: 3.1405065059661865 - accuracy: 0.2605000138282776 - val_loss: 4.593721389770508 - val_accuracy: 0.1247 - penalty: 2e-05\n",
            "hidden layer sizes: [72, 32, 37, 39, 95, 355], total units: 630\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.592445373535156 - val_accuracy: 0.1245 - penalty: 2e-05\n",
            "hidden layer sizes: [51, 12, 17, 19, 80, 297], total units: 476\n",
            "##########################################################\n",
            "Epoch 20/40\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.592445373535156 - val_accuracy: 0.1245 - penalty: 2e-05\n",
            "hidden layer sizes: [51, 12, 17, 19, 80, 297], total units: 476\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.592445373535156 - val_accuracy: 0.1245 - penalty: 2e-05\n",
            "hidden layer sizes: [71, 32, 37, 39, 100, 356], total units: 635\n",
            "Before pruning:\n",
            "loss: 3.1361820697784424 - accuracy: 0.2635599970817566 - val_loss: 4.444351673126221 - val_accuracy: 0.1205 - penalty: 2e-05\n",
            "hidden layer sizes: [71, 32, 37, 39, 100, 356], total units: 635\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.448339939117432 - val_accuracy: 0.1207 - penalty: 2e-05\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 21/40\n",
            "loss: 3.2385036945343018 - accuracy: 0.25856998562812805 - val_loss: 4.675017833709717 - val_accuracy: 0.1341 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 22/40\n",
            "loss: 2.901371479034424 - accuracy: 0.31407999992370605 - val_loss: 4.477153301239014 - val_accuracy: 0.1406 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 23/40\n",
            "loss: 2.7937018871307373 - accuracy: 0.33491000533103943 - val_loss: 4.307125568389893 - val_accuracy: 0.1534 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 24/40\n",
            "loss: 2.7058706283569336 - accuracy: 0.35078999400138855 - val_loss: 4.195457935333252 - val_accuracy: 0.1592 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 25/40\n",
            "loss: 2.626380681991577 - accuracy: 0.36733999848365784 - val_loss: 4.189493179321289 - val_accuracy: 0.1655 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 26/40\n",
            "loss: 2.5610861778259277 - accuracy: 0.3808799982070923 - val_loss: 4.13769006729126 - val_accuracy: 0.166 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 27/40\n",
            "loss: 2.49271821975708 - accuracy: 0.39118000864982605 - val_loss: 4.070734977722168 - val_accuracy: 0.1794 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 28/40\n",
            "loss: 2.429917335510254 - accuracy: 0.4063299894332886 - val_loss: 4.240698337554932 - val_accuracy: 0.1679 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 29/40\n",
            "loss: 2.3660051822662354 - accuracy: 0.4180299937725067 - val_loss: 4.168391704559326 - val_accuracy: 0.1801 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 30/40\n",
            "loss: 2.3107657432556152 - accuracy: 0.4284299910068512 - val_loss: 4.167135715484619 - val_accuracy: 0.1876 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 31/40\n",
            "loss: 2.2578744888305664 - accuracy: 0.4378400146961212 - val_loss: 4.233453750610352 - val_accuracy: 0.1816 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 32/40\n",
            "loss: 2.2084429264068604 - accuracy: 0.4487900137901306 - val_loss: 4.278738498687744 - val_accuracy: 0.1769 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 33/40\n",
            "loss: 2.1649351119995117 - accuracy: 0.45598000288009644 - val_loss: 4.2091546058654785 - val_accuracy: 0.1806 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 34/40\n",
            "loss: 2.1106207370758057 - accuracy: 0.46682998538017273 - val_loss: 4.1878662109375 - val_accuracy: 0.1862 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 35/40\n",
            "loss: 2.068870782852173 - accuracy: 0.476500004529953 - val_loss: 4.354595184326172 - val_accuracy: 0.1839 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 36/40\n",
            "loss: 2.0263774394989014 - accuracy: 0.4835300147533417 - val_loss: 4.214017391204834 - val_accuracy: 0.1896 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 37/40\n",
            "loss: 1.987017035484314 - accuracy: 0.4923500120639801 - val_loss: 4.226319313049316 - val_accuracy: 0.192 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 38/40\n",
            "loss: 1.9549823999404907 - accuracy: 0.4997600018978119 - val_loss: 4.336300849914551 - val_accuracy: 0.191 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 39/40\n",
            "loss: 1.9157605171203613 - accuracy: 0.5044999718666077 - val_loss: 4.289840221405029 - val_accuracy: 0.1865 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 40/40\n",
            "loss: 1.8856204748153687 - accuracy: 0.5110700130462646 - val_loss: 4.220312118530273 - val_accuracy: 0.1977 - penalty: 0.0\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "CPU times: user 14min 56s, sys: 32.2 s, total: 15min 28s\n",
            "Wall time: 11min 52s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "model = get_convolutional_model(tiny_imagenet.X_train_norm, regularization_penalty=0.0002, regularization_method='l1', layer_sizes=[48, 12, 17, 19, 77, 296], output_neurons=200)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "schedule = Schedule([EpochType.STATIC_WITH_REGULARIZATION] * 40)\n",
        "history = model.fit(tiny_imagenet.X_train_norm, tiny_imagenet.y_train, optimizer, schedule=schedule, batch_size=batch_size, min_new_neurons=20, \n",
        "                    validation_data=(tiny_imagenet.X_test_norm, tiny_imagenet.y_test), growth_percentage=0.2, verbose=True)"
      ],
      "metadata": {
        "id": "hrAjQ6H-VWrl",
        "outputId": "16bf485b-f619-443e-bf4f-c57a302c3841",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/40\n",
            "loss: 4.289374828338623 - accuracy: 0.09640000015497208 - val_loss: 5.259166717529297 - val_accuracy: 0.0573 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 2/40\n",
            "loss: 3.8369767665863037 - accuracy: 0.15317000448703766 - val_loss: 5.067516803741455 - val_accuracy: 0.0667 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 3/40\n",
            "loss: 3.6995861530303955 - accuracy: 0.17618000507354736 - val_loss: 5.2216477394104 - val_accuracy: 0.0671 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 4/40\n",
            "loss: 3.60565185546875 - accuracy: 0.18990999460220337 - val_loss: 4.899083614349365 - val_accuracy: 0.0808 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 5/40\n",
            "loss: 3.5238840579986572 - accuracy: 0.20287999510765076 - val_loss: 4.834376335144043 - val_accuracy: 0.086 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 6/40\n",
            "loss: 3.459003210067749 - accuracy: 0.2132200002670288 - val_loss: 4.847607612609863 - val_accuracy: 0.0867 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 7/40\n",
            "loss: 3.402411460876465 - accuracy: 0.22452999651432037 - val_loss: 4.803019046783447 - val_accuracy: 0.0926 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 8/40\n",
            "loss: 3.3482375144958496 - accuracy: 0.23319999873638153 - val_loss: 4.777381896972656 - val_accuracy: 0.0977 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 9/40\n",
            "loss: 3.30110239982605 - accuracy: 0.24003000557422638 - val_loss: 4.626590728759766 - val_accuracy: 0.1006 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 10/40\n",
            "loss: 3.260195016860962 - accuracy: 0.2469100058078766 - val_loss: 4.699289798736572 - val_accuracy: 0.1005 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 11/40\n",
            "loss: 3.2248644828796387 - accuracy: 0.25492000579833984 - val_loss: 4.491023063659668 - val_accuracy: 0.1135 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 12/40\n",
            "loss: 3.1932740211486816 - accuracy: 0.2579199969768524 - val_loss: 4.5923919677734375 - val_accuracy: 0.1099 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 13/40\n",
            "loss: 3.1649274826049805 - accuracy: 0.26499998569488525 - val_loss: 4.645729064941406 - val_accuracy: 0.1101 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 14/40\n",
            "loss: 3.130465030670166 - accuracy: 0.2681800127029419 - val_loss: 4.574737548828125 - val_accuracy: 0.1122 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 15/40\n",
            "loss: 3.0999701023101807 - accuracy: 0.2746700048446655 - val_loss: 4.467548370361328 - val_accuracy: 0.1249 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 16/40\n",
            "loss: 3.074228525161743 - accuracy: 0.27970999479293823 - val_loss: 4.457192420959473 - val_accuracy: 0.1248 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 17/40\n",
            "loss: 3.045534133911133 - accuracy: 0.2812199890613556 - val_loss: 4.466061115264893 - val_accuracy: 0.1311 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 18/40\n",
            "loss: 3.019561290740967 - accuracy: 0.2888599932193756 - val_loss: 4.410892009735107 - val_accuracy: 0.1339 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 19/40\n",
            "loss: 2.998582601547241 - accuracy: 0.29322001338005066 - val_loss: 4.194242000579834 - val_accuracy: 0.1464 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 20/40\n",
            "loss: 2.9674808979034424 - accuracy: 0.29774001240730286 - val_loss: 4.367214679718018 - val_accuracy: 0.1365 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 21/40\n",
            "loss: 2.9520633220672607 - accuracy: 0.3009600043296814 - val_loss: 4.281967639923096 - val_accuracy: 0.1405 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 22/40\n",
            "loss: 2.9310302734375 - accuracy: 0.30351999402046204 - val_loss: 4.3452301025390625 - val_accuracy: 0.1348 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 23/40\n",
            "loss: 2.908107280731201 - accuracy: 0.3084999918937683 - val_loss: 4.2326812744140625 - val_accuracy: 0.1524 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 24/40\n",
            "loss: 2.8914859294891357 - accuracy: 0.31286999583244324 - val_loss: 4.2467522621154785 - val_accuracy: 0.1455 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 25/40\n",
            "loss: 2.8705663681030273 - accuracy: 0.31415000557899475 - val_loss: 4.385305404663086 - val_accuracy: 0.1429 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 26/40\n",
            "loss: 2.8557422161102295 - accuracy: 0.3197999894618988 - val_loss: 4.311227798461914 - val_accuracy: 0.139 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 27/40\n",
            "loss: 2.8361141681671143 - accuracy: 0.32315999269485474 - val_loss: 4.178327560424805 - val_accuracy: 0.1569 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 28/40\n",
            "loss: 2.8190102577209473 - accuracy: 0.3243899941444397 - val_loss: 4.193903923034668 - val_accuracy: 0.1533 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 29/40\n",
            "loss: 2.8055028915405273 - accuracy: 0.3278200030326843 - val_loss: 4.239876747131348 - val_accuracy: 0.1537 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 30/40\n",
            "loss: 2.7928719520568848 - accuracy: 0.3301999866962433 - val_loss: 3.9878180027008057 - val_accuracy: 0.1678 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 31/40\n",
            "loss: 2.7682790756225586 - accuracy: 0.335099995136261 - val_loss: 4.3836469650268555 - val_accuracy: 0.1458 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 32/40\n",
            "loss: 2.756039619445801 - accuracy: 0.3376399874687195 - val_loss: 4.302917003631592 - val_accuracy: 0.1493 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 33/40\n",
            "loss: 2.7415318489074707 - accuracy: 0.3402099907398224 - val_loss: 4.184179782867432 - val_accuracy: 0.1605 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 34/40\n",
            "loss: 2.7327420711517334 - accuracy: 0.3403100073337555 - val_loss: 4.139418601989746 - val_accuracy: 0.162 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 35/40\n",
            "loss: 2.7128171920776367 - accuracy: 0.34544000029563904 - val_loss: 4.196424961090088 - val_accuracy: 0.1646 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 36/40\n",
            "loss: 2.7044472694396973 - accuracy: 0.34810999035835266 - val_loss: 4.131458282470703 - val_accuracy: 0.1672 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 37/40\n",
            "loss: 2.687086820602417 - accuracy: 0.3508799970149994 - val_loss: 4.093888759613037 - val_accuracy: 0.1667 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 38/40\n",
            "loss: 2.680232286453247 - accuracy: 0.3506399989128113 - val_loss: 4.165778636932373 - val_accuracy: 0.1628 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 39/40\n",
            "loss: 2.66850209236145 - accuracy: 0.3550499975681305 - val_loss: 4.108555316925049 - val_accuracy: 0.1672 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "##########################################################\n",
            "Epoch 40/40\n",
            "loss: 2.6607143878936768 - accuracy: 0.35482001304626465 - val_loss: 4.253663063049316 - val_accuracy: 0.1547 - penalty: 0.0002\n",
            "hidden layer sizes: [48, 12, 17, 19, 77, 296], total units: 469\n",
            "CPU times: user 10min 27s, sys: 27.5 s, total: 10min 55s\n",
            "Wall time: 7min 51s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "model = get_convolutional_model(tiny_imagenet.X_train_norm, regularization_penalty=0.00002, regularization_method='weighted_l1', layer_sizes=[100, 100, 100, 100, 100, 100], output_neurons=200)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "schedule = Schedule([EpochType.DYNAMIC] * 30 + [EpochType.STATIC_NO_REGULARIZATION] * 30)\n",
        "history = model.fit(tiny_imagenet.X_train_norm, tiny_imagenet.y_train, optimizer, schedule=schedule, batch_size=batch_size, min_new_neurons=20, \n",
        "                    validation_data=(tiny_imagenet.X_test_norm, tiny_imagenet.y_test), growth_percentage=0.2, verbose=True)"
      ],
      "metadata": {
        "id": "8qmYxbHKYtU0",
        "outputId": "7b83133b-bb9d-4a5b-af97-7b8018e4dbb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.558587074279785 - val_accuracy: 0.0039 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100, 100], total units: 600\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.558587074279785 - val_accuracy: 0.0039 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120, 120], total units: 720\n",
            "Before pruning:\n",
            "loss: 4.259202003479004 - accuracy: 0.09923999756574631 - val_loss: 5.461585998535156 - val_accuracy: 0.0431 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120, 120], total units: 720\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 5.461586952209473 - val_accuracy: 0.0431 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100, 120], total units: 620\n",
            "##########################################################\n",
            "Epoch 2/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.461586952209473 - val_accuracy: 0.0431 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 100, 100, 100, 100, 120], total units: 620\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.461587429046631 - val_accuracy: 0.0431 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120, 144], total units: 744\n",
            "Before pruning:\n",
            "loss: 4.006210803985596 - accuracy: 0.12343999743461609 - val_loss: 5.379511833190918 - val_accuracy: 0.0494 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 120, 120, 120, 120, 144], total units: 744\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 5.379067420959473 - val_accuracy: 0.0497 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 39, 50, 59, 53, 144], total units: 445\n",
            "##########################################################\n",
            "Epoch 3/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.379067420959473 - val_accuracy: 0.0497 - penalty: 2e-05\n",
            "hidden layer sizes: [100, 39, 50, 59, 53, 144], total units: 445\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.379067420959473 - val_accuracy: 0.0497 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 59, 70, 79, 73, 172], total units: 573\n",
            "Before pruning:\n",
            "loss: 3.8631763458251953 - accuracy: 0.14459000527858734 - val_loss: 5.364109516143799 - val_accuracy: 0.0652 - penalty: 2e-05\n",
            "hidden layer sizes: [120, 59, 70, 79, 73, 172], total units: 573\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 5.363754749298096 - val_accuracy: 0.0651 - penalty: 2e-05\n",
            "hidden layer sizes: [94, 26, 37, 37, 41, 172], total units: 407\n",
            "##########################################################\n",
            "Epoch 4/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.363754749298096 - val_accuracy: 0.0651 - penalty: 2e-05\n",
            "hidden layer sizes: [94, 26, 37, 37, 41, 172], total units: 407\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.363755702972412 - val_accuracy: 0.0651 - penalty: 2e-05\n",
            "hidden layer sizes: [114, 46, 57, 57, 61, 206], total units: 541\n",
            "Before pruning:\n",
            "loss: 3.692729949951172 - accuracy: 0.17177000641822815 - val_loss: 5.078550338745117 - val_accuracy: 0.0753 - penalty: 2e-05\n",
            "hidden layer sizes: [114, 46, 57, 57, 61, 206], total units: 541\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 5.078652858734131 - val_accuracy: 0.0753 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 21, 32, 30, 36, 206], total units: 410\n",
            "##########################################################\n",
            "Epoch 5/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 5.078652858734131 - val_accuracy: 0.0753 - penalty: 2e-05\n",
            "hidden layer sizes: [85, 21, 32, 30, 36, 206], total units: 410\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 5.078653335571289 - val_accuracy: 0.0753 - penalty: 2e-05\n",
            "hidden layer sizes: [105, 41, 52, 50, 56, 247], total units: 551\n",
            "Before pruning:\n",
            "loss: 3.5581905841827393 - accuracy: 0.19235999882221222 - val_loss: 4.81392240524292 - val_accuracy: 0.0862 - penalty: 2e-05\n",
            "hidden layer sizes: [105, 41, 52, 50, 56, 247], total units: 551\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.814635753631592 - val_accuracy: 0.0862 - penalty: 2e-05\n",
            "hidden layer sizes: [82, 16, 29, 28, 36, 244], total units: 435\n",
            "##########################################################\n",
            "Epoch 6/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.814635753631592 - val_accuracy: 0.0862 - penalty: 2e-05\n",
            "hidden layer sizes: [82, 16, 29, 28, 36, 244], total units: 435\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.814635753631592 - val_accuracy: 0.0862 - penalty: 2e-05\n",
            "hidden layer sizes: [102, 36, 49, 48, 56, 292], total units: 583\n",
            "Before pruning:\n",
            "loss: 3.47798490524292 - accuracy: 0.20427000522613525 - val_loss: 4.86498498916626 - val_accuracy: 0.0925 - penalty: 2e-05\n",
            "hidden layer sizes: [102, 36, 49, 48, 56, 292], total units: 583\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.866534233093262 - val_accuracy: 0.0921 - penalty: 2e-05\n",
            "hidden layer sizes: [81, 14, 28, 28, 38, 264], total units: 453\n",
            "##########################################################\n",
            "Epoch 7/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.866534233093262 - val_accuracy: 0.0921 - penalty: 2e-05\n",
            "hidden layer sizes: [81, 14, 28, 28, 38, 264], total units: 453\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.866535663604736 - val_accuracy: 0.0921 - penalty: 2e-05\n",
            "hidden layer sizes: [101, 34, 48, 48, 58, 316], total units: 605\n",
            "Before pruning:\n",
            "loss: 3.4082205295562744 - accuracy: 0.22022999823093414 - val_loss: 4.894439697265625 - val_accuracy: 0.0945 - penalty: 2e-05\n",
            "hidden layer sizes: [101, 34, 48, 48, 58, 316], total units: 605\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.8976945877075195 - val_accuracy: 0.0944 - penalty: 2e-05\n",
            "hidden layer sizes: [73, 12, 26, 28, 37, 269], total units: 445\n",
            "##########################################################\n",
            "Epoch 8/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.8976945877075195 - val_accuracy: 0.0944 - penalty: 2e-05\n",
            "hidden layer sizes: [73, 12, 26, 28, 37, 269], total units: 445\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.8976945877075195 - val_accuracy: 0.0944 - penalty: 2e-05\n",
            "hidden layer sizes: [93, 32, 46, 48, 57, 322], total units: 598\n",
            "Before pruning:\n",
            "loss: 3.365553855895996 - accuracy: 0.2243099957704544 - val_loss: 4.737705230712891 - val_accuracy: 0.0998 - penalty: 2e-05\n",
            "hidden layer sizes: [93, 32, 46, 48, 57, 322], total units: 598\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.742293357849121 - val_accuracy: 0.0991 - penalty: 2e-05\n",
            "hidden layer sizes: [70, 12, 25, 27, 38, 293], total units: 465\n",
            "##########################################################\n",
            "Epoch 9/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.742293357849121 - val_accuracy: 0.0991 - penalty: 2e-05\n",
            "hidden layer sizes: [70, 12, 25, 27, 38, 293], total units: 465\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.742292881011963 - val_accuracy: 0.0991 - penalty: 2e-05\n",
            "hidden layer sizes: [90, 32, 45, 47, 58, 351], total units: 623\n",
            "Before pruning:\n",
            "loss: 3.33231258392334 - accuracy: 0.2311200052499771 - val_loss: 4.76254415512085 - val_accuracy: 0.0977 - penalty: 2e-05\n",
            "hidden layer sizes: [90, 32, 45, 47, 58, 351], total units: 623\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.767833232879639 - val_accuracy: 0.0976 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 12, 24, 27, 41, 303], total units: 471\n",
            "##########################################################\n",
            "Epoch 10/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.767833232879639 - val_accuracy: 0.0976 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 12, 24, 27, 41, 303], total units: 471\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.7678327560424805 - val_accuracy: 0.0976 - penalty: 2e-05\n",
            "hidden layer sizes: [84, 32, 44, 47, 61, 363], total units: 631\n",
            "Before pruning:\n",
            "loss: 3.310650587081909 - accuracy: 0.23478999733924866 - val_loss: 4.630008697509766 - val_accuracy: 0.1082 - penalty: 2e-05\n",
            "hidden layer sizes: [84, 32, 44, 47, 61, 363], total units: 631\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.633068084716797 - val_accuracy: 0.1081 - penalty: 2e-05\n",
            "hidden layer sizes: [63, 12, 23, 26, 41, 303], total units: 468\n",
            "##########################################################\n",
            "Epoch 11/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.633068084716797 - val_accuracy: 0.1081 - penalty: 2e-05\n",
            "hidden layer sizes: [63, 12, 23, 26, 41, 303], total units: 468\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.6330671310424805 - val_accuracy: 0.1081 - penalty: 2e-05\n",
            "hidden layer sizes: [83, 32, 43, 46, 61, 363], total units: 628\n",
            "Before pruning:\n",
            "loss: 3.286367177963257 - accuracy: 0.23921999335289001 - val_loss: 4.6422576904296875 - val_accuracy: 0.1148 - penalty: 2e-05\n",
            "hidden layer sizes: [83, 32, 43, 46, 61, 363], total units: 628\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.643834590911865 - val_accuracy: 0.1147 - penalty: 2e-05\n",
            "hidden layer sizes: [58, 12, 22, 26, 38, 310], total units: 466\n",
            "##########################################################\n",
            "Epoch 12/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.643834590911865 - val_accuracy: 0.1147 - penalty: 2e-05\n",
            "hidden layer sizes: [58, 12, 22, 26, 38, 310], total units: 466\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.643834114074707 - val_accuracy: 0.1147 - penalty: 2e-05\n",
            "hidden layer sizes: [78, 32, 42, 46, 58, 372], total units: 628\n",
            "Before pruning:\n",
            "loss: 3.263369083404541 - accuracy: 0.24083000421524048 - val_loss: 4.669174671173096 - val_accuracy: 0.1121 - penalty: 2e-05\n",
            "hidden layer sizes: [78, 32, 42, 46, 58, 372], total units: 628\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.6701273918151855 - val_accuracy: 0.1124 - penalty: 2e-05\n",
            "hidden layer sizes: [55, 12, 22, 26, 37, 312], total units: 464\n",
            "##########################################################\n",
            "Epoch 13/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.6701273918151855 - val_accuracy: 0.1124 - penalty: 2e-05\n",
            "hidden layer sizes: [55, 12, 22, 26, 37, 312], total units: 464\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.6701273918151855 - val_accuracy: 0.1124 - penalty: 2e-05\n",
            "hidden layer sizes: [75, 32, 42, 46, 57, 374], total units: 626\n",
            "Before pruning:\n",
            "loss: 3.2436869144439697 - accuracy: 0.24498000741004944 - val_loss: 4.692123889923096 - val_accuracy: 0.1103 - penalty: 2e-05\n",
            "hidden layer sizes: [75, 32, 42, 46, 57, 374], total units: 626\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.697523593902588 - val_accuracy: 0.1102 - penalty: 2e-05\n",
            "hidden layer sizes: [54, 11, 20, 24, 43, 310], total units: 462\n",
            "##########################################################\n",
            "Epoch 14/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.697523593902588 - val_accuracy: 0.1102 - penalty: 2e-05\n",
            "hidden layer sizes: [54, 11, 20, 24, 43, 310], total units: 462\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.697523593902588 - val_accuracy: 0.1102 - penalty: 2e-05\n",
            "hidden layer sizes: [74, 31, 40, 44, 63, 372], total units: 624\n",
            "Before pruning:\n",
            "loss: 3.2276315689086914 - accuracy: 0.24922999739646912 - val_loss: 4.64387321472168 - val_accuracy: 0.1104 - penalty: 2e-05\n",
            "hidden layer sizes: [74, 31, 40, 44, 63, 372], total units: 624\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.643736839294434 - val_accuracy: 0.111 - penalty: 2e-05\n",
            "hidden layer sizes: [49, 11, 20, 24, 41, 311], total units: 456\n",
            "##########################################################\n",
            "Epoch 15/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.643736839294434 - val_accuracy: 0.111 - penalty: 2e-05\n",
            "hidden layer sizes: [49, 11, 20, 24, 41, 311], total units: 456\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.643735885620117 - val_accuracy: 0.111 - penalty: 2e-05\n",
            "hidden layer sizes: [69, 31, 40, 44, 61, 373], total units: 618\n",
            "Before pruning:\n",
            "loss: 3.21506404876709 - accuracy: 0.250110000371933 - val_loss: 4.574548244476318 - val_accuracy: 0.1112 - penalty: 2e-05\n",
            "hidden layer sizes: [69, 31, 40, 44, 61, 373], total units: 618\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.577556133270264 - val_accuracy: 0.1108 - penalty: 2e-05\n",
            "hidden layer sizes: [48, 11, 20, 24, 48, 313], total units: 464\n",
            "##########################################################\n",
            "Epoch 16/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.577556133270264 - val_accuracy: 0.1108 - penalty: 2e-05\n",
            "hidden layer sizes: [48, 11, 20, 24, 48, 313], total units: 464\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.577556610107422 - val_accuracy: 0.1108 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 31, 40, 44, 68, 375], total units: 626\n",
            "Before pruning:\n",
            "loss: 3.2011561393737793 - accuracy: 0.25146999955177307 - val_loss: 4.4906463623046875 - val_accuracy: 0.1111 - penalty: 2e-05\n",
            "hidden layer sizes: [68, 31, 40, 44, 68, 375], total units: 626\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.49276876449585 - val_accuracy: 0.111 - penalty: 2e-05\n",
            "hidden layer sizes: [47, 11, 19, 23, 45, 311], total units: 456\n",
            "##########################################################\n",
            "Epoch 17/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.49276876449585 - val_accuracy: 0.111 - penalty: 2e-05\n",
            "hidden layer sizes: [47, 11, 19, 23, 45, 311], total units: 456\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.492769241333008 - val_accuracy: 0.111 - penalty: 2e-05\n",
            "hidden layer sizes: [67, 31, 39, 43, 65, 373], total units: 618\n",
            "Before pruning:\n",
            "loss: 3.1900646686553955 - accuracy: 0.25356999039649963 - val_loss: 4.582438945770264 - val_accuracy: 0.1138 - penalty: 2e-05\n",
            "hidden layer sizes: [67, 31, 39, 43, 65, 373], total units: 618\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.590993404388428 - val_accuracy: 0.114 - penalty: 2e-05\n",
            "hidden layer sizes: [46, 11, 19, 22, 47, 310], total units: 455\n",
            "##########################################################\n",
            "Epoch 18/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.590993404388428 - val_accuracy: 0.114 - penalty: 2e-05\n",
            "hidden layer sizes: [46, 11, 19, 22, 47, 310], total units: 455\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.5909929275512695 - val_accuracy: 0.114 - penalty: 2e-05\n",
            "hidden layer sizes: [66, 31, 39, 42, 67, 372], total units: 617\n",
            "Before pruning:\n",
            "loss: 3.1736769676208496 - accuracy: 0.2573400139808655 - val_loss: 4.658469200134277 - val_accuracy: 0.1158 - penalty: 2e-05\n",
            "hidden layer sizes: [66, 31, 39, 42, 67, 372], total units: 617\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.662522315979004 - val_accuracy: 0.1162 - penalty: 2e-05\n",
            "hidden layer sizes: [45, 11, 19, 21, 49, 310], total units: 455\n",
            "##########################################################\n",
            "Epoch 19/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.662522315979004 - val_accuracy: 0.1162 - penalty: 2e-05\n",
            "hidden layer sizes: [45, 11, 19, 21, 49, 310], total units: 455\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.662522315979004 - val_accuracy: 0.1162 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 31, 39, 41, 69, 372], total units: 617\n",
            "Before pruning:\n",
            "loss: 3.155961036682129 - accuracy: 0.26017001271247864 - val_loss: 4.634313583374023 - val_accuracy: 0.1186 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 31, 39, 41, 69, 372], total units: 617\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.637068748474121 - val_accuracy: 0.1185 - penalty: 2e-05\n",
            "hidden layer sizes: [45, 11, 19, 21, 52, 310], total units: 458\n",
            "##########################################################\n",
            "Epoch 20/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.637068748474121 - val_accuracy: 0.1185 - penalty: 2e-05\n",
            "hidden layer sizes: [45, 11, 19, 21, 52, 310], total units: 458\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.637068748474121 - val_accuracy: 0.1185 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 31, 39, 41, 72, 372], total units: 620\n",
            "Before pruning:\n",
            "loss: 3.1518542766571045 - accuracy: 0.2615399956703186 - val_loss: 4.631877422332764 - val_accuracy: 0.1127 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 31, 39, 41, 72, 372], total units: 620\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.631044387817383 - val_accuracy: 0.1125 - penalty: 2e-05\n",
            "hidden layer sizes: [45, 11, 19, 20, 53, 311], total units: 459\n",
            "##########################################################\n",
            "Epoch 21/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.631044387817383 - val_accuracy: 0.1125 - penalty: 2e-05\n",
            "hidden layer sizes: [45, 11, 19, 20, 53, 311], total units: 459\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.631043910980225 - val_accuracy: 0.1125 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 31, 39, 40, 73, 373], total units: 621\n",
            "Before pruning:\n",
            "loss: 3.1324663162231445 - accuracy: 0.2641499936580658 - val_loss: 4.635553359985352 - val_accuracy: 0.1119 - penalty: 2e-05\n",
            "hidden layer sizes: [65, 31, 39, 40, 73, 373], total units: 621\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.6361799240112305 - val_accuracy: 0.1116 - penalty: 2e-05\n",
            "hidden layer sizes: [44, 11, 19, 20, 59, 310], total units: 463\n",
            "##########################################################\n",
            "Epoch 22/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.6361799240112305 - val_accuracy: 0.1116 - penalty: 2e-05\n",
            "hidden layer sizes: [44, 11, 19, 20, 59, 310], total units: 463\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.636180400848389 - val_accuracy: 0.1116 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 31, 39, 40, 79, 372], total units: 625\n",
            "Before pruning:\n",
            "loss: 3.1299192905426025 - accuracy: 0.26298999786376953 - val_loss: 4.561365127563477 - val_accuracy: 0.1167 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 31, 39, 40, 79, 372], total units: 625\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.561691761016846 - val_accuracy: 0.1165 - penalty: 2e-05\n",
            "hidden layer sizes: [44, 11, 19, 20, 57, 311], total units: 462\n",
            "##########################################################\n",
            "Epoch 23/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.561691761016846 - val_accuracy: 0.1165 - penalty: 2e-05\n",
            "hidden layer sizes: [44, 11, 19, 20, 57, 311], total units: 462\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.561690807342529 - val_accuracy: 0.1165 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 31, 39, 40, 77, 373], total units: 624\n",
            "Before pruning:\n",
            "loss: 3.1130590438842773 - accuracy: 0.2670300006866455 - val_loss: 4.419095516204834 - val_accuracy: 0.1283 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 31, 39, 40, 77, 373], total units: 624\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.418542385101318 - val_accuracy: 0.1284 - penalty: 2e-05\n",
            "hidden layer sizes: [44, 11, 19, 21, 58, 310], total units: 463\n",
            "##########################################################\n",
            "Epoch 24/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.418542385101318 - val_accuracy: 0.1284 - penalty: 2e-05\n",
            "hidden layer sizes: [44, 11, 19, 21, 58, 310], total units: 463\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.418542385101318 - val_accuracy: 0.1284 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 31, 39, 41, 78, 372], total units: 625\n",
            "Before pruning:\n",
            "loss: 3.110564708709717 - accuracy: 0.2662599980831146 - val_loss: 4.538193702697754 - val_accuracy: 0.1189 - penalty: 2e-05\n",
            "hidden layer sizes: [64, 31, 39, 41, 78, 372], total units: 625\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.537871837615967 - val_accuracy: 0.119 - penalty: 2e-05\n",
            "hidden layer sizes: [42, 11, 19, 20, 70, 310], total units: 472\n",
            "##########################################################\n",
            "Epoch 25/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.537871837615967 - val_accuracy: 0.119 - penalty: 2e-05\n",
            "hidden layer sizes: [42, 11, 19, 20, 70, 310], total units: 472\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.537872314453125 - val_accuracy: 0.119 - penalty: 2e-05\n",
            "hidden layer sizes: [62, 31, 39, 40, 90, 372], total units: 634\n",
            "Before pruning:\n",
            "loss: 3.1038835048675537 - accuracy: 0.2688699960708618 - val_loss: 4.484906196594238 - val_accuracy: 0.1188 - penalty: 2e-05\n",
            "hidden layer sizes: [62, 31, 39, 40, 90, 372], total units: 634\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.485731601715088 - val_accuracy: 0.1184 - penalty: 2e-05\n",
            "hidden layer sizes: [40, 11, 19, 20, 69, 310], total units: 469\n",
            "##########################################################\n",
            "Epoch 26/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.485731601715088 - val_accuracy: 0.1184 - penalty: 2e-05\n",
            "hidden layer sizes: [40, 11, 19, 20, 69, 310], total units: 469\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.48573112487793 - val_accuracy: 0.1184 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 31, 39, 40, 89, 372], total units: 631\n",
            "Before pruning:\n",
            "loss: 3.0965993404388428 - accuracy: 0.26996999979019165 - val_loss: 4.733083724975586 - val_accuracy: 0.1106 - penalty: 2e-05\n",
            "hidden layer sizes: [60, 31, 39, 40, 89, 372], total units: 631\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.734499931335449 - val_accuracy: 0.1108 - penalty: 2e-05\n",
            "hidden layer sizes: [39, 11, 19, 20, 69, 310], total units: 468\n",
            "##########################################################\n",
            "Epoch 27/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.734499931335449 - val_accuracy: 0.1108 - penalty: 2e-05\n",
            "hidden layer sizes: [39, 11, 19, 20, 69, 310], total units: 468\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.734496116638184 - val_accuracy: 0.1108 - penalty: 2e-05\n",
            "hidden layer sizes: [59, 31, 39, 40, 89, 372], total units: 630\n",
            "Before pruning:\n",
            "loss: 3.090688705444336 - accuracy: 0.2708300054073334 - val_loss: 4.537006378173828 - val_accuracy: 0.1185 - penalty: 2e-05\n",
            "hidden layer sizes: [59, 31, 39, 40, 89, 372], total units: 630\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.53663444519043 - val_accuracy: 0.1186 - penalty: 2e-05\n",
            "hidden layer sizes: [37, 11, 19, 21, 77, 310], total units: 475\n",
            "##########################################################\n",
            "Epoch 28/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.53663444519043 - val_accuracy: 0.1186 - penalty: 2e-05\n",
            "hidden layer sizes: [37, 11, 19, 21, 77, 310], total units: 475\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.536634922027588 - val_accuracy: 0.1186 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 31, 39, 41, 97, 372], total units: 637\n",
            "Before pruning:\n",
            "loss: 3.0844531059265137 - accuracy: 0.271340012550354 - val_loss: 4.629306793212891 - val_accuracy: 0.122 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 31, 39, 41, 97, 372], total units: 637\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.629480361938477 - val_accuracy: 0.122 - penalty: 2e-05\n",
            "hidden layer sizes: [37, 11, 19, 20, 80, 310], total units: 477\n",
            "##########################################################\n",
            "Epoch 29/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.629480361938477 - val_accuracy: 0.122 - penalty: 2e-05\n",
            "hidden layer sizes: [37, 11, 19, 20, 80, 310], total units: 477\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.629480838775635 - val_accuracy: 0.122 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 31, 39, 40, 100, 372], total units: 639\n",
            "Before pruning:\n",
            "loss: 3.0737996101379395 - accuracy: 0.2743400037288666 - val_loss: 4.715211868286133 - val_accuracy: 0.1143 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 31, 39, 40, 100, 372], total units: 639\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.716190338134766 - val_accuracy: 0.1142 - penalty: 2e-05\n",
            "hidden layer sizes: [37, 11, 19, 20, 84, 310], total units: 481\n",
            "##########################################################\n",
            "Epoch 30/60\n",
            "Before growing:\n",
            "loss: None - accuracy: None - val_loss: 4.716190338134766 - val_accuracy: 0.1142 - penalty: 2e-05\n",
            "hidden layer sizes: [37, 11, 19, 20, 84, 310], total units: 481\n",
            "After growing:\n",
            "loss: None - accuracy: None - val_loss: 4.716190338134766 - val_accuracy: 0.1142 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 31, 39, 40, 104, 372], total units: 643\n",
            "Before pruning:\n",
            "loss: 3.0703158378601074 - accuracy: 0.2745800018310547 - val_loss: 4.6840081214904785 - val_accuracy: 0.122 - penalty: 2e-05\n",
            "hidden layer sizes: [57, 31, 39, 40, 104, 372], total units: 643\n",
            "After pruning:\n",
            "loss: None - accuracy: None - val_loss: 4.683945178985596 - val_accuracy: 0.122 - penalty: 2e-05\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 31/60\n",
            "loss: 3.246882915496826 - accuracy: 0.2618100047111511 - val_loss: 4.479153156280518 - val_accuracy: 0.1352 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 32/60\n",
            "loss: 2.8623321056365967 - accuracy: 0.31922000646591187 - val_loss: 4.317714214324951 - val_accuracy: 0.146 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 33/60\n",
            "loss: 2.7526612281799316 - accuracy: 0.3427099883556366 - val_loss: 4.496099948883057 - val_accuracy: 0.145 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 34/60\n",
            "loss: 2.673252820968628 - accuracy: 0.35728999972343445 - val_loss: 4.141044616699219 - val_accuracy: 0.1593 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 35/60\n",
            "loss: 2.59960675239563 - accuracy: 0.37338000535964966 - val_loss: 4.354245185852051 - val_accuracy: 0.1604 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 36/60\n",
            "loss: 2.5359416007995605 - accuracy: 0.3843800127506256 - val_loss: 4.224964618682861 - val_accuracy: 0.1638 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 37/60\n",
            "loss: 2.474172592163086 - accuracy: 0.397379994392395 - val_loss: 4.361893177032471 - val_accuracy: 0.164 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 38/60\n",
            "loss: 2.420325994491577 - accuracy: 0.4077700078487396 - val_loss: 4.305993556976318 - val_accuracy: 0.1627 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 39/60\n",
            "loss: 2.357571601867676 - accuracy: 0.42118000984191895 - val_loss: 4.3974432945251465 - val_accuracy: 0.1579 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 40/60\n",
            "loss: 2.304961919784546 - accuracy: 0.4298900067806244 - val_loss: 4.188836097717285 - val_accuracy: 0.1749 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 41/60\n",
            "loss: 2.2541866302490234 - accuracy: 0.43904000520706177 - val_loss: 4.527584552764893 - val_accuracy: 0.1581 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 42/60\n",
            "loss: 2.215261697769165 - accuracy: 0.44749999046325684 - val_loss: 4.317127227783203 - val_accuracy: 0.1701 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 43/60\n",
            "loss: 2.1589598655700684 - accuracy: 0.45837000012397766 - val_loss: 4.334264755249023 - val_accuracy: 0.1722 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 44/60\n",
            "loss: 2.1167445182800293 - accuracy: 0.4648300111293793 - val_loss: 4.464268207550049 - val_accuracy: 0.1681 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 45/60\n",
            "loss: 2.0733606815338135 - accuracy: 0.4750699996948242 - val_loss: 4.329155921936035 - val_accuracy: 0.1731 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 46/60\n",
            "loss: 2.0307810306549072 - accuracy: 0.48107001185417175 - val_loss: 4.524293422698975 - val_accuracy: 0.169 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 47/60\n",
            "loss: 1.9967544078826904 - accuracy: 0.4906499981880188 - val_loss: 4.519810676574707 - val_accuracy: 0.1652 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 48/60\n",
            "loss: 1.9560863971710205 - accuracy: 0.49731001257896423 - val_loss: 4.475139141082764 - val_accuracy: 0.1689 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 49/60\n",
            "loss: 1.9167506694793701 - accuracy: 0.5062999725341797 - val_loss: 4.369975566864014 - val_accuracy: 0.1728 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 50/60\n",
            "loss: 1.8892220258712769 - accuracy: 0.5125200152397156 - val_loss: 4.365583896636963 - val_accuracy: 0.1838 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 51/60\n",
            "loss: 1.8505090475082397 - accuracy: 0.5185499787330627 - val_loss: 4.421718597412109 - val_accuracy: 0.1788 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 52/60\n",
            "loss: 1.8176560401916504 - accuracy: 0.5260499715805054 - val_loss: 4.528739929199219 - val_accuracy: 0.1744 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 53/60\n",
            "loss: 1.7850289344787598 - accuracy: 0.531279981136322 - val_loss: 4.515427589416504 - val_accuracy: 0.1801 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 54/60\n",
            "loss: 1.7551771402359009 - accuracy: 0.5374000072479248 - val_loss: 4.49268102645874 - val_accuracy: 0.1853 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 55/60\n",
            "loss: 1.7313982248306274 - accuracy: 0.5426200032234192 - val_loss: 4.473310947418213 - val_accuracy: 0.1866 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 56/60\n",
            "loss: 1.6980115175247192 - accuracy: 0.5502099990844727 - val_loss: 4.55034065246582 - val_accuracy: 0.1834 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 57/60\n",
            "loss: 1.6721645593643188 - accuracy: 0.5543500185012817 - val_loss: 4.683237552642822 - val_accuracy: 0.1814 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 58/60\n",
            "loss: 1.657073736190796 - accuracy: 0.5582000017166138 - val_loss: 4.43244743347168 - val_accuracy: 0.1908 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 59/60\n",
            "loss: 1.6225813627243042 - accuracy: 0.5651100277900696 - val_loss: 4.549902439117432 - val_accuracy: 0.1891 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 60/60\n",
            "loss: 1.6119625568389893 - accuracy: 0.5698000192642212 - val_loss: 4.643642425537109 - val_accuracy: 0.188 - penalty: 0.0\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "CPU times: user 20min 36s, sys: 42.8 s, total: 21min 18s\n",
            "Wall time: 16min 16s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "model = get_convolutional_model(tiny_imagenet.X_train_norm, regularization_penalty=0.0002, regularization_method='l1', layer_sizes=[37, 11, 19, 20, 86, 310], output_neurons=200)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "schedule = Schedule([EpochType.STATIC_WITH_REGULARIZATION] * 60)\n",
        "history = model.fit(tiny_imagenet.X_train_norm, tiny_imagenet.y_train, optimizer, schedule=schedule, batch_size=batch_size, min_new_neurons=20, \n",
        "                    validation_data=(tiny_imagenet.X_test_norm, tiny_imagenet.y_test), growth_percentage=0.2, verbose=True)"
      ],
      "metadata": {
        "id": "Mlgve6MyfCpf",
        "outputId": "50d8df8a-0ad1-4e2e-f65e-2c0a38ac9bc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################\n",
            "Epoch 1/60\n",
            "loss: 4.257846355438232 - accuracy: 0.0994499996304512 - val_loss: 5.318850994110107 - val_accuracy: 0.0526 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 2/60\n",
            "loss: 3.785670518875122 - accuracy: 0.16226999461650848 - val_loss: 5.088986396789551 - val_accuracy: 0.0651 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 3/60\n",
            "loss: 3.666051149368286 - accuracy: 0.17880000174045563 - val_loss: 5.0565667152404785 - val_accuracy: 0.0699 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 4/60\n",
            "loss: 3.5895581245422363 - accuracy: 0.19134999811649323 - val_loss: 5.020029544830322 - val_accuracy: 0.0803 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 5/60\n",
            "loss: 3.5234525203704834 - accuracy: 0.2010599970817566 - val_loss: 4.941208362579346 - val_accuracy: 0.0799 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 6/60\n",
            "loss: 3.4741902351379395 - accuracy: 0.2097499966621399 - val_loss: 4.928002834320068 - val_accuracy: 0.0822 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 7/60\n",
            "loss: 3.433316946029663 - accuracy: 0.2162099927663803 - val_loss: 4.859347343444824 - val_accuracy: 0.0894 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 8/60\n",
            "loss: 3.391428232192993 - accuracy: 0.22296999394893646 - val_loss: 4.734714508056641 - val_accuracy: 0.0906 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 9/60\n",
            "loss: 3.356670618057251 - accuracy: 0.22806000709533691 - val_loss: 4.693403244018555 - val_accuracy: 0.0972 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 10/60\n",
            "loss: 3.3287136554718018 - accuracy: 0.2333499938249588 - val_loss: 4.714365005493164 - val_accuracy: 0.0965 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 11/60\n",
            "loss: 3.286480665206909 - accuracy: 0.24026000499725342 - val_loss: 4.663084983825684 - val_accuracy: 0.102 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 12/60\n",
            "loss: 3.2551074028015137 - accuracy: 0.24508999288082123 - val_loss: 4.688838481903076 - val_accuracy: 0.1015 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 13/60\n",
            "loss: 3.2203259468078613 - accuracy: 0.2515900135040283 - val_loss: 4.773599624633789 - val_accuracy: 0.1078 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 14/60\n",
            "loss: 3.185358762741089 - accuracy: 0.25617000460624695 - val_loss: 4.746317386627197 - val_accuracy: 0.1035 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 15/60\n",
            "loss: 3.1519758701324463 - accuracy: 0.2636600136756897 - val_loss: 4.623055934906006 - val_accuracy: 0.1134 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 16/60\n",
            "loss: 3.1274209022521973 - accuracy: 0.2685900032520294 - val_loss: 4.4388861656188965 - val_accuracy: 0.1183 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 17/60\n",
            "loss: 3.096492290496826 - accuracy: 0.2734900116920471 - val_loss: 4.481044292449951 - val_accuracy: 0.1231 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 18/60\n",
            "loss: 3.070535659790039 - accuracy: 0.2780900001525879 - val_loss: 4.486494541168213 - val_accuracy: 0.1248 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 19/60\n",
            "loss: 3.0439131259918213 - accuracy: 0.28404998779296875 - val_loss: 4.55245304107666 - val_accuracy: 0.1202 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 20/60\n",
            "loss: 3.0249149799346924 - accuracy: 0.28758999705314636 - val_loss: 4.341054916381836 - val_accuracy: 0.1287 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 21/60\n",
            "loss: 2.996307849884033 - accuracy: 0.2917200028896332 - val_loss: 4.346397399902344 - val_accuracy: 0.1349 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 22/60\n",
            "loss: 2.9699313640594482 - accuracy: 0.2968299984931946 - val_loss: 4.252047061920166 - val_accuracy: 0.1409 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 23/60\n",
            "loss: 2.941521644592285 - accuracy: 0.3017300069332123 - val_loss: 4.393033504486084 - val_accuracy: 0.1308 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 24/60\n",
            "loss: 2.9225990772247314 - accuracy: 0.3052099943161011 - val_loss: 4.283941745758057 - val_accuracy: 0.1391 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 25/60\n",
            "loss: 2.896031141281128 - accuracy: 0.30952998995780945 - val_loss: 4.322470188140869 - val_accuracy: 0.1368 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 26/60\n",
            "loss: 2.876189708709717 - accuracy: 0.3138900101184845 - val_loss: 4.1742939949035645 - val_accuracy: 0.1522 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 27/60\n",
            "loss: 2.8598687648773193 - accuracy: 0.3165600001811981 - val_loss: 4.080598831176758 - val_accuracy: 0.1606 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 28/60\n",
            "loss: 2.8425440788269043 - accuracy: 0.32062000036239624 - val_loss: 4.150353908538818 - val_accuracy: 0.1537 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 29/60\n",
            "loss: 2.8235578536987305 - accuracy: 0.32381999492645264 - val_loss: 4.258582592010498 - val_accuracy: 0.1485 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 30/60\n",
            "loss: 2.8095505237579346 - accuracy: 0.3274799883365631 - val_loss: 4.251204013824463 - val_accuracy: 0.1445 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 31/60\n",
            "loss: 2.7949438095092773 - accuracy: 0.3278999924659729 - val_loss: 4.206493854522705 - val_accuracy: 0.1521 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 32/60\n",
            "loss: 2.78406023979187 - accuracy: 0.33246999979019165 - val_loss: 4.233453750610352 - val_accuracy: 0.1487 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 33/60\n",
            "loss: 2.770413398742676 - accuracy: 0.3345800042152405 - val_loss: 4.045029163360596 - val_accuracy: 0.162 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 34/60\n",
            "loss: 2.7549400329589844 - accuracy: 0.33682000637054443 - val_loss: 4.149669647216797 - val_accuracy: 0.1615 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 35/60\n",
            "loss: 2.746790647506714 - accuracy: 0.3393099904060364 - val_loss: 4.149161338806152 - val_accuracy: 0.1617 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 36/60\n",
            "loss: 2.728705883026123 - accuracy: 0.3419699966907501 - val_loss: 4.044126033782959 - val_accuracy: 0.1679 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 37/60\n",
            "loss: 2.7194769382476807 - accuracy: 0.342960000038147 - val_loss: 4.092695236206055 - val_accuracy: 0.1624 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 38/60\n",
            "loss: 2.709078550338745 - accuracy: 0.3455899953842163 - val_loss: 4.111531734466553 - val_accuracy: 0.1671 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 39/60\n",
            "loss: 2.701646566390991 - accuracy: 0.3476099967956543 - val_loss: 4.044355392456055 - val_accuracy: 0.1677 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 40/60\n",
            "loss: 2.690676212310791 - accuracy: 0.35071998834609985 - val_loss: 4.106562614440918 - val_accuracy: 0.1634 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 41/60\n",
            "loss: 2.6797430515289307 - accuracy: 0.351500004529953 - val_loss: 4.0388689041137695 - val_accuracy: 0.1702 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 42/60\n",
            "loss: 2.666510820388794 - accuracy: 0.35471001267433167 - val_loss: 4.037220001220703 - val_accuracy: 0.1706 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 43/60\n",
            "loss: 2.6606011390686035 - accuracy: 0.3544999957084656 - val_loss: 4.099428653717041 - val_accuracy: 0.1668 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 44/60\n",
            "loss: 2.655705690383911 - accuracy: 0.3559199869632721 - val_loss: 3.9622836112976074 - val_accuracy: 0.1796 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 45/60\n",
            "loss: 2.6379761695861816 - accuracy: 0.3576500117778778 - val_loss: 4.0088791847229 - val_accuracy: 0.1741 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 46/60\n",
            "loss: 2.6346542835235596 - accuracy: 0.3592100143432617 - val_loss: 3.844907522201538 - val_accuracy: 0.1913 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 47/60\n",
            "loss: 2.6219100952148438 - accuracy: 0.36333999037742615 - val_loss: 3.930230140686035 - val_accuracy: 0.1819 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 48/60\n",
            "loss: 2.613410234451294 - accuracy: 0.3631899952888489 - val_loss: 4.082435131072998 - val_accuracy: 0.1699 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 49/60\n",
            "loss: 2.601804733276367 - accuracy: 0.36570000648498535 - val_loss: 3.9956445693969727 - val_accuracy: 0.176 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 50/60\n",
            "loss: 2.600696325302124 - accuracy: 0.3662799894809723 - val_loss: 4.12166166305542 - val_accuracy: 0.1669 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 51/60\n",
            "loss: 2.598646640777588 - accuracy: 0.3659699857234955 - val_loss: 4.071061134338379 - val_accuracy: 0.1731 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 52/60\n",
            "loss: 2.5841305255889893 - accuracy: 0.36897000670433044 - val_loss: 4.040156841278076 - val_accuracy: 0.1771 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 53/60\n",
            "loss: 2.5771636962890625 - accuracy: 0.3702400028705597 - val_loss: 3.9472649097442627 - val_accuracy: 0.1825 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 54/60\n",
            "loss: 2.5636343955993652 - accuracy: 0.37189000844955444 - val_loss: 3.9921252727508545 - val_accuracy: 0.1791 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 55/60\n",
            "loss: 2.558887243270874 - accuracy: 0.3744499981403351 - val_loss: 3.9890968799591064 - val_accuracy: 0.1805 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 56/60\n",
            "loss: 2.5504958629608154 - accuracy: 0.3749699890613556 - val_loss: 3.853379249572754 - val_accuracy: 0.1943 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 57/60\n",
            "loss: 2.5440421104431152 - accuracy: 0.3768500089645386 - val_loss: 3.9528605937957764 - val_accuracy: 0.1842 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 58/60\n",
            "loss: 2.5352625846862793 - accuracy: 0.37841999530792236 - val_loss: 4.087200164794922 - val_accuracy: 0.1749 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 59/60\n",
            "loss: 2.5295183658599854 - accuracy: 0.3795900046825409 - val_loss: 3.909482479095459 - val_accuracy: 0.189 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "##########################################################\n",
            "Epoch 60/60\n",
            "loss: 2.5280590057373047 - accuracy: 0.3806000053882599 - val_loss: 4.08701753616333 - val_accuracy: 0.1728 - penalty: 0.0002\n",
            "hidden layer sizes: [37, 11, 19, 20, 86, 310], total units: 483\n",
            "CPU times: user 14min 51s, sys: 42.9 s, total: 15min 34s\n",
            "Wall time: 11min 7s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bMrz149vtoST"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}